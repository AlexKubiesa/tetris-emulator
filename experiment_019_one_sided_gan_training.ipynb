{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 019\n",
    "\n",
    "In this experiment, we will try \"one-sided\" GAN training, where we freeze either the generator or discriminator after some number of epochs and train the other one, to assess the degree to which it's \"playing catch-up\" with the other model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecordingDataset(Dataset):\n",
    "    def __init__(self, path: str):\n",
    "        self.path = path\n",
    "        if not os.path.exists(path):\n",
    "            raise FileNotFoundError()\n",
    "        with os.scandir(self.path) as it:\n",
    "            entry: os.DirEntry = next(iter(it))\n",
    "            _, self.ext = os.path.splitext(entry.name)\n",
    "            self.highest_index = max((int(Path(file.path).stem) for file in it), default=-1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.highest_index + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file = os.path.join(self.path, f\"{idx}{self.ext}\")\n",
    "        if not os.path.exists(file):\n",
    "            raise IndexError()\n",
    "        boards = np.load(file)\n",
    "\n",
    "        def transform(board):\n",
    "            board = torch.tensor(board, dtype=torch.long)\n",
    "            board = F.one_hot(board, 2) # One-hot encode the cell types\n",
    "            board = board.type(torch.float) # Convert to floating-point\n",
    "            board = board.permute((2, 0, 1)) # Move channels/classes to dimension 0\n",
    "            return board\n",
    "\n",
    "        x = transform(boards[-2]) # Ignore all boards except the last two\n",
    "        y = transform(boards[-1])\n",
    "        return x, y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2, 22, 10]) torch.float32\n",
      "torch.Size([4, 2, 22, 10]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "train_dataset = RecordingDataset(os.path.join(\"data\", \"tetris_emulator\", \"train\"))\n",
    "test_dataset = RecordingDataset(os.path.join(\"data\", \"tetris_emulator\", \"test\"))\n",
    "batch_size = 4\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "x, y = next(iter(train_dataloader))\n",
    "print(x.shape, x.dtype)\n",
    "print(y.shape, y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TetrisModel(nn.Module):\n",
    "    \"\"\"Predicts the next state of the cells.\n",
    "\n",
    "    Inputs:\n",
    "        x: Tensor of float32 of shape (batch_size, channels, height, width). channels = 2 is the one-hot encoding of cell types, with\n",
    "           0 for empty cells and 1 for filled cells. height = 22 and width = 10 are the dimensions of the game board. The entries\n",
    "           should be 0 for empty cells and 1 for filled cells.\n",
    "        z: Tensor of float32 of shape (batch_size, 4). The entries should be random numbers sampled from a uniform distribution.\n",
    "    \n",
    "    Returns: Tensor of float32 of shape (batch_size, height, width), logits for the new cells. Probabilities close to 0 (negative logits)\n",
    "             correspond to empty cells, and probabilities close to 1 (positive logits) correspond to filled cells.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.loc = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.glob = nn.Sequential(\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(160, 10)\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Conv2d(26, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 2, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, z):\n",
    "        batch_size, channels, height, width = x.shape\n",
    "        \n",
    "        z = z[:, :, None, None] # Expand dims to match x\n",
    "        z = z.repeat(1, 1, height, width) # Upscale to image size\n",
    "        x = torch.cat((x, z), dim=1)\n",
    "\n",
    "        x = self.loc(x)\n",
    "\n",
    "        x_glob = self.glob(x)\n",
    "        x_glob = x_glob[:, :, None, None] # Expand dims\n",
    "        x_glob = x_glob.repeat(1, 1, height, width) # Upscale to image size\n",
    "        x = torch.cat((x, x_glob), dim=1)\n",
    "\n",
    "        y = self.head(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TetrisDiscriminator(nn.Module):\n",
    "    \"\"\"A discriminator for the cell state predictions. Assesses the output of the generator.\n",
    "\n",
    "    Inputs:\n",
    "        x: Tensor of float32 of shape (batch_size, channels, height, width). channels = 2 is the one-hot encoding of cell types, with\n",
    "           0 for empty cells and 1 for filled cells. height = 22 and width = 10 are the dimensions of the game board. The entries\n",
    "           should be 0 for empty cells and 1 for filled cells.\n",
    "        y: Tensor of float32 of shape (batch_size, channels, height, width), as with x. This should be either the output of the\n",
    "           generator (with exp applied) or the one-hot encoding of the ground truth of the next cell states.\n",
    "    \n",
    "    Returns: Tensor of float32 of shape (batch_size, 1), decisions on whether the data are real or fake. Probabilities close to 0 (negative logits)\n",
    "             correspond to fake data, and probabilities close to 1 (positive logits) correspond to real data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.body = nn.Sequential(\n",
    "                nn.Conv2d(4, 16, 3, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2),\n",
    "                nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(160, 16),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(16, 1),\n",
    "                nn.Flatten(start_dim=0)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        x = torch.cat((x, y), dim=1)\n",
    "        logits = self.body(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def find_interesting_examples(dataset, num=4):\n",
    "    num_spawns = num // 2\n",
    "    num_normal = num - num_spawns\n",
    "    \n",
    "    def inner():\n",
    "        num_spawns_left = num_spawns\n",
    "        num_normal_left = num_normal\n",
    "\n",
    "        for x, y in dataset:\n",
    "            # Check for block spawn\n",
    "            if (x.argmax(0)[0] == 0).all() & (y.argmax(0)[0] == 1).any():\n",
    "                if num_spawns_left > 0:\n",
    "                    num_spawns_left -= 1\n",
    "                    yield x, y\n",
    "                else:\n",
    "                    continue\n",
    "            # Yield general examples\n",
    "            if num_normal_left > 0:\n",
    "                num_normal_left -= 1\n",
    "                yield x, y\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "    return list(itertools.islice(inner(), num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_prediction(x, pred, y):\n",
    "    \"\"\"Renders an example and prediction into a single-image array.\n",
    "    \n",
    "    Inputs:\n",
    "        x: Tensor of shape (height, width), the model input.\n",
    "        pred: Tensor of shape (height, width), the model prediction.\n",
    "        y: Tensor of shape (height, width), the target.\n",
    "    \"\"\"\n",
    "    assert len(x.shape) == 2, f\"Expected tensors of shape (width, height) but got {x.shape}\"\n",
    "    assert x.shape == pred.shape, f\"Shapes do not match: {x.shape} != {pred.shape}\"\n",
    "    assert x.shape == y.shape, f\"Shapes do not match: {x.shape} != {y.shape}\"\n",
    "    height, width = x.shape\n",
    "    with torch.no_grad():\n",
    "        separator = torch.ones(height, 1, dtype=x.dtype)\n",
    "        return torch.cat((x, separator, pred, separator, y), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_label = 1.0\n",
    "fake_label = 0.0\n",
    "\n",
    "def train_loop(dataloader, gen, disc, loss_fn, optimizer_gen, optimizer_disc):\n",
    "    gen.train()\n",
    "    disc.train()\n",
    "\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        ##################################################################\n",
    "        # (1) Update discriminator: minimize -log(D(x)) - log(1 - D(G(z)))\n",
    "        ##################################################################\n",
    "        disc.zero_grad()\n",
    "\n",
    "        ## Train with all-real batch\n",
    "        # Format batch\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        batch_size = X.size(0)\n",
    "        real_labels = torch.full((batch_size,), real_label, dtype=torch.float, device=device)\n",
    "        # Forward pass real batch through discriminator\n",
    "        output = torch.flatten(disc(X, y))\n",
    "        # Calculate loss on all-real batch\n",
    "        err_disc_real = loss_fn(output, real_labels)\n",
    "        # Calculate gradients for discriminator in backward pass\n",
    "        err_disc_real.backward()\n",
    "\n",
    "        ## Train with all-fake batch\n",
    "        # Generate batch of latent vectors\n",
    "        z = torch.rand(batch_size, 4, device=device)\n",
    "        # Generate fake image batch with generator\n",
    "        y_fake = gen(X, z)\n",
    "        fake_labels = torch.full((batch_size,), fake_label, dtype=torch.float, device=device)\n",
    "        # Classify all fake batch with discriminator\n",
    "        output = torch.flatten(disc(X, y_fake.detach()))\n",
    "        # Calculate discriminator's loss on the all-fake batch\n",
    "        err_disc_fake = loss_fn(output, fake_labels)\n",
    "        # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
    "        err_disc_fake.backward()\n",
    "\n",
    "        ## Update discriminator weights\n",
    "        # Compute error of discriminator as sum over the fake and the real batches\n",
    "        err_disc = err_disc_real + err_disc_fake\n",
    "        # Update discriminator\n",
    "        optimizer_disc.step()\n",
    "\n",
    "        ##############################################\n",
    "        # (2) Update generator: minimize -log(D(G(z)))\n",
    "        ##############################################\n",
    "        gen.zero_grad()\n",
    "        # Since we just updated the discriminator, perform another forward pass of the all-fake batch through it\n",
    "        output = torch.flatten(disc(X, y_fake))\n",
    "        # Calculate the generator's loss based on this output\n",
    "        # We use real labels because the generator wants to fool the discriminator\n",
    "        err_gen = loss_fn(output, real_labels)\n",
    "        # Calculate gradients for generator\n",
    "        err_gen.backward()\n",
    "        # Update generator\n",
    "        optimizer_gen.step()\n",
    "\n",
    "        # Output training stats\n",
    "        if batch % 20 == 0:\n",
    "            current = batch * dataloader.batch_size + batch_size\n",
    "            print(f\"[{current}/{size}] D loss: {err_disc.item():.4f}, G loss: {err_gen.item():.4f}\")\n",
    "\n",
    "\n",
    "def test_loop(split_name, dataloader, gen, disc, loss_fn, tb_writer, epoch, examples):\n",
    "    gen.eval()\n",
    "    disc.eval()\n",
    "\n",
    "    loss_disc = 0.0\n",
    "    loss_gen = 0.0\n",
    "    disc_accuracy = 0.0\n",
    "    cell_accuracy = 0.0\n",
    "    board_accuracy = 0.0\n",
    "    spawn_recall = 0.0\n",
    "    num_spawns = 0.0\n",
    "    spawn_precision = 0.0\n",
    "    num_predicted_spawns = 0.0\n",
    "\n",
    "    num_batches = len(dataloader)\n",
    "    with torch.no_grad():        \n",
    "        for X, y in dataloader:\n",
    "            batch_size = X.size(0)\n",
    "            real_labels = torch.full((batch_size,), real_label, dtype=torch.float, device=device)\n",
    "            fake_labels = torch.full((batch_size,), fake_label, dtype=torch.float, device=device)\n",
    "\n",
    "            output_real = disc(X, y)\n",
    "            loss_disc += loss_fn(output_real, real_labels).item()\n",
    "\n",
    "            z = torch.rand(batch_size, 4, device=device)\n",
    "            y_fake = gen(X, z)\n",
    "            output_fake = disc(X, y_fake)\n",
    "            \n",
    "            loss_disc += loss_fn(output_fake, fake_labels).item()\n",
    "            loss_gen += loss_fn(output_fake, real_labels).item()\n",
    "\n",
    "            pred_real = (output_real > 0.0)\n",
    "            pred_fake = (output_fake > 0.0)\n",
    "            disc_accuracy += pred_real.type(torch.float).mean().item()\n",
    "            disc_accuracy += (~pred_fake).type(torch.float).mean().item()\n",
    "\n",
    "            classes_X = torch.argmax(X, dim=1)\n",
    "            classes_y = torch.argmax(y, dim=1)\n",
    "            classes_y_fake = torch.argmax(y_fake, dim=1)\n",
    "            cell_accuracy += (classes_y_fake == classes_y).type(torch.float).mean().item()\n",
    "            board_accuracy += (classes_y_fake == classes_y).all(-1).all(-1).type(torch.float).mean().item()\n",
    "\n",
    "            actual_spawns = (classes_X[:, 0, :] == 0).all(-1) & (classes_y[:, 0, :] == 1).any(-1)\n",
    "            predicted_spawns = (classes_y_fake[:, 0, :] == 1).any(-1)\n",
    "            num_true_positives = (actual_spawns & predicted_spawns).type(torch.float).sum().item()\n",
    "            spawn_recall += num_true_positives\n",
    "            num_spawns += actual_spawns.type(torch.float).sum().item()\n",
    "            spawn_precision += num_true_positives\n",
    "            num_predicted_spawns += predicted_spawns.type(torch.float).sum().item()\n",
    "\n",
    "    loss_disc /= num_batches\n",
    "    loss_gen /= num_batches\n",
    "    cell_accuracy /= num_batches\n",
    "    board_accuracy /= num_batches\n",
    "    spawn_recall /= num_spawns\n",
    "    spawn_precision = np.nan if (num_predicted_spawns == 0.0) else (spawn_precision / num_predicted_spawns)\n",
    "    disc_accuracy /= (2.0 * num_batches)\n",
    "\n",
    "    print(f\"{split_name} error: \\n D loss: {loss_disc:>8f}, G loss: {loss_gen:>8f}, D accuracy: {(100*disc_accuracy):>0.1f}%, cell accuracy: {(100*cell_accuracy):>0.1f}%, board accuracy: {(100*board_accuracy):>0.1f}% \\n\")\n",
    "\n",
    "    tb_writer.add_scalar(f\"Discriminator loss/{split_name}\", loss_disc, epoch)\n",
    "    tb_writer.add_scalar(f\"Loss/{split_name}\", loss_gen, epoch)\n",
    "    tb_writer.add_scalar(f\"Discriminator accuracy/{split_name}\", disc_accuracy, epoch)\n",
    "    tb_writer.add_scalar(f\"Cell accuracy/{split_name}\", cell_accuracy, epoch)\n",
    "    tb_writer.add_scalar(f\"Board accuracy/{split_name}\", board_accuracy, epoch)\n",
    "    tb_writer.add_scalar(f\"Spawn recall/{split_name}\", spawn_recall, epoch)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (X, y) in enumerate(examples):\n",
    "            X, y = X.unsqueeze(0), y.unsqueeze(0)\n",
    "            z = torch.rand(1, 4, device=device)\n",
    "            y_fake = gen(X, z)\n",
    "            X, y, y_fake = X.squeeze(0), y.squeeze(0), y_fake.squeeze(0)\n",
    "            X, y, y_fake = X.argmax(0), y.argmax(0), y_fake.argmax(0)\n",
    "            img = render_prediction(X, y_fake, y)\n",
    "            tb_writer.add_image(f\"Predictions/{split_name}/{i}\", img, epoch, dataformats=\"HW\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Freeze generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_freeze_gen(run_name=\"\", freeze_epoch=0):\n",
    "    learning_rate = 1e-3\n",
    "    epochs = 50\n",
    "\n",
    "    gen = TetrisModel().to(device)\n",
    "    disc = TetrisDiscriminator().to(device)\n",
    "\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer_gen = torch.optim.Adam(gen.parameters(), lr=learning_rate)\n",
    "    optimizer_disc = torch.optim.Adam(disc.parameters(), lr=learning_rate)\n",
    "\n",
    "    log_dir = os.path.join(\"runs\", \"experiment_019\")\n",
    "    log_subdir = os.path.join(log_dir, run_name + \"_\" + datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"))\n",
    "    tb_writer = SummaryWriter(log_subdir)\n",
    "\n",
    "    train_examples = find_interesting_examples(train_dataset)\n",
    "    test_examples = find_interesting_examples(test_dataset)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch}\\n-------------------------------\")\n",
    "        if epoch == freeze_epoch:\n",
    "            gen.requires_grad_(False)\n",
    "        train_loop(train_dataloader, gen, disc, loss_fn, optimizer_gen, optimizer_disc)\n",
    "        test_loop(\"train\", train_dataloader, gen, disc, loss_fn, tb_writer, epoch, train_examples)\n",
    "        test_loop(\"test\", test_dataloader, gen, disc, loss_fn, tb_writer, epoch, test_examples)\n",
    "        for name, weight in disc.named_parameters():\n",
    "            tb_writer.add_histogram(f\"Discriminator weights/{name}\", weight, epoch)\n",
    "            tb_writer.add_histogram(f\"Discriminator gradients/{name}\", weight.grad, epoch)\n",
    "\n",
    "    tb_writer.close()\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3967, G loss: 0.7000\n",
      "[84/1762] D loss: 0.6812, G loss: 1.2337\n",
      "[164/1762] D loss: 0.1283, G loss: 2.6326\n",
      "[244/1762] D loss: 0.0180, G loss: 4.3576\n",
      "[324/1762] D loss: 0.0095, G loss: 5.2025\n",
      "[404/1762] D loss: 0.0043, G loss: 5.7294\n",
      "[484/1762] D loss: 0.0049, G loss: 5.9614\n",
      "[564/1762] D loss: 0.0022, G loss: 6.5074\n",
      "[644/1762] D loss: 0.0014, G loss: 6.8991\n",
      "[724/1762] D loss: 0.0019, G loss: 6.7251\n",
      "[804/1762] D loss: 0.0014, G loss: 7.0886\n",
      "[884/1762] D loss: 0.0011, G loss: 7.2144\n",
      "[964/1762] D loss: 0.0015, G loss: 7.2108\n",
      "[1044/1762] D loss: 0.0013, G loss: 7.3081\n",
      "[1124/1762] D loss: 0.0007, G loss: 7.7848\n",
      "[1204/1762] D loss: 0.0004, G loss: 7.9899\n",
      "[1284/1762] D loss: 0.0006, G loss: 8.0130\n",
      "[1364/1762] D loss: 0.0003, G loss: 8.2685\n",
      "[1444/1762] D loss: 0.0004, G loss: 8.1606\n",
      "[1524/1762] D loss: 0.0005, G loss: 8.0983\n",
      "[1604/1762] D loss: 0.0003, G loss: 8.4089\n",
      "[1684/1762] D loss: 0.0003, G loss: 8.3041\n",
      "[1762/1762] D loss: 0.0003, G loss: 8.2198\n",
      "train error: \n",
      " D loss: 0.000999, G loss: 7.045203, D accuracy: 100.0%, cell accuracy: 84.0%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000966, G loss: 7.083926, D accuracy: 100.0%, cell accuracy: 84.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0004, G loss: 8.3749\n",
      "[84/1762] D loss: 0.0002, G loss: 8.7084\n",
      "[164/1762] D loss: 0.0002, G loss: 8.5953\n",
      "[244/1762] D loss: 0.0002, G loss: 8.7086\n",
      "[324/1762] D loss: 0.0002, G loss: 8.9406\n",
      "[404/1762] D loss: 0.0002, G loss: 8.9395\n",
      "[484/1762] D loss: 0.0003, G loss: 8.7038\n",
      "[564/1762] D loss: 0.0002, G loss: 8.7545\n",
      "[644/1762] D loss: 0.0001, G loss: 9.4363\n",
      "[724/1762] D loss: 0.0001, G loss: 9.1592\n",
      "[804/1762] D loss: 0.0002, G loss: 9.0448\n",
      "[884/1762] D loss: 0.0001, G loss: 9.3698\n",
      "[964/1762] D loss: 0.0002, G loss: 9.1722\n",
      "[1044/1762] D loss: 0.0001, G loss: 9.6161\n",
      "[1124/1762] D loss: 0.0001, G loss: 9.7131\n",
      "[1204/1762] D loss: 0.0001, G loss: 9.4345\n",
      "[1284/1762] D loss: 0.0001, G loss: 9.1429\n",
      "[1364/1762] D loss: 0.0001, G loss: 9.6725\n",
      "[1444/1762] D loss: 0.0001, G loss: 9.7410\n",
      "[1524/1762] D loss: 0.0001, G loss: 9.4662\n",
      "[1604/1762] D loss: 0.0001, G loss: 10.0077\n",
      "[1684/1762] D loss: 0.0001, G loss: 10.0314\n",
      "[1762/1762] D loss: 0.0001, G loss: 9.7821\n",
      "train error: \n",
      " D loss: 0.000317, G loss: 8.180848, D accuracy: 100.0%, cell accuracy: 82.6%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000317, G loss: 8.192669, D accuracy: 100.0%, cell accuracy: 82.8%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001, G loss: 9.6765\n",
      "[84/1762] D loss: 0.0001, G loss: 9.9072\n",
      "[164/1762] D loss: 0.0001, G loss: 9.5632\n",
      "[244/1762] D loss: 0.0001, G loss: 9.5941\n",
      "[324/1762] D loss: 0.0001, G loss: 10.1525\n",
      "[404/1762] D loss: 0.0000, G loss: 10.4192\n",
      "[484/1762] D loss: 0.0000, G loss: 10.2358\n",
      "[564/1762] D loss: 0.0000, G loss: 10.0448\n",
      "[644/1762] D loss: 0.0001, G loss: 9.7998\n",
      "[724/1762] D loss: 0.0000, G loss: 10.4930\n",
      "[804/1762] D loss: 0.0000, G loss: 10.3619\n",
      "[884/1762] D loss: 0.0000, G loss: 10.5281\n",
      "[964/1762] D loss: 0.0001, G loss: 9.9777\n",
      "[1044/1762] D loss: 0.0000, G loss: 10.3671\n",
      "[1124/1762] D loss: 0.0001, G loss: 10.3436\n",
      "[1204/1762] D loss: 0.0000, G loss: 10.3198\n",
      "[1284/1762] D loss: 0.0001, G loss: 10.3267\n",
      "[1364/1762] D loss: 0.0001, G loss: 10.0955\n",
      "[1444/1762] D loss: 0.0001, G loss: 10.1942\n",
      "[1524/1762] D loss: 0.0000, G loss: 10.7122\n",
      "[1604/1762] D loss: 0.0000, G loss: 10.4711\n",
      "[1684/1762] D loss: 0.0000, G loss: 10.7423\n",
      "[1762/1762] D loss: 0.0000, G loss: 10.7361\n",
      "train error: \n",
      " D loss: 0.000158, G loss: 8.875541, D accuracy: 100.0%, cell accuracy: 82.3%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000159, G loss: 8.887409, D accuracy: 100.0%, cell accuracy: 81.8%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 10.3574\n",
      "[84/1762] D loss: 0.0000, G loss: 10.4831\n",
      "[164/1762] D loss: 0.0001, G loss: 10.1098\n",
      "[244/1762] D loss: 0.0001, G loss: 10.3298\n",
      "[324/1762] D loss: 0.0000, G loss: 10.6816\n",
      "[404/1762] D loss: 0.0000, G loss: 10.7225\n",
      "[484/1762] D loss: 0.0000, G loss: 11.0263\n",
      "[564/1762] D loss: 0.0000, G loss: 10.5917\n",
      "[644/1762] D loss: 0.0000, G loss: 10.7384\n",
      "[724/1762] D loss: 0.0000, G loss: 10.9636\n",
      "[804/1762] D loss: 0.0000, G loss: 10.8041\n",
      "[884/1762] D loss: 0.0000, G loss: 10.7700\n",
      "[964/1762] D loss: 0.0000, G loss: 10.6535\n",
      "[1044/1762] D loss: 0.0000, G loss: 11.1726\n",
      "[1124/1762] D loss: 0.0000, G loss: 10.9636\n",
      "[1204/1762] D loss: 0.0000, G loss: 10.9282\n",
      "[1284/1762] D loss: 0.0000, G loss: 11.1105\n",
      "[1364/1762] D loss: 0.0000, G loss: 11.2802\n",
      "[1444/1762] D loss: 0.0000, G loss: 11.3226\n",
      "[1524/1762] D loss: 0.0000, G loss: 10.8819\n",
      "[1604/1762] D loss: 0.0000, G loss: 11.4300\n",
      "[1684/1762] D loss: 0.0000, G loss: 10.9852\n",
      "[1762/1762] D loss: 0.0000, G loss: 11.2732\n",
      "train error: \n",
      " D loss: 0.000083, G loss: 9.546412, D accuracy: 100.0%, cell accuracy: 84.0%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000081, G loss: 9.573462, D accuracy: 100.0%, cell accuracy: 84.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 11.3281\n",
      "[84/1762] D loss: 0.0000, G loss: 11.1797\n",
      "[164/1762] D loss: 0.0000, G loss: 10.9202\n",
      "[244/1762] D loss: 0.0000, G loss: 11.6052\n",
      "[324/1762] D loss: 0.0000, G loss: 11.7920\n",
      "[404/1762] D loss: 0.0000, G loss: 11.4054\n",
      "[484/1762] D loss: 0.0000, G loss: 11.5136\n",
      "[564/1762] D loss: 0.0000, G loss: 11.6944\n",
      "[644/1762] D loss: 0.0000, G loss: 11.4223\n",
      "[724/1762] D loss: 0.0000, G loss: 11.6452\n",
      "[804/1762] D loss: 0.0000, G loss: 11.3478\n",
      "[884/1762] D loss: 0.0000, G loss: 11.6635\n",
      "[964/1762] D loss: 0.0000, G loss: 11.3054\n",
      "[1044/1762] D loss: 0.0000, G loss: 11.5788\n",
      "[1124/1762] D loss: 0.0000, G loss: 11.3245\n",
      "[1204/1762] D loss: 0.0000, G loss: 11.5999\n",
      "[1284/1762] D loss: 0.0000, G loss: 11.8915\n",
      "[1364/1762] D loss: 0.0000, G loss: 11.6344\n",
      "[1444/1762] D loss: 0.0000, G loss: 11.7327\n",
      "[1524/1762] D loss: 0.0000, G loss: 11.9281\n",
      "[1604/1762] D loss: 0.0000, G loss: 11.8043\n",
      "[1684/1762] D loss: 0.0000, G loss: 11.7454\n",
      "[1762/1762] D loss: 0.0000, G loss: 11.9323\n",
      "train error: \n",
      " D loss: 0.000065, G loss: 9.769941, D accuracy: 100.0%, cell accuracy: 84.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000064, G loss: 9.788382, D accuracy: 100.0%, cell accuracy: 85.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 11.6997\n",
      "[84/1762] D loss: 0.0000, G loss: 11.9309\n",
      "[164/1762] D loss: 0.0000, G loss: 11.5207\n",
      "[244/1762] D loss: 0.0000, G loss: 11.9324\n",
      "[324/1762] D loss: 0.0000, G loss: 11.4642\n",
      "[404/1762] D loss: 0.0000, G loss: 11.9817\n",
      "[484/1762] D loss: 0.0000, G loss: 12.2077\n",
      "[564/1762] D loss: 0.0000, G loss: 11.9371\n",
      "[644/1762] D loss: 0.0000, G loss: 12.0152\n",
      "[724/1762] D loss: 0.0000, G loss: 11.6145\n",
      "[804/1762] D loss: 0.0000, G loss: 11.8149\n",
      "[884/1762] D loss: 0.0000, G loss: 11.9659\n",
      "[964/1762] D loss: 0.0000, G loss: 11.5620\n",
      "[1044/1762] D loss: 0.0000, G loss: 11.6866\n",
      "[1124/1762] D loss: 0.0000, G loss: 12.0532\n",
      "[1204/1762] D loss: 0.0000, G loss: 12.2644\n",
      "[1284/1762] D loss: 0.0000, G loss: 12.0877\n",
      "[1364/1762] D loss: 0.0000, G loss: 11.8539\n",
      "[1444/1762] D loss: 0.0000, G loss: 11.8009\n",
      "[1524/1762] D loss: 0.0000, G loss: 11.6887\n",
      "[1604/1762] D loss: 0.0000, G loss: 12.4385\n",
      "[1684/1762] D loss: 0.0000, G loss: 11.6334\n",
      "[1762/1762] D loss: 0.0000, G loss: 12.3396\n",
      "train error: \n",
      " D loss: 0.000039, G loss: 10.277949, D accuracy: 100.0%, cell accuracy: 83.0%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000039, G loss: 10.293179, D accuracy: 100.0%, cell accuracy: 83.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 12.2372\n",
      "[84/1762] D loss: 0.0000, G loss: 12.3020\n",
      "[164/1762] D loss: 0.0000, G loss: 11.9707\n",
      "[244/1762] D loss: 0.0000, G loss: 12.2826\n",
      "[324/1762] D loss: 0.0000, G loss: 12.2295\n",
      "[404/1762] D loss: 0.0000, G loss: 12.0461\n",
      "[484/1762] D loss: 0.0000, G loss: 11.9387\n",
      "[564/1762] D loss: 0.0000, G loss: 12.2068\n",
      "[644/1762] D loss: 0.0000, G loss: 12.1797\n",
      "[724/1762] D loss: 0.0000, G loss: 12.1865\n",
      "[804/1762] D loss: 0.0000, G loss: 12.7585\n",
      "[884/1762] D loss: 0.0000, G loss: 11.9874\n",
      "[964/1762] D loss: 0.0000, G loss: 12.1297\n",
      "[1044/1762] D loss: 0.0000, G loss: 12.3172\n",
      "[1124/1762] D loss: 0.0000, G loss: 12.4652\n",
      "[1204/1762] D loss: 0.0000, G loss: 12.4127\n",
      "[1284/1762] D loss: 0.0000, G loss: 12.4334\n",
      "[1364/1762] D loss: 0.0000, G loss: 12.5495\n",
      "[1444/1762] D loss: 0.0000, G loss: 11.9629\n",
      "[1524/1762] D loss: 0.0000, G loss: 12.2698\n",
      "[1604/1762] D loss: 0.0000, G loss: 12.4159\n",
      "[1684/1762] D loss: 0.0000, G loss: 12.7941\n",
      "[1762/1762] D loss: 0.0000, G loss: 12.4858\n",
      "train error: \n",
      " D loss: 0.000028, G loss: 10.623888, D accuracy: 100.0%, cell accuracy: 82.8%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000028, G loss: 10.640339, D accuracy: 100.0%, cell accuracy: 83.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 12.2154\n",
      "[84/1762] D loss: 0.0000, G loss: 12.6013\n",
      "[164/1762] D loss: 0.0000, G loss: 12.4299\n",
      "[244/1762] D loss: 0.0000, G loss: 12.5424\n",
      "[324/1762] D loss: 0.0000, G loss: 12.7895\n",
      "[404/1762] D loss: 0.0000, G loss: 12.9561\n",
      "[484/1762] D loss: 0.0000, G loss: 12.2860\n",
      "[564/1762] D loss: 0.0000, G loss: 12.6787\n",
      "[644/1762] D loss: 0.0000, G loss: 11.9088\n",
      "[724/1762] D loss: 0.0000, G loss: 12.4564\n",
      "[804/1762] D loss: 0.0000, G loss: 12.9078\n",
      "[884/1762] D loss: 0.0000, G loss: 12.6246\n",
      "[964/1762] D loss: 0.0000, G loss: 12.6975\n",
      "[1044/1762] D loss: 0.0000, G loss: 12.8439\n",
      "[1124/1762] D loss: 0.0000, G loss: 13.0858\n",
      "[1204/1762] D loss: 0.0000, G loss: 13.0479\n",
      "[1284/1762] D loss: 0.0000, G loss: 12.9080\n",
      "[1364/1762] D loss: 0.0000, G loss: 12.9145\n",
      "[1444/1762] D loss: 0.0000, G loss: 12.9212\n",
      "[1524/1762] D loss: 0.0000, G loss: 13.0874\n",
      "[1604/1762] D loss: 0.0000, G loss: 12.5018\n",
      "[1684/1762] D loss: 0.0000, G loss: 12.4980\n",
      "[1762/1762] D loss: 0.0000, G loss: 13.1744\n",
      "train error: \n",
      " D loss: 0.000024, G loss: 10.760295, D accuracy: 100.0%, cell accuracy: 84.3%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000025, G loss: 10.750269, D accuracy: 100.0%, cell accuracy: 84.5%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 12.6448\n",
      "[84/1762] D loss: 0.0000, G loss: 12.9970\n",
      "[164/1762] D loss: 0.0000, G loss: 12.9879\n",
      "[244/1762] D loss: 0.0000, G loss: 13.3499\n",
      "[324/1762] D loss: 0.0000, G loss: 13.2437\n",
      "[404/1762] D loss: 0.0000, G loss: 12.8542\n",
      "[484/1762] D loss: 0.0000, G loss: 12.7873\n",
      "[564/1762] D loss: 0.0000, G loss: 12.9946\n",
      "[644/1762] D loss: 0.0000, G loss: 13.2783\n",
      "[724/1762] D loss: 0.0000, G loss: 12.8881\n",
      "[804/1762] D loss: 0.0000, G loss: 13.0329\n",
      "[884/1762] D loss: 0.0000, G loss: 13.4121\n",
      "[964/1762] D loss: 0.0000, G loss: 13.0253\n",
      "[1044/1762] D loss: 0.0000, G loss: 12.6710\n",
      "[1124/1762] D loss: 0.0000, G loss: 13.3251\n",
      "[1204/1762] D loss: 0.0000, G loss: 13.1006\n",
      "[1284/1762] D loss: 0.0000, G loss: 12.9661\n",
      "[1364/1762] D loss: 0.0000, G loss: 12.7899\n",
      "[1444/1762] D loss: 0.0000, G loss: 13.4548\n",
      "[1524/1762] D loss: 0.0000, G loss: 13.3191\n",
      "[1604/1762] D loss: 0.0000, G loss: 13.2749\n",
      "[1684/1762] D loss: 0.0000, G loss: 12.7685\n",
      "[1762/1762] D loss: 0.0000, G loss: 13.1936\n",
      "train error: \n",
      " D loss: 0.000014, G loss: 11.297815, D accuracy: 100.0%, cell accuracy: 83.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000014, G loss: 11.320919, D accuracy: 100.0%, cell accuracy: 83.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 12.9588\n",
      "[84/1762] D loss: 0.0000, G loss: 13.2792\n",
      "[164/1762] D loss: 0.0000, G loss: 12.8795\n",
      "[244/1762] D loss: 0.0000, G loss: 12.9417\n",
      "[324/1762] D loss: 0.0000, G loss: 13.6240\n",
      "[404/1762] D loss: 0.0000, G loss: 13.3917\n",
      "[484/1762] D loss: 0.0000, G loss: 13.4542\n",
      "[564/1762] D loss: 0.0000, G loss: 13.0993\n",
      "[644/1762] D loss: 0.0000, G loss: 13.5656\n",
      "[724/1762] D loss: 0.0000, G loss: 13.1856\n",
      "[804/1762] D loss: 0.0000, G loss: 13.0660\n",
      "[884/1762] D loss: 0.0000, G loss: 13.2142\n",
      "[964/1762] D loss: 0.0000, G loss: 13.3487\n",
      "[1044/1762] D loss: 0.0000, G loss: 13.3189\n",
      "[1124/1762] D loss: 0.0000, G loss: 13.3620\n",
      "[1204/1762] D loss: 0.0000, G loss: 13.5143\n",
      "[1284/1762] D loss: 0.0000, G loss: 13.4195\n",
      "[1364/1762] D loss: 0.0000, G loss: 13.4769\n",
      "[1444/1762] D loss: 0.0000, G loss: 13.3881\n",
      "[1524/1762] D loss: 0.0000, G loss: 13.2673\n",
      "[1604/1762] D loss: 0.0000, G loss: 13.6496\n",
      "[1684/1762] D loss: 0.0000, G loss: 13.5216\n",
      "[1762/1762] D loss: 0.0000, G loss: 13.3290\n",
      "train error: \n",
      " D loss: 0.000010, G loss: 11.696655, D accuracy: 100.0%, cell accuracy: 83.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000010, G loss: 11.678417, D accuracy: 100.0%, cell accuracy: 83.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 13.6455\n",
      "[84/1762] D loss: 0.0000, G loss: 13.8978\n",
      "[164/1762] D loss: 0.0000, G loss: 13.3311\n",
      "[244/1762] D loss: 0.0000, G loss: 13.9875\n",
      "[324/1762] D loss: 0.0000, G loss: 13.5786\n",
      "[404/1762] D loss: 0.0000, G loss: 13.6075\n",
      "[484/1762] D loss: 0.0000, G loss: 13.8161\n",
      "[564/1762] D loss: 0.0000, G loss: 13.5453\n",
      "[644/1762] D loss: 0.0000, G loss: 13.6643\n",
      "[724/1762] D loss: 0.0000, G loss: 13.4427\n",
      "[804/1762] D loss: 0.0000, G loss: 13.6854\n",
      "[884/1762] D loss: 0.0000, G loss: 13.8497\n",
      "[964/1762] D loss: 0.0000, G loss: 13.5005\n",
      "[1044/1762] D loss: 0.0000, G loss: 13.7279\n",
      "[1124/1762] D loss: 0.0000, G loss: 14.0737\n",
      "[1204/1762] D loss: 0.0000, G loss: 13.7448\n",
      "[1284/1762] D loss: 0.0000, G loss: 13.7293\n",
      "[1364/1762] D loss: 0.0000, G loss: 13.6898\n",
      "[1444/1762] D loss: 0.0000, G loss: 13.9180\n",
      "[1524/1762] D loss: 0.0000, G loss: 13.5579\n",
      "[1604/1762] D loss: 0.0000, G loss: 13.9125\n",
      "[1684/1762] D loss: 0.0000, G loss: 13.8820\n",
      "[1762/1762] D loss: 0.0000, G loss: 13.9890\n",
      "train error: \n",
      " D loss: 0.000010, G loss: 11.660310, D accuracy: 100.0%, cell accuracy: 84.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000010, G loss: 11.663774, D accuracy: 100.0%, cell accuracy: 84.5%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 13.1934\n",
      "[84/1762] D loss: 0.0000, G loss: 13.9481\n",
      "[164/1762] D loss: 0.0000, G loss: 13.6644\n",
      "[244/1762] D loss: 0.0000, G loss: 13.9396\n",
      "[324/1762] D loss: 0.0000, G loss: 13.8989\n",
      "[404/1762] D loss: 0.0000, G loss: 13.8842\n",
      "[484/1762] D loss: 0.0000, G loss: 13.9217\n",
      "[564/1762] D loss: 0.0000, G loss: 13.3860\n",
      "[644/1762] D loss: 0.0000, G loss: 14.0369\n",
      "[724/1762] D loss: 0.0000, G loss: 13.8019\n",
      "[804/1762] D loss: 0.0000, G loss: 13.9983\n",
      "[884/1762] D loss: 0.0000, G loss: 13.8682\n",
      "[964/1762] D loss: 0.0000, G loss: 13.6498\n",
      "[1044/1762] D loss: 0.0000, G loss: 13.6659\n",
      "[1124/1762] D loss: 0.0000, G loss: 14.1139\n",
      "[1204/1762] D loss: 0.0000, G loss: 14.3578\n",
      "[1284/1762] D loss: 0.0000, G loss: 13.8958\n",
      "[1364/1762] D loss: 0.0000, G loss: 14.1873\n",
      "[1444/1762] D loss: 0.0000, G loss: 14.0686\n",
      "[1524/1762] D loss: 0.0000, G loss: 13.9446\n",
      "[1604/1762] D loss: 0.0000, G loss: 14.2955\n",
      "[1684/1762] D loss: 0.0000, G loss: 13.9222\n",
      "[1762/1762] D loss: 0.0000, G loss: 13.9856\n",
      "train error: \n",
      " D loss: 0.000008, G loss: 11.832420, D accuracy: 100.0%, cell accuracy: 83.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000009, G loss: 11.825372, D accuracy: 100.0%, cell accuracy: 84.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 14.2757\n",
      "[84/1762] D loss: 0.0000, G loss: 13.9657\n",
      "[164/1762] D loss: 0.0000, G loss: 14.3308\n",
      "[244/1762] D loss: 0.0000, G loss: 14.4894\n",
      "[324/1762] D loss: 0.0000, G loss: 14.1213\n",
      "[404/1762] D loss: 0.0000, G loss: 13.8392\n",
      "[484/1762] D loss: 0.0000, G loss: 14.5695\n",
      "[564/1762] D loss: 0.0000, G loss: 14.0613\n",
      "[644/1762] D loss: 0.0000, G loss: 14.3553\n",
      "[724/1762] D loss: 0.0000, G loss: 14.5969\n",
      "[804/1762] D loss: 0.0000, G loss: 13.8984\n",
      "[884/1762] D loss: 0.0000, G loss: 14.2818\n",
      "[964/1762] D loss: 0.0000, G loss: 14.4759\n",
      "[1044/1762] D loss: 0.0000, G loss: 14.4675\n",
      "[1124/1762] D loss: 0.0000, G loss: 13.7900\n",
      "[1204/1762] D loss: 0.0000, G loss: 14.0570\n",
      "[1284/1762] D loss: 0.0000, G loss: 14.4910\n",
      "[1364/1762] D loss: 0.0000, G loss: 14.2108\n",
      "[1444/1762] D loss: 0.0000, G loss: 13.8059\n",
      "[1524/1762] D loss: 0.0000, G loss: 14.6570\n",
      "[1604/1762] D loss: 0.0000, G loss: 14.5977\n",
      "[1684/1762] D loss: 0.0000, G loss: 14.5449\n",
      "[1762/1762] D loss: 0.0000, G loss: 14.6570\n",
      "train error: \n",
      " D loss: 0.000005, G loss: 12.272585, D accuracy: 100.0%, cell accuracy: 83.6%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000005, G loss: 12.309478, D accuracy: 100.0%, cell accuracy: 83.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 14.6078\n",
      "[84/1762] D loss: 0.0000, G loss: 13.9208\n",
      "[164/1762] D loss: 0.0000, G loss: 14.4894\n",
      "[244/1762] D loss: 0.0000, G loss: 14.4945\n",
      "[324/1762] D loss: 0.0000, G loss: 14.4639\n",
      "[404/1762] D loss: 0.0000, G loss: 14.8455\n",
      "[484/1762] D loss: 0.0000, G loss: 14.3370\n",
      "[564/1762] D loss: 0.0000, G loss: 14.5486\n",
      "[644/1762] D loss: 0.0000, G loss: 14.3016\n",
      "[724/1762] D loss: 0.0000, G loss: 14.4994\n",
      "[804/1762] D loss: 0.0000, G loss: 14.5731\n",
      "[884/1762] D loss: 0.0000, G loss: 14.4363\n",
      "[964/1762] D loss: 0.0000, G loss: 14.7916\n",
      "[1044/1762] D loss: 0.0000, G loss: 14.5857\n",
      "[1124/1762] D loss: 0.0000, G loss: 14.5514\n",
      "[1204/1762] D loss: 0.0000, G loss: 14.5899\n",
      "[1284/1762] D loss: 0.0000, G loss: 14.4350\n",
      "[1364/1762] D loss: 0.0000, G loss: 14.7456\n",
      "[1444/1762] D loss: 0.0000, G loss: 14.5268\n",
      "[1524/1762] D loss: 0.0000, G loss: 14.1017\n",
      "[1604/1762] D loss: 0.0000, G loss: 14.4368\n",
      "[1684/1762] D loss: 0.0000, G loss: 14.5407\n",
      "[1762/1762] D loss: 0.0000, G loss: 14.4242\n",
      "train error: \n",
      " D loss: 0.000005, G loss: 12.377242, D accuracy: 100.0%, cell accuracy: 83.2%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000005, G loss: 12.401732, D accuracy: 100.0%, cell accuracy: 82.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 14.4326\n",
      "[84/1762] D loss: 0.0000, G loss: 14.7833\n",
      "[164/1762] D loss: 0.0000, G loss: 14.6748\n",
      "[244/1762] D loss: 0.0000, G loss: 14.6277\n",
      "[324/1762] D loss: 0.0000, G loss: 14.8351\n",
      "[404/1762] D loss: 0.0000, G loss: 14.5739\n",
      "[484/1762] D loss: 0.0000, G loss: 15.0557\n",
      "[564/1762] D loss: 0.0000, G loss: 14.8714\n",
      "[644/1762] D loss: 0.0000, G loss: 14.8700\n",
      "[724/1762] D loss: 0.0000, G loss: 14.9756\n",
      "[804/1762] D loss: 0.0000, G loss: 14.7482\n",
      "[884/1762] D loss: 0.0000, G loss: 14.9716\n",
      "[964/1762] D loss: 0.0000, G loss: 14.5309\n",
      "[1044/1762] D loss: 0.0000, G loss: 15.0850\n",
      "[1124/1762] D loss: 0.0000, G loss: 14.8014\n",
      "[1204/1762] D loss: 0.0000, G loss: 14.8695\n",
      "[1284/1762] D loss: 0.0000, G loss: 14.5826\n",
      "[1364/1762] D loss: 0.0000, G loss: 15.1440\n",
      "[1444/1762] D loss: 0.0000, G loss: 14.8248\n",
      "[1524/1762] D loss: 0.0000, G loss: 13.7230\n",
      "[1604/1762] D loss: 0.0000, G loss: 14.9724\n",
      "[1684/1762] D loss: 0.0000, G loss: 14.7972\n",
      "[1762/1762] D loss: 0.0000, G loss: 14.4620\n",
      "train error: \n",
      " D loss: 0.000004, G loss: 12.616685, D accuracy: 100.0%, cell accuracy: 82.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000004, G loss: 12.594389, D accuracy: 100.0%, cell accuracy: 83.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 14.8940\n",
      "[84/1762] D loss: 0.0000, G loss: 15.0476\n",
      "[164/1762] D loss: 0.0000, G loss: 15.1132\n",
      "[244/1762] D loss: 0.0000, G loss: 15.0071\n",
      "[324/1762] D loss: 0.0000, G loss: 15.1884\n",
      "[404/1762] D loss: 0.0000, G loss: 14.9544\n",
      "[484/1762] D loss: 0.0000, G loss: 15.1557\n",
      "[564/1762] D loss: 0.0000, G loss: 15.0359\n",
      "[644/1762] D loss: 0.0000, G loss: 15.0799\n",
      "[724/1762] D loss: 0.0000, G loss: 14.9465\n",
      "[804/1762] D loss: 0.0000, G loss: 14.8168\n",
      "[884/1762] D loss: 0.0000, G loss: 14.7325\n",
      "[964/1762] D loss: 0.0000, G loss: 14.8129\n",
      "[1044/1762] D loss: 0.0000, G loss: 15.0659\n",
      "[1124/1762] D loss: 0.0000, G loss: 15.1093\n",
      "[1204/1762] D loss: 0.0000, G loss: 15.3006\n",
      "[1284/1762] D loss: 0.0000, G loss: 15.2000\n",
      "[1364/1762] D loss: 0.0000, G loss: 14.9302\n",
      "[1444/1762] D loss: 0.0000, G loss: 15.7253\n",
      "[1524/1762] D loss: 0.0000, G loss: 15.0920\n",
      "[1604/1762] D loss: 0.0000, G loss: 15.3359\n",
      "[1684/1762] D loss: 0.0000, G loss: 14.7999\n",
      "[1762/1762] D loss: 0.0000, G loss: 15.4042\n",
      "train error: \n",
      " D loss: 0.000003, G loss: 12.913566, D accuracy: 100.0%, cell accuracy: 82.8%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000003, G loss: 12.964670, D accuracy: 100.0%, cell accuracy: 82.5%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 15.1589\n",
      "[84/1762] D loss: 0.0000, G loss: 15.5883\n",
      "[164/1762] D loss: 0.0000, G loss: 15.4544\n",
      "[244/1762] D loss: 0.0000, G loss: 15.2869\n",
      "[324/1762] D loss: 0.0000, G loss: 15.0275\n",
      "[404/1762] D loss: 0.0000, G loss: 15.3091\n",
      "[484/1762] D loss: 0.0000, G loss: 15.4166\n",
      "[564/1762] D loss: 0.0000, G loss: 14.7658\n",
      "[644/1762] D loss: 0.0000, G loss: 15.4399\n",
      "[724/1762] D loss: 0.0000, G loss: 15.1440\n",
      "[804/1762] D loss: 0.0000, G loss: 15.2610\n",
      "[884/1762] D loss: 0.0000, G loss: 15.0455\n",
      "[964/1762] D loss: 0.0000, G loss: 15.5173\n",
      "[1044/1762] D loss: 0.0000, G loss: 15.3747\n",
      "[1124/1762] D loss: 0.0000, G loss: 15.2239\n",
      "[1204/1762] D loss: 0.0000, G loss: 15.1221\n",
      "[1284/1762] D loss: 0.0000, G loss: 15.4532\n",
      "[1364/1762] D loss: 0.0000, G loss: 15.4978\n",
      "[1444/1762] D loss: 0.0000, G loss: 15.4093\n",
      "[1524/1762] D loss: 0.0000, G loss: 14.8797\n",
      "[1604/1762] D loss: 0.0000, G loss: 15.4182\n",
      "[1684/1762] D loss: 0.0000, G loss: 15.3677\n",
      "[1762/1762] D loss: 0.0000, G loss: 15.7555\n",
      "train error: \n",
      " D loss: 0.000002, G loss: 13.180005, D accuracy: 100.0%, cell accuracy: 83.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000002, G loss: 13.206833, D accuracy: 100.0%, cell accuracy: 82.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 15.6410\n",
      "[84/1762] D loss: 0.0000, G loss: 15.4418\n",
      "[164/1762] D loss: 0.0000, G loss: 15.4783\n",
      "[244/1762] D loss: 0.0000, G loss: 15.5911\n",
      "[324/1762] D loss: 0.0000, G loss: 15.7776\n",
      "[404/1762] D loss: 0.0000, G loss: 15.6394\n",
      "[484/1762] D loss: 0.0000, G loss: 15.5405\n",
      "[564/1762] D loss: 0.0000, G loss: 15.2747\n",
      "[644/1762] D loss: 0.0000, G loss: 15.4436\n",
      "[724/1762] D loss: 0.0000, G loss: 15.7599\n",
      "[804/1762] D loss: 0.0000, G loss: 15.7106\n",
      "[884/1762] D loss: 0.0000, G loss: 15.6349\n",
      "[964/1762] D loss: 0.0000, G loss: 15.5129\n",
      "[1044/1762] D loss: 0.0000, G loss: 15.5339\n",
      "[1124/1762] D loss: 0.0000, G loss: 15.1388\n",
      "[1204/1762] D loss: 0.0000, G loss: 15.5533\n",
      "[1284/1762] D loss: 0.0000, G loss: 15.2620\n",
      "[1364/1762] D loss: 0.0000, G loss: 15.2851\n",
      "[1444/1762] D loss: 0.0000, G loss: 15.7476\n",
      "[1524/1762] D loss: 0.0000, G loss: 15.4255\n",
      "[1604/1762] D loss: 0.0000, G loss: 15.9161\n",
      "[1684/1762] D loss: 0.0000, G loss: 15.8213\n",
      "[1762/1762] D loss: 0.0000, G loss: 16.0516\n",
      "train error: \n",
      " D loss: 0.000002, G loss: 13.343433, D accuracy: 100.0%, cell accuracy: 83.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000002, G loss: 13.361437, D accuracy: 100.0%, cell accuracy: 83.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 15.7724\n",
      "[84/1762] D loss: 0.0000, G loss: 14.8438\n",
      "[164/1762] D loss: 0.0000, G loss: 15.9191\n",
      "[244/1762] D loss: 0.0000, G loss: 15.9302\n",
      "[324/1762] D loss: 0.0000, G loss: 15.6322\n",
      "[404/1762] D loss: 0.0000, G loss: 15.0151\n",
      "[484/1762] D loss: 0.0000, G loss: 16.1432\n",
      "[564/1762] D loss: 0.0000, G loss: 15.8968\n",
      "[644/1762] D loss: 0.0000, G loss: 16.1261\n",
      "[724/1762] D loss: 0.0000, G loss: 15.9024\n",
      "[804/1762] D loss: 0.0000, G loss: 15.0206\n",
      "[884/1762] D loss: 0.0000, G loss: 15.8295\n",
      "[964/1762] D loss: 0.0000, G loss: 15.6781\n",
      "[1044/1762] D loss: 0.0000, G loss: 15.8284\n",
      "[1124/1762] D loss: 0.0000, G loss: 16.0471\n",
      "[1204/1762] D loss: 0.0000, G loss: 15.8401\n",
      "[1284/1762] D loss: 0.0000, G loss: 16.0211\n",
      "[1364/1762] D loss: 0.0000, G loss: 15.7339\n",
      "[1444/1762] D loss: 0.0000, G loss: 15.8170\n",
      "[1524/1762] D loss: 0.0000, G loss: 15.9727\n",
      "[1604/1762] D loss: 0.0000, G loss: 15.5269\n",
      "[1684/1762] D loss: 0.0000, G loss: 16.1400\n",
      "[1762/1762] D loss: 0.0000, G loss: 16.1040\n",
      "train error: \n",
      " D loss: 0.000002, G loss: 13.561526, D accuracy: 100.0%, cell accuracy: 84.8%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000001, G loss: 13.607010, D accuracy: 100.0%, cell accuracy: 84.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 16.1483\n",
      "[84/1762] D loss: 0.0000, G loss: 15.9737\n",
      "[164/1762] D loss: 0.0000, G loss: 15.5069\n",
      "[244/1762] D loss: 0.0000, G loss: 16.0983\n",
      "[324/1762] D loss: 0.0000, G loss: 16.1424\n",
      "[404/1762] D loss: 0.0000, G loss: 16.1289\n",
      "[484/1762] D loss: 0.0000, G loss: 16.3559\n",
      "[564/1762] D loss: 0.0000, G loss: 15.8981\n",
      "[644/1762] D loss: 0.0000, G loss: 16.0013\n",
      "[724/1762] D loss: 0.0000, G loss: 16.1365\n",
      "[804/1762] D loss: 0.0000, G loss: 16.0119\n",
      "[884/1762] D loss: 0.0000, G loss: 16.3784\n",
      "[964/1762] D loss: 0.0000, G loss: 16.2783\n",
      "[1044/1762] D loss: 0.0000, G loss: 16.3271\n",
      "[1124/1762] D loss: 0.0000, G loss: 15.3201\n",
      "[1204/1762] D loss: 0.0000, G loss: 16.0379\n",
      "[1284/1762] D loss: 0.0000, G loss: 16.3192\n",
      "[1364/1762] D loss: 0.0000, G loss: 15.8106\n",
      "[1444/1762] D loss: 0.0000, G loss: 16.1619\n",
      "[1524/1762] D loss: 0.0000, G loss: 16.1975\n",
      "[1604/1762] D loss: 0.0000, G loss: 16.3074\n",
      "[1684/1762] D loss: 0.0000, G loss: 16.2970\n",
      "[1762/1762] D loss: 0.0000, G loss: 16.5988\n",
      "train error: \n",
      " D loss: 0.000001, G loss: 13.936511, D accuracy: 100.0%, cell accuracy: 83.0%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000001, G loss: 13.962461, D accuracy: 100.0%, cell accuracy: 83.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 16.6748\n",
      "[84/1762] D loss: 0.0000, G loss: 15.8582\n",
      "[164/1762] D loss: 0.0000, G loss: 15.9711\n",
      "[244/1762] D loss: 0.0000, G loss: 16.2133\n",
      "[324/1762] D loss: 0.0000, G loss: 16.3418\n",
      "[404/1762] D loss: 0.0000, G loss: 16.5704\n",
      "[484/1762] D loss: 0.0000, G loss: 16.3292\n",
      "[564/1762] D loss: 0.0000, G loss: 16.3687\n",
      "[644/1762] D loss: 0.0000, G loss: 16.3103\n",
      "[724/1762] D loss: 0.0000, G loss: 16.2391\n",
      "[804/1762] D loss: 0.0000, G loss: 16.1533\n",
      "[884/1762] D loss: 0.0000, G loss: 16.5958\n",
      "[964/1762] D loss: 0.0000, G loss: 16.2695\n",
      "[1044/1762] D loss: 0.0000, G loss: 16.6871\n",
      "[1124/1762] D loss: 0.0000, G loss: 16.7833\n",
      "[1204/1762] D loss: 0.0000, G loss: 16.3640\n",
      "[1284/1762] D loss: 0.0000, G loss: 16.2307\n",
      "[1364/1762] D loss: 0.0000, G loss: 16.5739\n",
      "[1444/1762] D loss: 0.0000, G loss: 16.3306\n",
      "[1524/1762] D loss: 0.0000, G loss: 16.7225\n",
      "[1604/1762] D loss: 0.0000, G loss: 16.6815\n",
      "[1684/1762] D loss: 0.0000, G loss: 16.5406\n",
      "[1762/1762] D loss: 0.0000, G loss: 16.9948\n",
      "train error: \n",
      " D loss: 0.000001, G loss: 14.009742, D accuracy: 100.0%, cell accuracy: 83.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000001, G loss: 14.008148, D accuracy: 100.0%, cell accuracy: 83.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 16.7656\n",
      "[84/1762] D loss: 0.0000, G loss: 16.5057\n",
      "[164/1762] D loss: 0.0000, G loss: 15.9896\n",
      "[244/1762] D loss: 0.0000, G loss: 16.7746\n",
      "[324/1762] D loss: 0.0000, G loss: 16.7452\n",
      "[404/1762] D loss: 0.0000, G loss: 16.3576\n",
      "[484/1762] D loss: 0.0000, G loss: 16.4745\n",
      "[564/1762] D loss: 0.0000, G loss: 16.7704\n",
      "[644/1762] D loss: 0.0000, G loss: 16.6161\n",
      "[724/1762] D loss: 0.0000, G loss: 16.6523\n",
      "[804/1762] D loss: 0.0000, G loss: 16.6742\n",
      "[884/1762] D loss: 0.0000, G loss: 16.4632\n",
      "[964/1762] D loss: 0.0000, G loss: 16.4108\n",
      "[1044/1762] D loss: 0.0000, G loss: 16.7287\n",
      "[1124/1762] D loss: 0.0000, G loss: 16.4269\n",
      "[1204/1762] D loss: 0.0000, G loss: 16.8831\n",
      "[1284/1762] D loss: 0.0000, G loss: 16.7412\n",
      "[1364/1762] D loss: 0.0000, G loss: 16.6299\n",
      "[1444/1762] D loss: 0.0000, G loss: 16.4013\n",
      "[1524/1762] D loss: 0.0000, G loss: 16.6971\n",
      "[1604/1762] D loss: 0.0000, G loss: 16.6663\n",
      "[1684/1762] D loss: 0.0000, G loss: 16.4111\n",
      "[1762/1762] D loss: 0.0000, G loss: 17.1421\n",
      "train error: \n",
      " D loss: 0.000001, G loss: 14.146330, D accuracy: 100.0%, cell accuracy: 83.4%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000001, G loss: 14.141030, D accuracy: 100.0%, cell accuracy: 83.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 16.1837\n",
      "[84/1762] D loss: 0.0000, G loss: 16.6694\n",
      "[164/1762] D loss: 0.0000, G loss: 16.4772\n",
      "[244/1762] D loss: 0.0000, G loss: 16.9078\n",
      "[324/1762] D loss: 0.0000, G loss: 16.9613\n",
      "[404/1762] D loss: 0.0000, G loss: 16.5287\n",
      "[484/1762] D loss: 0.0000, G loss: 16.7383\n",
      "[564/1762] D loss: 0.0000, G loss: 16.8747\n",
      "[644/1762] D loss: 0.0000, G loss: 16.8012\n",
      "[724/1762] D loss: 0.0000, G loss: 17.1037\n",
      "[804/1762] D loss: 0.0000, G loss: 16.9190\n",
      "[884/1762] D loss: 0.0000, G loss: 16.4992\n",
      "[964/1762] D loss: 0.0000, G loss: 17.0129\n",
      "[1044/1762] D loss: 0.0000, G loss: 16.8476\n",
      "[1124/1762] D loss: 0.0000, G loss: 17.0243\n",
      "[1204/1762] D loss: 0.0000, G loss: 16.5038\n",
      "[1284/1762] D loss: 0.0000, G loss: 17.1607\n",
      "[1364/1762] D loss: 0.0000, G loss: 17.1284\n",
      "[1444/1762] D loss: 0.0000, G loss: 16.8883\n",
      "[1524/1762] D loss: 0.0000, G loss: 16.7446\n",
      "[1604/1762] D loss: 0.0000, G loss: 17.2899\n",
      "[1684/1762] D loss: 0.0000, G loss: 16.9961\n",
      "[1762/1762] D loss: 0.0000, G loss: 16.7562\n",
      "train error: \n",
      " D loss: 0.000001, G loss: 14.509696, D accuracy: 100.0%, cell accuracy: 84.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000001, G loss: 14.543503, D accuracy: 100.0%, cell accuracy: 83.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 17.1454\n",
      "[84/1762] D loss: 0.0000, G loss: 16.7451\n",
      "[164/1762] D loss: 0.0000, G loss: 17.1207\n",
      "[244/1762] D loss: 0.0000, G loss: 17.1683\n",
      "[324/1762] D loss: 0.0000, G loss: 17.1171\n",
      "[404/1762] D loss: 0.0000, G loss: 17.2926\n",
      "[484/1762] D loss: 0.0000, G loss: 16.6628\n",
      "[564/1762] D loss: 0.0000, G loss: 16.6241\n",
      "[644/1762] D loss: 0.0000, G loss: 17.0873\n",
      "[724/1762] D loss: 0.0000, G loss: 17.1978\n",
      "[804/1762] D loss: 0.0000, G loss: 17.1443\n",
      "[884/1762] D loss: 0.0000, G loss: 17.0809\n",
      "[964/1762] D loss: 0.0000, G loss: 17.1590\n",
      "[1044/1762] D loss: 0.0000, G loss: 17.1607\n",
      "[1124/1762] D loss: 0.0000, G loss: 17.2864\n",
      "[1204/1762] D loss: 0.0000, G loss: 17.1038\n",
      "[1284/1762] D loss: 0.0000, G loss: 17.0463\n",
      "[1364/1762] D loss: 0.0000, G loss: 17.0776\n",
      "[1444/1762] D loss: 0.0000, G loss: 17.2236\n",
      "[1524/1762] D loss: 0.0000, G loss: 17.2247\n",
      "[1604/1762] D loss: 0.0000, G loss: 17.1233\n",
      "[1684/1762] D loss: 0.0000, G loss: 17.0189\n",
      "[1762/1762] D loss: 0.0000, G loss: 17.3928\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 14.834606, D accuracy: 100.0%, cell accuracy: 83.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 14.870383, D accuracy: 100.0%, cell accuracy: 82.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 17.1657\n",
      "[84/1762] D loss: 0.0000, G loss: 17.1782\n",
      "[164/1762] D loss: 0.0000, G loss: 17.2737\n",
      "[244/1762] D loss: 0.0000, G loss: 17.4195\n",
      "[324/1762] D loss: 0.0000, G loss: 17.2582\n",
      "[404/1762] D loss: 0.0000, G loss: 17.3574\n",
      "[484/1762] D loss: 0.0000, G loss: 17.1694\n",
      "[564/1762] D loss: 0.0000, G loss: 17.3918\n",
      "[644/1762] D loss: 0.0000, G loss: 16.8829\n",
      "[724/1762] D loss: 0.0000, G loss: 17.3875\n",
      "[804/1762] D loss: 0.0000, G loss: 17.1638\n",
      "[884/1762] D loss: 0.0000, G loss: 17.5837\n",
      "[964/1762] D loss: 0.0000, G loss: 17.2418\n",
      "[1044/1762] D loss: 0.0000, G loss: 17.3450\n",
      "[1124/1762] D loss: 0.0000, G loss: 17.0955\n",
      "[1204/1762] D loss: 0.0000, G loss: 17.4979\n",
      "[1284/1762] D loss: 0.0000, G loss: 17.5882\n",
      "[1364/1762] D loss: 0.0000, G loss: 17.1292\n",
      "[1444/1762] D loss: 0.0000, G loss: 17.5487\n",
      "[1524/1762] D loss: 0.0000, G loss: 17.4837\n",
      "[1604/1762] D loss: 0.0000, G loss: 17.6340\n",
      "[1684/1762] D loss: 0.0000, G loss: 17.6602\n",
      "[1762/1762] D loss: 0.0000, G loss: 17.5322\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 15.203543, D accuracy: 100.0%, cell accuracy: 83.2%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 15.206093, D accuracy: 100.0%, cell accuracy: 82.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 17.1800\n",
      "[84/1762] D loss: 0.0000, G loss: 17.6033\n",
      "[164/1762] D loss: 0.0000, G loss: 17.6030\n",
      "[244/1762] D loss: 0.0000, G loss: 17.2827\n",
      "[324/1762] D loss: 0.0000, G loss: 17.8562\n",
      "[404/1762] D loss: 0.0000, G loss: 17.7744\n",
      "[484/1762] D loss: 0.0000, G loss: 17.5328\n",
      "[564/1762] D loss: 0.0000, G loss: 17.7566\n",
      "[644/1762] D loss: 0.0000, G loss: 17.5973\n",
      "[724/1762] D loss: 0.0000, G loss: 17.2275\n",
      "[804/1762] D loss: 0.0000, G loss: 17.6355\n",
      "[884/1762] D loss: 0.0000, G loss: 17.3710\n",
      "[964/1762] D loss: 0.0000, G loss: 17.6964\n",
      "[1044/1762] D loss: 0.0000, G loss: 16.8762\n",
      "[1124/1762] D loss: 0.0000, G loss: 17.4060\n",
      "[1204/1762] D loss: 0.0000, G loss: 17.6085\n",
      "[1284/1762] D loss: 0.0000, G loss: 17.7459\n",
      "[1364/1762] D loss: 0.0000, G loss: 17.8755\n",
      "[1444/1762] D loss: 0.0000, G loss: 18.1851\n",
      "[1524/1762] D loss: 0.0000, G loss: 17.6952\n",
      "[1604/1762] D loss: 0.0000, G loss: 17.4825\n",
      "[1684/1762] D loss: 0.0000, G loss: 17.6002\n",
      "[1762/1762] D loss: 0.0000, G loss: 17.8324\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 15.214219, D accuracy: 100.0%, cell accuracy: 83.8%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 15.226550, D accuracy: 100.0%, cell accuracy: 83.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 17.9608\n",
      "[84/1762] D loss: 0.0000, G loss: 17.8030\n",
      "[164/1762] D loss: 0.0000, G loss: 17.7717\n",
      "[244/1762] D loss: 0.0000, G loss: 17.5013\n",
      "[324/1762] D loss: 0.0000, G loss: 17.5658\n",
      "[404/1762] D loss: 0.0000, G loss: 18.0423\n",
      "[484/1762] D loss: 0.0000, G loss: 17.6740\n",
      "[564/1762] D loss: 0.0000, G loss: 17.8557\n",
      "[644/1762] D loss: 0.0000, G loss: 17.7644\n",
      "[724/1762] D loss: 0.0000, G loss: 17.4280\n",
      "[804/1762] D loss: 0.0000, G loss: 18.0352\n",
      "[884/1762] D loss: 0.0000, G loss: 17.4871\n",
      "[964/1762] D loss: 0.0000, G loss: 17.9420\n",
      "[1044/1762] D loss: 0.0000, G loss: 17.6490\n",
      "[1124/1762] D loss: 0.0000, G loss: 17.5499\n",
      "[1204/1762] D loss: 0.0000, G loss: 18.0519\n",
      "[1284/1762] D loss: 0.0000, G loss: 17.8975\n",
      "[1364/1762] D loss: 0.0000, G loss: 17.6784\n",
      "[1444/1762] D loss: 0.0000, G loss: 18.3338\n",
      "[1524/1762] D loss: 0.0000, G loss: 18.2564\n",
      "[1604/1762] D loss: 0.0000, G loss: 18.0659\n",
      "[1684/1762] D loss: 0.0000, G loss: 17.9361\n",
      "[1762/1762] D loss: 0.0000, G loss: 18.0779\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 15.531883, D accuracy: 100.0%, cell accuracy: 83.2%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 15.551827, D accuracy: 100.0%, cell accuracy: 82.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 18.0453\n",
      "[84/1762] D loss: 0.0000, G loss: 18.1020\n",
      "[164/1762] D loss: 0.0000, G loss: 18.4494\n",
      "[244/1762] D loss: 0.0000, G loss: 17.7635\n",
      "[324/1762] D loss: 0.0000, G loss: 17.9132\n",
      "[404/1762] D loss: 0.0000, G loss: 17.9873\n",
      "[484/1762] D loss: 0.0000, G loss: 18.0125\n",
      "[564/1762] D loss: 0.0000, G loss: 18.1134\n",
      "[644/1762] D loss: 0.0000, G loss: 17.7985\n",
      "[724/1762] D loss: 0.0000, G loss: 17.9163\n",
      "[804/1762] D loss: 0.0000, G loss: 17.8600\n",
      "[884/1762] D loss: 0.0000, G loss: 18.2869\n",
      "[964/1762] D loss: 0.0000, G loss: 18.4131\n",
      "[1044/1762] D loss: 0.0000, G loss: 18.0974\n",
      "[1124/1762] D loss: 0.0000, G loss: 17.9995\n",
      "[1204/1762] D loss: 0.0000, G loss: 17.9462\n",
      "[1284/1762] D loss: 0.0000, G loss: 17.5246\n",
      "[1364/1762] D loss: 0.0000, G loss: 18.4181\n",
      "[1444/1762] D loss: 0.0000, G loss: 18.0263\n",
      "[1524/1762] D loss: 0.0000, G loss: 18.2264\n",
      "[1604/1762] D loss: 0.0000, G loss: 18.1550\n",
      "[1684/1762] D loss: 0.0000, G loss: 18.1174\n",
      "[1762/1762] D loss: 0.0000, G loss: 18.6678\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 15.710477, D accuracy: 100.0%, cell accuracy: 85.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 15.726202, D accuracy: 100.0%, cell accuracy: 84.8%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 17.6194\n",
      "[84/1762] D loss: 0.0000, G loss: 18.4524\n",
      "[164/1762] D loss: 0.0000, G loss: 18.1074\n",
      "[244/1762] D loss: 0.0000, G loss: 18.0170\n",
      "[324/1762] D loss: 0.0000, G loss: 18.1137\n",
      "[404/1762] D loss: 0.0000, G loss: 18.1050\n",
      "[484/1762] D loss: 0.0000, G loss: 18.1087\n",
      "[564/1762] D loss: 0.0000, G loss: 18.3918\n",
      "[644/1762] D loss: 0.0000, G loss: 18.2786\n",
      "[724/1762] D loss: 0.0000, G loss: 18.2324\n",
      "[804/1762] D loss: 0.0000, G loss: 18.4236\n",
      "[884/1762] D loss: 0.0000, G loss: 17.9540\n",
      "[964/1762] D loss: 0.0000, G loss: 18.3446\n",
      "[1044/1762] D loss: 0.0000, G loss: 18.5815\n",
      "[1124/1762] D loss: 0.0000, G loss: 18.6184\n",
      "[1204/1762] D loss: 0.0000, G loss: 18.6044\n",
      "[1284/1762] D loss: 0.0000, G loss: 18.5468\n",
      "[1364/1762] D loss: 0.0000, G loss: 18.4454\n",
      "[1444/1762] D loss: 0.0000, G loss: 17.9857\n",
      "[1524/1762] D loss: 0.0000, G loss: 18.4520\n",
      "[1604/1762] D loss: 0.0000, G loss: 18.3823\n",
      "[1684/1762] D loss: 0.0000, G loss: 18.3600\n",
      "[1762/1762] D loss: 0.0000, G loss: 18.2802\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 15.951413, D accuracy: 100.0%, cell accuracy: 84.6%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 15.948996, D accuracy: 100.0%, cell accuracy: 84.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 18.1272\n",
      "[84/1762] D loss: 0.0000, G loss: 18.9423\n",
      "[164/1762] D loss: 0.0000, G loss: 18.3781\n",
      "[244/1762] D loss: 0.0000, G loss: 18.6609\n",
      "[324/1762] D loss: 0.0000, G loss: 18.5742\n",
      "[404/1762] D loss: 0.0000, G loss: 18.5466\n",
      "[484/1762] D loss: 0.0000, G loss: 18.7467\n",
      "[564/1762] D loss: 0.0000, G loss: 17.6771\n",
      "[644/1762] D loss: 0.0000, G loss: 18.6288\n",
      "[724/1762] D loss: 0.0000, G loss: 18.8000\n",
      "[804/1762] D loss: 0.0000, G loss: 18.4780\n",
      "[884/1762] D loss: 0.0000, G loss: 18.2595\n",
      "[964/1762] D loss: 0.0000, G loss: 18.7693\n",
      "[1044/1762] D loss: 0.0000, G loss: 18.7296\n",
      "[1124/1762] D loss: 0.0000, G loss: 18.6732\n",
      "[1204/1762] D loss: 0.0000, G loss: 18.5194\n",
      "[1284/1762] D loss: 0.0000, G loss: 18.4780\n",
      "[1364/1762] D loss: 0.0000, G loss: 18.0251\n",
      "[1444/1762] D loss: 0.0000, G loss: 18.7200\n",
      "[1524/1762] D loss: 0.0000, G loss: 18.7405\n",
      "[1604/1762] D loss: 0.0000, G loss: 18.7755\n",
      "[1684/1762] D loss: 0.0000, G loss: 18.5874\n",
      "[1762/1762] D loss: 0.0000, G loss: 19.3193\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 16.301699, D accuracy: 100.0%, cell accuracy: 83.3%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 16.306892, D accuracy: 100.0%, cell accuracy: 83.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 18.9787\n",
      "[84/1762] D loss: 0.0000, G loss: 18.7408\n",
      "[164/1762] D loss: 0.0000, G loss: 18.8761\n",
      "[244/1762] D loss: 0.0000, G loss: 18.9206\n",
      "[324/1762] D loss: 0.0000, G loss: 18.9296\n",
      "[404/1762] D loss: 0.0000, G loss: 18.3926\n",
      "[484/1762] D loss: 0.0000, G loss: 18.4937\n",
      "[564/1762] D loss: 0.0000, G loss: 18.8840\n",
      "[644/1762] D loss: 0.0000, G loss: 18.6712\n",
      "[724/1762] D loss: 0.0000, G loss: 19.1231\n",
      "[804/1762] D loss: 0.0000, G loss: 18.7111\n",
      "[884/1762] D loss: 0.0000, G loss: 18.8455\n",
      "[964/1762] D loss: 0.0000, G loss: 18.6948\n",
      "[1044/1762] D loss: 0.0000, G loss: 18.2344\n",
      "[1124/1762] D loss: 0.0000, G loss: 18.9290\n",
      "[1204/1762] D loss: 0.0000, G loss: 18.8308\n",
      "[1284/1762] D loss: 0.0000, G loss: 18.8651\n",
      "[1364/1762] D loss: 0.0000, G loss: 19.1409\n",
      "[1444/1762] D loss: 0.0000, G loss: 18.8124\n",
      "[1524/1762] D loss: 0.0000, G loss: 18.3880\n",
      "[1604/1762] D loss: 0.0000, G loss: 19.0716\n",
      "[1684/1762] D loss: 0.0000, G loss: 19.0618\n",
      "[1762/1762] D loss: 0.0000, G loss: 18.7644\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 16.369162, D accuracy: 100.0%, cell accuracy: 83.6%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 16.366318, D accuracy: 100.0%, cell accuracy: 83.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 19.0032\n",
      "[84/1762] D loss: 0.0000, G loss: 18.9573\n",
      "[164/1762] D loss: 0.0000, G loss: 18.8883\n",
      "[244/1762] D loss: 0.0000, G loss: 18.5905\n",
      "[324/1762] D loss: 0.0000, G loss: 19.3188\n",
      "[404/1762] D loss: 0.0000, G loss: 19.0459\n",
      "[484/1762] D loss: 0.0000, G loss: 18.9749\n",
      "[564/1762] D loss: 0.0000, G loss: 18.9113\n",
      "[644/1762] D loss: 0.0000, G loss: 19.1771\n",
      "[724/1762] D loss: 0.0000, G loss: 19.3022\n",
      "[804/1762] D loss: 0.0000, G loss: 19.2574\n",
      "[884/1762] D loss: 0.0000, G loss: 18.5588\n",
      "[964/1762] D loss: 0.0000, G loss: 19.3820\n",
      "[1044/1762] D loss: 0.0000, G loss: 19.3520\n",
      "[1124/1762] D loss: 0.0000, G loss: 19.1446\n",
      "[1204/1762] D loss: 0.0000, G loss: 18.9078\n",
      "[1284/1762] D loss: 0.0000, G loss: 18.7977\n",
      "[1364/1762] D loss: 0.0000, G loss: 19.3481\n",
      "[1444/1762] D loss: 0.0000, G loss: 19.2910\n",
      "[1524/1762] D loss: 0.0000, G loss: 18.6844\n",
      "[1604/1762] D loss: 0.0000, G loss: 18.8393\n",
      "[1684/1762] D loss: 0.0000, G loss: 19.1204\n",
      "[1762/1762] D loss: 0.0000, G loss: 19.4602\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 16.564779, D accuracy: 100.0%, cell accuracy: 83.8%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 16.586524, D accuracy: 100.0%, cell accuracy: 83.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 19.0703\n",
      "[84/1762] D loss: 0.0000, G loss: 19.1865\n",
      "[164/1762] D loss: 0.0000, G loss: 18.8022\n",
      "[244/1762] D loss: 0.0000, G loss: 18.9458\n",
      "[324/1762] D loss: 0.0000, G loss: 19.1645\n",
      "[404/1762] D loss: 0.0000, G loss: 19.1291\n",
      "[484/1762] D loss: 0.0000, G loss: 19.4725\n",
      "[564/1762] D loss: 0.0000, G loss: 18.6562\n",
      "[644/1762] D loss: 0.0000, G loss: 19.1183\n",
      "[724/1762] D loss: 0.0000, G loss: 19.1353\n",
      "[804/1762] D loss: 0.0000, G loss: 18.9322\n",
      "[884/1762] D loss: 0.0000, G loss: 19.3763\n",
      "[964/1762] D loss: 0.0000, G loss: 19.7279\n",
      "[1044/1762] D loss: 0.0000, G loss: 19.2631\n",
      "[1124/1762] D loss: 0.0000, G loss: 19.3775\n",
      "[1204/1762] D loss: 0.0000, G loss: 19.4138\n",
      "[1284/1762] D loss: 0.0000, G loss: 19.0059\n",
      "[1364/1762] D loss: 0.0000, G loss: 19.5707\n",
      "[1444/1762] D loss: 0.0000, G loss: 19.5174\n",
      "[1524/1762] D loss: 0.0000, G loss: 19.4428\n",
      "[1604/1762] D loss: 0.0000, G loss: 19.3645\n",
      "[1684/1762] D loss: 0.0000, G loss: 19.6495\n",
      "[1762/1762] D loss: 0.0000, G loss: 19.8899\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 16.859617, D accuracy: 100.0%, cell accuracy: 83.2%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 16.907620, D accuracy: 100.0%, cell accuracy: 82.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 19.8669\n",
      "[84/1762] D loss: 0.0000, G loss: 19.2150\n",
      "[164/1762] D loss: 0.0000, G loss: 19.0361\n",
      "[244/1762] D loss: 0.0000, G loss: 19.4547\n",
      "[324/1762] D loss: 0.0000, G loss: 19.5433\n",
      "[404/1762] D loss: 0.0000, G loss: 19.4156\n",
      "[484/1762] D loss: 0.0000, G loss: 19.4746\n",
      "[564/1762] D loss: 0.0000, G loss: 19.4324\n",
      "[644/1762] D loss: 0.0000, G loss: 19.5169\n",
      "[724/1762] D loss: 0.0000, G loss: 19.4120\n",
      "[804/1762] D loss: 0.0000, G loss: 19.6629\n",
      "[884/1762] D loss: 0.0000, G loss: 19.8202\n",
      "[964/1762] D loss: 0.0000, G loss: 19.5976\n",
      "[1044/1762] D loss: 0.0000, G loss: 19.1423\n",
      "[1124/1762] D loss: 0.0000, G loss: 19.2779\n",
      "[1204/1762] D loss: 0.0000, G loss: 18.8344\n",
      "[1284/1762] D loss: 0.0000, G loss: 19.4969\n",
      "[1364/1762] D loss: 0.0000, G loss: 19.9121\n",
      "[1444/1762] D loss: 0.0000, G loss: 19.6998\n",
      "[1524/1762] D loss: 0.0000, G loss: 19.6581\n",
      "[1604/1762] D loss: 0.0000, G loss: 19.7124\n",
      "[1684/1762] D loss: 0.0000, G loss: 19.6313\n",
      "[1762/1762] D loss: 0.0000, G loss: 20.0909\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 17.033208, D accuracy: 100.0%, cell accuracy: 83.3%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 17.034149, D accuracy: 100.0%, cell accuracy: 83.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 19.3344\n",
      "[84/1762] D loss: 0.0000, G loss: 19.6743\n",
      "[164/1762] D loss: 0.0000, G loss: 19.7580\n",
      "[244/1762] D loss: 0.0000, G loss: 19.6359\n",
      "[324/1762] D loss: 0.0000, G loss: 20.1204\n",
      "[404/1762] D loss: 0.0000, G loss: 19.6192\n",
      "[484/1762] D loss: 0.0000, G loss: 20.0026\n",
      "[564/1762] D loss: 0.0000, G loss: 20.0187\n",
      "[644/1762] D loss: 0.0000, G loss: 19.4905\n",
      "[724/1762] D loss: 0.0000, G loss: 19.8792\n",
      "[804/1762] D loss: 0.0000, G loss: 19.9968\n",
      "[884/1762] D loss: 0.0000, G loss: 19.3197\n",
      "[964/1762] D loss: 0.0000, G loss: 20.0883\n",
      "[1044/1762] D loss: 0.0000, G loss: 19.3532\n",
      "[1124/1762] D loss: 0.0000, G loss: 19.9112\n",
      "[1204/1762] D loss: 0.0000, G loss: 19.6385\n",
      "[1284/1762] D loss: 0.0000, G loss: 19.7355\n",
      "[1364/1762] D loss: 0.0000, G loss: 19.8902\n",
      "[1444/1762] D loss: 0.0000, G loss: 19.5454\n",
      "[1524/1762] D loss: 0.0000, G loss: 20.0679\n",
      "[1604/1762] D loss: 0.0000, G loss: 19.7931\n",
      "[1684/1762] D loss: 0.0000, G loss: 19.5067\n",
      "[1762/1762] D loss: 0.0000, G loss: 20.2761\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 17.297249, D accuracy: 100.0%, cell accuracy: 83.2%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 17.352516, D accuracy: 100.0%, cell accuracy: 82.8%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 20.2232\n",
      "[84/1762] D loss: 0.0000, G loss: 19.8745\n",
      "[164/1762] D loss: 0.0000, G loss: 19.7395\n",
      "[244/1762] D loss: 0.0000, G loss: 20.0492\n",
      "[324/1762] D loss: 0.0000, G loss: 19.6157\n",
      "[404/1762] D loss: 0.0000, G loss: 19.9696\n",
      "[484/1762] D loss: 0.0000, G loss: 20.1338\n",
      "[564/1762] D loss: 0.0000, G loss: 20.3671\n",
      "[644/1762] D loss: 0.0000, G loss: 20.0729\n",
      "[724/1762] D loss: 0.0000, G loss: 20.1490\n",
      "[804/1762] D loss: 0.0000, G loss: 20.1892\n",
      "[884/1762] D loss: 0.0000, G loss: 20.2561\n",
      "[964/1762] D loss: 0.0000, G loss: 20.0509\n",
      "[1044/1762] D loss: 0.0000, G loss: 20.3563\n",
      "[1124/1762] D loss: 0.0000, G loss: 19.8482\n",
      "[1204/1762] D loss: 0.0000, G loss: 19.8534\n",
      "[1284/1762] D loss: 0.0000, G loss: 20.4037\n",
      "[1364/1762] D loss: 0.0000, G loss: 20.1862\n",
      "[1444/1762] D loss: 0.0000, G loss: 20.1675\n",
      "[1524/1762] D loss: 0.0000, G loss: 19.7856\n",
      "[1604/1762] D loss: 0.0000, G loss: 20.0311\n",
      "[1684/1762] D loss: 0.0000, G loss: 20.3679\n",
      "[1762/1762] D loss: 0.0000, G loss: 20.3174\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 17.516229, D accuracy: 100.0%, cell accuracy: 83.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 17.482938, D accuracy: 100.0%, cell accuracy: 82.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 19.9451\n",
      "[84/1762] D loss: 0.0000, G loss: 20.2807\n",
      "[164/1762] D loss: 0.0000, G loss: 20.0542\n",
      "[244/1762] D loss: 0.0000, G loss: 20.2020\n",
      "[324/1762] D loss: 0.0000, G loss: 20.2837\n",
      "[404/1762] D loss: 0.0000, G loss: 20.0572\n",
      "[484/1762] D loss: 0.0000, G loss: 20.0031\n",
      "[564/1762] D loss: 0.0000, G loss: 20.4732\n",
      "[644/1762] D loss: 0.0000, G loss: 20.3658\n",
      "[724/1762] D loss: 0.0000, G loss: 20.2511\n",
      "[804/1762] D loss: 0.0000, G loss: 20.2517\n",
      "[884/1762] D loss: 0.0000, G loss: 19.5972\n",
      "[964/1762] D loss: 0.0000, G loss: 20.2939\n",
      "[1044/1762] D loss: 0.0000, G loss: 20.4886\n",
      "[1124/1762] D loss: 0.0000, G loss: 20.4184\n",
      "[1204/1762] D loss: 0.0000, G loss: 20.7688\n",
      "[1284/1762] D loss: 0.0000, G loss: 20.5214\n",
      "[1364/1762] D loss: 0.0000, G loss: 19.9202\n",
      "[1444/1762] D loss: 0.0000, G loss: 20.4465\n",
      "[1524/1762] D loss: 0.0000, G loss: 20.2762\n",
      "[1604/1762] D loss: 0.0000, G loss: 20.6196\n",
      "[1684/1762] D loss: 0.0000, G loss: 20.2835\n",
      "[1762/1762] D loss: 0.0000, G loss: 20.5525\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 17.778197, D accuracy: 100.0%, cell accuracy: 83.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 17.770524, D accuracy: 100.0%, cell accuracy: 83.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 20.2210\n",
      "[84/1762] D loss: 0.0000, G loss: 20.1899\n",
      "[164/1762] D loss: 0.0000, G loss: 20.6393\n",
      "[244/1762] D loss: 0.0000, G loss: 20.4893\n",
      "[324/1762] D loss: 0.0000, G loss: 20.6900\n",
      "[404/1762] D loss: 0.0000, G loss: 20.6994\n",
      "[484/1762] D loss: 0.0000, G loss: 20.5995\n",
      "[564/1762] D loss: 0.0000, G loss: 20.8048\n",
      "[644/1762] D loss: 0.0000, G loss: 20.6308\n",
      "[724/1762] D loss: 0.0000, G loss: 20.7661\n",
      "[804/1762] D loss: 0.0000, G loss: 20.5714\n",
      "[884/1762] D loss: 0.0000, G loss: 20.7398\n",
      "[964/1762] D loss: 0.0000, G loss: 20.9544\n",
      "[1044/1762] D loss: 0.0000, G loss: 20.3638\n",
      "[1124/1762] D loss: 0.0000, G loss: 20.3175\n",
      "[1204/1762] D loss: 0.0000, G loss: 20.7195\n",
      "[1284/1762] D loss: 0.0000, G loss: 20.7259\n",
      "[1364/1762] D loss: 0.0000, G loss: 20.7755\n",
      "[1444/1762] D loss: 0.0000, G loss: 20.6619\n",
      "[1524/1762] D loss: 0.0000, G loss: 20.7775\n",
      "[1604/1762] D loss: 0.0000, G loss: 20.4468\n",
      "[1684/1762] D loss: 0.0000, G loss: 20.6441\n",
      "[1762/1762] D loss: 0.0000, G loss: 20.5011\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 18.070030, D accuracy: 100.0%, cell accuracy: 83.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 18.055359, D accuracy: 100.0%, cell accuracy: 83.5%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 20.2046\n",
      "[84/1762] D loss: 0.0000, G loss: 20.5656\n",
      "[164/1762] D loss: 0.0000, G loss: 20.5270\n",
      "[244/1762] D loss: 0.0000, G loss: 20.8168\n",
      "[324/1762] D loss: 0.0000, G loss: 20.5612\n",
      "[404/1762] D loss: 0.0000, G loss: 20.6239\n",
      "[484/1762] D loss: 0.0000, G loss: 20.6825\n",
      "[564/1762] D loss: 0.0000, G loss: 20.9068\n",
      "[644/1762] D loss: 0.0000, G loss: 20.7486\n",
      "[724/1762] D loss: 0.0000, G loss: 21.0819\n",
      "[804/1762] D loss: 0.0000, G loss: 20.4948\n",
      "[884/1762] D loss: 0.0000, G loss: 20.4914\n",
      "[964/1762] D loss: 0.0000, G loss: 21.1326\n",
      "[1044/1762] D loss: 0.0000, G loss: 21.1485\n",
      "[1124/1762] D loss: 0.0000, G loss: 20.8466\n",
      "[1204/1762] D loss: 0.0000, G loss: 21.1357\n",
      "[1284/1762] D loss: 0.0000, G loss: 20.9348\n",
      "[1364/1762] D loss: 0.0000, G loss: 20.7368\n",
      "[1444/1762] D loss: 0.0000, G loss: 20.5443\n",
      "[1524/1762] D loss: 0.0000, G loss: 20.8848\n",
      "[1604/1762] D loss: 0.0000, G loss: 20.7641\n",
      "[1684/1762] D loss: 0.0000, G loss: 20.7470\n",
      "[1762/1762] D loss: 0.0000, G loss: 21.2432\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 17.903842, D accuracy: 100.0%, cell accuracy: 83.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 17.922001, D accuracy: 100.0%, cell accuracy: 83.5%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 21.3278\n",
      "[84/1762] D loss: 0.0000, G loss: 20.7928\n",
      "[164/1762] D loss: 0.0000, G loss: 21.0286\n",
      "[244/1762] D loss: 0.0000, G loss: 20.6402\n",
      "[324/1762] D loss: 0.0000, G loss: 20.8659\n",
      "[404/1762] D loss: 0.0000, G loss: 20.9882\n",
      "[484/1762] D loss: 0.0000, G loss: 20.9335\n",
      "[564/1762] D loss: 0.0000, G loss: 20.8492\n",
      "[644/1762] D loss: 0.0000, G loss: 20.5212\n",
      "[724/1762] D loss: 0.0000, G loss: 20.4881\n",
      "[804/1762] D loss: 0.0000, G loss: 20.1804\n",
      "[884/1762] D loss: 0.0000, G loss: 21.2899\n",
      "[964/1762] D loss: 0.0000, G loss: 20.9915\n",
      "[1044/1762] D loss: 0.0000, G loss: 20.9947\n",
      "[1124/1762] D loss: 0.0000, G loss: 21.4452\n",
      "[1204/1762] D loss: 0.0000, G loss: 21.2828\n",
      "[1284/1762] D loss: 0.0000, G loss: 21.3165\n",
      "[1364/1762] D loss: 0.0000, G loss: 20.8302\n",
      "[1444/1762] D loss: 0.0000, G loss: 21.0311\n",
      "[1524/1762] D loss: 0.0000, G loss: 21.3978\n",
      "[1604/1762] D loss: 0.0000, G loss: 21.2088\n",
      "[1684/1762] D loss: 0.0000, G loss: 21.2440\n",
      "[1762/1762] D loss: 0.0000, G loss: 20.9997\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 18.423635, D accuracy: 100.0%, cell accuracy: 83.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 18.451501, D accuracy: 100.0%, cell accuracy: 83.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 21.2181\n",
      "[84/1762] D loss: 0.0000, G loss: 21.2429\n",
      "[164/1762] D loss: 0.0000, G loss: 20.8072\n",
      "[244/1762] D loss: 0.0000, G loss: 20.6140\n",
      "[324/1762] D loss: 0.0000, G loss: 21.1404\n",
      "[404/1762] D loss: 0.0000, G loss: 21.5505\n",
      "[484/1762] D loss: 0.0000, G loss: 21.2463\n",
      "[564/1762] D loss: 0.0000, G loss: 21.3699\n",
      "[644/1762] D loss: 0.0000, G loss: 21.3929\n",
      "[724/1762] D loss: 0.0000, G loss: 21.3800\n",
      "[804/1762] D loss: 0.0000, G loss: 21.2274\n",
      "[884/1762] D loss: 0.0000, G loss: 20.9069\n",
      "[964/1762] D loss: 0.0000, G loss: 21.6316\n",
      "[1044/1762] D loss: 0.0000, G loss: 21.1149\n",
      "[1124/1762] D loss: 0.0000, G loss: 20.6339\n",
      "[1204/1762] D loss: 0.0000, G loss: 21.0780\n",
      "[1284/1762] D loss: 0.0000, G loss: 21.1423\n",
      "[1364/1762] D loss: 0.0000, G loss: 21.5975\n",
      "[1444/1762] D loss: 0.0000, G loss: 20.8977\n",
      "[1524/1762] D loss: 0.0000, G loss: 21.0584\n",
      "[1604/1762] D loss: 0.0000, G loss: 21.3663\n",
      "[1684/1762] D loss: 0.0000, G loss: 21.5113\n",
      "[1762/1762] D loss: 0.0000, G loss: 21.9731\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 18.644171, D accuracy: 100.0%, cell accuracy: 84.0%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 18.636292, D accuracy: 100.0%, cell accuracy: 84.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 21.2234\n",
      "[84/1762] D loss: 0.0000, G loss: 21.5733\n",
      "[164/1762] D loss: 0.0000, G loss: 21.4479\n",
      "[244/1762] D loss: 0.0000, G loss: 21.3255\n",
      "[324/1762] D loss: 0.0000, G loss: 21.3932\n",
      "[404/1762] D loss: 0.0000, G loss: 21.4670\n",
      "[484/1762] D loss: 0.0000, G loss: 21.6049\n",
      "[564/1762] D loss: 0.0000, G loss: 21.5359\n",
      "[644/1762] D loss: 0.0000, G loss: 21.5485\n",
      "[724/1762] D loss: 0.0000, G loss: 21.6595\n",
      "[804/1762] D loss: 0.0000, G loss: 21.7181\n",
      "[884/1762] D loss: 0.0000, G loss: 20.9098\n",
      "[964/1762] D loss: 0.0000, G loss: 21.4722\n",
      "[1044/1762] D loss: 0.0000, G loss: 21.9703\n",
      "[1124/1762] D loss: 0.0000, G loss: 21.6355\n",
      "[1204/1762] D loss: 0.0000, G loss: 21.6079\n",
      "[1284/1762] D loss: 0.0000, G loss: 21.4673\n",
      "[1364/1762] D loss: 0.0000, G loss: 21.5988\n",
      "[1444/1762] D loss: 0.0000, G loss: 21.5536\n",
      "[1524/1762] D loss: 0.0000, G loss: 20.7655\n",
      "[1604/1762] D loss: 0.0000, G loss: 21.3309\n",
      "[1684/1762] D loss: 0.0000, G loss: 21.7656\n",
      "[1762/1762] D loss: 0.0000, G loss: 21.6526\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 18.764855, D accuracy: 100.0%, cell accuracy: 83.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 18.806561, D accuracy: 100.0%, cell accuracy: 82.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 20.6642\n",
      "[84/1762] D loss: 0.0000, G loss: 21.8252\n",
      "[164/1762] D loss: 0.0000, G loss: 21.8461\n",
      "[244/1762] D loss: 0.0000, G loss: 21.3707\n",
      "[324/1762] D loss: 0.0000, G loss: 21.8392\n",
      "[404/1762] D loss: 0.0000, G loss: 21.4876\n",
      "[484/1762] D loss: 0.0000, G loss: 21.5218\n",
      "[564/1762] D loss: 0.0000, G loss: 21.7804\n",
      "[644/1762] D loss: 0.0000, G loss: 21.5837\n",
      "[724/1762] D loss: 0.0000, G loss: 21.9075\n",
      "[804/1762] D loss: 0.0000, G loss: 21.5829\n",
      "[884/1762] D loss: 0.0000, G loss: 21.8545\n",
      "[964/1762] D loss: 0.0000, G loss: 21.4775\n",
      "[1044/1762] D loss: 0.0000, G loss: 21.7968\n",
      "[1124/1762] D loss: 0.0000, G loss: 21.6891\n",
      "[1204/1762] D loss: 0.0000, G loss: 21.7682\n",
      "[1284/1762] D loss: 0.0000, G loss: 21.9229\n",
      "[1364/1762] D loss: 0.0000, G loss: 21.9297\n",
      "[1444/1762] D loss: 0.0000, G loss: 21.6521\n",
      "[1524/1762] D loss: 0.0000, G loss: 22.0589\n",
      "[1604/1762] D loss: 0.0000, G loss: 22.0616\n",
      "[1684/1762] D loss: 0.0000, G loss: 21.7638\n",
      "[1762/1762] D loss: 0.0000, G loss: 22.2147\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 19.033944, D accuracy: 100.0%, cell accuracy: 83.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 19.026491, D accuracy: 100.0%, cell accuracy: 83.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 22.2891\n",
      "[84/1762] D loss: 0.0000, G loss: 21.4970\n",
      "[164/1762] D loss: 0.0000, G loss: 21.9897\n",
      "[244/1762] D loss: 0.0000, G loss: 21.4463\n",
      "[324/1762] D loss: 0.0000, G loss: 21.6827\n",
      "[404/1762] D loss: 0.0000, G loss: 22.1365\n",
      "[484/1762] D loss: 0.0000, G loss: 21.9543\n",
      "[564/1762] D loss: 0.0000, G loss: 22.3464\n",
      "[644/1762] D loss: 0.0000, G loss: 22.2239\n",
      "[724/1762] D loss: 0.0000, G loss: 22.2544\n",
      "[804/1762] D loss: 0.0000, G loss: 22.0352\n",
      "[884/1762] D loss: 0.0000, G loss: 22.0721\n",
      "[964/1762] D loss: 0.0000, G loss: 21.8633\n",
      "[1044/1762] D loss: 0.0000, G loss: 21.8258\n",
      "[1124/1762] D loss: 0.0000, G loss: 22.2251\n",
      "[1204/1762] D loss: 0.0000, G loss: 21.8034\n",
      "[1284/1762] D loss: 0.0000, G loss: 21.6069\n",
      "[1364/1762] D loss: 0.0000, G loss: 22.1387\n",
      "[1444/1762] D loss: 0.0000, G loss: 22.1167\n",
      "[1524/1762] D loss: 0.0000, G loss: 21.7588\n",
      "[1604/1762] D loss: 0.0000, G loss: 22.4016\n",
      "[1684/1762] D loss: 0.0000, G loss: 21.8124\n",
      "[1762/1762] D loss: 0.0000, G loss: 22.2708\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 19.185794, D accuracy: 100.0%, cell accuracy: 84.6%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 19.228380, D accuracy: 100.0%, cell accuracy: 84.5%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 22.1714\n",
      "[84/1762] D loss: 0.0000, G loss: 22.3391\n",
      "[164/1762] D loss: 0.0000, G loss: 22.2524\n",
      "[244/1762] D loss: 0.0000, G loss: 21.9964\n",
      "[324/1762] D loss: 0.0000, G loss: 22.4813\n",
      "[404/1762] D loss: 0.0000, G loss: 22.2158\n",
      "[484/1762] D loss: 0.0000, G loss: 22.2260\n",
      "[564/1762] D loss: 0.0000, G loss: 22.5215\n",
      "[644/1762] D loss: 0.0000, G loss: 22.2644\n",
      "[724/1762] D loss: 0.0000, G loss: 22.3071\n",
      "[804/1762] D loss: 0.0000, G loss: 21.5784\n",
      "[884/1762] D loss: 0.0000, G loss: 22.3361\n",
      "[964/1762] D loss: 0.0000, G loss: 22.1261\n",
      "[1044/1762] D loss: 0.0000, G loss: 22.2286\n",
      "[1124/1762] D loss: 0.0000, G loss: 22.4176\n",
      "[1204/1762] D loss: 0.0000, G loss: 22.0938\n",
      "[1284/1762] D loss: 0.0000, G loss: 22.2115\n",
      "[1364/1762] D loss: 0.0000, G loss: 21.9289\n",
      "[1444/1762] D loss: 0.0000, G loss: 22.2049\n",
      "[1524/1762] D loss: 0.0000, G loss: 22.2639\n",
      "[1604/1762] D loss: 0.0000, G loss: 22.3237\n",
      "[1684/1762] D loss: 0.0000, G loss: 22.2843\n",
      "[1762/1762] D loss: 0.0000, G loss: 21.9030\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 19.197875, D accuracy: 100.0%, cell accuracy: 84.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 19.183008, D accuracy: 100.0%, cell accuracy: 84.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 22.1682\n",
      "[84/1762] D loss: 0.0000, G loss: 22.4621\n",
      "[164/1762] D loss: 0.0000, G loss: 21.9472\n",
      "[244/1762] D loss: 0.0000, G loss: 22.3517\n",
      "[324/1762] D loss: 0.0000, G loss: 22.4064\n",
      "[404/1762] D loss: 0.0000, G loss: 22.0664\n",
      "[484/1762] D loss: 0.0000, G loss: 21.8908\n",
      "[564/1762] D loss: 0.0000, G loss: 22.6107\n",
      "[644/1762] D loss: 0.0000, G loss: 22.6599\n",
      "[724/1762] D loss: 0.0000, G loss: 22.5492\n",
      "[804/1762] D loss: 0.0000, G loss: 22.2237\n",
      "[884/1762] D loss: 0.0000, G loss: 22.5120\n",
      "[964/1762] D loss: 0.0000, G loss: 22.9573\n",
      "[1044/1762] D loss: 0.0000, G loss: 22.5666\n",
      "[1124/1762] D loss: 0.0000, G loss: 22.2663\n",
      "[1204/1762] D loss: 0.0000, G loss: 22.5663\n",
      "[1284/1762] D loss: 0.0000, G loss: 22.4319\n",
      "[1364/1762] D loss: 0.0000, G loss: 22.7579\n",
      "[1444/1762] D loss: 0.0000, G loss: 22.3315\n",
      "[1524/1762] D loss: 0.0000, G loss: 22.6623\n",
      "[1604/1762] D loss: 0.0000, G loss: 22.1236\n",
      "[1684/1762] D loss: 0.0000, G loss: 22.6549\n",
      "[1762/1762] D loss: 0.0000, G loss: 22.4677\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 19.626316, D accuracy: 100.0%, cell accuracy: 84.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 19.629194, D accuracy: 100.0%, cell accuracy: 85.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 21.8461\n",
      "[84/1762] D loss: 0.0000, G loss: 22.5340\n",
      "[164/1762] D loss: 0.0000, G loss: 22.8527\n",
      "[244/1762] D loss: 0.0000, G loss: 22.8115\n",
      "[324/1762] D loss: 0.0000, G loss: 22.5828\n",
      "[404/1762] D loss: 0.0000, G loss: 22.6388\n",
      "[484/1762] D loss: 0.0000, G loss: 22.7350\n",
      "[564/1762] D loss: 0.0000, G loss: 22.5134\n",
      "[644/1762] D loss: 0.0000, G loss: 22.7551\n",
      "[724/1762] D loss: 0.0000, G loss: 22.9693\n",
      "[804/1762] D loss: 0.0000, G loss: 21.9542\n",
      "[884/1762] D loss: 0.0000, G loss: 22.5714\n",
      "[964/1762] D loss: 0.0000, G loss: 22.7804\n",
      "[1044/1762] D loss: 0.0000, G loss: 22.4482\n",
      "[1124/1762] D loss: 0.0000, G loss: 22.9979\n",
      "[1204/1762] D loss: 0.0000, G loss: 22.1913\n",
      "[1284/1762] D loss: 0.0000, G loss: 22.7515\n",
      "[1364/1762] D loss: 0.0000, G loss: 22.4890\n",
      "[1444/1762] D loss: 0.0000, G loss: 22.7921\n",
      "[1524/1762] D loss: 0.0000, G loss: 22.7426\n",
      "[1604/1762] D loss: 0.0000, G loss: 22.4263\n",
      "[1684/1762] D loss: 0.0000, G loss: 22.6643\n",
      "[1762/1762] D loss: 0.0000, G loss: 22.8022\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 19.847280, D accuracy: 100.0%, cell accuracy: 84.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 19.879050, D accuracy: 100.0%, cell accuracy: 84.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 22.7570\n",
      "[84/1762] D loss: 0.0000, G loss: 22.6601\n",
      "[164/1762] D loss: 0.0000, G loss: 22.7292\n",
      "[244/1762] D loss: 0.0000, G loss: 22.8665\n",
      "[324/1762] D loss: 0.0000, G loss: 22.9809\n",
      "[404/1762] D loss: 0.0000, G loss: 22.6259\n",
      "[484/1762] D loss: 0.0000, G loss: 22.6669\n",
      "[564/1762] D loss: 0.0000, G loss: 23.0042\n",
      "[644/1762] D loss: 0.0000, G loss: 23.0273\n",
      "[724/1762] D loss: 0.0000, G loss: 23.0995\n",
      "[804/1762] D loss: 0.0000, G loss: 22.1128\n",
      "[884/1762] D loss: 0.0000, G loss: 22.9895\n",
      "[964/1762] D loss: 0.0000, G loss: 23.2810\n",
      "[1044/1762] D loss: 0.0000, G loss: 22.8498\n",
      "[1124/1762] D loss: 0.0000, G loss: 22.6963\n",
      "[1204/1762] D loss: 0.0000, G loss: 22.9241\n",
      "[1284/1762] D loss: 0.0000, G loss: 22.9440\n",
      "[1364/1762] D loss: 0.0000, G loss: 23.0397\n",
      "[1444/1762] D loss: 0.0000, G loss: 23.0284\n",
      "[1524/1762] D loss: 0.0000, G loss: 23.2157\n",
      "[1604/1762] D loss: 0.0000, G loss: 22.5834\n",
      "[1684/1762] D loss: 0.0000, G loss: 23.4800\n",
      "[1762/1762] D loss: 0.0000, G loss: 23.2275\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 20.093575, D accuracy: 100.0%, cell accuracy: 84.2%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 20.167052, D accuracy: 100.0%, cell accuracy: 83.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 22.5479\n",
      "[84/1762] D loss: 0.0000, G loss: 22.3880\n",
      "[164/1762] D loss: 0.0000, G loss: 22.7875\n",
      "[244/1762] D loss: 0.0000, G loss: 22.8612\n",
      "[324/1762] D loss: 0.0000, G loss: 23.5171\n",
      "[404/1762] D loss: 0.0000, G loss: 22.9327\n",
      "[484/1762] D loss: 0.0000, G loss: 22.6183\n",
      "[564/1762] D loss: 0.0000, G loss: 23.2355\n",
      "[644/1762] D loss: 0.0000, G loss: 23.1340\n",
      "[724/1762] D loss: 0.0000, G loss: 22.4264\n",
      "[804/1762] D loss: 0.0000, G loss: 23.2820\n",
      "[884/1762] D loss: 0.0000, G loss: 22.9222\n",
      "[964/1762] D loss: 0.0000, G loss: 23.1923\n",
      "[1044/1762] D loss: 0.0000, G loss: 23.4652\n",
      "[1124/1762] D loss: 0.0000, G loss: 23.1813\n",
      "[1204/1762] D loss: 0.0000, G loss: 23.3545\n",
      "[1284/1762] D loss: 0.0000, G loss: 23.1135\n",
      "[1364/1762] D loss: 0.0000, G loss: 23.0640\n",
      "[1444/1762] D loss: 0.0000, G loss: 22.5157\n",
      "[1524/1762] D loss: 0.0000, G loss: 23.2812\n",
      "[1604/1762] D loss: 0.0000, G loss: 23.1438\n",
      "[1684/1762] D loss: 0.0000, G loss: 22.9467\n",
      "[1762/1762] D loss: 0.0000, G loss: 23.0509\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 20.377823, D accuracy: 100.0%, cell accuracy: 81.2%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 20.402256, D accuracy: 100.0%, cell accuracy: 81.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 23.3724\n",
      "[84/1762] D loss: 0.0000, G loss: 23.4349\n",
      "[164/1762] D loss: 0.0000, G loss: 22.2250\n",
      "[244/1762] D loss: 0.0000, G loss: 23.2518\n",
      "[324/1762] D loss: 0.0000, G loss: 23.1891\n",
      "[404/1762] D loss: 0.0000, G loss: 23.1652\n",
      "[484/1762] D loss: 0.0000, G loss: 23.6875\n",
      "[564/1762] D loss: 0.0000, G loss: 22.8128\n",
      "[644/1762] D loss: 0.0000, G loss: 23.5531\n",
      "[724/1762] D loss: 0.0000, G loss: 23.1761\n",
      "[804/1762] D loss: 0.0000, G loss: 23.1752\n",
      "[884/1762] D loss: 0.0000, G loss: 23.0418\n",
      "[964/1762] D loss: 0.0000, G loss: 23.7005\n",
      "[1044/1762] D loss: 0.0000, G loss: 23.4599\n",
      "[1124/1762] D loss: 0.0000, G loss: 23.3078\n",
      "[1204/1762] D loss: 0.0000, G loss: 23.5546\n",
      "[1284/1762] D loss: 0.0000, G loss: 23.4172\n",
      "[1364/1762] D loss: 0.0000, G loss: 22.9178\n",
      "[1444/1762] D loss: 0.0000, G loss: 23.1871\n",
      "[1524/1762] D loss: 0.0000, G loss: 23.1908\n",
      "[1604/1762] D loss: 0.0000, G loss: 23.0326\n",
      "[1684/1762] D loss: 0.0000, G loss: 22.8451\n",
      "[1762/1762] D loss: 0.0000, G loss: 23.5658\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 20.750386, D accuracy: 100.0%, cell accuracy: 83.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 20.792582, D accuracy: 100.0%, cell accuracy: 83.0%, board accuracy: 0.0% \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_and_freeze_gen(run_name=\"freeze_gen_epoch_0\", freeze_epoch=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3628, G loss: 0.7337\n",
      "[84/1762] D loss: 0.5267, G loss: 1.8589\n",
      "[164/1762] D loss: 0.1896, G loss: 3.0379\n",
      "[244/1762] D loss: 0.0452, G loss: 4.2842\n",
      "[324/1762] D loss: 0.0156, G loss: 5.3431\n",
      "[404/1762] D loss: 0.0315, G loss: 5.3833\n",
      "[484/1762] D loss: 0.0203, G loss: 5.1763\n",
      "[564/1762] D loss: 0.0087, G loss: 6.5806\n",
      "[644/1762] D loss: 0.0066, G loss: 5.4703\n",
      "[724/1762] D loss: 0.0158, G loss: 5.8748\n",
      "[804/1762] D loss: 0.2884, G loss: 5.5163\n",
      "[884/1762] D loss: 0.3284, G loss: 3.3779\n",
      "[964/1762] D loss: 0.3438, G loss: 1.3096\n",
      "[1044/1762] D loss: 0.0829, G loss: 2.8302\n",
      "[1124/1762] D loss: 0.6703, G loss: 3.7446\n",
      "[1204/1762] D loss: 0.3261, G loss: 2.5430\n",
      "[1284/1762] D loss: 0.8957, G loss: 2.5023\n",
      "[1364/1762] D loss: 0.7811, G loss: 2.0888\n",
      "[1444/1762] D loss: 0.7707, G loss: 0.9743\n",
      "[1524/1762] D loss: 0.7088, G loss: 0.7719\n",
      "[1604/1762] D loss: 1.6000, G loss: 0.4953\n",
      "[1684/1762] D loss: 1.0720, G loss: 0.8630\n",
      "[1762/1762] D loss: 0.9721, G loss: 1.0535\n",
      "train error: \n",
      " D loss: 1.255436, G loss: 1.198395, D accuracy: 62.3%, cell accuracy: 99.4%, board accuracy: 58.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.261674, G loss: 1.157144, D accuracy: 62.6%, cell accuracy: 99.4%, board accuracy: 56.6% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0520, G loss: 0.9387\n",
      "[84/1762] D loss: 0.9968, G loss: 1.5758\n",
      "[164/1762] D loss: 1.3921, G loss: 0.5416\n",
      "[244/1762] D loss: 1.1577, G loss: 0.7260\n",
      "[324/1762] D loss: 1.3526, G loss: 0.7384\n",
      "[404/1762] D loss: 1.6053, G loss: 0.9618\n",
      "[484/1762] D loss: 1.2137, G loss: 0.9924\n",
      "[564/1762] D loss: 1.2845, G loss: 0.8392\n",
      "[644/1762] D loss: 1.4678, G loss: 1.1222\n",
      "[724/1762] D loss: 1.4241, G loss: 0.9679\n",
      "[804/1762] D loss: 1.6252, G loss: 1.1515\n",
      "[884/1762] D loss: 1.3626, G loss: 1.1502\n",
      "[964/1762] D loss: 0.7920, G loss: 1.2385\n",
      "[1044/1762] D loss: 0.8638, G loss: 1.3341\n",
      "[1124/1762] D loss: 1.4012, G loss: 1.5210\n",
      "[1204/1762] D loss: 0.4064, G loss: 1.9778\n",
      "[1284/1762] D loss: 1.3775, G loss: 0.7626\n",
      "[1364/1762] D loss: 1.9710, G loss: 1.5051\n",
      "[1444/1762] D loss: 1.8070, G loss: 0.3571\n",
      "[1524/1762] D loss: 1.3552, G loss: 0.5936\n",
      "[1604/1762] D loss: 0.9854, G loss: 1.3680\n",
      "[1684/1762] D loss: 1.3629, G loss: 1.0698\n",
      "[1762/1762] D loss: 1.0600, G loss: 0.8499\n",
      "train error: \n",
      " D loss: 1.298320, G loss: 0.815408, D accuracy: 59.1%, cell accuracy: 99.6%, board accuracy: 67.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.284956, G loss: 0.868802, D accuracy: 59.0%, cell accuracy: 99.5%, board accuracy: 63.9% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3334, G loss: 0.7295\n",
      "[84/1762] D loss: 1.3290, G loss: 0.6861\n",
      "[164/1762] D loss: 1.2685, G loss: 0.5994\n",
      "[244/1762] D loss: 0.3612, G loss: 1.9378\n",
      "[324/1762] D loss: 1.0982, G loss: 0.9927\n",
      "[404/1762] D loss: 0.6873, G loss: 1.3683\n",
      "[484/1762] D loss: 1.0466, G loss: 0.8424\n",
      "[564/1762] D loss: 1.2254, G loss: 0.7870\n",
      "[644/1762] D loss: 1.3561, G loss: 1.0831\n",
      "[724/1762] D loss: 1.4264, G loss: 0.6257\n",
      "[804/1762] D loss: 1.2753, G loss: 1.2279\n",
      "[884/1762] D loss: 1.4622, G loss: 0.5833\n",
      "[964/1762] D loss: 1.4607, G loss: 0.5056\n",
      "[1044/1762] D loss: 0.8243, G loss: 1.0807\n",
      "[1124/1762] D loss: 1.3292, G loss: 0.9471\n",
      "[1204/1762] D loss: 1.2724, G loss: 1.4104\n",
      "[1284/1762] D loss: 1.4161, G loss: 1.0173\n",
      "[1364/1762] D loss: 1.3397, G loss: 0.7229\n",
      "[1444/1762] D loss: 0.3865, G loss: 2.1049\n",
      "[1524/1762] D loss: 0.7099, G loss: 1.2308\n",
      "[1604/1762] D loss: 1.7166, G loss: 1.3273\n",
      "[1684/1762] D loss: 1.5833, G loss: 0.4563\n",
      "[1762/1762] D loss: 1.4810, G loss: 0.9409\n",
      "train error: \n",
      " D loss: 1.351275, G loss: 0.747908, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.338342, G loss: 0.770827, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 84.5% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3187, G loss: 1.6358\n",
      "[84/1762] D loss: 2.0517, G loss: 1.4439\n",
      "[164/1762] D loss: 1.3779, G loss: 0.4144\n",
      "[244/1762] D loss: 1.4961, G loss: 0.4948\n",
      "[324/1762] D loss: 1.4232, G loss: 0.6455\n",
      "[404/1762] D loss: 1.4482, G loss: 0.9380\n",
      "[484/1762] D loss: 1.4212, G loss: 0.7177\n",
      "[564/1762] D loss: 1.4929, G loss: 1.0293\n",
      "[644/1762] D loss: 1.5204, G loss: 0.4996\n",
      "[724/1762] D loss: 1.6070, G loss: 0.3868\n",
      "[804/1762] D loss: 2.0490, G loss: 1.5040\n",
      "[884/1762] D loss: 1.4019, G loss: 0.9927\n",
      "[964/1762] D loss: 0.3954, G loss: 1.4043\n",
      "[1044/1762] D loss: 1.4146, G loss: 0.6057\n",
      "[1124/1762] D loss: 1.1627, G loss: 1.8123\n",
      "[1204/1762] D loss: 0.2664, G loss: 2.3853\n",
      "[1284/1762] D loss: 0.9243, G loss: 0.6369\n",
      "[1364/1762] D loss: 1.4955, G loss: 0.5189\n",
      "[1444/1762] D loss: 1.4064, G loss: 0.6114\n",
      "[1524/1762] D loss: 2.0825, G loss: 2.0283\n",
      "[1604/1762] D loss: 1.3942, G loss: 0.4060\n",
      "[1684/1762] D loss: 0.5396, G loss: 1.2619\n",
      "[1762/1762] D loss: 1.8243, G loss: 1.4660\n",
      "train error: \n",
      " D loss: 1.534407, G loss: 1.224640, D accuracy: 51.4%, cell accuracy: 99.8%, board accuracy: 86.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.529427, G loss: 1.224723, D accuracy: 51.8%, cell accuracy: 99.8%, board accuracy: 83.9% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.7476, G loss: 1.1868\n",
      "[84/1762] D loss: 0.7769, G loss: 0.8466\n",
      "[164/1762] D loss: 0.4664, G loss: 1.1726\n",
      "[244/1762] D loss: 1.4395, G loss: 0.6936\n",
      "[324/1762] D loss: 0.3064, G loss: 1.9504\n",
      "[404/1762] D loss: 1.4746, G loss: 0.7576\n",
      "[484/1762] D loss: 1.4207, G loss: 0.8132\n",
      "[564/1762] D loss: 1.4733, G loss: 1.1530\n",
      "[644/1762] D loss: 1.4536, G loss: 0.9302\n",
      "[724/1762] D loss: 0.4585, G loss: 1.9527\n",
      "[804/1762] D loss: 1.5423, G loss: 1.1759\n",
      "[884/1762] D loss: 1.4871, G loss: 0.3819\n",
      "[964/1762] D loss: 1.4245, G loss: 0.6034\n",
      "[1044/1762] D loss: 0.7103, G loss: 1.3495\n",
      "[1124/1762] D loss: 1.3238, G loss: 0.6487\n",
      "[1204/1762] D loss: 0.4816, G loss: 1.1666\n",
      "[1284/1762] D loss: 1.3798, G loss: 0.7318\n",
      "[1364/1762] D loss: 1.1797, G loss: 1.0435\n",
      "[1444/1762] D loss: 1.4080, G loss: 0.6452\n",
      "[1524/1762] D loss: 1.1291, G loss: 0.9532\n",
      "[1604/1762] D loss: 1.4820, G loss: 1.0446\n",
      "[1684/1762] D loss: 0.3226, G loss: 1.4838\n",
      "[1762/1762] D loss: 1.6926, G loss: 1.3272\n",
      "train error: \n",
      " D loss: 1.380583, G loss: 0.840045, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 82.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.370116, G loss: 0.844323, D accuracy: 53.9%, cell accuracy: 99.7%, board accuracy: 77.5% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2407, G loss: 1.8056\n",
      "[84/1762] D loss: 1.3325, G loss: 0.6849\n",
      "[164/1762] D loss: 0.1712, G loss: 1.9373\n",
      "[244/1762] D loss: 1.4367, G loss: 0.6008\n",
      "[324/1762] D loss: 1.5460, G loss: 0.9840\n",
      "[404/1762] D loss: 0.6093, G loss: 1.0002\n",
      "[484/1762] D loss: 1.4381, G loss: 0.6465\n",
      "[564/1762] D loss: 1.2121, G loss: 0.7770\n",
      "[644/1762] D loss: 1.1798, G loss: 1.2801\n",
      "[724/1762] D loss: 1.5818, G loss: 0.4079\n",
      "[804/1762] D loss: 1.3636, G loss: 1.2570\n",
      "[884/1762] D loss: 1.4410, G loss: 0.4088\n",
      "[964/1762] D loss: 1.5093, G loss: 0.4373\n",
      "[1044/1762] D loss: 1.7495, G loss: 1.4604\n",
      "[1124/1762] D loss: 1.4833, G loss: 1.0184\n",
      "[1204/1762] D loss: 1.3766, G loss: 1.4084\n",
      "[1284/1762] D loss: 1.2275, G loss: 0.6825\n",
      "[1364/1762] D loss: 1.3333, G loss: 0.9839\n",
      "[1444/1762] D loss: 1.9268, G loss: 1.5144\n",
      "[1524/1762] D loss: 0.3099, G loss: 1.2261\n",
      "[1604/1762] D loss: 1.2641, G loss: 0.5343\n",
      "[1684/1762] D loss: 1.2600, G loss: 0.5768\n",
      "[1762/1762] D loss: 1.4101, G loss: 0.9258\n",
      "train error: \n",
      " D loss: 1.347095, G loss: 0.723280, D accuracy: 55.8%, cell accuracy: 99.8%, board accuracy: 82.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.341553, G loss: 0.734159, D accuracy: 55.6%, cell accuracy: 99.7%, board accuracy: 78.6% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4160, G loss: 0.6172\n",
      "[84/1762] D loss: 1.6365, G loss: 1.1870\n",
      "[164/1762] D loss: 1.5344, G loss: 0.4064\n",
      "[244/1762] D loss: 1.3959, G loss: 0.6559\n",
      "[324/1762] D loss: 0.6461, G loss: 1.0032\n",
      "[404/1762] D loss: 1.4331, G loss: 0.8508\n",
      "[484/1762] D loss: 1.4128, G loss: 0.9008\n",
      "[564/1762] D loss: 1.5041, G loss: 1.0116\n",
      "[644/1762] D loss: 1.4159, G loss: 1.0397\n",
      "[724/1762] D loss: 1.2840, G loss: 0.4716\n",
      "[804/1762] D loss: 0.9811, G loss: 1.0001\n",
      "[884/1762] D loss: 1.0716, G loss: 1.3950\n",
      "[964/1762] D loss: 0.8900, G loss: 0.9216\n",
      "[1044/1762] D loss: 1.4795, G loss: 0.8791\n",
      "[1124/1762] D loss: 0.1853, G loss: 1.8667\n",
      "[1204/1762] D loss: 1.3337, G loss: 0.5502\n",
      "[1284/1762] D loss: 1.4161, G loss: 0.8395\n",
      "[1364/1762] D loss: 1.4046, G loss: 1.0028\n",
      "[1444/1762] D loss: 0.4203, G loss: 1.2382\n",
      "[1524/1762] D loss: 1.6858, G loss: 0.4088\n",
      "[1604/1762] D loss: 1.4248, G loss: 0.7570\n",
      "[1684/1762] D loss: 1.2879, G loss: 1.6504\n",
      "[1762/1762] D loss: 0.2151, G loss: 2.1066\n",
      "train error: \n",
      " D loss: 1.697803, G loss: 0.295011, D accuracy: 51.2%, cell accuracy: 99.8%, board accuracy: 82.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.696876, G loss: 0.295799, D accuracy: 51.4%, cell accuracy: 99.7%, board accuracy: 78.0% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3411, G loss: 0.8878\n",
      "[84/1762] D loss: 1.7811, G loss: 1.3803\n",
      "[164/1762] D loss: 1.6047, G loss: 0.3628\n",
      "[244/1762] D loss: 1.3735, G loss: 0.8699\n",
      "[324/1762] D loss: 1.0118, G loss: 1.5449\n",
      "[404/1762] D loss: 0.3665, G loss: 1.3266\n",
      "[484/1762] D loss: 1.3461, G loss: 0.8243\n",
      "[564/1762] D loss: 1.3021, G loss: 0.9746\n",
      "[644/1762] D loss: 1.4847, G loss: 0.6167\n",
      "[724/1762] D loss: 1.4405, G loss: 0.4794\n",
      "[804/1762] D loss: 0.8178, G loss: 0.9155\n",
      "[884/1762] D loss: 1.3341, G loss: 0.7207\n",
      "[964/1762] D loss: 0.2998, G loss: 1.5205\n",
      "[1044/1762] D loss: 1.2922, G loss: 0.9354\n",
      "[1124/1762] D loss: 0.2378, G loss: 2.0537\n",
      "[1204/1762] D loss: 0.9487, G loss: 1.5139\n",
      "[1284/1762] D loss: 1.2451, G loss: 2.5543\n",
      "[1364/1762] D loss: 0.8151, G loss: 1.0868\n",
      "[1444/1762] D loss: 1.1563, G loss: 0.9428\n",
      "[1524/1762] D loss: 1.2765, G loss: 0.7763\n",
      "[1604/1762] D loss: 1.4171, G loss: 0.5990\n",
      "[1684/1762] D loss: 2.1619, G loss: 0.2137\n",
      "[1762/1762] D loss: 1.5851, G loss: 1.4050\n",
      "train error: \n",
      " D loss: 1.514373, G loss: 1.332306, D accuracy: 53.0%, cell accuracy: 99.8%, board accuracy: 81.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.503893, G loss: 1.360309, D accuracy: 53.5%, cell accuracy: 99.7%, board accuracy: 77.5% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1523, G loss: 2.7997\n",
      "[84/1762] D loss: 1.5627, G loss: 0.9444\n",
      "[164/1762] D loss: 2.0593, G loss: 1.4549\n",
      "[244/1762] D loss: 1.0536, G loss: 0.8361\n",
      "[324/1762] D loss: 0.4397, G loss: 2.0557\n",
      "[404/1762] D loss: 1.0544, G loss: 0.9736\n",
      "[484/1762] D loss: 1.4173, G loss: 0.9242\n",
      "[564/1762] D loss: 1.3594, G loss: 0.6661\n",
      "[644/1762] D loss: 0.7074, G loss: 1.8942\n",
      "[724/1762] D loss: 0.8308, G loss: 1.0582\n",
      "[804/1762] D loss: 1.7746, G loss: 1.6677\n",
      "[884/1762] D loss: 0.2069, G loss: 1.9059\n",
      "[964/1762] D loss: 1.3812, G loss: 0.9859\n",
      "[1044/1762] D loss: 1.6932, G loss: 1.1083\n",
      "[1124/1762] D loss: 1.3558, G loss: 0.4961\n",
      "[1204/1762] D loss: 1.7780, G loss: 3.2125\n",
      "[1284/1762] D loss: 1.6248, G loss: 0.3313\n",
      "[1364/1762] D loss: 1.3114, G loss: 0.8872\n",
      "[1444/1762] D loss: 0.2091, G loss: 1.9452\n",
      "[1524/1762] D loss: 1.3755, G loss: 1.2450\n",
      "[1604/1762] D loss: 1.2695, G loss: 0.8816\n",
      "[1684/1762] D loss: 1.3607, G loss: 0.7441\n",
      "[1762/1762] D loss: 1.5146, G loss: 1.0844\n",
      "train error: \n",
      " D loss: 1.384654, G loss: 0.572898, D accuracy: 56.2%, cell accuracy: 99.8%, board accuracy: 81.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.366425, G loss: 0.591025, D accuracy: 56.6%, cell accuracy: 99.7%, board accuracy: 75.2% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1115, G loss: 2.4942\n",
      "[84/1762] D loss: 0.6929, G loss: 1.7193\n",
      "[164/1762] D loss: 1.2770, G loss: 1.0513\n",
      "[244/1762] D loss: 0.8159, G loss: 1.3154\n",
      "[324/1762] D loss: 0.2652, G loss: 1.8589\n",
      "[404/1762] D loss: 0.1174, G loss: 2.0170\n",
      "[484/1762] D loss: 0.3621, G loss: 1.4673\n",
      "[564/1762] D loss: 1.1998, G loss: 1.7709\n",
      "[644/1762] D loss: 1.2134, G loss: 1.0560\n",
      "[724/1762] D loss: 1.6687, G loss: 1.2646\n",
      "[804/1762] D loss: 1.0101, G loss: 0.7878\n",
      "[884/1762] D loss: 0.9693, G loss: 0.7653\n",
      "[964/1762] D loss: 0.7717, G loss: 1.2339\n",
      "[1044/1762] D loss: 1.1167, G loss: 0.6607\n",
      "[1124/1762] D loss: 1.3640, G loss: 1.1167\n",
      "[1204/1762] D loss: 0.8329, G loss: 1.1823\n",
      "[1284/1762] D loss: 0.8558, G loss: 1.2299\n",
      "[1364/1762] D loss: 1.6145, G loss: 1.1044\n",
      "[1444/1762] D loss: 0.5069, G loss: 0.9020\n",
      "[1524/1762] D loss: 0.9723, G loss: 0.7037\n",
      "[1604/1762] D loss: 1.4044, G loss: 0.7615\n",
      "[1684/1762] D loss: 0.9050, G loss: 1.5859\n",
      "[1762/1762] D loss: 1.3927, G loss: 0.6244\n",
      "train error: \n",
      " D loss: 1.341406, G loss: 0.760398, D accuracy: 56.3%, cell accuracy: 99.7%, board accuracy: 81.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.318291, G loss: 0.773123, D accuracy: 57.0%, cell accuracy: 99.7%, board accuracy: 77.7% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.2776, G loss: 0.1996\n",
      "[84/1762] D loss: 1.5513, G loss: 1.0168\n",
      "[164/1762] D loss: 1.4312, G loss: 0.7746\n",
      "[244/1762] D loss: 1.0432, G loss: 1.7175\n",
      "[324/1762] D loss: 1.3429, G loss: 0.5784\n",
      "[404/1762] D loss: 1.3214, G loss: 1.0240\n",
      "[484/1762] D loss: 0.6716, G loss: 1.5166\n",
      "[564/1762] D loss: 0.2903, G loss: 1.6570\n",
      "[644/1762] D loss: 1.2765, G loss: 0.9911\n",
      "[724/1762] D loss: 0.6567, G loss: 1.2615\n",
      "[804/1762] D loss: 0.6907, G loss: 2.2055\n",
      "[884/1762] D loss: 0.0806, G loss: 3.1695\n",
      "[964/1762] D loss: 1.3483, G loss: 0.7227\n",
      "[1044/1762] D loss: 0.7232, G loss: 1.3126\n",
      "[1124/1762] D loss: 1.1818, G loss: 0.8785\n",
      "[1204/1762] D loss: 1.5001, G loss: 0.4028\n",
      "[1284/1762] D loss: 1.4105, G loss: 2.2328\n",
      "[1364/1762] D loss: 0.1392, G loss: 2.2917\n",
      "[1444/1762] D loss: 1.3453, G loss: 0.7010\n",
      "[1524/1762] D loss: 0.7542, G loss: 3.5244\n",
      "[1604/1762] D loss: 1.6760, G loss: 0.2822\n",
      "[1684/1762] D loss: 0.7219, G loss: 2.3846\n",
      "[1762/1762] D loss: 1.4619, G loss: 1.2058\n",
      "train error: \n",
      " D loss: 1.438970, G loss: 0.559420, D accuracy: 53.9%, cell accuracy: 99.7%, board accuracy: 80.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.428249, G loss: 0.570984, D accuracy: 54.4%, cell accuracy: 99.7%, board accuracy: 75.7% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3060, G loss: 1.6416\n",
      "[84/1762] D loss: 1.5955, G loss: 1.9627\n",
      "[164/1762] D loss: 0.1836, G loss: 2.2473\n",
      "[244/1762] D loss: 2.3186, G loss: 1.6875\n",
      "[324/1762] D loss: 1.3298, G loss: 0.5123\n",
      "[404/1762] D loss: 1.9473, G loss: 0.3274\n",
      "[484/1762] D loss: 1.6672, G loss: 1.2611\n",
      "[564/1762] D loss: 1.3676, G loss: 1.0446\n",
      "[644/1762] D loss: 1.3338, G loss: 0.5638\n",
      "[724/1762] D loss: 1.7643, G loss: 0.3163\n",
      "[804/1762] D loss: 1.4273, G loss: 0.5280\n",
      "[884/1762] D loss: 0.0349, G loss: 4.1289\n",
      "[964/1762] D loss: 0.1071, G loss: 2.7277\n",
      "[1044/1762] D loss: 0.3690, G loss: 2.3770\n",
      "[1124/1762] D loss: 1.7557, G loss: 0.3106\n",
      "[1204/1762] D loss: 1.2413, G loss: 1.0742\n",
      "[1284/1762] D loss: 1.0396, G loss: 0.9577\n",
      "[1364/1762] D loss: 0.8948, G loss: 1.0454\n",
      "[1444/1762] D loss: 1.4156, G loss: 0.4553\n",
      "[1524/1762] D loss: 0.6627, G loss: 1.6438\n",
      "[1604/1762] D loss: 0.6783, G loss: 1.5999\n",
      "[1684/1762] D loss: 1.1483, G loss: 0.5911\n",
      "[1762/1762] D loss: 0.0708, G loss: 2.8182\n",
      "train error: \n",
      " D loss: 1.797692, G loss: 0.285277, D accuracy: 52.5%, cell accuracy: 99.8%, board accuracy: 81.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.775181, G loss: 0.297862, D accuracy: 52.7%, cell accuracy: 99.7%, board accuracy: 78.0% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3359, G loss: 0.5715\n",
      "[84/1762] D loss: 2.0079, G loss: 0.1862\n",
      "[164/1762] D loss: 1.0955, G loss: 2.9183\n",
      "[244/1762] D loss: 1.2701, G loss: 0.4743\n",
      "[324/1762] D loss: 1.9269, G loss: 0.2680\n",
      "[404/1762] D loss: 0.4908, G loss: 2.1744\n",
      "[484/1762] D loss: 0.2065, G loss: 1.9717\n",
      "[564/1762] D loss: 1.2978, G loss: 1.0509\n",
      "[644/1762] D loss: 0.7715, G loss: 1.2126\n",
      "[724/1762] D loss: 0.1929, G loss: 2.1517\n",
      "[804/1762] D loss: 0.3274, G loss: 1.3477\n",
      "[884/1762] D loss: 1.4316, G loss: 0.6042\n",
      "[964/1762] D loss: 0.4714, G loss: 2.4952\n",
      "[1044/1762] D loss: 0.7350, G loss: 2.1718\n",
      "[1124/1762] D loss: 0.2705, G loss: 2.2361\n",
      "[1204/1762] D loss: 0.7948, G loss: 1.0894\n",
      "[1284/1762] D loss: 1.2376, G loss: 0.7870\n",
      "[1364/1762] D loss: 0.3661, G loss: 1.8477\n",
      "[1444/1762] D loss: 0.1794, G loss: 2.1782\n",
      "[1524/1762] D loss: 0.1468, G loss: 3.3055\n",
      "[1604/1762] D loss: 1.4214, G loss: 0.9919\n",
      "[1684/1762] D loss: 1.0662, G loss: 0.4161\n",
      "[1762/1762] D loss: 1.3107, G loss: 1.0468\n",
      "train error: \n",
      " D loss: 2.758635, G loss: 2.771801, D accuracy: 50.0%, cell accuracy: 99.8%, board accuracy: 82.3% \n",
      "\n",
      "test error: \n",
      " D loss: 2.772441, G loss: 2.831693, D accuracy: 50.0%, cell accuracy: 99.7%, board accuracy: 76.6% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0948, G loss: 3.4507\n",
      "[84/1762] D loss: 1.5169, G loss: 0.5511\n",
      "[164/1762] D loss: 1.4667, G loss: 1.2438\n",
      "[244/1762] D loss: 1.3297, G loss: 0.5427\n",
      "[324/1762] D loss: 0.4838, G loss: 1.3005\n",
      "[404/1762] D loss: 1.2922, G loss: 0.7678\n",
      "[484/1762] D loss: 0.6728, G loss: 1.1816\n",
      "[564/1762] D loss: 1.1330, G loss: 1.6356\n",
      "[644/1762] D loss: 0.9576, G loss: 2.5931\n",
      "[724/1762] D loss: 0.3969, G loss: 1.8053\n",
      "[804/1762] D loss: 0.0335, G loss: 4.0636\n",
      "[884/1762] D loss: 1.1362, G loss: 2.2854\n",
      "[964/1762] D loss: 0.9165, G loss: 1.2074\n",
      "[1044/1762] D loss: 0.3089, G loss: 2.3019\n",
      "[1124/1762] D loss: 0.6246, G loss: 1.3890\n",
      "[1204/1762] D loss: 1.3906, G loss: 1.0258\n",
      "[1284/1762] D loss: 1.2157, G loss: 0.8840\n",
      "[1364/1762] D loss: 1.3605, G loss: 1.2309\n",
      "[1444/1762] D loss: 0.0226, G loss: 5.6172\n",
      "[1524/1762] D loss: 1.4158, G loss: 0.6321\n",
      "[1604/1762] D loss: 1.5258, G loss: 0.4753\n",
      "[1684/1762] D loss: 1.7132, G loss: 2.0938\n",
      "[1762/1762] D loss: 1.3526, G loss: 1.4168\n",
      "train error: \n",
      " D loss: 1.411139, G loss: 0.845917, D accuracy: 52.5%, cell accuracy: 99.7%, board accuracy: 81.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.391528, G loss: 0.846943, D accuracy: 53.0%, cell accuracy: 99.7%, board accuracy: 77.5% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6429, G loss: 1.0634\n",
      "[84/1762] D loss: 1.3843, G loss: 1.0445\n",
      "[164/1762] D loss: 1.4607, G loss: 1.1233\n",
      "[244/1762] D loss: 1.0604, G loss: 1.1283\n",
      "[324/1762] D loss: 1.7474, G loss: 0.3740\n",
      "[404/1762] D loss: 1.3186, G loss: 1.2233\n",
      "[484/1762] D loss: 0.7612, G loss: 2.0263\n",
      "[564/1762] D loss: 1.2334, G loss: 0.5218\n",
      "[644/1762] D loss: 0.0413, G loss: 4.0532\n",
      "[724/1762] D loss: 0.9971, G loss: 3.9444\n",
      "[804/1762] D loss: 0.1647, G loss: 1.9089\n",
      "[884/1762] D loss: 0.3960, G loss: 1.5108\n",
      "[964/1762] D loss: 0.6559, G loss: 2.4560\n",
      "[1044/1762] D loss: 0.0224, G loss: 4.8628\n",
      "[1124/1762] D loss: 1.1409, G loss: 0.6468\n",
      "[1204/1762] D loss: 0.8363, G loss: 0.9288\n",
      "[1284/1762] D loss: 1.1859, G loss: 0.7900\n",
      "[1364/1762] D loss: 0.7802, G loss: 1.2360\n",
      "[1444/1762] D loss: 0.0978, G loss: 2.9458\n",
      "[1524/1762] D loss: 0.7267, G loss: 0.7309\n",
      "[1604/1762] D loss: 1.4947, G loss: 0.4746\n",
      "[1684/1762] D loss: 1.3573, G loss: 0.7739\n",
      "[1762/1762] D loss: 1.3477, G loss: 3.1367\n",
      "train error: \n",
      " D loss: 2.937281, G loss: 3.061081, D accuracy: 50.0%, cell accuracy: 99.7%, board accuracy: 81.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.925720, G loss: 3.062220, D accuracy: 50.1%, cell accuracy: 99.7%, board accuracy: 78.0% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.6057, G loss: 2.0996\n",
      "[84/1762] D loss: 1.2200, G loss: 0.6434\n",
      "[164/1762] D loss: 0.0670, G loss: 3.0337\n",
      "[244/1762] D loss: 0.1638, G loss: 1.7359\n",
      "[324/1762] D loss: 0.8775, G loss: 1.6741\n",
      "[404/1762] D loss: 1.4079, G loss: 0.8645\n",
      "[484/1762] D loss: 0.0145, G loss: 6.8428\n",
      "[564/1762] D loss: 0.3040, G loss: 1.1696\n",
      "[644/1762] D loss: 1.7638, G loss: 0.3191\n",
      "[724/1762] D loss: 0.2833, G loss: 2.3581\n",
      "[804/1762] D loss: 1.1207, G loss: 0.6494\n",
      "[884/1762] D loss: 0.6644, G loss: 1.5421\n",
      "[964/1762] D loss: 0.4700, G loss: 1.5805\n",
      "[1044/1762] D loss: 1.2807, G loss: 0.7901\n",
      "[1124/1762] D loss: 1.1741, G loss: 1.0181\n",
      "[1204/1762] D loss: 0.1394, G loss: 4.3149\n",
      "[1284/1762] D loss: 0.3099, G loss: 2.3190\n",
      "[1364/1762] D loss: 1.1807, G loss: 1.0191\n",
      "[1444/1762] D loss: 0.4004, G loss: 2.0138\n",
      "[1524/1762] D loss: 1.5867, G loss: 1.3457\n",
      "[1604/1762] D loss: 0.0055, G loss: 6.6130\n",
      "[1684/1762] D loss: 1.0476, G loss: 1.0369\n",
      "[1762/1762] D loss: 0.6858, G loss: 0.8245\n",
      "train error: \n",
      " D loss: 1.438456, G loss: 1.064819, D accuracy: 53.8%, cell accuracy: 99.7%, board accuracy: 79.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.424853, G loss: 1.094446, D accuracy: 54.0%, cell accuracy: 99.6%, board accuracy: 73.4% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7696, G loss: 0.7009\n",
      "[84/1762] D loss: 0.6547, G loss: 1.0242\n",
      "[164/1762] D loss: 0.5718, G loss: 1.1252\n",
      "[244/1762] D loss: 0.5581, G loss: 1.4083\n",
      "[324/1762] D loss: 0.2055, G loss: 4.2989\n",
      "[404/1762] D loss: 1.9994, G loss: 0.3094\n",
      "[484/1762] D loss: 0.6488, G loss: 5.8911\n",
      "[564/1762] D loss: 1.3082, G loss: 0.3166\n",
      "[644/1762] D loss: 0.3844, G loss: 1.4484\n",
      "[724/1762] D loss: 0.7489, G loss: 1.1962\n",
      "[804/1762] D loss: 1.4057, G loss: 0.5607\n",
      "[884/1762] D loss: 0.9169, G loss: 0.6668\n",
      "[964/1762] D loss: 0.5063, G loss: 0.9856\n",
      "[1044/1762] D loss: 0.7059, G loss: 1.4413\n",
      "[1124/1762] D loss: 0.1296, G loss: 4.0526\n",
      "[1204/1762] D loss: 0.6686, G loss: 2.6049\n",
      "[1284/1762] D loss: 1.7243, G loss: 1.0817\n",
      "[1364/1762] D loss: 0.6589, G loss: 0.8188\n",
      "[1444/1762] D loss: 0.0266, G loss: 4.2413\n",
      "[1524/1762] D loss: 1.3360, G loss: 0.7261\n",
      "[1604/1762] D loss: 1.4199, G loss: 2.7276\n",
      "[1684/1762] D loss: 0.3698, G loss: 2.3354\n",
      "[1762/1762] D loss: 1.2370, G loss: 0.7236\n",
      "train error: \n",
      " D loss: 2.330390, G loss: 2.290694, D accuracy: 50.4%, cell accuracy: 99.8%, board accuracy: 82.1% \n",
      "\n",
      "test error: \n",
      " D loss: 2.283455, G loss: 2.283605, D accuracy: 50.7%, cell accuracy: 99.7%, board accuracy: 77.0% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0358, G loss: 0.7772\n",
      "[84/1762] D loss: 0.7674, G loss: 2.9436\n",
      "[164/1762] D loss: 1.3036, G loss: 0.9888\n",
      "[244/1762] D loss: 0.8133, G loss: 1.6986\n",
      "[324/1762] D loss: 0.6479, G loss: 2.3620\n",
      "[404/1762] D loss: 0.0121, G loss: 5.9686\n",
      "[484/1762] D loss: 0.0127, G loss: 5.1140\n",
      "[564/1762] D loss: 0.7758, G loss: 1.2826\n",
      "[644/1762] D loss: 0.0331, G loss: 4.1594\n",
      "[724/1762] D loss: 1.0583, G loss: 0.8113\n",
      "[804/1762] D loss: 1.4572, G loss: 0.6504\n",
      "[884/1762] D loss: 0.6875, G loss: 1.0196\n",
      "[964/1762] D loss: 1.5982, G loss: 4.1809\n",
      "[1044/1762] D loss: 1.4296, G loss: 1.4797\n",
      "[1124/1762] D loss: 1.2591, G loss: 0.6566\n",
      "[1204/1762] D loss: 1.4583, G loss: 0.4840\n",
      "[1284/1762] D loss: 0.0675, G loss: 2.8283\n",
      "[1364/1762] D loss: 1.2564, G loss: 1.6394\n",
      "[1444/1762] D loss: 0.7479, G loss: 2.6607\n",
      "[1524/1762] D loss: 0.0703, G loss: 3.1564\n",
      "[1604/1762] D loss: 0.4567, G loss: 1.6743\n",
      "[1684/1762] D loss: 0.6959, G loss: 1.5787\n",
      "[1762/1762] D loss: 1.4716, G loss: 1.1105\n",
      "train error: \n",
      " D loss: 1.417247, G loss: 1.256529, D accuracy: 57.3%, cell accuracy: 99.7%, board accuracy: 81.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.393514, G loss: 1.319482, D accuracy: 58.3%, cell accuracy: 99.7%, board accuracy: 76.8% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2754, G loss: 1.5255\n",
      "[84/1762] D loss: 0.2277, G loss: 1.9583\n",
      "[164/1762] D loss: 0.0975, G loss: 2.5107\n",
      "[244/1762] D loss: 0.9387, G loss: 1.2327\n",
      "[324/1762] D loss: 1.2158, G loss: 0.5361\n",
      "[404/1762] D loss: 0.0787, G loss: 3.4355\n",
      "[484/1762] D loss: 1.4438, G loss: 1.2052\n",
      "[564/1762] D loss: 0.0226, G loss: 4.3117\n",
      "[644/1762] D loss: 3.6397, G loss: 3.3542\n",
      "[724/1762] D loss: 0.3066, G loss: 3.8070\n",
      "[804/1762] D loss: 0.1235, G loss: 3.0486\n",
      "[884/1762] D loss: 1.0566, G loss: 0.8613\n",
      "[964/1762] D loss: 1.9093, G loss: 2.3411\n",
      "[1044/1762] D loss: 1.0678, G loss: 0.9928\n",
      "[1124/1762] D loss: 0.9233, G loss: 0.7212\n",
      "[1204/1762] D loss: 1.3710, G loss: 0.5488\n",
      "[1284/1762] D loss: 0.4614, G loss: 1.7092\n",
      "[1364/1762] D loss: 1.4647, G loss: 1.4886\n",
      "[1444/1762] D loss: 0.0368, G loss: 3.8406\n",
      "[1524/1762] D loss: 0.2436, G loss: 3.3298\n",
      "[1604/1762] D loss: 1.1881, G loss: 0.7708\n",
      "[1684/1762] D loss: 0.6329, G loss: 1.6608\n",
      "[1762/1762] D loss: 0.1252, G loss: 6.3070\n",
      "train error: \n",
      " D loss: 1.671159, G loss: 0.472975, D accuracy: 57.1%, cell accuracy: 99.7%, board accuracy: 79.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.597407, G loss: 0.564138, D accuracy: 58.8%, cell accuracy: 99.6%, board accuracy: 75.5% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.6775, G loss: 1.8384\n",
      "[84/1762] D loss: 1.7866, G loss: 0.3246\n",
      "[164/1762] D loss: 0.9253, G loss: 1.5176\n",
      "[244/1762] D loss: 0.2460, G loss: 1.4133\n",
      "[324/1762] D loss: 0.8629, G loss: 1.2213\n",
      "[404/1762] D loss: 1.1794, G loss: 1.0983\n",
      "[484/1762] D loss: 0.0492, G loss: 7.2641\n",
      "[564/1762] D loss: 0.5128, G loss: 1.2365\n",
      "[644/1762] D loss: 0.6114, G loss: 1.5883\n",
      "[724/1762] D loss: 1.2009, G loss: 0.7149\n",
      "[804/1762] D loss: 0.7721, G loss: 1.4243\n",
      "[884/1762] D loss: 1.2269, G loss: 1.2395\n",
      "[964/1762] D loss: 1.4265, G loss: 0.7478\n",
      "[1044/1762] D loss: 0.5698, G loss: 4.3168\n",
      "[1124/1762] D loss: 0.2113, G loss: 2.6744\n",
      "[1204/1762] D loss: 0.0765, G loss: 3.1033\n",
      "[1284/1762] D loss: 1.1911, G loss: 4.9773\n",
      "[1364/1762] D loss: 1.0549, G loss: 0.8396\n",
      "[1444/1762] D loss: 0.7151, G loss: 3.5950\n",
      "[1524/1762] D loss: 1.1421, G loss: 0.5924\n",
      "[1604/1762] D loss: 0.4585, G loss: 2.6246\n",
      "[1684/1762] D loss: 1.9204, G loss: 0.2738\n",
      "[1762/1762] D loss: 0.6117, G loss: 3.3159\n",
      "train error: \n",
      " D loss: 3.612198, G loss: 0.045814, D accuracy: 49.9%, cell accuracy: 99.7%, board accuracy: 81.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.647211, G loss: 0.043533, D accuracy: 49.8%, cell accuracy: 99.7%, board accuracy: 78.2% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5345, G loss: 1.5434\n",
      "[84/1762] D loss: 1.5221, G loss: 1.4574\n",
      "[164/1762] D loss: 0.1447, G loss: 1.9634\n",
      "[244/1762] D loss: 1.3338, G loss: 1.0674\n",
      "[324/1762] D loss: 0.0868, G loss: 2.4027\n",
      "[404/1762] D loss: 0.0555, G loss: 7.7737\n",
      "[484/1762] D loss: 0.6754, G loss: 1.1210\n",
      "[564/1762] D loss: 0.0961, G loss: 2.7206\n",
      "[644/1762] D loss: 0.5937, G loss: 2.0069\n",
      "[724/1762] D loss: 0.1934, G loss: 2.3596\n",
      "[804/1762] D loss: 0.6366, G loss: 1.3104\n",
      "[884/1762] D loss: 0.8735, G loss: 0.9855\n",
      "[964/1762] D loss: 0.7626, G loss: 1.4596\n",
      "[1044/1762] D loss: 1.2166, G loss: 0.4438\n",
      "[1124/1762] D loss: 0.8546, G loss: 0.9765\n",
      "[1204/1762] D loss: 0.0159, G loss: 4.6459\n",
      "[1284/1762] D loss: 1.8635, G loss: 0.2660\n",
      "[1364/1762] D loss: 0.0832, G loss: 4.0836\n",
      "[1444/1762] D loss: 1.9249, G loss: 0.3518\n",
      "[1524/1762] D loss: 0.1094, G loss: 5.1137\n",
      "[1604/1762] D loss: 2.8070, G loss: 3.5152\n",
      "[1684/1762] D loss: 0.3586, G loss: 1.7315\n",
      "[1762/1762] D loss: 1.5071, G loss: 0.6548\n",
      "train error: \n",
      " D loss: 3.911367, G loss: 0.054534, D accuracy: 50.7%, cell accuracy: 99.7%, board accuracy: 80.3% \n",
      "\n",
      "test error: \n",
      " D loss: 3.803311, G loss: 0.069175, D accuracy: 50.7%, cell accuracy: 99.7%, board accuracy: 77.7% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0673, G loss: 3.6158\n",
      "[84/1762] D loss: 1.4948, G loss: 3.7283\n",
      "[164/1762] D loss: 0.2148, G loss: 3.5389\n",
      "[244/1762] D loss: 0.8981, G loss: 5.1212\n",
      "[324/1762] D loss: 0.9165, G loss: 2.2997\n",
      "[404/1762] D loss: 1.0548, G loss: 1.3219\n",
      "[484/1762] D loss: 0.0643, G loss: 3.1964\n",
      "[564/1762] D loss: 0.9243, G loss: 0.7002\n",
      "[644/1762] D loss: 0.0585, G loss: 3.6785\n",
      "[724/1762] D loss: 2.3721, G loss: 0.2528\n",
      "[804/1762] D loss: 0.3511, G loss: 6.7009\n",
      "[884/1762] D loss: 0.9550, G loss: 1.2237\n",
      "[964/1762] D loss: 0.3049, G loss: 4.6830\n",
      "[1044/1762] D loss: 0.7257, G loss: 5.7360\n",
      "[1124/1762] D loss: 0.2074, G loss: 3.9458\n",
      "[1204/1762] D loss: 0.1994, G loss: 5.3004\n",
      "[1284/1762] D loss: 2.7297, G loss: 0.1344\n",
      "[1364/1762] D loss: 0.4121, G loss: 1.4078\n",
      "[1444/1762] D loss: 0.0049, G loss: 6.2347\n",
      "[1524/1762] D loss: 1.7351, G loss: 0.4500\n",
      "[1604/1762] D loss: 2.7299, G loss: 0.2246\n",
      "[1684/1762] D loss: 3.3561, G loss: 3.0492\n",
      "[1762/1762] D loss: 0.3978, G loss: 2.5665\n",
      "train error: \n",
      " D loss: 3.711929, G loss: 0.062903, D accuracy: 50.6%, cell accuracy: 99.7%, board accuracy: 82.4% \n",
      "\n",
      "test error: \n",
      " D loss: 3.633971, G loss: 0.066525, D accuracy: 50.6%, cell accuracy: 99.7%, board accuracy: 78.9% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0325, G loss: 3.1425\n",
      "[84/1762] D loss: 0.1006, G loss: 3.4303\n",
      "[164/1762] D loss: 0.4721, G loss: 5.8026\n",
      "[244/1762] D loss: 0.2396, G loss: 1.5362\n",
      "[324/1762] D loss: 0.8979, G loss: 1.3831\n",
      "[404/1762] D loss: 1.4845, G loss: 0.3712\n",
      "[484/1762] D loss: 0.0845, G loss: 2.7129\n",
      "[564/1762] D loss: 0.6094, G loss: 2.0747\n",
      "[644/1762] D loss: 0.3623, G loss: 2.9937\n",
      "[724/1762] D loss: 1.1606, G loss: 1.5553\n",
      "[804/1762] D loss: 1.1509, G loss: 0.5069\n",
      "[884/1762] D loss: 0.5152, G loss: 1.8081\n",
      "[964/1762] D loss: 0.0155, G loss: 5.0032\n",
      "[1044/1762] D loss: 0.0647, G loss: 5.3744\n",
      "[1124/1762] D loss: 0.1785, G loss: 2.2077\n",
      "[1204/1762] D loss: 0.0586, G loss: 5.9176\n",
      "[1284/1762] D loss: 0.1472, G loss: 3.5116\n",
      "[1364/1762] D loss: 0.0116, G loss: 4.3817\n",
      "[1444/1762] D loss: 2.7229, G loss: 0.1613\n",
      "[1524/1762] D loss: 0.6487, G loss: 1.8840\n",
      "[1604/1762] D loss: 1.8693, G loss: 2.4426\n",
      "[1684/1762] D loss: 0.1148, G loss: 3.0314\n",
      "[1762/1762] D loss: 0.3193, G loss: 3.7253\n",
      "train error: \n",
      " D loss: 1.370094, G loss: 0.869540, D accuracy: 57.4%, cell accuracy: 99.7%, board accuracy: 81.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.357782, G loss: 0.959962, D accuracy: 59.1%, cell accuracy: 99.7%, board accuracy: 75.5% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1253, G loss: 4.8385\n",
      "[84/1762] D loss: 0.8470, G loss: 1.2482\n",
      "[164/1762] D loss: 0.9827, G loss: 1.0191\n",
      "[244/1762] D loss: 0.3751, G loss: 5.3466\n",
      "[324/1762] D loss: 0.0403, G loss: 3.2168\n",
      "[404/1762] D loss: 0.0105, G loss: 5.2979\n",
      "[484/1762] D loss: 0.2314, G loss: 4.5618\n",
      "[564/1762] D loss: 0.7825, G loss: 1.0199\n",
      "[644/1762] D loss: 0.1592, G loss: 2.7712\n",
      "[724/1762] D loss: 0.1041, G loss: 5.1661\n",
      "[804/1762] D loss: 0.8227, G loss: 3.2264\n",
      "[884/1762] D loss: 0.3337, G loss: 2.1822\n",
      "[964/1762] D loss: 1.2056, G loss: 0.5592\n",
      "[1044/1762] D loss: 0.3620, G loss: 4.8146\n",
      "[1124/1762] D loss: 0.3088, G loss: 6.5778\n",
      "[1204/1762] D loss: 0.4344, G loss: 1.8062\n",
      "[1284/1762] D loss: 0.6897, G loss: 3.6755\n",
      "[1364/1762] D loss: 0.2075, G loss: 2.7477\n",
      "[1444/1762] D loss: 0.0042, G loss: 5.2481\n",
      "[1524/1762] D loss: 0.2420, G loss: 2.9821\n",
      "[1604/1762] D loss: 0.5822, G loss: 2.5873\n",
      "[1684/1762] D loss: 0.7012, G loss: 6.2414\n",
      "[1762/1762] D loss: 0.6088, G loss: 1.1300\n",
      "train error: \n",
      " D loss: 3.152501, G loss: 3.543414, D accuracy: 50.3%, cell accuracy: 99.8%, board accuracy: 82.5% \n",
      "\n",
      "test error: \n",
      " D loss: 3.089855, G loss: 3.548259, D accuracy: 50.1%, cell accuracy: 99.7%, board accuracy: 79.3% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0195, G loss: 4.0190\n",
      "[84/1762] D loss: 0.5531, G loss: 1.9343\n",
      "[164/1762] D loss: 1.0140, G loss: 0.7769\n",
      "[244/1762] D loss: 0.1329, G loss: 3.7973\n",
      "[324/1762] D loss: 0.0605, G loss: 3.2022\n",
      "[404/1762] D loss: 0.5264, G loss: 2.6040\n",
      "[484/1762] D loss: 0.8776, G loss: 1.2835\n",
      "[564/1762] D loss: 0.3358, G loss: 4.8152\n",
      "[644/1762] D loss: 0.0812, G loss: 4.2441\n",
      "[724/1762] D loss: 0.0048, G loss: 7.2654\n",
      "[804/1762] D loss: 0.6662, G loss: 1.0049\n",
      "[884/1762] D loss: 0.5659, G loss: 3.5136\n",
      "[964/1762] D loss: 0.2379, G loss: 2.3049\n",
      "[1044/1762] D loss: 1.0871, G loss: 0.5442\n",
      "[1124/1762] D loss: 0.0880, G loss: 3.5941\n",
      "[1204/1762] D loss: 0.0158, G loss: 7.1462\n",
      "[1284/1762] D loss: 0.0199, G loss: 3.9766\n",
      "[1364/1762] D loss: 0.0079, G loss: 6.0734\n",
      "[1444/1762] D loss: 0.1742, G loss: 3.5735\n",
      "[1524/1762] D loss: 0.0295, G loss: 4.5294\n",
      "[1604/1762] D loss: 0.1835, G loss: 2.6699\n",
      "[1684/1762] D loss: 0.9524, G loss: 2.5988\n",
      "[1762/1762] D loss: 0.1592, G loss: 6.2415\n",
      "train error: \n",
      " D loss: 1.602846, G loss: 2.063908, D accuracy: 59.1%, cell accuracy: 99.8%, board accuracy: 81.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.589534, G loss: 2.151557, D accuracy: 61.3%, cell accuracy: 99.7%, board accuracy: 76.6% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3292, G loss: 2.7992\n",
      "[84/1762] D loss: 0.0762, G loss: 5.2803\n",
      "[164/1762] D loss: 1.4588, G loss: 2.3650\n",
      "[244/1762] D loss: 0.2318, G loss: 3.6539\n",
      "[324/1762] D loss: 0.0483, G loss: 3.6851\n",
      "[404/1762] D loss: 0.3502, G loss: 3.8883\n",
      "[484/1762] D loss: 0.9570, G loss: 0.9308\n",
      "[564/1762] D loss: 0.6028, G loss: 1.2856\n",
      "[644/1762] D loss: 0.9970, G loss: 5.1932\n",
      "[724/1762] D loss: 0.2375, G loss: 3.8222\n",
      "[804/1762] D loss: 2.8784, G loss: 0.1331\n",
      "[884/1762] D loss: 0.8946, G loss: 5.8126\n",
      "[964/1762] D loss: 0.0274, G loss: 7.0022\n",
      "[1044/1762] D loss: 0.7515, G loss: 1.9009\n",
      "[1124/1762] D loss: 0.7963, G loss: 1.2455\n",
      "[1204/1762] D loss: 0.7547, G loss: 2.5060\n",
      "[1284/1762] D loss: 0.1763, G loss: 7.0489\n",
      "[1364/1762] D loss: 0.0041, G loss: 6.4397\n",
      "[1444/1762] D loss: 0.0016, G loss: 8.0216\n",
      "[1524/1762] D loss: 0.1743, G loss: 5.3458\n",
      "[1604/1762] D loss: 0.0488, G loss: 4.8947\n",
      "[1684/1762] D loss: 0.0004, G loss: 8.7750\n",
      "[1762/1762] D loss: 0.0024, G loss: 7.9251\n",
      "train error: \n",
      " D loss: 1.319054, G loss: 1.414040, D accuracy: 60.9%, cell accuracy: 99.7%, board accuracy: 78.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.265957, G loss: 1.520420, D accuracy: 63.9%, cell accuracy: 99.6%, board accuracy: 76.4% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3950, G loss: 5.5105\n",
      "[84/1762] D loss: 0.0418, G loss: 6.2008\n",
      "[164/1762] D loss: 0.1595, G loss: 4.4173\n",
      "[244/1762] D loss: 0.0190, G loss: 5.8460\n",
      "[324/1762] D loss: 0.1347, G loss: 5.6326\n",
      "[404/1762] D loss: 0.0827, G loss: 3.8338\n",
      "[484/1762] D loss: 0.2174, G loss: 4.0884\n",
      "[564/1762] D loss: 0.0152, G loss: 7.2854\n",
      "[644/1762] D loss: 0.1617, G loss: 3.4204\n",
      "[724/1762] D loss: 0.4891, G loss: 2.2397\n",
      "[804/1762] D loss: 0.0195, G loss: 5.1734\n",
      "[884/1762] D loss: 1.0914, G loss: 7.2321\n",
      "[964/1762] D loss: 0.3039, G loss: 1.6086\n",
      "[1044/1762] D loss: 0.7034, G loss: 2.7621\n",
      "[1124/1762] D loss: 1.2960, G loss: 3.0027\n",
      "[1204/1762] D loss: 0.6770, G loss: 1.3111\n",
      "[1284/1762] D loss: 0.3864, G loss: 1.9549\n",
      "[1364/1762] D loss: 0.1111, G loss: 4.8278\n",
      "[1444/1762] D loss: 0.0010, G loss: 7.9122\n",
      "[1524/1762] D loss: 0.0011, G loss: 7.6974\n",
      "[1604/1762] D loss: 0.1819, G loss: 2.8273\n",
      "[1684/1762] D loss: 0.1328, G loss: 7.1005\n",
      "[1762/1762] D loss: 1.2223, G loss: 4.7363\n",
      "train error: \n",
      " D loss: 1.931029, G loss: 0.460504, D accuracy: 58.4%, cell accuracy: 99.7%, board accuracy: 80.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.850180, G loss: 0.511219, D accuracy: 59.1%, cell accuracy: 99.7%, board accuracy: 74.8% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5465, G loss: 7.6604\n",
      "[84/1762] D loss: 0.0759, G loss: 8.7498\n",
      "[164/1762] D loss: 0.0033, G loss: 6.5931\n",
      "[244/1762] D loss: 0.0393, G loss: 5.0481\n",
      "[324/1762] D loss: 0.9945, G loss: 0.8808\n",
      "[404/1762] D loss: 0.1795, G loss: 2.6150\n",
      "[484/1762] D loss: 0.7255, G loss: 1.2281\n",
      "[564/1762] D loss: 0.0699, G loss: 9.0707\n",
      "[644/1762] D loss: 0.6348, G loss: 1.2443\n",
      "[724/1762] D loss: 0.0245, G loss: 6.4744\n",
      "[804/1762] D loss: 0.0094, G loss: 5.9177\n",
      "[884/1762] D loss: 0.1713, G loss: 10.3206\n",
      "[964/1762] D loss: 0.0221, G loss: 6.1394\n",
      "[1044/1762] D loss: 0.0724, G loss: 3.7904\n",
      "[1124/1762] D loss: 0.0116, G loss: 6.9239\n",
      "[1204/1762] D loss: 0.4681, G loss: 2.1369\n",
      "[1284/1762] D loss: 0.8088, G loss: 6.3802\n",
      "[1364/1762] D loss: 0.4250, G loss: 5.1303\n",
      "[1444/1762] D loss: 0.0316, G loss: 4.0216\n",
      "[1524/1762] D loss: 0.4001, G loss: 2.1957\n",
      "[1604/1762] D loss: 0.0047, G loss: 6.9908\n",
      "[1684/1762] D loss: 0.0166, G loss: 4.8998\n",
      "[1762/1762] D loss: 1.0630, G loss: 2.0878\n",
      "train error: \n",
      " D loss: 2.476013, G loss: 0.269949, D accuracy: 54.2%, cell accuracy: 99.7%, board accuracy: 82.1% \n",
      "\n",
      "test error: \n",
      " D loss: 2.399928, G loss: 0.338246, D accuracy: 56.6%, cell accuracy: 99.7%, board accuracy: 76.6% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1156, G loss: 2.5057\n",
      "[84/1762] D loss: 0.2851, G loss: 5.0128\n",
      "[164/1762] D loss: 0.0307, G loss: 6.6103\n",
      "[244/1762] D loss: 0.7394, G loss: 1.9193\n",
      "[324/1762] D loss: 0.0619, G loss: 6.0676\n",
      "[404/1762] D loss: 0.1056, G loss: 5.7383\n",
      "[484/1762] D loss: 0.4968, G loss: 3.5160\n",
      "[564/1762] D loss: 0.0532, G loss: 3.4002\n",
      "[644/1762] D loss: 0.2025, G loss: 1.8558\n",
      "[724/1762] D loss: 0.1964, G loss: 3.5441\n",
      "[804/1762] D loss: 1.4855, G loss: 1.0982\n",
      "[884/1762] D loss: 0.4025, G loss: 3.4794\n",
      "[964/1762] D loss: 0.3533, G loss: 3.5813\n",
      "[1044/1762] D loss: 0.0198, G loss: 3.8872\n",
      "[1124/1762] D loss: 0.0037, G loss: 6.4440\n",
      "[1204/1762] D loss: 0.0642, G loss: 6.0146\n",
      "[1284/1762] D loss: 0.0022, G loss: 7.2216\n",
      "[1364/1762] D loss: 1.5293, G loss: 6.9495\n",
      "[1444/1762] D loss: 0.5932, G loss: 3.2373\n",
      "[1524/1762] D loss: 0.0874, G loss: 3.9526\n",
      "[1604/1762] D loss: 0.0013, G loss: 9.5413\n",
      "[1684/1762] D loss: 0.0136, G loss: 5.5157\n",
      "[1762/1762] D loss: 0.6250, G loss: 4.4185\n",
      "train error: \n",
      " D loss: 2.531322, G loss: 3.335038, D accuracy: 53.6%, cell accuracy: 99.7%, board accuracy: 81.6% \n",
      "\n",
      "test error: \n",
      " D loss: 2.518424, G loss: 3.457867, D accuracy: 55.2%, cell accuracy: 99.7%, board accuracy: 77.3% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0728, G loss: 5.8568\n",
      "[84/1762] D loss: 0.0493, G loss: 3.6216\n",
      "[164/1762] D loss: 0.0108, G loss: 6.5736\n",
      "[244/1762] D loss: 0.0147, G loss: 4.5998\n",
      "[324/1762] D loss: 0.0023, G loss: 9.7752\n",
      "[404/1762] D loss: 0.0873, G loss: 8.9583\n",
      "[484/1762] D loss: 0.2332, G loss: 1.8743\n",
      "[564/1762] D loss: 0.1728, G loss: 4.2416\n",
      "[644/1762] D loss: 0.3087, G loss: 4.5611\n",
      "[724/1762] D loss: 0.0920, G loss: 3.3937\n",
      "[804/1762] D loss: 0.2519, G loss: 2.9641\n",
      "[884/1762] D loss: 0.2271, G loss: 3.3496\n",
      "[964/1762] D loss: 1.4066, G loss: 4.7817\n",
      "[1044/1762] D loss: 0.0009, G loss: 9.7220\n",
      "[1124/1762] D loss: 0.0309, G loss: 3.0935\n",
      "[1204/1762] D loss: 0.1359, G loss: 2.5825\n",
      "[1284/1762] D loss: 0.2074, G loss: 3.5913\n",
      "[1364/1762] D loss: 0.5934, G loss: 1.1706\n",
      "[1444/1762] D loss: 0.4408, G loss: 2.3616\n",
      "[1524/1762] D loss: 0.3321, G loss: 3.9504\n",
      "[1604/1762] D loss: 0.0164, G loss: 4.3688\n",
      "[1684/1762] D loss: 0.0134, G loss: 5.4241\n",
      "[1762/1762] D loss: 0.0136, G loss: 7.2681\n",
      "train error: \n",
      " D loss: 10.126405, G loss: 10.450981, D accuracy: 50.0%, cell accuracy: 99.7%, board accuracy: 80.8% \n",
      "\n",
      "test error: \n",
      " D loss: 10.065202, G loss: 10.448278, D accuracy: 50.0%, cell accuracy: 99.7%, board accuracy: 77.0% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5016, G loss: 2.0892\n",
      "[84/1762] D loss: 0.3712, G loss: 4.4610\n",
      "[164/1762] D loss: 0.1194, G loss: 5.1770\n",
      "[244/1762] D loss: 0.0098, G loss: 6.2055\n",
      "[324/1762] D loss: 0.2850, G loss: 5.3084\n",
      "[404/1762] D loss: 0.5315, G loss: 9.2023\n",
      "[484/1762] D loss: 0.1918, G loss: 2.0513\n",
      "[564/1762] D loss: 0.0286, G loss: 5.2307\n",
      "[644/1762] D loss: 0.0079, G loss: 8.1532\n",
      "[724/1762] D loss: 0.6219, G loss: 2.5676\n",
      "[804/1762] D loss: 0.2731, G loss: 3.2360\n",
      "[884/1762] D loss: 0.0057, G loss: 5.8955\n",
      "[964/1762] D loss: 0.0511, G loss: 6.0861\n",
      "[1044/1762] D loss: 0.0006, G loss: 8.9795\n",
      "[1124/1762] D loss: 0.0042, G loss: 9.3111\n",
      "[1204/1762] D loss: 0.0995, G loss: 3.7713\n",
      "[1284/1762] D loss: 0.0153, G loss: 8.6501\n",
      "[1364/1762] D loss: 0.0152, G loss: 4.6950\n",
      "[1444/1762] D loss: 0.1177, G loss: 4.3147\n",
      "[1524/1762] D loss: 0.1902, G loss: 2.3486\n",
      "[1604/1762] D loss: 0.0202, G loss: 4.9232\n",
      "[1684/1762] D loss: 0.0492, G loss: 3.7775\n",
      "[1762/1762] D loss: 0.0441, G loss: 6.0105\n",
      "train error: \n",
      " D loss: 1.396344, G loss: 1.403422, D accuracy: 67.5%, cell accuracy: 99.8%, board accuracy: 82.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.400076, G loss: 1.475134, D accuracy: 68.6%, cell accuracy: 99.7%, board accuracy: 78.6% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6727, G loss: 1.0011\n",
      "[84/1762] D loss: 0.0055, G loss: 8.6355\n",
      "[164/1762] D loss: 0.0971, G loss: 2.9391\n",
      "[244/1762] D loss: 0.1134, G loss: 3.4128\n",
      "[324/1762] D loss: 0.4414, G loss: 1.2969\n",
      "[404/1762] D loss: 0.4552, G loss: 1.3673\n",
      "[484/1762] D loss: 0.0527, G loss: 5.2838\n",
      "[564/1762] D loss: 0.0358, G loss: 4.8106\n",
      "[644/1762] D loss: 0.0034, G loss: 6.9560\n",
      "[724/1762] D loss: 0.6480, G loss: 7.8732\n",
      "[804/1762] D loss: 0.0471, G loss: 4.4770\n",
      "[884/1762] D loss: 0.0011, G loss: 7.9782\n",
      "[964/1762] D loss: 0.1464, G loss: 3.3494\n",
      "[1044/1762] D loss: 0.5871, G loss: 1.9018\n",
      "[1124/1762] D loss: 0.0008, G loss: 9.0403\n",
      "[1204/1762] D loss: 0.3286, G loss: 4.6873\n",
      "[1284/1762] D loss: 0.0189, G loss: 10.8001\n",
      "[1364/1762] D loss: 0.0007, G loss: 10.9617\n",
      "[1444/1762] D loss: 0.0144, G loss: 7.0728\n",
      "[1524/1762] D loss: 0.0010, G loss: 9.4003\n",
      "[1604/1762] D loss: 0.0276, G loss: 4.3542\n",
      "[1684/1762] D loss: 0.0383, G loss: 6.9281\n",
      "[1762/1762] D loss: 0.0002, G loss: 9.5579\n",
      "train error: \n",
      " D loss: 1.361115, G loss: 1.112524, D accuracy: 64.9%, cell accuracy: 99.7%, board accuracy: 80.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.308516, G loss: 1.160566, D accuracy: 67.8%, cell accuracy: 99.7%, board accuracy: 75.9% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0005, G loss: 8.1400\n",
      "[84/1762] D loss: 0.0159, G loss: 6.0840\n",
      "[164/1762] D loss: 0.3812, G loss: 1.6156\n",
      "[244/1762] D loss: 0.0466, G loss: 4.4720\n",
      "[324/1762] D loss: 1.4012, G loss: 1.4441\n",
      "[404/1762] D loss: 1.3828, G loss: 1.4422\n",
      "[484/1762] D loss: 0.2881, G loss: 3.6169\n",
      "[564/1762] D loss: 0.4427, G loss: 1.3654\n",
      "[644/1762] D loss: 0.4763, G loss: 3.3790\n",
      "[724/1762] D loss: 1.1354, G loss: 5.7946\n",
      "[804/1762] D loss: 0.5023, G loss: 1.4292\n",
      "[884/1762] D loss: 0.7596, G loss: 1.0705\n",
      "[964/1762] D loss: 0.2421, G loss: 2.9740\n",
      "[1044/1762] D loss: 0.0141, G loss: 4.9203\n",
      "[1124/1762] D loss: 0.0058, G loss: 6.2595\n",
      "[1204/1762] D loss: 0.0182, G loss: 5.6217\n",
      "[1284/1762] D loss: 0.0346, G loss: 5.2544\n",
      "[1364/1762] D loss: 0.0019, G loss: 6.9433\n",
      "[1444/1762] D loss: 0.0536, G loss: 8.2254\n",
      "[1524/1762] D loss: 1.2445, G loss: 1.5649\n",
      "[1604/1762] D loss: 0.0007, G loss: 9.0446\n",
      "[1684/1762] D loss: 0.9621, G loss: 6.9958\n",
      "[1762/1762] D loss: 0.0000, G loss: 13.5240\n",
      "train error: \n",
      " D loss: 2.846036, G loss: 3.302974, D accuracy: 50.9%, cell accuracy: 99.8%, board accuracy: 82.4% \n",
      "\n",
      "test error: \n",
      " D loss: 2.762133, G loss: 3.365637, D accuracy: 50.3%, cell accuracy: 99.7%, board accuracy: 78.4% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3233, G loss: 6.3259\n",
      "[84/1762] D loss: 0.2463, G loss: 7.6317\n",
      "[164/1762] D loss: 0.7713, G loss: 6.0489\n",
      "[244/1762] D loss: 0.2270, G loss: 5.7941\n",
      "[324/1762] D loss: 0.7469, G loss: 3.0794\n",
      "[404/1762] D loss: 0.0168, G loss: 4.9553\n",
      "[484/1762] D loss: 0.0015, G loss: 7.3307\n",
      "[564/1762] D loss: 0.0384, G loss: 7.4950\n",
      "[644/1762] D loss: 0.3357, G loss: 1.6161\n",
      "[724/1762] D loss: 0.0157, G loss: 6.8046\n",
      "[804/1762] D loss: 0.3432, G loss: 9.4879\n",
      "[884/1762] D loss: 0.1415, G loss: 5.4437\n",
      "[964/1762] D loss: 0.0502, G loss: 8.1677\n",
      "[1044/1762] D loss: 0.1374, G loss: 5.5991\n",
      "[1124/1762] D loss: 0.0013, G loss: 8.2800\n",
      "[1204/1762] D loss: 0.0657, G loss: 4.1046\n",
      "[1284/1762] D loss: 0.5621, G loss: 1.8033\n",
      "[1364/1762] D loss: 0.3097, G loss: 2.7261\n",
      "[1444/1762] D loss: 0.0670, G loss: 5.6358\n",
      "[1524/1762] D loss: 0.2887, G loss: 4.4684\n",
      "[1604/1762] D loss: 0.0041, G loss: 7.2451\n",
      "[1684/1762] D loss: 0.0431, G loss: 3.3496\n",
      "[1762/1762] D loss: 5.5287, G loss: 0.0565\n",
      "train error: \n",
      " D loss: 3.986028, G loss: 5.017414, D accuracy: 52.4%, cell accuracy: 99.8%, board accuracy: 82.7% \n",
      "\n",
      "test error: \n",
      " D loss: 3.796801, G loss: 5.083334, D accuracy: 53.6%, cell accuracy: 99.7%, board accuracy: 78.0% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0751, G loss: 5.5481\n",
      "[84/1762] D loss: 0.0018, G loss: 6.3443\n",
      "[164/1762] D loss: 0.6376, G loss: 1.8348\n",
      "[244/1762] D loss: 0.3507, G loss: 2.7721\n",
      "[324/1762] D loss: 0.0933, G loss: 4.0399\n",
      "[404/1762] D loss: 0.0024, G loss: 7.2976\n",
      "[484/1762] D loss: 0.0008, G loss: 8.2799\n",
      "[564/1762] D loss: 0.0354, G loss: 4.0197\n",
      "[644/1762] D loss: 0.0051, G loss: 9.1738\n",
      "[724/1762] D loss: 0.0398, G loss: 9.1494\n",
      "[804/1762] D loss: 0.0019, G loss: 10.2766\n",
      "[884/1762] D loss: 1.2918, G loss: 0.5140\n",
      "[964/1762] D loss: 0.7454, G loss: 2.0054\n",
      "[1044/1762] D loss: 0.3764, G loss: 3.0698\n",
      "[1124/1762] D loss: 0.3228, G loss: 2.3978\n",
      "[1204/1762] D loss: 0.0049, G loss: 7.0398\n",
      "[1284/1762] D loss: 0.0006, G loss: 9.1838\n",
      "[1364/1762] D loss: 0.1770, G loss: 6.7808\n",
      "[1444/1762] D loss: 0.4717, G loss: 4.4377\n",
      "[1524/1762] D loss: 0.2153, G loss: 3.5687\n",
      "[1604/1762] D loss: 0.2425, G loss: 7.1837\n",
      "[1684/1762] D loss: 0.0441, G loss: 3.6479\n",
      "[1762/1762] D loss: 1.2051, G loss: 3.6316\n",
      "train error: \n",
      " D loss: 1.462311, G loss: 1.288760, D accuracy: 68.1%, cell accuracy: 99.8%, board accuracy: 82.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.491249, G loss: 1.344916, D accuracy: 67.3%, cell accuracy: 99.7%, board accuracy: 78.0% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0161, G loss: 6.8111\n",
      "[84/1762] D loss: 0.1588, G loss: 5.5466\n",
      "[164/1762] D loss: 0.2266, G loss: 9.1468\n",
      "[244/1762] D loss: 0.0623, G loss: 6.0424\n",
      "[324/1762] D loss: 0.0335, G loss: 4.7202\n",
      "[404/1762] D loss: 0.3066, G loss: 1.5999\n",
      "[484/1762] D loss: 0.0032, G loss: 10.5451\n",
      "[564/1762] D loss: 0.1584, G loss: 7.4206\n",
      "[644/1762] D loss: 0.0003, G loss: 10.1130\n",
      "[724/1762] D loss: 0.0033, G loss: 6.4016\n",
      "[804/1762] D loss: 0.5102, G loss: 5.3244\n",
      "[884/1762] D loss: 0.0001, G loss: 10.7522\n",
      "[964/1762] D loss: 0.0380, G loss: 7.7866\n",
      "[1044/1762] D loss: 0.0869, G loss: 2.8075\n",
      "[1124/1762] D loss: 0.0020, G loss: 6.8305\n",
      "[1204/1762] D loss: 0.0003, G loss: 8.8922\n",
      "[1284/1762] D loss: 0.0010, G loss: 7.9971\n",
      "[1364/1762] D loss: 0.0029, G loss: 6.2728\n",
      "[1444/1762] D loss: 0.0052, G loss: 6.5404\n",
      "[1524/1762] D loss: 0.0390, G loss: 7.5522\n",
      "[1604/1762] D loss: 0.0046, G loss: 11.8188\n",
      "[1684/1762] D loss: 1.3886, G loss: 1.3671\n",
      "[1762/1762] D loss: 0.0143, G loss: 4.3587\n",
      "train error: \n",
      " D loss: 3.599703, G loss: 4.203031, D accuracy: 52.0%, cell accuracy: 99.8%, board accuracy: 83.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.491565, G loss: 4.174294, D accuracy: 53.2%, cell accuracy: 99.7%, board accuracy: 78.9% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7085, G loss: 1.7846\n",
      "[84/1762] D loss: 0.0023, G loss: 8.5230\n",
      "[164/1762] D loss: 0.0008, G loss: 8.6132\n",
      "[244/1762] D loss: 0.0306, G loss: 8.3806\n",
      "[324/1762] D loss: 0.0025, G loss: 7.3072\n",
      "[404/1762] D loss: 0.0560, G loss: 7.4082\n",
      "[484/1762] D loss: 0.0004, G loss: 8.1555\n",
      "[564/1762] D loss: 0.1365, G loss: 3.0090\n",
      "[644/1762] D loss: 0.2831, G loss: 10.1976\n",
      "[724/1762] D loss: 0.0011, G loss: 7.6478\n",
      "[804/1762] D loss: 0.1270, G loss: 6.2513\n",
      "[884/1762] D loss: 0.0006, G loss: 9.2061\n",
      "[964/1762] D loss: 0.0097, G loss: 7.0785\n",
      "[1044/1762] D loss: 0.0867, G loss: 7.3149\n",
      "[1124/1762] D loss: 0.5412, G loss: 5.1756\n",
      "[1204/1762] D loss: 0.0126, G loss: 5.3820\n",
      "[1284/1762] D loss: 0.6735, G loss: 3.0238\n",
      "[1364/1762] D loss: 0.0260, G loss: 9.0660\n",
      "[1444/1762] D loss: 0.0918, G loss: 4.6903\n",
      "[1524/1762] D loss: 0.0307, G loss: 2.9390\n",
      "[1604/1762] D loss: 0.1116, G loss: 2.8964\n",
      "[1684/1762] D loss: 0.0075, G loss: 5.7128\n",
      "[1762/1762] D loss: 0.1043, G loss: 1.5907\n",
      "train error: \n",
      " D loss: 5.946364, G loss: 7.282847, D accuracy: 50.2%, cell accuracy: 99.7%, board accuracy: 80.7% \n",
      "\n",
      "test error: \n",
      " D loss: 5.839117, G loss: 7.301911, D accuracy: 50.2%, cell accuracy: 99.7%, board accuracy: 77.0% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0007, G loss: 9.1528\n",
      "[84/1762] D loss: 0.1898, G loss: 2.4932\n",
      "[164/1762] D loss: 0.0477, G loss: 3.9755\n",
      "[244/1762] D loss: 0.0120, G loss: 9.1062\n",
      "[324/1762] D loss: 0.0028, G loss: 8.3749\n",
      "[404/1762] D loss: 0.0298, G loss: 4.5474\n",
      "[484/1762] D loss: 0.0033, G loss: 6.0335\n",
      "[564/1762] D loss: 1.3930, G loss: 0.8490\n",
      "[644/1762] D loss: 0.1440, G loss: 4.3512\n",
      "[724/1762] D loss: 0.0082, G loss: 6.7311\n",
      "[804/1762] D loss: 0.0097, G loss: 7.3415\n",
      "[884/1762] D loss: 0.0006, G loss: 11.2772\n",
      "[964/1762] D loss: 0.0012, G loss: 8.8280\n",
      "[1044/1762] D loss: 0.0570, G loss: 3.4684\n",
      "[1124/1762] D loss: 0.5063, G loss: 3.4371\n",
      "[1204/1762] D loss: 0.3357, G loss: 3.4135\n",
      "[1284/1762] D loss: 0.0027, G loss: 7.8825\n",
      "[1364/1762] D loss: 0.0245, G loss: 5.9168\n",
      "[1444/1762] D loss: 0.6971, G loss: 2.0197\n",
      "[1524/1762] D loss: 0.0352, G loss: 6.6732\n",
      "[1604/1762] D loss: 0.0283, G loss: 7.1848\n",
      "[1684/1762] D loss: 0.0066, G loss: 6.5798\n",
      "[1762/1762] D loss: 3.3384, G loss: 0.4516\n",
      "train error: \n",
      " D loss: 1.552950, G loss: 2.404087, D accuracy: 64.0%, cell accuracy: 99.8%, board accuracy: 82.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.562883, G loss: 2.639529, D accuracy: 65.7%, cell accuracy: 99.7%, board accuracy: 78.0% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0159, G loss: 6.0645\n",
      "[84/1762] D loss: 0.0002, G loss: 9.7891\n",
      "[164/1762] D loss: 1.0524, G loss: 1.8319\n",
      "[244/1762] D loss: 0.0807, G loss: 3.5080\n",
      "[324/1762] D loss: 0.3221, G loss: 3.1816\n",
      "[404/1762] D loss: 0.0310, G loss: 12.3822\n",
      "[484/1762] D loss: 0.0071, G loss: 5.9908\n",
      "[564/1762] D loss: 0.0173, G loss: 5.4680\n",
      "[644/1762] D loss: 0.1800, G loss: 3.9531\n",
      "[724/1762] D loss: 0.0035, G loss: 7.4759\n",
      "[804/1762] D loss: 0.0254, G loss: 6.9562\n",
      "[884/1762] D loss: 0.0036, G loss: 9.3915\n",
      "[964/1762] D loss: 0.0161, G loss: 9.0676\n",
      "[1044/1762] D loss: 0.0165, G loss: 5.8770\n",
      "[1124/1762] D loss: 0.0151, G loss: 4.2154\n",
      "[1204/1762] D loss: 0.0669, G loss: 5.7067\n",
      "[1284/1762] D loss: 0.2288, G loss: 1.9787\n",
      "[1364/1762] D loss: 0.0005, G loss: 11.1457\n",
      "[1444/1762] D loss: 0.0002, G loss: 11.2874\n",
      "[1524/1762] D loss: 0.0028, G loss: 9.5581\n",
      "[1604/1762] D loss: 0.6457, G loss: 2.1046\n",
      "[1684/1762] D loss: 0.3634, G loss: 6.8609\n",
      "[1762/1762] D loss: 0.1927, G loss: 2.7493\n",
      "train error: \n",
      " D loss: 10.671389, G loss: 11.176216, D accuracy: 50.0%, cell accuracy: 99.8%, board accuracy: 83.2% \n",
      "\n",
      "test error: \n",
      " D loss: 10.608630, G loss: 11.250301, D accuracy: 50.0%, cell accuracy: 99.7%, board accuracy: 78.4% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1112, G loss: 6.0681\n",
      "[84/1762] D loss: 1.3996, G loss: 4.9565\n",
      "[164/1762] D loss: 0.0002, G loss: 11.8343\n",
      "[244/1762] D loss: 0.0600, G loss: 3.7682\n",
      "[324/1762] D loss: 0.4648, G loss: 7.1465\n",
      "[404/1762] D loss: 1.4643, G loss: 8.5061\n",
      "[484/1762] D loss: 0.0096, G loss: 5.6561\n",
      "[564/1762] D loss: 0.1720, G loss: 3.5522\n",
      "[644/1762] D loss: 0.0031, G loss: 8.4495\n",
      "[724/1762] D loss: 0.8985, G loss: 2.2981\n",
      "[804/1762] D loss: 0.0005, G loss: 9.7008\n",
      "[884/1762] D loss: 0.0069, G loss: 10.1919\n",
      "[964/1762] D loss: 0.0007, G loss: 10.7194\n",
      "[1044/1762] D loss: 0.0072, G loss: 9.8556\n",
      "[1124/1762] D loss: 0.4368, G loss: 2.1910\n",
      "[1204/1762] D loss: 0.0827, G loss: 4.0933\n",
      "[1284/1762] D loss: 0.0046, G loss: 11.2300\n",
      "[1364/1762] D loss: 0.0013, G loss: 8.6807\n",
      "[1444/1762] D loss: 0.6177, G loss: 2.4114\n",
      "[1524/1762] D loss: 0.4530, G loss: 2.8229\n",
      "[1604/1762] D loss: 0.0018, G loss: 8.4095\n",
      "[1684/1762] D loss: 0.0119, G loss: 10.1885\n",
      "[1762/1762] D loss: 0.0078, G loss: 7.3594\n",
      "train error: \n",
      " D loss: 1.119501, G loss: 1.655238, D accuracy: 72.1%, cell accuracy: 99.7%, board accuracy: 81.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.071005, G loss: 1.761057, D accuracy: 73.3%, cell accuracy: 99.7%, board accuracy: 75.0% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0868, G loss: 5.3360\n",
      "[84/1762] D loss: 0.0033, G loss: 10.3817\n",
      "[164/1762] D loss: 0.0457, G loss: 4.4395\n",
      "[244/1762] D loss: 0.0008, G loss: 9.8221\n",
      "[324/1762] D loss: 0.0003, G loss: 9.3607\n",
      "[404/1762] D loss: 0.0630, G loss: 9.2218\n",
      "[484/1762] D loss: 0.0008, G loss: 10.5992\n",
      "[564/1762] D loss: 0.0104, G loss: 5.9710\n",
      "[644/1762] D loss: 0.0028, G loss: 6.6438\n",
      "[724/1762] D loss: 0.0365, G loss: 6.0220\n",
      "[804/1762] D loss: 0.0020, G loss: 7.2777\n",
      "[884/1762] D loss: 0.0002, G loss: 10.4935\n",
      "[964/1762] D loss: 0.5915, G loss: 1.2179\n",
      "[1044/1762] D loss: 0.0026, G loss: 7.1555\n",
      "[1124/1762] D loss: 0.0466, G loss: 4.7462\n",
      "[1204/1762] D loss: 0.0239, G loss: 5.3925\n",
      "[1284/1762] D loss: 0.0260, G loss: 10.7960\n",
      "[1364/1762] D loss: 0.0094, G loss: 5.0869\n",
      "[1444/1762] D loss: 0.0978, G loss: 4.1376\n",
      "[1524/1762] D loss: 0.0027, G loss: 7.8072\n",
      "[1604/1762] D loss: 0.1865, G loss: 2.7939\n",
      "[1684/1762] D loss: 0.3083, G loss: 7.1465\n",
      "[1762/1762] D loss: 0.0029, G loss: 6.8046\n",
      "train error: \n",
      " D loss: 2.474984, G loss: 3.814485, D accuracy: 57.9%, cell accuracy: 99.7%, board accuracy: 81.4% \n",
      "\n",
      "test error: \n",
      " D loss: 2.275466, G loss: 3.829652, D accuracy: 59.7%, cell accuracy: 99.7%, board accuracy: 75.2% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8954, G loss: 6.7723\n",
      "[84/1762] D loss: 0.4165, G loss: 1.2899\n",
      "[164/1762] D loss: 0.0635, G loss: 4.5207\n",
      "[244/1762] D loss: 0.9084, G loss: 8.0522\n",
      "[324/1762] D loss: 0.0646, G loss: 7.1214\n",
      "[404/1762] D loss: 0.2913, G loss: 3.8902\n",
      "[484/1762] D loss: 0.0008, G loss: 8.6201\n",
      "[564/1762] D loss: 0.2323, G loss: 5.9283\n",
      "[644/1762] D loss: 0.7438, G loss: 3.3664\n",
      "[724/1762] D loss: 0.0106, G loss: 7.7304\n",
      "[804/1762] D loss: 0.0047, G loss: 10.5156\n",
      "[884/1762] D loss: 0.0630, G loss: 4.9014\n",
      "[964/1762] D loss: 0.0575, G loss: 3.8217\n",
      "[1044/1762] D loss: 0.0410, G loss: 8.9493\n",
      "[1124/1762] D loss: 0.0016, G loss: 7.8873\n",
      "[1204/1762] D loss: 0.4285, G loss: 3.9567\n",
      "[1284/1762] D loss: 0.0019, G loss: 8.7628\n",
      "[1364/1762] D loss: 0.0314, G loss: 5.5608\n",
      "[1444/1762] D loss: 0.0153, G loss: 10.5693\n",
      "[1524/1762] D loss: 0.1238, G loss: 3.2267\n",
      "[1604/1762] D loss: 0.1543, G loss: 4.0018\n",
      "[1684/1762] D loss: 0.1606, G loss: 7.8158\n",
      "[1762/1762] D loss: 0.0068, G loss: 7.0640\n",
      "train error: \n",
      " D loss: 3.299701, G loss: 4.681345, D accuracy: 53.1%, cell accuracy: 99.7%, board accuracy: 80.1% \n",
      "\n",
      "test error: \n",
      " D loss: 3.143202, G loss: 4.711487, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 76.8% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3298, G loss: 7.3627\n",
      "[84/1762] D loss: 0.0039, G loss: 7.6988\n",
      "[164/1762] D loss: 0.0858, G loss: 4.2183\n",
      "[244/1762] D loss: 0.0827, G loss: 7.0864\n",
      "[324/1762] D loss: 1.1004, G loss: 1.9601\n",
      "[404/1762] D loss: 0.0016, G loss: 7.8439\n",
      "[484/1762] D loss: 0.0171, G loss: 5.8970\n",
      "[564/1762] D loss: 0.0048, G loss: 10.5611\n",
      "[644/1762] D loss: 0.0208, G loss: 5.4319\n",
      "[724/1762] D loss: 0.0054, G loss: 6.5241\n",
      "[804/1762] D loss: 0.5963, G loss: 6.7650\n",
      "[884/1762] D loss: 0.0002, G loss: 8.9219\n",
      "[964/1762] D loss: 0.1119, G loss: 7.5786\n",
      "[1044/1762] D loss: 0.0019, G loss: 10.5232\n",
      "[1124/1762] D loss: 0.0199, G loss: 5.7432\n",
      "[1204/1762] D loss: 0.0009, G loss: 8.4519\n",
      "[1284/1762] D loss: 1.0977, G loss: 6.6082\n",
      "[1364/1762] D loss: 0.0084, G loss: 9.4570\n",
      "[1444/1762] D loss: 0.0853, G loss: 8.2987\n",
      "[1524/1762] D loss: 0.0039, G loss: 6.3682\n",
      "[1604/1762] D loss: 0.0038, G loss: 8.2694\n",
      "[1684/1762] D loss: 0.0605, G loss: 4.0072\n",
      "[1762/1762] D loss: 0.2877, G loss: 1.6567\n",
      "train error: \n",
      " D loss: 3.306876, G loss: 3.951398, D accuracy: 53.0%, cell accuracy: 99.8%, board accuracy: 83.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.396970, G loss: 4.038833, D accuracy: 52.8%, cell accuracy: 99.7%, board accuracy: 79.3% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1142, G loss: 9.9708\n",
      "[84/1762] D loss: 0.1861, G loss: 7.3199\n",
      "[164/1762] D loss: 0.0098, G loss: 6.6375\n",
      "[244/1762] D loss: 0.0005, G loss: 7.6142\n",
      "[324/1762] D loss: 0.0081, G loss: 6.9989\n",
      "[404/1762] D loss: 0.0009, G loss: 11.7240\n",
      "[484/1762] D loss: 0.0048, G loss: 10.9136\n",
      "[564/1762] D loss: 0.0092, G loss: 7.3206\n",
      "[644/1762] D loss: 0.0506, G loss: 8.0863\n",
      "[724/1762] D loss: 0.0423, G loss: 10.2362\n",
      "[804/1762] D loss: 0.0003, G loss: 9.7426\n",
      "[884/1762] D loss: 0.0010, G loss: 9.3367\n",
      "[964/1762] D loss: 0.0394, G loss: 5.2379\n",
      "[1044/1762] D loss: 0.0617, G loss: 11.4119\n",
      "[1124/1762] D loss: 0.0016, G loss: 11.6746\n",
      "[1204/1762] D loss: 0.0009, G loss: 9.8433\n",
      "[1284/1762] D loss: 0.0229, G loss: 8.1872\n",
      "[1364/1762] D loss: 0.0032, G loss: 6.3416\n",
      "[1444/1762] D loss: 0.1364, G loss: 4.3530\n",
      "[1524/1762] D loss: 0.0822, G loss: 11.0020\n",
      "[1604/1762] D loss: 0.0818, G loss: 6.6196\n",
      "[1684/1762] D loss: 0.0070, G loss: 4.8407\n",
      "[1762/1762] D loss: 0.0000, G loss: 11.5156\n",
      "train error: \n",
      " D loss: 1.535900, G loss: 1.021189, D accuracy: 59.8%, cell accuracy: 99.7%, board accuracy: 81.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.521598, G loss: 1.030792, D accuracy: 58.8%, cell accuracy: 99.7%, board accuracy: 77.5% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1265, G loss: 5.2769\n",
      "[84/1762] D loss: 0.0173, G loss: 8.3943\n",
      "[164/1762] D loss: 0.0491, G loss: 11.9856\n",
      "[244/1762] D loss: 0.0072, G loss: 8.1024\n",
      "[324/1762] D loss: 0.0035, G loss: 8.8487\n",
      "[404/1762] D loss: 0.0922, G loss: 3.3897\n",
      "[484/1762] D loss: 0.0006, G loss: 9.9279\n",
      "[564/1762] D loss: 0.0008, G loss: 10.5625\n",
      "[644/1762] D loss: 0.0021, G loss: 9.3360\n",
      "[724/1762] D loss: 0.0003, G loss: 13.8881\n",
      "[804/1762] D loss: 3.3855, G loss: 6.1594\n",
      "[884/1762] D loss: 1.3884, G loss: 2.1790\n",
      "[964/1762] D loss: 0.1829, G loss: 4.9013\n",
      "[1044/1762] D loss: 0.0305, G loss: 6.2589\n",
      "[1124/1762] D loss: 1.2304, G loss: 7.4762\n",
      "[1204/1762] D loss: 0.4868, G loss: 3.2133\n",
      "[1284/1762] D loss: 0.1704, G loss: 5.0637\n",
      "[1364/1762] D loss: 0.0150, G loss: 9.3401\n",
      "[1444/1762] D loss: 0.0611, G loss: 5.1001\n",
      "[1524/1762] D loss: 0.0077, G loss: 5.5135\n",
      "[1604/1762] D loss: 0.0172, G loss: 7.9924\n",
      "[1684/1762] D loss: 0.0001, G loss: 10.4224\n",
      "[1762/1762] D loss: 0.0151, G loss: 4.3477\n",
      "train error: \n",
      " D loss: 2.709157, G loss: 4.338653, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 81.2% \n",
      "\n",
      "test error: \n",
      " D loss: 2.700853, G loss: 4.518053, D accuracy: 55.2%, cell accuracy: 99.7%, board accuracy: 76.1% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0087, G loss: 9.7143\n",
      "[84/1762] D loss: 0.0103, G loss: 8.5692\n",
      "[164/1762] D loss: 0.0016, G loss: 9.7323\n",
      "[244/1762] D loss: 0.0047, G loss: 5.0908\n",
      "[324/1762] D loss: 0.0003, G loss: 10.2669\n",
      "[404/1762] D loss: 0.0002, G loss: 11.0614\n",
      "[484/1762] D loss: 0.0023, G loss: 8.5067\n",
      "[564/1762] D loss: 0.0043, G loss: 7.2755\n",
      "[644/1762] D loss: 0.0008, G loss: 10.1439\n",
      "[724/1762] D loss: 0.2242, G loss: 2.8485\n",
      "[804/1762] D loss: 0.0010, G loss: 7.0317\n",
      "[884/1762] D loss: 0.0027, G loss: 9.8497\n",
      "[964/1762] D loss: 0.3437, G loss: 9.2438\n",
      "[1044/1762] D loss: 0.7761, G loss: 1.3038\n",
      "[1124/1762] D loss: 0.0015, G loss: 10.3764\n",
      "[1204/1762] D loss: 0.0204, G loss: 4.3579\n",
      "[1284/1762] D loss: 0.0003, G loss: 11.9355\n",
      "[1364/1762] D loss: 0.0090, G loss: 7.7897\n",
      "[1444/1762] D loss: 0.0008, G loss: 7.5664\n",
      "[1524/1762] D loss: 0.1218, G loss: 3.6544\n",
      "[1604/1762] D loss: 0.0462, G loss: 6.6960\n",
      "[1684/1762] D loss: 0.0002, G loss: 12.3399\n",
      "[1762/1762] D loss: 0.0136, G loss: 6.2675\n",
      "train error: \n",
      " D loss: 5.309466, G loss: 6.063512, D accuracy: 50.3%, cell accuracy: 99.8%, board accuracy: 82.7% \n",
      "\n",
      "test error: \n",
      " D loss: 5.288587, G loss: 6.074396, D accuracy: 50.5%, cell accuracy: 99.7%, board accuracy: 76.6% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2102, G loss: 3.5036\n",
      "[84/1762] D loss: 0.0004, G loss: 10.8989\n",
      "[164/1762] D loss: 0.0028, G loss: 5.9563\n",
      "[244/1762] D loss: 0.0047, G loss: 7.4170\n",
      "[324/1762] D loss: 0.0095, G loss: 5.8431\n",
      "[404/1762] D loss: 0.0014, G loss: 11.0634\n",
      "[484/1762] D loss: 0.0057, G loss: 8.1426\n",
      "[564/1762] D loss: 0.0003, G loss: 9.0801\n",
      "[644/1762] D loss: 0.1315, G loss: 5.9588\n",
      "[724/1762] D loss: 0.0324, G loss: 7.6122\n",
      "[804/1762] D loss: 0.0047, G loss: 11.8954\n",
      "[884/1762] D loss: 0.3728, G loss: 3.6595\n",
      "[964/1762] D loss: 0.0029, G loss: 10.1201\n",
      "[1044/1762] D loss: 0.0040, G loss: 6.1719\n",
      "[1124/1762] D loss: 0.0187, G loss: 7.1133\n",
      "[1204/1762] D loss: 0.0309, G loss: 6.9389\n",
      "[1284/1762] D loss: 0.0318, G loss: 7.4801\n",
      "[1364/1762] D loss: 0.0112, G loss: 9.6028\n",
      "[1444/1762] D loss: 0.0005, G loss: 9.5866\n",
      "[1524/1762] D loss: 0.2045, G loss: 2.7606\n",
      "[1604/1762] D loss: 0.0015, G loss: 7.7692\n",
      "[1684/1762] D loss: 0.2213, G loss: 3.9941\n",
      "[1762/1762] D loss: 0.0008, G loss: 7.9695\n",
      "train error: \n",
      " D loss: 1.986467, G loss: 0.409102, D accuracy: 56.1%, cell accuracy: 99.7%, board accuracy: 81.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.991320, G loss: 0.405359, D accuracy: 56.4%, cell accuracy: 99.7%, board accuracy: 76.8% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0020, G loss: 8.0153\n",
      "[84/1762] D loss: 0.0151, G loss: 5.3490\n",
      "[164/1762] D loss: 0.0016, G loss: 7.6096\n",
      "[244/1762] D loss: 0.0001, G loss: 11.1070\n",
      "[324/1762] D loss: 0.0026, G loss: 8.6614\n",
      "[404/1762] D loss: 0.0013, G loss: 7.1256\n",
      "[484/1762] D loss: 0.0080, G loss: 5.8928\n",
      "[564/1762] D loss: 0.0856, G loss: 4.8583\n",
      "[644/1762] D loss: 0.0062, G loss: 7.2193\n",
      "[724/1762] D loss: 0.0309, G loss: 8.4277\n",
      "[804/1762] D loss: 0.0259, G loss: 3.8889\n",
      "[884/1762] D loss: 0.0168, G loss: 5.5484\n",
      "[964/1762] D loss: 0.0014, G loss: 7.8431\n",
      "[1044/1762] D loss: 0.0003, G loss: 8.3193\n",
      "[1124/1762] D loss: 0.0002, G loss: 12.0502\n",
      "[1204/1762] D loss: 0.4308, G loss: 3.5431\n",
      "[1284/1762] D loss: 0.0009, G loss: 10.0419\n",
      "[1364/1762] D loss: 0.6355, G loss: 10.8100\n",
      "[1444/1762] D loss: 1.2142, G loss: 2.7300\n",
      "[1524/1762] D loss: 0.1187, G loss: 8.5348\n",
      "[1604/1762] D loss: 0.2934, G loss: 5.2549\n",
      "[1684/1762] D loss: 0.2370, G loss: 3.7607\n",
      "[1762/1762] D loss: 0.0046, G loss: 6.0854\n",
      "train error: \n",
      " D loss: 2.272098, G loss: 3.180749, D accuracy: 62.0%, cell accuracy: 99.7%, board accuracy: 80.8% \n",
      "\n",
      "test error: \n",
      " D loss: 2.204292, G loss: 3.281877, D accuracy: 64.0%, cell accuracy: 99.7%, board accuracy: 76.6% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0059, G loss: 7.9863\n",
      "[84/1762] D loss: 0.0341, G loss: 5.4317\n",
      "[164/1762] D loss: 0.0006, G loss: 11.5948\n",
      "[244/1762] D loss: 0.0078, G loss: 6.2571\n",
      "[324/1762] D loss: 0.0003, G loss: 9.0006\n",
      "[404/1762] D loss: 0.0528, G loss: 5.2771\n",
      "[484/1762] D loss: 0.0509, G loss: 5.3261\n",
      "[564/1762] D loss: 0.0081, G loss: 6.2577\n",
      "[644/1762] D loss: 0.0136, G loss: 4.7054\n",
      "[724/1762] D loss: 0.0006, G loss: 7.7920\n",
      "[804/1762] D loss: 0.0211, G loss: 10.2496\n",
      "[884/1762] D loss: 0.0018, G loss: 12.5863\n",
      "[964/1762] D loss: 0.0620, G loss: 11.2313\n",
      "[1044/1762] D loss: 0.0001, G loss: 11.3290\n",
      "[1124/1762] D loss: 0.0002, G loss: 9.7573\n",
      "[1204/1762] D loss: 0.1382, G loss: 4.1046\n",
      "[1284/1762] D loss: 0.0119, G loss: 5.6071\n",
      "[1364/1762] D loss: 0.7243, G loss: 1.7017\n",
      "[1444/1762] D loss: 0.6908, G loss: 2.5876\n",
      "[1524/1762] D loss: 0.4362, G loss: 2.7207\n",
      "[1604/1762] D loss: 0.5162, G loss: 3.3648\n",
      "[1684/1762] D loss: 0.0740, G loss: 11.6154\n",
      "[1762/1762] D loss: 0.2483, G loss: 4.7931\n",
      "train error: \n",
      " D loss: 1.635840, G loss: 1.895787, D accuracy: 62.2%, cell accuracy: 99.8%, board accuracy: 82.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.563671, G loss: 2.066054, D accuracy: 63.7%, cell accuracy: 99.7%, board accuracy: 77.5% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5798, G loss: 3.9839\n",
      "[84/1762] D loss: 0.0003, G loss: 9.9133\n",
      "[164/1762] D loss: 0.4145, G loss: 2.8455\n",
      "[244/1762] D loss: 0.1218, G loss: 5.1447\n",
      "[324/1762] D loss: 0.0018, G loss: 11.5960\n",
      "[404/1762] D loss: 0.0451, G loss: 10.6012\n",
      "[484/1762] D loss: 0.0008, G loss: 10.0136\n",
      "[564/1762] D loss: 0.0003, G loss: 11.7210\n",
      "[644/1762] D loss: 0.0365, G loss: 3.9123\n",
      "[724/1762] D loss: 0.1409, G loss: 3.8341\n",
      "[804/1762] D loss: 0.0033, G loss: 9.8583\n",
      "[884/1762] D loss: 0.0006, G loss: 9.8622\n",
      "[964/1762] D loss: 0.0007, G loss: 11.7900\n",
      "[1044/1762] D loss: 0.0268, G loss: 9.3837\n",
      "[1124/1762] D loss: 0.0007, G loss: 12.7305\n",
      "[1204/1762] D loss: 0.0217, G loss: 7.1407\n",
      "[1284/1762] D loss: 0.0007, G loss: 10.9835\n",
      "[1364/1762] D loss: 0.0404, G loss: 11.6261\n",
      "[1444/1762] D loss: 0.0060, G loss: 6.4516\n",
      "[1524/1762] D loss: 0.7424, G loss: 14.0594\n",
      "[1604/1762] D loss: 0.0335, G loss: 4.1196\n",
      "[1684/1762] D loss: 0.1407, G loss: 6.0002\n",
      "[1762/1762] D loss: 0.0354, G loss: 10.1947\n",
      "train error: \n",
      " D loss: 4.357330, G loss: 5.636107, D accuracy: 51.5%, cell accuracy: 99.8%, board accuracy: 82.9% \n",
      "\n",
      "test error: \n",
      " D loss: 4.315334, G loss: 5.813946, D accuracy: 51.9%, cell accuracy: 99.7%, board accuracy: 76.8% \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_and_freeze_gen(run_name=\"freeze_gen_epoch_5\", freeze_epoch=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the generator is frozen immediately, the discriminator easily learns to distinguish between fake and real data.\n",
    "\n",
    "However, if the generator is frozen after 5 epochs, the discriminator loss becomes unstable. The frozen generator's highest board accuracy is 86.56%, which suggests that the generator could expect to get at most 56.72% predictions correct*. The discriminator's actual accuracy for the corresponding epochs was 55.07% and 52.75%, which suggests there is some room for improvement.\n",
    "\n",
    "The instability can be seen most clearly in the discriminator loss, which jumps up and down and on average goes up.\n",
    "\n",
    "*Let $ p_g $ be the probability that the generator produces passable output, as defines by the rules of Tetris. Let $ a_g $ be the probability that the generator's output matches the training data, and $ a_d $ the probability of the discriminator making a correct classification. Then we have $ a_d \\le \\frac{1}{2} + \\frac{1}{2} (1 - p_g) = 1 - \\frac{1}{2} p_g $, because the discriminator gets shown 50% real and 50% fake data, and since $ p_g \\le 1 $, the best strategy for a perfect discriminator is to label data as real when it looks real and fake when it looks fake. If it does so, it marks all of the real data correctly and $ (1 - p_g) $ of the fake data correctly. It's difficult to measure $ p_g $ directly, but we know $ a_g \\le p_g $. (\"If it matches the training data, then it looks realistic.\")\n",
    "\n",
    "Therefore we get the equation $ a_d + \\frac{1}{2} a_g \\le 1 $.\n",
    "\n",
    "There is a lower bound too. If the generator produces terrible output and the discriminator guesses randomly, we get $ a_d + \\frac{1}{2} a_g \\ge \\frac{1}{2} $.\n",
    "\n",
    "This suggests the metric $ 2 a_d + a_g - 1 $, which should be between 0 and 1.\n",
    "\n",
    "In practice, this metric might be negative if the discriminator is doing worse than random chance, but in this case it could just flip the prediction and score higher. The metric could also be slightly above 1, because the discriminator might get lucky with its guesses.\n",
    "\n",
    "When the metric is high, we can interpret this as \"given the current performance of the generator, the discriminator is able to identify almost all of its mistakes\".\n",
    "\n",
    "Let's redefine the test loop to include this metric."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(split_name, dataloader, gen, disc, loss_fn, tb_writer, epoch, examples):\n",
    "    gen.eval()\n",
    "    disc.eval()\n",
    "\n",
    "    loss_disc = 0.0\n",
    "    loss_gen = 0.0\n",
    "    disc_accuracy = 0.0\n",
    "    cell_accuracy = 0.0\n",
    "    board_accuracy = 0.0\n",
    "    spawn_recall = 0.0\n",
    "    num_spawns = 0.0\n",
    "    spawn_precision = 0.0\n",
    "    num_predicted_spawns = 0.0\n",
    "\n",
    "    num_batches = len(dataloader)\n",
    "    with torch.no_grad():        \n",
    "        for X, y in dataloader:\n",
    "            batch_size = X.size(0)\n",
    "            real_labels = torch.full((batch_size,), real_label, dtype=torch.float, device=device)\n",
    "            fake_labels = torch.full((batch_size,), fake_label, dtype=torch.float, device=device)\n",
    "\n",
    "            output_real = disc(X, y)\n",
    "            loss_disc += loss_fn(output_real, real_labels).item()\n",
    "\n",
    "            z = torch.rand(batch_size, 4, device=device)\n",
    "            y_fake = gen(X, z)\n",
    "            output_fake = disc(X, y_fake)\n",
    "            \n",
    "            loss_disc += loss_fn(output_fake, fake_labels).item()\n",
    "            loss_gen += loss_fn(output_fake, real_labels).item()\n",
    "\n",
    "            pred_real = (output_real > 0.0)\n",
    "            pred_fake = (output_fake > 0.0)\n",
    "            disc_accuracy += pred_real.type(torch.float).mean().item()\n",
    "            disc_accuracy += (~pred_fake).type(torch.float).mean().item()\n",
    "\n",
    "            classes_X = torch.argmax(X, dim=1)\n",
    "            classes_y = torch.argmax(y, dim=1)\n",
    "            classes_y_fake = torch.argmax(y_fake, dim=1)\n",
    "            cell_accuracy += (classes_y_fake == classes_y).type(torch.float).mean().item()\n",
    "            board_accuracy += (classes_y_fake == classes_y).all(-1).all(-1).type(torch.float).mean().item()\n",
    "\n",
    "            actual_spawns = (classes_X[:, 0, :] == 0).all(-1) & (classes_y[:, 0, :] == 1).any(-1)\n",
    "            predicted_spawns = (classes_y_fake[:, 0, :] == 1).any(-1)\n",
    "            num_true_positives = (actual_spawns & predicted_spawns).type(torch.float).sum().item()\n",
    "            spawn_recall += num_true_positives\n",
    "            num_spawns += actual_spawns.type(torch.float).sum().item()\n",
    "            spawn_precision += num_true_positives\n",
    "            num_predicted_spawns += predicted_spawns.type(torch.float).sum().item()\n",
    "\n",
    "    loss_disc /= num_batches\n",
    "    loss_gen /= num_batches\n",
    "    cell_accuracy /= num_batches\n",
    "    board_accuracy /= num_batches\n",
    "    spawn_recall /= num_spawns\n",
    "    spawn_precision = np.nan if (num_predicted_spawns == 0.0) else (spawn_precision / num_predicted_spawns)\n",
    "    disc_accuracy /= (2.0 * num_batches)\n",
    "    combined_accuracy = board_accuracy + 2.0 * disc_accuracy - 1.0\n",
    "\n",
    "    print(f\"{split_name} error: \\n D loss: {loss_disc:>8f}, G loss: {loss_gen:>8f}, D accuracy: {(100*disc_accuracy):>0.1f}%, cell accuracy: {(100*cell_accuracy):>0.1f}%, board accuracy: {(100*board_accuracy):>0.1f}% \\n\")\n",
    "\n",
    "    tb_writer.add_scalar(f\"Discriminator loss/{split_name}\", loss_disc, epoch)\n",
    "    tb_writer.add_scalar(f\"Loss/{split_name}\", loss_gen, epoch)\n",
    "    tb_writer.add_scalar(f\"Discriminator accuracy/{split_name}\", disc_accuracy, epoch)\n",
    "    tb_writer.add_scalar(f\"Cell accuracy/{split_name}\", cell_accuracy, epoch)\n",
    "    tb_writer.add_scalar(f\"Board accuracy/{split_name}\", board_accuracy, epoch)\n",
    "    tb_writer.add_scalar(f\"Spawn recall/{split_name}\", spawn_recall, epoch)\n",
    "    tb_writer.add_scalar(f\"Combined accuracy/{split_name}\", combined_accuracy, epoch)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (X, y) in enumerate(examples):\n",
    "            X, y = X.unsqueeze(0), y.unsqueeze(0)\n",
    "            z = torch.rand(1, 4, device=device)\n",
    "            y_fake = gen(X, z)\n",
    "            X, y, y_fake = X.squeeze(0), y.squeeze(0), y_fake.squeeze(0)\n",
    "            X, y, y_fake = X.argmax(0), y.argmax(0), y_fake.argmax(0)\n",
    "            img = render_prediction(X, y_fake, y)\n",
    "            tb_writer.add_image(f\"Predictions/{split_name}/{i}\", img, epoch, dataformats=\"HW\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3582, G loss: 0.7652\n",
      "[84/1762] D loss: 0.5708, G loss: 1.3413\n",
      "[164/1762] D loss: 0.2174, G loss: 2.0594\n",
      "[244/1762] D loss: 0.0727, G loss: 3.8658\n",
      "[324/1762] D loss: 0.0449, G loss: 3.9796\n",
      "[404/1762] D loss: 0.0299, G loss: 4.6527\n",
      "[484/1762] D loss: 0.0272, G loss: 4.5964\n",
      "[564/1762] D loss: 0.0789, G loss: 4.6917\n",
      "[644/1762] D loss: 0.1421, G loss: 4.2983\n",
      "[724/1762] D loss: 0.1460, G loss: 2.6522\n",
      "[804/1762] D loss: 0.4003, G loss: 3.4869\n",
      "[884/1762] D loss: 0.0498, G loss: 4.6915\n",
      "[964/1762] D loss: 1.2528, G loss: 2.1709\n",
      "[1044/1762] D loss: 0.4615, G loss: 0.8731\n",
      "[1124/1762] D loss: 2.1258, G loss: 0.4588\n",
      "[1204/1762] D loss: 0.8899, G loss: 1.2532\n",
      "[1284/1762] D loss: 0.6042, G loss: 0.8578\n",
      "[1364/1762] D loss: 0.6118, G loss: 1.4607\n",
      "[1444/1762] D loss: 1.0362, G loss: 1.2556\n",
      "[1524/1762] D loss: 1.1309, G loss: 2.9071\n",
      "[1604/1762] D loss: 0.8528, G loss: 1.1346\n",
      "[1684/1762] D loss: 0.6562, G loss: 2.8039\n",
      "[1762/1762] D loss: 1.6781, G loss: 0.6633\n",
      "train error: \n",
      " D loss: 1.193707, G loss: 1.142508, D accuracy: 66.4%, cell accuracy: 99.6%, board accuracy: 54.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.167488, G loss: 1.182273, D accuracy: 68.2%, cell accuracy: 99.5%, board accuracy: 49.1% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.1189, G loss: 1.8263\n",
      "[84/1762] D loss: 1.6104, G loss: 2.0784\n",
      "[164/1762] D loss: 0.8596, G loss: 3.0387\n",
      "[244/1762] D loss: 0.7392, G loss: 1.6256\n",
      "[324/1762] D loss: 1.5621, G loss: 0.4185\n",
      "[404/1762] D loss: 1.7824, G loss: 1.4483\n",
      "[484/1762] D loss: 1.0900, G loss: 1.8469\n",
      "[564/1762] D loss: 1.1932, G loss: 0.5082\n",
      "[644/1762] D loss: 1.3445, G loss: 0.8142\n",
      "[724/1762] D loss: 1.3758, G loss: 0.7579\n",
      "[804/1762] D loss: 1.0015, G loss: 1.0391\n",
      "[884/1762] D loss: 1.5695, G loss: 1.3508\n",
      "[964/1762] D loss: 1.3808, G loss: 0.7374\n",
      "[1044/1762] D loss: 1.4313, G loss: 0.5987\n",
      "[1124/1762] D loss: 1.2252, G loss: 1.1093\n",
      "[1204/1762] D loss: 1.3446, G loss: 0.6637\n",
      "[1284/1762] D loss: 0.9696, G loss: 0.9103\n",
      "[1364/1762] D loss: 1.3851, G loss: 0.6120\n",
      "[1444/1762] D loss: 1.3764, G loss: 0.7204\n",
      "[1524/1762] D loss: 0.8263, G loss: 0.8134\n",
      "[1604/1762] D loss: 1.3393, G loss: 0.6376\n",
      "[1684/1762] D loss: 1.4834, G loss: 0.4643\n",
      "[1762/1762] D loss: 1.4654, G loss: 0.4467\n",
      "train error: \n",
      " D loss: 1.630512, G loss: 0.317754, D accuracy: 50.7%, cell accuracy: 99.7%, board accuracy: 77.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.606866, G loss: 0.327376, D accuracy: 51.1%, cell accuracy: 99.7%, board accuracy: 73.0% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1576, G loss: 0.5877\n",
      "[84/1762] D loss: 1.5403, G loss: 0.4418\n",
      "[164/1762] D loss: 1.1478, G loss: 1.0236\n",
      "[244/1762] D loss: 1.2790, G loss: 0.7660\n",
      "[324/1762] D loss: 1.1392, G loss: 0.7180\n",
      "[404/1762] D loss: 0.9502, G loss: 1.0770\n",
      "[484/1762] D loss: 1.6160, G loss: 0.3565\n",
      "[564/1762] D loss: 1.1494, G loss: 0.9713\n",
      "[644/1762] D loss: 0.7421, G loss: 1.2502\n",
      "[724/1762] D loss: 0.8275, G loss: 0.9105\n",
      "[804/1762] D loss: 1.4546, G loss: 0.8857\n",
      "[884/1762] D loss: 0.6981, G loss: 0.9072\n",
      "[964/1762] D loss: 1.3626, G loss: 0.7604\n",
      "[1044/1762] D loss: 1.4088, G loss: 0.6594\n",
      "[1124/1762] D loss: 1.4503, G loss: 0.5005\n",
      "[1204/1762] D loss: 1.4777, G loss: 0.6834\n",
      "[1284/1762] D loss: 1.3783, G loss: 0.8388\n",
      "[1364/1762] D loss: 1.3660, G loss: 0.9960\n",
      "[1444/1762] D loss: 0.3936, G loss: 2.0893\n",
      "[1524/1762] D loss: 1.4995, G loss: 0.8767\n",
      "[1604/1762] D loss: 1.2140, G loss: 1.1957\n",
      "[1684/1762] D loss: 1.4080, G loss: 0.7751\n",
      "[1762/1762] D loss: 1.4139, G loss: 0.9110\n",
      "train error: \n",
      " D loss: 1.358413, G loss: 0.977195, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 81.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.345750, G loss: 1.035070, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 78.6% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6797, G loss: 1.4416\n",
      "[84/1762] D loss: 1.3554, G loss: 0.9658\n",
      "[164/1762] D loss: 1.3432, G loss: 0.7979\n",
      "[244/1762] D loss: 0.6093, G loss: 0.9932\n",
      "[324/1762] D loss: 0.5330, G loss: 1.3621\n",
      "[404/1762] D loss: 1.4776, G loss: 0.8258\n",
      "[484/1762] D loss: 0.8382, G loss: 0.8678\n",
      "[564/1762] D loss: 1.4386, G loss: 1.0532\n",
      "[644/1762] D loss: 0.4935, G loss: 1.7575\n",
      "[724/1762] D loss: 1.3936, G loss: 0.7298\n",
      "[804/1762] D loss: 1.3895, G loss: 0.5993\n",
      "[884/1762] D loss: 1.4816, G loss: 0.4803\n",
      "[964/1762] D loss: 0.6886, G loss: 0.9489\n",
      "[1044/1762] D loss: 0.4463, G loss: 2.0823\n",
      "[1124/1762] D loss: 1.4883, G loss: 1.2758\n",
      "[1204/1762] D loss: 1.4417, G loss: 0.6045\n",
      "[1284/1762] D loss: 0.4557, G loss: 1.2516\n",
      "[1364/1762] D loss: 0.4850, G loss: 1.6567\n",
      "[1444/1762] D loss: 1.3749, G loss: 0.6935\n",
      "[1524/1762] D loss: 1.4070, G loss: 0.5150\n",
      "[1604/1762] D loss: 1.4144, G loss: 0.7305\n",
      "[1684/1762] D loss: 1.4783, G loss: 0.5764\n",
      "[1762/1762] D loss: 1.5380, G loss: 0.9554\n",
      "train error: \n",
      " D loss: 1.263756, G loss: 1.068362, D accuracy: 59.1%, cell accuracy: 99.5%, board accuracy: 59.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.257064, G loss: 1.099999, D accuracy: 57.7%, cell accuracy: 99.5%, board accuracy: 55.7% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4976, G loss: 0.9255\n",
      "[84/1762] D loss: 0.5078, G loss: 1.6482\n",
      "[164/1762] D loss: 1.3926, G loss: 0.5805\n",
      "[244/1762] D loss: 1.4373, G loss: 0.6701\n",
      "[324/1762] D loss: 1.1457, G loss: 1.4250\n",
      "[404/1762] D loss: 1.4113, G loss: 0.7976\n",
      "[484/1762] D loss: 1.4719, G loss: 0.9191\n",
      "[564/1762] D loss: 1.4126, G loss: 0.8823\n",
      "[644/1762] D loss: 1.3300, G loss: 0.5572\n",
      "[724/1762] D loss: 0.3413, G loss: 1.7704\n",
      "[804/1762] D loss: 0.9850, G loss: 1.0626\n",
      "[884/1762] D loss: 1.3778, G loss: 0.6037\n",
      "[964/1762] D loss: 1.4199, G loss: 1.2746\n",
      "[1044/1762] D loss: 1.4376, G loss: 0.5963\n",
      "[1124/1762] D loss: 0.8842, G loss: 0.7022\n",
      "[1204/1762] D loss: 1.3224, G loss: 0.7834\n",
      "[1284/1762] D loss: 0.7414, G loss: 1.4797\n",
      "[1364/1762] D loss: 0.5860, G loss: 1.4406\n",
      "[1444/1762] D loss: 1.6972, G loss: 1.3170\n",
      "[1524/1762] D loss: 1.3870, G loss: 0.8697\n",
      "[1604/1762] D loss: 0.5729, G loss: 1.2813\n",
      "[1684/1762] D loss: 1.5443, G loss: 1.0361\n",
      "[1762/1762] D loss: 0.2604, G loss: 1.9101\n",
      "train error: \n",
      " D loss: 1.362090, G loss: 0.706115, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.364343, G loss: 0.708317, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 84.3% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4458, G loss: 1.2001\n",
      "[84/1762] D loss: 1.3375, G loss: 0.5051\n",
      "[164/1762] D loss: 1.5378, G loss: 0.4928\n",
      "[244/1762] D loss: 1.3981, G loss: 0.7271\n",
      "[324/1762] D loss: 1.3788, G loss: 0.7030\n",
      "[404/1762] D loss: 1.3919, G loss: 0.5328\n",
      "[484/1762] D loss: 1.4007, G loss: 0.7712\n",
      "[564/1762] D loss: 0.1435, G loss: 2.2400\n",
      "[644/1762] D loss: 1.4135, G loss: 0.7438\n",
      "[724/1762] D loss: 1.5347, G loss: 1.2261\n",
      "[804/1762] D loss: 1.5448, G loss: 0.4934\n",
      "[884/1762] D loss: 1.7367, G loss: 1.2657\n",
      "[964/1762] D loss: 1.2879, G loss: 0.8223\n",
      "[1044/1762] D loss: 1.5298, G loss: 1.1623\n",
      "[1124/1762] D loss: 1.3905, G loss: 0.6371\n",
      "[1204/1762] D loss: 1.2395, G loss: 0.5131\n",
      "[1284/1762] D loss: 0.1746, G loss: 2.1441\n",
      "[1364/1762] D loss: 1.5254, G loss: 0.9215\n",
      "[1444/1762] D loss: 1.3483, G loss: 0.8462\n",
      "[1524/1762] D loss: 1.3937, G loss: 0.7586\n",
      "[1604/1762] D loss: 0.2706, G loss: 1.8622\n",
      "[1684/1762] D loss: 1.4259, G loss: 0.6354\n",
      "[1762/1762] D loss: 1.5971, G loss: 0.4650\n",
      "train error: \n",
      " D loss: 1.342950, G loss: 0.637877, D accuracy: 55.9%, cell accuracy: 99.8%, board accuracy: 86.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.337465, G loss: 0.649095, D accuracy: 55.9%, cell accuracy: 99.8%, board accuracy: 83.6% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4278, G loss: 0.6186\n",
      "[84/1762] D loss: 0.3758, G loss: 1.3128\n",
      "[164/1762] D loss: 1.3717, G loss: 1.0155\n",
      "[244/1762] D loss: 0.1009, G loss: 2.6435\n",
      "[324/1762] D loss: 1.2107, G loss: 0.9596\n",
      "[404/1762] D loss: 0.4415, G loss: 1.2472\n",
      "[484/1762] D loss: 0.5832, G loss: 1.3147\n",
      "[564/1762] D loss: 1.3307, G loss: 0.7172\n",
      "[644/1762] D loss: 1.4044, G loss: 0.7188\n",
      "[724/1762] D loss: 1.1775, G loss: 0.8714\n",
      "[804/1762] D loss: 1.3538, G loss: 0.8600\n",
      "[884/1762] D loss: 1.4710, G loss: 1.1616\n",
      "[964/1762] D loss: 0.3955, G loss: 1.4625\n",
      "[1044/1762] D loss: 0.8441, G loss: 1.7768\n",
      "[1124/1762] D loss: 1.6386, G loss: 1.2618\n",
      "[1204/1762] D loss: 1.4839, G loss: 0.5373\n",
      "[1284/1762] D loss: 1.3552, G loss: 0.6305\n",
      "[1364/1762] D loss: 1.4170, G loss: 0.7203\n",
      "[1444/1762] D loss: 1.3380, G loss: 0.7039\n",
      "[1524/1762] D loss: 1.4138, G loss: 0.9176\n",
      "[1604/1762] D loss: 1.4203, G loss: 0.5433\n",
      "[1684/1762] D loss: 0.3080, G loss: 1.4850\n",
      "[1762/1762] D loss: 1.5155, G loss: 0.9516\n",
      "train error: \n",
      " D loss: 1.317773, G loss: 0.681930, D accuracy: 56.3%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.314919, G loss: 0.683839, D accuracy: 56.5%, cell accuracy: 99.8%, board accuracy: 84.5% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4290, G loss: 0.6974\n",
      "[84/1762] D loss: 1.6505, G loss: 1.1830\n",
      "[164/1762] D loss: 1.4067, G loss: 0.8785\n",
      "[244/1762] D loss: 1.3822, G loss: 1.0729\n",
      "[324/1762] D loss: 1.2255, G loss: 0.9353\n",
      "[404/1762] D loss: 0.9037, G loss: 1.3227\n",
      "[484/1762] D loss: 1.3838, G loss: 0.7313\n",
      "[564/1762] D loss: 0.0117, G loss: 4.6576\n",
      "[644/1762] D loss: 1.3930, G loss: 0.6248\n",
      "[724/1762] D loss: 1.3159, G loss: 1.3046\n",
      "[804/1762] D loss: 1.3817, G loss: 0.8509\n",
      "[884/1762] D loss: 1.6451, G loss: 2.5659\n",
      "[964/1762] D loss: 1.4091, G loss: 0.5762\n",
      "[1044/1762] D loss: 0.3415, G loss: 1.3096\n",
      "[1124/1762] D loss: 1.4760, G loss: 0.6199\n",
      "[1204/1762] D loss: 1.2927, G loss: 0.8251\n",
      "[1284/1762] D loss: 0.4169, G loss: 1.4519\n",
      "[1364/1762] D loss: 0.8396, G loss: 1.0253\n",
      "[1444/1762] D loss: 0.1362, G loss: 2.5366\n",
      "[1524/1762] D loss: 0.1307, G loss: 1.7671\n",
      "[1604/1762] D loss: 1.3846, G loss: 0.8997\n",
      "[1684/1762] D loss: 0.2827, G loss: 1.5784\n",
      "[1762/1762] D loss: 1.4328, G loss: 0.5668\n",
      "train error: \n",
      " D loss: 1.387356, G loss: 0.512452, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 86.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.391410, G loss: 0.507116, D accuracy: 55.8%, cell accuracy: 99.8%, board accuracy: 83.9% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3724, G loss: 0.8550\n",
      "[84/1762] D loss: 1.5740, G loss: 1.0831\n",
      "[164/1762] D loss: 1.3977, G loss: 0.7117\n",
      "[244/1762] D loss: 1.3624, G loss: 0.5981\n",
      "[324/1762] D loss: 1.4243, G loss: 1.0192\n",
      "[404/1762] D loss: 1.3793, G loss: 0.7444\n",
      "[484/1762] D loss: 0.6441, G loss: 1.1628\n",
      "[564/1762] D loss: 1.3669, G loss: 0.7790\n",
      "[644/1762] D loss: 0.8652, G loss: 1.2720\n",
      "[724/1762] D loss: 1.3919, G loss: 0.8284\n",
      "[804/1762] D loss: 1.3552, G loss: 0.5955\n",
      "[884/1762] D loss: 0.2261, G loss: 1.9693\n",
      "[964/1762] D loss: 1.3799, G loss: 0.4699\n",
      "[1044/1762] D loss: 0.4038, G loss: 1.7052\n",
      "[1124/1762] D loss: 1.3859, G loss: 0.7082\n",
      "[1204/1762] D loss: 1.4055, G loss: 0.6149\n",
      "[1284/1762] D loss: 1.3496, G loss: 0.6555\n",
      "[1364/1762] D loss: 1.4719, G loss: 0.4418\n",
      "[1444/1762] D loss: 0.4764, G loss: 1.1222\n",
      "[1524/1762] D loss: 1.3100, G loss: 1.0789\n",
      "[1604/1762] D loss: 1.4726, G loss: 0.9025\n",
      "[1684/1762] D loss: 1.2314, G loss: 2.0682\n",
      "[1762/1762] D loss: 1.3686, G loss: 0.7532\n",
      "train error: \n",
      " D loss: 1.429816, G loss: 0.465428, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 87.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.432810, G loss: 0.464598, D accuracy: 55.8%, cell accuracy: 99.8%, board accuracy: 83.6% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4516, G loss: 0.5691\n",
      "[84/1762] D loss: 1.0463, G loss: 1.5327\n",
      "[164/1762] D loss: 0.8392, G loss: 1.1580\n",
      "[244/1762] D loss: 1.3729, G loss: 0.5956\n",
      "[324/1762] D loss: 0.0149, G loss: 4.3852\n",
      "[404/1762] D loss: 1.5371, G loss: 1.3373\n",
      "[484/1762] D loss: 0.2195, G loss: 1.4075\n",
      "[564/1762] D loss: 0.2667, G loss: 1.7132\n",
      "[644/1762] D loss: 0.1955, G loss: 1.9721\n",
      "[724/1762] D loss: 0.0693, G loss: 2.8828\n",
      "[804/1762] D loss: 1.4296, G loss: 0.9049\n",
      "[884/1762] D loss: 1.4009, G loss: 0.5019\n",
      "[964/1762] D loss: 0.4401, G loss: 1.4119\n",
      "[1044/1762] D loss: 0.8666, G loss: 1.6350\n",
      "[1124/1762] D loss: 1.3858, G loss: 0.5654\n",
      "[1204/1762] D loss: 1.1510, G loss: 0.8839\n",
      "[1284/1762] D loss: 1.1534, G loss: 1.2254\n",
      "[1364/1762] D loss: 1.4368, G loss: 0.6145\n",
      "[1444/1762] D loss: 1.3908, G loss: 0.7377\n",
      "[1524/1762] D loss: 1.3855, G loss: 0.8528\n",
      "[1604/1762] D loss: 1.4007, G loss: 0.6032\n",
      "[1684/1762] D loss: 0.2048, G loss: 1.7152\n",
      "[1762/1762] D loss: 1.3849, G loss: 0.5417\n",
      "train error: \n",
      " D loss: 1.352490, G loss: 0.616526, D accuracy: 56.5%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.361118, G loss: 0.610340, D accuracy: 56.6%, cell accuracy: 99.8%, board accuracy: 84.1% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3869, G loss: 0.4989\n",
      "[84/1762] D loss: 0.2516, G loss: 1.7448\n",
      "[164/1762] D loss: 1.3750, G loss: 0.6147\n",
      "[244/1762] D loss: 1.4323, G loss: 1.0241\n",
      "[324/1762] D loss: 1.7834, G loss: 0.4472\n",
      "[404/1762] D loss: 1.5027, G loss: 0.6718\n",
      "[484/1762] D loss: 1.4316, G loss: 0.7167\n",
      "[564/1762] D loss: 0.1873, G loss: 2.0605\n",
      "[644/1762] D loss: 1.3829, G loss: 0.7134\n",
      "[724/1762] D loss: 1.1518, G loss: 1.3256\n",
      "[804/1762] D loss: 1.4243, G loss: 0.5574\n",
      "[884/1762] D loss: 1.3779, G loss: 0.4823\n",
      "[964/1762] D loss: 1.6531, G loss: 1.0271\n",
      "[1044/1762] D loss: 1.4427, G loss: 0.5972\n",
      "[1124/1762] D loss: 1.4277, G loss: 0.9341\n",
      "[1204/1762] D loss: 0.9801, G loss: 1.1537\n",
      "[1284/1762] D loss: 0.2009, G loss: 2.2351\n",
      "[1364/1762] D loss: 1.3302, G loss: 1.4911\n",
      "[1444/1762] D loss: 1.3515, G loss: 0.7622\n",
      "[1524/1762] D loss: 1.4134, G loss: 0.6687\n",
      "[1604/1762] D loss: 1.4460, G loss: 0.8900\n",
      "[1684/1762] D loss: 1.3755, G loss: 0.6045\n",
      "[1762/1762] D loss: 1.4020, G loss: 0.8616\n",
      "train error: \n",
      " D loss: 1.311991, G loss: 0.738076, D accuracy: 58.0%, cell accuracy: 99.8%, board accuracy: 86.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.313105, G loss: 0.756100, D accuracy: 57.5%, cell accuracy: 99.8%, board accuracy: 84.1% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3581, G loss: 0.8302\n",
      "[84/1762] D loss: 1.3636, G loss: 0.6205\n",
      "[164/1762] D loss: 1.8173, G loss: 1.0536\n",
      "[244/1762] D loss: 0.7666, G loss: 1.9375\n",
      "[324/1762] D loss: 1.4765, G loss: 0.9161\n",
      "[404/1762] D loss: 0.3166, G loss: 1.7317\n",
      "[484/1762] D loss: 0.8799, G loss: 1.2915\n",
      "[564/1762] D loss: 1.6432, G loss: 0.4069\n",
      "[644/1762] D loss: 1.3676, G loss: 0.6271\n",
      "[724/1762] D loss: 1.1992, G loss: 0.9347\n",
      "[804/1762] D loss: 1.3690, G loss: 0.7952\n",
      "[884/1762] D loss: 0.2231, G loss: 1.9340\n",
      "[964/1762] D loss: 1.6873, G loss: 0.9655\n",
      "[1044/1762] D loss: 0.4681, G loss: 1.3272\n",
      "[1124/1762] D loss: 0.1164, G loss: 2.8523\n",
      "[1204/1762] D loss: 1.5411, G loss: 0.6979\n",
      "[1284/1762] D loss: 0.0650, G loss: 3.4023\n",
      "[1364/1762] D loss: 1.2499, G loss: 0.7516\n",
      "[1444/1762] D loss: 0.1985, G loss: 1.8011\n",
      "[1524/1762] D loss: 0.2247, G loss: 1.6928\n",
      "[1604/1762] D loss: 1.4913, G loss: 0.4298\n",
      "[1684/1762] D loss: 1.0202, G loss: 1.0746\n",
      "[1762/1762] D loss: 1.3817, G loss: 0.7400\n",
      "train error: \n",
      " D loss: 1.376470, G loss: 0.963919, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 87.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.383937, G loss: 0.945485, D accuracy: 55.6%, cell accuracy: 99.8%, board accuracy: 83.4% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4972, G loss: 0.8662\n",
      "[84/1762] D loss: 0.4424, G loss: 1.2622\n",
      "[164/1762] D loss: 1.4296, G loss: 0.8600\n",
      "[244/1762] D loss: 1.3291, G loss: 1.0381\n",
      "[324/1762] D loss: 1.4014, G loss: 0.5923\n",
      "[404/1762] D loss: 1.3380, G loss: 0.7081\n",
      "[484/1762] D loss: 0.2529, G loss: 1.9794\n",
      "[564/1762] D loss: 1.5054, G loss: 0.8979\n",
      "[644/1762] D loss: 1.3932, G loss: 0.8140\n",
      "[724/1762] D loss: 1.0384, G loss: 1.2896\n",
      "[804/1762] D loss: 1.3876, G loss: 0.7379\n",
      "[884/1762] D loss: 0.0322, G loss: 3.4626\n",
      "[964/1762] D loss: 1.5116, G loss: 0.5679\n",
      "[1044/1762] D loss: 0.9815, G loss: 2.4437\n",
      "[1124/1762] D loss: 0.1904, G loss: 1.9942\n",
      "[1204/1762] D loss: 0.3292, G loss: 1.3946\n",
      "[1284/1762] D loss: 1.7403, G loss: 1.3112\n",
      "[1364/1762] D loss: 1.2830, G loss: 1.2119\n",
      "[1444/1762] D loss: 1.2470, G loss: 0.8331\n",
      "[1524/1762] D loss: 1.4732, G loss: 0.6836\n",
      "[1604/1762] D loss: 0.4886, G loss: 1.3144\n",
      "[1684/1762] D loss: 0.4961, G loss: 1.0664\n",
      "[1762/1762] D loss: 1.3680, G loss: 1.1039\n",
      "train error: \n",
      " D loss: 1.537230, G loss: 0.409294, D accuracy: 52.2%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.538028, G loss: 0.416140, D accuracy: 51.8%, cell accuracy: 99.8%, board accuracy: 84.5% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1427, G loss: 2.3037\n",
      "[84/1762] D loss: 0.0575, G loss: 3.2108\n",
      "[164/1762] D loss: 1.4459, G loss: 0.8179\n",
      "[244/1762] D loss: 1.3973, G loss: 0.6919\n",
      "[324/1762] D loss: 1.3950, G loss: 0.6452\n",
      "[404/1762] D loss: 0.2446, G loss: 2.3580\n",
      "[484/1762] D loss: 1.3628, G loss: 0.6733\n",
      "[564/1762] D loss: 1.3479, G loss: 0.7324\n",
      "[644/1762] D loss: 0.1364, G loss: 2.1752\n",
      "[724/1762] D loss: 0.8108, G loss: 1.1156\n",
      "[804/1762] D loss: 1.2686, G loss: 0.7971\n",
      "[884/1762] D loss: 1.4129, G loss: 1.0326\n",
      "[964/1762] D loss: 1.3717, G loss: 1.4219\n",
      "[1044/1762] D loss: 0.3204, G loss: 1.4026\n",
      "[1124/1762] D loss: 0.5731, G loss: 2.2389\n",
      "[1204/1762] D loss: 1.3974, G loss: 1.1246\n",
      "[1284/1762] D loss: 1.6565, G loss: 1.3541\n",
      "[1364/1762] D loss: 0.7859, G loss: 0.7270\n",
      "[1444/1762] D loss: 1.4634, G loss: 1.0184\n",
      "[1524/1762] D loss: 1.4710, G loss: 0.5943\n",
      "[1604/1762] D loss: 1.6082, G loss: 1.0198\n",
      "[1684/1762] D loss: 1.5691, G loss: 1.0998\n",
      "[1762/1762] D loss: 1.4005, G loss: 0.4899\n",
      "train error: \n",
      " D loss: 1.355932, G loss: 0.803468, D accuracy: 56.5%, cell accuracy: 99.8%, board accuracy: 87.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.366705, G loss: 0.814209, D accuracy: 56.4%, cell accuracy: 99.8%, board accuracy: 84.1% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1694, G loss: 1.8492\n",
      "[84/1762] D loss: 0.4009, G loss: 1.2498\n",
      "[164/1762] D loss: 0.2786, G loss: 1.6469\n",
      "[244/1762] D loss: 1.1936, G loss: 0.7229\n",
      "[324/1762] D loss: 0.4626, G loss: 1.1193\n",
      "[404/1762] D loss: 1.5639, G loss: 0.5865\n",
      "[484/1762] D loss: 1.3772, G loss: 0.6946\n",
      "[564/1762] D loss: 1.1960, G loss: 0.9343\n",
      "[644/1762] D loss: 1.6428, G loss: 1.5209\n",
      "[724/1762] D loss: 1.3426, G loss: 0.7529\n",
      "[804/1762] D loss: 1.3622, G loss: 0.7212\n",
      "[884/1762] D loss: 0.2347, G loss: 1.8015\n",
      "[964/1762] D loss: 1.5626, G loss: 0.4661\n",
      "[1044/1762] D loss: 0.9993, G loss: 1.3657\n",
      "[1124/1762] D loss: 0.9451, G loss: 1.0284\n",
      "[1204/1762] D loss: 1.4209, G loss: 0.6435\n",
      "[1284/1762] D loss: 0.0170, G loss: 4.4228\n",
      "[1364/1762] D loss: 1.2344, G loss: 0.6229\n",
      "[1444/1762] D loss: 0.8012, G loss: 1.8817\n",
      "[1524/1762] D loss: 2.1023, G loss: 1.8221\n",
      "[1604/1762] D loss: 1.4351, G loss: 0.5239\n",
      "[1684/1762] D loss: 0.1795, G loss: 2.4907\n",
      "[1762/1762] D loss: 1.3626, G loss: 0.6321\n",
      "train error: \n",
      " D loss: 1.320815, G loss: 0.919861, D accuracy: 56.5%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.325017, G loss: 0.930147, D accuracy: 57.0%, cell accuracy: 99.8%, board accuracy: 84.8% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2147, G loss: 1.5674\n",
      "[84/1762] D loss: 1.3676, G loss: 0.5396\n",
      "[164/1762] D loss: 1.2656, G loss: 1.0776\n",
      "[244/1762] D loss: 0.3817, G loss: 1.2617\n",
      "[324/1762] D loss: 0.1469, G loss: 2.4905\n",
      "[404/1762] D loss: 1.5061, G loss: 1.1138\n",
      "[484/1762] D loss: 1.3979, G loss: 0.5169\n",
      "[564/1762] D loss: 0.2530, G loss: 1.5823\n",
      "[644/1762] D loss: 1.3897, G loss: 0.5906\n",
      "[724/1762] D loss: 1.2933, G loss: 0.6713\n",
      "[804/1762] D loss: 0.2103, G loss: 2.4627\n",
      "[884/1762] D loss: 1.4752, G loss: 1.5101\n",
      "[964/1762] D loss: 0.9777, G loss: 0.6418\n",
      "[1044/1762] D loss: 0.8172, G loss: 0.9576\n",
      "[1124/1762] D loss: 1.3502, G loss: 0.7850\n",
      "[1204/1762] D loss: 1.2855, G loss: 0.6337\n",
      "[1284/1762] D loss: 1.2701, G loss: 0.7671\n",
      "[1364/1762] D loss: 1.3253, G loss: 0.9971\n",
      "[1444/1762] D loss: 1.2879, G loss: 0.7759\n",
      "[1524/1762] D loss: 1.4374, G loss: 0.5085\n",
      "[1604/1762] D loss: 1.4397, G loss: 1.0395\n",
      "[1684/1762] D loss: 0.1633, G loss: 2.0520\n",
      "[1762/1762] D loss: 1.3369, G loss: 0.6122\n",
      "train error: \n",
      " D loss: 1.370684, G loss: 0.681934, D accuracy: 55.6%, cell accuracy: 99.8%, board accuracy: 86.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.393742, G loss: 0.678791, D accuracy: 55.6%, cell accuracy: 99.8%, board accuracy: 84.8% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3966, G loss: 0.5480\n",
      "[84/1762] D loss: 1.4387, G loss: 0.5834\n",
      "[164/1762] D loss: 1.3626, G loss: 0.6338\n",
      "[244/1762] D loss: 1.2607, G loss: 0.7675\n",
      "[324/1762] D loss: 1.4204, G loss: 0.8633\n",
      "[404/1762] D loss: 1.5055, G loss: 1.1223\n",
      "[484/1762] D loss: 1.4342, G loss: 0.7547\n",
      "[564/1762] D loss: 0.1563, G loss: 2.0781\n",
      "[644/1762] D loss: 1.3617, G loss: 0.9392\n",
      "[724/1762] D loss: 0.1002, G loss: 2.4533\n",
      "[804/1762] D loss: 1.4024, G loss: 0.7425\n",
      "[884/1762] D loss: 1.4723, G loss: 0.4335\n",
      "[964/1762] D loss: 0.5271, G loss: 1.6964\n",
      "[1044/1762] D loss: 1.4031, G loss: 0.7050\n",
      "[1124/1762] D loss: 1.6109, G loss: 0.3972\n",
      "[1204/1762] D loss: 1.4584, G loss: 1.0464\n",
      "[1284/1762] D loss: 1.4329, G loss: 0.6868\n",
      "[1364/1762] D loss: 1.4390, G loss: 0.9268\n",
      "[1444/1762] D loss: 1.6452, G loss: 1.0644\n",
      "[1524/1762] D loss: 1.5722, G loss: 0.4022\n",
      "[1604/1762] D loss: 0.2920, G loss: 1.7473\n",
      "[1684/1762] D loss: 0.1353, G loss: 2.1829\n",
      "[1762/1762] D loss: 1.3807, G loss: 0.5352\n",
      "train error: \n",
      " D loss: 1.407981, G loss: 0.686981, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 87.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.435798, G loss: 0.722047, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 83.2% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1915, G loss: 1.7983\n",
      "[84/1762] D loss: 1.3998, G loss: 1.0327\n",
      "[164/1762] D loss: 1.4009, G loss: 0.9303\n",
      "[244/1762] D loss: 1.4668, G loss: 0.5542\n",
      "[324/1762] D loss: 1.4618, G loss: 0.5289\n",
      "[404/1762] D loss: 0.0187, G loss: 4.7038\n",
      "[484/1762] D loss: 0.1457, G loss: 2.3018\n",
      "[564/1762] D loss: 0.3626, G loss: 1.5319\n",
      "[644/1762] D loss: 1.4009, G loss: 0.9650\n",
      "[724/1762] D loss: 0.8935, G loss: 3.0141\n",
      "[804/1762] D loss: 0.0248, G loss: 4.0269\n",
      "[884/1762] D loss: 0.2821, G loss: 1.6334\n",
      "[964/1762] D loss: 0.8710, G loss: 1.5307\n",
      "[1044/1762] D loss: 1.3318, G loss: 0.6414\n",
      "[1124/1762] D loss: 0.8054, G loss: 1.7237\n",
      "[1204/1762] D loss: 0.0775, G loss: 3.0576\n",
      "[1284/1762] D loss: 1.0045, G loss: 0.7054\n",
      "[1364/1762] D loss: 1.0475, G loss: 2.6527\n",
      "[1444/1762] D loss: 1.4079, G loss: 0.7566\n",
      "[1524/1762] D loss: 0.8854, G loss: 1.6119\n",
      "[1604/1762] D loss: 0.9475, G loss: 3.1689\n",
      "[1684/1762] D loss: 0.1287, G loss: 2.3465\n",
      "[1762/1762] D loss: 1.5743, G loss: 0.3753\n",
      "train error: \n",
      " D loss: 1.657490, G loss: 0.348200, D accuracy: 52.2%, cell accuracy: 99.8%, board accuracy: 86.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.661027, G loss: 0.363498, D accuracy: 51.9%, cell accuracy: 99.8%, board accuracy: 83.9% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5195, G loss: 1.0986\n",
      "[84/1762] D loss: 1.3827, G loss: 1.0636\n",
      "[164/1762] D loss: 0.0759, G loss: 3.0762\n",
      "[244/1762] D loss: 1.4805, G loss: 0.3788\n",
      "[324/1762] D loss: 0.0356, G loss: 3.6838\n",
      "[404/1762] D loss: 1.4066, G loss: 0.5243\n",
      "[484/1762] D loss: 1.0114, G loss: 2.7136\n",
      "[564/1762] D loss: 0.0778, G loss: 3.2192\n",
      "[644/1762] D loss: 1.4651, G loss: 0.5915\n",
      "[724/1762] D loss: 0.0219, G loss: 4.3163\n",
      "[804/1762] D loss: 1.7616, G loss: 0.3167\n",
      "[884/1762] D loss: 1.3742, G loss: 0.7883\n",
      "[964/1762] D loss: 0.7086, G loss: 1.0970\n",
      "[1044/1762] D loss: 0.2167, G loss: 1.8969\n",
      "[1124/1762] D loss: 1.6755, G loss: 0.4725\n",
      "[1204/1762] D loss: 1.4344, G loss: 0.5531\n",
      "[1284/1762] D loss: 1.3944, G loss: 0.5798\n",
      "[1364/1762] D loss: 1.0687, G loss: 0.8884\n",
      "[1444/1762] D loss: 0.1668, G loss: 2.0612\n",
      "[1524/1762] D loss: 1.4737, G loss: 0.5511\n",
      "[1604/1762] D loss: 1.4791, G loss: 0.8660\n",
      "[1684/1762] D loss: 1.3788, G loss: 1.0173\n",
      "[1762/1762] D loss: 1.5720, G loss: 0.4330\n",
      "train error: \n",
      " D loss: 1.523298, G loss: 0.453778, D accuracy: 56.0%, cell accuracy: 99.8%, board accuracy: 86.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.510629, G loss: 0.489362, D accuracy: 57.0%, cell accuracy: 99.8%, board accuracy: 83.0% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1137, G loss: 2.3314\n",
      "[84/1762] D loss: 1.4614, G loss: 0.5598\n",
      "[164/1762] D loss: 0.1224, G loss: 2.4177\n",
      "[244/1762] D loss: 0.0375, G loss: 3.3679\n",
      "[324/1762] D loss: 0.1621, G loss: 1.9383\n",
      "[404/1762] D loss: 1.3609, G loss: 0.7477\n",
      "[484/1762] D loss: 0.6780, G loss: 4.4181\n",
      "[564/1762] D loss: 1.8862, G loss: 0.3518\n",
      "[644/1762] D loss: 1.4771, G loss: 0.5025\n",
      "[724/1762] D loss: 1.5974, G loss: 1.0175\n",
      "[804/1762] D loss: 0.2081, G loss: 1.8639\n",
      "[884/1762] D loss: 1.2660, G loss: 0.6259\n",
      "[964/1762] D loss: 1.1707, G loss: 1.1257\n",
      "[1044/1762] D loss: 0.1507, G loss: 2.3615\n",
      "[1124/1762] D loss: 1.5940, G loss: 1.1930\n",
      "[1204/1762] D loss: 1.2804, G loss: 0.7174\n",
      "[1284/1762] D loss: 0.8128, G loss: 1.5454\n",
      "[1364/1762] D loss: 1.5042, G loss: 1.6850\n",
      "[1444/1762] D loss: 0.7689, G loss: 3.5211\n",
      "[1524/1762] D loss: 0.0231, G loss: 3.8482\n",
      "[1604/1762] D loss: 0.6608, G loss: 6.1715\n",
      "[1684/1762] D loss: 1.4509, G loss: 0.4688\n",
      "[1762/1762] D loss: 1.5684, G loss: 1.0952\n",
      "train error: \n",
      " D loss: 1.353156, G loss: 1.023511, D accuracy: 55.6%, cell accuracy: 99.8%, board accuracy: 86.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.363313, G loss: 1.042033, D accuracy: 56.0%, cell accuracy: 99.8%, board accuracy: 83.6% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0328, G loss: 3.8086\n",
      "[84/1762] D loss: 0.4081, G loss: 1.1994\n",
      "[164/1762] D loss: 1.3136, G loss: 0.8987\n",
      "[244/1762] D loss: 0.0644, G loss: 2.9651\n",
      "[324/1762] D loss: 1.3951, G loss: 0.8862\n",
      "[404/1762] D loss: 0.4571, G loss: 1.3780\n",
      "[484/1762] D loss: 1.4570, G loss: 0.6846\n",
      "[564/1762] D loss: 1.3812, G loss: 0.4978\n",
      "[644/1762] D loss: 1.3461, G loss: 0.7082\n",
      "[724/1762] D loss: 1.0327, G loss: 0.9257\n",
      "[804/1762] D loss: 2.2082, G loss: 0.2315\n",
      "[884/1762] D loss: 1.3865, G loss: 0.6651\n",
      "[964/1762] D loss: 0.2999, G loss: 1.4184\n",
      "[1044/1762] D loss: 1.4177, G loss: 0.9159\n",
      "[1124/1762] D loss: 1.3229, G loss: 0.8571\n",
      "[1204/1762] D loss: 1.1668, G loss: 0.6872\n",
      "[1284/1762] D loss: 1.6316, G loss: 2.4734\n",
      "[1364/1762] D loss: 0.0359, G loss: 4.1897\n",
      "[1444/1762] D loss: 0.1408, G loss: 2.2206\n",
      "[1524/1762] D loss: 1.8010, G loss: 0.2690\n",
      "[1604/1762] D loss: 0.6865, G loss: 1.3011\n",
      "[1684/1762] D loss: 1.7909, G loss: 0.3532\n",
      "[1762/1762] D loss: 1.3251, G loss: 0.7247\n",
      "train error: \n",
      " D loss: 1.353037, G loss: 1.114309, D accuracy: 56.3%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.363923, G loss: 1.106444, D accuracy: 56.0%, cell accuracy: 99.8%, board accuracy: 84.3% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3638, G loss: 0.8402\n",
      "[84/1762] D loss: 0.4600, G loss: 1.8885\n",
      "[164/1762] D loss: 1.8298, G loss: 0.2865\n",
      "[244/1762] D loss: 1.4902, G loss: 0.5458\n",
      "[324/1762] D loss: 1.5690, G loss: 0.5100\n",
      "[404/1762] D loss: 1.4060, G loss: 0.9633\n",
      "[484/1762] D loss: 1.2667, G loss: 0.8507\n",
      "[564/1762] D loss: 1.4232, G loss: 0.5042\n",
      "[644/1762] D loss: 0.2191, G loss: 1.9416\n",
      "[724/1762] D loss: 1.3767, G loss: 0.5809\n",
      "[804/1762] D loss: 1.4620, G loss: 0.5308\n",
      "[884/1762] D loss: 0.2312, G loss: 1.6456\n",
      "[964/1762] D loss: 1.5049, G loss: 0.4555\n",
      "[1044/1762] D loss: 0.4923, G loss: 2.5020\n",
      "[1124/1762] D loss: 1.3408, G loss: 1.6786\n",
      "[1204/1762] D loss: 0.8401, G loss: 1.0345\n",
      "[1284/1762] D loss: 0.0387, G loss: 3.6182\n",
      "[1364/1762] D loss: 1.3560, G loss: 0.5840\n",
      "[1444/1762] D loss: 1.3653, G loss: 0.6078\n",
      "[1524/1762] D loss: 0.0240, G loss: 4.0195\n",
      "[1604/1762] D loss: 1.4953, G loss: 1.1337\n",
      "[1684/1762] D loss: 1.8277, G loss: 5.0739\n",
      "[1762/1762] D loss: 1.5065, G loss: 0.3829\n",
      "train error: \n",
      " D loss: 1.678289, G loss: 0.339644, D accuracy: 52.4%, cell accuracy: 99.8%, board accuracy: 87.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.662981, G loss: 0.370758, D accuracy: 53.0%, cell accuracy: 99.8%, board accuracy: 84.1% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4471, G loss: 1.7313\n",
      "[84/1762] D loss: 0.2721, G loss: 2.0308\n",
      "[164/1762] D loss: 0.4593, G loss: 2.3640\n",
      "[244/1762] D loss: 1.4006, G loss: 0.5566\n",
      "[324/1762] D loss: 0.0041, G loss: 5.9861\n",
      "[404/1762] D loss: 2.5341, G loss: 0.1327\n",
      "[484/1762] D loss: 0.6622, G loss: 2.6684\n",
      "[564/1762] D loss: 1.4067, G loss: 0.8177\n",
      "[644/1762] D loss: 1.2528, G loss: 1.1574\n",
      "[724/1762] D loss: 0.8117, G loss: 5.3575\n",
      "[804/1762] D loss: 1.5333, G loss: 1.2514\n",
      "[884/1762] D loss: 0.2966, G loss: 1.5282\n",
      "[964/1762] D loss: 1.3518, G loss: 0.8148\n",
      "[1044/1762] D loss: 0.0288, G loss: 4.3760\n",
      "[1124/1762] D loss: 1.3449, G loss: 0.6694\n",
      "[1204/1762] D loss: 1.1940, G loss: 0.8926\n",
      "[1284/1762] D loss: 1.3921, G loss: 0.7277\n",
      "[1364/1762] D loss: 1.6760, G loss: 0.2541\n",
      "[1444/1762] D loss: 0.3920, G loss: 3.6573\n",
      "[1524/1762] D loss: 0.0075, G loss: 5.5127\n",
      "[1604/1762] D loss: 0.0210, G loss: 4.3773\n",
      "[1684/1762] D loss: 0.1707, G loss: 2.4868\n",
      "[1762/1762] D loss: 1.1563, G loss: 0.8847\n",
      "train error: \n",
      " D loss: 1.587039, G loss: 0.472855, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.613460, G loss: 0.486823, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 84.5% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5190, G loss: 0.9636\n",
      "[84/1762] D loss: 1.4907, G loss: 1.1748\n",
      "[164/1762] D loss: 0.2664, G loss: 1.4430\n",
      "[244/1762] D loss: 1.3529, G loss: 1.1072\n",
      "[324/1762] D loss: 0.6467, G loss: 1.7207\n",
      "[404/1762] D loss: 0.9249, G loss: 0.7788\n",
      "[484/1762] D loss: 1.3903, G loss: 0.5686\n",
      "[564/1762] D loss: 0.0135, G loss: 4.5101\n",
      "[644/1762] D loss: 1.3952, G loss: 0.5270\n",
      "[724/1762] D loss: 1.8450, G loss: 1.4164\n",
      "[804/1762] D loss: 1.5724, G loss: 0.4666\n",
      "[884/1762] D loss: 0.1607, G loss: 1.8147\n",
      "[964/1762] D loss: 1.2889, G loss: 0.9239\n",
      "[1044/1762] D loss: 0.9356, G loss: 1.4763\n",
      "[1124/1762] D loss: 0.1063, G loss: 2.4697\n",
      "[1204/1762] D loss: 0.5515, G loss: 1.0780\n",
      "[1284/1762] D loss: 1.0550, G loss: 0.8573\n",
      "[1364/1762] D loss: 1.0421, G loss: 0.8326\n",
      "[1444/1762] D loss: 0.0053, G loss: 5.8312\n",
      "[1524/1762] D loss: 1.3743, G loss: 0.6632\n",
      "[1604/1762] D loss: 0.1306, G loss: 2.3527\n",
      "[1684/1762] D loss: 0.8813, G loss: 2.2525\n",
      "[1762/1762] D loss: 1.0487, G loss: 1.3490\n",
      "train error: \n",
      " D loss: 1.382528, G loss: 0.674930, D accuracy: 55.8%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.383043, G loss: 0.739581, D accuracy: 56.2%, cell accuracy: 99.8%, board accuracy: 83.0% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3307, G loss: 0.7884\n",
      "[84/1762] D loss: 0.6257, G loss: 3.7896\n",
      "[164/1762] D loss: 0.1038, G loss: 2.5124\n",
      "[244/1762] D loss: 1.5071, G loss: 0.4191\n",
      "[324/1762] D loss: 1.3028, G loss: 0.8417\n",
      "[404/1762] D loss: 0.1457, G loss: 2.2292\n",
      "[484/1762] D loss: 0.1701, G loss: 2.1795\n",
      "[564/1762] D loss: 1.4234, G loss: 0.4211\n",
      "[644/1762] D loss: 1.2832, G loss: 0.6176\n",
      "[724/1762] D loss: 0.7752, G loss: 1.1872\n",
      "[804/1762] D loss: 0.0228, G loss: 5.0239\n",
      "[884/1762] D loss: 0.1263, G loss: 2.1456\n",
      "[964/1762] D loss: 1.6734, G loss: 1.7108\n",
      "[1044/1762] D loss: 1.5855, G loss: 1.1505\n",
      "[1124/1762] D loss: 0.7021, G loss: 1.9968\n",
      "[1204/1762] D loss: 1.7274, G loss: 1.4500\n",
      "[1284/1762] D loss: 0.7648, G loss: 2.5467\n",
      "[1364/1762] D loss: 0.0329, G loss: 4.3410\n",
      "[1444/1762] D loss: 1.2241, G loss: 0.9109\n",
      "[1524/1762] D loss: 1.2508, G loss: 0.9655\n",
      "[1604/1762] D loss: 1.2435, G loss: 0.8021\n",
      "[1684/1762] D loss: 1.4890, G loss: 1.1450\n",
      "[1762/1762] D loss: 1.3501, G loss: 0.9656\n",
      "train error: \n",
      " D loss: 1.318216, G loss: 0.722341, D accuracy: 58.8%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.311796, G loss: 0.769566, D accuracy: 59.4%, cell accuracy: 99.8%, board accuracy: 84.1% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2303, G loss: 2.5436\n",
      "[84/1762] D loss: 1.7023, G loss: 1.1467\n",
      "[164/1762] D loss: 1.6475, G loss: 1.3611\n",
      "[244/1762] D loss: 0.1307, G loss: 2.4470\n",
      "[324/1762] D loss: 1.5009, G loss: 1.4426\n",
      "[404/1762] D loss: 0.2186, G loss: 1.9346\n",
      "[484/1762] D loss: 1.3606, G loss: 0.8278\n",
      "[564/1762] D loss: 0.1523, G loss: 2.8071\n",
      "[644/1762] D loss: 0.2015, G loss: 1.9381\n",
      "[724/1762] D loss: 0.9413, G loss: 1.2731\n",
      "[804/1762] D loss: 1.6489, G loss: 0.3567\n",
      "[884/1762] D loss: 1.3115, G loss: 0.8996\n",
      "[964/1762] D loss: 0.1354, G loss: 2.6223\n",
      "[1044/1762] D loss: 0.0832, G loss: 3.0346\n",
      "[1124/1762] D loss: 1.4138, G loss: 0.9211\n",
      "[1204/1762] D loss: 1.4282, G loss: 0.4100\n",
      "[1284/1762] D loss: 1.1400, G loss: 0.7891\n",
      "[1364/1762] D loss: 0.6231, G loss: 1.5203\n",
      "[1444/1762] D loss: 0.0136, G loss: 5.4367\n",
      "[1524/1762] D loss: 0.5922, G loss: 2.0637\n",
      "[1604/1762] D loss: 0.3857, G loss: 1.4327\n",
      "[1684/1762] D loss: 0.1885, G loss: 1.7929\n",
      "[1762/1762] D loss: 1.6342, G loss: 5.3983\n",
      "train error: \n",
      " D loss: 1.403077, G loss: 1.055768, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.412277, G loss: 1.095801, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 84.5% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4986, G loss: 4.0378\n",
      "[84/1762] D loss: 2.0145, G loss: 0.2346\n",
      "[164/1762] D loss: 0.2745, G loss: 2.3080\n",
      "[244/1762] D loss: 1.2868, G loss: 1.0960\n",
      "[324/1762] D loss: 0.0776, G loss: 2.8352\n",
      "[404/1762] D loss: 1.3996, G loss: 0.4671\n",
      "[484/1762] D loss: 1.4040, G loss: 0.6019\n",
      "[564/1762] D loss: 1.4381, G loss: 0.9733\n",
      "[644/1762] D loss: 0.1055, G loss: 2.4880\n",
      "[724/1762] D loss: 0.7113, G loss: 1.8758\n",
      "[804/1762] D loss: 1.4959, G loss: 0.5005\n",
      "[884/1762] D loss: 1.4470, G loss: 1.0521\n",
      "[964/1762] D loss: 0.4629, G loss: 2.3806\n",
      "[1044/1762] D loss: 1.1426, G loss: 0.9626\n",
      "[1124/1762] D loss: 1.1763, G loss: 0.8606\n",
      "[1204/1762] D loss: 0.0062, G loss: 5.9284\n",
      "[1284/1762] D loss: 1.3440, G loss: 0.8690\n",
      "[1364/1762] D loss: 1.3203, G loss: 0.7037\n",
      "[1444/1762] D loss: 1.3325, G loss: 0.6922\n",
      "[1524/1762] D loss: 1.1144, G loss: 3.1423\n",
      "[1604/1762] D loss: 1.1680, G loss: 1.1491\n",
      "[1684/1762] D loss: 0.0368, G loss: 3.3205\n",
      "[1762/1762] D loss: 0.3050, G loss: 5.4616\n",
      "train error: \n",
      " D loss: 1.372992, G loss: 0.909419, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 86.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.389207, G loss: 0.948408, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 83.9% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0280, G loss: 3.7094\n",
      "[84/1762] D loss: 1.4415, G loss: 1.0304\n",
      "[164/1762] D loss: 0.0048, G loss: 5.6790\n",
      "[244/1762] D loss: 0.3056, G loss: 1.8052\n",
      "[324/1762] D loss: 1.4038, G loss: 0.9008\n",
      "[404/1762] D loss: 1.5538, G loss: 0.2686\n",
      "[484/1762] D loss: 0.1742, G loss: 4.0470\n",
      "[564/1762] D loss: 0.8194, G loss: 1.5029\n",
      "[644/1762] D loss: 0.0365, G loss: 3.5241\n",
      "[724/1762] D loss: 1.7202, G loss: 1.0034\n",
      "[804/1762] D loss: 1.2326, G loss: 0.5687\n",
      "[884/1762] D loss: 1.2908, G loss: 0.6030\n",
      "[964/1762] D loss: 0.6987, G loss: 1.6870\n",
      "[1044/1762] D loss: 0.2905, G loss: 3.9915\n",
      "[1124/1762] D loss: 1.3239, G loss: 0.8940\n",
      "[1204/1762] D loss: 0.6580, G loss: 1.6033\n",
      "[1284/1762] D loss: 0.0102, G loss: 5.6143\n",
      "[1364/1762] D loss: 0.1440, G loss: 2.0443\n",
      "[1444/1762] D loss: 1.3979, G loss: 0.6289\n",
      "[1524/1762] D loss: 0.0161, G loss: 4.2415\n",
      "[1604/1762] D loss: 1.1329, G loss: 0.7216\n",
      "[1684/1762] D loss: 1.5398, G loss: 0.4661\n",
      "[1762/1762] D loss: 0.5569, G loss: 6.4398\n",
      "train error: \n",
      " D loss: 1.942448, G loss: 2.117640, D accuracy: 51.0%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.949549, G loss: 2.122044, D accuracy: 50.9%, cell accuracy: 99.8%, board accuracy: 84.3% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4452, G loss: 1.2455\n",
      "[84/1762] D loss: 1.0349, G loss: 1.2132\n",
      "[164/1762] D loss: 1.0607, G loss: 1.1830\n",
      "[244/1762] D loss: 1.0505, G loss: 5.2946\n",
      "[324/1762] D loss: 0.6743, G loss: 2.6344\n",
      "[404/1762] D loss: 0.1610, G loss: 2.2242\n",
      "[484/1762] D loss: 0.4000, G loss: 1.5607\n",
      "[564/1762] D loss: 1.4120, G loss: 0.6170\n",
      "[644/1762] D loss: 1.3086, G loss: 0.8230\n",
      "[724/1762] D loss: 0.6385, G loss: 1.0845\n",
      "[804/1762] D loss: 1.5124, G loss: 0.6095\n",
      "[884/1762] D loss: 0.1243, G loss: 2.1023\n",
      "[964/1762] D loss: 1.0203, G loss: 0.8130\n",
      "[1044/1762] D loss: 1.3888, G loss: 0.5389\n",
      "[1124/1762] D loss: 1.5375, G loss: 0.9421\n",
      "[1204/1762] D loss: 1.3797, G loss: 0.9924\n",
      "[1284/1762] D loss: 1.5028, G loss: 1.3091\n",
      "[1364/1762] D loss: 0.1867, G loss: 1.9232\n",
      "[1444/1762] D loss: 0.1146, G loss: 2.4280\n",
      "[1524/1762] D loss: 0.1228, G loss: 3.3977\n",
      "[1604/1762] D loss: 0.2707, G loss: 1.4413\n",
      "[1684/1762] D loss: 0.8587, G loss: 1.2699\n",
      "[1762/1762] D loss: 0.4699, G loss: 3.8784\n",
      "train error: \n",
      " D loss: 1.361856, G loss: 0.721339, D accuracy: 57.8%, cell accuracy: 99.8%, board accuracy: 86.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.340992, G loss: 0.741063, D accuracy: 59.7%, cell accuracy: 99.8%, board accuracy: 83.6% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0030, G loss: 6.4030\n",
      "[84/1762] D loss: 1.2787, G loss: 1.0451\n",
      "[164/1762] D loss: 1.2140, G loss: 1.4476\n",
      "[244/1762] D loss: 1.0503, G loss: 0.9010\n",
      "[324/1762] D loss: 1.3509, G loss: 0.9766\n",
      "[404/1762] D loss: 1.4137, G loss: 1.3384\n",
      "[484/1762] D loss: 0.1091, G loss: 3.1118\n",
      "[564/1762] D loss: 1.2542, G loss: 0.7647\n",
      "[644/1762] D loss: 1.4213, G loss: 0.7450\n",
      "[724/1762] D loss: 0.0270, G loss: 3.3896\n",
      "[804/1762] D loss: 1.3255, G loss: 0.7819\n",
      "[884/1762] D loss: 1.5482, G loss: 1.1930\n",
      "[964/1762] D loss: 0.9221, G loss: 1.5002\n",
      "[1044/1762] D loss: 1.3316, G loss: 0.9028\n",
      "[1124/1762] D loss: 0.4976, G loss: 2.4336\n",
      "[1204/1762] D loss: 1.4944, G loss: 0.5128\n",
      "[1284/1762] D loss: 0.1175, G loss: 2.4585\n",
      "[1364/1762] D loss: 1.1470, G loss: 0.9535\n",
      "[1444/1762] D loss: 1.3261, G loss: 0.7810\n",
      "[1524/1762] D loss: 0.1072, G loss: 2.3778\n",
      "[1604/1762] D loss: 0.6657, G loss: 2.5677\n",
      "[1684/1762] D loss: 0.4393, G loss: 2.7242\n",
      "[1762/1762] D loss: 1.4983, G loss: 0.8724\n",
      "train error: \n",
      " D loss: 1.717120, G loss: 0.477068, D accuracy: 51.1%, cell accuracy: 99.8%, board accuracy: 86.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.727540, G loss: 0.492249, D accuracy: 50.7%, cell accuracy: 99.8%, board accuracy: 84.5% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4928, G loss: 2.5202\n",
      "[84/1762] D loss: 1.6040, G loss: 1.8027\n",
      "[164/1762] D loss: 1.4218, G loss: 0.5245\n",
      "[244/1762] D loss: 1.4055, G loss: 0.4823\n",
      "[324/1762] D loss: 1.2942, G loss: 0.9438\n",
      "[404/1762] D loss: 1.2576, G loss: 2.0386\n",
      "[484/1762] D loss: 1.3101, G loss: 0.7311\n",
      "[564/1762] D loss: 0.9508, G loss: 6.8018\n",
      "[644/1762] D loss: 1.3657, G loss: 0.7000\n",
      "[724/1762] D loss: 1.4925, G loss: 0.9995\n",
      "[804/1762] D loss: 1.4191, G loss: 0.8150\n",
      "[884/1762] D loss: 1.4660, G loss: 0.9518\n",
      "[964/1762] D loss: 0.1157, G loss: 3.1627\n",
      "[1044/1762] D loss: 1.2386, G loss: 0.9625\n",
      "[1124/1762] D loss: 1.0944, G loss: 1.5414\n",
      "[1204/1762] D loss: 1.4865, G loss: 0.4877\n",
      "[1284/1762] D loss: 0.6531, G loss: 5.9306\n",
      "[1364/1762] D loss: 1.3684, G loss: 0.5428\n",
      "[1444/1762] D loss: 1.3385, G loss: 0.8814\n",
      "[1524/1762] D loss: 1.3798, G loss: 1.1439\n",
      "[1604/1762] D loss: 0.7374, G loss: 1.2409\n",
      "[1684/1762] D loss: 1.2476, G loss: 1.2577\n",
      "[1762/1762] D loss: 1.7218, G loss: 1.3376\n",
      "train error: \n",
      " D loss: 1.424754, G loss: 1.366378, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 85.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.429318, G loss: 1.359150, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 83.6% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0246, G loss: 3.9340\n",
      "[84/1762] D loss: 0.0109, G loss: 4.9488\n",
      "[164/1762] D loss: 0.0911, G loss: 2.5652\n",
      "[244/1762] D loss: 0.2181, G loss: 1.7101\n",
      "[324/1762] D loss: 0.2497, G loss: 1.8264\n",
      "[404/1762] D loss: 1.5751, G loss: 2.5963\n",
      "[484/1762] D loss: 1.3229, G loss: 0.6172\n",
      "[564/1762] D loss: 0.5499, G loss: 6.9561\n",
      "[644/1762] D loss: 0.3048, G loss: 2.4636\n",
      "[724/1762] D loss: 0.3405, G loss: 1.2970\n",
      "[804/1762] D loss: 1.4236, G loss: 0.5727\n",
      "[884/1762] D loss: 1.3989, G loss: 0.8940\n",
      "[964/1762] D loss: 1.0702, G loss: 0.8049\n",
      "[1044/1762] D loss: 0.0327, G loss: 3.6393\n",
      "[1124/1762] D loss: 0.0485, G loss: 3.7385\n",
      "[1204/1762] D loss: 0.0038, G loss: 7.8333\n",
      "[1284/1762] D loss: 0.2442, G loss: 4.0748\n",
      "[1364/1762] D loss: 1.3976, G loss: 0.6768\n",
      "[1444/1762] D loss: 0.2222, G loss: 1.7747\n",
      "[1524/1762] D loss: 0.0035, G loss: 6.9161\n",
      "[1604/1762] D loss: 1.7395, G loss: 0.2888\n",
      "[1684/1762] D loss: 1.3251, G loss: 0.8908\n",
      "[1762/1762] D loss: 1.2041, G loss: 0.6546\n",
      "train error: \n",
      " D loss: 2.359369, G loss: 0.265721, D accuracy: 51.6%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "test error: \n",
      " D loss: 2.364878, G loss: 0.252145, D accuracy: 51.0%, cell accuracy: 99.8%, board accuracy: 85.0% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9455, G loss: 0.8350\n",
      "[84/1762] D loss: 1.2079, G loss: 0.7994\n",
      "[164/1762] D loss: 1.2794, G loss: 0.9606\n",
      "[244/1762] D loss: 1.2204, G loss: 1.0425\n",
      "[324/1762] D loss: 0.7072, G loss: 1.2304\n",
      "[404/1762] D loss: 0.0105, G loss: 5.0915\n",
      "[484/1762] D loss: 0.7438, G loss: 1.7195\n",
      "[564/1762] D loss: 1.4057, G loss: 0.6744\n",
      "[644/1762] D loss: 0.0253, G loss: 4.2690\n",
      "[724/1762] D loss: 1.3465, G loss: 0.5045\n",
      "[804/1762] D loss: 0.1682, G loss: 3.0734\n",
      "[884/1762] D loss: 0.3897, G loss: 1.9076\n",
      "[964/1762] D loss: 0.8819, G loss: 4.1167\n",
      "[1044/1762] D loss: 1.5839, G loss: 1.5051\n",
      "[1124/1762] D loss: 1.2939, G loss: 0.8508\n",
      "[1204/1762] D loss: 0.0490, G loss: 2.9135\n",
      "[1284/1762] D loss: 0.1763, G loss: 3.9356\n",
      "[1364/1762] D loss: 0.0068, G loss: 6.2479\n",
      "[1444/1762] D loss: 0.0052, G loss: 6.0029\n",
      "[1524/1762] D loss: 0.5256, G loss: 2.9214\n",
      "[1604/1762] D loss: 0.9316, G loss: 1.1905\n",
      "[1684/1762] D loss: 1.1783, G loss: 0.6173\n",
      "[1762/1762] D loss: 1.5509, G loss: 0.4095\n",
      "train error: \n",
      " D loss: 1.921619, G loss: 0.393024, D accuracy: 53.1%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.930453, G loss: 0.443740, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 84.1% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.6289, G loss: 0.4488\n",
      "[84/1762] D loss: 0.0771, G loss: 2.5970\n",
      "[164/1762] D loss: 0.2160, G loss: 1.9963\n",
      "[244/1762] D loss: 0.0054, G loss: 7.0888\n",
      "[324/1762] D loss: 0.7588, G loss: 2.9041\n",
      "[404/1762] D loss: 0.0657, G loss: 3.2600\n",
      "[484/1762] D loss: 0.9809, G loss: 1.5091\n",
      "[564/1762] D loss: 1.7888, G loss: 0.4387\n",
      "[644/1762] D loss: 0.0037, G loss: 7.1203\n",
      "[724/1762] D loss: 1.3062, G loss: 0.7803\n",
      "[804/1762] D loss: 0.0056, G loss: 6.2968\n",
      "[884/1762] D loss: 0.4820, G loss: 4.4158\n",
      "[964/1762] D loss: 1.4535, G loss: 0.5505\n",
      "[1044/1762] D loss: 0.2715, G loss: 1.6043\n",
      "[1124/1762] D loss: 2.0276, G loss: 0.3726\n",
      "[1204/1762] D loss: 0.1926, G loss: 6.8228\n",
      "[1284/1762] D loss: 0.0042, G loss: 7.0747\n",
      "[1364/1762] D loss: 1.3490, G loss: 0.5229\n",
      "[1444/1762] D loss: 0.0056, G loss: 6.2098\n",
      "[1524/1762] D loss: 1.4726, G loss: 0.3376\n",
      "[1604/1762] D loss: 1.3827, G loss: 0.7664\n",
      "[1684/1762] D loss: 1.2335, G loss: 1.1268\n",
      "[1762/1762] D loss: 1.3762, G loss: 1.1573\n",
      "train error: \n",
      " D loss: 1.462645, G loss: 0.658774, D accuracy: 56.5%, cell accuracy: 99.8%, board accuracy: 86.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.481273, G loss: 0.656194, D accuracy: 56.7%, cell accuracy: 99.8%, board accuracy: 84.8% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0891, G loss: 1.1581\n",
      "[84/1762] D loss: 1.4457, G loss: 0.7912\n",
      "[164/1762] D loss: 0.0118, G loss: 5.2847\n",
      "[244/1762] D loss: 0.0055, G loss: 5.4726\n",
      "[324/1762] D loss: 0.0199, G loss: 4.1484\n",
      "[404/1762] D loss: 0.8192, G loss: 2.9661\n",
      "[484/1762] D loss: 1.5707, G loss: 0.8954\n",
      "[564/1762] D loss: 0.2195, G loss: 1.7377\n",
      "[644/1762] D loss: 0.0363, G loss: 4.0160\n",
      "[724/1762] D loss: 0.0033, G loss: 5.9403\n",
      "[804/1762] D loss: 0.8262, G loss: 1.2194\n",
      "[884/1762] D loss: 1.2011, G loss: 1.4101\n",
      "[964/1762] D loss: 0.4495, G loss: 1.3602\n",
      "[1044/1762] D loss: 1.3382, G loss: 0.7390\n",
      "[1124/1762] D loss: 1.2840, G loss: 0.6083\n",
      "[1204/1762] D loss: 1.3210, G loss: 0.8853\n",
      "[1284/1762] D loss: 0.0060, G loss: 5.8390\n",
      "[1364/1762] D loss: 1.6416, G loss: 1.4385\n",
      "[1444/1762] D loss: 0.6856, G loss: 1.7855\n",
      "[1524/1762] D loss: 0.6005, G loss: 5.2629\n",
      "[1604/1762] D loss: 0.0142, G loss: 6.7120\n",
      "[1684/1762] D loss: 0.2092, G loss: 2.2395\n",
      "[1762/1762] D loss: 0.0062, G loss: 5.1604\n",
      "train error: \n",
      " D loss: 1.890975, G loss: 0.425802, D accuracy: 52.9%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.898994, G loss: 0.457788, D accuracy: 52.3%, cell accuracy: 99.8%, board accuracy: 83.4% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0685, G loss: 2.8095\n",
      "[84/1762] D loss: 2.3666, G loss: 0.1584\n",
      "[164/1762] D loss: 0.2482, G loss: 6.6626\n",
      "[244/1762] D loss: 1.4901, G loss: 0.4441\n",
      "[324/1762] D loss: 0.9267, G loss: 1.4752\n",
      "[404/1762] D loss: 1.8124, G loss: 0.4875\n",
      "[484/1762] D loss: 0.0034, G loss: 6.8345\n",
      "[564/1762] D loss: 0.3067, G loss: 3.8683\n",
      "[644/1762] D loss: 0.7147, G loss: 1.3162\n",
      "[724/1762] D loss: 1.3039, G loss: 0.5694\n",
      "[804/1762] D loss: 0.2126, G loss: 3.0075\n",
      "[884/1762] D loss: 1.4735, G loss: 0.7447\n",
      "[964/1762] D loss: 1.0744, G loss: 1.7206\n",
      "[1044/1762] D loss: 1.2703, G loss: 0.5994\n",
      "[1124/1762] D loss: 1.2119, G loss: 1.2095\n",
      "[1204/1762] D loss: 1.2891, G loss: 0.9540\n",
      "[1284/1762] D loss: 0.0302, G loss: 3.9574\n",
      "[1364/1762] D loss: 0.1156, G loss: 2.5641\n",
      "[1444/1762] D loss: 0.5828, G loss: 1.7406\n",
      "[1524/1762] D loss: 1.1705, G loss: 0.8077\n",
      "[1604/1762] D loss: 1.1293, G loss: 1.1956\n",
      "[1684/1762] D loss: 2.6335, G loss: 2.6185\n",
      "[1762/1762] D loss: 0.0049, G loss: 5.5138\n",
      "train error: \n",
      " D loss: 1.441624, G loss: 0.732825, D accuracy: 57.0%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.429454, G loss: 0.695144, D accuracy: 58.3%, cell accuracy: 99.8%, board accuracy: 84.3% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.6873, G loss: 1.2151\n",
      "[84/1762] D loss: 0.5465, G loss: 1.7885\n",
      "[164/1762] D loss: 0.2431, G loss: 3.8567\n",
      "[244/1762] D loss: 0.1220, G loss: 2.2967\n",
      "[324/1762] D loss: 1.1763, G loss: 2.2367\n",
      "[404/1762] D loss: 1.3853, G loss: 0.7949\n",
      "[484/1762] D loss: 0.9772, G loss: 1.3323\n",
      "[564/1762] D loss: 0.4415, G loss: 1.1819\n",
      "[644/1762] D loss: 0.6654, G loss: 5.8216\n",
      "[724/1762] D loss: 1.4373, G loss: 0.4111\n",
      "[804/1762] D loss: 1.6718, G loss: 0.4159\n",
      "[884/1762] D loss: 0.0584, G loss: 6.6717\n",
      "[964/1762] D loss: 1.0950, G loss: 0.9226\n",
      "[1044/1762] D loss: 1.3309, G loss: 1.2460\n",
      "[1124/1762] D loss: 0.1337, G loss: 2.7931\n",
      "[1204/1762] D loss: 1.0410, G loss: 5.4826\n",
      "[1284/1762] D loss: 1.4088, G loss: 0.5147\n",
      "[1364/1762] D loss: 0.9630, G loss: 1.3013\n",
      "[1444/1762] D loss: 0.2594, G loss: 3.5819\n",
      "[1524/1762] D loss: 0.0259, G loss: 4.5610\n",
      "[1604/1762] D loss: 1.3701, G loss: 1.3328\n",
      "[1684/1762] D loss: 0.0019, G loss: 7.7918\n",
      "[1762/1762] D loss: 0.0443, G loss: 4.5026\n",
      "train error: \n",
      " D loss: 1.393898, G loss: 1.139390, D accuracy: 57.3%, cell accuracy: 99.8%, board accuracy: 87.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.408118, G loss: 1.147681, D accuracy: 56.5%, cell accuracy: 99.8%, board accuracy: 85.5% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.9492, G loss: 0.3061\n",
      "[84/1762] D loss: 1.4509, G loss: 1.0575\n",
      "[164/1762] D loss: 0.0848, G loss: 2.8599\n",
      "[244/1762] D loss: 1.7445, G loss: 0.3563\n",
      "[324/1762] D loss: 0.9321, G loss: 0.9907\n",
      "[404/1762] D loss: 1.3468, G loss: 0.9198\n",
      "[484/1762] D loss: 0.0591, G loss: 3.0278\n",
      "[564/1762] D loss: 0.4502, G loss: 3.1591\n",
      "[644/1762] D loss: 1.4550, G loss: 0.8350\n",
      "[724/1762] D loss: 0.8348, G loss: 1.1776\n",
      "[804/1762] D loss: 0.4253, G loss: 1.6045\n",
      "[884/1762] D loss: 0.0031, G loss: 7.2856\n",
      "[964/1762] D loss: 2.2336, G loss: 1.7144\n",
      "[1044/1762] D loss: 0.3956, G loss: 1.9236\n",
      "[1124/1762] D loss: 1.3265, G loss: 0.5226\n",
      "[1204/1762] D loss: 0.6847, G loss: 3.4764\n",
      "[1284/1762] D loss: 1.5970, G loss: 0.4372\n",
      "[1364/1762] D loss: 1.0323, G loss: 0.9650\n",
      "[1444/1762] D loss: 0.1968, G loss: 5.0952\n",
      "[1524/1762] D loss: 0.1834, G loss: 1.3120\n",
      "[1604/1762] D loss: 0.0885, G loss: 2.7720\n",
      "[1684/1762] D loss: 1.3072, G loss: 0.8494\n",
      "[1762/1762] D loss: 1.3016, G loss: 1.1070\n",
      "train error: \n",
      " D loss: 1.311246, G loss: 0.978824, D accuracy: 60.1%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.324033, G loss: 1.018832, D accuracy: 59.7%, cell accuracy: 99.8%, board accuracy: 85.0% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5823, G loss: 1.2302\n",
      "[84/1762] D loss: 0.4025, G loss: 1.1089\n",
      "[164/1762] D loss: 0.2760, G loss: 4.4406\n",
      "[244/1762] D loss: 1.5495, G loss: 0.6489\n",
      "[324/1762] D loss: 0.0032, G loss: 6.7582\n",
      "[404/1762] D loss: 0.7634, G loss: 1.3538\n",
      "[484/1762] D loss: 1.0269, G loss: 1.6193\n",
      "[564/1762] D loss: 0.6264, G loss: 2.5321\n",
      "[644/1762] D loss: 0.6714, G loss: 4.0238\n",
      "[724/1762] D loss: 0.0313, G loss: 6.6806\n",
      "[804/1762] D loss: 1.3570, G loss: 0.6520\n",
      "[884/1762] D loss: 0.1068, G loss: 2.9104\n",
      "[964/1762] D loss: 1.3328, G loss: 0.5568\n",
      "[1044/1762] D loss: 0.8265, G loss: 1.8248\n",
      "[1124/1762] D loss: 0.9177, G loss: 0.7161\n",
      "[1204/1762] D loss: 0.0030, G loss: 7.0554\n",
      "[1284/1762] D loss: 1.4824, G loss: 1.3385\n",
      "[1364/1762] D loss: 0.0016, G loss: 7.5322\n",
      "[1444/1762] D loss: 1.2888, G loss: 0.8322\n",
      "[1524/1762] D loss: 1.2659, G loss: 0.7167\n",
      "[1604/1762] D loss: 0.7065, G loss: 2.1489\n",
      "[1684/1762] D loss: 1.4744, G loss: 1.0494\n",
      "[1762/1762] D loss: 0.6089, G loss: 2.0854\n",
      "train error: \n",
      " D loss: 1.451718, G loss: 1.368843, D accuracy: 59.8%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.487568, G loss: 1.429319, D accuracy: 57.8%, cell accuracy: 99.8%, board accuracy: 83.4% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3767, G loss: 0.4502\n",
      "[84/1762] D loss: 1.7633, G loss: 0.3280\n",
      "[164/1762] D loss: 0.0578, G loss: 2.7669\n",
      "[244/1762] D loss: 0.7549, G loss: 2.7268\n",
      "[324/1762] D loss: 1.2711, G loss: 0.6348\n",
      "[404/1762] D loss: 0.7857, G loss: 3.5414\n",
      "[484/1762] D loss: 1.6650, G loss: 0.4263\n",
      "[564/1762] D loss: 0.1873, G loss: 3.0167\n",
      "[644/1762] D loss: 0.0587, G loss: 3.5424\n",
      "[724/1762] D loss: 0.3024, G loss: 5.1321\n",
      "[804/1762] D loss: 0.3742, G loss: 1.5183\n",
      "[884/1762] D loss: 1.3791, G loss: 0.9878\n",
      "[964/1762] D loss: 1.0737, G loss: 0.8922\n",
      "[1044/1762] D loss: 0.3942, G loss: 1.9946\n",
      "[1124/1762] D loss: 1.5555, G loss: 0.4202\n",
      "[1204/1762] D loss: 1.3450, G loss: 1.2627\n",
      "[1284/1762] D loss: 1.0305, G loss: 1.4704\n",
      "[1364/1762] D loss: 1.1560, G loss: 1.0286\n",
      "[1444/1762] D loss: 0.7985, G loss: 2.1445\n",
      "[1524/1762] D loss: 0.6780, G loss: 5.0058\n",
      "[1604/1762] D loss: 0.1103, G loss: 2.2716\n",
      "[1684/1762] D loss: 1.5159, G loss: 0.4630\n",
      "[1762/1762] D loss: 0.9838, G loss: 0.7687\n",
      "train error: \n",
      " D loss: 1.806930, G loss: 1.781819, D accuracy: 50.9%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.872663, G loss: 1.788665, D accuracy: 50.8%, cell accuracy: 99.8%, board accuracy: 84.1% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1989, G loss: 0.7279\n",
      "[84/1762] D loss: 0.0059, G loss: 6.9957\n",
      "[164/1762] D loss: 1.5468, G loss: 0.9819\n",
      "[244/1762] D loss: 0.6956, G loss: 3.8763\n",
      "[324/1762] D loss: 0.7300, G loss: 1.0536\n",
      "[404/1762] D loss: 0.0107, G loss: 4.4854\n",
      "[484/1762] D loss: 1.5784, G loss: 0.3874\n",
      "[564/1762] D loss: 1.1362, G loss: 0.6244\n",
      "[644/1762] D loss: 1.8672, G loss: 0.4290\n",
      "[724/1762] D loss: 0.0875, G loss: 3.0082\n",
      "[804/1762] D loss: 0.0354, G loss: 3.7742\n",
      "[884/1762] D loss: 0.0051, G loss: 6.8890\n",
      "[964/1762] D loss: 0.1528, G loss: 6.1853\n",
      "[1044/1762] D loss: 1.4568, G loss: 0.6863\n",
      "[1124/1762] D loss: 0.2511, G loss: 1.9101\n",
      "[1204/1762] D loss: 1.2753, G loss: 0.8484\n",
      "[1284/1762] D loss: 0.4677, G loss: 5.5378\n",
      "[1364/1762] D loss: 1.3692, G loss: 0.5222\n",
      "[1444/1762] D loss: 0.6927, G loss: 2.5280\n",
      "[1524/1762] D loss: 1.2247, G loss: 0.5783\n",
      "[1604/1762] D loss: 0.1155, G loss: 4.4425\n",
      "[1684/1762] D loss: 0.0370, G loss: 3.5253\n",
      "[1762/1762] D loss: 1.4843, G loss: 0.5384\n",
      "train error: \n",
      " D loss: 1.597667, G loss: 0.604278, D accuracy: 52.9%, cell accuracy: 99.8%, board accuracy: 86.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.627433, G loss: 0.564869, D accuracy: 53.1%, cell accuracy: 99.8%, board accuracy: 85.2% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6020, G loss: 1.3515\n",
      "[84/1762] D loss: 0.8243, G loss: 1.3823\n",
      "[164/1762] D loss: 0.5756, G loss: 6.9903\n",
      "[244/1762] D loss: 0.9368, G loss: 6.6963\n",
      "[324/1762] D loss: 0.1553, G loss: 2.5209\n",
      "[404/1762] D loss: 0.1094, G loss: 2.7334\n",
      "[484/1762] D loss: 1.2446, G loss: 1.1693\n",
      "[564/1762] D loss: 1.2900, G loss: 1.0681\n",
      "[644/1762] D loss: 0.4394, G loss: 4.7802\n",
      "[724/1762] D loss: 0.7754, G loss: 3.1381\n",
      "[804/1762] D loss: 1.7126, G loss: 7.0615\n",
      "[884/1762] D loss: 1.5995, G loss: 0.7776\n",
      "[964/1762] D loss: 1.3593, G loss: 0.8900\n",
      "[1044/1762] D loss: 0.0099, G loss: 5.0482\n",
      "[1124/1762] D loss: 1.3100, G loss: 0.7175\n",
      "[1204/1762] D loss: 1.4363, G loss: 1.2803\n",
      "[1284/1762] D loss: 1.2655, G loss: 0.8018\n",
      "[1364/1762] D loss: 0.9413, G loss: 3.7098\n",
      "[1444/1762] D loss: 1.3601, G loss: 0.5767\n",
      "[1524/1762] D loss: 1.3726, G loss: 0.6384\n",
      "[1604/1762] D loss: 0.2820, G loss: 1.5761\n",
      "[1684/1762] D loss: 1.3971, G loss: 0.4336\n",
      "[1762/1762] D loss: 1.0986, G loss: 0.9704\n",
      "train error: \n",
      " D loss: 1.460685, G loss: 1.440735, D accuracy: 58.8%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.527779, G loss: 1.441928, D accuracy: 57.4%, cell accuracy: 99.8%, board accuracy: 83.4% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0083, G loss: 5.2295\n",
      "[84/1762] D loss: 2.0366, G loss: 0.2113\n",
      "[164/1762] D loss: 1.5245, G loss: 0.4263\n",
      "[244/1762] D loss: 0.2709, G loss: 3.4679\n",
      "[324/1762] D loss: 1.2039, G loss: 7.9986\n",
      "[404/1762] D loss: 1.3719, G loss: 1.2394\n",
      "[484/1762] D loss: 1.6197, G loss: 0.6898\n",
      "[564/1762] D loss: 0.0212, G loss: 6.1958\n",
      "[644/1762] D loss: 0.0318, G loss: 4.7007\n",
      "[724/1762] D loss: 1.3912, G loss: 1.1228\n",
      "[804/1762] D loss: 1.2315, G loss: 0.7383\n",
      "[884/1762] D loss: 0.0570, G loss: 3.2551\n",
      "[964/1762] D loss: 0.0034, G loss: 7.9067\n",
      "[1044/1762] D loss: 0.0129, G loss: 5.3407\n",
      "[1124/1762] D loss: 1.3775, G loss: 1.1797\n",
      "[1204/1762] D loss: 0.5069, G loss: 2.3999\n",
      "[1284/1762] D loss: 0.7630, G loss: 1.0050\n",
      "[1364/1762] D loss: 0.0501, G loss: 3.0596\n",
      "[1444/1762] D loss: 0.6929, G loss: 1.3822\n",
      "[1524/1762] D loss: 1.2281, G loss: 0.8037\n",
      "[1604/1762] D loss: 0.3595, G loss: 5.7794\n",
      "[1684/1762] D loss: 0.0135, G loss: 4.5287\n",
      "[1762/1762] D loss: 1.1336, G loss: 0.9497\n",
      "train error: \n",
      " D loss: 2.068690, G loss: 0.460877, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "test error: \n",
      " D loss: 2.133303, G loss: 0.406799, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 85.0% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0997, G loss: 2.8337\n",
      "[84/1762] D loss: 1.2811, G loss: 0.6008\n",
      "[164/1762] D loss: 0.5817, G loss: 1.6715\n",
      "[244/1762] D loss: 0.0036, G loss: 7.7371\n",
      "[324/1762] D loss: 0.0561, G loss: 2.9861\n",
      "[404/1762] D loss: 0.5412, G loss: 2.0791\n",
      "[484/1762] D loss: 1.6305, G loss: 0.3312\n",
      "[564/1762] D loss: 1.2262, G loss: 1.2210\n",
      "[644/1762] D loss: 1.5624, G loss: 1.3145\n",
      "[724/1762] D loss: 0.9176, G loss: 0.8826\n",
      "[804/1762] D loss: 0.1921, G loss: 5.6218\n",
      "[884/1762] D loss: 1.4742, G loss: 1.2744\n",
      "[964/1762] D loss: 1.3778, G loss: 0.6283\n",
      "[1044/1762] D loss: 0.7932, G loss: 2.1549\n",
      "[1124/1762] D loss: 1.5461, G loss: 0.3790\n",
      "[1204/1762] D loss: 0.0471, G loss: 3.1361\n",
      "[1284/1762] D loss: 2.5957, G loss: 0.1098\n",
      "[1364/1762] D loss: 2.9705, G loss: 0.0959\n",
      "[1444/1762] D loss: 0.8757, G loss: 1.4689\n",
      "[1524/1762] D loss: 1.3223, G loss: 0.5190\n",
      "[1604/1762] D loss: 0.5113, G loss: 6.0464\n",
      "[1684/1762] D loss: 1.4077, G loss: 1.2817\n",
      "[1762/1762] D loss: 0.9291, G loss: 1.1266\n",
      "train error: \n",
      " D loss: 1.328330, G loss: 0.891268, D accuracy: 60.4%, cell accuracy: 99.8%, board accuracy: 86.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.355780, G loss: 0.953405, D accuracy: 60.5%, cell accuracy: 99.8%, board accuracy: 84.1% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0760, G loss: 3.0586\n",
      "[84/1762] D loss: 2.0031, G loss: 0.2459\n",
      "[164/1762] D loss: 1.2976, G loss: 0.7274\n",
      "[244/1762] D loss: 0.0090, G loss: 5.7313\n",
      "[324/1762] D loss: 1.2805, G loss: 0.9211\n",
      "[404/1762] D loss: 0.2509, G loss: 1.6219\n",
      "[484/1762] D loss: 1.2718, G loss: 0.8692\n",
      "[564/1762] D loss: 0.0063, G loss: 7.7160\n",
      "[644/1762] D loss: 0.6645, G loss: 2.3609\n",
      "[724/1762] D loss: 0.2527, G loss: 4.7282\n",
      "[804/1762] D loss: 0.2103, G loss: 1.9375\n",
      "[884/1762] D loss: 1.1225, G loss: 0.8752\n",
      "[964/1762] D loss: 0.8731, G loss: 1.3844\n",
      "[1044/1762] D loss: 1.5841, G loss: 0.3309\n",
      "[1124/1762] D loss: 1.4222, G loss: 0.6514\n",
      "[1204/1762] D loss: 1.2296, G loss: 1.0866\n",
      "[1284/1762] D loss: 1.2315, G loss: 0.7053\n",
      "[1364/1762] D loss: 0.3225, G loss: 1.4517\n",
      "[1444/1762] D loss: 0.7992, G loss: 1.3143\n",
      "[1524/1762] D loss: 0.0923, G loss: 7.2691\n",
      "[1604/1762] D loss: 0.9754, G loss: 3.3192\n",
      "[1684/1762] D loss: 0.1968, G loss: 6.3660\n",
      "[1762/1762] D loss: 0.5047, G loss: 7.0223\n",
      "train error: \n",
      " D loss: 2.114131, G loss: 2.505600, D accuracy: 50.3%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.160167, G loss: 2.538143, D accuracy: 50.1%, cell accuracy: 99.8%, board accuracy: 83.9% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0033, G loss: 6.7124\n",
      "[84/1762] D loss: 0.7466, G loss: 1.5425\n",
      "[164/1762] D loss: 0.2317, G loss: 1.5607\n",
      "[244/1762] D loss: 0.1162, G loss: 4.1536\n",
      "[324/1762] D loss: 1.0087, G loss: 0.9495\n",
      "[404/1762] D loss: 1.1135, G loss: 1.1357\n",
      "[484/1762] D loss: 0.1295, G loss: 8.1622\n",
      "[564/1762] D loss: 0.0047, G loss: 5.6772\n",
      "[644/1762] D loss: 0.8239, G loss: 2.2982\n",
      "[724/1762] D loss: 1.1056, G loss: 0.8489\n",
      "[804/1762] D loss: 1.3186, G loss: 0.6431\n",
      "[884/1762] D loss: 0.0513, G loss: 3.4427\n",
      "[964/1762] D loss: 0.6377, G loss: 5.0361\n",
      "[1044/1762] D loss: 0.4427, G loss: 2.1705\n",
      "[1124/1762] D loss: 1.7083, G loss: 1.7168\n",
      "[1204/1762] D loss: 0.5278, G loss: 1.6669\n",
      "[1284/1762] D loss: 1.2551, G loss: 0.5073\n",
      "[1364/1762] D loss: 0.3458, G loss: 5.9153\n",
      "[1444/1762] D loss: 0.0868, G loss: 2.5945\n",
      "[1524/1762] D loss: 1.8541, G loss: 0.3803\n",
      "[1604/1762] D loss: 1.0061, G loss: 1.0466\n",
      "[1684/1762] D loss: 0.9500, G loss: 0.8490\n",
      "[1762/1762] D loss: 1.0647, G loss: 0.7078\n",
      "train error: \n",
      " D loss: 1.262751, G loss: 1.045590, D accuracy: 62.3%, cell accuracy: 99.8%, board accuracy: 86.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.282321, G loss: 1.050082, D accuracy: 62.7%, cell accuracy: 99.8%, board accuracy: 84.5% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6978, G loss: 2.6062\n",
      "[84/1762] D loss: 0.0140, G loss: 5.1014\n",
      "[164/1762] D loss: 0.0037, G loss: 6.7777\n",
      "[244/1762] D loss: 0.9706, G loss: 1.2629\n",
      "[324/1762] D loss: 0.9547, G loss: 1.0596\n",
      "[404/1762] D loss: 2.6149, G loss: 0.1241\n",
      "[484/1762] D loss: 0.7168, G loss: 2.4306\n",
      "[564/1762] D loss: 0.0089, G loss: 7.8623\n",
      "[644/1762] D loss: 0.2518, G loss: 3.3640\n",
      "[724/1762] D loss: 1.1692, G loss: 0.4979\n",
      "[804/1762] D loss: 0.8835, G loss: 1.0489\n",
      "[884/1762] D loss: 0.0103, G loss: 5.1528\n",
      "[964/1762] D loss: 0.2235, G loss: 4.9610\n",
      "[1044/1762] D loss: 1.2204, G loss: 0.5433\n",
      "[1124/1762] D loss: 0.0109, G loss: 5.7380\n",
      "[1204/1762] D loss: 1.1952, G loss: 2.9552\n",
      "[1284/1762] D loss: 1.0862, G loss: 1.3182\n",
      "[1364/1762] D loss: 0.9889, G loss: 0.8575\n",
      "[1444/1762] D loss: 1.6825, G loss: 0.5885\n",
      "[1524/1762] D loss: 0.0021, G loss: 8.7960\n",
      "[1604/1762] D loss: 0.0024, G loss: 7.0771\n",
      "[1684/1762] D loss: 0.8765, G loss: 7.0170\n",
      "[1762/1762] D loss: 1.4210, G loss: 0.8097\n",
      "train error: \n",
      " D loss: 1.308422, G loss: 0.974724, D accuracy: 62.1%, cell accuracy: 99.8%, board accuracy: 86.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.325145, G loss: 0.939098, D accuracy: 62.0%, cell accuracy: 99.8%, board accuracy: 83.4% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.9765, G loss: 0.3337\n",
      "[84/1762] D loss: 1.2030, G loss: 0.7555\n",
      "[164/1762] D loss: 1.5563, G loss: 6.1749\n",
      "[244/1762] D loss: 0.9975, G loss: 0.7418\n",
      "[324/1762] D loss: 0.3228, G loss: 1.4077\n",
      "[404/1762] D loss: 1.4528, G loss: 0.4445\n",
      "[484/1762] D loss: 0.4054, G loss: 5.4641\n",
      "[564/1762] D loss: 0.0193, G loss: 5.5847\n",
      "[644/1762] D loss: 0.0067, G loss: 5.3149\n",
      "[724/1762] D loss: 0.3771, G loss: 1.8184\n",
      "[804/1762] D loss: 0.7738, G loss: 2.8732\n",
      "[884/1762] D loss: 1.1611, G loss: 0.8578\n",
      "[964/1762] D loss: 1.7573, G loss: 0.3699\n",
      "[1044/1762] D loss: 0.0572, G loss: 3.0773\n",
      "[1124/1762] D loss: 0.1329, G loss: 2.3133\n",
      "[1204/1762] D loss: 0.2161, G loss: 4.1466\n",
      "[1284/1762] D loss: 0.9027, G loss: 0.7743\n",
      "[1364/1762] D loss: 0.9289, G loss: 1.1549\n",
      "[1444/1762] D loss: 0.3103, G loss: 4.7547\n",
      "[1524/1762] D loss: 1.1791, G loss: 0.8522\n",
      "[1604/1762] D loss: 1.1514, G loss: 0.8099\n",
      "[1684/1762] D loss: 0.4391, G loss: 8.5767\n",
      "[1762/1762] D loss: 0.9449, G loss: 1.0090\n",
      "train error: \n",
      " D loss: 1.664325, G loss: 0.956800, D accuracy: 56.0%, cell accuracy: 99.8%, board accuracy: 86.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.691493, G loss: 1.020563, D accuracy: 56.8%, cell accuracy: 99.8%, board accuracy: 83.4% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.1134, G loss: 5.6345\n",
      "[84/1762] D loss: 1.2386, G loss: 1.0896\n",
      "[164/1762] D loss: 0.0126, G loss: 5.0923\n",
      "[244/1762] D loss: 0.0262, G loss: 4.1204\n",
      "[324/1762] D loss: 0.4748, G loss: 2.9830\n",
      "[404/1762] D loss: 1.3906, G loss: 1.2907\n",
      "[484/1762] D loss: 0.0563, G loss: 3.4610\n",
      "[564/1762] D loss: 0.0758, G loss: 3.2374\n",
      "[644/1762] D loss: 0.0753, G loss: 3.0818\n",
      "[724/1762] D loss: 0.0020, G loss: 7.7363\n",
      "[804/1762] D loss: 0.4666, G loss: 2.5116\n",
      "[884/1762] D loss: 0.9270, G loss: 0.9866\n",
      "[964/1762] D loss: 1.0753, G loss: 0.8773\n",
      "[1044/1762] D loss: 0.4175, G loss: 7.2760\n",
      "[1124/1762] D loss: 0.0073, G loss: 4.8443\n",
      "[1204/1762] D loss: 0.0022, G loss: 6.2677\n",
      "[1284/1762] D loss: 0.1503, G loss: 4.0496\n",
      "[1364/1762] D loss: 1.2207, G loss: 0.6639\n",
      "[1444/1762] D loss: 1.5876, G loss: 0.7303\n",
      "[1524/1762] D loss: 1.6869, G loss: 0.2932\n",
      "[1604/1762] D loss: 1.4722, G loss: 0.4460\n",
      "[1684/1762] D loss: 0.4110, G loss: 4.5943\n",
      "[1762/1762] D loss: 0.1943, G loss: 5.3707\n",
      "train error: \n",
      " D loss: 1.751652, G loss: 2.117423, D accuracy: 52.0%, cell accuracy: 99.8%, board accuracy: 87.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.768252, G loss: 2.132915, D accuracy: 52.6%, cell accuracy: 99.8%, board accuracy: 84.5% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6187, G loss: 3.0030\n",
      "[84/1762] D loss: 1.3401, G loss: 0.7389\n",
      "[164/1762] D loss: 0.3690, G loss: 7.3023\n",
      "[244/1762] D loss: 1.1844, G loss: 0.6373\n",
      "[324/1762] D loss: 0.4310, G loss: 2.3860\n",
      "[404/1762] D loss: 0.5055, G loss: 2.1815\n",
      "[484/1762] D loss: 0.8587, G loss: 1.2632\n",
      "[564/1762] D loss: 0.2010, G loss: 2.9818\n",
      "[644/1762] D loss: 0.0105, G loss: 5.0838\n",
      "[724/1762] D loss: 1.6667, G loss: 0.3955\n",
      "[804/1762] D loss: 1.0408, G loss: 1.0277\n",
      "[884/1762] D loss: 0.3788, G loss: 5.2695\n",
      "[964/1762] D loss: 0.0456, G loss: 3.6017\n",
      "[1044/1762] D loss: 0.0083, G loss: 6.3304\n",
      "[1124/1762] D loss: 0.2225, G loss: 6.4825\n",
      "[1204/1762] D loss: 0.0546, G loss: 3.0329\n",
      "[1284/1762] D loss: 0.1867, G loss: 6.0952\n",
      "[1364/1762] D loss: 1.1356, G loss: 0.9960\n",
      "[1444/1762] D loss: 1.2979, G loss: 0.5687\n",
      "[1524/1762] D loss: 1.0013, G loss: 1.2374\n",
      "[1604/1762] D loss: 0.0622, G loss: 3.1453\n",
      "[1684/1762] D loss: 0.0389, G loss: 4.3604\n",
      "[1762/1762] D loss: 0.8448, G loss: 1.4296\n",
      "train error: \n",
      " D loss: 1.841054, G loss: 0.548263, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.866881, G loss: 0.548681, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 83.4% \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#train_and_freeze_gen(run_name=\"freeze_gen_epoch_0\", freeze_epoch=0)\n",
    "train_and_freeze_gen(run_name=\"freeze_gen_epoch_5\", freeze_epoch=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The combined accuracy metric oscillates between 89% and 111%. This averages out at 100%, but the variance seems too high. Perhaps the discriminator is doing alright but the generator is not improving for some reason."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Freeze discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_freeze_disc(run_name=\"\", freeze_epoch=0):\n",
    "    learning_rate = 1e-3\n",
    "    epochs = 50\n",
    "\n",
    "    gen = TetrisModel().to(device)\n",
    "    disc = TetrisDiscriminator().to(device)\n",
    "\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer_gen = torch.optim.Adam(gen.parameters(), lr=learning_rate)\n",
    "    optimizer_disc = torch.optim.Adam(disc.parameters(), lr=learning_rate)\n",
    "\n",
    "    log_dir = os.path.join(\"runs\", \"experiment_019\")\n",
    "    log_subdir = os.path.join(log_dir, run_name + \"_\" + datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"))\n",
    "    tb_writer = SummaryWriter(log_subdir)\n",
    "\n",
    "    train_examples = find_interesting_examples(train_dataset)\n",
    "    test_examples = find_interesting_examples(test_dataset)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch}\\n-------------------------------\")\n",
    "        if epoch == freeze_epoch:\n",
    "            disc.requires_grad_(False)\n",
    "        train_loop(train_dataloader, gen, disc, loss_fn, optimizer_gen, optimizer_disc)\n",
    "        test_loop(\"train\", train_dataloader, gen, disc, loss_fn, tb_writer, epoch, train_examples)\n",
    "        test_loop(\"test\", test_dataloader, gen, disc, loss_fn, tb_writer, epoch, test_examples)\n",
    "        for name, weight in gen.named_parameters():\n",
    "            tb_writer.add_histogram(f\"Generator weights/{name}\", weight, epoch)\n",
    "            tb_writer.add_histogram(f\"Generator gradients/{name}\", weight.grad, epoch)\n",
    "\n",
    "    tb_writer.close()\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apparently we need to update the training loop to support tensors that don't require grad\n",
    "\n",
    "def train_loop(dataloader, gen, disc, loss_fn, optimizer_gen, optimizer_disc):\n",
    "    gen.train()\n",
    "    disc.train()\n",
    "\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        ##################################################################\n",
    "        # (1) Update discriminator: minimize -log(D(x)) - log(1 - D(G(z)))\n",
    "        ##################################################################\n",
    "        disc.zero_grad()\n",
    "\n",
    "        ## Train with all-real batch\n",
    "        # Format batch\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        batch_size = X.size(0)\n",
    "        real_labels = torch.full((batch_size,), real_label, dtype=torch.float, device=device)\n",
    "        # Forward pass real batch through discriminator\n",
    "        output = torch.flatten(disc(X, y))\n",
    "        # Calculate loss on all-real batch\n",
    "        err_disc_real = loss_fn(output, real_labels)\n",
    "        # Calculate gradients for discriminator in backward pass\n",
    "        if err_disc_real.requires_grad:\n",
    "            err_disc_real.backward()\n",
    "\n",
    "        ## Train with all-fake batch\n",
    "        # Generate batch of latent vectors\n",
    "        z = torch.rand(batch_size, 4, device=device)\n",
    "        # Generate fake image batch with generator\n",
    "        y_fake = gen(X, z)\n",
    "        fake_labels = torch.full((batch_size,), fake_label, dtype=torch.float, device=device)\n",
    "        # Classify all fake batch with discriminator\n",
    "        output = torch.flatten(disc(X, y_fake.detach()))\n",
    "        # Calculate discriminator's loss on the all-fake batch\n",
    "        err_disc_fake = loss_fn(output, fake_labels)\n",
    "        # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
    "        if err_disc_fake.requires_grad:\n",
    "            err_disc_fake.backward()\n",
    "\n",
    "        ## Update discriminator weights\n",
    "        # Compute error of discriminator as sum over the fake and the real batches\n",
    "        err_disc = err_disc_real + err_disc_fake\n",
    "        # Update discriminator\n",
    "        optimizer_disc.step()\n",
    "\n",
    "        ##############################################\n",
    "        # (2) Update generator: minimize -log(D(G(z)))\n",
    "        ##############################################\n",
    "        gen.zero_grad()\n",
    "        # Since we just updated the discriminator, perform another forward pass of the all-fake batch through it\n",
    "        output = torch.flatten(disc(X, y_fake))\n",
    "        # Calculate the generator's loss based on this output\n",
    "        # We use real labels because the generator wants to fool the discriminator\n",
    "        err_gen = loss_fn(output, real_labels)\n",
    "        # Calculate gradients for generator\n",
    "        err_gen.backward()\n",
    "        # Update generator\n",
    "        optimizer_gen.step()\n",
    "\n",
    "        # Output training stats\n",
    "        if batch % 20 == 0:\n",
    "            current = batch * dataloader.batch_size + batch_size\n",
    "            print(f\"[{current}/{size}] D loss: {err_disc.item():.4f}, G loss: {err_gen.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4153, G loss: 0.5613\n",
      "[84/1762] D loss: 1.4798, G loss: 0.5093\n",
      "[164/1762] D loss: 1.5648, G loss: 0.4513\n",
      "[244/1762] D loss: 1.5752, G loss: 0.4422\n",
      "[324/1762] D loss: 1.6349, G loss: 0.4127\n",
      "[404/1762] D loss: 1.6430, G loss: 0.4090\n",
      "[484/1762] D loss: 1.6900, G loss: 0.3823\n",
      "[564/1762] D loss: 1.7131, G loss: 0.3743\n",
      "[644/1762] D loss: 1.7187, G loss: 0.3823\n",
      "[724/1762] D loss: 1.6856, G loss: 0.3939\n",
      "[804/1762] D loss: 1.7639, G loss: 0.3545\n",
      "[884/1762] D loss: 1.7295, G loss: 0.3840\n",
      "[964/1762] D loss: 1.7367, G loss: 0.3794\n",
      "[1044/1762] D loss: 1.7267, G loss: 0.3667\n",
      "[1124/1762] D loss: 1.7729, G loss: 0.3558\n",
      "[1204/1762] D loss: 1.7590, G loss: 0.3697\n",
      "[1284/1762] D loss: 1.7550, G loss: 0.3567\n",
      "[1364/1762] D loss: 1.7479, G loss: 0.3659\n",
      "[1444/1762] D loss: 1.7279, G loss: 0.3667\n",
      "[1524/1762] D loss: 1.7807, G loss: 0.3520\n",
      "[1604/1762] D loss: 1.7501, G loss: 0.3549\n",
      "[1684/1762] D loss: 1.7437, G loss: 0.3769\n",
      "[1762/1762] D loss: 1.7445, G loss: 0.3521\n",
      "train error: \n",
      " D loss: 1.749759, G loss: 0.364371, D accuracy: 50.0%, cell accuracy: 48.2%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.747527, G loss: 0.365529, D accuracy: 50.0%, cell accuracy: 48.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.7664, G loss: 0.3558\n",
      "[84/1762] D loss: 1.7818, G loss: 0.3436\n",
      "[164/1762] D loss: 1.7828, G loss: 0.3520\n",
      "[244/1762] D loss: 1.8063, G loss: 0.3377\n",
      "[324/1762] D loss: 1.8074, G loss: 0.3359\n",
      "[404/1762] D loss: 1.7585, G loss: 0.3599\n",
      "[484/1762] D loss: 1.8129, G loss: 0.3413\n",
      "[564/1762] D loss: 1.8251, G loss: 0.3249\n",
      "[644/1762] D loss: 1.7583, G loss: 0.3444\n",
      "[724/1762] D loss: 1.8072, G loss: 0.3384\n",
      "[804/1762] D loss: 1.7688, G loss: 0.3637\n",
      "[884/1762] D loss: 1.7841, G loss: 0.3495\n",
      "[964/1762] D loss: 1.7912, G loss: 0.3467\n",
      "[1044/1762] D loss: 1.7577, G loss: 0.3531\n",
      "[1124/1762] D loss: 1.7786, G loss: 0.3392\n",
      "[1204/1762] D loss: 1.7959, G loss: 0.3455\n",
      "[1284/1762] D loss: 1.7962, G loss: 0.3318\n",
      "[1364/1762] D loss: 1.7884, G loss: 0.3554\n",
      "[1444/1762] D loss: 1.8005, G loss: 0.3275\n",
      "[1524/1762] D loss: 1.7977, G loss: 0.3432\n",
      "[1604/1762] D loss: 1.7901, G loss: 0.3478\n",
      "[1684/1762] D loss: 1.8042, G loss: 0.3330\n",
      "[1762/1762] D loss: 1.7319, G loss: 0.3666\n",
      "train error: \n",
      " D loss: 1.781975, G loss: 0.347272, D accuracy: 50.0%, cell accuracy: 47.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.777116, G loss: 0.349471, D accuracy: 50.0%, cell accuracy: 48.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.7828, G loss: 0.3500\n",
      "[84/1762] D loss: 1.7799, G loss: 0.3540\n",
      "[164/1762] D loss: 1.7678, G loss: 0.3469\n",
      "[244/1762] D loss: 1.7646, G loss: 0.3497\n",
      "[324/1762] D loss: 1.8174, G loss: 0.3315\n",
      "[404/1762] D loss: 1.7936, G loss: 0.3429\n",
      "[484/1762] D loss: 1.7800, G loss: 0.3571\n",
      "[564/1762] D loss: 1.8027, G loss: 0.3347\n",
      "[644/1762] D loss: 1.7624, G loss: 0.3547\n",
      "[724/1762] D loss: 1.8129, G loss: 0.3366\n",
      "[804/1762] D loss: 1.8216, G loss: 0.3391\n",
      "[884/1762] D loss: 1.7940, G loss: 0.3377\n",
      "[964/1762] D loss: 1.7956, G loss: 0.3494\n",
      "[1044/1762] D loss: 1.7811, G loss: 0.3440\n",
      "[1124/1762] D loss: 1.7935, G loss: 0.3413\n",
      "[1204/1762] D loss: 1.8058, G loss: 0.3349\n",
      "[1284/1762] D loss: 1.8315, G loss: 0.3213\n",
      "[1364/1762] D loss: 1.7804, G loss: 0.3529\n",
      "[1444/1762] D loss: 1.8552, G loss: 0.3157\n",
      "[1524/1762] D loss: 1.8188, G loss: 0.3233\n",
      "[1604/1762] D loss: 1.7877, G loss: 0.3414\n",
      "[1684/1762] D loss: 1.8191, G loss: 0.3297\n",
      "[1762/1762] D loss: 1.8208, G loss: 0.3331\n",
      "train error: \n",
      " D loss: 1.793803, G loss: 0.343555, D accuracy: 50.0%, cell accuracy: 50.2%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.790442, G loss: 0.345085, D accuracy: 50.0%, cell accuracy: 50.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.7863, G loss: 0.3568\n",
      "[84/1762] D loss: 1.8120, G loss: 0.3323\n",
      "[164/1762] D loss: 1.8162, G loss: 0.3336\n",
      "[244/1762] D loss: 1.7868, G loss: 0.3420\n",
      "[324/1762] D loss: 1.8080, G loss: 0.3405\n",
      "[404/1762] D loss: 1.8338, G loss: 0.3299\n",
      "[484/1762] D loss: 1.8118, G loss: 0.3309\n",
      "[564/1762] D loss: 1.8079, G loss: 0.3358\n",
      "[644/1762] D loss: 1.8105, G loss: 0.3370\n",
      "[724/1762] D loss: 1.8234, G loss: 0.3350\n",
      "[804/1762] D loss: 1.8054, G loss: 0.3343\n",
      "[884/1762] D loss: 1.7950, G loss: 0.3458\n",
      "[964/1762] D loss: 1.8113, G loss: 0.3490\n",
      "[1044/1762] D loss: 1.8551, G loss: 0.3165\n",
      "[1124/1762] D loss: 1.8323, G loss: 0.3268\n",
      "[1204/1762] D loss: 1.8312, G loss: 0.3249\n",
      "[1284/1762] D loss: 1.8196, G loss: 0.3364\n",
      "[1364/1762] D loss: 1.8036, G loss: 0.3332\n",
      "[1444/1762] D loss: 1.7790, G loss: 0.3518\n",
      "[1524/1762] D loss: 1.8161, G loss: 0.3269\n",
      "[1604/1762] D loss: 1.8167, G loss: 0.3391\n",
      "[1684/1762] D loss: 1.7913, G loss: 0.3434\n",
      "[1762/1762] D loss: 1.8406, G loss: 0.3155\n",
      "train error: \n",
      " D loss: 1.807418, G loss: 0.336775, D accuracy: 50.0%, cell accuracy: 51.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.803190, G loss: 0.338593, D accuracy: 50.0%, cell accuracy: 51.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.8066, G loss: 0.3332\n",
      "[84/1762] D loss: 1.8132, G loss: 0.3215\n",
      "[164/1762] D loss: 1.8213, G loss: 0.3261\n",
      "[244/1762] D loss: 1.7913, G loss: 0.3490\n",
      "[324/1762] D loss: 1.7880, G loss: 0.3417\n",
      "[404/1762] D loss: 1.8195, G loss: 0.3202\n",
      "[484/1762] D loss: 1.8192, G loss: 0.3289\n",
      "[564/1762] D loss: 1.8182, G loss: 0.3383\n",
      "[644/1762] D loss: 1.8073, G loss: 0.3339\n",
      "[724/1762] D loss: 1.8083, G loss: 0.3206\n",
      "[804/1762] D loss: 1.8009, G loss: 0.3327\n",
      "[884/1762] D loss: 1.8325, G loss: 0.3315\n",
      "[964/1762] D loss: 1.7833, G loss: 0.3424\n",
      "[1044/1762] D loss: 1.8757, G loss: 0.3104\n",
      "[1124/1762] D loss: 1.8129, G loss: 0.3410\n",
      "[1204/1762] D loss: 1.7806, G loss: 0.3457\n",
      "[1284/1762] D loss: 1.8263, G loss: 0.3318\n",
      "[1364/1762] D loss: 1.7948, G loss: 0.3374\n",
      "[1444/1762] D loss: 1.7823, G loss: 0.3407\n",
      "[1524/1762] D loss: 1.8069, G loss: 0.3543\n",
      "[1604/1762] D loss: 1.8058, G loss: 0.3377\n",
      "[1684/1762] D loss: 1.8319, G loss: 0.3253\n",
      "[1762/1762] D loss: 1.8355, G loss: 0.3324\n",
      "train error: \n",
      " D loss: 1.821473, G loss: 0.333448, D accuracy: 50.0%, cell accuracy: 51.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.814086, G loss: 0.336434, D accuracy: 50.0%, cell accuracy: 51.8%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.8608, G loss: 0.3111\n",
      "[84/1762] D loss: 1.8374, G loss: 0.3195\n",
      "[164/1762] D loss: 1.8174, G loss: 0.3293\n",
      "[244/1762] D loss: 1.8213, G loss: 0.3301\n",
      "[324/1762] D loss: 1.7762, G loss: 0.3425\n",
      "[404/1762] D loss: 1.8399, G loss: 0.3279\n",
      "[484/1762] D loss: 1.7851, G loss: 0.3559\n",
      "[564/1762] D loss: 1.8340, G loss: 0.3344\n",
      "[644/1762] D loss: 1.7868, G loss: 0.3427\n",
      "[724/1762] D loss: 1.8449, G loss: 0.3152\n",
      "[804/1762] D loss: 1.8687, G loss: 0.3124\n",
      "[884/1762] D loss: 1.8204, G loss: 0.3265\n",
      "[964/1762] D loss: 1.8565, G loss: 0.3090\n",
      "[1044/1762] D loss: 1.8076, G loss: 0.3486\n",
      "[1124/1762] D loss: 1.8581, G loss: 0.3143\n",
      "[1204/1762] D loss: 1.8442, G loss: 0.3147\n",
      "[1284/1762] D loss: 1.8049, G loss: 0.3443\n",
      "[1364/1762] D loss: 1.8464, G loss: 0.3150\n",
      "[1444/1762] D loss: 1.8658, G loss: 0.3164\n",
      "[1524/1762] D loss: 1.8397, G loss: 0.3231\n",
      "[1604/1762] D loss: 1.7883, G loss: 0.3444\n",
      "[1684/1762] D loss: 1.8948, G loss: 0.2945\n",
      "[1762/1762] D loss: 1.8879, G loss: 0.2933\n",
      "train error: \n",
      " D loss: 1.851217, G loss: 0.320538, D accuracy: 50.0%, cell accuracy: 50.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.841356, G loss: 0.324292, D accuracy: 50.0%, cell accuracy: 51.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.8710, G loss: 0.3038\n",
      "[84/1762] D loss: 1.8419, G loss: 0.3176\n",
      "[164/1762] D loss: 1.8238, G loss: 0.3355\n",
      "[244/1762] D loss: 1.7838, G loss: 0.3545\n",
      "[324/1762] D loss: 1.8525, G loss: 0.3252\n",
      "[404/1762] D loss: 1.8800, G loss: 0.3074\n",
      "[484/1762] D loss: 1.8616, G loss: 0.3112\n",
      "[564/1762] D loss: 1.8165, G loss: 0.3295\n",
      "[644/1762] D loss: 1.8830, G loss: 0.3022\n",
      "[724/1762] D loss: 1.8667, G loss: 0.3144\n",
      "[804/1762] D loss: 1.8380, G loss: 0.3230\n",
      "[884/1762] D loss: 1.9136, G loss: 0.3050\n",
      "[964/1762] D loss: 1.8766, G loss: 0.3156\n",
      "[1044/1762] D loss: 1.8166, G loss: 0.3388\n",
      "[1124/1762] D loss: 1.8955, G loss: 0.2963\n",
      "[1204/1762] D loss: 1.8244, G loss: 0.3347\n",
      "[1284/1762] D loss: 1.8494, G loss: 0.3224\n",
      "[1364/1762] D loss: 1.8473, G loss: 0.3206\n",
      "[1444/1762] D loss: 1.8775, G loss: 0.3161\n",
      "[1524/1762] D loss: 1.8571, G loss: 0.3176\n",
      "[1604/1762] D loss: 1.8831, G loss: 0.3034\n",
      "[1684/1762] D loss: 1.8419, G loss: 0.3229\n",
      "[1762/1762] D loss: 1.8228, G loss: 0.3401\n",
      "train error: \n",
      " D loss: 1.857508, G loss: 0.319665, D accuracy: 50.0%, cell accuracy: 50.0%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.854098, G loss: 0.321105, D accuracy: 50.0%, cell accuracy: 50.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.8275, G loss: 0.3328\n",
      "[84/1762] D loss: 1.8667, G loss: 0.3059\n",
      "[164/1762] D loss: 1.8371, G loss: 0.3198\n",
      "[244/1762] D loss: 1.8613, G loss: 0.3195\n",
      "[324/1762] D loss: 1.8928, G loss: 0.3083\n",
      "[404/1762] D loss: 1.9031, G loss: 0.2903\n",
      "[484/1762] D loss: 1.7989, G loss: 0.3435\n",
      "[564/1762] D loss: 1.8436, G loss: 0.3280\n",
      "[644/1762] D loss: 1.7989, G loss: 0.3398\n",
      "[724/1762] D loss: 1.8541, G loss: 0.3201\n",
      "[804/1762] D loss: 1.8794, G loss: 0.3083\n",
      "[884/1762] D loss: 1.8665, G loss: 0.3151\n",
      "[964/1762] D loss: 1.8896, G loss: 0.3154\n",
      "[1044/1762] D loss: 1.8809, G loss: 0.3081\n",
      "[1124/1762] D loss: 1.9182, G loss: 0.2827\n",
      "[1204/1762] D loss: 1.9159, G loss: 0.2939\n",
      "[1284/1762] D loss: 1.8756, G loss: 0.3174\n",
      "[1364/1762] D loss: 1.8094, G loss: 0.3307\n",
      "[1444/1762] D loss: 1.9059, G loss: 0.2947\n",
      "[1524/1762] D loss: 1.8642, G loss: 0.3160\n",
      "[1604/1762] D loss: 1.8559, G loss: 0.3182\n",
      "[1684/1762] D loss: 1.8064, G loss: 0.3446\n",
      "[1762/1762] D loss: 1.8630, G loss: 0.3288\n",
      "train error: \n",
      " D loss: 1.861384, G loss: 0.318106, D accuracy: 50.0%, cell accuracy: 49.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.856483, G loss: 0.320110, D accuracy: 50.0%, cell accuracy: 50.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.8751, G loss: 0.3146\n",
      "[84/1762] D loss: 1.8752, G loss: 0.3174\n",
      "[164/1762] D loss: 1.9088, G loss: 0.2848\n",
      "[244/1762] D loss: 1.8886, G loss: 0.3085\n",
      "[324/1762] D loss: 1.8476, G loss: 0.3230\n",
      "[404/1762] D loss: 1.8881, G loss: 0.3029\n",
      "[484/1762] D loss: 1.9088, G loss: 0.2961\n",
      "[564/1762] D loss: 1.8053, G loss: 0.3391\n",
      "[644/1762] D loss: 1.9062, G loss: 0.3165\n",
      "[724/1762] D loss: 1.8733, G loss: 0.3135\n",
      "[804/1762] D loss: 1.8652, G loss: 0.3170\n",
      "[884/1762] D loss: 1.8448, G loss: 0.3273\n",
      "[964/1762] D loss: 1.8947, G loss: 0.3027\n",
      "[1044/1762] D loss: 1.8524, G loss: 0.3280\n",
      "[1124/1762] D loss: 1.8786, G loss: 0.3137\n",
      "[1204/1762] D loss: 1.8672, G loss: 0.3213\n",
      "[1284/1762] D loss: 1.9958, G loss: 0.2687\n",
      "[1364/1762] D loss: 1.8793, G loss: 0.3025\n",
      "[1444/1762] D loss: 1.8816, G loss: 0.3094\n",
      "[1524/1762] D loss: 1.8651, G loss: 0.3168\n",
      "[1604/1762] D loss: 1.8144, G loss: 0.3366\n",
      "[1684/1762] D loss: 1.8974, G loss: 0.2996\n",
      "[1762/1762] D loss: 1.9513, G loss: 0.2742\n",
      "train error: \n",
      " D loss: 1.887582, G loss: 0.308297, D accuracy: 50.0%, cell accuracy: 52.0%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.883364, G loss: 0.309950, D accuracy: 50.0%, cell accuracy: 51.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.9266, G loss: 0.2937\n",
      "[84/1762] D loss: 1.8975, G loss: 0.3005\n",
      "[164/1762] D loss: 1.8847, G loss: 0.3049\n",
      "[244/1762] D loss: 1.8393, G loss: 0.3217\n",
      "[324/1762] D loss: 1.8119, G loss: 0.3383\n",
      "[404/1762] D loss: 1.8979, G loss: 0.2956\n",
      "[484/1762] D loss: 1.9299, G loss: 0.2946\n",
      "[564/1762] D loss: 1.8706, G loss: 0.3047\n",
      "[644/1762] D loss: 1.8931, G loss: 0.2934\n",
      "[724/1762] D loss: 1.8242, G loss: 0.3329\n",
      "[804/1762] D loss: 1.8808, G loss: 0.3064\n",
      "[884/1762] D loss: 1.8776, G loss: 0.3189\n",
      "[964/1762] D loss: 1.9105, G loss: 0.2886\n",
      "[1044/1762] D loss: 1.9529, G loss: 0.2831\n",
      "[1124/1762] D loss: 1.8969, G loss: 0.3085\n",
      "[1204/1762] D loss: 1.9898, G loss: 0.2799\n",
      "[1284/1762] D loss: 1.8831, G loss: 0.3108\n",
      "[1364/1762] D loss: 1.8914, G loss: 0.2985\n",
      "[1444/1762] D loss: 1.9037, G loss: 0.2935\n",
      "[1524/1762] D loss: 1.9515, G loss: 0.2764\n",
      "[1604/1762] D loss: 1.9366, G loss: 0.2914\n",
      "[1684/1762] D loss: 1.9559, G loss: 0.2856\n",
      "[1762/1762] D loss: 1.8365, G loss: 0.3420\n",
      "train error: \n",
      " D loss: 1.893457, G loss: 0.306359, D accuracy: 50.0%, cell accuracy: 50.3%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.891352, G loss: 0.307204, D accuracy: 50.0%, cell accuracy: 50.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.8856, G loss: 0.3098\n",
      "[84/1762] D loss: 1.9596, G loss: 0.2732\n",
      "[164/1762] D loss: 1.9087, G loss: 0.2928\n",
      "[244/1762] D loss: 1.8988, G loss: 0.3090\n",
      "[324/1762] D loss: 1.9372, G loss: 0.2863\n",
      "[404/1762] D loss: 1.9255, G loss: 0.2944\n",
      "[484/1762] D loss: 1.9433, G loss: 0.2806\n",
      "[564/1762] D loss: 1.9252, G loss: 0.2883\n",
      "[644/1762] D loss: 1.8716, G loss: 0.3081\n",
      "[724/1762] D loss: 1.8516, G loss: 0.3219\n",
      "[804/1762] D loss: 1.8277, G loss: 0.3400\n",
      "[884/1762] D loss: 1.9563, G loss: 0.2822\n",
      "[964/1762] D loss: 1.8486, G loss: 0.3240\n",
      "[1044/1762] D loss: 1.9307, G loss: 0.2902\n",
      "[1124/1762] D loss: 1.8833, G loss: 0.3062\n",
      "[1204/1762] D loss: 1.8770, G loss: 0.3137\n",
      "[1284/1762] D loss: 1.9510, G loss: 0.2754\n",
      "[1364/1762] D loss: 1.8982, G loss: 0.3109\n",
      "[1444/1762] D loss: 1.9167, G loss: 0.2978\n",
      "[1524/1762] D loss: 1.9003, G loss: 0.3059\n",
      "[1604/1762] D loss: 1.8902, G loss: 0.3031\n",
      "[1684/1762] D loss: 1.8603, G loss: 0.3232\n",
      "[1762/1762] D loss: 1.9232, G loss: 0.2947\n",
      "train error: \n",
      " D loss: 1.902238, G loss: 0.305278, D accuracy: 50.0%, cell accuracy: 49.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.898374, G loss: 0.306752, D accuracy: 50.0%, cell accuracy: 49.8%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.8385, G loss: 0.3305\n",
      "[84/1762] D loss: 1.9282, G loss: 0.2873\n",
      "[164/1762] D loss: 1.8990, G loss: 0.3109\n",
      "[244/1762] D loss: 1.9322, G loss: 0.2912\n",
      "[324/1762] D loss: 1.8980, G loss: 0.3010\n",
      "[404/1762] D loss: 1.9257, G loss: 0.3028\n",
      "[484/1762] D loss: 1.8588, G loss: 0.3204\n",
      "[564/1762] D loss: 1.9040, G loss: 0.2945\n",
      "[644/1762] D loss: 1.8607, G loss: 0.3196\n",
      "[724/1762] D loss: 1.8830, G loss: 0.3134\n",
      "[804/1762] D loss: 1.9053, G loss: 0.3088\n",
      "[884/1762] D loss: 1.9280, G loss: 0.2859\n",
      "[964/1762] D loss: 1.9062, G loss: 0.2983\n",
      "[1044/1762] D loss: 1.9335, G loss: 0.2814\n",
      "[1124/1762] D loss: 1.9934, G loss: 0.2649\n",
      "[1204/1762] D loss: 1.8949, G loss: 0.3003\n",
      "[1284/1762] D loss: 1.8946, G loss: 0.3077\n",
      "[1364/1762] D loss: 1.9305, G loss: 0.2921\n",
      "[1444/1762] D loss: 1.9608, G loss: 0.2848\n",
      "[1524/1762] D loss: 1.9208, G loss: 0.2916\n",
      "[1604/1762] D loss: 1.9357, G loss: 0.2921\n",
      "[1684/1762] D loss: 1.9808, G loss: 0.2748\n",
      "[1762/1762] D loss: 1.9289, G loss: 0.2835\n",
      "train error: \n",
      " D loss: 1.924226, G loss: 0.295213, D accuracy: 50.0%, cell accuracy: 50.6%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.919632, G loss: 0.296803, D accuracy: 50.0%, cell accuracy: 50.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.9159, G loss: 0.3008\n",
      "[84/1762] D loss: 1.9250, G loss: 0.3001\n",
      "[164/1762] D loss: 1.8774, G loss: 0.3143\n",
      "[244/1762] D loss: 1.9460, G loss: 0.2780\n",
      "[324/1762] D loss: 1.9789, G loss: 0.2745\n",
      "[404/1762] D loss: 1.9597, G loss: 0.2740\n",
      "[484/1762] D loss: 1.8838, G loss: 0.3149\n",
      "[564/1762] D loss: 1.9268, G loss: 0.2932\n",
      "[644/1762] D loss: 1.9455, G loss: 0.2901\n",
      "[724/1762] D loss: 1.8907, G loss: 0.3177\n",
      "[804/1762] D loss: 1.9450, G loss: 0.2976\n",
      "[884/1762] D loss: 1.9156, G loss: 0.2997\n",
      "[964/1762] D loss: 1.9755, G loss: 0.2696\n",
      "[1044/1762] D loss: 1.9036, G loss: 0.3103\n",
      "[1124/1762] D loss: 1.9306, G loss: 0.2949\n",
      "[1204/1762] D loss: 1.8997, G loss: 0.2963\n",
      "[1284/1762] D loss: 1.9392, G loss: 0.2811\n",
      "[1364/1762] D loss: 1.9296, G loss: 0.2965\n",
      "[1444/1762] D loss: 1.9297, G loss: 0.2989\n",
      "[1524/1762] D loss: 1.8506, G loss: 0.3259\n",
      "[1604/1762] D loss: 1.9049, G loss: 0.2956\n",
      "[1684/1762] D loss: 1.8748, G loss: 0.3181\n",
      "[1762/1762] D loss: 1.8828, G loss: 0.3084\n",
      "train error: \n",
      " D loss: 1.952010, G loss: 0.285910, D accuracy: 50.0%, cell accuracy: 48.3%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.946173, G loss: 0.287960, D accuracy: 50.0%, cell accuracy: 48.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.9431, G loss: 0.2995\n",
      "[84/1762] D loss: 1.9503, G loss: 0.2889\n",
      "[164/1762] D loss: 1.8669, G loss: 0.3278\n",
      "[244/1762] D loss: 1.9218, G loss: 0.2889\n",
      "[324/1762] D loss: 1.9075, G loss: 0.3037\n",
      "[404/1762] D loss: 1.9237, G loss: 0.3006\n",
      "[484/1762] D loss: 1.8975, G loss: 0.2956\n",
      "[564/1762] D loss: 1.9187, G loss: 0.2953\n",
      "[644/1762] D loss: 1.9537, G loss: 0.2887\n",
      "[724/1762] D loss: 1.9226, G loss: 0.3032\n",
      "[804/1762] D loss: 1.9146, G loss: 0.2938\n",
      "[884/1762] D loss: 1.9548, G loss: 0.2791\n",
      "[964/1762] D loss: 1.9030, G loss: 0.3062\n",
      "[1044/1762] D loss: 1.8664, G loss: 0.3129\n",
      "[1124/1762] D loss: 1.9196, G loss: 0.2928\n",
      "[1204/1762] D loss: 1.9303, G loss: 0.2887\n",
      "[1284/1762] D loss: 1.9934, G loss: 0.2722\n",
      "[1364/1762] D loss: 1.9733, G loss: 0.2869\n",
      "[1444/1762] D loss: 1.9459, G loss: 0.2863\n",
      "[1524/1762] D loss: 1.9393, G loss: 0.2846\n",
      "[1604/1762] D loss: 1.9370, G loss: 0.2818\n",
      "[1684/1762] D loss: 1.9497, G loss: 0.2853\n",
      "[1762/1762] D loss: 1.8853, G loss: 0.3065\n",
      "train error: \n",
      " D loss: 1.955153, G loss: 0.285020, D accuracy: 50.0%, cell accuracy: 49.8%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.945764, G loss: 0.288153, D accuracy: 50.0%, cell accuracy: 49.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.9847, G loss: 0.2722\n",
      "[84/1762] D loss: 1.8792, G loss: 0.3116\n",
      "[164/1762] D loss: 1.8540, G loss: 0.3302\n",
      "[244/1762] D loss: 1.9522, G loss: 0.2903\n",
      "[324/1762] D loss: 1.9430, G loss: 0.2872\n",
      "[404/1762] D loss: 1.9898, G loss: 0.2807\n",
      "[484/1762] D loss: 1.9067, G loss: 0.3056\n",
      "[564/1762] D loss: 1.9139, G loss: 0.2890\n",
      "[644/1762] D loss: 1.9490, G loss: 0.2885\n",
      "[724/1762] D loss: 1.9817, G loss: 0.2744\n",
      "[804/1762] D loss: 1.9732, G loss: 0.2698\n",
      "[884/1762] D loss: 1.9345, G loss: 0.2932\n",
      "[964/1762] D loss: 1.9152, G loss: 0.3006\n",
      "[1044/1762] D loss: 1.9291, G loss: 0.2934\n",
      "[1124/1762] D loss: 1.9689, G loss: 0.2791\n",
      "[1204/1762] D loss: 1.9248, G loss: 0.3018\n",
      "[1284/1762] D loss: 1.9633, G loss: 0.2814\n",
      "[1364/1762] D loss: 1.8785, G loss: 0.3129\n",
      "[1444/1762] D loss: 1.9068, G loss: 0.3079\n",
      "[1524/1762] D loss: 1.9499, G loss: 0.2849\n",
      "[1604/1762] D loss: 1.8956, G loss: 0.3112\n",
      "[1684/1762] D loss: 1.9665, G loss: 0.2755\n",
      "[1762/1762] D loss: 1.9865, G loss: 0.2768\n",
      "train error: \n",
      " D loss: 1.956353, G loss: 0.283626, D accuracy: 50.0%, cell accuracy: 50.2%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.949640, G loss: 0.285853, D accuracy: 50.0%, cell accuracy: 50.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.9738, G loss: 0.2697\n",
      "[84/1762] D loss: 1.9477, G loss: 0.2880\n",
      "[164/1762] D loss: 1.9546, G loss: 0.2933\n",
      "[244/1762] D loss: 1.9366, G loss: 0.2969\n",
      "[324/1762] D loss: 1.9612, G loss: 0.2846\n",
      "[404/1762] D loss: 1.9300, G loss: 0.2878\n",
      "[484/1762] D loss: 1.9481, G loss: 0.2800\n",
      "[564/1762] D loss: 1.9333, G loss: 0.2880\n",
      "[644/1762] D loss: 1.9830, G loss: 0.2804\n",
      "[724/1762] D loss: 1.9672, G loss: 0.2829\n",
      "[804/1762] D loss: 1.9188, G loss: 0.2950\n",
      "[884/1762] D loss: 1.9837, G loss: 0.2749\n",
      "[964/1762] D loss: 1.9965, G loss: 0.2645\n",
      "[1044/1762] D loss: 1.9478, G loss: 0.2941\n",
      "[1124/1762] D loss: 1.8858, G loss: 0.3192\n",
      "[1204/1762] D loss: 2.0030, G loss: 0.2609\n",
      "[1284/1762] D loss: 1.9481, G loss: 0.2951\n",
      "[1364/1762] D loss: 1.9748, G loss: 0.2676\n",
      "[1444/1762] D loss: 1.9308, G loss: 0.2999\n",
      "[1524/1762] D loss: 2.0205, G loss: 0.2579\n",
      "[1604/1762] D loss: 1.9270, G loss: 0.2976\n",
      "[1684/1762] D loss: 2.0062, G loss: 0.2620\n",
      "[1762/1762] D loss: 1.9196, G loss: 0.3019\n",
      "train error: \n",
      " D loss: 1.979336, G loss: 0.276506, D accuracy: 50.0%, cell accuracy: 49.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.971035, G loss: 0.279114, D accuracy: 50.0%, cell accuracy: 49.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.0005, G loss: 0.2701\n",
      "[84/1762] D loss: 2.0126, G loss: 0.2676\n",
      "[164/1762] D loss: 1.9641, G loss: 0.2850\n",
      "[244/1762] D loss: 1.9799, G loss: 0.2750\n",
      "[324/1762] D loss: 1.9683, G loss: 0.2775\n",
      "[404/1762] D loss: 1.9535, G loss: 0.2908\n",
      "[484/1762] D loss: 1.9922, G loss: 0.2611\n",
      "[564/1762] D loss: 1.9264, G loss: 0.2947\n",
      "[644/1762] D loss: 1.9568, G loss: 0.2899\n",
      "[724/1762] D loss: 1.9558, G loss: 0.2846\n",
      "[804/1762] D loss: 1.9484, G loss: 0.2900\n",
      "[884/1762] D loss: 1.9531, G loss: 0.2825\n",
      "[964/1762] D loss: 1.9923, G loss: 0.2746\n",
      "[1044/1762] D loss: 1.9606, G loss: 0.2779\n",
      "[1124/1762] D loss: 1.9577, G loss: 0.2830\n",
      "[1204/1762] D loss: 1.8902, G loss: 0.3185\n",
      "[1284/1762] D loss: 1.9135, G loss: 0.2989\n",
      "[1364/1762] D loss: 1.9608, G loss: 0.2771\n",
      "[1444/1762] D loss: 1.9751, G loss: 0.2726\n",
      "[1524/1762] D loss: 1.9788, G loss: 0.2721\n",
      "[1604/1762] D loss: 1.9968, G loss: 0.2638\n",
      "[1684/1762] D loss: 1.9627, G loss: 0.2855\n",
      "[1762/1762] D loss: 1.9695, G loss: 0.2809\n",
      "train error: \n",
      " D loss: 1.988827, G loss: 0.275031, D accuracy: 50.0%, cell accuracy: 50.8%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.980802, G loss: 0.277602, D accuracy: 50.0%, cell accuracy: 50.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.9644, G loss: 0.2751\n",
      "[84/1762] D loss: 1.9680, G loss: 0.2843\n",
      "[164/1762] D loss: 1.9365, G loss: 0.2934\n",
      "[244/1762] D loss: 1.9846, G loss: 0.2766\n",
      "[324/1762] D loss: 1.9911, G loss: 0.2723\n",
      "[404/1762] D loss: 1.9799, G loss: 0.2707\n",
      "[484/1762] D loss: 1.9691, G loss: 0.2821\n",
      "[564/1762] D loss: 1.9704, G loss: 0.2777\n",
      "[644/1762] D loss: 2.0121, G loss: 0.2594\n",
      "[724/1762] D loss: 2.0949, G loss: 0.2412\n",
      "[804/1762] D loss: 1.9449, G loss: 0.2847\n",
      "[884/1762] D loss: 1.9822, G loss: 0.2751\n",
      "[964/1762] D loss: 1.9463, G loss: 0.2882\n",
      "[1044/1762] D loss: 1.9753, G loss: 0.2806\n",
      "[1124/1762] D loss: 1.9894, G loss: 0.2701\n",
      "[1204/1762] D loss: 2.0171, G loss: 0.2627\n",
      "[1284/1762] D loss: 2.0014, G loss: 0.2775\n",
      "[1364/1762] D loss: 1.9699, G loss: 0.2729\n",
      "[1444/1762] D loss: 1.9365, G loss: 0.2809\n",
      "[1524/1762] D loss: 1.9783, G loss: 0.2800\n",
      "[1604/1762] D loss: 1.8877, G loss: 0.3052\n",
      "[1684/1762] D loss: 1.9643, G loss: 0.2757\n",
      "[1762/1762] D loss: 1.9709, G loss: 0.2717\n",
      "train error: \n",
      " D loss: 1.979845, G loss: 0.277684, D accuracy: 50.0%, cell accuracy: 48.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.972251, G loss: 0.280155, D accuracy: 50.0%, cell accuracy: 49.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.9896, G loss: 0.2752\n",
      "[84/1762] D loss: 2.0335, G loss: 0.2573\n",
      "[164/1762] D loss: 1.9592, G loss: 0.2810\n",
      "[244/1762] D loss: 1.9386, G loss: 0.2901\n",
      "[324/1762] D loss: 1.9592, G loss: 0.2926\n",
      "[404/1762] D loss: 1.9839, G loss: 0.2705\n",
      "[484/1762] D loss: 1.9626, G loss: 0.2755\n",
      "[564/1762] D loss: 2.0397, G loss: 0.2552\n",
      "[644/1762] D loss: 2.0154, G loss: 0.2581\n",
      "[724/1762] D loss: 1.9884, G loss: 0.2759\n",
      "[804/1762] D loss: 1.9606, G loss: 0.2821\n",
      "[884/1762] D loss: 1.9508, G loss: 0.2887\n",
      "[964/1762] D loss: 1.8851, G loss: 0.3191\n",
      "[1044/1762] D loss: 1.9595, G loss: 0.2771\n",
      "[1124/1762] D loss: 1.9277, G loss: 0.2954\n",
      "[1204/1762] D loss: 1.9975, G loss: 0.2656\n",
      "[1284/1762] D loss: 1.9759, G loss: 0.2875\n",
      "[1364/1762] D loss: 2.0454, G loss: 0.2457\n",
      "[1444/1762] D loss: 1.9254, G loss: 0.2930\n",
      "[1524/1762] D loss: 1.9922, G loss: 0.2701\n",
      "[1604/1762] D loss: 1.9388, G loss: 0.2903\n",
      "[1684/1762] D loss: 1.9569, G loss: 0.2745\n",
      "[1762/1762] D loss: 1.9553, G loss: 0.2883\n",
      "train error: \n",
      " D loss: 1.984940, G loss: 0.276323, D accuracy: 50.0%, cell accuracy: 50.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.977155, G loss: 0.278833, D accuracy: 50.0%, cell accuracy: 50.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.9983, G loss: 0.2731\n",
      "[84/1762] D loss: 1.8829, G loss: 0.3095\n",
      "[164/1762] D loss: 2.0112, G loss: 0.2620\n",
      "[244/1762] D loss: 1.9944, G loss: 0.2652\n",
      "[324/1762] D loss: 1.9844, G loss: 0.2738\n",
      "[404/1762] D loss: 1.9613, G loss: 0.2754\n",
      "[484/1762] D loss: 2.0049, G loss: 0.2674\n",
      "[564/1762] D loss: 2.0114, G loss: 0.2660\n",
      "[644/1762] D loss: 1.9681, G loss: 0.2671\n",
      "[724/1762] D loss: 1.9606, G loss: 0.2820\n",
      "[804/1762] D loss: 1.9922, G loss: 0.2672\n",
      "[884/1762] D loss: 1.9415, G loss: 0.2843\n",
      "[964/1762] D loss: 2.0211, G loss: 0.2659\n",
      "[1044/1762] D loss: 2.0276, G loss: 0.2626\n",
      "[1124/1762] D loss: 1.9441, G loss: 0.2975\n",
      "[1204/1762] D loss: 1.9850, G loss: 0.2789\n",
      "[1284/1762] D loss: 2.0012, G loss: 0.2664\n",
      "[1364/1762] D loss: 1.9728, G loss: 0.2809\n",
      "[1444/1762] D loss: 2.0344, G loss: 0.2586\n",
      "[1524/1762] D loss: 1.9931, G loss: 0.2659\n",
      "[1604/1762] D loss: 2.0357, G loss: 0.2591\n",
      "[1684/1762] D loss: 1.9629, G loss: 0.2860\n",
      "[1762/1762] D loss: 1.9482, G loss: 0.2730\n",
      "train error: \n",
      " D loss: 1.997861, G loss: 0.272064, D accuracy: 50.0%, cell accuracy: 50.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.990653, G loss: 0.274342, D accuracy: 50.0%, cell accuracy: 50.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.9841, G loss: 0.2768\n",
      "[84/1762] D loss: 1.9722, G loss: 0.2771\n",
      "[164/1762] D loss: 1.9809, G loss: 0.2702\n",
      "[244/1762] D loss: 2.0117, G loss: 0.2718\n",
      "[324/1762] D loss: 2.0122, G loss: 0.2587\n",
      "[404/1762] D loss: 1.9154, G loss: 0.3018\n",
      "[484/1762] D loss: 1.9648, G loss: 0.2902\n",
      "[564/1762] D loss: 1.9520, G loss: 0.2820\n",
      "[644/1762] D loss: 1.9566, G loss: 0.2941\n",
      "[724/1762] D loss: 2.0240, G loss: 0.2668\n",
      "[804/1762] D loss: 1.9863, G loss: 0.2679\n",
      "[884/1762] D loss: 2.0195, G loss: 0.2724\n",
      "[964/1762] D loss: 2.0134, G loss: 0.2641\n",
      "[1044/1762] D loss: 2.0300, G loss: 0.2599\n",
      "[1124/1762] D loss: 1.9577, G loss: 0.2803\n",
      "[1204/1762] D loss: 1.9575, G loss: 0.2958\n",
      "[1284/1762] D loss: 1.9824, G loss: 0.2709\n",
      "[1364/1762] D loss: 1.9725, G loss: 0.2784\n",
      "[1444/1762] D loss: 2.0008, G loss: 0.2608\n",
      "[1524/1762] D loss: 2.0452, G loss: 0.2532\n",
      "[1604/1762] D loss: 2.0327, G loss: 0.2628\n",
      "[1684/1762] D loss: 1.9218, G loss: 0.2927\n",
      "[1762/1762] D loss: 1.9769, G loss: 0.2706\n",
      "train error: \n",
      " D loss: 1.984426, G loss: 0.277805, D accuracy: 50.0%, cell accuracy: 50.6%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.977963, G loss: 0.279972, D accuracy: 50.0%, cell accuracy: 50.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.0097, G loss: 0.2743\n",
      "[84/1762] D loss: 1.9999, G loss: 0.2672\n",
      "[164/1762] D loss: 1.9415, G loss: 0.2840\n",
      "[244/1762] D loss: 1.9680, G loss: 0.2791\n",
      "[324/1762] D loss: 2.0080, G loss: 0.2689\n",
      "[404/1762] D loss: 1.9893, G loss: 0.2702\n",
      "[484/1762] D loss: 2.0103, G loss: 0.2625\n",
      "[564/1762] D loss: 2.0238, G loss: 0.2629\n",
      "[644/1762] D loss: 1.9447, G loss: 0.2979\n",
      "[724/1762] D loss: 2.0720, G loss: 0.2472\n",
      "[804/1762] D loss: 1.9974, G loss: 0.2792\n",
      "[884/1762] D loss: 2.0421, G loss: 0.2508\n",
      "[964/1762] D loss: 1.9822, G loss: 0.2842\n",
      "[1044/1762] D loss: 1.9681, G loss: 0.2794\n",
      "[1124/1762] D loss: 1.9491, G loss: 0.2860\n",
      "[1204/1762] D loss: 2.0294, G loss: 0.2513\n",
      "[1284/1762] D loss: 1.9892, G loss: 0.2859\n",
      "[1364/1762] D loss: 2.0090, G loss: 0.2678\n",
      "[1444/1762] D loss: 2.0142, G loss: 0.2688\n",
      "[1524/1762] D loss: 1.9041, G loss: 0.3030\n",
      "[1604/1762] D loss: 1.9134, G loss: 0.3100\n",
      "[1684/1762] D loss: 1.9673, G loss: 0.2800\n",
      "[1762/1762] D loss: 1.9506, G loss: 0.2876\n",
      "train error: \n",
      " D loss: 2.006711, G loss: 0.269177, D accuracy: 50.0%, cell accuracy: 49.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.000306, G loss: 0.271194, D accuracy: 50.0%, cell accuracy: 49.8%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.9308, G loss: 0.2974\n",
      "[84/1762] D loss: 2.0200, G loss: 0.2602\n",
      "[164/1762] D loss: 1.9591, G loss: 0.2855\n",
      "[244/1762] D loss: 2.0148, G loss: 0.2623\n",
      "[324/1762] D loss: 1.9790, G loss: 0.2837\n",
      "[404/1762] D loss: 1.9431, G loss: 0.2989\n",
      "[484/1762] D loss: 2.0224, G loss: 0.2587\n",
      "[564/1762] D loss: 2.0655, G loss: 0.2418\n",
      "[644/1762] D loss: 1.9392, G loss: 0.3025\n",
      "[724/1762] D loss: 2.0438, G loss: 0.2516\n",
      "[804/1762] D loss: 2.0226, G loss: 0.2621\n",
      "[884/1762] D loss: 1.9848, G loss: 0.2658\n",
      "[964/1762] D loss: 2.0079, G loss: 0.2805\n",
      "[1044/1762] D loss: 2.0225, G loss: 0.2632\n",
      "[1124/1762] D loss: 2.0183, G loss: 0.2549\n",
      "[1204/1762] D loss: 1.9600, G loss: 0.2857\n",
      "[1284/1762] D loss: 2.0508, G loss: 0.2553\n",
      "[1364/1762] D loss: 2.0618, G loss: 0.2465\n",
      "[1444/1762] D loss: 1.9893, G loss: 0.2779\n",
      "[1524/1762] D loss: 2.0220, G loss: 0.2730\n",
      "[1604/1762] D loss: 1.9785, G loss: 0.2772\n",
      "[1684/1762] D loss: 1.9764, G loss: 0.2790\n",
      "[1762/1762] D loss: 1.9929, G loss: 0.2760\n",
      "train error: \n",
      " D loss: 2.023348, G loss: 0.262967, D accuracy: 50.0%, cell accuracy: 48.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.015373, G loss: 0.265343, D accuracy: 50.0%, cell accuracy: 48.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.0576, G loss: 0.2459\n",
      "[84/1762] D loss: 1.9925, G loss: 0.2709\n",
      "[164/1762] D loss: 1.9542, G loss: 0.2867\n",
      "[244/1762] D loss: 1.9826, G loss: 0.2771\n",
      "[324/1762] D loss: 2.0015, G loss: 0.2690\n",
      "[404/1762] D loss: 1.9977, G loss: 0.2627\n",
      "[484/1762] D loss: 1.9909, G loss: 0.2788\n",
      "[564/1762] D loss: 2.0788, G loss: 0.2433\n",
      "[644/1762] D loss: 1.9884, G loss: 0.2732\n",
      "[724/1762] D loss: 1.9964, G loss: 0.2753\n",
      "[804/1762] D loss: 1.9499, G loss: 0.2885\n",
      "[884/1762] D loss: 2.0665, G loss: 0.2503\n",
      "[964/1762] D loss: 2.0262, G loss: 0.2623\n",
      "[1044/1762] D loss: 2.0003, G loss: 0.2651\n",
      "[1124/1762] D loss: 2.0460, G loss: 0.2556\n",
      "[1204/1762] D loss: 2.0393, G loss: 0.2532\n",
      "[1284/1762] D loss: 1.9783, G loss: 0.2781\n",
      "[1364/1762] D loss: 2.0278, G loss: 0.2615\n",
      "[1444/1762] D loss: 1.9664, G loss: 0.2772\n",
      "[1524/1762] D loss: 1.9634, G loss: 0.2846\n",
      "[1604/1762] D loss: 2.0200, G loss: 0.2576\n",
      "[1684/1762] D loss: 1.9428, G loss: 0.2960\n",
      "[1762/1762] D loss: 1.9500, G loss: 0.2939\n",
      "train error: \n",
      " D loss: 2.046565, G loss: 0.254382, D accuracy: 50.0%, cell accuracy: 49.8%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.037311, G loss: 0.256970, D accuracy: 50.0%, cell accuracy: 50.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.0289, G loss: 0.2622\n",
      "[84/1762] D loss: 2.0176, G loss: 0.2626\n",
      "[164/1762] D loss: 2.0187, G loss: 0.2620\n",
      "[244/1762] D loss: 2.0177, G loss: 0.2663\n",
      "[324/1762] D loss: 2.0176, G loss: 0.2626\n",
      "[404/1762] D loss: 1.9801, G loss: 0.2795\n",
      "[484/1762] D loss: 2.0037, G loss: 0.2700\n",
      "[564/1762] D loss: 1.9749, G loss: 0.2805\n",
      "[644/1762] D loss: 1.9859, G loss: 0.2802\n",
      "[724/1762] D loss: 2.0863, G loss: 0.2404\n",
      "[804/1762] D loss: 2.0172, G loss: 0.2669\n",
      "[884/1762] D loss: 2.0201, G loss: 0.2599\n",
      "[964/1762] D loss: 2.0410, G loss: 0.2583\n",
      "[1044/1762] D loss: 2.0444, G loss: 0.2585\n",
      "[1124/1762] D loss: 2.0074, G loss: 0.2649\n",
      "[1204/1762] D loss: 1.9887, G loss: 0.2696\n",
      "[1284/1762] D loss: 2.0280, G loss: 0.2523\n",
      "[1364/1762] D loss: 2.0011, G loss: 0.2624\n",
      "[1444/1762] D loss: 2.0305, G loss: 0.2525\n",
      "[1524/1762] D loss: 2.0451, G loss: 0.2530\n",
      "[1604/1762] D loss: 2.0029, G loss: 0.2702\n",
      "[1684/1762] D loss: 2.0570, G loss: 0.2450\n",
      "[1762/1762] D loss: 2.0316, G loss: 0.2585\n",
      "train error: \n",
      " D loss: 2.022377, G loss: 0.263273, D accuracy: 50.0%, cell accuracy: 50.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.012463, G loss: 0.266205, D accuracy: 50.0%, cell accuracy: 50.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.9956, G loss: 0.2764\n",
      "[84/1762] D loss: 2.0095, G loss: 0.2601\n",
      "[164/1762] D loss: 2.0330, G loss: 0.2578\n",
      "[244/1762] D loss: 1.9804, G loss: 0.2744\n",
      "[324/1762] D loss: 2.0430, G loss: 0.2576\n",
      "[404/1762] D loss: 1.9298, G loss: 0.3048\n",
      "[484/1762] D loss: 2.0054, G loss: 0.2695\n",
      "[564/1762] D loss: 2.0266, G loss: 0.2609\n",
      "[644/1762] D loss: 2.0166, G loss: 0.2765\n",
      "[724/1762] D loss: 2.0106, G loss: 0.2667\n",
      "[804/1762] D loss: 2.0037, G loss: 0.2668\n",
      "[884/1762] D loss: 1.9988, G loss: 0.2674\n",
      "[964/1762] D loss: 1.9622, G loss: 0.2800\n",
      "[1044/1762] D loss: 2.0016, G loss: 0.2605\n",
      "[1124/1762] D loss: 2.0150, G loss: 0.2580\n",
      "[1204/1762] D loss: 2.0331, G loss: 0.2602\n",
      "[1284/1762] D loss: 2.0733, G loss: 0.2395\n",
      "[1364/1762] D loss: 1.9742, G loss: 0.2865\n",
      "[1444/1762] D loss: 2.0290, G loss: 0.2595\n",
      "[1524/1762] D loss: 2.0252, G loss: 0.2650\n",
      "[1604/1762] D loss: 2.0309, G loss: 0.2575\n",
      "[1684/1762] D loss: 2.0432, G loss: 0.2529\n",
      "[1762/1762] D loss: 1.8620, G loss: 0.3353\n",
      "train error: \n",
      " D loss: 2.041842, G loss: 0.257907, D accuracy: 50.0%, cell accuracy: 50.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.033744, G loss: 0.260247, D accuracy: 50.0%, cell accuracy: 50.8%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.0858, G loss: 0.2412\n",
      "[84/1762] D loss: 2.0261, G loss: 0.2542\n",
      "[164/1762] D loss: 1.9847, G loss: 0.2677\n",
      "[244/1762] D loss: 1.9911, G loss: 0.2668\n",
      "[324/1762] D loss: 2.0002, G loss: 0.2704\n",
      "[404/1762] D loss: 2.0083, G loss: 0.2701\n",
      "[484/1762] D loss: 1.9355, G loss: 0.2888\n",
      "[564/1762] D loss: 1.9611, G loss: 0.2853\n",
      "[644/1762] D loss: 2.0304, G loss: 0.2542\n",
      "[724/1762] D loss: 2.0294, G loss: 0.2698\n",
      "[804/1762] D loss: 2.0155, G loss: 0.2649\n",
      "[884/1762] D loss: 2.0295, G loss: 0.2595\n",
      "[964/1762] D loss: 1.9686, G loss: 0.2944\n",
      "[1044/1762] D loss: 2.0413, G loss: 0.2574\n",
      "[1124/1762] D loss: 2.0295, G loss: 0.2557\n",
      "[1204/1762] D loss: 2.0226, G loss: 0.2710\n",
      "[1284/1762] D loss: 2.0090, G loss: 0.2696\n",
      "[1364/1762] D loss: 2.0191, G loss: 0.2695\n",
      "[1444/1762] D loss: 1.9811, G loss: 0.2784\n",
      "[1524/1762] D loss: 2.0329, G loss: 0.2625\n",
      "[1604/1762] D loss: 2.0459, G loss: 0.2619\n",
      "[1684/1762] D loss: 1.9992, G loss: 0.2785\n",
      "[1762/1762] D loss: 1.9642, G loss: 0.2849\n",
      "train error: \n",
      " D loss: 2.036526, G loss: 0.259492, D accuracy: 50.0%, cell accuracy: 49.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.025575, G loss: 0.262700, D accuracy: 50.0%, cell accuracy: 50.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.9760, G loss: 0.2824\n",
      "[84/1762] D loss: 2.0122, G loss: 0.2724\n",
      "[164/1762] D loss: 2.0136, G loss: 0.2587\n",
      "[244/1762] D loss: 1.9996, G loss: 0.2672\n",
      "[324/1762] D loss: 2.0047, G loss: 0.2654\n",
      "[404/1762] D loss: 2.0167, G loss: 0.2719\n",
      "[484/1762] D loss: 2.0235, G loss: 0.2550\n",
      "[564/1762] D loss: 2.0406, G loss: 0.2551\n",
      "[644/1762] D loss: 1.9779, G loss: 0.2802\n",
      "[724/1762] D loss: 1.9627, G loss: 0.2803\n",
      "[804/1762] D loss: 2.0689, G loss: 0.2436\n",
      "[884/1762] D loss: 1.9862, G loss: 0.2828\n",
      "[964/1762] D loss: 2.0255, G loss: 0.2576\n",
      "[1044/1762] D loss: 2.0657, G loss: 0.2559\n",
      "[1124/1762] D loss: 2.0269, G loss: 0.2565\n",
      "[1204/1762] D loss: 2.0091, G loss: 0.2618\n",
      "[1284/1762] D loss: 2.0076, G loss: 0.2662\n",
      "[1364/1762] D loss: 2.0566, G loss: 0.2421\n",
      "[1444/1762] D loss: 2.0055, G loss: 0.2767\n",
      "[1524/1762] D loss: 1.9795, G loss: 0.2816\n",
      "[1604/1762] D loss: 2.0325, G loss: 0.2478\n",
      "[1684/1762] D loss: 1.9748, G loss: 0.2756\n",
      "[1762/1762] D loss: 2.1104, G loss: 0.2318\n",
      "train error: \n",
      " D loss: 2.043810, G loss: 0.257208, D accuracy: 50.0%, cell accuracy: 50.0%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.034376, G loss: 0.259891, D accuracy: 50.0%, cell accuracy: 50.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.1031, G loss: 0.2330\n",
      "[84/1762] D loss: 2.0339, G loss: 0.2479\n",
      "[164/1762] D loss: 2.0117, G loss: 0.2709\n",
      "[244/1762] D loss: 2.0520, G loss: 0.2492\n",
      "[324/1762] D loss: 1.9885, G loss: 0.2667\n",
      "[404/1762] D loss: 2.0052, G loss: 0.2584\n",
      "[484/1762] D loss: 2.0044, G loss: 0.2650\n",
      "[564/1762] D loss: 2.1141, G loss: 0.2346\n",
      "[644/1762] D loss: 2.0407, G loss: 0.2519\n",
      "[724/1762] D loss: 2.0460, G loss: 0.2578\n",
      "[804/1762] D loss: 2.0126, G loss: 0.2630\n",
      "[884/1762] D loss: 2.0859, G loss: 0.2410\n",
      "[964/1762] D loss: 2.0247, G loss: 0.2558\n",
      "[1044/1762] D loss: 1.9354, G loss: 0.2892\n",
      "[1124/1762] D loss: 2.0320, G loss: 0.2566\n",
      "[1204/1762] D loss: 2.0515, G loss: 0.2537\n",
      "[1284/1762] D loss: 1.9991, G loss: 0.2799\n",
      "[1364/1762] D loss: 2.0483, G loss: 0.2611\n",
      "[1444/1762] D loss: 2.0212, G loss: 0.2535\n",
      "[1524/1762] D loss: 1.9887, G loss: 0.2762\n",
      "[1604/1762] D loss: 1.9899, G loss: 0.2771\n",
      "[1684/1762] D loss: 2.0435, G loss: 0.2565\n",
      "[1762/1762] D loss: 2.0159, G loss: 0.2701\n",
      "train error: \n",
      " D loss: 2.033182, G loss: 0.261294, D accuracy: 50.0%, cell accuracy: 50.8%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.024765, G loss: 0.263822, D accuracy: 50.0%, cell accuracy: 50.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.0921, G loss: 0.2449\n",
      "[84/1762] D loss: 1.9839, G loss: 0.2706\n",
      "[164/1762] D loss: 2.0389, G loss: 0.2657\n",
      "[244/1762] D loss: 1.9858, G loss: 0.2739\n",
      "[324/1762] D loss: 2.0479, G loss: 0.2540\n",
      "[404/1762] D loss: 2.0836, G loss: 0.2408\n",
      "[484/1762] D loss: 2.0743, G loss: 0.2521\n",
      "[564/1762] D loss: 2.0793, G loss: 0.2373\n",
      "[644/1762] D loss: 2.0103, G loss: 0.2667\n",
      "[724/1762] D loss: 2.0065, G loss: 0.2629\n",
      "[804/1762] D loss: 2.0045, G loss: 0.2723\n",
      "[884/1762] D loss: 2.0498, G loss: 0.2528\n",
      "[964/1762] D loss: 2.0022, G loss: 0.2647\n",
      "[1044/1762] D loss: 2.0012, G loss: 0.2712\n",
      "[1124/1762] D loss: 2.1023, G loss: 0.2365\n",
      "[1204/1762] D loss: 1.9846, G loss: 0.2773\n",
      "[1284/1762] D loss: 2.0402, G loss: 0.2591\n",
      "[1364/1762] D loss: 2.0257, G loss: 0.2714\n",
      "[1444/1762] D loss: 2.0026, G loss: 0.2729\n",
      "[1524/1762] D loss: 2.0309, G loss: 0.2625\n",
      "[1604/1762] D loss: 2.0496, G loss: 0.2597\n",
      "[1684/1762] D loss: 2.0204, G loss: 0.2611\n",
      "[1762/1762] D loss: 1.9302, G loss: 0.2981\n",
      "train error: \n",
      " D loss: 2.044010, G loss: 0.257988, D accuracy: 50.0%, cell accuracy: 49.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.034586, G loss: 0.260742, D accuracy: 50.0%, cell accuracy: 49.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.0339, G loss: 0.2505\n",
      "[84/1762] D loss: 2.0044, G loss: 0.2658\n",
      "[164/1762] D loss: 2.0869, G loss: 0.2382\n",
      "[244/1762] D loss: 2.0137, G loss: 0.2718\n",
      "[324/1762] D loss: 2.0426, G loss: 0.2535\n",
      "[404/1762] D loss: 1.9870, G loss: 0.2713\n",
      "[484/1762] D loss: 2.0792, G loss: 0.2448\n",
      "[564/1762] D loss: 1.9853, G loss: 0.2731\n",
      "[644/1762] D loss: 2.0203, G loss: 0.2561\n",
      "[724/1762] D loss: 1.9479, G loss: 0.2972\n",
      "[804/1762] D loss: 2.0206, G loss: 0.2672\n",
      "[884/1762] D loss: 2.0409, G loss: 0.2568\n",
      "[964/1762] D loss: 2.0604, G loss: 0.2474\n",
      "[1044/1762] D loss: 2.0258, G loss: 0.2584\n",
      "[1124/1762] D loss: 1.9948, G loss: 0.2699\n",
      "[1204/1762] D loss: 2.0520, G loss: 0.2563\n",
      "[1284/1762] D loss: 2.1028, G loss: 0.2360\n",
      "[1364/1762] D loss: 2.0442, G loss: 0.2614\n",
      "[1444/1762] D loss: 2.0414, G loss: 0.2558\n",
      "[1524/1762] D loss: 1.9888, G loss: 0.2749\n",
      "[1604/1762] D loss: 2.0350, G loss: 0.2596\n",
      "[1684/1762] D loss: 1.9632, G loss: 0.2865\n",
      "[1762/1762] D loss: 1.9840, G loss: 0.2727\n",
      "train error: \n",
      " D loss: 2.039635, G loss: 0.258422, D accuracy: 50.0%, cell accuracy: 49.8%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.029911, G loss: 0.261228, D accuracy: 50.0%, cell accuracy: 50.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.0575, G loss: 0.2513\n",
      "[84/1762] D loss: 2.0516, G loss: 0.2506\n",
      "[164/1762] D loss: 2.0141, G loss: 0.2554\n",
      "[244/1762] D loss: 2.0236, G loss: 0.2560\n",
      "[324/1762] D loss: 2.0906, G loss: 0.2436\n",
      "[404/1762] D loss: 2.0371, G loss: 0.2523\n",
      "[484/1762] D loss: 2.0033, G loss: 0.2683\n",
      "[564/1762] D loss: 2.0438, G loss: 0.2613\n",
      "[644/1762] D loss: 2.0389, G loss: 0.2571\n",
      "[724/1762] D loss: 1.9830, G loss: 0.2767\n",
      "[804/1762] D loss: 2.0594, G loss: 0.2583\n",
      "[884/1762] D loss: 2.0663, G loss: 0.2491\n",
      "[964/1762] D loss: 2.0902, G loss: 0.2383\n",
      "[1044/1762] D loss: 1.9987, G loss: 0.2722\n",
      "[1124/1762] D loss: 2.0161, G loss: 0.2732\n",
      "[1204/1762] D loss: 2.0524, G loss: 0.2531\n",
      "[1284/1762] D loss: 1.9882, G loss: 0.2663\n",
      "[1364/1762] D loss: 1.9979, G loss: 0.2660\n",
      "[1444/1762] D loss: 2.0795, G loss: 0.2437\n",
      "[1524/1762] D loss: 2.0206, G loss: 0.2578\n",
      "[1604/1762] D loss: 2.0277, G loss: 0.2601\n",
      "[1684/1762] D loss: 1.9551, G loss: 0.2869\n",
      "[1762/1762] D loss: 2.0818, G loss: 0.2399\n",
      "train error: \n",
      " D loss: 2.035327, G loss: 0.260478, D accuracy: 50.0%, cell accuracy: 50.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.026260, G loss: 0.263221, D accuracy: 50.0%, cell accuracy: 50.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.0085, G loss: 0.2775\n",
      "[84/1762] D loss: 2.0111, G loss: 0.2660\n",
      "[164/1762] D loss: 2.0518, G loss: 0.2490\n",
      "[244/1762] D loss: 2.0165, G loss: 0.2644\n",
      "[324/1762] D loss: 2.0704, G loss: 0.2396\n",
      "[404/1762] D loss: 2.0778, G loss: 0.2434\n",
      "[484/1762] D loss: 2.0929, G loss: 0.2416\n",
      "[564/1762] D loss: 2.0501, G loss: 0.2500\n",
      "[644/1762] D loss: 1.9852, G loss: 0.2803\n",
      "[724/1762] D loss: 2.0087, G loss: 0.2636\n",
      "[804/1762] D loss: 2.0412, G loss: 0.2585\n",
      "[884/1762] D loss: 2.0195, G loss: 0.2659\n",
      "[964/1762] D loss: 2.0893, G loss: 0.2359\n",
      "[1044/1762] D loss: 2.0367, G loss: 0.2619\n",
      "[1124/1762] D loss: 2.0087, G loss: 0.2651\n",
      "[1204/1762] D loss: 2.0950, G loss: 0.2413\n",
      "[1284/1762] D loss: 2.0499, G loss: 0.2513\n",
      "[1364/1762] D loss: 2.0476, G loss: 0.2465\n",
      "[1444/1762] D loss: 2.0181, G loss: 0.2605\n",
      "[1524/1762] D loss: 2.0332, G loss: 0.2585\n",
      "[1604/1762] D loss: 2.0478, G loss: 0.2537\n",
      "[1684/1762] D loss: 2.0242, G loss: 0.2614\n",
      "[1762/1762] D loss: 2.0120, G loss: 0.2644\n",
      "train error: \n",
      " D loss: 2.049946, G loss: 0.256097, D accuracy: 50.0%, cell accuracy: 50.3%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.040871, G loss: 0.258797, D accuracy: 50.0%, cell accuracy: 50.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.0883, G loss: 0.2392\n",
      "[84/1762] D loss: 2.0375, G loss: 0.2619\n",
      "[164/1762] D loss: 1.9849, G loss: 0.2760\n",
      "[244/1762] D loss: 1.9453, G loss: 0.2983\n",
      "[324/1762] D loss: 2.0231, G loss: 0.2655\n",
      "[404/1762] D loss: 2.0088, G loss: 0.2772\n",
      "[484/1762] D loss: 2.1013, G loss: 0.2511\n",
      "[564/1762] D loss: 2.0318, G loss: 0.2550\n",
      "[644/1762] D loss: 2.0420, G loss: 0.2609\n",
      "[724/1762] D loss: 2.0230, G loss: 0.2689\n",
      "[804/1762] D loss: 2.0701, G loss: 0.2473\n",
      "[884/1762] D loss: 2.0239, G loss: 0.2649\n",
      "[964/1762] D loss: 1.9603, G loss: 0.2848\n",
      "[1044/1762] D loss: 2.0441, G loss: 0.2560\n",
      "[1124/1762] D loss: 2.0831, G loss: 0.2489\n",
      "[1204/1762] D loss: 2.0442, G loss: 0.2609\n",
      "[1284/1762] D loss: 2.0058, G loss: 0.2648\n",
      "[1364/1762] D loss: 2.0541, G loss: 0.2447\n",
      "[1444/1762] D loss: 1.9672, G loss: 0.2820\n",
      "[1524/1762] D loss: 1.9773, G loss: 0.2807\n",
      "[1604/1762] D loss: 2.0725, G loss: 0.2439\n",
      "[1684/1762] D loss: 2.0512, G loss: 0.2486\n",
      "[1762/1762] D loss: 2.0541, G loss: 0.2458\n",
      "train error: \n",
      " D loss: 2.053504, G loss: 0.254993, D accuracy: 50.0%, cell accuracy: 49.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.044208, G loss: 0.257711, D accuracy: 50.0%, cell accuracy: 49.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.0429, G loss: 0.2591\n",
      "[84/1762] D loss: 1.9846, G loss: 0.2885\n",
      "[164/1762] D loss: 2.0763, G loss: 0.2413\n",
      "[244/1762] D loss: 2.0757, G loss: 0.2498\n",
      "[324/1762] D loss: 2.0228, G loss: 0.2563\n",
      "[404/1762] D loss: 1.9665, G loss: 0.2786\n",
      "[484/1762] D loss: 1.9973, G loss: 0.2765\n",
      "[564/1762] D loss: 2.0069, G loss: 0.2729\n",
      "[644/1762] D loss: 1.9781, G loss: 0.2786\n",
      "[724/1762] D loss: 2.0445, G loss: 0.2535\n",
      "[804/1762] D loss: 2.0122, G loss: 0.2631\n",
      "[884/1762] D loss: 2.0711, G loss: 0.2506\n",
      "[964/1762] D loss: 1.9810, G loss: 0.2745\n",
      "[1044/1762] D loss: 1.9950, G loss: 0.2770\n",
      "[1124/1762] D loss: 1.9539, G loss: 0.2917\n",
      "[1204/1762] D loss: 2.0003, G loss: 0.2718\n",
      "[1284/1762] D loss: 2.0214, G loss: 0.2660\n",
      "[1364/1762] D loss: 1.9523, G loss: 0.2909\n",
      "[1444/1762] D loss: 2.0865, G loss: 0.2428\n",
      "[1524/1762] D loss: 2.0217, G loss: 0.2671\n",
      "[1604/1762] D loss: 2.0474, G loss: 0.2487\n",
      "[1684/1762] D loss: 2.0436, G loss: 0.2608\n",
      "[1762/1762] D loss: 1.9836, G loss: 0.2735\n",
      "train error: \n",
      " D loss: 2.066181, G loss: 0.250685, D accuracy: 50.0%, cell accuracy: 50.0%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.055318, G loss: 0.253721, D accuracy: 50.0%, cell accuracy: 50.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.0244, G loss: 0.2691\n",
      "[84/1762] D loss: 2.0859, G loss: 0.2434\n",
      "[164/1762] D loss: 2.0625, G loss: 0.2611\n",
      "[244/1762] D loss: 2.0395, G loss: 0.2567\n",
      "[324/1762] D loss: 2.0121, G loss: 0.2678\n",
      "[404/1762] D loss: 2.0481, G loss: 0.2449\n",
      "[484/1762] D loss: 1.9979, G loss: 0.2742\n",
      "[564/1762] D loss: 1.9867, G loss: 0.2764\n",
      "[644/1762] D loss: 2.0502, G loss: 0.2519\n",
      "[724/1762] D loss: 2.0097, G loss: 0.2703\n",
      "[804/1762] D loss: 2.0437, G loss: 0.2576\n",
      "[884/1762] D loss: 1.9864, G loss: 0.2763\n",
      "[964/1762] D loss: 2.1263, G loss: 0.2336\n",
      "[1044/1762] D loss: 2.0864, G loss: 0.2397\n",
      "[1124/1762] D loss: 1.9873, G loss: 0.2763\n",
      "[1204/1762] D loss: 2.0433, G loss: 0.2565\n",
      "[1284/1762] D loss: 2.0555, G loss: 0.2500\n",
      "[1364/1762] D loss: 2.0366, G loss: 0.2572\n",
      "[1444/1762] D loss: 1.9940, G loss: 0.2706\n",
      "[1524/1762] D loss: 2.0232, G loss: 0.2732\n",
      "[1604/1762] D loss: 2.0320, G loss: 0.2533\n",
      "[1684/1762] D loss: 2.0496, G loss: 0.2540\n",
      "[1762/1762] D loss: 2.0171, G loss: 0.2730\n",
      "train error: \n",
      " D loss: 2.073227, G loss: 0.248527, D accuracy: 50.0%, cell accuracy: 49.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.062727, G loss: 0.251470, D accuracy: 50.0%, cell accuracy: 50.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.9794, G loss: 0.2753\n",
      "[84/1762] D loss: 2.0873, G loss: 0.2478\n",
      "[164/1762] D loss: 2.0482, G loss: 0.2493\n",
      "[244/1762] D loss: 2.0863, G loss: 0.2398\n",
      "[324/1762] D loss: 2.0110, G loss: 0.2754\n",
      "[404/1762] D loss: 2.0528, G loss: 0.2474\n",
      "[484/1762] D loss: 2.0974, G loss: 0.2368\n",
      "[564/1762] D loss: 2.0420, G loss: 0.2528\n",
      "[644/1762] D loss: 2.0469, G loss: 0.2465\n",
      "[724/1762] D loss: 2.0240, G loss: 0.2598\n",
      "[804/1762] D loss: 2.0847, G loss: 0.2449\n",
      "[884/1762] D loss: 1.9959, G loss: 0.2768\n",
      "[964/1762] D loss: 2.0196, G loss: 0.2624\n",
      "[1044/1762] D loss: 1.9915, G loss: 0.2727\n",
      "[1124/1762] D loss: 2.0207, G loss: 0.2591\n",
      "[1204/1762] D loss: 1.9791, G loss: 0.2676\n",
      "[1284/1762] D loss: 1.9915, G loss: 0.2814\n",
      "[1364/1762] D loss: 2.0688, G loss: 0.2426\n",
      "[1444/1762] D loss: 2.1030, G loss: 0.2317\n",
      "[1524/1762] D loss: 2.0684, G loss: 0.2485\n",
      "[1604/1762] D loss: 2.0946, G loss: 0.2355\n",
      "[1684/1762] D loss: 1.9817, G loss: 0.2766\n",
      "[1762/1762] D loss: 1.9702, G loss: 0.2898\n",
      "train error: \n",
      " D loss: 2.060980, G loss: 0.252096, D accuracy: 50.0%, cell accuracy: 50.3%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.051071, G loss: 0.254904, D accuracy: 50.0%, cell accuracy: 50.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.0805, G loss: 0.2383\n",
      "[84/1762] D loss: 1.9882, G loss: 0.2786\n",
      "[164/1762] D loss: 2.0140, G loss: 0.2581\n",
      "[244/1762] D loss: 2.1072, G loss: 0.2310\n",
      "[324/1762] D loss: 2.0484, G loss: 0.2523\n",
      "[404/1762] D loss: 2.1079, G loss: 0.2334\n",
      "[484/1762] D loss: 1.9873, G loss: 0.2820\n",
      "[564/1762] D loss: 2.0197, G loss: 0.2695\n",
      "[644/1762] D loss: 1.9672, G loss: 0.2839\n",
      "[724/1762] D loss: 2.0584, G loss: 0.2568\n",
      "[804/1762] D loss: 2.0855, G loss: 0.2428\n",
      "[884/1762] D loss: 2.0896, G loss: 0.2422\n",
      "[964/1762] D loss: 2.0478, G loss: 0.2536\n",
      "[1044/1762] D loss: 2.0989, G loss: 0.2424\n",
      "[1124/1762] D loss: 2.0182, G loss: 0.2579\n",
      "[1204/1762] D loss: 1.9941, G loss: 0.2757\n",
      "[1284/1762] D loss: 2.0504, G loss: 0.2621\n",
      "[1364/1762] D loss: 2.1047, G loss: 0.2376\n",
      "[1444/1762] D loss: 2.0409, G loss: 0.2607\n",
      "[1524/1762] D loss: 2.0438, G loss: 0.2480\n",
      "[1604/1762] D loss: 2.0044, G loss: 0.2583\n",
      "[1684/1762] D loss: 2.0790, G loss: 0.2457\n",
      "[1762/1762] D loss: 2.0514, G loss: 0.2499\n",
      "train error: \n",
      " D loss: 2.064694, G loss: 0.250927, D accuracy: 50.0%, cell accuracy: 49.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.055247, G loss: 0.253651, D accuracy: 50.0%, cell accuracy: 50.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.0125, G loss: 0.2641\n",
      "[84/1762] D loss: 2.0316, G loss: 0.2611\n",
      "[164/1762] D loss: 1.9857, G loss: 0.2756\n",
      "[244/1762] D loss: 2.0408, G loss: 0.2604\n",
      "[324/1762] D loss: 2.0751, G loss: 0.2457\n",
      "[404/1762] D loss: 2.0132, G loss: 0.2657\n",
      "[484/1762] D loss: 2.0577, G loss: 0.2514\n",
      "[564/1762] D loss: 2.0716, G loss: 0.2421\n",
      "[644/1762] D loss: 2.0211, G loss: 0.2593\n",
      "[724/1762] D loss: 2.0290, G loss: 0.2571\n",
      "[804/1762] D loss: 2.0216, G loss: 0.2658\n",
      "[884/1762] D loss: 2.0379, G loss: 0.2686\n",
      "[964/1762] D loss: 2.0924, G loss: 0.2468\n",
      "[1044/1762] D loss: 1.9609, G loss: 0.2883\n",
      "[1124/1762] D loss: 2.0611, G loss: 0.2531\n",
      "[1204/1762] D loss: 2.0670, G loss: 0.2462\n",
      "[1284/1762] D loss: 2.0770, G loss: 0.2444\n",
      "[1364/1762] D loss: 2.0643, G loss: 0.2586\n",
      "[1444/1762] D loss: 2.0698, G loss: 0.2452\n",
      "[1524/1762] D loss: 2.0753, G loss: 0.2497\n",
      "[1604/1762] D loss: 2.0630, G loss: 0.2477\n",
      "[1684/1762] D loss: 2.0089, G loss: 0.2647\n",
      "[1762/1762] D loss: 2.0749, G loss: 0.2364\n",
      "train error: \n",
      " D loss: 2.067957, G loss: 0.249393, D accuracy: 50.0%, cell accuracy: 48.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.059115, G loss: 0.251838, D accuracy: 50.0%, cell accuracy: 49.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.0303, G loss: 0.2659\n",
      "[84/1762] D loss: 2.0961, G loss: 0.2345\n",
      "[164/1762] D loss: 2.0867, G loss: 0.2445\n",
      "[244/1762] D loss: 2.0339, G loss: 0.2651\n",
      "[324/1762] D loss: 1.9838, G loss: 0.2755\n",
      "[404/1762] D loss: 2.0603, G loss: 0.2532\n",
      "[484/1762] D loss: 2.0364, G loss: 0.2548\n",
      "[564/1762] D loss: 2.0884, G loss: 0.2374\n",
      "[644/1762] D loss: 2.0476, G loss: 0.2560\n",
      "[724/1762] D loss: 2.0617, G loss: 0.2425\n",
      "[804/1762] D loss: 2.0884, G loss: 0.2443\n",
      "[884/1762] D loss: 1.9733, G loss: 0.2842\n",
      "[964/1762] D loss: 2.0288, G loss: 0.2626\n",
      "[1044/1762] D loss: 2.1220, G loss: 0.2274\n",
      "[1124/1762] D loss: 2.0555, G loss: 0.2497\n",
      "[1204/1762] D loss: 2.0290, G loss: 0.2683\n",
      "[1284/1762] D loss: 2.0619, G loss: 0.2541\n",
      "[1364/1762] D loss: 2.0837, G loss: 0.2468\n",
      "[1444/1762] D loss: 2.0276, G loss: 0.2603\n",
      "[1524/1762] D loss: 2.0405, G loss: 0.2540\n",
      "[1604/1762] D loss: 1.9861, G loss: 0.2645\n",
      "[1684/1762] D loss: 2.0461, G loss: 0.2566\n",
      "[1762/1762] D loss: 2.0067, G loss: 0.2773\n",
      "train error: \n",
      " D loss: 2.076729, G loss: 0.247261, D accuracy: 50.0%, cell accuracy: 49.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.066257, G loss: 0.250187, D accuracy: 50.0%, cell accuracy: 50.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.0850, G loss: 0.2494\n",
      "[84/1762] D loss: 2.0165, G loss: 0.2742\n",
      "[164/1762] D loss: 1.9976, G loss: 0.2744\n",
      "[244/1762] D loss: 2.0692, G loss: 0.2471\n",
      "[324/1762] D loss: 2.0500, G loss: 0.2599\n",
      "[404/1762] D loss: 2.1089, G loss: 0.2352\n",
      "[484/1762] D loss: 2.0257, G loss: 0.2617\n",
      "[564/1762] D loss: 2.0096, G loss: 0.2680\n",
      "[644/1762] D loss: 2.0650, G loss: 0.2484\n",
      "[724/1762] D loss: 2.0998, G loss: 0.2409\n",
      "[804/1762] D loss: 2.0494, G loss: 0.2507\n",
      "[884/1762] D loss: 2.0755, G loss: 0.2450\n",
      "[964/1762] D loss: 2.0909, G loss: 0.2360\n",
      "[1044/1762] D loss: 2.0330, G loss: 0.2609\n",
      "[1124/1762] D loss: 2.0712, G loss: 0.2406\n",
      "[1204/1762] D loss: 2.0736, G loss: 0.2459\n",
      "[1284/1762] D loss: 1.9948, G loss: 0.2737\n",
      "[1364/1762] D loss: 2.0627, G loss: 0.2471\n",
      "[1444/1762] D loss: 2.0280, G loss: 0.2640\n",
      "[1524/1762] D loss: 2.0097, G loss: 0.2741\n",
      "[1604/1762] D loss: 2.1169, G loss: 0.2347\n",
      "[1684/1762] D loss: 2.0819, G loss: 0.2451\n",
      "[1762/1762] D loss: 2.0695, G loss: 0.2418\n",
      "train error: \n",
      " D loss: 2.056886, G loss: 0.254856, D accuracy: 50.0%, cell accuracy: 49.8%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.047219, G loss: 0.257695, D accuracy: 50.0%, cell accuracy: 50.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.0071, G loss: 0.2724\n",
      "[84/1762] D loss: 2.0583, G loss: 0.2576\n",
      "[164/1762] D loss: 2.0900, G loss: 0.2364\n",
      "[244/1762] D loss: 2.0836, G loss: 0.2463\n",
      "[324/1762] D loss: 2.0753, G loss: 0.2448\n",
      "[404/1762] D loss: 2.0405, G loss: 0.2624\n",
      "[484/1762] D loss: 2.1776, G loss: 0.2149\n",
      "[564/1762] D loss: 2.0301, G loss: 0.2606\n",
      "[644/1762] D loss: 2.0603, G loss: 0.2510\n",
      "[724/1762] D loss: 2.0395, G loss: 0.2465\n",
      "[804/1762] D loss: 2.1092, G loss: 0.2324\n",
      "[884/1762] D loss: 2.0175, G loss: 0.2604\n",
      "[964/1762] D loss: 2.0321, G loss: 0.2632\n",
      "[1044/1762] D loss: 2.0202, G loss: 0.2685\n",
      "[1124/1762] D loss: 2.0130, G loss: 0.2680\n",
      "[1204/1762] D loss: 2.0414, G loss: 0.2529\n",
      "[1284/1762] D loss: 2.0609, G loss: 0.2543\n",
      "[1364/1762] D loss: 2.0536, G loss: 0.2617\n",
      "[1444/1762] D loss: 2.0370, G loss: 0.2608\n",
      "[1524/1762] D loss: 2.0700, G loss: 0.2436\n",
      "[1604/1762] D loss: 2.0344, G loss: 0.2567\n",
      "[1684/1762] D loss: 2.0420, G loss: 0.2624\n",
      "[1762/1762] D loss: 2.0436, G loss: 0.2580\n",
      "train error: \n",
      " D loss: 2.079853, G loss: 0.246486, D accuracy: 50.0%, cell accuracy: 50.0%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.068467, G loss: 0.249593, D accuracy: 50.0%, cell accuracy: 50.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.0580, G loss: 0.2513\n",
      "[84/1762] D loss: 2.0552, G loss: 0.2469\n",
      "[164/1762] D loss: 2.0090, G loss: 0.2664\n",
      "[244/1762] D loss: 2.0393, G loss: 0.2608\n",
      "[324/1762] D loss: 2.0489, G loss: 0.2504\n",
      "[404/1762] D loss: 2.0467, G loss: 0.2546\n",
      "[484/1762] D loss: 2.0735, G loss: 0.2425\n",
      "[564/1762] D loss: 2.0699, G loss: 0.2578\n",
      "[644/1762] D loss: 2.0518, G loss: 0.2522\n",
      "[724/1762] D loss: 2.0462, G loss: 0.2562\n",
      "[804/1762] D loss: 2.0272, G loss: 0.2721\n",
      "[884/1762] D loss: 2.0173, G loss: 0.2634\n",
      "[964/1762] D loss: 2.0253, G loss: 0.2627\n",
      "[1044/1762] D loss: 2.0156, G loss: 0.2656\n",
      "[1124/1762] D loss: 2.0193, G loss: 0.2626\n",
      "[1204/1762] D loss: 2.0821, G loss: 0.2455\n",
      "[1284/1762] D loss: 2.1021, G loss: 0.2367\n",
      "[1364/1762] D loss: 2.0525, G loss: 0.2614\n",
      "[1444/1762] D loss: 2.0516, G loss: 0.2573\n",
      "[1524/1762] D loss: 1.9881, G loss: 0.2775\n",
      "[1604/1762] D loss: 2.0571, G loss: 0.2583\n",
      "[1684/1762] D loss: 1.9572, G loss: 0.2892\n",
      "[1762/1762] D loss: 2.0090, G loss: 0.2763\n",
      "train error: \n",
      " D loss: 2.063532, G loss: 0.251620, D accuracy: 50.0%, cell accuracy: 49.4%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.053916, G loss: 0.254370, D accuracy: 50.0%, cell accuracy: 49.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.0952, G loss: 0.2322\n",
      "[84/1762] D loss: 2.0792, G loss: 0.2527\n",
      "[164/1762] D loss: 2.0689, G loss: 0.2467\n",
      "[244/1762] D loss: 2.0903, G loss: 0.2449\n",
      "[324/1762] D loss: 2.0124, G loss: 0.2653\n",
      "[404/1762] D loss: 2.0822, G loss: 0.2427\n",
      "[484/1762] D loss: 2.0753, G loss: 0.2404\n",
      "[564/1762] D loss: 2.0339, G loss: 0.2644\n",
      "[644/1762] D loss: 2.0551, G loss: 0.2605\n",
      "[724/1762] D loss: 2.1116, G loss: 0.2418\n",
      "[804/1762] D loss: 2.0217, G loss: 0.2626\n",
      "[884/1762] D loss: 2.0561, G loss: 0.2515\n",
      "[964/1762] D loss: 2.0096, G loss: 0.2599\n",
      "[1044/1762] D loss: 2.0005, G loss: 0.2755\n",
      "[1124/1762] D loss: 2.0595, G loss: 0.2513\n",
      "[1204/1762] D loss: 2.1144, G loss: 0.2364\n",
      "[1284/1762] D loss: 2.0469, G loss: 0.2581\n",
      "[1364/1762] D loss: 2.0624, G loss: 0.2480\n",
      "[1444/1762] D loss: 2.0887, G loss: 0.2412\n",
      "[1524/1762] D loss: 2.1003, G loss: 0.2356\n",
      "[1604/1762] D loss: 2.1134, G loss: 0.2316\n",
      "[1684/1762] D loss: 2.0517, G loss: 0.2637\n",
      "[1762/1762] D loss: 2.0836, G loss: 0.2416\n",
      "train error: \n",
      " D loss: 2.062254, G loss: 0.252391, D accuracy: 50.0%, cell accuracy: 49.4%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.051132, G loss: 0.255590, D accuracy: 50.0%, cell accuracy: 49.5%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.0977, G loss: 0.2391\n",
      "[84/1762] D loss: 2.0090, G loss: 0.2751\n",
      "[164/1762] D loss: 2.1314, G loss: 0.2277\n",
      "[244/1762] D loss: 2.0908, G loss: 0.2435\n",
      "[324/1762] D loss: 2.1029, G loss: 0.2434\n",
      "[404/1762] D loss: 2.0208, G loss: 0.2642\n",
      "[484/1762] D loss: 2.0390, G loss: 0.2528\n",
      "[564/1762] D loss: 2.0704, G loss: 0.2493\n",
      "[644/1762] D loss: 2.0469, G loss: 0.2531\n",
      "[724/1762] D loss: 2.0681, G loss: 0.2471\n",
      "[804/1762] D loss: 2.0428, G loss: 0.2650\n",
      "[884/1762] D loss: 2.0624, G loss: 0.2532\n",
      "[964/1762] D loss: 2.0329, G loss: 0.2609\n",
      "[1044/1762] D loss: 2.0742, G loss: 0.2493\n",
      "[1124/1762] D loss: 2.0377, G loss: 0.2607\n",
      "[1204/1762] D loss: 2.0426, G loss: 0.2526\n",
      "[1284/1762] D loss: 2.0137, G loss: 0.2701\n",
      "[1364/1762] D loss: 2.0277, G loss: 0.2664\n",
      "[1444/1762] D loss: 1.9698, G loss: 0.2808\n",
      "[1524/1762] D loss: 2.0826, G loss: 0.2410\n",
      "[1604/1762] D loss: 2.0682, G loss: 0.2521\n",
      "[1684/1762] D loss: 2.0164, G loss: 0.2779\n",
      "[1762/1762] D loss: 2.0666, G loss: 0.2412\n",
      "train error: \n",
      " D loss: 2.078432, G loss: 0.247637, D accuracy: 50.0%, cell accuracy: 49.0%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.068763, G loss: 0.250334, D accuracy: 50.0%, cell accuracy: 49.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.0222, G loss: 0.2590\n",
      "[84/1762] D loss: 2.0604, G loss: 0.2562\n",
      "[164/1762] D loss: 2.0676, G loss: 0.2539\n",
      "[244/1762] D loss: 1.9979, G loss: 0.2807\n",
      "[324/1762] D loss: 2.0227, G loss: 0.2643\n",
      "[404/1762] D loss: 2.0054, G loss: 0.2702\n",
      "[484/1762] D loss: 2.0127, G loss: 0.2638\n",
      "[564/1762] D loss: 2.0525, G loss: 0.2476\n",
      "[644/1762] D loss: 2.0907, G loss: 0.2449\n",
      "[724/1762] D loss: 2.0523, G loss: 0.2566\n",
      "[804/1762] D loss: 2.0489, G loss: 0.2582\n",
      "[884/1762] D loss: 2.0087, G loss: 0.2752\n",
      "[964/1762] D loss: 2.1184, G loss: 0.2374\n",
      "[1044/1762] D loss: 1.9921, G loss: 0.2738\n",
      "[1124/1762] D loss: 2.0726, G loss: 0.2491\n",
      "[1204/1762] D loss: 2.0088, G loss: 0.2679\n",
      "[1284/1762] D loss: 2.0121, G loss: 0.2713\n",
      "[1364/1762] D loss: 2.0434, G loss: 0.2634\n",
      "[1444/1762] D loss: 2.0748, G loss: 0.2441\n",
      "[1524/1762] D loss: 2.1230, G loss: 0.2217\n",
      "[1604/1762] D loss: 2.0596, G loss: 0.2492\n",
      "[1684/1762] D loss: 2.0300, G loss: 0.2641\n",
      "[1762/1762] D loss: 2.0160, G loss: 0.2676\n",
      "train error: \n",
      " D loss: 2.056155, G loss: 0.253859, D accuracy: 50.0%, cell accuracy: 49.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.045986, G loss: 0.256851, D accuracy: 50.0%, cell accuracy: 49.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.0139, G loss: 0.2677\n",
      "[84/1762] D loss: 2.0094, G loss: 0.2706\n",
      "[164/1762] D loss: 2.0701, G loss: 0.2515\n",
      "[244/1762] D loss: 2.0981, G loss: 0.2411\n",
      "[324/1762] D loss: 2.0078, G loss: 0.2659\n",
      "[404/1762] D loss: 2.0979, G loss: 0.2499\n",
      "[484/1762] D loss: 2.0166, G loss: 0.2686\n",
      "[564/1762] D loss: 2.0596, G loss: 0.2538\n",
      "[644/1762] D loss: 2.0165, G loss: 0.2666\n",
      "[724/1762] D loss: 2.0926, G loss: 0.2422\n",
      "[804/1762] D loss: 2.0242, G loss: 0.2609\n",
      "[884/1762] D loss: 2.0404, G loss: 0.2596\n",
      "[964/1762] D loss: 2.0979, G loss: 0.2399\n",
      "[1044/1762] D loss: 2.0096, G loss: 0.2668\n",
      "[1124/1762] D loss: 2.0410, G loss: 0.2611\n",
      "[1204/1762] D loss: 2.0184, G loss: 0.2640\n",
      "[1284/1762] D loss: 2.0615, G loss: 0.2456\n",
      "[1364/1762] D loss: 2.0022, G loss: 0.2667\n",
      "[1444/1762] D loss: 2.0479, G loss: 0.2541\n",
      "[1524/1762] D loss: 2.0660, G loss: 0.2512\n",
      "[1604/1762] D loss: 2.0195, G loss: 0.2719\n",
      "[1684/1762] D loss: 2.0678, G loss: 0.2475\n",
      "[1762/1762] D loss: 2.1246, G loss: 0.2363\n",
      "train error: \n",
      " D loss: 2.061194, G loss: 0.253009, D accuracy: 50.0%, cell accuracy: 49.2%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.050068, G loss: 0.256163, D accuracy: 50.0%, cell accuracy: 49.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.1345, G loss: 0.2239\n",
      "[84/1762] D loss: 2.0912, G loss: 0.2535\n",
      "[164/1762] D loss: 2.0665, G loss: 0.2543\n",
      "[244/1762] D loss: 2.0108, G loss: 0.2724\n",
      "[324/1762] D loss: 2.0754, G loss: 0.2376\n",
      "[404/1762] D loss: 2.1602, G loss: 0.2156\n",
      "[484/1762] D loss: 2.0770, G loss: 0.2490\n",
      "[564/1762] D loss: 2.0221, G loss: 0.2682\n",
      "[644/1762] D loss: 2.0174, G loss: 0.2673\n",
      "[724/1762] D loss: 2.1048, G loss: 0.2396\n",
      "[804/1762] D loss: 2.1138, G loss: 0.2280\n",
      "[884/1762] D loss: 2.0347, G loss: 0.2613\n",
      "[964/1762] D loss: 2.0212, G loss: 0.2638\n",
      "[1044/1762] D loss: 2.0101, G loss: 0.2746\n",
      "[1124/1762] D loss: 2.0668, G loss: 0.2606\n",
      "[1204/1762] D loss: 2.0710, G loss: 0.2514\n",
      "[1284/1762] D loss: 2.0921, G loss: 0.2421\n",
      "[1364/1762] D loss: 2.0626, G loss: 0.2494\n",
      "[1444/1762] D loss: 2.0519, G loss: 0.2570\n",
      "[1524/1762] D loss: 2.0755, G loss: 0.2493\n",
      "[1604/1762] D loss: 2.0855, G loss: 0.2429\n",
      "[1684/1762] D loss: 2.0401, G loss: 0.2567\n",
      "[1762/1762] D loss: 2.0567, G loss: 0.2552\n",
      "train error: \n",
      " D loss: 2.059652, G loss: 0.253710, D accuracy: 50.0%, cell accuracy: 49.8%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.049297, G loss: 0.256794, D accuracy: 50.0%, cell accuracy: 49.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.0744, G loss: 0.2512\n",
      "[84/1762] D loss: 2.0914, G loss: 0.2445\n",
      "[164/1762] D loss: 2.0349, G loss: 0.2552\n",
      "[244/1762] D loss: 2.1016, G loss: 0.2396\n",
      "[324/1762] D loss: 2.0608, G loss: 0.2532\n",
      "[404/1762] D loss: 2.0116, G loss: 0.2779\n",
      "[484/1762] D loss: 2.0363, G loss: 0.2559\n",
      "[564/1762] D loss: 2.0537, G loss: 0.2493\n",
      "[644/1762] D loss: 2.0330, G loss: 0.2618\n",
      "[724/1762] D loss: 2.0526, G loss: 0.2497\n",
      "[804/1762] D loss: 2.0656, G loss: 0.2437\n",
      "[884/1762] D loss: 2.0528, G loss: 0.2579\n",
      "[964/1762] D loss: 2.1132, G loss: 0.2397\n",
      "[1044/1762] D loss: 2.0081, G loss: 0.2802\n",
      "[1124/1762] D loss: 2.0021, G loss: 0.2709\n",
      "[1204/1762] D loss: 2.0412, G loss: 0.2676\n",
      "[1284/1762] D loss: 2.0700, G loss: 0.2539\n",
      "[1364/1762] D loss: 2.0235, G loss: 0.2650\n",
      "[1444/1762] D loss: 2.0393, G loss: 0.2574\n",
      "[1524/1762] D loss: 1.9995, G loss: 0.2707\n",
      "[1604/1762] D loss: 1.9987, G loss: 0.2721\n",
      "[1684/1762] D loss: 2.0804, G loss: 0.2488\n",
      "[1762/1762] D loss: 2.0140, G loss: 0.2756\n",
      "train error: \n",
      " D loss: 2.083990, G loss: 0.245680, D accuracy: 50.0%, cell accuracy: 49.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.072500, G loss: 0.248897, D accuracy: 50.0%, cell accuracy: 50.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.1301, G loss: 0.2292\n",
      "[84/1762] D loss: 2.1113, G loss: 0.2387\n",
      "[164/1762] D loss: 2.0940, G loss: 0.2337\n",
      "[244/1762] D loss: 1.9923, G loss: 0.2752\n",
      "[324/1762] D loss: 2.0190, G loss: 0.2693\n",
      "[404/1762] D loss: 2.0924, G loss: 0.2451\n",
      "[484/1762] D loss: 2.0288, G loss: 0.2540\n",
      "[564/1762] D loss: 2.0852, G loss: 0.2438\n",
      "[644/1762] D loss: 2.0881, G loss: 0.2405\n",
      "[724/1762] D loss: 2.0845, G loss: 0.2459\n",
      "[804/1762] D loss: 2.0311, G loss: 0.2643\n",
      "[884/1762] D loss: 2.0679, G loss: 0.2451\n",
      "[964/1762] D loss: 2.0604, G loss: 0.2536\n",
      "[1044/1762] D loss: 2.0576, G loss: 0.2453\n",
      "[1124/1762] D loss: 2.0005, G loss: 0.2762\n",
      "[1204/1762] D loss: 2.0513, G loss: 0.2622\n",
      "[1284/1762] D loss: 2.0472, G loss: 0.2527\n",
      "[1364/1762] D loss: 2.0342, G loss: 0.2587\n",
      "[1444/1762] D loss: 2.0326, G loss: 0.2581\n",
      "[1524/1762] D loss: 2.0204, G loss: 0.2769\n",
      "[1604/1762] D loss: 2.0426, G loss: 0.2541\n",
      "[1684/1762] D loss: 2.1286, G loss: 0.2277\n",
      "[1762/1762] D loss: 2.1416, G loss: 0.2190\n",
      "train error: \n",
      " D loss: 2.078603, G loss: 0.247414, D accuracy: 50.0%, cell accuracy: 48.6%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.067691, G loss: 0.250514, D accuracy: 50.0%, cell accuracy: 48.7%, board accuracy: 0.0% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4251, G loss: 0.6386\n",
      "[84/1762] D loss: 0.5518, G loss: 1.6198\n",
      "[164/1762] D loss: 0.1278, G loss: 3.0148\n",
      "[244/1762] D loss: 0.0570, G loss: 4.2220\n",
      "[324/1762] D loss: 0.0274, G loss: 4.3713\n",
      "[404/1762] D loss: 0.0175, G loss: 5.4810\n",
      "[484/1762] D loss: 0.0370, G loss: 5.1970\n",
      "[564/1762] D loss: 0.0615, G loss: 4.8398\n",
      "[644/1762] D loss: 0.3075, G loss: 4.8926\n",
      "[724/1762] D loss: 0.8949, G loss: 3.0633\n",
      "[804/1762] D loss: 0.1229, G loss: 3.8447\n",
      "[884/1762] D loss: 0.6493, G loss: 5.4825\n",
      "[964/1762] D loss: 0.1544, G loss: 3.1616\n",
      "[1044/1762] D loss: 0.6211, G loss: 2.4652\n",
      "[1124/1762] D loss: 1.0279, G loss: 4.5649\n",
      "[1204/1762] D loss: 1.1708, G loss: 1.1965\n",
      "[1284/1762] D loss: 0.9951, G loss: 1.8691\n",
      "[1364/1762] D loss: 0.8664, G loss: 1.7037\n",
      "[1444/1762] D loss: 0.8526, G loss: 1.3625\n",
      "[1524/1762] D loss: 1.0715, G loss: 1.2091\n",
      "[1604/1762] D loss: 1.1254, G loss: 0.9808\n",
      "[1684/1762] D loss: 1.7604, G loss: 1.8048\n",
      "[1762/1762] D loss: 0.9960, G loss: 1.5257\n",
      "train error: \n",
      " D loss: 1.490644, G loss: 1.503868, D accuracy: 55.3%, cell accuracy: 99.7%, board accuracy: 74.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.524514, G loss: 1.603281, D accuracy: 55.1%, cell accuracy: 99.6%, board accuracy: 71.8% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.8859, G loss: 1.7927\n",
      "[84/1762] D loss: 1.2289, G loss: 1.2937\n",
      "[164/1762] D loss: 1.1940, G loss: 0.9013\n",
      "[244/1762] D loss: 1.1857, G loss: 1.2774\n",
      "[324/1762] D loss: 1.7231, G loss: 0.3953\n",
      "[404/1762] D loss: 1.3189, G loss: 0.5950\n",
      "[484/1762] D loss: 0.6968, G loss: 1.3544\n",
      "[564/1762] D loss: 1.3036, G loss: 0.6379\n",
      "[644/1762] D loss: 1.2140, G loss: 0.8356\n",
      "[724/1762] D loss: 1.3337, G loss: 0.7841\n",
      "[804/1762] D loss: 1.1580, G loss: 0.9389\n",
      "[884/1762] D loss: 1.0919, G loss: 1.1173\n",
      "[964/1762] D loss: 1.3021, G loss: 0.8237\n",
      "[1044/1762] D loss: 1.1678, G loss: 0.8602\n",
      "[1124/1762] D loss: 1.2071, G loss: 1.2201\n",
      "[1204/1762] D loss: 1.3510, G loss: 0.9772\n",
      "[1284/1762] D loss: 1.0374, G loss: 0.8705\n",
      "[1364/1762] D loss: 1.4285, G loss: 0.4736\n",
      "[1444/1762] D loss: 1.2518, G loss: 0.8014\n",
      "[1524/1762] D loss: 1.2596, G loss: 0.6459\n",
      "[1604/1762] D loss: 1.3978, G loss: 0.4703\n",
      "[1684/1762] D loss: 1.3656, G loss: 0.9375\n",
      "[1762/1762] D loss: 1.3196, G loss: 1.0865\n",
      "train error: \n",
      " D loss: 1.317643, G loss: 0.691383, D accuracy: 56.9%, cell accuracy: 99.8%, board accuracy: 82.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.300983, G loss: 0.723989, D accuracy: 57.8%, cell accuracy: 99.7%, board accuracy: 78.2% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0353, G loss: 0.7919\n",
      "[84/1762] D loss: 1.3710, G loss: 0.4256\n",
      "[164/1762] D loss: 0.6629, G loss: 2.1408\n",
      "[244/1762] D loss: 1.7368, G loss: 1.3260\n",
      "[324/1762] D loss: 1.4875, G loss: 0.5549\n",
      "[404/1762] D loss: 1.5298, G loss: 0.8867\n",
      "[484/1762] D loss: 1.6287, G loss: 1.2957\n",
      "[564/1762] D loss: 1.2421, G loss: 0.9057\n",
      "[644/1762] D loss: 1.3987, G loss: 0.7404\n",
      "[724/1762] D loss: 0.7714, G loss: 1.1479\n",
      "[804/1762] D loss: 1.3819, G loss: 0.7187\n",
      "[884/1762] D loss: 1.3838, G loss: 0.6436\n",
      "[964/1762] D loss: 1.4139, G loss: 0.5771\n",
      "[1044/1762] D loss: 1.4580, G loss: 1.0801\n",
      "[1124/1762] D loss: 1.5197, G loss: 0.5659\n",
      "[1204/1762] D loss: 1.5234, G loss: 1.1525\n",
      "[1284/1762] D loss: 1.2942, G loss: 1.2394\n",
      "[1364/1762] D loss: 1.1935, G loss: 1.2649\n",
      "[1444/1762] D loss: 1.4254, G loss: 1.1123\n",
      "[1524/1762] D loss: 1.9159, G loss: 0.8108\n",
      "[1604/1762] D loss: 1.7899, G loss: 0.8854\n",
      "[1684/1762] D loss: 1.3845, G loss: 0.6831\n",
      "[1762/1762] D loss: 1.3894, G loss: 0.6982\n",
      "train error: \n",
      " D loss: 1.437098, G loss: 0.687100, D accuracy: 47.1%, cell accuracy: 99.6%, board accuracy: 53.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.453312, G loss: 0.691398, D accuracy: 45.7%, cell accuracy: 99.6%, board accuracy: 53.9% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3861, G loss: 0.6965\n",
      "[84/1762] D loss: 1.4466, G loss: 0.7107\n",
      "[164/1762] D loss: 1.3736, G loss: 0.6883\n",
      "[244/1762] D loss: 1.3946, G loss: 0.6307\n",
      "[324/1762] D loss: 1.3779, G loss: 0.7566\n",
      "[404/1762] D loss: 1.3821, G loss: 0.6514\n",
      "[484/1762] D loss: 1.3839, G loss: 0.7220\n",
      "[564/1762] D loss: 1.3784, G loss: 0.7801\n",
      "[644/1762] D loss: 1.3496, G loss: 0.7729\n",
      "[724/1762] D loss: 1.3016, G loss: 0.7183\n",
      "[804/1762] D loss: 1.3914, G loss: 0.7436\n",
      "[884/1762] D loss: 1.2171, G loss: 0.7399\n",
      "[964/1762] D loss: 1.1824, G loss: 0.7703\n",
      "[1044/1762] D loss: 1.3900, G loss: 0.6601\n",
      "[1124/1762] D loss: 1.3885, G loss: 0.6419\n",
      "[1204/1762] D loss: 1.3546, G loss: 0.7879\n",
      "[1284/1762] D loss: 1.3896, G loss: 0.6671\n",
      "[1364/1762] D loss: 1.3809, G loss: 0.7244\n",
      "[1444/1762] D loss: 1.3826, G loss: 0.6826\n",
      "[1524/1762] D loss: 1.3889, G loss: 0.7462\n",
      "[1604/1762] D loss: 1.3793, G loss: 0.7311\n",
      "[1684/1762] D loss: 1.0682, G loss: 1.0309\n",
      "[1762/1762] D loss: 1.3826, G loss: 0.7615\n",
      "train error: \n",
      " D loss: 1.329443, G loss: 0.815662, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 86.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.311286, G loss: 0.837468, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 84.1% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3950, G loss: 0.8232\n",
      "[84/1762] D loss: 1.4024, G loss: 0.7723\n",
      "[164/1762] D loss: 1.3851, G loss: 0.6605\n",
      "[244/1762] D loss: 1.3797, G loss: 0.7498\n",
      "[324/1762] D loss: 1.3842, G loss: 0.8725\n",
      "[404/1762] D loss: 1.3880, G loss: 0.6193\n",
      "[484/1762] D loss: 1.4118, G loss: 0.6397\n",
      "[564/1762] D loss: 1.4033, G loss: 0.8314\n",
      "[644/1762] D loss: 1.3901, G loss: 0.8633\n",
      "[724/1762] D loss: 1.4959, G loss: 0.4779\n",
      "[804/1762] D loss: 1.3635, G loss: 0.7795\n",
      "[884/1762] D loss: 1.6976, G loss: 0.4604\n",
      "[964/1762] D loss: 0.9997, G loss: 0.8035\n",
      "[1044/1762] D loss: 1.3448, G loss: 0.9880\n",
      "[1124/1762] D loss: 0.8622, G loss: 0.7299\n",
      "[1204/1762] D loss: 1.3899, G loss: 0.7344\n",
      "[1284/1762] D loss: 1.4137, G loss: 0.5909\n",
      "[1364/1762] D loss: 0.9189, G loss: 0.6856\n",
      "[1444/1762] D loss: 1.4495, G loss: 0.9384\n",
      "[1524/1762] D loss: 1.3511, G loss: 0.7728\n",
      "[1604/1762] D loss: 1.4129, G loss: 0.6783\n",
      "[1684/1762] D loss: 2.0840, G loss: 0.9192\n",
      "[1762/1762] D loss: 1.8062, G loss: 1.4816\n",
      "train error: \n",
      " D loss: 1.981849, G loss: 1.482132, D accuracy: 50.3%, cell accuracy: 99.6%, board accuracy: 66.5% \n",
      "\n",
      "test error: \n",
      " D loss: 2.062106, G loss: 1.504856, D accuracy: 50.1%, cell accuracy: 99.5%, board accuracy: 64.1% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.5880, G loss: 2.0929\n",
      "[84/1762] D loss: 2.0118, G loss: 1.1934\n",
      "[164/1762] D loss: 2.5564, G loss: 0.9445\n",
      "[244/1762] D loss: 2.0451, G loss: 0.7345\n",
      "[324/1762] D loss: 2.4069, G loss: 0.5570\n",
      "[404/1762] D loss: 2.3315, G loss: 0.3481\n",
      "[484/1762] D loss: 2.6963, G loss: 0.4079\n",
      "[564/1762] D loss: 2.4994, G loss: 0.5386\n",
      "[644/1762] D loss: 2.4432, G loss: 0.8863\n",
      "[724/1762] D loss: 2.3960, G loss: 0.3926\n",
      "[804/1762] D loss: 2.6824, G loss: 0.8301\n",
      "[884/1762] D loss: 2.2616, G loss: 0.6884\n",
      "[964/1762] D loss: 2.5697, G loss: 0.7950\n",
      "[1044/1762] D loss: 3.1268, G loss: 0.4661\n",
      "[1124/1762] D loss: 2.8845, G loss: 0.5132\n",
      "[1204/1762] D loss: 2.6115, G loss: 0.4294\n",
      "[1284/1762] D loss: 2.3658, G loss: 0.6242\n",
      "[1364/1762] D loss: 2.3639, G loss: 0.4004\n",
      "[1444/1762] D loss: 3.2858, G loss: 0.4387\n",
      "[1524/1762] D loss: 2.7599, G loss: 0.6795\n",
      "[1604/1762] D loss: 2.3062, G loss: 0.3179\n",
      "[1684/1762] D loss: 2.1857, G loss: 0.3889\n",
      "[1762/1762] D loss: 2.6730, G loss: 0.4421\n",
      "train error: \n",
      " D loss: 2.581366, G loss: 0.451248, D accuracy: 6.3%, cell accuracy: 95.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.632378, G loss: 0.467591, D accuracy: 6.9%, cell accuracy: 95.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.1400, G loss: 0.6491\n",
      "[84/1762] D loss: 2.7469, G loss: 0.3460\n",
      "[164/1762] D loss: 2.4599, G loss: 0.5995\n",
      "[244/1762] D loss: 2.6288, G loss: 0.6686\n",
      "[324/1762] D loss: 2.4344, G loss: 0.5704\n",
      "[404/1762] D loss: 2.6750, G loss: 0.4629\n",
      "[484/1762] D loss: 3.3790, G loss: 0.4970\n",
      "[564/1762] D loss: 2.4188, G loss: 0.4718\n",
      "[644/1762] D loss: 2.8987, G loss: 0.4795\n",
      "[724/1762] D loss: 2.5204, G loss: 0.3302\n",
      "[804/1762] D loss: 2.8800, G loss: 0.6107\n",
      "[884/1762] D loss: 2.6908, G loss: 0.3686\n",
      "[964/1762] D loss: 2.4216, G loss: 0.3574\n",
      "[1044/1762] D loss: 2.9363, G loss: 0.3176\n",
      "[1124/1762] D loss: 2.5273, G loss: 0.5345\n",
      "[1204/1762] D loss: 3.0240, G loss: 0.5999\n",
      "[1284/1762] D loss: 3.1594, G loss: 0.4743\n",
      "[1364/1762] D loss: 2.9679, G loss: 0.4580\n",
      "[1444/1762] D loss: 2.8068, G loss: 0.5747\n",
      "[1524/1762] D loss: 2.7424, G loss: 0.5384\n",
      "[1604/1762] D loss: 2.4478, G loss: 0.4416\n",
      "[1684/1762] D loss: 2.7594, G loss: 0.6259\n",
      "[1762/1762] D loss: 3.9487, G loss: 0.3248\n",
      "train error: \n",
      " D loss: 2.636087, G loss: 0.389579, D accuracy: 4.5%, cell accuracy: 95.2%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.668542, G loss: 0.410310, D accuracy: 5.6%, cell accuracy: 95.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.8743, G loss: 0.4154\n",
      "[84/1762] D loss: 2.5498, G loss: 0.4145\n",
      "[164/1762] D loss: 3.7668, G loss: 0.4613\n",
      "[244/1762] D loss: 2.5722, G loss: 0.4502\n",
      "[324/1762] D loss: 2.7251, G loss: 0.4199\n",
      "[404/1762] D loss: 2.5310, G loss: 0.2447\n",
      "[484/1762] D loss: 3.0924, G loss: 0.3975\n",
      "[564/1762] D loss: 2.5573, G loss: 0.3911\n",
      "[644/1762] D loss: 3.2432, G loss: 0.5380\n",
      "[724/1762] D loss: 2.7892, G loss: 0.5038\n",
      "[804/1762] D loss: 2.9017, G loss: 0.4236\n",
      "[884/1762] D loss: 2.4472, G loss: 0.4206\n",
      "[964/1762] D loss: 3.1874, G loss: 0.5472\n",
      "[1044/1762] D loss: 3.2718, G loss: 0.4485\n",
      "[1124/1762] D loss: 2.9314, G loss: 0.3821\n",
      "[1204/1762] D loss: 2.9127, G loss: 0.4287\n",
      "[1284/1762] D loss: 2.5786, G loss: 0.3113\n",
      "[1364/1762] D loss: 3.0371, G loss: 0.4773\n",
      "[1444/1762] D loss: 2.9699, G loss: 0.4770\n",
      "[1524/1762] D loss: 2.7516, G loss: 0.4052\n",
      "[1604/1762] D loss: 3.1428, G loss: 0.4610\n",
      "[1684/1762] D loss: 2.9767, G loss: 0.4005\n",
      "[1762/1762] D loss: 3.0719, G loss: 0.5209\n",
      "train error: \n",
      " D loss: 2.764448, G loss: 0.351736, D accuracy: 2.0%, cell accuracy: 94.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.794835, G loss: 0.370959, D accuracy: 2.2%, cell accuracy: 94.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.7806, G loss: 0.2929\n",
      "[84/1762] D loss: 2.8260, G loss: 0.4912\n",
      "[164/1762] D loss: 2.3846, G loss: 0.5055\n",
      "[244/1762] D loss: 2.5548, G loss: 0.4233\n",
      "[324/1762] D loss: 3.0734, G loss: 0.4354\n",
      "[404/1762] D loss: 2.5917, G loss: 0.2285\n",
      "[484/1762] D loss: 2.7432, G loss: 0.3108\n",
      "[564/1762] D loss: 2.5862, G loss: 0.3745\n",
      "[644/1762] D loss: 3.0769, G loss: 0.3595\n",
      "[724/1762] D loss: 3.0583, G loss: 0.3428\n",
      "[804/1762] D loss: 3.2145, G loss: 0.3839\n",
      "[884/1762] D loss: 2.6579, G loss: 0.4345\n",
      "[964/1762] D loss: 3.3143, G loss: 0.3213\n",
      "[1044/1762] D loss: 3.0722, G loss: 0.3763\n",
      "[1124/1762] D loss: 3.0772, G loss: 0.3571\n",
      "[1204/1762] D loss: 2.4080, G loss: 0.4399\n",
      "[1284/1762] D loss: 2.8777, G loss: 0.4661\n",
      "[1364/1762] D loss: 2.7829, G loss: 0.3483\n",
      "[1444/1762] D loss: 3.2096, G loss: 0.2787\n",
      "[1524/1762] D loss: 2.6826, G loss: 0.4070\n",
      "[1604/1762] D loss: 2.7943, G loss: 0.2313\n",
      "[1684/1762] D loss: 2.6709, G loss: 0.2905\n",
      "[1762/1762] D loss: 3.4455, G loss: 0.4540\n",
      "train error: \n",
      " D loss: 2.960431, G loss: 0.293313, D accuracy: 0.7%, cell accuracy: 94.2%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.999002, G loss: 0.305120, D accuracy: 0.2%, cell accuracy: 94.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.5558, G loss: 0.4351\n",
      "[84/1762] D loss: 3.0309, G loss: 0.4775\n",
      "[164/1762] D loss: 3.0806, G loss: 0.3903\n",
      "[244/1762] D loss: 2.7404, G loss: 0.2696\n",
      "[324/1762] D loss: 2.2142, G loss: 0.4317\n",
      "[404/1762] D loss: 3.2252, G loss: 0.4798\n",
      "[484/1762] D loss: 2.9408, G loss: 0.2794\n",
      "[564/1762] D loss: 2.9834, G loss: 0.2603\n",
      "[644/1762] D loss: 3.0751, G loss: 0.2392\n",
      "[724/1762] D loss: 3.1241, G loss: 0.2736\n",
      "[804/1762] D loss: 2.8005, G loss: 0.2795\n",
      "[884/1762] D loss: 3.3253, G loss: 0.2965\n",
      "[964/1762] D loss: 2.9943, G loss: 0.3346\n",
      "[1044/1762] D loss: 3.4510, G loss: 0.3761\n",
      "[1124/1762] D loss: 4.1627, G loss: 0.3526\n",
      "[1204/1762] D loss: 3.0791, G loss: 0.3103\n",
      "[1284/1762] D loss: 2.4696, G loss: 0.2987\n",
      "[1364/1762] D loss: 2.5896, G loss: 0.3092\n",
      "[1444/1762] D loss: 3.3477, G loss: 0.2865\n",
      "[1524/1762] D loss: 3.1655, G loss: 0.4961\n",
      "[1604/1762] D loss: 2.8917, G loss: 0.2301\n",
      "[1684/1762] D loss: 2.6393, G loss: 0.2457\n",
      "[1762/1762] D loss: 3.6946, G loss: 0.3879\n",
      "train error: \n",
      " D loss: 2.986812, G loss: 0.281466, D accuracy: 0.7%, cell accuracy: 94.0%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.017561, G loss: 0.298407, D accuracy: 0.8%, cell accuracy: 94.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 3.3229, G loss: 0.2861\n",
      "[84/1762] D loss: 3.1022, G loss: 0.2933\n",
      "[164/1762] D loss: 3.0342, G loss: 0.4033\n",
      "[244/1762] D loss: 2.7930, G loss: 0.1713\n",
      "[324/1762] D loss: 2.8813, G loss: 0.3321\n",
      "[404/1762] D loss: 2.4232, G loss: 0.4860\n",
      "[484/1762] D loss: 3.2883, G loss: 0.3608\n",
      "[564/1762] D loss: 2.6298, G loss: 0.4188\n",
      "[644/1762] D loss: 3.3853, G loss: 0.2688\n",
      "[724/1762] D loss: 2.8169, G loss: 0.2999\n",
      "[804/1762] D loss: 2.7305, G loss: 0.3421\n",
      "[884/1762] D loss: 2.8767, G loss: 0.2948\n",
      "[964/1762] D loss: 3.1179, G loss: 0.2693\n",
      "[1044/1762] D loss: 3.1896, G loss: 0.3116\n",
      "[1124/1762] D loss: 3.2349, G loss: 0.4309\n",
      "[1204/1762] D loss: 2.9209, G loss: 0.4091\n",
      "[1284/1762] D loss: 2.8350, G loss: 0.2882\n",
      "[1364/1762] D loss: 3.1043, G loss: 0.3254\n",
      "[1444/1762] D loss: 2.5839, G loss: 0.2750\n",
      "[1524/1762] D loss: 2.8201, G loss: 0.2580\n",
      "[1604/1762] D loss: 3.0978, G loss: 0.2181\n",
      "[1684/1762] D loss: 3.0416, G loss: 0.2693\n",
      "[1762/1762] D loss: 2.6049, G loss: 0.2342\n",
      "train error: \n",
      " D loss: 3.044850, G loss: 0.259167, D accuracy: 0.5%, cell accuracy: 93.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.068799, G loss: 0.275635, D accuracy: 0.2%, cell accuracy: 93.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.8665, G loss: 0.2520\n",
      "[84/1762] D loss: 2.9363, G loss: 0.2359\n",
      "[164/1762] D loss: 3.2320, G loss: 0.3152\n",
      "[244/1762] D loss: 2.9612, G loss: 0.2875\n",
      "[324/1762] D loss: 3.3864, G loss: 0.4380\n",
      "[404/1762] D loss: 2.6368, G loss: 0.2212\n",
      "[484/1762] D loss: 2.8262, G loss: 0.2731\n",
      "[564/1762] D loss: 2.9592, G loss: 0.3426\n",
      "[644/1762] D loss: 2.9024, G loss: 0.3052\n",
      "[724/1762] D loss: 3.0456, G loss: 0.2252\n",
      "[804/1762] D loss: 3.0040, G loss: 0.2801\n",
      "[884/1762] D loss: 2.6275, G loss: 0.2730\n",
      "[964/1762] D loss: 2.9235, G loss: 0.2296\n",
      "[1044/1762] D loss: 2.8669, G loss: 0.3202\n",
      "[1124/1762] D loss: 3.0128, G loss: 0.2811\n",
      "[1204/1762] D loss: 3.1828, G loss: 0.3857\n",
      "[1284/1762] D loss: 3.3039, G loss: 0.2070\n",
      "[1364/1762] D loss: 2.9543, G loss: 0.2652\n",
      "[1444/1762] D loss: 2.7021, G loss: 0.3703\n",
      "[1524/1762] D loss: 2.7571, G loss: 0.2531\n",
      "[1604/1762] D loss: 2.8179, G loss: 0.2362\n",
      "[1684/1762] D loss: 3.1778, G loss: 0.3571\n",
      "[1762/1762] D loss: 2.8730, G loss: 0.2155\n",
      "train error: \n",
      " D loss: 3.083197, G loss: 0.239721, D accuracy: 0.6%, cell accuracy: 93.8%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.111933, G loss: 0.253889, D accuracy: 0.2%, cell accuracy: 93.8%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 3.2009, G loss: 0.2269\n",
      "[84/1762] D loss: 3.1519, G loss: 0.2496\n",
      "[164/1762] D loss: 3.2640, G loss: 0.2921\n",
      "[244/1762] D loss: 2.8984, G loss: 0.2187\n",
      "[324/1762] D loss: 3.2086, G loss: 0.2679\n",
      "[404/1762] D loss: 3.9286, G loss: 0.2006\n",
      "[484/1762] D loss: 3.2380, G loss: 0.2816\n",
      "[564/1762] D loss: 3.1370, G loss: 0.3641\n",
      "[644/1762] D loss: 2.9979, G loss: 0.1866\n",
      "[724/1762] D loss: 2.4380, G loss: 0.3056\n",
      "[804/1762] D loss: 3.0543, G loss: 0.3186\n",
      "[884/1762] D loss: 3.1530, G loss: 0.3450\n",
      "[964/1762] D loss: 2.6805, G loss: 0.2267\n",
      "[1044/1762] D loss: 2.9393, G loss: 0.2936\n",
      "[1124/1762] D loss: 2.8947, G loss: 0.2598\n",
      "[1204/1762] D loss: 3.2474, G loss: 0.2358\n",
      "[1284/1762] D loss: 3.9305, G loss: 0.2812\n",
      "[1364/1762] D loss: 2.9131, G loss: 0.3745\n",
      "[1444/1762] D loss: 3.3252, G loss: 0.2546\n",
      "[1524/1762] D loss: 2.9267, G loss: 0.2562\n",
      "[1604/1762] D loss: 3.6629, G loss: 0.3967\n",
      "[1684/1762] D loss: 3.1585, G loss: 0.2809\n",
      "[1762/1762] D loss: 2.9378, G loss: 0.1784\n",
      "train error: \n",
      " D loss: 3.105761, G loss: 0.245074, D accuracy: 0.5%, cell accuracy: 93.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.143610, G loss: 0.257168, D accuracy: 0.2%, cell accuracy: 93.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 3.0394, G loss: 0.2605\n",
      "[84/1762] D loss: 3.2227, G loss: 0.2384\n",
      "[164/1762] D loss: 3.7081, G loss: 0.4644\n",
      "[244/1762] D loss: 2.9988, G loss: 0.2259\n",
      "[324/1762] D loss: 2.8785, G loss: 0.2619\n",
      "[404/1762] D loss: 2.7219, G loss: 0.2486\n",
      "[484/1762] D loss: 3.0898, G loss: 0.2300\n",
      "[564/1762] D loss: 2.7827, G loss: 0.2581\n",
      "[644/1762] D loss: 2.7788, G loss: 0.1864\n",
      "[724/1762] D loss: 3.2584, G loss: 0.3074\n",
      "[804/1762] D loss: 3.3815, G loss: 0.3110\n",
      "[884/1762] D loss: 2.7131, G loss: 0.2405\n",
      "[964/1762] D loss: 2.8170, G loss: 0.3297\n",
      "[1044/1762] D loss: 3.3597, G loss: 0.2648\n",
      "[1124/1762] D loss: 2.7840, G loss: 0.2975\n",
      "[1204/1762] D loss: 2.8921, G loss: 0.2784\n",
      "[1284/1762] D loss: 3.2536, G loss: 0.2604\n",
      "[1364/1762] D loss: 3.0782, G loss: 0.3353\n",
      "[1444/1762] D loss: 2.8286, G loss: 0.3551\n",
      "[1524/1762] D loss: 3.0497, G loss: 0.2383\n",
      "[1604/1762] D loss: 3.9766, G loss: 0.4249\n",
      "[1684/1762] D loss: 3.7357, G loss: 0.2979\n",
      "[1762/1762] D loss: 2.8367, G loss: 0.2756\n",
      "train error: \n",
      " D loss: 3.168994, G loss: 0.235056, D accuracy: 0.3%, cell accuracy: 93.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.196609, G loss: 0.249832, D accuracy: 0.2%, cell accuracy: 93.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 3.4904, G loss: 0.3127\n",
      "[84/1762] D loss: 3.2648, G loss: 0.2963\n",
      "[164/1762] D loss: 3.7128, G loss: 0.3337\n",
      "[244/1762] D loss: 3.2414, G loss: 0.3735\n",
      "[324/1762] D loss: 3.0064, G loss: 0.3423\n",
      "[404/1762] D loss: 2.7874, G loss: 0.2200\n",
      "[484/1762] D loss: 2.8096, G loss: 0.2033\n",
      "[564/1762] D loss: 2.7785, G loss: 0.2791\n",
      "[644/1762] D loss: 2.7149, G loss: 0.2298\n",
      "[724/1762] D loss: 3.7523, G loss: 0.3512\n",
      "[804/1762] D loss: 3.4443, G loss: 0.3126\n",
      "[884/1762] D loss: 3.6207, G loss: 0.3219\n",
      "[964/1762] D loss: 3.2975, G loss: 0.2727\n",
      "[1044/1762] D loss: 3.4637, G loss: 0.3389\n",
      "[1124/1762] D loss: 3.1952, G loss: 0.2723\n",
      "[1204/1762] D loss: 2.9136, G loss: 0.2938\n",
      "[1284/1762] D loss: 3.2786, G loss: 0.2673\n",
      "[1364/1762] D loss: 2.8776, G loss: 0.2827\n",
      "[1444/1762] D loss: 3.0464, G loss: 0.3131\n",
      "[1524/1762] D loss: 3.8245, G loss: 0.3544\n",
      "[1604/1762] D loss: 2.9468, G loss: 0.3075\n",
      "[1684/1762] D loss: 3.2643, G loss: 0.2477\n",
      "[1762/1762] D loss: 3.3417, G loss: 0.2881\n",
      "train error: \n",
      " D loss: 3.104558, G loss: 0.236856, D accuracy: 0.5%, cell accuracy: 93.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.133408, G loss: 0.250652, D accuracy: 0.3%, cell accuracy: 93.5%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.8339, G loss: 0.2287\n",
      "[84/1762] D loss: 2.7968, G loss: 0.2717\n",
      "[164/1762] D loss: 3.5423, G loss: 0.2498\n",
      "[244/1762] D loss: 3.4779, G loss: 0.2490\n",
      "[324/1762] D loss: 3.4723, G loss: 0.3140\n",
      "[404/1762] D loss: 3.6915, G loss: 0.4784\n",
      "[484/1762] D loss: 2.9021, G loss: 0.2519\n",
      "[564/1762] D loss: 3.3016, G loss: 0.2735\n",
      "[644/1762] D loss: 3.0132, G loss: 0.4232\n",
      "[724/1762] D loss: 3.6683, G loss: 0.2729\n",
      "[804/1762] D loss: 3.6318, G loss: 0.3156\n",
      "[884/1762] D loss: 3.3471, G loss: 0.2281\n",
      "[964/1762] D loss: 2.8445, G loss: 0.2541\n",
      "[1044/1762] D loss: 3.5246, G loss: 0.3060\n",
      "[1124/1762] D loss: 2.6978, G loss: 0.2612\n",
      "[1204/1762] D loss: 3.6251, G loss: 0.3890\n",
      "[1284/1762] D loss: 3.4979, G loss: 0.2622\n",
      "[1364/1762] D loss: 2.7580, G loss: 0.2305\n",
      "[1444/1762] D loss: 2.6146, G loss: 0.2762\n",
      "[1524/1762] D loss: 3.6481, G loss: 0.2417\n",
      "[1604/1762] D loss: 3.1341, G loss: 0.2166\n",
      "[1684/1762] D loss: 3.3587, G loss: 0.2437\n",
      "[1762/1762] D loss: 3.1800, G loss: 0.3796\n",
      "train error: \n",
      " D loss: 3.133468, G loss: 0.238081, D accuracy: 0.4%, cell accuracy: 93.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.166545, G loss: 0.250745, D accuracy: 0.0%, cell accuracy: 93.8%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.9595, G loss: 0.2701\n",
      "[84/1762] D loss: 2.9783, G loss: 0.3373\n",
      "[164/1762] D loss: 3.1681, G loss: 0.2412\n",
      "[244/1762] D loss: 3.7485, G loss: 0.2832\n",
      "[324/1762] D loss: 3.0759, G loss: 0.2071\n",
      "[404/1762] D loss: 3.0354, G loss: 0.2393\n",
      "[484/1762] D loss: 3.3550, G loss: 0.3080\n",
      "[564/1762] D loss: 2.7036, G loss: 0.2913\n",
      "[644/1762] D loss: 3.2603, G loss: 0.2591\n",
      "[724/1762] D loss: 3.0319, G loss: 0.2448\n",
      "[804/1762] D loss: 2.9114, G loss: 0.3559\n",
      "[884/1762] D loss: 3.4526, G loss: 0.2840\n",
      "[964/1762] D loss: 3.3423, G loss: 0.2980\n",
      "[1044/1762] D loss: 3.5242, G loss: 0.2367\n",
      "[1124/1762] D loss: 3.0356, G loss: 0.1956\n",
      "[1204/1762] D loss: 3.2328, G loss: 0.2216\n",
      "[1284/1762] D loss: 2.8923, G loss: 0.2336\n",
      "[1364/1762] D loss: 3.0059, G loss: 0.2751\n",
      "[1444/1762] D loss: 3.2466, G loss: 0.2788\n",
      "[1524/1762] D loss: 3.1718, G loss: 0.3171\n",
      "[1604/1762] D loss: 3.3708, G loss: 0.2726\n",
      "[1684/1762] D loss: 3.2376, G loss: 0.2080\n",
      "[1762/1762] D loss: 2.8140, G loss: 0.2136\n",
      "train error: \n",
      " D loss: 3.231077, G loss: 0.207011, D accuracy: 0.5%, cell accuracy: 93.4%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.245501, G loss: 0.222284, D accuracy: 0.5%, cell accuracy: 93.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 3.0333, G loss: 0.2509\n",
      "[84/1762] D loss: 3.7856, G loss: 0.2848\n",
      "[164/1762] D loss: 2.8918, G loss: 0.1895\n",
      "[244/1762] D loss: 2.7129, G loss: 0.1855\n",
      "[324/1762] D loss: 3.3451, G loss: 0.2163\n",
      "[404/1762] D loss: 3.3712, G loss: 0.2856\n",
      "[484/1762] D loss: 3.4890, G loss: 0.1419\n",
      "[564/1762] D loss: 2.7303, G loss: 0.2392\n",
      "[644/1762] D loss: 3.8012, G loss: 0.2725\n",
      "[724/1762] D loss: 2.7649, G loss: 0.2081\n",
      "[804/1762] D loss: 3.1655, G loss: 0.1697\n",
      "[884/1762] D loss: 3.1382, G loss: 0.2069\n",
      "[964/1762] D loss: 3.1491, G loss: 0.2629\n",
      "[1044/1762] D loss: 2.8971, G loss: 0.3100\n",
      "[1124/1762] D loss: 3.0957, G loss: 0.2822\n",
      "[1204/1762] D loss: 3.1626, G loss: 0.4179\n",
      "[1284/1762] D loss: 3.5594, G loss: 0.1780\n",
      "[1364/1762] D loss: 2.8145, G loss: 0.2336\n",
      "[1444/1762] D loss: 3.7571, G loss: 0.2893\n",
      "[1524/1762] D loss: 3.3741, G loss: 0.2346\n",
      "[1604/1762] D loss: 3.8352, G loss: 0.2854\n",
      "[1684/1762] D loss: 2.9317, G loss: 0.2973\n",
      "[1762/1762] D loss: 2.9485, G loss: 0.3037\n",
      "train error: \n",
      " D loss: 3.127178, G loss: 0.233277, D accuracy: 0.4%, cell accuracy: 93.3%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.145036, G loss: 0.249584, D accuracy: 0.2%, cell accuracy: 93.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.9972, G loss: 0.1975\n",
      "[84/1762] D loss: 3.5969, G loss: 0.2466\n",
      "[164/1762] D loss: 3.3858, G loss: 0.2338\n",
      "[244/1762] D loss: 3.5979, G loss: 0.2774\n",
      "[324/1762] D loss: 3.5923, G loss: 0.2467\n",
      "[404/1762] D loss: 2.7799, G loss: 0.1783\n",
      "[484/1762] D loss: 3.0983, G loss: 0.1668\n",
      "[564/1762] D loss: 3.1554, G loss: 0.3180\n",
      "[644/1762] D loss: 2.8462, G loss: 0.2748\n",
      "[724/1762] D loss: 2.8848, G loss: 0.1837\n",
      "[804/1762] D loss: 4.0431, G loss: 0.2911\n",
      "[884/1762] D loss: 3.2751, G loss: 0.3936\n",
      "[964/1762] D loss: 3.2487, G loss: 0.2209\n",
      "[1044/1762] D loss: 3.1199, G loss: 0.2984\n",
      "[1124/1762] D loss: 2.9839, G loss: 0.2749\n",
      "[1204/1762] D loss: 3.2454, G loss: 0.2496\n",
      "[1284/1762] D loss: 2.9748, G loss: 0.2436\n",
      "[1364/1762] D loss: 2.9097, G loss: 0.2618\n",
      "[1444/1762] D loss: 3.4464, G loss: 0.2408\n",
      "[1524/1762] D loss: 3.6679, G loss: 0.2853\n",
      "[1604/1762] D loss: 3.3555, G loss: 0.1734\n",
      "[1684/1762] D loss: 3.3993, G loss: 0.2230\n",
      "[1762/1762] D loss: 3.5252, G loss: 0.1852\n",
      "train error: \n",
      " D loss: 3.143434, G loss: 0.219837, D accuracy: 0.5%, cell accuracy: 93.4%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.161686, G loss: 0.233976, D accuracy: 0.3%, cell accuracy: 93.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.9519, G loss: 0.2240\n",
      "[84/1762] D loss: 2.8086, G loss: 0.2000\n",
      "[164/1762] D loss: 3.2504, G loss: 0.2090\n",
      "[244/1762] D loss: 2.8910, G loss: 0.2407\n",
      "[324/1762] D loss: 3.0722, G loss: 0.2904\n",
      "[404/1762] D loss: 2.7305, G loss: 0.2190\n",
      "[484/1762] D loss: 3.3260, G loss: 0.2480\n",
      "[564/1762] D loss: 3.9287, G loss: 0.2562\n",
      "[644/1762] D loss: 2.8712, G loss: 0.2161\n",
      "[724/1762] D loss: 3.2235, G loss: 0.2329\n",
      "[804/1762] D loss: 3.1085, G loss: 0.1427\n",
      "[884/1762] D loss: 3.7690, G loss: 0.3319\n",
      "[964/1762] D loss: 3.5737, G loss: 0.2013\n",
      "[1044/1762] D loss: 3.7663, G loss: 0.1819\n",
      "[1124/1762] D loss: 3.5544, G loss: 0.2613\n",
      "[1204/1762] D loss: 3.7856, G loss: 0.2958\n",
      "[1284/1762] D loss: 3.4751, G loss: 0.2765\n",
      "[1364/1762] D loss: 3.5748, G loss: 0.2276\n",
      "[1444/1762] D loss: 3.0320, G loss: 0.2934\n",
      "[1524/1762] D loss: 3.3848, G loss: 0.3840\n",
      "[1604/1762] D loss: 3.0390, G loss: 0.2077\n",
      "[1684/1762] D loss: 3.2471, G loss: 0.2341\n",
      "[1762/1762] D loss: 3.8008, G loss: 0.2190\n",
      "train error: \n",
      " D loss: 3.224667, G loss: 0.228960, D accuracy: 0.3%, cell accuracy: 93.3%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.245492, G loss: 0.243948, D accuracy: 0.5%, cell accuracy: 93.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 3.0760, G loss: 0.1796\n",
      "[84/1762] D loss: 3.5247, G loss: 0.1737\n",
      "[164/1762] D loss: 3.0606, G loss: 0.3287\n",
      "[244/1762] D loss: 3.4670, G loss: 0.2305\n",
      "[324/1762] D loss: 3.2806, G loss: 0.1726\n",
      "[404/1762] D loss: 3.3173, G loss: 0.2461\n",
      "[484/1762] D loss: 3.4261, G loss: 0.2774\n",
      "[564/1762] D loss: 3.3773, G loss: 0.2537\n",
      "[644/1762] D loss: 2.9266, G loss: 0.1966\n",
      "[724/1762] D loss: 3.6690, G loss: 0.3247\n",
      "[804/1762] D loss: 2.9361, G loss: 0.2490\n",
      "[884/1762] D loss: 3.3617, G loss: 0.2687\n",
      "[964/1762] D loss: 2.8946, G loss: 0.1996\n",
      "[1044/1762] D loss: 2.8550, G loss: 0.2048\n",
      "[1124/1762] D loss: 3.0980, G loss: 0.2747\n",
      "[1204/1762] D loss: 3.4347, G loss: 0.3571\n",
      "[1284/1762] D loss: 3.2001, G loss: 0.3233\n",
      "[1364/1762] D loss: 2.9520, G loss: 0.1602\n",
      "[1444/1762] D loss: 3.0798, G loss: 0.2195\n",
      "[1524/1762] D loss: 2.9457, G loss: 0.2060\n",
      "[1604/1762] D loss: 3.0288, G loss: 0.1784\n",
      "[1684/1762] D loss: 3.1731, G loss: 0.2493\n",
      "[1762/1762] D loss: 2.9845, G loss: 0.2533\n",
      "train error: \n",
      " D loss: 3.257564, G loss: 0.193453, D accuracy: 0.7%, cell accuracy: 92.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.271544, G loss: 0.207488, D accuracy: 0.5%, cell accuracy: 92.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.8527, G loss: 0.2372\n",
      "[84/1762] D loss: 3.2238, G loss: 0.2896\n",
      "[164/1762] D loss: 2.7533, G loss: 0.3044\n",
      "[244/1762] D loss: 3.0684, G loss: 0.3130\n",
      "[324/1762] D loss: 3.4545, G loss: 0.2660\n",
      "[404/1762] D loss: 3.0015, G loss: 0.2308\n",
      "[484/1762] D loss: 2.9496, G loss: 0.2246\n",
      "[564/1762] D loss: 3.7817, G loss: 0.3161\n",
      "[644/1762] D loss: 3.1456, G loss: 0.2781\n",
      "[724/1762] D loss: 3.6745, G loss: 0.2386\n",
      "[804/1762] D loss: 2.8468, G loss: 0.2716\n",
      "[884/1762] D loss: 3.2457, G loss: 0.2624\n",
      "[964/1762] D loss: 2.9854, G loss: 0.1845\n",
      "[1044/1762] D loss: 2.8962, G loss: 0.2476\n",
      "[1124/1762] D loss: 3.8735, G loss: 0.3812\n",
      "[1204/1762] D loss: 2.9279, G loss: 0.2382\n",
      "[1284/1762] D loss: 3.4756, G loss: 0.2574\n",
      "[1364/1762] D loss: 3.0899, G loss: 0.2717\n",
      "[1444/1762] D loss: 2.8084, G loss: 0.1560\n",
      "[1524/1762] D loss: 3.7138, G loss: 0.2044\n",
      "[1604/1762] D loss: 3.5813, G loss: 0.2267\n",
      "[1684/1762] D loss: 3.2985, G loss: 0.2238\n",
      "[1762/1762] D loss: 3.1667, G loss: 0.3109\n",
      "train error: \n",
      " D loss: 3.247412, G loss: 0.220662, D accuracy: 0.2%, cell accuracy: 93.3%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.261905, G loss: 0.238425, D accuracy: 0.1%, cell accuracy: 93.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 3.4099, G loss: 0.2086\n",
      "[84/1762] D loss: 3.1999, G loss: 0.3166\n",
      "[164/1762] D loss: 3.2772, G loss: 0.3746\n",
      "[244/1762] D loss: 3.2130, G loss: 0.1693\n",
      "[324/1762] D loss: 3.3968, G loss: 0.2010\n",
      "[404/1762] D loss: 3.6516, G loss: 0.1925\n",
      "[484/1762] D loss: 3.4223, G loss: 0.2551\n",
      "[564/1762] D loss: 3.4738, G loss: 0.2019\n",
      "[644/1762] D loss: 3.4698, G loss: 0.1653\n",
      "[724/1762] D loss: 3.5525, G loss: 0.2078\n",
      "[804/1762] D loss: 3.6308, G loss: 0.3085\n",
      "[884/1762] D loss: 2.7971, G loss: 0.3218\n",
      "[964/1762] D loss: 3.0032, G loss: 0.2261\n",
      "[1044/1762] D loss: 3.3802, G loss: 0.2685\n",
      "[1124/1762] D loss: 3.4336, G loss: 0.1812\n",
      "[1204/1762] D loss: 3.1566, G loss: 0.2835\n",
      "[1284/1762] D loss: 3.4548, G loss: 0.2361\n",
      "[1364/1762] D loss: 3.8820, G loss: 0.2309\n",
      "[1444/1762] D loss: 3.0768, G loss: 0.2194\n",
      "[1524/1762] D loss: 3.4097, G loss: 0.2130\n",
      "[1604/1762] D loss: 3.8413, G loss: 0.3855\n",
      "[1684/1762] D loss: 3.1115, G loss: 0.1697\n",
      "[1762/1762] D loss: 3.2175, G loss: 0.1384\n",
      "train error: \n",
      " D loss: 3.252660, G loss: 0.210157, D accuracy: 0.5%, cell accuracy: 93.2%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.274383, G loss: 0.225410, D accuracy: 0.2%, cell accuracy: 93.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 3.6983, G loss: 0.3351\n",
      "[84/1762] D loss: 3.3403, G loss: 0.1853\n",
      "[164/1762] D loss: 2.8195, G loss: 0.2248\n",
      "[244/1762] D loss: 3.0292, G loss: 0.2463\n",
      "[324/1762] D loss: 3.4925, G loss: 0.1900\n",
      "[404/1762] D loss: 3.0209, G loss: 0.2491\n",
      "[484/1762] D loss: 2.7442, G loss: 0.2895\n",
      "[564/1762] D loss: 3.6276, G loss: 0.2666\n",
      "[644/1762] D loss: 3.4527, G loss: 0.2039\n",
      "[724/1762] D loss: 3.9765, G loss: 0.2266\n",
      "[804/1762] D loss: 2.9235, G loss: 0.2914\n",
      "[884/1762] D loss: 3.0861, G loss: 0.2979\n",
      "[964/1762] D loss: 4.0078, G loss: 0.2511\n",
      "[1044/1762] D loss: 3.0369, G loss: 0.1968\n",
      "[1124/1762] D loss: 3.5984, G loss: 0.2194\n",
      "[1204/1762] D loss: 3.7326, G loss: 0.2376\n",
      "[1284/1762] D loss: 3.4697, G loss: 0.2606\n",
      "[1364/1762] D loss: 3.4201, G loss: 0.3068\n",
      "[1444/1762] D loss: 2.8402, G loss: 0.2814\n",
      "[1524/1762] D loss: 3.3843, G loss: 0.1905\n",
      "[1604/1762] D loss: 3.4760, G loss: 0.2388\n",
      "[1684/1762] D loss: 3.5838, G loss: 0.2078\n",
      "[1762/1762] D loss: 2.7646, G loss: 0.2527\n",
      "train error: \n",
      " D loss: 3.257049, G loss: 0.197776, D accuracy: 0.6%, cell accuracy: 93.0%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.276753, G loss: 0.211579, D accuracy: 0.5%, cell accuracy: 92.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 3.4858, G loss: 0.1953\n",
      "[84/1762] D loss: 3.4523, G loss: 0.2466\n",
      "[164/1762] D loss: 3.7613, G loss: 0.2640\n",
      "[244/1762] D loss: 3.1196, G loss: 0.1997\n",
      "[324/1762] D loss: 3.5505, G loss: 0.2527\n",
      "[404/1762] D loss: 3.8266, G loss: 0.2037\n",
      "[484/1762] D loss: 3.3682, G loss: 0.2499\n",
      "[564/1762] D loss: 3.9034, G loss: 0.2154\n",
      "[644/1762] D loss: 2.9739, G loss: 0.2328\n",
      "[724/1762] D loss: 3.3633, G loss: 0.3367\n",
      "[804/1762] D loss: 3.4058, G loss: 0.1942\n",
      "[884/1762] D loss: 3.0968, G loss: 0.2598\n",
      "[964/1762] D loss: 3.2137, G loss: 0.2791\n",
      "[1044/1762] D loss: 4.3252, G loss: 0.2550\n",
      "[1124/1762] D loss: 2.9717, G loss: 0.2336\n",
      "[1204/1762] D loss: 3.2171, G loss: 0.1599\n",
      "[1284/1762] D loss: 3.5330, G loss: 0.2259\n",
      "[1364/1762] D loss: 2.9472, G loss: 0.2786\n",
      "[1444/1762] D loss: 4.1339, G loss: 0.2067\n",
      "[1524/1762] D loss: 3.7726, G loss: 0.2919\n",
      "[1604/1762] D loss: 3.6419, G loss: 0.2390\n",
      "[1684/1762] D loss: 3.1372, G loss: 0.2206\n",
      "[1762/1762] D loss: 3.6637, G loss: 0.2468\n",
      "train error: \n",
      " D loss: 3.181717, G loss: 0.198467, D accuracy: 0.9%, cell accuracy: 93.0%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.203369, G loss: 0.210450, D accuracy: 0.7%, cell accuracy: 93.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 3.6770, G loss: 0.2649\n",
      "[84/1762] D loss: 3.5923, G loss: 0.3264\n",
      "[164/1762] D loss: 3.5770, G loss: 0.3063\n",
      "[244/1762] D loss: 2.8977, G loss: 0.2576\n",
      "[324/1762] D loss: 2.9974, G loss: 0.2373\n",
      "[404/1762] D loss: 3.8498, G loss: 0.2542\n",
      "[484/1762] D loss: 3.5988, G loss: 0.2330\n",
      "[564/1762] D loss: 3.0290, G loss: 0.2344\n",
      "[644/1762] D loss: 2.9649, G loss: 0.2237\n",
      "[724/1762] D loss: 3.1995, G loss: 0.2359\n",
      "[804/1762] D loss: 3.3470, G loss: 0.2124\n",
      "[884/1762] D loss: 3.1941, G loss: 0.2223\n",
      "[964/1762] D loss: 3.3906, G loss: 0.2587\n",
      "[1044/1762] D loss: 3.4712, G loss: 0.1897\n",
      "[1124/1762] D loss: 2.9958, G loss: 0.2164\n",
      "[1204/1762] D loss: 3.6492, G loss: 0.2399\n",
      "[1284/1762] D loss: 3.0281, G loss: 0.1802\n",
      "[1364/1762] D loss: 2.7335, G loss: 0.2562\n",
      "[1444/1762] D loss: 3.1958, G loss: 0.3445\n",
      "[1524/1762] D loss: 3.3515, G loss: 0.2611\n",
      "[1604/1762] D loss: 2.8102, G loss: 0.2351\n",
      "[1684/1762] D loss: 3.4539, G loss: 0.1877\n",
      "[1762/1762] D loss: 3.3375, G loss: 0.1322\n",
      "train error: \n",
      " D loss: 3.274706, G loss: 0.206184, D accuracy: 0.4%, cell accuracy: 93.0%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.299948, G loss: 0.220553, D accuracy: 0.1%, cell accuracy: 93.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.8830, G loss: 0.2222\n",
      "[84/1762] D loss: 3.1690, G loss: 0.2008\n",
      "[164/1762] D loss: 2.7829, G loss: 0.1823\n",
      "[244/1762] D loss: 3.8919, G loss: 0.2526\n",
      "[324/1762] D loss: 2.9537, G loss: 0.2323\n",
      "[404/1762] D loss: 2.9153, G loss: 0.2826\n",
      "[484/1762] D loss: 3.1407, G loss: 0.2337\n",
      "[564/1762] D loss: 3.3876, G loss: 0.1758\n",
      "[644/1762] D loss: 3.2401, G loss: 0.2360\n",
      "[724/1762] D loss: 3.2219, G loss: 0.1417\n",
      "[804/1762] D loss: 2.9962, G loss: 0.2081\n",
      "[884/1762] D loss: 3.6935, G loss: 0.1689\n",
      "[964/1762] D loss: 3.3700, G loss: 0.1670\n",
      "[1044/1762] D loss: 2.9571, G loss: 0.3322\n",
      "[1124/1762] D loss: 3.3534, G loss: 0.2234\n",
      "[1204/1762] D loss: 3.3921, G loss: 0.1970\n",
      "[1284/1762] D loss: 3.4988, G loss: 0.2552\n",
      "[1364/1762] D loss: 3.0746, G loss: 0.1832\n",
      "[1444/1762] D loss: 3.3524, G loss: 0.1982\n",
      "[1524/1762] D loss: 3.9204, G loss: 0.2072\n",
      "[1604/1762] D loss: 3.7764, G loss: 0.2693\n",
      "[1684/1762] D loss: 3.1653, G loss: 0.1736\n",
      "[1762/1762] D loss: 2.9443, G loss: 0.2120\n",
      "train error: \n",
      " D loss: 3.292350, G loss: 0.204107, D accuracy: 0.3%, cell accuracy: 93.0%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.319125, G loss: 0.217407, D accuracy: 0.1%, cell accuracy: 93.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 3.3995, G loss: 0.2231\n",
      "[84/1762] D loss: 2.5914, G loss: 0.2347\n",
      "[164/1762] D loss: 3.1061, G loss: 0.2050\n",
      "[244/1762] D loss: 3.3771, G loss: 0.1815\n",
      "[324/1762] D loss: 3.1333, G loss: 0.2204\n",
      "[404/1762] D loss: 3.2765, G loss: 0.1843\n",
      "[484/1762] D loss: 3.1046, G loss: 0.2328\n",
      "[564/1762] D loss: 3.1518, G loss: 0.3311\n",
      "[644/1762] D loss: 3.1602, G loss: 0.1780\n",
      "[724/1762] D loss: 3.3102, G loss: 0.3129\n",
      "[804/1762] D loss: 3.6542, G loss: 0.2074\n",
      "[884/1762] D loss: 3.1284, G loss: 0.2784\n",
      "[964/1762] D loss: 3.1897, G loss: 0.1648\n",
      "[1044/1762] D loss: 3.2895, G loss: 0.1947\n",
      "[1124/1762] D loss: 3.0478, G loss: 0.2255\n",
      "[1204/1762] D loss: 3.1773, G loss: 0.2017\n",
      "[1284/1762] D loss: 3.1465, G loss: 0.2180\n",
      "[1364/1762] D loss: 3.0868, G loss: 0.2435\n",
      "[1444/1762] D loss: 3.0731, G loss: 0.1712\n",
      "[1524/1762] D loss: 3.2481, G loss: 0.1669\n",
      "[1604/1762] D loss: 2.9227, G loss: 0.2673\n",
      "[1684/1762] D loss: 3.4229, G loss: 0.3163\n",
      "[1762/1762] D loss: 3.9454, G loss: 0.2767\n",
      "train error: \n",
      " D loss: 3.315070, G loss: 0.194704, D accuracy: 0.4%, cell accuracy: 93.0%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.339381, G loss: 0.207292, D accuracy: 0.1%, cell accuracy: 92.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 3.7118, G loss: 0.2741\n",
      "[84/1762] D loss: 3.1483, G loss: 0.2518\n",
      "[164/1762] D loss: 3.2582, G loss: 0.1841\n",
      "[244/1762] D loss: 3.2611, G loss: 0.2619\n",
      "[324/1762] D loss: 2.9344, G loss: 0.2147\n",
      "[404/1762] D loss: 3.0564, G loss: 0.2216\n",
      "[484/1762] D loss: 3.4191, G loss: 0.2313\n",
      "[564/1762] D loss: 3.4973, G loss: 0.1983\n",
      "[644/1762] D loss: 3.2101, G loss: 0.1891\n",
      "[724/1762] D loss: 3.3419, G loss: 0.1856\n",
      "[804/1762] D loss: 2.9957, G loss: 0.3050\n",
      "[884/1762] D loss: 3.8079, G loss: 0.1945\n",
      "[964/1762] D loss: 3.5901, G loss: 0.2809\n",
      "[1044/1762] D loss: 2.9345, G loss: 0.1802\n",
      "[1124/1762] D loss: 3.2537, G loss: 0.2370\n",
      "[1204/1762] D loss: 3.4653, G loss: 0.2359\n",
      "[1284/1762] D loss: 2.9571, G loss: 0.2486\n",
      "[1364/1762] D loss: 3.3095, G loss: 0.2686\n",
      "[1444/1762] D loss: 3.5871, G loss: 0.2259\n",
      "[1524/1762] D loss: 3.2649, G loss: 0.2992\n",
      "[1604/1762] D loss: 3.3067, G loss: 0.1595\n",
      "[1684/1762] D loss: 3.7265, G loss: 0.1929\n",
      "[1762/1762] D loss: 3.6526, G loss: 0.2132\n",
      "train error: \n",
      " D loss: 3.344709, G loss: 0.194341, D accuracy: 0.3%, cell accuracy: 92.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.369752, G loss: 0.208014, D accuracy: 0.1%, cell accuracy: 92.8%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 3.0436, G loss: 0.1433\n",
      "[84/1762] D loss: 3.2759, G loss: 0.1990\n",
      "[164/1762] D loss: 3.7661, G loss: 0.2005\n",
      "[244/1762] D loss: 2.9833, G loss: 0.1903\n",
      "[324/1762] D loss: 3.0935, G loss: 0.1742\n",
      "[404/1762] D loss: 4.0360, G loss: 0.2162\n",
      "[484/1762] D loss: 2.9941, G loss: 0.2239\n",
      "[564/1762] D loss: 3.4268, G loss: 0.1692\n",
      "[644/1762] D loss: 3.7094, G loss: 0.2573\n",
      "[724/1762] D loss: 3.1110, G loss: 0.2454\n",
      "[804/1762] D loss: 3.5250, G loss: 0.1849\n",
      "[884/1762] D loss: 2.9590, G loss: 0.1917\n",
      "[964/1762] D loss: 3.0984, G loss: 0.2007\n",
      "[1044/1762] D loss: 3.3397, G loss: 0.2342\n",
      "[1124/1762] D loss: 3.3738, G loss: 0.2764\n",
      "[1204/1762] D loss: 3.1526, G loss: 0.2266\n",
      "[1284/1762] D loss: 3.1246, G loss: 0.2070\n",
      "[1364/1762] D loss: 4.1428, G loss: 0.1971\n",
      "[1444/1762] D loss: 2.9433, G loss: 0.2231\n",
      "[1524/1762] D loss: 3.2133, G loss: 0.1743\n",
      "[1604/1762] D loss: 3.2617, G loss: 0.2097\n",
      "[1684/1762] D loss: 3.1951, G loss: 0.2326\n",
      "[1762/1762] D loss: 3.4407, G loss: 0.3084\n",
      "train error: \n",
      " D loss: 3.274379, G loss: 0.203660, D accuracy: 0.2%, cell accuracy: 92.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.301233, G loss: 0.216190, D accuracy: 0.2%, cell accuracy: 92.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.8997, G loss: 0.2003\n",
      "[84/1762] D loss: 3.2303, G loss: 0.1876\n",
      "[164/1762] D loss: 3.5265, G loss: 0.1697\n",
      "[244/1762] D loss: 3.0541, G loss: 0.2074\n",
      "[324/1762] D loss: 3.7507, G loss: 0.2898\n",
      "[404/1762] D loss: 3.6849, G loss: 0.2342\n",
      "[484/1762] D loss: 3.1670, G loss: 0.2055\n",
      "[564/1762] D loss: 3.6898, G loss: 0.2058\n",
      "[644/1762] D loss: 3.5662, G loss: 0.1657\n",
      "[724/1762] D loss: 3.4629, G loss: 0.1948\n",
      "[804/1762] D loss: 3.4878, G loss: 0.2425\n",
      "[884/1762] D loss: 3.1035, G loss: 0.1689\n",
      "[964/1762] D loss: 3.8540, G loss: 0.1977\n",
      "[1044/1762] D loss: 2.9647, G loss: 0.1385\n",
      "[1124/1762] D loss: 2.9763, G loss: 0.1938\n",
      "[1204/1762] D loss: 4.0744, G loss: 0.2236\n",
      "[1284/1762] D loss: 3.0698, G loss: 0.1931\n",
      "[1364/1762] D loss: 3.2175, G loss: 0.2373\n",
      "[1444/1762] D loss: 2.9424, G loss: 0.2042\n",
      "[1524/1762] D loss: 2.9187, G loss: 0.2241\n",
      "[1604/1762] D loss: 2.9198, G loss: 0.1721\n",
      "[1684/1762] D loss: 3.5858, G loss: 0.2563\n",
      "[1762/1762] D loss: 2.9959, G loss: 0.2793\n",
      "train error: \n",
      " D loss: 3.280948, G loss: 0.203387, D accuracy: 0.2%, cell accuracy: 92.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.304261, G loss: 0.216683, D accuracy: 0.1%, cell accuracy: 92.8%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 3.0605, G loss: 0.2253\n",
      "[84/1762] D loss: 3.1029, G loss: 0.1709\n",
      "[164/1762] D loss: 4.0831, G loss: 0.2077\n",
      "[244/1762] D loss: 3.2982, G loss: 0.2438\n",
      "[324/1762] D loss: 3.7849, G loss: 0.2072\n",
      "[404/1762] D loss: 2.9321, G loss: 0.1806\n",
      "[484/1762] D loss: 3.0428, G loss: 0.1783\n",
      "[564/1762] D loss: 3.7780, G loss: 0.1997\n",
      "[644/1762] D loss: 3.2003, G loss: 0.2526\n",
      "[724/1762] D loss: 3.2494, G loss: 0.3644\n",
      "[804/1762] D loss: 2.9524, G loss: 0.3515\n",
      "[884/1762] D loss: 3.3440, G loss: 0.2562\n",
      "[964/1762] D loss: 2.6225, G loss: 0.2390\n",
      "[1044/1762] D loss: 2.8019, G loss: 0.2311\n",
      "[1124/1762] D loss: 3.6736, G loss: 0.2101\n",
      "[1204/1762] D loss: 3.5044, G loss: 0.1865\n",
      "[1284/1762] D loss: 3.4684, G loss: 0.1319\n",
      "[1364/1762] D loss: 3.1910, G loss: 0.2288\n",
      "[1444/1762] D loss: 3.6502, G loss: 0.2546\n",
      "[1524/1762] D loss: 3.2196, G loss: 0.1647\n",
      "[1604/1762] D loss: 3.5020, G loss: 0.1559\n",
      "[1684/1762] D loss: 2.8785, G loss: 0.2484\n",
      "[1762/1762] D loss: 3.3425, G loss: 0.3942\n",
      "train error: \n",
      " D loss: 3.290642, G loss: 0.203890, D accuracy: 0.2%, cell accuracy: 92.6%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.317537, G loss: 0.217162, D accuracy: 0.1%, cell accuracy: 92.5%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 3.0235, G loss: 0.1982\n",
      "[84/1762] D loss: 3.6187, G loss: 0.2078\n",
      "[164/1762] D loss: 3.9008, G loss: 0.2285\n",
      "[244/1762] D loss: 3.5136, G loss: 0.1963\n",
      "[324/1762] D loss: 3.8185, G loss: 0.1828\n",
      "[404/1762] D loss: 2.8960, G loss: 0.2771\n",
      "[484/1762] D loss: 3.7812, G loss: 0.2735\n",
      "[564/1762] D loss: 3.7688, G loss: 0.2501\n",
      "[644/1762] D loss: 3.4586, G loss: 0.2709\n",
      "[724/1762] D loss: 3.6347, G loss: 0.2322\n",
      "[804/1762] D loss: 3.4851, G loss: 0.1725\n",
      "[884/1762] D loss: 3.0985, G loss: 0.1643\n",
      "[964/1762] D loss: 3.2797, G loss: 0.1589\n",
      "[1044/1762] D loss: 3.3863, G loss: 0.1990\n",
      "[1124/1762] D loss: 3.4758, G loss: 0.2537\n",
      "[1204/1762] D loss: 3.3414, G loss: 0.2083\n",
      "[1284/1762] D loss: 3.1290, G loss: 0.1608\n",
      "[1364/1762] D loss: 3.2043, G loss: 0.1986\n",
      "[1444/1762] D loss: 3.1244, G loss: 0.1583\n",
      "[1524/1762] D loss: 3.7526, G loss: 0.2072\n",
      "[1604/1762] D loss: 3.2177, G loss: 0.1518\n",
      "[1684/1762] D loss: 3.0570, G loss: 0.1926\n",
      "[1762/1762] D loss: 3.1180, G loss: 0.1974\n",
      "train error: \n",
      " D loss: 3.381800, G loss: 0.181672, D accuracy: 0.3%, cell accuracy: 92.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.402978, G loss: 0.194227, D accuracy: 0.1%, cell accuracy: 92.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 3.0397, G loss: 0.1934\n",
      "[84/1762] D loss: 2.8816, G loss: 0.2662\n",
      "[164/1762] D loss: 3.6779, G loss: 0.2291\n",
      "[244/1762] D loss: 3.2987, G loss: 0.2483\n",
      "[324/1762] D loss: 3.3437, G loss: 0.2307\n",
      "[404/1762] D loss: 3.5233, G loss: 0.2143\n",
      "[484/1762] D loss: 3.6394, G loss: 0.2563\n",
      "[564/1762] D loss: 3.1089, G loss: 0.2408\n",
      "[644/1762] D loss: 3.4961, G loss: 0.1742\n",
      "[724/1762] D loss: 3.0154, G loss: 0.1863\n",
      "[804/1762] D loss: 3.3462, G loss: 0.1544\n",
      "[884/1762] D loss: 3.6017, G loss: 0.1473\n",
      "[964/1762] D loss: 3.3544, G loss: 0.2299\n",
      "[1044/1762] D loss: 3.5118, G loss: 0.2722\n",
      "[1124/1762] D loss: 3.5282, G loss: 0.2659\n",
      "[1204/1762] D loss: 3.4680, G loss: 0.2040\n",
      "[1284/1762] D loss: 3.1203, G loss: 0.1690\n",
      "[1364/1762] D loss: 2.9438, G loss: 0.1875\n",
      "[1444/1762] D loss: 3.3390, G loss: 0.2393\n",
      "[1524/1762] D loss: 3.9116, G loss: 0.2196\n",
      "[1604/1762] D loss: 3.0950, G loss: 0.1910\n",
      "[1684/1762] D loss: 4.0183, G loss: 0.2702\n",
      "[1762/1762] D loss: 3.7966, G loss: 0.2961\n",
      "train error: \n",
      " D loss: 3.371536, G loss: 0.188211, D accuracy: 0.2%, cell accuracy: 92.8%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.396668, G loss: 0.200573, D accuracy: 0.1%, cell accuracy: 92.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 3.5681, G loss: 0.2103\n",
      "[84/1762] D loss: 3.6652, G loss: 0.2957\n",
      "[164/1762] D loss: 3.1546, G loss: 0.1969\n",
      "[244/1762] D loss: 3.6403, G loss: 0.1567\n",
      "[324/1762] D loss: 3.2374, G loss: 0.2069\n",
      "[404/1762] D loss: 2.8143, G loss: 0.2030\n",
      "[484/1762] D loss: 3.5429, G loss: 0.2237\n",
      "[564/1762] D loss: 3.7174, G loss: 0.2121\n",
      "[644/1762] D loss: 3.2099, G loss: 0.2846\n",
      "[724/1762] D loss: 3.2349, G loss: 0.2286\n",
      "[804/1762] D loss: 3.3844, G loss: 0.1983\n",
      "[884/1762] D loss: 3.0030, G loss: 0.2098\n",
      "[964/1762] D loss: 2.8581, G loss: 0.2571\n",
      "[1044/1762] D loss: 3.6359, G loss: 0.3091\n",
      "[1124/1762] D loss: 3.6987, G loss: 0.1994\n",
      "[1204/1762] D loss: 2.9015, G loss: 0.1712\n",
      "[1284/1762] D loss: 3.1262, G loss: 0.2174\n",
      "[1364/1762] D loss: 3.1440, G loss: 0.2090\n",
      "[1444/1762] D loss: 3.9221, G loss: 0.2144\n",
      "[1524/1762] D loss: 3.2050, G loss: 0.1730\n",
      "[1604/1762] D loss: 3.4826, G loss: 0.2373\n",
      "[1684/1762] D loss: 3.6574, G loss: 0.1440\n",
      "[1762/1762] D loss: 3.6590, G loss: 0.1835\n",
      "train error: \n",
      " D loss: 3.407467, G loss: 0.172190, D accuracy: 0.5%, cell accuracy: 92.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.431204, G loss: 0.182143, D accuracy: 0.0%, cell accuracy: 92.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 3.1885, G loss: 0.1568\n",
      "[84/1762] D loss: 3.6412, G loss: 0.1329\n",
      "[164/1762] D loss: 3.0041, G loss: 0.2011\n",
      "[244/1762] D loss: 3.1255, G loss: 0.2306\n",
      "[324/1762] D loss: 3.4483, G loss: 0.2091\n",
      "[404/1762] D loss: 3.2804, G loss: 0.1998\n",
      "[484/1762] D loss: 3.4045, G loss: 0.2146\n",
      "[564/1762] D loss: 3.1942, G loss: 0.3045\n",
      "[644/1762] D loss: 3.8403, G loss: 0.1795\n",
      "[724/1762] D loss: 3.0985, G loss: 0.2066\n",
      "[804/1762] D loss: 3.0147, G loss: 0.1785\n",
      "[884/1762] D loss: 3.4951, G loss: 0.1744\n",
      "[964/1762] D loss: 3.1478, G loss: 0.2133\n",
      "[1044/1762] D loss: 3.2258, G loss: 0.2160\n",
      "[1124/1762] D loss: 3.0466, G loss: 0.1878\n",
      "[1204/1762] D loss: 3.1720, G loss: 0.2306\n",
      "[1284/1762] D loss: 3.7974, G loss: 0.2668\n",
      "[1364/1762] D loss: 3.4310, G loss: 0.2181\n",
      "[1444/1762] D loss: 3.4221, G loss: 0.1917\n",
      "[1524/1762] D loss: 3.1443, G loss: 0.2298\n",
      "[1604/1762] D loss: 3.0969, G loss: 0.1941\n",
      "[1684/1762] D loss: 3.3307, G loss: 0.1648\n",
      "[1762/1762] D loss: 4.3007, G loss: 0.1843\n",
      "train error: \n",
      " D loss: 3.357798, G loss: 0.183379, D accuracy: 0.4%, cell accuracy: 92.8%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.375986, G loss: 0.196733, D accuracy: 0.1%, cell accuracy: 92.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 3.4507, G loss: 0.2619\n",
      "[84/1762] D loss: 4.0816, G loss: 0.1956\n",
      "[164/1762] D loss: 3.0754, G loss: 0.2074\n",
      "[244/1762] D loss: 3.6672, G loss: 0.2851\n",
      "[324/1762] D loss: 3.7102, G loss: 0.1533\n",
      "[404/1762] D loss: 3.0708, G loss: 0.1910\n",
      "[484/1762] D loss: 3.4478, G loss: 0.1733\n",
      "[564/1762] D loss: 3.9288, G loss: 0.1810\n",
      "[644/1762] D loss: 3.3733, G loss: 0.2516\n",
      "[724/1762] D loss: 3.3294, G loss: 0.2489\n",
      "[804/1762] D loss: 3.2195, G loss: 0.2573\n",
      "[884/1762] D loss: 3.3177, G loss: 0.2017\n",
      "[964/1762] D loss: 2.9266, G loss: 0.2252\n",
      "[1044/1762] D loss: 2.8723, G loss: 0.2565\n",
      "[1124/1762] D loss: 3.1934, G loss: 0.3270\n",
      "[1204/1762] D loss: 3.0177, G loss: 0.1682\n",
      "[1284/1762] D loss: 3.7177, G loss: 0.1960\n",
      "[1364/1762] D loss: 3.0594, G loss: 0.2426\n",
      "[1444/1762] D loss: 3.2890, G loss: 0.1551\n",
      "[1524/1762] D loss: 3.4350, G loss: 0.2742\n",
      "[1604/1762] D loss: 3.1878, G loss: 0.1663\n",
      "[1684/1762] D loss: 3.4348, G loss: 0.1786\n",
      "[1762/1762] D loss: 3.9758, G loss: 0.2175\n",
      "train error: \n",
      " D loss: 3.357313, G loss: 0.174324, D accuracy: 0.5%, cell accuracy: 92.8%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.375137, G loss: 0.185603, D accuracy: 0.1%, cell accuracy: 92.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 3.5617, G loss: 0.1767\n",
      "[84/1762] D loss: 2.9903, G loss: 0.1977\n",
      "[164/1762] D loss: 3.7874, G loss: 0.2598\n",
      "[244/1762] D loss: 3.2517, G loss: 0.2931\n",
      "[324/1762] D loss: 3.1184, G loss: 0.1260\n",
      "[404/1762] D loss: 3.7682, G loss: 0.2150\n",
      "[484/1762] D loss: 2.8435, G loss: 0.2370\n",
      "[564/1762] D loss: 3.7677, G loss: 0.2707\n",
      "[644/1762] D loss: 3.4811, G loss: 0.2104\n",
      "[724/1762] D loss: 3.6451, G loss: 0.2160\n",
      "[804/1762] D loss: 3.1477, G loss: 0.1307\n",
      "[884/1762] D loss: 3.5572, G loss: 0.1971\n",
      "[964/1762] D loss: 3.3788, G loss: 0.2175\n",
      "[1044/1762] D loss: 3.0973, G loss: 0.1882\n",
      "[1124/1762] D loss: 2.9703, G loss: 0.2213\n",
      "[1204/1762] D loss: 3.0486, G loss: 0.1681\n",
      "[1284/1762] D loss: 3.6867, G loss: 0.1442\n",
      "[1364/1762] D loss: 3.1659, G loss: 0.1724\n",
      "[1444/1762] D loss: 2.6980, G loss: 0.2146\n",
      "[1524/1762] D loss: 3.1276, G loss: 0.3057\n",
      "[1604/1762] D loss: 3.5776, G loss: 0.1473\n",
      "[1684/1762] D loss: 3.5795, G loss: 0.1518\n",
      "[1762/1762] D loss: 4.1023, G loss: 0.2401\n",
      "train error: \n",
      " D loss: 3.394540, G loss: 0.172114, D accuracy: 0.4%, cell accuracy: 92.6%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.414790, G loss: 0.183440, D accuracy: 0.1%, cell accuracy: 92.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 3.2518, G loss: 0.2258\n",
      "[84/1762] D loss: 3.1861, G loss: 0.2749\n",
      "[164/1762] D loss: 3.4386, G loss: 0.1995\n",
      "[244/1762] D loss: 3.3137, G loss: 0.1865\n",
      "[324/1762] D loss: 3.6215, G loss: 0.2209\n",
      "[404/1762] D loss: 3.6884, G loss: 0.2580\n",
      "[484/1762] D loss: 3.5636, G loss: 0.2024\n",
      "[564/1762] D loss: 3.0460, G loss: 0.1599\n",
      "[644/1762] D loss: 3.2215, G loss: 0.1694\n",
      "[724/1762] D loss: 3.6063, G loss: 0.1622\n",
      "[804/1762] D loss: 3.5036, G loss: 0.1875\n",
      "[884/1762] D loss: 3.1633, G loss: 0.1246\n",
      "[964/1762] D loss: 3.1662, G loss: 0.1627\n",
      "[1044/1762] D loss: 3.1871, G loss: 0.2186\n",
      "[1124/1762] D loss: 2.9759, G loss: 0.1972\n",
      "[1204/1762] D loss: 3.3698, G loss: 0.2942\n",
      "[1284/1762] D loss: 3.6191, G loss: 0.1817\n",
      "[1364/1762] D loss: 3.6635, G loss: 0.1575\n",
      "[1444/1762] D loss: 3.3491, G loss: 0.2594\n",
      "[1524/1762] D loss: 3.0658, G loss: 0.2199\n",
      "[1604/1762] D loss: 2.9718, G loss: 0.1704\n",
      "[1684/1762] D loss: 3.1422, G loss: 0.2201\n",
      "[1762/1762] D loss: 2.9856, G loss: 0.1372\n",
      "train error: \n",
      " D loss: 3.334229, G loss: 0.184289, D accuracy: 0.4%, cell accuracy: 92.8%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.345543, G loss: 0.198742, D accuracy: 0.1%, cell accuracy: 92.8%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 3.1673, G loss: 0.1715\n",
      "[84/1762] D loss: 3.4328, G loss: 0.1449\n",
      "[164/1762] D loss: 3.2104, G loss: 0.2194\n",
      "[244/1762] D loss: 3.4354, G loss: 0.1700\n",
      "[324/1762] D loss: 3.3311, G loss: 0.1850\n",
      "[404/1762] D loss: 3.5527, G loss: 0.1461\n",
      "[484/1762] D loss: 3.8272, G loss: 0.1980\n",
      "[564/1762] D loss: 3.1265, G loss: 0.2040\n",
      "[644/1762] D loss: 3.2882, G loss: 0.2623\n",
      "[724/1762] D loss: 3.1664, G loss: 0.1768\n",
      "[804/1762] D loss: 3.9110, G loss: 0.2215\n",
      "[884/1762] D loss: 3.2963, G loss: 0.2158\n",
      "[964/1762] D loss: 3.3437, G loss: 0.2551\n",
      "[1044/1762] D loss: 3.1500, G loss: 0.1515\n",
      "[1124/1762] D loss: 3.1463, G loss: 0.1813\n",
      "[1204/1762] D loss: 3.0722, G loss: 0.2269\n",
      "[1284/1762] D loss: 3.0181, G loss: 0.2364\n",
      "[1364/1762] D loss: 2.9833, G loss: 0.2228\n",
      "[1444/1762] D loss: 3.5929, G loss: 0.2261\n",
      "[1524/1762] D loss: 3.1846, G loss: 0.1425\n",
      "[1604/1762] D loss: 3.3561, G loss: 0.1736\n",
      "[1684/1762] D loss: 3.3861, G loss: 0.1317\n",
      "[1762/1762] D loss: 3.4678, G loss: 0.1928\n",
      "train error: \n",
      " D loss: 3.426319, G loss: 0.167121, D accuracy: 0.4%, cell accuracy: 92.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.434908, G loss: 0.181201, D accuracy: 0.1%, cell accuracy: 92.5%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 3.5340, G loss: 0.2103\n",
      "[84/1762] D loss: 3.1248, G loss: 0.1938\n",
      "[164/1762] D loss: 3.8014, G loss: 0.2317\n",
      "[244/1762] D loss: 3.5636, G loss: 0.2209\n",
      "[324/1762] D loss: 3.5379, G loss: 0.1512\n",
      "[404/1762] D loss: 3.4489, G loss: 0.2110\n",
      "[484/1762] D loss: 3.5952, G loss: 0.1181\n",
      "[564/1762] D loss: 2.8912, G loss: 0.1912\n",
      "[644/1762] D loss: 3.2316, G loss: 0.1314\n",
      "[724/1762] D loss: 3.0849, G loss: 0.2813\n",
      "[804/1762] D loss: 3.3334, G loss: 0.2101\n",
      "[884/1762] D loss: 3.8762, G loss: 0.2275\n",
      "[964/1762] D loss: 3.2634, G loss: 0.2441\n",
      "[1044/1762] D loss: 3.4072, G loss: 0.2532\n",
      "[1124/1762] D loss: 3.1806, G loss: 0.2431\n",
      "[1204/1762] D loss: 3.1143, G loss: 0.1964\n",
      "[1284/1762] D loss: 3.5665, G loss: 0.1707\n",
      "[1364/1762] D loss: 3.1354, G loss: 0.2575\n",
      "[1444/1762] D loss: 3.7938, G loss: 0.1626\n",
      "[1524/1762] D loss: 3.1703, G loss: 0.1930\n",
      "[1604/1762] D loss: 3.5007, G loss: 0.2022\n",
      "[1684/1762] D loss: 3.4760, G loss: 0.1909\n",
      "[1762/1762] D loss: 3.6014, G loss: 0.1693\n",
      "train error: \n",
      " D loss: 3.403869, G loss: 0.171941, D accuracy: 0.4%, cell accuracy: 92.6%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.423489, G loss: 0.184848, D accuracy: 0.1%, cell accuracy: 92.5%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 3.3804, G loss: 0.1777\n",
      "[84/1762] D loss: 3.7024, G loss: 0.2124\n",
      "[164/1762] D loss: 3.0103, G loss: 0.1689\n",
      "[244/1762] D loss: 3.7600, G loss: 0.1516\n",
      "[324/1762] D loss: 3.7767, G loss: 0.1829\n",
      "[404/1762] D loss: 3.0255, G loss: 0.1730\n",
      "[484/1762] D loss: 3.6109, G loss: 0.2155\n",
      "[564/1762] D loss: 3.3787, G loss: 0.1873\n",
      "[644/1762] D loss: 3.0148, G loss: 0.2776\n",
      "[724/1762] D loss: 3.6908, G loss: 0.2237\n",
      "[804/1762] D loss: 3.1879, G loss: 0.2537\n",
      "[884/1762] D loss: 3.0913, G loss: 0.1668\n",
      "[964/1762] D loss: 3.0147, G loss: 0.1426\n",
      "[1044/1762] D loss: 3.0157, G loss: 0.1281\n",
      "[1124/1762] D loss: 3.2364, G loss: 0.1792\n",
      "[1204/1762] D loss: 3.6542, G loss: 0.1480\n",
      "[1284/1762] D loss: 3.0708, G loss: 0.1714\n",
      "[1364/1762] D loss: 3.4275, G loss: 0.1663\n",
      "[1444/1762] D loss: 3.9708, G loss: 0.1565\n",
      "[1524/1762] D loss: 3.6326, G loss: 0.2620\n",
      "[1604/1762] D loss: 3.3464, G loss: 0.1934\n",
      "[1684/1762] D loss: 3.9099, G loss: 0.1962\n",
      "[1762/1762] D loss: 2.8973, G loss: 0.1538\n",
      "train error: \n",
      " D loss: 3.435966, G loss: 0.166660, D accuracy: 0.4%, cell accuracy: 92.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.447916, G loss: 0.179380, D accuracy: 0.1%, cell accuracy: 92.5%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 3.5382, G loss: 0.2276\n",
      "[84/1762] D loss: 2.9767, G loss: 0.1796\n",
      "[164/1762] D loss: 2.8915, G loss: 0.2062\n",
      "[244/1762] D loss: 2.9129, G loss: 0.1673\n",
      "[324/1762] D loss: 2.8696, G loss: 0.1552\n",
      "[404/1762] D loss: 3.4064, G loss: 0.1781\n",
      "[484/1762] D loss: 3.5116, G loss: 0.1522\n",
      "[564/1762] D loss: 2.9890, G loss: 0.2197\n",
      "[644/1762] D loss: 3.6455, G loss: 0.2530\n",
      "[724/1762] D loss: 3.5833, G loss: 0.1884\n",
      "[804/1762] D loss: 3.9282, G loss: 0.2199\n",
      "[884/1762] D loss: 3.2875, G loss: 0.1986\n",
      "[964/1762] D loss: 3.6318, G loss: 0.1521\n",
      "[1044/1762] D loss: 3.8162, G loss: 0.2289\n",
      "[1124/1762] D loss: 3.3404, G loss: 0.1649\n",
      "[1204/1762] D loss: 3.3887, G loss: 0.1840\n",
      "[1284/1762] D loss: 3.1943, G loss: 0.2380\n",
      "[1364/1762] D loss: 3.9747, G loss: 0.2297\n",
      "[1444/1762] D loss: 3.3021, G loss: 0.2129\n",
      "[1524/1762] D loss: 3.1101, G loss: 0.1235\n",
      "[1604/1762] D loss: 3.4255, G loss: 0.1577\n",
      "[1684/1762] D loss: 2.6567, G loss: 0.2356\n",
      "[1762/1762] D loss: 3.8337, G loss: 0.2142\n",
      "train error: \n",
      " D loss: 3.497820, G loss: 0.158380, D accuracy: 0.4%, cell accuracy: 92.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.511920, G loss: 0.171326, D accuracy: 0.1%, cell accuracy: 92.5%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 3.4529, G loss: 0.1833\n",
      "[84/1762] D loss: 3.2206, G loss: 0.1802\n",
      "[164/1762] D loss: 3.5942, G loss: 0.1506\n",
      "[244/1762] D loss: 3.0359, G loss: 0.2739\n",
      "[324/1762] D loss: 3.7814, G loss: 0.2105\n",
      "[404/1762] D loss: 3.3459, G loss: 0.2096\n",
      "[484/1762] D loss: 3.5861, G loss: 0.2862\n",
      "[564/1762] D loss: 3.5270, G loss: 0.1500\n",
      "[644/1762] D loss: 3.4947, G loss: 0.2437\n",
      "[724/1762] D loss: 3.1501, G loss: 0.1301\n",
      "[804/1762] D loss: 3.6762, G loss: 0.2085\n",
      "[884/1762] D loss: 3.1575, G loss: 0.1333\n",
      "[964/1762] D loss: 3.0115, G loss: 0.1980\n",
      "[1044/1762] D loss: 3.6540, G loss: 0.3687\n",
      "[1124/1762] D loss: 3.2155, G loss: 0.1890\n",
      "[1204/1762] D loss: 3.7462, G loss: 0.1808\n",
      "[1284/1762] D loss: 3.2278, G loss: 0.2723\n",
      "[1364/1762] D loss: 3.4186, G loss: 0.1752\n",
      "[1444/1762] D loss: 3.1760, G loss: 0.1994\n",
      "[1524/1762] D loss: 3.2556, G loss: 0.1704\n",
      "[1604/1762] D loss: 3.6232, G loss: 0.2120\n",
      "[1684/1762] D loss: 3.1336, G loss: 0.1774\n",
      "[1762/1762] D loss: 4.1122, G loss: 0.3657\n",
      "train error: \n",
      " D loss: 3.388602, G loss: 0.181898, D accuracy: 0.3%, cell accuracy: 92.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.404443, G loss: 0.195658, D accuracy: 0.1%, cell accuracy: 92.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 3.3693, G loss: 0.1925\n",
      "[84/1762] D loss: 3.2982, G loss: 0.1835\n",
      "[164/1762] D loss: 3.3050, G loss: 0.1790\n",
      "[244/1762] D loss: 3.4225, G loss: 0.1646\n",
      "[324/1762] D loss: 3.6238, G loss: 0.1675\n",
      "[404/1762] D loss: 3.9326, G loss: 0.2183\n",
      "[484/1762] D loss: 3.0998, G loss: 0.2159\n",
      "[564/1762] D loss: 3.1125, G loss: 0.1919\n",
      "[644/1762] D loss: 3.0537, G loss: 0.1668\n",
      "[724/1762] D loss: 3.1345, G loss: 0.1560\n",
      "[804/1762] D loss: 4.0249, G loss: 0.2410\n",
      "[884/1762] D loss: 3.3422, G loss: 0.2904\n",
      "[964/1762] D loss: 3.3950, G loss: 0.2037\n",
      "[1044/1762] D loss: 3.3002, G loss: 0.1908\n",
      "[1124/1762] D loss: 2.9480, G loss: 0.2081\n",
      "[1204/1762] D loss: 3.5933, G loss: 0.1524\n",
      "[1284/1762] D loss: 3.2314, G loss: 0.1282\n",
      "[1364/1762] D loss: 3.0760, G loss: 0.1334\n",
      "[1444/1762] D loss: 3.4772, G loss: 0.1339\n",
      "[1524/1762] D loss: 3.7494, G loss: 0.2327\n",
      "[1604/1762] D loss: 3.4267, G loss: 0.1556\n",
      "[1684/1762] D loss: 3.8644, G loss: 0.2450\n",
      "[1762/1762] D loss: 3.0359, G loss: 0.2250\n",
      "train error: \n",
      " D loss: 3.399337, G loss: 0.173869, D accuracy: 0.4%, cell accuracy: 92.4%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.407782, G loss: 0.188953, D accuracy: 0.1%, cell accuracy: 92.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 3.2401, G loss: 0.2081\n",
      "[84/1762] D loss: 4.1904, G loss: 0.2458\n",
      "[164/1762] D loss: 4.4693, G loss: 0.1801\n",
      "[244/1762] D loss: 3.4802, G loss: 0.2393\n",
      "[324/1762] D loss: 3.0556, G loss: 0.1421\n",
      "[404/1762] D loss: 3.6464, G loss: 0.2458\n",
      "[484/1762] D loss: 2.9727, G loss: 0.2129\n",
      "[564/1762] D loss: 3.2390, G loss: 0.2363\n",
      "[644/1762] D loss: 3.0813, G loss: 0.1881\n",
      "[724/1762] D loss: 3.3965, G loss: 0.1718\n",
      "[804/1762] D loss: 3.5164, G loss: 0.1445\n",
      "[884/1762] D loss: 3.1857, G loss: 0.2453\n",
      "[964/1762] D loss: 2.9915, G loss: 0.1689\n",
      "[1044/1762] D loss: 3.4167, G loss: 0.1924\n",
      "[1124/1762] D loss: 3.8283, G loss: 0.2010\n",
      "[1204/1762] D loss: 3.4041, G loss: 0.2769\n",
      "[1284/1762] D loss: 3.4845, G loss: 0.2566\n",
      "[1364/1762] D loss: 3.8508, G loss: 0.2671\n",
      "[1444/1762] D loss: 3.0801, G loss: 0.1809\n",
      "[1524/1762] D loss: 2.7852, G loss: 0.2315\n",
      "[1604/1762] D loss: 3.6405, G loss: 0.1637\n",
      "[1684/1762] D loss: 2.9905, G loss: 0.1969\n",
      "[1762/1762] D loss: 2.9865, G loss: 0.1792\n",
      "train error: \n",
      " D loss: 3.449500, G loss: 0.171325, D accuracy: 0.3%, cell accuracy: 92.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.461463, G loss: 0.185590, D accuracy: 0.1%, cell accuracy: 92.5%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 3.7828, G loss: 0.3067\n",
      "[84/1762] D loss: 3.1860, G loss: 0.1410\n",
      "[164/1762] D loss: 3.5866, G loss: 0.1528\n",
      "[244/1762] D loss: 3.6577, G loss: 0.1489\n",
      "[324/1762] D loss: 3.3697, G loss: 0.2154\n",
      "[404/1762] D loss: 3.8886, G loss: 0.2718\n",
      "[484/1762] D loss: 3.4780, G loss: 0.2553\n",
      "[564/1762] D loss: 3.2110, G loss: 0.1521\n",
      "[644/1762] D loss: 3.7183, G loss: 0.1485\n",
      "[724/1762] D loss: 3.6622, G loss: 0.1525\n",
      "[804/1762] D loss: 3.1515, G loss: 0.1847\n",
      "[884/1762] D loss: 3.4195, G loss: 0.1630\n",
      "[964/1762] D loss: 3.8220, G loss: 0.1655\n",
      "[1044/1762] D loss: 3.8558, G loss: 0.2252\n",
      "[1124/1762] D loss: 3.6520, G loss: 0.2674\n",
      "[1204/1762] D loss: 3.4936, G loss: 0.1668\n",
      "[1284/1762] D loss: 3.5545, G loss: 0.1914\n",
      "[1364/1762] D loss: 3.4803, G loss: 0.1506\n",
      "[1444/1762] D loss: 3.0445, G loss: 0.2105\n",
      "[1524/1762] D loss: 3.1776, G loss: 0.1908\n",
      "[1604/1762] D loss: 3.7061, G loss: 0.2382\n",
      "[1684/1762] D loss: 3.1412, G loss: 0.1500\n",
      "[1762/1762] D loss: 3.8615, G loss: 0.1638\n",
      "train error: \n",
      " D loss: 3.490789, G loss: 0.157628, D accuracy: 0.4%, cell accuracy: 92.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.499175, G loss: 0.171544, D accuracy: 0.1%, cell accuracy: 92.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 3.2418, G loss: 0.2441\n",
      "[84/1762] D loss: 3.5560, G loss: 0.1740\n",
      "[164/1762] D loss: 2.9905, G loss: 0.2113\n",
      "[244/1762] D loss: 3.5307, G loss: 0.2010\n",
      "[324/1762] D loss: 3.5315, G loss: 0.1424\n",
      "[404/1762] D loss: 3.3154, G loss: 0.1890\n",
      "[484/1762] D loss: 3.4898, G loss: 0.2775\n",
      "[564/1762] D loss: 3.9858, G loss: 0.1403\n",
      "[644/1762] D loss: 3.8629, G loss: 0.2272\n",
      "[724/1762] D loss: 3.1655, G loss: 0.1620\n",
      "[804/1762] D loss: 3.7666, G loss: 0.1445\n",
      "[884/1762] D loss: 3.3409, G loss: 0.1017\n",
      "[964/1762] D loss: 3.1509, G loss: 0.1828\n",
      "[1044/1762] D loss: 3.6937, G loss: 0.1347\n",
      "[1124/1762] D loss: 3.5222, G loss: 0.1412\n",
      "[1204/1762] D loss: 3.3191, G loss: 0.1727\n",
      "[1284/1762] D loss: 2.9532, G loss: 0.1374\n",
      "[1364/1762] D loss: 3.3355, G loss: 0.1847\n",
      "[1444/1762] D loss: 3.3069, G loss: 0.1536\n",
      "[1524/1762] D loss: 3.2005, G loss: 0.2543\n",
      "[1604/1762] D loss: 3.4690, G loss: 0.1825\n",
      "[1684/1762] D loss: 3.4554, G loss: 0.1365\n",
      "[1762/1762] D loss: 4.1984, G loss: 0.1557\n",
      "train error: \n",
      " D loss: 3.403856, G loss: 0.172307, D accuracy: 0.4%, cell accuracy: 92.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.414480, G loss: 0.185910, D accuracy: 0.1%, cell accuracy: 92.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 3.2508, G loss: 0.1538\n",
      "[84/1762] D loss: 3.9214, G loss: 0.2091\n",
      "[164/1762] D loss: 3.3363, G loss: 0.1307\n",
      "[244/1762] D loss: 3.7599, G loss: 0.2202\n",
      "[324/1762] D loss: 3.2564, G loss: 0.1605\n",
      "[404/1762] D loss: 3.8097, G loss: 0.2103\n",
      "[484/1762] D loss: 3.4563, G loss: 0.2184\n",
      "[564/1762] D loss: 3.1091, G loss: 0.1879\n",
      "[644/1762] D loss: 3.2552, G loss: 0.2173\n",
      "[724/1762] D loss: 3.5869, G loss: 0.1975\n",
      "[804/1762] D loss: 3.2614, G loss: 0.2172\n",
      "[884/1762] D loss: 3.4821, G loss: 0.2544\n",
      "[964/1762] D loss: 3.5276, G loss: 0.1744\n",
      "[1044/1762] D loss: 3.2565, G loss: 0.2282\n",
      "[1124/1762] D loss: 3.0784, G loss: 0.1784\n",
      "[1204/1762] D loss: 3.7967, G loss: 0.1384\n",
      "[1284/1762] D loss: 3.4102, G loss: 0.1562\n",
      "[1364/1762] D loss: 3.2008, G loss: 0.1941\n",
      "[1444/1762] D loss: 3.7936, G loss: 0.2315\n",
      "[1524/1762] D loss: 3.8577, G loss: 0.2479\n",
      "[1604/1762] D loss: 3.3002, G loss: 0.1718\n",
      "[1684/1762] D loss: 3.5341, G loss: 0.1190\n",
      "[1762/1762] D loss: 4.0722, G loss: 0.1987\n",
      "train error: \n",
      " D loss: 3.509084, G loss: 0.159803, D accuracy: 0.4%, cell accuracy: 92.6%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.526565, G loss: 0.173418, D accuracy: 0.1%, cell accuracy: 92.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.9870, G loss: 0.1485\n",
      "[84/1762] D loss: 3.3772, G loss: 0.1819\n",
      "[164/1762] D loss: 3.2311, G loss: 0.2748\n",
      "[244/1762] D loss: 3.5608, G loss: 0.1850\n",
      "[324/1762] D loss: 3.6876, G loss: 0.1693\n",
      "[404/1762] D loss: 3.5302, G loss: 0.1466\n",
      "[484/1762] D loss: 3.2402, G loss: 0.1409\n",
      "[564/1762] D loss: 3.2451, G loss: 0.1673\n",
      "[644/1762] D loss: 3.4037, G loss: 0.1600\n",
      "[724/1762] D loss: 3.2741, G loss: 0.2707\n",
      "[804/1762] D loss: 3.2086, G loss: 0.1921\n",
      "[884/1762] D loss: 2.9701, G loss: 0.1761\n",
      "[964/1762] D loss: 2.8825, G loss: 0.2384\n",
      "[1044/1762] D loss: 3.5329, G loss: 0.2166\n",
      "[1124/1762] D loss: 3.8728, G loss: 0.1487\n",
      "[1204/1762] D loss: 3.6106, G loss: 0.1734\n",
      "[1284/1762] D loss: 3.7786, G loss: 0.2511\n",
      "[1364/1762] D loss: 3.5175, G loss: 0.2365\n",
      "[1444/1762] D loss: 3.7625, G loss: 0.2590\n",
      "[1524/1762] D loss: 3.3551, G loss: 0.2529\n",
      "[1604/1762] D loss: 3.1108, G loss: 0.1786\n",
      "[1684/1762] D loss: 3.1695, G loss: 0.1720\n",
      "[1762/1762] D loss: 2.9221, G loss: 0.2059\n",
      "train error: \n",
      " D loss: 3.469659, G loss: 0.163051, D accuracy: 0.4%, cell accuracy: 92.8%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.476579, G loss: 0.178476, D accuracy: 0.1%, cell accuracy: 92.7%, board accuracy: 0.0% \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_and_freeze_disc(run_name=\"freeze_disc_epoch_0\", freeze_epoch=0)\n",
    "train_and_freeze_disc(run_name=\"freeze_disc_epoch_5\", freeze_epoch=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3696, G loss: 0.7796\n",
      "[84/1762] D loss: 0.6314, G loss: 1.4119\n",
      "[164/1762] D loss: 0.1031, G loss: 3.2123\n",
      "[244/1762] D loss: 0.0252, G loss: 4.6887\n",
      "[324/1762] D loss: 0.0307, G loss: 5.0415\n",
      "[404/1762] D loss: 0.0320, G loss: 4.3509\n",
      "[484/1762] D loss: 0.1698, G loss: 4.8203\n",
      "[564/1762] D loss: 0.3615, G loss: 2.9130\n",
      "[644/1762] D loss: 0.2233, G loss: 2.3559\n",
      "[724/1762] D loss: 0.3234, G loss: 2.9364\n",
      "[804/1762] D loss: 0.6554, G loss: 2.1477\n",
      "[884/1762] D loss: 0.3603, G loss: 3.6595\n",
      "[964/1762] D loss: 0.9268, G loss: 1.1082\n",
      "[1044/1762] D loss: 0.9498, G loss: 1.6084\n",
      "[1124/1762] D loss: 1.1009, G loss: 1.4884\n",
      "[1204/1762] D loss: 0.7465, G loss: 1.3513\n",
      "[1284/1762] D loss: 1.2277, G loss: 0.5546\n",
      "[1364/1762] D loss: 1.6587, G loss: 0.3056\n",
      "[1444/1762] D loss: 1.3217, G loss: 1.0860\n",
      "[1524/1762] D loss: 1.2649, G loss: 0.6344\n",
      "[1604/1762] D loss: 1.4319, G loss: 0.5391\n",
      "[1684/1762] D loss: 1.3456, G loss: 0.7154\n",
      "[1762/1762] D loss: 1.2866, G loss: 0.7127\n",
      "train error: \n",
      " D loss: 1.324560, G loss: 0.797531, D accuracy: 58.0%, cell accuracy: 99.7%, board accuracy: 81.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.330126, G loss: 0.786452, D accuracy: 59.8%, cell accuracy: 99.7%, board accuracy: 78.9% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1587, G loss: 0.9979\n",
      "[84/1762] D loss: 1.4423, G loss: 0.4682\n",
      "[164/1762] D loss: 1.2223, G loss: 1.2391\n",
      "[244/1762] D loss: 0.9770, G loss: 0.9792\n",
      "[324/1762] D loss: 1.1774, G loss: 0.6662\n",
      "[404/1762] D loss: 1.0143, G loss: 0.7882\n",
      "[484/1762] D loss: 1.4071, G loss: 0.6017\n",
      "[564/1762] D loss: 0.9588, G loss: 0.8794\n",
      "[644/1762] D loss: 1.5070, G loss: 0.5974\n",
      "[724/1762] D loss: 1.3599, G loss: 0.6689\n",
      "[804/1762] D loss: 1.1083, G loss: 0.6575\n",
      "[884/1762] D loss: 1.6631, G loss: 1.1620\n",
      "[964/1762] D loss: 1.6243, G loss: 0.5289\n",
      "[1044/1762] D loss: 1.1528, G loss: 0.6634\n",
      "[1124/1762] D loss: 1.3604, G loss: 0.8447\n",
      "[1204/1762] D loss: 1.1429, G loss: 1.0809\n",
      "[1284/1762] D loss: 1.4092, G loss: 0.6074\n",
      "[1364/1762] D loss: 0.9783, G loss: 1.3295\n",
      "[1444/1762] D loss: 1.8049, G loss: 0.3901\n",
      "[1524/1762] D loss: 1.0352, G loss: 1.2212\n",
      "[1604/1762] D loss: 1.3804, G loss: 0.6237\n",
      "[1684/1762] D loss: 1.4189, G loss: 0.5427\n",
      "[1762/1762] D loss: 0.4445, G loss: 1.6733\n",
      "train error: \n",
      " D loss: 1.308225, G loss: 0.771151, D accuracy: 57.3%, cell accuracy: 99.8%, board accuracy: 80.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.295299, G loss: 0.788134, D accuracy: 58.6%, cell accuracy: 99.7%, board accuracy: 76.6% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2067, G loss: 1.0494\n",
      "[84/1762] D loss: 1.3767, G loss: 0.4838\n",
      "[164/1762] D loss: 1.5235, G loss: 0.6167\n",
      "[244/1762] D loss: 1.4027, G loss: 0.9953\n",
      "[324/1762] D loss: 0.9528, G loss: 0.9243\n",
      "[404/1762] D loss: 1.5132, G loss: 0.5899\n",
      "[484/1762] D loss: 2.3676, G loss: 0.2068\n",
      "[564/1762] D loss: 1.7145, G loss: 0.9373\n",
      "[644/1762] D loss: 1.1578, G loss: 0.9969\n",
      "[724/1762] D loss: 1.1656, G loss: 0.6794\n",
      "[804/1762] D loss: 1.5592, G loss: 0.5587\n",
      "[884/1762] D loss: 0.9911, G loss: 0.9614\n",
      "[964/1762] D loss: 1.2904, G loss: 1.0706\n",
      "[1044/1762] D loss: 1.3852, G loss: 1.0606\n",
      "[1124/1762] D loss: 0.9410, G loss: 0.8406\n",
      "[1204/1762] D loss: 1.4213, G loss: 0.5004\n",
      "[1284/1762] D loss: 1.4624, G loss: 0.8464\n",
      "[1364/1762] D loss: 1.3161, G loss: 0.6748\n",
      "[1444/1762] D loss: 1.6762, G loss: 1.5316\n",
      "[1524/1762] D loss: 1.1632, G loss: 0.5878\n",
      "[1604/1762] D loss: 1.4540, G loss: 0.9304\n",
      "[1684/1762] D loss: 1.2883, G loss: 0.8037\n",
      "[1762/1762] D loss: 0.5884, G loss: 1.5741\n",
      "train error: \n",
      " D loss: 1.353673, G loss: 0.719674, D accuracy: 54.6%, cell accuracy: 99.7%, board accuracy: 82.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.352772, G loss: 0.723478, D accuracy: 55.0%, cell accuracy: 99.7%, board accuracy: 80.0% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5642, G loss: 1.4939\n",
      "[84/1762] D loss: 1.5126, G loss: 0.3920\n",
      "[164/1762] D loss: 1.2438, G loss: 0.9212\n",
      "[244/1762] D loss: 1.4375, G loss: 0.7368\n",
      "[324/1762] D loss: 1.3597, G loss: 0.7766\n",
      "[404/1762] D loss: 1.3108, G loss: 0.7356\n",
      "[484/1762] D loss: 1.4128, G loss: 0.6823\n",
      "[564/1762] D loss: 0.5203, G loss: 1.6632\n",
      "[644/1762] D loss: 1.2883, G loss: 0.9224\n",
      "[724/1762] D loss: 1.3304, G loss: 0.9639\n",
      "[804/1762] D loss: 1.4472, G loss: 0.9425\n",
      "[884/1762] D loss: 0.7734, G loss: 0.8180\n",
      "[964/1762] D loss: 1.4305, G loss: 0.6513\n",
      "[1044/1762] D loss: 1.3464, G loss: 1.2533\n",
      "[1124/1762] D loss: 1.4863, G loss: 0.9770\n",
      "[1204/1762] D loss: 1.2783, G loss: 0.8563\n",
      "[1284/1762] D loss: 1.4435, G loss: 0.5868\n",
      "[1364/1762] D loss: 1.4428, G loss: 0.4969\n",
      "[1444/1762] D loss: 1.4653, G loss: 1.2081\n",
      "[1524/1762] D loss: 0.8178, G loss: 0.7191\n",
      "[1604/1762] D loss: 1.5147, G loss: 0.7616\n",
      "[1684/1762] D loss: 1.2213, G loss: 1.2178\n",
      "[1762/1762] D loss: 1.0801, G loss: 0.7344\n",
      "train error: \n",
      " D loss: 1.597954, G loss: 0.428567, D accuracy: 51.5%, cell accuracy: 99.5%, board accuracy: 47.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.619481, G loss: 0.433435, D accuracy: 49.8%, cell accuracy: 99.5%, board accuracy: 48.9% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.6595, G loss: 0.5976\n",
      "[84/1762] D loss: 1.4322, G loss: 0.9398\n",
      "[164/1762] D loss: 1.4368, G loss: 0.8409\n",
      "[244/1762] D loss: 0.8081, G loss: 1.0922\n",
      "[324/1762] D loss: 1.4003, G loss: 0.8493\n",
      "[404/1762] D loss: 1.3762, G loss: 0.7695\n",
      "[484/1762] D loss: 1.3885, G loss: 0.6985\n",
      "[564/1762] D loss: 1.4182, G loss: 0.7218\n",
      "[644/1762] D loss: 1.4681, G loss: 0.9740\n",
      "[724/1762] D loss: 1.4651, G loss: 0.5158\n",
      "[804/1762] D loss: 1.3856, G loss: 0.5820\n",
      "[884/1762] D loss: 0.5601, G loss: 1.4956\n",
      "[964/1762] D loss: 0.5187, G loss: 1.4737\n",
      "[1044/1762] D loss: 1.4621, G loss: 0.6929\n",
      "[1124/1762] D loss: 0.9897, G loss: 1.3123\n",
      "[1204/1762] D loss: 1.4534, G loss: 1.3435\n",
      "[1284/1762] D loss: 1.3984, G loss: 0.8487\n",
      "[1364/1762] D loss: 1.3378, G loss: 1.0646\n",
      "[1444/1762] D loss: 1.3904, G loss: 0.8054\n",
      "[1524/1762] D loss: 1.3871, G loss: 0.7710\n",
      "[1604/1762] D loss: 1.1677, G loss: 0.8635\n",
      "[1684/1762] D loss: 1.4531, G loss: 0.9669\n",
      "[1762/1762] D loss: 1.4705, G loss: 0.6201\n",
      "train error: \n",
      " D loss: 1.354538, G loss: 0.695075, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 85.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.346286, G loss: 0.709550, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 84.1% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6974, G loss: 1.0022\n",
      "[84/1762] D loss: 1.3966, G loss: 0.6903\n",
      "[164/1762] D loss: 0.4721, G loss: 1.4044\n",
      "[244/1762] D loss: 1.3843, G loss: 0.6664\n",
      "[324/1762] D loss: 1.5066, G loss: 0.4782\n",
      "[404/1762] D loss: 1.4073, G loss: 1.0397\n",
      "[484/1762] D loss: 1.6024, G loss: 1.0682\n",
      "[564/1762] D loss: 0.4355, G loss: 1.2548\n",
      "[644/1762] D loss: 1.5977, G loss: 0.4111\n",
      "[724/1762] D loss: 1.6047, G loss: 1.2339\n",
      "[804/1762] D loss: 1.1014, G loss: 0.9981\n",
      "[884/1762] D loss: 0.8591, G loss: 0.8444\n",
      "[964/1762] D loss: 1.1147, G loss: 1.0406\n",
      "[1044/1762] D loss: 0.4395, G loss: 1.5569\n",
      "[1124/1762] D loss: 1.4754, G loss: 0.8896\n",
      "[1204/1762] D loss: 1.3544, G loss: 0.5297\n",
      "[1284/1762] D loss: 0.6722, G loss: 1.0965\n",
      "[1364/1762] D loss: 1.4090, G loss: 0.7318\n",
      "[1444/1762] D loss: 0.3004, G loss: 1.8332\n",
      "[1524/1762] D loss: 1.6623, G loss: 1.0405\n",
      "[1604/1762] D loss: 0.4681, G loss: 1.4028\n",
      "[1684/1762] D loss: 1.3336, G loss: 0.9469\n",
      "[1762/1762] D loss: 1.4220, G loss: 0.8956\n",
      "train error: \n",
      " D loss: 1.398087, G loss: 0.531010, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 86.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.386221, G loss: 0.544477, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 83.4% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4541, G loss: 0.8388\n",
      "[84/1762] D loss: 0.4788, G loss: 1.8902\n",
      "[164/1762] D loss: 1.3569, G loss: 1.1053\n",
      "[244/1762] D loss: 1.4734, G loss: 0.8141\n",
      "[324/1762] D loss: 1.4280, G loss: 0.6308\n",
      "[404/1762] D loss: 1.4220, G loss: 0.6157\n",
      "[484/1762] D loss: 1.1510, G loss: 1.0815\n",
      "[564/1762] D loss: 1.6028, G loss: 0.7926\n",
      "[644/1762] D loss: 1.0509, G loss: 3.0095\n",
      "[724/1762] D loss: 1.4183, G loss: 0.6713\n",
      "[804/1762] D loss: 1.4241, G loss: 0.7564\n",
      "[884/1762] D loss: 1.3265, G loss: 0.6837\n",
      "[964/1762] D loss: 1.4361, G loss: 0.5877\n",
      "[1044/1762] D loss: 0.6169, G loss: 1.1095\n",
      "[1124/1762] D loss: 1.3856, G loss: 0.6853\n",
      "[1204/1762] D loss: 0.6897, G loss: 0.9861\n",
      "[1284/1762] D loss: 1.1872, G loss: 1.1521\n",
      "[1364/1762] D loss: 1.4577, G loss: 0.4484\n",
      "[1444/1762] D loss: 1.4185, G loss: 0.9058\n",
      "[1524/1762] D loss: 1.1660, G loss: 0.7241\n",
      "[1604/1762] D loss: 1.4168, G loss: 0.8275\n",
      "[1684/1762] D loss: 1.2375, G loss: 0.7800\n",
      "[1762/1762] D loss: 0.2032, G loss: 1.9480\n",
      "train error: \n",
      " D loss: 1.584197, G loss: 0.353139, D accuracy: 50.3%, cell accuracy: 99.8%, board accuracy: 85.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.575359, G loss: 0.363108, D accuracy: 49.8%, cell accuracy: 99.8%, board accuracy: 80.9% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4433, G loss: 0.6265\n",
      "[84/1762] D loss: 0.1573, G loss: 2.0838\n",
      "[164/1762] D loss: 1.4241, G loss: 0.8785\n",
      "[244/1762] D loss: 1.3907, G loss: 0.6229\n",
      "[324/1762] D loss: 1.4435, G loss: 0.9694\n",
      "[404/1762] D loss: 0.4869, G loss: 1.2003\n",
      "[484/1762] D loss: 1.3902, G loss: 0.9152\n",
      "[564/1762] D loss: 1.3127, G loss: 1.8813\n",
      "[644/1762] D loss: 1.0953, G loss: 1.2663\n",
      "[724/1762] D loss: 1.4174, G loss: 0.5337\n",
      "[804/1762] D loss: 1.4321, G loss: 0.7018\n",
      "[884/1762] D loss: 1.4145, G loss: 0.7337\n",
      "[964/1762] D loss: 1.4357, G loss: 0.7570\n",
      "[1044/1762] D loss: 1.3741, G loss: 0.7818\n",
      "[1124/1762] D loss: 0.4458, G loss: 2.4530\n",
      "[1204/1762] D loss: 0.3919, G loss: 1.3162\n",
      "[1284/1762] D loss: 1.4431, G loss: 0.7903\n",
      "[1364/1762] D loss: 1.0079, G loss: 1.0728\n",
      "[1444/1762] D loss: 1.3765, G loss: 0.7955\n",
      "[1524/1762] D loss: 1.3656, G loss: 0.9579\n",
      "[1604/1762] D loss: 0.6943, G loss: 0.9653\n",
      "[1684/1762] D loss: 1.4126, G loss: 0.6100\n",
      "[1762/1762] D loss: 1.4240, G loss: 0.6647\n",
      "train error: \n",
      " D loss: 1.351581, G loss: 0.801989, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.352711, G loss: 0.802108, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 85.0% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2643, G loss: 1.0566\n",
      "[84/1762] D loss: 1.4356, G loss: 0.4834\n",
      "[164/1762] D loss: 1.4077, G loss: 0.5338\n",
      "[244/1762] D loss: 0.3595, G loss: 1.5734\n",
      "[324/1762] D loss: 1.5285, G loss: 1.0535\n",
      "[404/1762] D loss: 0.1254, G loss: 2.4418\n",
      "[484/1762] D loss: 1.3978, G loss: 0.6528\n",
      "[564/1762] D loss: 1.3877, G loss: 0.7243\n",
      "[644/1762] D loss: 0.2831, G loss: 1.8255\n",
      "[724/1762] D loss: 1.4468, G loss: 0.9198\n",
      "[804/1762] D loss: 1.4979, G loss: 0.8927\n",
      "[884/1762] D loss: 1.0535, G loss: 0.8646\n",
      "[964/1762] D loss: 1.4116, G loss: 0.7088\n",
      "[1044/1762] D loss: 1.3988, G loss: 0.6785\n",
      "[1124/1762] D loss: 1.3973, G loss: 0.6752\n",
      "[1204/1762] D loss: 1.3604, G loss: 0.5267\n",
      "[1284/1762] D loss: 1.4333, G loss: 0.5763\n",
      "[1364/1762] D loss: 1.0982, G loss: 1.0371\n",
      "[1444/1762] D loss: 1.4072, G loss: 0.9208\n",
      "[1524/1762] D loss: 0.3085, G loss: 1.6719\n",
      "[1604/1762] D loss: 0.2452, G loss: 1.9525\n",
      "[1684/1762] D loss: 1.5184, G loss: 1.2250\n",
      "[1762/1762] D loss: 0.7179, G loss: 1.5356\n",
      "train error: \n",
      " D loss: 2.823592, G loss: 0.294180, D accuracy: 12.1%, cell accuracy: 96.2%, board accuracy: 12.4% \n",
      "\n",
      "test error: \n",
      " D loss: 2.813327, G loss: 0.304186, D accuracy: 13.3%, cell accuracy: 96.2%, board accuracy: 11.4% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2132, G loss: 0.8600\n",
      "[84/1762] D loss: 0.9271, G loss: 1.1184\n",
      "[164/1762] D loss: 0.4555, G loss: 1.5529\n",
      "[244/1762] D loss: 1.4173, G loss: 0.8011\n",
      "[324/1762] D loss: 0.4258, G loss: 1.3525\n",
      "[404/1762] D loss: 1.6236, G loss: 1.2053\n",
      "[484/1762] D loss: 1.3984, G loss: 0.7949\n",
      "[564/1762] D loss: 1.4010, G loss: 0.7003\n",
      "[644/1762] D loss: 1.4142, G loss: 0.7095\n",
      "[724/1762] D loss: 1.3251, G loss: 0.7484\n",
      "[804/1762] D loss: 0.8714, G loss: 0.6435\n",
      "[884/1762] D loss: 0.5781, G loss: 1.2237\n",
      "[964/1762] D loss: 1.3414, G loss: 1.1580\n",
      "[1044/1762] D loss: 1.6041, G loss: 1.0648\n",
      "[1124/1762] D loss: 1.3887, G loss: 0.6514\n",
      "[1204/1762] D loss: 1.4446, G loss: 0.8900\n",
      "[1284/1762] D loss: 1.4330, G loss: 0.9422\n",
      "[1364/1762] D loss: 1.4124, G loss: 0.9456\n",
      "[1444/1762] D loss: 1.4323, G loss: 0.6005\n",
      "[1524/1762] D loss: 1.6340, G loss: 1.3332\n",
      "[1604/1762] D loss: 1.1402, G loss: 1.0760\n",
      "[1684/1762] D loss: 1.5034, G loss: 0.8139\n",
      "[1762/1762] D loss: 1.2906, G loss: 0.6062\n",
      "train error: \n",
      " D loss: 1.342449, G loss: 0.551010, D accuracy: 58.7%, cell accuracy: 99.4%, board accuracy: 49.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.350989, G loss: 0.545155, D accuracy: 57.7%, cell accuracy: 99.4%, board accuracy: 53.6% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4628, G loss: 0.5531\n",
      "[84/1762] D loss: 1.4107, G loss: 0.6960\n",
      "[164/1762] D loss: 0.3482, G loss: 1.6425\n",
      "[244/1762] D loss: 1.3739, G loss: 0.7820\n",
      "[324/1762] D loss: 1.1306, G loss: 1.0824\n",
      "[404/1762] D loss: 1.5666, G loss: 1.0666\n",
      "[484/1762] D loss: 1.4052, G loss: 0.8115\n",
      "[564/1762] D loss: 1.4392, G loss: 0.8484\n",
      "[644/1762] D loss: 1.3904, G loss: 0.6110\n",
      "[724/1762] D loss: 0.5185, G loss: 1.0793\n",
      "[804/1762] D loss: 1.4892, G loss: 1.0371\n",
      "[884/1762] D loss: 1.4224, G loss: 0.5870\n",
      "[964/1762] D loss: 1.4207, G loss: 0.8157\n",
      "[1044/1762] D loss: 1.3482, G loss: 0.6965\n",
      "[1124/1762] D loss: 1.4326, G loss: 0.9572\n",
      "[1204/1762] D loss: 1.2840, G loss: 1.3222\n",
      "[1284/1762] D loss: 1.5201, G loss: 0.8706\n",
      "[1364/1762] D loss: 0.3801, G loss: 1.5793\n",
      "[1444/1762] D loss: 0.3504, G loss: 1.2344\n",
      "[1524/1762] D loss: 1.4205, G loss: 0.7513\n",
      "[1604/1762] D loss: 0.1883, G loss: 1.7895\n",
      "[1684/1762] D loss: 1.3341, G loss: 0.8625\n",
      "[1762/1762] D loss: 1.6734, G loss: 1.2798\n",
      "train error: \n",
      " D loss: 1.353822, G loss: 0.777198, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 91.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.353080, G loss: 0.782841, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4619, G loss: 0.9100\n",
      "[84/1762] D loss: 1.4418, G loss: 0.8016\n",
      "[164/1762] D loss: 0.3918, G loss: 1.2745\n",
      "[244/1762] D loss: 0.2785, G loss: 1.7321\n",
      "[324/1762] D loss: 1.5217, G loss: 1.0762\n",
      "[404/1762] D loss: 0.4515, G loss: 1.3983\n",
      "[484/1762] D loss: 1.1286, G loss: 0.9578\n",
      "[564/1762] D loss: 1.4201, G loss: 0.7924\n",
      "[644/1762] D loss: 1.5998, G loss: 1.1556\n",
      "[724/1762] D loss: 1.4000, G loss: 0.7454\n",
      "[804/1762] D loss: 1.5057, G loss: 1.1383\n",
      "[884/1762] D loss: 1.4429, G loss: 0.8141\n",
      "[964/1762] D loss: 1.3568, G loss: 0.7200\n",
      "[1044/1762] D loss: 1.2787, G loss: 0.7744\n",
      "[1124/1762] D loss: 1.4026, G loss: 0.8416\n",
      "[1204/1762] D loss: 1.3969, G loss: 0.7016\n",
      "[1284/1762] D loss: 1.7157, G loss: 1.3775\n",
      "[1364/1762] D loss: 1.4363, G loss: 0.8464\n",
      "[1444/1762] D loss: 1.4404, G loss: 0.7167\n",
      "[1524/1762] D loss: 1.4523, G loss: 0.4523\n",
      "[1604/1762] D loss: 0.3592, G loss: 1.6792\n",
      "[1684/1762] D loss: 1.4113, G loss: 0.8097\n",
      "[1762/1762] D loss: 1.5863, G loss: 1.0940\n",
      "train error: \n",
      " D loss: 1.353302, G loss: 0.682488, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.352735, G loss: 0.697247, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3976, G loss: 1.1187\n",
      "[84/1762] D loss: 0.1776, G loss: 1.7478\n",
      "[164/1762] D loss: 1.4384, G loss: 0.7218\n",
      "[244/1762] D loss: 1.4780, G loss: 0.5216\n",
      "[324/1762] D loss: 1.3963, G loss: 0.7351\n",
      "[404/1762] D loss: 1.4263, G loss: 0.4761\n",
      "[484/1762] D loss: 1.4661, G loss: 0.7038\n",
      "[564/1762] D loss: 1.4755, G loss: 0.9045\n",
      "[644/1762] D loss: 1.3997, G loss: 0.6229\n",
      "[724/1762] D loss: 1.4911, G loss: 0.9073\n",
      "[804/1762] D loss: 0.2679, G loss: 1.5988\n",
      "[884/1762] D loss: 1.4396, G loss: 0.8272\n",
      "[964/1762] D loss: 1.4796, G loss: 0.8485\n",
      "[1044/1762] D loss: 1.3917, G loss: 0.6765\n",
      "[1124/1762] D loss: 1.4938, G loss: 1.1987\n",
      "[1204/1762] D loss: 0.3183, G loss: 1.4618\n",
      "[1284/1762] D loss: 1.9359, G loss: 1.7460\n",
      "[1364/1762] D loss: 1.4183, G loss: 0.5042\n",
      "[1444/1762] D loss: 1.5838, G loss: 0.4250\n",
      "[1524/1762] D loss: 1.4166, G loss: 0.8720\n",
      "[1604/1762] D loss: 1.4581, G loss: 0.9410\n",
      "[1684/1762] D loss: 0.1055, G loss: 2.4225\n",
      "[1762/1762] D loss: 1.4177, G loss: 0.7422\n",
      "train error: \n",
      " D loss: 1.400239, G loss: 0.543065, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 88.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.396448, G loss: 0.564196, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 85.9% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4197, G loss: 0.8125\n",
      "[84/1762] D loss: 0.0683, G loss: 2.9355\n",
      "[164/1762] D loss: 0.2150, G loss: 1.8836\n",
      "[244/1762] D loss: 1.4063, G loss: 0.7200\n",
      "[324/1762] D loss: 0.2811, G loss: 1.4727\n",
      "[404/1762] D loss: 1.4021, G loss: 0.5619\n",
      "[484/1762] D loss: 1.5097, G loss: 0.4269\n",
      "[564/1762] D loss: 0.2672, G loss: 1.7459\n",
      "[644/1762] D loss: 1.4517, G loss: 0.8499\n",
      "[724/1762] D loss: 1.4050, G loss: 0.8398\n",
      "[804/1762] D loss: 1.4358, G loss: 0.5319\n",
      "[884/1762] D loss: 1.4214, G loss: 0.5013\n",
      "[964/1762] D loss: 0.3188, G loss: 1.4924\n",
      "[1044/1762] D loss: 1.4385, G loss: 0.5775\n",
      "[1124/1762] D loss: 1.4250, G loss: 0.6045\n",
      "[1204/1762] D loss: 1.4402, G loss: 0.9727\n",
      "[1284/1762] D loss: 0.1145, G loss: 2.5818\n",
      "[1364/1762] D loss: 1.3740, G loss: 0.7028\n",
      "[1444/1762] D loss: 1.3361, G loss: 0.7133\n",
      "[1524/1762] D loss: 1.4121, G loss: 0.8247\n",
      "[1604/1762] D loss: 1.4291, G loss: 1.6191\n",
      "[1684/1762] D loss: 0.1710, G loss: 2.7306\n",
      "[1762/1762] D loss: 0.0932, G loss: 3.1610\n",
      "train error: \n",
      " D loss: 1.058034, G loss: 2.752161, D accuracy: 69.4%, cell accuracy: 98.3%, board accuracy: 17.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.116682, G loss: 2.782779, D accuracy: 67.2%, cell accuracy: 98.2%, board accuracy: 15.5% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2672, G loss: 3.2682\n",
      "[84/1762] D loss: 1.4344, G loss: 0.4539\n",
      "[164/1762] D loss: 1.5264, G loss: 1.0101\n",
      "[244/1762] D loss: 1.4642, G loss: 0.7386\n",
      "[324/1762] D loss: 1.3313, G loss: 0.7791\n",
      "[404/1762] D loss: 1.4333, G loss: 0.8112\n",
      "[484/1762] D loss: 0.2500, G loss: 1.6654\n",
      "[564/1762] D loss: 1.3906, G loss: 0.6507\n",
      "[644/1762] D loss: 0.0978, G loss: 2.6081\n",
      "[724/1762] D loss: 0.3048, G loss: 1.5828\n",
      "[804/1762] D loss: 1.3859, G loss: 0.7867\n",
      "[884/1762] D loss: 1.3930, G loss: 0.5664\n",
      "[964/1762] D loss: 1.4510, G loss: 0.8407\n",
      "[1044/1762] D loss: 1.5063, G loss: 0.4949\n",
      "[1124/1762] D loss: 1.3209, G loss: 0.9820\n",
      "[1204/1762] D loss: 1.4012, G loss: 0.7663\n",
      "[1284/1762] D loss: 0.0720, G loss: 3.0830\n",
      "[1364/1762] D loss: 1.4651, G loss: 0.7825\n",
      "[1444/1762] D loss: 1.4324, G loss: 1.0850\n",
      "[1524/1762] D loss: 1.3436, G loss: 0.6193\n",
      "[1604/1762] D loss: 0.2610, G loss: 1.7754\n",
      "[1684/1762] D loss: 1.4047, G loss: 0.6684\n",
      "[1762/1762] D loss: 1.4183, G loss: 0.5778\n",
      "train error: \n",
      " D loss: 1.436160, G loss: 0.540975, D accuracy: 52.9%, cell accuracy: 99.9%, board accuracy: 91.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.451464, G loss: 0.558623, D accuracy: 52.6%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4080, G loss: 0.6533\n",
      "[84/1762] D loss: 0.2354, G loss: 1.7343\n",
      "[164/1762] D loss: 1.4190, G loss: 0.7111\n",
      "[244/1762] D loss: 1.4516, G loss: 0.5646\n",
      "[324/1762] D loss: 1.5942, G loss: 1.2428\n",
      "[404/1762] D loss: 1.6373, G loss: 0.9410\n",
      "[484/1762] D loss: 0.3565, G loss: 1.2599\n",
      "[564/1762] D loss: 1.4047, G loss: 0.8281\n",
      "[644/1762] D loss: 1.3953, G loss: 0.7094\n",
      "[724/1762] D loss: 1.4198, G loss: 0.7907\n",
      "[804/1762] D loss: 1.6455, G loss: 1.2897\n",
      "[884/1762] D loss: 0.2939, G loss: 1.6081\n",
      "[964/1762] D loss: 1.5389, G loss: 1.0215\n",
      "[1044/1762] D loss: 0.4326, G loss: 1.2800\n",
      "[1124/1762] D loss: 1.4083, G loss: 0.5624\n",
      "[1204/1762] D loss: 1.4180, G loss: 0.7927\n",
      "[1284/1762] D loss: 1.5284, G loss: 1.1255\n",
      "[1364/1762] D loss: 1.3197, G loss: 0.9130\n",
      "[1444/1762] D loss: 1.4375, G loss: 0.4439\n",
      "[1524/1762] D loss: 1.4189, G loss: 0.8549\n",
      "[1604/1762] D loss: 1.4123, G loss: 0.6220\n",
      "[1684/1762] D loss: 0.0583, G loss: 3.1956\n",
      "[1762/1762] D loss: 0.0446, G loss: 3.1960\n",
      "train error: \n",
      " D loss: 2.126882, G loss: 0.173481, D accuracy: 50.6%, cell accuracy: 99.5%, board accuracy: 69.5% \n",
      "\n",
      "test error: \n",
      " D loss: 2.080623, G loss: 0.193457, D accuracy: 51.5%, cell accuracy: 99.5%, board accuracy: 66.6% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3445, G loss: 0.6441\n",
      "[84/1762] D loss: 0.0761, G loss: 2.7505\n",
      "[164/1762] D loss: 1.4526, G loss: 0.5676\n",
      "[244/1762] D loss: 0.3995, G loss: 1.1772\n",
      "[324/1762] D loss: 1.5230, G loss: 1.0371\n",
      "[404/1762] D loss: 1.5532, G loss: 0.9994\n",
      "[484/1762] D loss: 1.5456, G loss: 0.4681\n",
      "[564/1762] D loss: 0.9946, G loss: 1.6427\n",
      "[644/1762] D loss: 0.3603, G loss: 1.3312\n",
      "[724/1762] D loss: 1.3469, G loss: 0.8947\n",
      "[804/1762] D loss: 1.3932, G loss: 0.7318\n",
      "[884/1762] D loss: 1.4401, G loss: 0.8560\n",
      "[964/1762] D loss: 1.4061, G loss: 0.6106\n",
      "[1044/1762] D loss: 1.4238, G loss: 0.6569\n",
      "[1124/1762] D loss: 1.5817, G loss: 1.2350\n",
      "[1204/1762] D loss: 0.2182, G loss: 1.7306\n",
      "[1284/1762] D loss: 1.3951, G loss: 0.7567\n",
      "[1364/1762] D loss: 0.2272, G loss: 1.6473\n",
      "[1444/1762] D loss: 1.4094, G loss: 0.6498\n",
      "[1524/1762] D loss: 1.3984, G loss: 0.8161\n",
      "[1604/1762] D loss: 1.3961, G loss: 0.7330\n",
      "[1684/1762] D loss: 1.3904, G loss: 0.7988\n",
      "[1762/1762] D loss: 1.4433, G loss: 0.9538\n",
      "train error: \n",
      " D loss: 1.428855, G loss: 0.551167, D accuracy: 53.1%, cell accuracy: 99.8%, board accuracy: 89.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.440914, G loss: 0.573999, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4788, G loss: 0.9880\n",
      "[84/1762] D loss: 1.3947, G loss: 0.6945\n",
      "[164/1762] D loss: 1.4323, G loss: 0.8328\n",
      "[244/1762] D loss: 1.3970, G loss: 0.7068\n",
      "[324/1762] D loss: 1.4113, G loss: 0.8207\n",
      "[404/1762] D loss: 1.4314, G loss: 0.7754\n",
      "[484/1762] D loss: 1.4312, G loss: 0.8054\n",
      "[564/1762] D loss: 1.4055, G loss: 0.6621\n",
      "[644/1762] D loss: 1.5028, G loss: 0.9614\n",
      "[724/1762] D loss: 1.3897, G loss: 0.7326\n",
      "[804/1762] D loss: 0.2376, G loss: 1.5946\n",
      "[884/1762] D loss: 1.5522, G loss: 1.0642\n",
      "[964/1762] D loss: 1.3676, G loss: 0.7745\n",
      "[1044/1762] D loss: 1.3896, G loss: 0.7697\n",
      "[1124/1762] D loss: 1.4168, G loss: 0.8688\n",
      "[1204/1762] D loss: 1.4023, G loss: 0.7365\n",
      "[1284/1762] D loss: 1.3980, G loss: 0.5864\n",
      "[1364/1762] D loss: 1.4532, G loss: 0.4721\n",
      "[1444/1762] D loss: 0.1860, G loss: 1.9276\n",
      "[1524/1762] D loss: 1.4294, G loss: 0.8430\n",
      "[1604/1762] D loss: 1.3706, G loss: 0.6768\n",
      "[1684/1762] D loss: 1.5954, G loss: 0.5561\n",
      "[1762/1762] D loss: 1.4036, G loss: 0.6921\n",
      "train error: \n",
      " D loss: 1.810343, G loss: 0.248090, D accuracy: 49.4%, cell accuracy: 99.8%, board accuracy: 91.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.794532, G loss: 0.260389, D accuracy: 48.9%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3926, G loss: 0.8339\n",
      "[84/1762] D loss: 0.1109, G loss: 2.4331\n",
      "[164/1762] D loss: 1.4340, G loss: 0.7445\n",
      "[244/1762] D loss: 1.4002, G loss: 0.7006\n",
      "[324/1762] D loss: 1.4172, G loss: 0.6967\n",
      "[404/1762] D loss: 0.1103, G loss: 2.4494\n",
      "[484/1762] D loss: 0.2057, G loss: 1.7126\n",
      "[564/1762] D loss: 1.4019, G loss: 0.6998\n",
      "[644/1762] D loss: 1.4266, G loss: 0.5591\n",
      "[724/1762] D loss: 1.4026, G loss: 0.6402\n",
      "[804/1762] D loss: 1.6392, G loss: 0.5771\n",
      "[884/1762] D loss: 0.5588, G loss: 0.9406\n",
      "[964/1762] D loss: 1.4100, G loss: 0.7122\n",
      "[1044/1762] D loss: 1.4353, G loss: 0.5397\n",
      "[1124/1762] D loss: 0.1337, G loss: 2.2126\n",
      "[1204/1762] D loss: 0.0623, G loss: 2.9569\n",
      "[1284/1762] D loss: 0.3899, G loss: 1.3939\n",
      "[1364/1762] D loss: 1.5232, G loss: 1.0060\n",
      "[1444/1762] D loss: 1.7924, G loss: 0.3654\n",
      "[1524/1762] D loss: 0.0670, G loss: 2.8959\n",
      "[1604/1762] D loss: 0.2427, G loss: 1.7713\n",
      "[1684/1762] D loss: 1.5045, G loss: 0.6893\n",
      "[1762/1762] D loss: 1.4458, G loss: 0.8665\n",
      "train error: \n",
      " D loss: 1.485821, G loss: 0.451933, D accuracy: 53.1%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.483795, G loss: 0.476312, D accuracy: 53.4%, cell accuracy: 99.7%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5098, G loss: 0.9179\n",
      "[84/1762] D loss: 1.4113, G loss: 0.5991\n",
      "[164/1762] D loss: 0.3812, G loss: 1.5644\n",
      "[244/1762] D loss: 1.3337, G loss: 0.8593\n",
      "[324/1762] D loss: 1.4427, G loss: 0.7807\n",
      "[404/1762] D loss: 1.4366, G loss: 0.6571\n",
      "[484/1762] D loss: 1.4655, G loss: 0.9553\n",
      "[564/1762] D loss: 1.4108, G loss: 0.6539\n",
      "[644/1762] D loss: 1.3997, G loss: 0.7546\n",
      "[724/1762] D loss: 0.3004, G loss: 1.4319\n",
      "[804/1762] D loss: 1.3983, G loss: 0.6314\n",
      "[884/1762] D loss: 1.4065, G loss: 0.7413\n",
      "[964/1762] D loss: 1.3326, G loss: 0.6396\n",
      "[1044/1762] D loss: 1.4301, G loss: 0.6072\n",
      "[1124/1762] D loss: 1.3969, G loss: 0.8560\n",
      "[1204/1762] D loss: 0.2178, G loss: 1.7906\n",
      "[1284/1762] D loss: 1.4068, G loss: 0.6372\n",
      "[1364/1762] D loss: 1.3659, G loss: 0.7585\n",
      "[1444/1762] D loss: 1.4291, G loss: 0.7176\n",
      "[1524/1762] D loss: 1.4793, G loss: 0.9814\n",
      "[1604/1762] D loss: 0.1933, G loss: 1.7483\n",
      "[1684/1762] D loss: 1.4168, G loss: 0.7718\n",
      "[1762/1762] D loss: 1.4170, G loss: 0.5838\n",
      "train error: \n",
      " D loss: 2.868556, G loss: 0.075116, D accuracy: 50.1%, cell accuracy: 99.7%, board accuracy: 82.4% \n",
      "\n",
      "test error: \n",
      " D loss: 2.828424, G loss: 0.081836, D accuracy: 50.1%, cell accuracy: 99.6%, board accuracy: 80.9% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2798, G loss: 1.5097\n",
      "[84/1762] D loss: 1.4071, G loss: 0.5644\n",
      "[164/1762] D loss: 1.4490, G loss: 0.4946\n",
      "[244/1762] D loss: 1.4615, G loss: 0.4617\n",
      "[324/1762] D loss: 1.4632, G loss: 0.4755\n",
      "[404/1762] D loss: 0.5733, G loss: 0.8870\n",
      "[484/1762] D loss: 1.3900, G loss: 0.6065\n",
      "[564/1762] D loss: 0.0533, G loss: 3.0645\n",
      "[644/1762] D loss: 0.3062, G loss: 1.3932\n",
      "[724/1762] D loss: 1.4045, G loss: 0.5896\n",
      "[804/1762] D loss: 1.4825, G loss: 0.4584\n",
      "[884/1762] D loss: 1.4498, G loss: 0.4897\n",
      "[964/1762] D loss: 1.3637, G loss: 0.7878\n",
      "[1044/1762] D loss: 1.1869, G loss: 0.6887\n",
      "[1124/1762] D loss: 1.4243, G loss: 0.5429\n",
      "[1204/1762] D loss: 1.5047, G loss: 0.6409\n",
      "[1284/1762] D loss: 1.3884, G loss: 0.5735\n",
      "[1364/1762] D loss: 1.4795, G loss: 0.4276\n",
      "[1444/1762] D loss: 1.5309, G loss: 0.4004\n",
      "[1524/1762] D loss: 0.6191, G loss: 0.9232\n",
      "[1604/1762] D loss: 1.3712, G loss: 0.5824\n",
      "[1684/1762] D loss: 1.5990, G loss: 0.5421\n",
      "[1762/1762] D loss: 1.4093, G loss: 0.6557\n",
      "train error: \n",
      " D loss: 1.811495, G loss: 0.253298, D accuracy: 50.7%, cell accuracy: 99.5%, board accuracy: 72.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.784583, G loss: 0.273043, D accuracy: 51.1%, cell accuracy: 99.4%, board accuracy: 69.8% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.7976, G loss: 0.3156\n",
      "[84/1762] D loss: 1.5427, G loss: 0.4379\n",
      "[164/1762] D loss: 1.4050, G loss: 0.5675\n",
      "[244/1762] D loss: 0.7205, G loss: 0.7216\n",
      "[324/1762] D loss: 1.4327, G loss: 0.5405\n",
      "[404/1762] D loss: 2.0338, G loss: 0.3155\n",
      "[484/1762] D loss: 1.7450, G loss: 0.3249\n",
      "[564/1762] D loss: 1.7107, G loss: 0.3350\n",
      "[644/1762] D loss: 1.8927, G loss: 0.2727\n",
      "[724/1762] D loss: 0.6846, G loss: 0.7868\n",
      "[804/1762] D loss: 1.6671, G loss: 0.3970\n",
      "[884/1762] D loss: 1.6725, G loss: 0.3709\n",
      "[964/1762] D loss: 2.1154, G loss: 0.2313\n",
      "[1044/1762] D loss: 2.1941, G loss: 0.2013\n",
      "[1124/1762] D loss: 1.6576, G loss: 0.3747\n",
      "[1204/1762] D loss: 0.3127, G loss: 1.5136\n",
      "[1284/1762] D loss: 0.6145, G loss: 0.7945\n",
      "[1364/1762] D loss: 2.6581, G loss: 0.1194\n",
      "[1444/1762] D loss: 1.5846, G loss: 0.4470\n",
      "[1524/1762] D loss: 1.4617, G loss: 0.4782\n",
      "[1604/1762] D loss: 1.4088, G loss: 0.6492\n",
      "[1684/1762] D loss: 1.2541, G loss: 0.8426\n",
      "[1762/1762] D loss: 1.0616, G loss: 0.8854\n",
      "train error: \n",
      " D loss: 2.190749, G loss: 0.158551, D accuracy: 49.8%, cell accuracy: 98.6%, board accuracy: 36.7% \n",
      "\n",
      "test error: \n",
      " D loss: 2.163189, G loss: 0.162917, D accuracy: 49.4%, cell accuracy: 98.5%, board accuracy: 35.7% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.1582, G loss: 0.3038\n",
      "[84/1762] D loss: 1.5328, G loss: 0.6021\n",
      "[164/1762] D loss: 1.5404, G loss: 0.6134\n",
      "[244/1762] D loss: 2.1505, G loss: 0.2513\n",
      "[324/1762] D loss: 2.1800, G loss: 0.2104\n",
      "[404/1762] D loss: 1.2644, G loss: 0.3902\n",
      "[484/1762] D loss: 1.7523, G loss: 0.4158\n",
      "[564/1762] D loss: 1.6639, G loss: 0.3787\n",
      "[644/1762] D loss: 1.8973, G loss: 0.2740\n",
      "[724/1762] D loss: 1.6752, G loss: 0.3557\n",
      "[804/1762] D loss: 2.0796, G loss: 0.2451\n",
      "[884/1762] D loss: 1.9476, G loss: 0.3791\n",
      "[964/1762] D loss: 1.6025, G loss: 0.4378\n",
      "[1044/1762] D loss: 1.4062, G loss: 0.5889\n",
      "[1124/1762] D loss: 2.1490, G loss: 0.2076\n",
      "[1204/1762] D loss: 1.7259, G loss: 0.4137\n",
      "[1284/1762] D loss: 1.7891, G loss: 0.3371\n",
      "[1364/1762] D loss: 1.7405, G loss: 0.3806\n",
      "[1444/1762] D loss: 1.4761, G loss: 0.5497\n",
      "[1524/1762] D loss: 1.5647, G loss: 0.4518\n",
      "[1604/1762] D loss: 2.1959, G loss: 0.2370\n",
      "[1684/1762] D loss: 2.0165, G loss: 0.2776\n",
      "[1762/1762] D loss: 0.6350, G loss: 0.9666\n",
      "train error: \n",
      " D loss: 4.261418, G loss: 0.017684, D accuracy: 50.0%, cell accuracy: 98.4%, board accuracy: 35.1% \n",
      "\n",
      "test error: \n",
      " D loss: 4.191304, G loss: 0.019200, D accuracy: 50.0%, cell accuracy: 98.2%, board accuracy: 32.5% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.6287, G loss: 0.4771\n",
      "[84/1762] D loss: 0.8814, G loss: 0.6200\n",
      "[164/1762] D loss: 1.9562, G loss: 0.2881\n",
      "[244/1762] D loss: 1.3834, G loss: 0.6223\n",
      "[324/1762] D loss: 1.6172, G loss: 0.4299\n",
      "[404/1762] D loss: 1.5662, G loss: 0.4480\n",
      "[484/1762] D loss: 1.1865, G loss: 0.3680\n",
      "[564/1762] D loss: 1.7017, G loss: 0.4374\n",
      "[644/1762] D loss: 2.0443, G loss: 0.2831\n",
      "[724/1762] D loss: 1.7918, G loss: 0.3803\n",
      "[804/1762] D loss: 2.3448, G loss: 0.1797\n",
      "[884/1762] D loss: 0.9473, G loss: 0.6419\n",
      "[964/1762] D loss: 0.9870, G loss: 0.5038\n",
      "[1044/1762] D loss: 2.1560, G loss: 0.2229\n",
      "[1124/1762] D loss: 1.6431, G loss: 0.4350\n",
      "[1204/1762] D loss: 1.9673, G loss: 0.2965\n",
      "[1284/1762] D loss: 2.4780, G loss: 0.1791\n",
      "[1364/1762] D loss: 2.3374, G loss: 0.1933\n",
      "[1444/1762] D loss: 2.1961, G loss: 0.2283\n",
      "[1524/1762] D loss: 2.2611, G loss: 0.2113\n",
      "[1604/1762] D loss: 1.9525, G loss: 0.3296\n",
      "[1684/1762] D loss: 0.7708, G loss: 0.7282\n",
      "[1762/1762] D loss: 2.5913, G loss: 0.1125\n",
      "train error: \n",
      " D loss: 2.090302, G loss: 0.178353, D accuracy: 49.8%, cell accuracy: 98.4%, board accuracy: 34.4% \n",
      "\n",
      "test error: \n",
      " D loss: 2.043897, G loss: 0.189095, D accuracy: 49.5%, cell accuracy: 98.3%, board accuracy: 31.8% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.0074, G loss: 0.2666\n",
      "[84/1762] D loss: 1.3612, G loss: 0.6554\n",
      "[164/1762] D loss: 1.3693, G loss: 0.6778\n",
      "[244/1762] D loss: 1.7713, G loss: 0.4159\n",
      "[324/1762] D loss: 1.6183, G loss: 0.5260\n",
      "[404/1762] D loss: 1.5073, G loss: 0.5222\n",
      "[484/1762] D loss: 2.3386, G loss: 0.2171\n",
      "[564/1762] D loss: 1.8359, G loss: 0.3553\n",
      "[644/1762] D loss: 1.2125, G loss: 0.4369\n",
      "[724/1762] D loss: 1.6374, G loss: 0.6631\n",
      "[804/1762] D loss: 1.9398, G loss: 0.3004\n",
      "[884/1762] D loss: 1.6831, G loss: 0.5594\n",
      "[964/1762] D loss: 1.5702, G loss: 0.4208\n",
      "[1044/1762] D loss: 1.6625, G loss: 0.4530\n",
      "[1124/1762] D loss: 2.0099, G loss: 0.4491\n",
      "[1204/1762] D loss: 1.9989, G loss: 0.2470\n",
      "[1284/1762] D loss: 1.8987, G loss: 0.3378\n",
      "[1364/1762] D loss: 0.5799, G loss: 0.9008\n",
      "[1444/1762] D loss: 2.2094, G loss: 0.1925\n",
      "[1524/1762] D loss: 1.9009, G loss: 0.3503\n",
      "[1604/1762] D loss: 2.3026, G loss: 0.1987\n",
      "[1684/1762] D loss: 2.0368, G loss: 0.2829\n",
      "[1762/1762] D loss: 1.3602, G loss: 0.8629\n",
      "train error: \n",
      " D loss: 2.339834, G loss: 0.132337, D accuracy: 49.7%, cell accuracy: 98.3%, board accuracy: 29.3% \n",
      "\n",
      "test error: \n",
      " D loss: 2.296217, G loss: 0.138906, D accuracy: 49.4%, cell accuracy: 98.2%, board accuracy: 28.2% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5621, G loss: 0.4486\n",
      "[84/1762] D loss: 1.7170, G loss: 0.4072\n",
      "[164/1762] D loss: 1.9095, G loss: 0.2545\n",
      "[244/1762] D loss: 1.4345, G loss: 0.5358\n",
      "[324/1762] D loss: 2.2725, G loss: 0.1945\n",
      "[404/1762] D loss: 1.2235, G loss: 0.3962\n",
      "[484/1762] D loss: 0.7539, G loss: 0.6856\n",
      "[564/1762] D loss: 1.9249, G loss: 0.3390\n",
      "[644/1762] D loss: 0.7384, G loss: 0.7364\n",
      "[724/1762] D loss: 1.0952, G loss: 0.4228\n",
      "[804/1762] D loss: 0.6533, G loss: 0.8191\n",
      "[884/1762] D loss: 1.9452, G loss: 0.2674\n",
      "[964/1762] D loss: 1.4894, G loss: 0.2685\n",
      "[1044/1762] D loss: 1.1653, G loss: 0.4677\n",
      "[1124/1762] D loss: 2.1787, G loss: 0.1989\n",
      "[1204/1762] D loss: 1.0801, G loss: 0.4238\n",
      "[1284/1762] D loss: 3.0691, G loss: 0.1082\n",
      "[1364/1762] D loss: 1.7495, G loss: 0.2406\n",
      "[1444/1762] D loss: 1.6760, G loss: 0.2096\n",
      "[1524/1762] D loss: 1.6732, G loss: 0.3730\n",
      "[1604/1762] D loss: 1.4214, G loss: 0.2846\n",
      "[1684/1762] D loss: 0.5539, G loss: 0.8708\n",
      "[1762/1762] D loss: 2.4933, G loss: 0.2056\n",
      "train error: \n",
      " D loss: 2.227020, G loss: 0.144131, D accuracy: 49.7%, cell accuracy: 98.4%, board accuracy: 35.7% \n",
      "\n",
      "test error: \n",
      " D loss: 2.189996, G loss: 0.150919, D accuracy: 49.4%, cell accuracy: 98.3%, board accuracy: 35.2% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4412, G loss: 0.5558\n",
      "[84/1762] D loss: 1.9673, G loss: 0.2783\n",
      "[164/1762] D loss: 1.0936, G loss: 0.6736\n",
      "[244/1762] D loss: 0.8851, G loss: 0.5571\n",
      "[324/1762] D loss: 2.9015, G loss: 0.1018\n",
      "[404/1762] D loss: 2.8249, G loss: 0.1042\n",
      "[484/1762] D loss: 1.9907, G loss: 0.2897\n",
      "[564/1762] D loss: 2.5002, G loss: 0.1644\n",
      "[644/1762] D loss: 0.6862, G loss: 0.7407\n",
      "[724/1762] D loss: 5.9296, G loss: 0.0051\n",
      "[804/1762] D loss: 5.9694, G loss: 0.0074\n",
      "[884/1762] D loss: 7.7529, G loss: 0.0020\n",
      "[964/1762] D loss: 6.6755, G loss: 0.0029\n",
      "[1044/1762] D loss: 7.3427, G loss: 0.0008\n",
      "[1124/1762] D loss: 8.8875, G loss: 0.0003\n",
      "[1204/1762] D loss: 7.0764, G loss: 0.0018\n",
      "[1284/1762] D loss: 6.5166, G loss: 0.0035\n",
      "[1364/1762] D loss: 8.5066, G loss: 0.0004\n",
      "[1444/1762] D loss: 8.1435, G loss: 0.0005\n",
      "[1524/1762] D loss: 7.8163, G loss: 0.0012\n",
      "[1604/1762] D loss: 7.4560, G loss: 0.0009\n",
      "[1684/1762] D loss: 7.1240, G loss: 0.0021\n",
      "[1762/1762] D loss: 8.9122, G loss: 0.0002\n",
      "train error: \n",
      " D loss: 7.314229, G loss: 0.001327, D accuracy: 50.0%, cell accuracy: 96.0%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 7.300173, G loss: 0.001416, D accuracy: 50.0%, cell accuracy: 95.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 8.4489, G loss: 0.0005\n",
      "[84/1762] D loss: 8.2551, G loss: 0.0008\n",
      "[164/1762] D loss: 8.2694, G loss: 0.0005\n",
      "[244/1762] D loss: 8.6947, G loss: 0.0003\n",
      "[324/1762] D loss: 7.8789, G loss: 0.0005\n",
      "[404/1762] D loss: 6.7966, G loss: 0.0035\n",
      "[484/1762] D loss: 7.4914, G loss: 0.0011\n",
      "[564/1762] D loss: 7.3850, G loss: 0.0025\n",
      "[644/1762] D loss: 7.7041, G loss: 0.0009\n",
      "[724/1762] D loss: 8.9952, G loss: 0.0002\n",
      "[804/1762] D loss: 8.9633, G loss: 0.0003\n",
      "[884/1762] D loss: 8.8425, G loss: 0.0003\n",
      "[964/1762] D loss: 8.4989, G loss: 0.0006\n",
      "[1044/1762] D loss: 7.8895, G loss: 0.0005\n",
      "[1124/1762] D loss: 7.9202, G loss: 0.0009\n",
      "[1204/1762] D loss: 8.5167, G loss: 0.0002\n",
      "[1284/1762] D loss: 8.4367, G loss: 0.0005\n",
      "[1364/1762] D loss: 7.8567, G loss: 0.0010\n",
      "[1444/1762] D loss: 7.7496, G loss: 0.0006\n",
      "[1524/1762] D loss: 8.6346, G loss: 0.0007\n",
      "[1604/1762] D loss: 8.8515, G loss: 0.0003\n",
      "[1684/1762] D loss: 8.6477, G loss: 0.0004\n",
      "[1762/1762] D loss: 7.0919, G loss: 0.0024\n",
      "train error: \n",
      " D loss: 7.190471, G loss: 0.001352, D accuracy: 50.0%, cell accuracy: 96.2%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 7.134185, G loss: 0.001559, D accuracy: 50.0%, cell accuracy: 96.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 8.0034, G loss: 0.0006\n",
      "[84/1762] D loss: 7.9153, G loss: 0.0004\n",
      "[164/1762] D loss: 8.5146, G loss: 0.0005\n",
      "[244/1762] D loss: 8.1062, G loss: 0.0007\n",
      "[324/1762] D loss: 8.6935, G loss: 0.0003\n",
      "[404/1762] D loss: 8.1205, G loss: 0.0004\n",
      "[484/1762] D loss: 8.3990, G loss: 0.0003\n",
      "[564/1762] D loss: 8.7930, G loss: 0.0003\n",
      "[644/1762] D loss: 7.9260, G loss: 0.0004\n",
      "[724/1762] D loss: 6.9121, G loss: 0.0012\n",
      "[804/1762] D loss: 7.8186, G loss: 0.0010\n",
      "[884/1762] D loss: 7.1435, G loss: 0.0026\n",
      "[964/1762] D loss: 7.7638, G loss: 0.0009\n",
      "[1044/1762] D loss: 8.3866, G loss: 0.0004\n",
      "[1124/1762] D loss: 8.2295, G loss: 0.0005\n",
      "[1204/1762] D loss: 7.8406, G loss: 0.0010\n",
      "[1284/1762] D loss: 7.9696, G loss: 0.0004\n",
      "[1364/1762] D loss: 8.2550, G loss: 0.0005\n",
      "[1444/1762] D loss: 7.5949, G loss: 0.0011\n",
      "[1524/1762] D loss: 8.0607, G loss: 0.0003\n",
      "[1604/1762] D loss: 8.9340, G loss: 0.0002\n",
      "[1684/1762] D loss: 7.3189, G loss: 0.0014\n",
      "[1762/1762] D loss: 8.9995, G loss: 0.0002\n",
      "train error: \n",
      " D loss: 7.598293, G loss: 0.000920, D accuracy: 50.0%, cell accuracy: 96.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 7.534419, G loss: 0.001078, D accuracy: 50.0%, cell accuracy: 96.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 8.3313, G loss: 0.0008\n",
      "[84/1762] D loss: 8.1880, G loss: 0.0010\n",
      "[164/1762] D loss: 8.1983, G loss: 0.0005\n",
      "[244/1762] D loss: 9.3027, G loss: 0.0002\n",
      "[324/1762] D loss: 7.6769, G loss: 0.0006\n",
      "[404/1762] D loss: 8.3282, G loss: 0.0004\n",
      "[484/1762] D loss: 8.3742, G loss: 0.0005\n",
      "[564/1762] D loss: 8.1409, G loss: 0.0007\n",
      "[644/1762] D loss: 8.2944, G loss: 0.0008\n",
      "[724/1762] D loss: 7.1173, G loss: 0.0028\n",
      "[804/1762] D loss: 8.1804, G loss: 0.0004\n",
      "[884/1762] D loss: 8.4937, G loss: 0.0004\n",
      "[964/1762] D loss: 8.4202, G loss: 0.0006\n",
      "[1044/1762] D loss: 8.7838, G loss: 0.0004\n",
      "[1124/1762] D loss: 7.7356, G loss: 0.0016\n",
      "[1204/1762] D loss: 7.9003, G loss: 0.0007\n",
      "[1284/1762] D loss: 8.1205, G loss: 0.0004\n",
      "[1364/1762] D loss: 8.2609, G loss: 0.0007\n",
      "[1444/1762] D loss: 7.8964, G loss: 0.0016\n",
      "[1524/1762] D loss: 7.7820, G loss: 0.0005\n",
      "[1604/1762] D loss: 9.2455, G loss: 0.0002\n",
      "[1684/1762] D loss: 7.1304, G loss: 0.0011\n",
      "[1762/1762] D loss: 8.1190, G loss: 0.0006\n",
      "train error: \n",
      " D loss: 7.745884, G loss: 0.000778, D accuracy: 50.0%, cell accuracy: 96.1%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 7.696093, G loss: 0.000877, D accuracy: 50.0%, cell accuracy: 96.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 8.1181, G loss: 0.0004\n",
      "[84/1762] D loss: 8.5126, G loss: 0.0005\n",
      "[164/1762] D loss: 8.0163, G loss: 0.0009\n",
      "[244/1762] D loss: 8.2181, G loss: 0.0006\n",
      "[324/1762] D loss: 8.3033, G loss: 0.0009\n",
      "[404/1762] D loss: 8.2969, G loss: 0.0005\n",
      "[484/1762] D loss: 8.4925, G loss: 0.0002\n",
      "[564/1762] D loss: 7.1433, G loss: 0.0019\n",
      "[644/1762] D loss: 7.5025, G loss: 0.0007\n",
      "[724/1762] D loss: 7.3342, G loss: 0.0007\n",
      "[804/1762] D loss: 8.8086, G loss: 0.0004\n",
      "[884/1762] D loss: 8.2891, G loss: 0.0004\n",
      "[964/1762] D loss: 6.8897, G loss: 0.0020\n",
      "[1044/1762] D loss: 8.7258, G loss: 0.0003\n",
      "[1124/1762] D loss: 8.5217, G loss: 0.0003\n",
      "[1204/1762] D loss: 8.1083, G loss: 0.0006\n",
      "[1284/1762] D loss: 7.2638, G loss: 0.0010\n",
      "[1364/1762] D loss: 9.2120, G loss: 0.0002\n",
      "[1444/1762] D loss: 7.5115, G loss: 0.0023\n",
      "[1524/1762] D loss: 8.0118, G loss: 0.0003\n",
      "[1604/1762] D loss: 8.2943, G loss: 0.0008\n",
      "[1684/1762] D loss: 7.8258, G loss: 0.0008\n",
      "[1762/1762] D loss: 7.8022, G loss: 0.0005\n",
      "train error: \n",
      " D loss: 8.158654, G loss: 0.000514, D accuracy: 50.0%, cell accuracy: 96.0%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 8.112213, G loss: 0.000564, D accuracy: 50.0%, cell accuracy: 95.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 7.8132, G loss: 0.0016\n",
      "[84/1762] D loss: 8.8315, G loss: 0.0002\n",
      "[164/1762] D loss: 7.8898, G loss: 0.0005\n",
      "[244/1762] D loss: 5.6403, G loss: 0.0064\n",
      "[324/1762] D loss: 7.2448, G loss: 0.0013\n",
      "[404/1762] D loss: 7.7277, G loss: 0.0013\n",
      "[484/1762] D loss: 8.0781, G loss: 0.0007\n",
      "[564/1762] D loss: 7.8417, G loss: 0.0009\n",
      "[644/1762] D loss: 7.8540, G loss: 0.0018\n",
      "[724/1762] D loss: 7.8843, G loss: 0.0004\n",
      "[804/1762] D loss: 8.0613, G loss: 0.0007\n",
      "[884/1762] D loss: 8.7022, G loss: 0.0004\n",
      "[964/1762] D loss: 7.4222, G loss: 0.0009\n",
      "[1044/1762] D loss: 8.6291, G loss: 0.0005\n",
      "[1124/1762] D loss: 7.9970, G loss: 0.0012\n",
      "[1204/1762] D loss: 8.2384, G loss: 0.0004\n",
      "[1284/1762] D loss: 7.7461, G loss: 0.0005\n",
      "[1364/1762] D loss: 8.3162, G loss: 0.0006\n",
      "[1444/1762] D loss: 7.5875, G loss: 0.0013\n",
      "[1524/1762] D loss: 8.5550, G loss: 0.0004\n",
      "[1604/1762] D loss: 8.2525, G loss: 0.0006\n",
      "[1684/1762] D loss: 8.8977, G loss: 0.0002\n",
      "[1762/1762] D loss: 8.6439, G loss: 0.0004\n",
      "train error: \n",
      " D loss: 7.560071, G loss: 0.000837, D accuracy: 50.0%, cell accuracy: 96.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 7.495768, G loss: 0.000923, D accuracy: 50.0%, cell accuracy: 96.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 8.2632, G loss: 0.0008\n",
      "[84/1762] D loss: 8.1733, G loss: 0.0007\n",
      "[164/1762] D loss: 8.5906, G loss: 0.0002\n",
      "[244/1762] D loss: 8.4008, G loss: 0.0006\n",
      "[324/1762] D loss: 7.9108, G loss: 0.0009\n",
      "[404/1762] D loss: 8.3683, G loss: 0.0003\n",
      "[484/1762] D loss: 7.7667, G loss: 0.0011\n",
      "[564/1762] D loss: 7.9670, G loss: 0.0009\n",
      "[644/1762] D loss: 8.7046, G loss: 0.0003\n",
      "[724/1762] D loss: 8.5329, G loss: 0.0004\n",
      "[804/1762] D loss: 8.2021, G loss: 0.0003\n",
      "[884/1762] D loss: 8.7364, G loss: 0.0004\n",
      "[964/1762] D loss: 8.4521, G loss: 0.0006\n",
      "[1044/1762] D loss: 8.4812, G loss: 0.0006\n",
      "[1124/1762] D loss: 8.3979, G loss: 0.0005\n",
      "[1204/1762] D loss: 8.0517, G loss: 0.0005\n",
      "[1284/1762] D loss: 6.9069, G loss: 0.0016\n",
      "[1364/1762] D loss: 7.9824, G loss: 0.0008\n",
      "[1444/1762] D loss: 7.3728, G loss: 0.0008\n",
      "[1524/1762] D loss: 8.8859, G loss: 0.0005\n",
      "[1604/1762] D loss: 8.7522, G loss: 0.0003\n",
      "[1684/1762] D loss: 7.6840, G loss: 0.0006\n",
      "[1762/1762] D loss: 8.7413, G loss: 0.0003\n",
      "train error: \n",
      " D loss: 7.916405, G loss: 0.000592, D accuracy: 50.0%, cell accuracy: 96.0%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 7.857390, G loss: 0.000651, D accuracy: 50.0%, cell accuracy: 95.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 8.1917, G loss: 0.0017\n",
      "[84/1762] D loss: 7.2885, G loss: 0.0009\n",
      "[164/1762] D loss: 7.5151, G loss: 0.0006\n",
      "[244/1762] D loss: 7.7761, G loss: 0.0005\n",
      "[324/1762] D loss: 7.9968, G loss: 0.0009\n",
      "[404/1762] D loss: 8.8852, G loss: 0.0003\n",
      "[484/1762] D loss: 7.5792, G loss: 0.0009\n",
      "[564/1762] D loss: 9.0663, G loss: 0.0002\n",
      "[644/1762] D loss: 7.2035, G loss: 0.0015\n",
      "[724/1762] D loss: 7.9420, G loss: 0.0005\n",
      "[804/1762] D loss: 8.2337, G loss: 0.0003\n",
      "[884/1762] D loss: 9.1594, G loss: 0.0002\n",
      "[964/1762] D loss: 8.7927, G loss: 0.0003\n",
      "[1044/1762] D loss: 6.6479, G loss: 0.0039\n",
      "[1124/1762] D loss: 7.7207, G loss: 0.0006\n",
      "[1204/1762] D loss: 6.9900, G loss: 0.0017\n",
      "[1284/1762] D loss: 8.6063, G loss: 0.0004\n",
      "[1364/1762] D loss: 8.5461, G loss: 0.0005\n",
      "[1444/1762] D loss: 8.5798, G loss: 0.0004\n",
      "[1524/1762] D loss: 8.6347, G loss: 0.0004\n",
      "[1604/1762] D loss: 8.9354, G loss: 0.0002\n",
      "[1684/1762] D loss: 8.3873, G loss: 0.0005\n",
      "[1762/1762] D loss: 8.2039, G loss: 0.0005\n",
      "train error: \n",
      " D loss: 7.853626, G loss: 0.000626, D accuracy: 50.0%, cell accuracy: 96.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 7.789783, G loss: 0.000684, D accuracy: 50.0%, cell accuracy: 96.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 8.8264, G loss: 0.0003\n",
      "[84/1762] D loss: 7.1857, G loss: 0.0021\n",
      "[164/1762] D loss: 8.5053, G loss: 0.0004\n",
      "[244/1762] D loss: 8.6374, G loss: 0.0003\n",
      "[324/1762] D loss: 8.6673, G loss: 0.0003\n",
      "[404/1762] D loss: 8.1596, G loss: 0.0003\n",
      "[484/1762] D loss: 8.4855, G loss: 0.0007\n",
      "[564/1762] D loss: 7.4973, G loss: 0.0007\n",
      "[644/1762] D loss: 8.5994, G loss: 0.0003\n",
      "[724/1762] D loss: 6.7408, G loss: 0.0024\n",
      "[804/1762] D loss: 8.3052, G loss: 0.0013\n",
      "[884/1762] D loss: 7.1727, G loss: 0.0013\n",
      "[964/1762] D loss: 8.3783, G loss: 0.0004\n",
      "[1044/1762] D loss: 8.1522, G loss: 0.0003\n",
      "[1124/1762] D loss: 8.3022, G loss: 0.0005\n",
      "[1204/1762] D loss: 8.3919, G loss: 0.0007\n",
      "[1284/1762] D loss: 7.9834, G loss: 0.0013\n",
      "[1364/1762] D loss: 7.2284, G loss: 0.0010\n",
      "[1444/1762] D loss: 8.7931, G loss: 0.0003\n",
      "[1524/1762] D loss: 8.6061, G loss: 0.0005\n",
      "[1604/1762] D loss: 8.0259, G loss: 0.0008\n",
      "[1684/1762] D loss: 8.4801, G loss: 0.0004\n",
      "[1762/1762] D loss: 8.1929, G loss: 0.0004\n",
      "train error: \n",
      " D loss: 7.871638, G loss: 0.000584, D accuracy: 50.0%, cell accuracy: 96.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 7.797115, G loss: 0.000643, D accuracy: 50.0%, cell accuracy: 96.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 8.6063, G loss: 0.0003\n",
      "[84/1762] D loss: 8.2910, G loss: 0.0005\n",
      "[164/1762] D loss: 8.4231, G loss: 0.0004\n",
      "[244/1762] D loss: 8.6105, G loss: 0.0004\n",
      "[324/1762] D loss: 8.3194, G loss: 0.0007\n",
      "[404/1762] D loss: 8.5984, G loss: 0.0005\n",
      "[484/1762] D loss: 8.9422, G loss: 0.0003\n",
      "[564/1762] D loss: 8.0120, G loss: 0.0008\n",
      "[644/1762] D loss: 8.5429, G loss: 0.0003\n",
      "[724/1762] D loss: 9.0149, G loss: 0.0002\n",
      "[804/1762] D loss: 8.6089, G loss: 0.0004\n",
      "[884/1762] D loss: 8.8642, G loss: 0.0002\n",
      "[964/1762] D loss: 8.7700, G loss: 0.0004\n",
      "[1044/1762] D loss: 8.5348, G loss: 0.0005\n",
      "[1124/1762] D loss: 8.3176, G loss: 0.0004\n",
      "[1204/1762] D loss: 8.5675, G loss: 0.0005\n",
      "[1284/1762] D loss: 8.8120, G loss: 0.0003\n",
      "[1364/1762] D loss: 8.7237, G loss: 0.0003\n",
      "[1444/1762] D loss: 9.0455, G loss: 0.0002\n",
      "[1524/1762] D loss: 8.8166, G loss: 0.0003\n",
      "[1604/1762] D loss: 8.9358, G loss: 0.0003\n",
      "[1684/1762] D loss: 7.8762, G loss: 0.0007\n",
      "[1762/1762] D loss: 8.8929, G loss: 0.0002\n",
      "train error: \n",
      " D loss: 8.090327, G loss: 0.000461, D accuracy: 50.0%, cell accuracy: 96.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 8.034025, G loss: 0.000500, D accuracy: 50.0%, cell accuracy: 96.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 8.4028, G loss: 0.0005\n",
      "[84/1762] D loss: 6.9468, G loss: 0.0012\n",
      "[164/1762] D loss: 8.4388, G loss: 0.0005\n",
      "[244/1762] D loss: 8.6055, G loss: 0.0004\n",
      "[324/1762] D loss: 7.2944, G loss: 0.0012\n",
      "[404/1762] D loss: 7.8654, G loss: 0.0006\n",
      "[484/1762] D loss: 8.1515, G loss: 0.0003\n",
      "[564/1762] D loss: 7.6936, G loss: 0.0005\n",
      "[644/1762] D loss: 9.1460, G loss: 0.0002\n",
      "[724/1762] D loss: 9.2601, G loss: 0.0002\n",
      "[804/1762] D loss: 8.2117, G loss: 0.0016\n",
      "[884/1762] D loss: 8.4753, G loss: 0.0004\n",
      "[964/1762] D loss: 8.6835, G loss: 0.0003\n",
      "[1044/1762] D loss: 9.0395, G loss: 0.0002\n",
      "[1124/1762] D loss: 7.8167, G loss: 0.0012\n",
      "[1204/1762] D loss: 8.6339, G loss: 0.0005\n",
      "[1284/1762] D loss: 8.3403, G loss: 0.0004\n",
      "[1364/1762] D loss: 8.4609, G loss: 0.0004\n",
      "[1444/1762] D loss: 8.6306, G loss: 0.0002\n",
      "[1524/1762] D loss: 8.0549, G loss: 0.0005\n",
      "[1604/1762] D loss: 8.9729, G loss: 0.0002\n",
      "[1684/1762] D loss: 8.2398, G loss: 0.0005\n",
      "[1762/1762] D loss: 8.2178, G loss: 0.0004\n",
      "train error: \n",
      " D loss: 8.255823, G loss: 0.000417, D accuracy: 50.0%, cell accuracy: 95.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 8.202505, G loss: 0.000459, D accuracy: 50.0%, cell accuracy: 95.8%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 8.6985, G loss: 0.0003\n",
      "[84/1762] D loss: 8.4338, G loss: 0.0006\n",
      "[164/1762] D loss: 8.7607, G loss: 0.0003\n",
      "[244/1762] D loss: 8.8573, G loss: 0.0003\n",
      "[324/1762] D loss: 9.1036, G loss: 0.0002\n",
      "[404/1762] D loss: 7.3993, G loss: 0.0013\n",
      "[484/1762] D loss: 9.0199, G loss: 0.0002\n",
      "[564/1762] D loss: 9.0092, G loss: 0.0002\n",
      "[644/1762] D loss: 8.6273, G loss: 0.0003\n",
      "[724/1762] D loss: 8.1278, G loss: 0.0004\n",
      "[804/1762] D loss: 8.4233, G loss: 0.0002\n",
      "[884/1762] D loss: 7.4783, G loss: 0.0007\n",
      "[964/1762] D loss: 8.2492, G loss: 0.0012\n",
      "[1044/1762] D loss: 9.0375, G loss: 0.0002\n",
      "[1124/1762] D loss: 9.0236, G loss: 0.0002\n",
      "[1204/1762] D loss: 7.5488, G loss: 0.0007\n",
      "[1284/1762] D loss: 8.3830, G loss: 0.0003\n",
      "[1364/1762] D loss: 7.7119, G loss: 0.0005\n",
      "[1444/1762] D loss: 8.7386, G loss: 0.0003\n",
      "[1524/1762] D loss: 8.7018, G loss: 0.0003\n",
      "[1604/1762] D loss: 8.6376, G loss: 0.0004\n",
      "[1684/1762] D loss: 7.7269, G loss: 0.0005\n",
      "[1762/1762] D loss: 7.3528, G loss: 0.0016\n",
      "train error: \n",
      " D loss: 8.100793, G loss: 0.000456, D accuracy: 50.0%, cell accuracy: 96.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 8.037590, G loss: 0.000498, D accuracy: 50.0%, cell accuracy: 96.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 8.9551, G loss: 0.0002\n",
      "[84/1762] D loss: 8.7158, G loss: 0.0004\n",
      "[164/1762] D loss: 8.9950, G loss: 0.0002\n",
      "[244/1762] D loss: 8.8272, G loss: 0.0002\n",
      "[324/1762] D loss: 8.4258, G loss: 0.0005\n",
      "[404/1762] D loss: 7.9611, G loss: 0.0009\n",
      "[484/1762] D loss: 8.2830, G loss: 0.0003\n",
      "[564/1762] D loss: 9.1438, G loss: 0.0002\n",
      "[644/1762] D loss: 8.2256, G loss: 0.0003\n",
      "[724/1762] D loss: 8.9985, G loss: 0.0002\n",
      "[804/1762] D loss: 8.5141, G loss: 0.0005\n",
      "[884/1762] D loss: 8.6505, G loss: 0.0003\n",
      "[964/1762] D loss: 9.0380, G loss: 0.0007\n",
      "[1044/1762] D loss: 9.0583, G loss: 0.0002\n",
      "[1124/1762] D loss: 8.8794, G loss: 0.0003\n",
      "[1204/1762] D loss: 8.6081, G loss: 0.0002\n",
      "[1284/1762] D loss: 9.1634, G loss: 0.0002\n",
      "[1364/1762] D loss: 8.1465, G loss: 0.0004\n",
      "[1444/1762] D loss: 8.7298, G loss: 0.0003\n",
      "[1524/1762] D loss: 7.8785, G loss: 0.0005\n",
      "[1604/1762] D loss: 8.9968, G loss: 0.0002\n",
      "[1684/1762] D loss: 8.3122, G loss: 0.0006\n",
      "[1762/1762] D loss: 9.4382, G loss: 0.0002\n",
      "train error: \n",
      " D loss: 8.558563, G loss: 0.000289, D accuracy: 50.0%, cell accuracy: 96.0%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 8.513076, G loss: 0.000305, D accuracy: 50.0%, cell accuracy: 95.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 9.2335, G loss: 0.0002\n",
      "[84/1762] D loss: 8.9665, G loss: 0.0002\n",
      "[164/1762] D loss: 9.1284, G loss: 0.0002\n",
      "[244/1762] D loss: 8.4232, G loss: 0.0002\n",
      "[324/1762] D loss: 8.7964, G loss: 0.0003\n",
      "[404/1762] D loss: 8.3218, G loss: 0.0003\n",
      "[484/1762] D loss: 9.6556, G loss: 0.0001\n",
      "[564/1762] D loss: 8.8005, G loss: 0.0003\n",
      "[644/1762] D loss: 8.5147, G loss: 0.0004\n",
      "[724/1762] D loss: 8.5097, G loss: 0.0002\n",
      "[804/1762] D loss: 9.0527, G loss: 0.0002\n",
      "[884/1762] D loss: 8.7195, G loss: 0.0003\n",
      "[964/1762] D loss: 9.4086, G loss: 0.0002\n",
      "[1044/1762] D loss: 8.0956, G loss: 0.0009\n",
      "[1124/1762] D loss: 9.6942, G loss: 0.0001\n",
      "[1204/1762] D loss: 9.8230, G loss: 0.0001\n",
      "[1284/1762] D loss: 8.4741, G loss: 0.0004\n",
      "[1364/1762] D loss: 8.7429, G loss: 0.0005\n",
      "[1444/1762] D loss: 8.7582, G loss: 0.0006\n",
      "[1524/1762] D loss: 8.8995, G loss: 0.0001\n",
      "[1604/1762] D loss: 9.0059, G loss: 0.0002\n",
      "[1684/1762] D loss: 9.4965, G loss: 0.0002\n",
      "[1762/1762] D loss: 8.0735, G loss: 0.0008\n",
      "train error: \n",
      " D loss: 8.704531, G loss: 0.000278, D accuracy: 50.0%, cell accuracy: 96.2%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 8.684841, G loss: 0.000291, D accuracy: 50.0%, cell accuracy: 96.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 9.3152, G loss: 0.0002\n",
      "[84/1762] D loss: 9.5605, G loss: 0.0003\n",
      "[164/1762] D loss: 9.1167, G loss: 0.0001\n",
      "[244/1762] D loss: 9.5390, G loss: 0.0002\n",
      "[324/1762] D loss: 8.4326, G loss: 0.0004\n",
      "[404/1762] D loss: 8.1854, G loss: 0.0006\n",
      "[484/1762] D loss: 9.7923, G loss: 0.0001\n",
      "[564/1762] D loss: 9.5170, G loss: 0.0002\n",
      "[644/1762] D loss: 8.8966, G loss: 0.0005\n",
      "[724/1762] D loss: 8.3947, G loss: 0.0003\n",
      "[804/1762] D loss: 9.7686, G loss: 0.0001\n",
      "[884/1762] D loss: 8.8524, G loss: 0.0003\n",
      "[964/1762] D loss: 9.6944, G loss: 0.0001\n",
      "[1044/1762] D loss: 10.0042, G loss: 0.0001\n",
      "[1124/1762] D loss: 9.0664, G loss: 0.0004\n",
      "[1204/1762] D loss: 8.8279, G loss: 0.0002\n",
      "[1284/1762] D loss: 9.1277, G loss: 0.0002\n",
      "[1364/1762] D loss: 8.4680, G loss: 0.0005\n",
      "[1444/1762] D loss: 9.1373, G loss: 0.0002\n",
      "[1524/1762] D loss: 9.7971, G loss: 0.0001\n",
      "[1604/1762] D loss: 9.3536, G loss: 0.0002\n",
      "[1684/1762] D loss: 9.8597, G loss: 0.0001\n",
      "[1762/1762] D loss: 10.6654, G loss: 0.0000\n",
      "train error: \n",
      " D loss: 9.600610, G loss: 0.000153, D accuracy: 50.0%, cell accuracy: 95.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 9.656358, G loss: 0.000158, D accuracy: 50.0%, cell accuracy: 95.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 9.5648, G loss: 0.0002\n",
      "[84/1762] D loss: 9.8444, G loss: 0.0001\n",
      "[164/1762] D loss: 9.5543, G loss: 0.0001\n",
      "[244/1762] D loss: 10.2650, G loss: 0.0001\n",
      "[324/1762] D loss: 9.1673, G loss: 0.0002\n",
      "[404/1762] D loss: 9.8575, G loss: 0.0001\n",
      "[484/1762] D loss: 9.0141, G loss: 0.0005\n",
      "[564/1762] D loss: 10.1467, G loss: 0.0001\n",
      "[644/1762] D loss: 9.1740, G loss: 0.0005\n",
      "[724/1762] D loss: 9.3289, G loss: 0.0002\n",
      "[804/1762] D loss: 9.5387, G loss: 0.0001\n",
      "[884/1762] D loss: 9.1915, G loss: 0.0001\n",
      "[964/1762] D loss: 10.6936, G loss: 0.0000\n",
      "[1044/1762] D loss: 8.8861, G loss: 0.0002\n",
      "[1124/1762] D loss: 9.9940, G loss: 0.0001\n",
      "[1204/1762] D loss: 9.9156, G loss: 0.0001\n",
      "[1284/1762] D loss: 9.5703, G loss: 0.0001\n",
      "[1364/1762] D loss: 8.8329, G loss: 0.0006\n",
      "[1444/1762] D loss: 10.4197, G loss: 0.0001\n",
      "[1524/1762] D loss: 10.1306, G loss: 0.0001\n",
      "[1604/1762] D loss: 9.0375, G loss: 0.0004\n",
      "[1684/1762] D loss: 9.0249, G loss: 0.0002\n",
      "[1762/1762] D loss: 10.0780, G loss: 0.0001\n",
      "train error: \n",
      " D loss: 9.840010, G loss: 0.000111, D accuracy: 50.0%, cell accuracy: 95.2%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 9.887397, G loss: 0.000121, D accuracy: 50.0%, cell accuracy: 95.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 9.8560, G loss: 0.0001\n",
      "[84/1762] D loss: 8.4708, G loss: 0.0005\n",
      "[164/1762] D loss: 10.9295, G loss: 0.0000\n",
      "[244/1762] D loss: 10.4009, G loss: 0.0001\n",
      "[324/1762] D loss: 9.7328, G loss: 0.0001\n",
      "[404/1762] D loss: 10.0021, G loss: 0.0001\n",
      "[484/1762] D loss: 9.9245, G loss: 0.0001\n",
      "[564/1762] D loss: 9.2361, G loss: 0.0001\n",
      "[644/1762] D loss: 10.0417, G loss: 0.0001\n",
      "[724/1762] D loss: 8.8797, G loss: 0.0003\n",
      "[804/1762] D loss: 9.7202, G loss: 0.0002\n",
      "[884/1762] D loss: 9.9794, G loss: 0.0001\n",
      "[964/1762] D loss: 10.1730, G loss: 0.0001\n",
      "[1044/1762] D loss: 9.3858, G loss: 0.0001\n",
      "[1124/1762] D loss: 10.6646, G loss: 0.0000\n",
      "[1204/1762] D loss: 9.3076, G loss: 0.0002\n",
      "[1284/1762] D loss: 9.8198, G loss: 0.0003\n",
      "[1364/1762] D loss: 9.8626, G loss: 0.0002\n",
      "[1444/1762] D loss: 8.7964, G loss: 0.0004\n",
      "[1524/1762] D loss: 9.6646, G loss: 0.0001\n",
      "[1604/1762] D loss: 9.1795, G loss: 0.0007\n",
      "[1684/1762] D loss: 10.0974, G loss: 0.0001\n",
      "[1762/1762] D loss: 10.0323, G loss: 0.0001\n",
      "train error: \n",
      " D loss: 10.109246, G loss: 0.000082, D accuracy: 50.0%, cell accuracy: 95.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 10.151321, G loss: 0.000088, D accuracy: 50.0%, cell accuracy: 95.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 10.1961, G loss: 0.0001\n",
      "[84/1762] D loss: 8.9263, G loss: 0.0003\n",
      "[164/1762] D loss: 10.2841, G loss: 0.0001\n",
      "[244/1762] D loss: 10.0926, G loss: 0.0001\n",
      "[324/1762] D loss: 10.7877, G loss: 0.0000\n",
      "[404/1762] D loss: 9.7272, G loss: 0.0001\n",
      "[484/1762] D loss: 9.8201, G loss: 0.0001\n",
      "[564/1762] D loss: 9.7754, G loss: 0.0001\n",
      "[644/1762] D loss: 10.0403, G loss: 0.0001\n",
      "[724/1762] D loss: 10.2327, G loss: 0.0001\n",
      "[804/1762] D loss: 9.3622, G loss: 0.0001\n",
      "[884/1762] D loss: 9.6603, G loss: 0.0001\n",
      "[964/1762] D loss: 10.1777, G loss: 0.0001\n",
      "[1044/1762] D loss: 9.8168, G loss: 0.0001\n",
      "[1124/1762] D loss: 9.8636, G loss: 0.0001\n",
      "[1204/1762] D loss: 8.6429, G loss: 0.0004\n",
      "[1284/1762] D loss: 9.2078, G loss: 0.0002\n",
      "[1364/1762] D loss: 9.8255, G loss: 0.0002\n",
      "[1444/1762] D loss: 8.9147, G loss: 0.0002\n",
      "[1524/1762] D loss: 10.0278, G loss: 0.0001\n",
      "[1604/1762] D loss: 10.4077, G loss: 0.0000\n",
      "[1684/1762] D loss: 9.7478, G loss: 0.0001\n",
      "[1762/1762] D loss: 9.2166, G loss: 0.0004\n",
      "train error: \n",
      " D loss: 10.149736, G loss: 0.000082, D accuracy: 50.0%, cell accuracy: 95.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 10.196397, G loss: 0.000084, D accuracy: 50.0%, cell accuracy: 95.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 10.4145, G loss: 0.0001\n",
      "[84/1762] D loss: 9.8126, G loss: 0.0001\n",
      "[164/1762] D loss: 9.5268, G loss: 0.0001\n",
      "[244/1762] D loss: 9.7233, G loss: 0.0001\n",
      "[324/1762] D loss: 9.4536, G loss: 0.0001\n",
      "[404/1762] D loss: 10.0355, G loss: 0.0001\n",
      "[484/1762] D loss: 9.6871, G loss: 0.0001\n",
      "[564/1762] D loss: 9.7313, G loss: 0.0001\n",
      "[644/1762] D loss: 10.0503, G loss: 0.0001\n",
      "[724/1762] D loss: 9.4954, G loss: 0.0001\n",
      "[804/1762] D loss: 10.0709, G loss: 0.0001\n",
      "[884/1762] D loss: 10.4060, G loss: 0.0001\n",
      "[964/1762] D loss: 9.6558, G loss: 0.0001\n",
      "[1044/1762] D loss: 9.5611, G loss: 0.0001\n",
      "[1124/1762] D loss: 10.6054, G loss: 0.0000\n",
      "[1204/1762] D loss: 10.2913, G loss: 0.0000\n",
      "[1284/1762] D loss: 10.9366, G loss: 0.0000\n",
      "[1364/1762] D loss: 10.6025, G loss: 0.0000\n",
      "[1444/1762] D loss: 9.4909, G loss: 0.0001\n",
      "[1524/1762] D loss: 9.5632, G loss: 0.0001\n",
      "[1604/1762] D loss: 9.4129, G loss: 0.0003\n",
      "[1684/1762] D loss: 10.1354, G loss: 0.0004\n",
      "[1762/1762] D loss: 10.3814, G loss: 0.0001\n",
      "train error: \n",
      " D loss: 10.495250, G loss: 0.000051, D accuracy: 50.0%, cell accuracy: 95.0%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 10.530433, G loss: 0.000053, D accuracy: 50.0%, cell accuracy: 95.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 9.9947, G loss: 0.0001\n",
      "[84/1762] D loss: 11.0114, G loss: 0.0000\n",
      "[164/1762] D loss: 9.9563, G loss: 0.0001\n",
      "[244/1762] D loss: 10.8732, G loss: 0.0000\n",
      "[324/1762] D loss: 10.0226, G loss: 0.0001\n",
      "[404/1762] D loss: 10.1889, G loss: 0.0001\n",
      "[484/1762] D loss: 10.1745, G loss: 0.0000\n",
      "[564/1762] D loss: 9.8298, G loss: 0.0001\n",
      "[644/1762] D loss: 10.2505, G loss: 0.0002\n",
      "[724/1762] D loss: 10.4546, G loss: 0.0001\n",
      "[804/1762] D loss: 10.6397, G loss: 0.0000\n",
      "[884/1762] D loss: 9.9513, G loss: 0.0001\n",
      "[964/1762] D loss: 9.6408, G loss: 0.0001\n",
      "[1044/1762] D loss: 11.0300, G loss: 0.0000\n",
      "[1124/1762] D loss: 10.3780, G loss: 0.0000\n",
      "[1204/1762] D loss: 11.1362, G loss: 0.0000\n",
      "[1284/1762] D loss: 10.5391, G loss: 0.0000\n",
      "[1364/1762] D loss: 10.6681, G loss: 0.0000\n",
      "[1444/1762] D loss: 10.2054, G loss: 0.0000\n",
      "[1524/1762] D loss: 9.7872, G loss: 0.0001\n",
      "[1604/1762] D loss: 10.8176, G loss: 0.0000\n",
      "[1684/1762] D loss: 9.7210, G loss: 0.0003\n",
      "[1762/1762] D loss: 10.8598, G loss: 0.0000\n",
      "train error: \n",
      " D loss: 10.799996, G loss: 0.000033, D accuracy: 50.0%, cell accuracy: 95.2%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 10.791837, G loss: 0.000033, D accuracy: 50.0%, cell accuracy: 95.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 10.5977, G loss: 0.0000\n",
      "[84/1762] D loss: 10.0734, G loss: 0.0001\n",
      "[164/1762] D loss: 10.4010, G loss: 0.0000\n",
      "[244/1762] D loss: 9.6107, G loss: 0.0001\n",
      "[324/1762] D loss: 10.3782, G loss: 0.0000\n",
      "[404/1762] D loss: 10.7521, G loss: 0.0000\n",
      "[484/1762] D loss: 10.8503, G loss: 0.0000\n",
      "[564/1762] D loss: 11.0637, G loss: 0.0000\n",
      "[644/1762] D loss: 10.3400, G loss: 0.0001\n",
      "[724/1762] D loss: 11.1444, G loss: 0.0000\n",
      "[804/1762] D loss: 10.7729, G loss: 0.0000\n",
      "[884/1762] D loss: 10.3067, G loss: 0.0000\n",
      "[964/1762] D loss: 10.9434, G loss: 0.0000\n",
      "[1044/1762] D loss: 10.2327, G loss: 0.0001\n",
      "[1124/1762] D loss: 10.6569, G loss: 0.0000\n",
      "[1204/1762] D loss: 10.2596, G loss: 0.0001\n",
      "[1284/1762] D loss: 11.0286, G loss: 0.0000\n",
      "[1364/1762] D loss: 10.2047, G loss: 0.0001\n",
      "[1444/1762] D loss: 9.8845, G loss: 0.0001\n",
      "[1524/1762] D loss: 10.0498, G loss: 0.0000\n",
      "[1604/1762] D loss: 10.1271, G loss: 0.0001\n",
      "[1684/1762] D loss: 10.7473, G loss: 0.0000\n",
      "[1762/1762] D loss: 11.4035, G loss: 0.0000\n",
      "train error: \n",
      " D loss: 10.833937, G loss: 0.000031, D accuracy: 50.0%, cell accuracy: 95.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 10.828029, G loss: 0.000033, D accuracy: 50.0%, cell accuracy: 95.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 10.7566, G loss: 0.0000\n",
      "[84/1762] D loss: 10.9131, G loss: 0.0000\n",
      "[164/1762] D loss: 10.1102, G loss: 0.0000\n",
      "[244/1762] D loss: 10.3889, G loss: 0.0001\n",
      "[324/1762] D loss: 10.4278, G loss: 0.0001\n",
      "[404/1762] D loss: 10.0321, G loss: 0.0000\n",
      "[484/1762] D loss: 10.2504, G loss: 0.0001\n",
      "[564/1762] D loss: 10.0986, G loss: 0.0001\n",
      "[644/1762] D loss: 10.5816, G loss: 0.0001\n",
      "[724/1762] D loss: 10.2672, G loss: 0.0001\n",
      "[804/1762] D loss: 10.6973, G loss: 0.0000\n",
      "[884/1762] D loss: 10.5338, G loss: 0.0000\n",
      "[964/1762] D loss: 10.6576, G loss: 0.0000\n",
      "[1044/1762] D loss: 10.4199, G loss: 0.0000\n",
      "[1124/1762] D loss: 9.5927, G loss: 0.0001\n",
      "[1204/1762] D loss: 10.3565, G loss: 0.0001\n",
      "[1284/1762] D loss: 10.4007, G loss: 0.0001\n",
      "[1364/1762] D loss: 10.5358, G loss: 0.0001\n",
      "[1444/1762] D loss: 11.0007, G loss: 0.0000\n",
      "[1524/1762] D loss: 10.2982, G loss: 0.0001\n",
      "[1604/1762] D loss: 10.1336, G loss: 0.0000\n",
      "[1684/1762] D loss: 11.1808, G loss: 0.0000\n",
      "[1762/1762] D loss: 10.3445, G loss: 0.0001\n",
      "train error: \n",
      " D loss: 10.956254, G loss: 0.000025, D accuracy: 50.0%, cell accuracy: 95.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 10.934103, G loss: 0.000028, D accuracy: 50.0%, cell accuracy: 95.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 10.6159, G loss: 0.0000\n",
      "[84/1762] D loss: 10.3074, G loss: 0.0001\n",
      "[164/1762] D loss: 10.2817, G loss: 0.0001\n",
      "[244/1762] D loss: 9.9193, G loss: 0.0001\n",
      "[324/1762] D loss: 10.8442, G loss: 0.0000\n",
      "[404/1762] D loss: 10.3243, G loss: 0.0000\n",
      "[484/1762] D loss: 10.9412, G loss: 0.0000\n",
      "[564/1762] D loss: 10.6523, G loss: 0.0000\n",
      "[644/1762] D loss: 10.7298, G loss: 0.0000\n",
      "[724/1762] D loss: 10.9980, G loss: 0.0000\n",
      "[804/1762] D loss: 10.7873, G loss: 0.0000\n",
      "[884/1762] D loss: 10.3913, G loss: 0.0000\n",
      "[964/1762] D loss: 11.1465, G loss: 0.0000\n",
      "[1044/1762] D loss: 10.9074, G loss: 0.0000\n",
      "[1124/1762] D loss: 10.6108, G loss: 0.0000\n",
      "[1204/1762] D loss: 10.6660, G loss: 0.0000\n",
      "[1284/1762] D loss: 10.6382, G loss: 0.0000\n",
      "[1364/1762] D loss: 10.6685, G loss: 0.0001\n",
      "[1444/1762] D loss: 11.2537, G loss: 0.0000\n",
      "[1524/1762] D loss: 9.6080, G loss: 0.0002\n",
      "[1604/1762] D loss: 10.8561, G loss: 0.0000\n",
      "[1684/1762] D loss: 10.1625, G loss: 0.0001\n",
      "[1762/1762] D loss: 11.3600, G loss: 0.0000\n",
      "train error: \n",
      " D loss: 11.020514, G loss: 0.000024, D accuracy: 50.0%, cell accuracy: 95.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 10.997412, G loss: 0.000027, D accuracy: 50.0%, cell accuracy: 95.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 11.0939, G loss: 0.0000\n",
      "[84/1762] D loss: 10.7015, G loss: 0.0000\n",
      "[164/1762] D loss: 10.2167, G loss: 0.0000\n",
      "[244/1762] D loss: 10.5190, G loss: 0.0000\n",
      "[324/1762] D loss: 10.9346, G loss: 0.0000\n",
      "[404/1762] D loss: 11.0569, G loss: 0.0000\n",
      "[484/1762] D loss: 10.1633, G loss: 0.0000\n",
      "[564/1762] D loss: 10.1311, G loss: 0.0000\n",
      "[644/1762] D loss: 11.2124, G loss: 0.0000\n",
      "[724/1762] D loss: 10.4926, G loss: 0.0001\n",
      "[804/1762] D loss: 10.4932, G loss: 0.0000\n",
      "[884/1762] D loss: 10.8519, G loss: 0.0000\n",
      "[964/1762] D loss: 10.9250, G loss: 0.0000\n",
      "[1044/1762] D loss: 11.0162, G loss: 0.0000\n",
      "[1124/1762] D loss: 10.8878, G loss: 0.0000\n",
      "[1204/1762] D loss: 10.2981, G loss: 0.0000\n",
      "[1284/1762] D loss: 10.8874, G loss: 0.0000\n",
      "[1364/1762] D loss: 10.3591, G loss: 0.0001\n",
      "[1444/1762] D loss: 9.8050, G loss: 0.0002\n",
      "[1524/1762] D loss: 9.8497, G loss: 0.0001\n",
      "[1604/1762] D loss: 11.3373, G loss: 0.0000\n",
      "[1684/1762] D loss: 9.9456, G loss: 0.0001\n",
      "[1762/1762] D loss: 10.7667, G loss: 0.0000\n",
      "train error: \n",
      " D loss: 10.847667, G loss: 0.000024, D accuracy: 50.0%, cell accuracy: 95.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 10.827724, G loss: 0.000026, D accuracy: 50.0%, cell accuracy: 95.0%, board accuracy: 0.0% \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_and_freeze_disc(run_name=\"freeze_disc_epoch_20\", freeze_epoch=20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the discriminator is frozen, the generator doesn't have the same problem. It easily learns to fool the discriminator and reduces its own loss to very low numbers around 1.0e-4 or even lower."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Freeze gen and replace disc\n",
    "\n",
    "There are at least two possible explanations for why freezing the generator doesn't have the desired effect:\n",
    "* After a few epochs, the generator becomes so good that the discriminator architecture is incapable of learning the task of distinguishing between its output and the real data.\n",
    "* Or, after a few epochs, the discriminator gets \"locked into a bad state\", where it cannot adapt to the generator's new behaviour.\n",
    "\n",
    "We can distinguish between these two situations by first training the GAN as normal for a few epochs (say 5), then freezing the generator and replacing the discriminator with a newly initialized one. If the discriminator architecture is capable of learning to spot fakes from a partially trained generator, then we know the discriminator's architecture is valid. Otherwise, we can experiment with different architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_freeze_gen_and_replace_disc(run_name=\"\", freeze_epoch=5, new_learning_rate=1e-4):\n",
    "    learning_rate = 1e-3\n",
    "    epochs = 50\n",
    "\n",
    "    gen = TetrisModel().to(device)\n",
    "    disc = TetrisDiscriminator().to(device)\n",
    "\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer_gen = torch.optim.Adam(gen.parameters(), lr=learning_rate)\n",
    "    optimizer_disc = torch.optim.Adam(disc.parameters(), lr=learning_rate)\n",
    "\n",
    "    log_dir = os.path.join(\"runs\", \"experiment_019\")\n",
    "    log_subdir = os.path.join(log_dir, run_name + \"_\" + datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"))\n",
    "    tb_writer = SummaryWriter(log_subdir)\n",
    "\n",
    "    train_examples = find_interesting_examples(train_dataset)\n",
    "    test_examples = find_interesting_examples(test_dataset)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch}\\n-------------------------------\")\n",
    "        if epoch == freeze_epoch:\n",
    "            gen.requires_grad_(False)\n",
    "            disc = TetrisDiscriminator().to(device)\n",
    "            optimizer_disc = torch.optim.Adam(disc.parameters(), lr=new_learning_rate)\n",
    "        train_loop(train_dataloader, gen, disc, loss_fn, optimizer_gen, optimizer_disc)\n",
    "        test_loop(\"train\", train_dataloader, gen, disc, loss_fn, tb_writer, epoch, train_examples)\n",
    "        test_loop(\"test\", test_dataloader, gen, disc, loss_fn, tb_writer, epoch, test_examples)\n",
    "        for name, weight in disc.named_parameters():\n",
    "            tb_writer.add_histogram(f\"Discriminator weights/{name}\", weight, epoch)\n",
    "            tb_writer.add_histogram(f\"Discriminator gradients/{name}\", weight.grad, epoch)\n",
    "\n",
    "    tb_writer.close()\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3479, G loss: 0.7482\n",
      "[84/1762] D loss: 0.9303, G loss: 0.8759\n",
      "[164/1762] D loss: 0.3762, G loss: 1.8266\n",
      "[244/1762] D loss: 0.1265, G loss: 3.7376\n",
      "[324/1762] D loss: 0.0473, G loss: 3.6683\n",
      "[404/1762] D loss: 0.1313, G loss: 3.1214\n",
      "[484/1762] D loss: 0.2862, G loss: 5.2596\n",
      "[564/1762] D loss: 0.3426, G loss: 3.4827\n",
      "[644/1762] D loss: 0.4483, G loss: 4.3587\n",
      "[724/1762] D loss: 0.6159, G loss: 2.2959\n",
      "[804/1762] D loss: 0.8739, G loss: 1.8865\n",
      "[884/1762] D loss: 1.2328, G loss: 1.3862\n",
      "[964/1762] D loss: 0.9520, G loss: 0.8686\n",
      "[1044/1762] D loss: 1.1783, G loss: 0.8119\n",
      "[1124/1762] D loss: 1.6243, G loss: 1.6233\n",
      "[1204/1762] D loss: 1.1677, G loss: 1.2102\n",
      "[1284/1762] D loss: 0.9198, G loss: 0.9742\n",
      "[1364/1762] D loss: 1.4271, G loss: 0.4428\n",
      "[1444/1762] D loss: 1.5194, G loss: 0.4273\n",
      "[1524/1762] D loss: 1.2375, G loss: 0.7237\n",
      "[1604/1762] D loss: 1.1886, G loss: 0.8156\n",
      "[1684/1762] D loss: 1.4111, G loss: 0.8492\n",
      "[1762/1762] D loss: 0.7200, G loss: 1.8081\n",
      "train error: \n",
      " D loss: 1.422005, G loss: 1.299748, D accuracy: 54.9%, cell accuracy: 99.6%, board accuracy: 62.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.401395, G loss: 1.289077, D accuracy: 55.8%, cell accuracy: 99.5%, board accuracy: 61.6% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2694, G loss: 1.3115\n",
      "[84/1762] D loss: 1.4000, G loss: 1.1273\n",
      "[164/1762] D loss: 1.4403, G loss: 0.8512\n",
      "[244/1762] D loss: 1.0757, G loss: 0.8623\n",
      "[324/1762] D loss: 0.6241, G loss: 1.5259\n",
      "[404/1762] D loss: 1.1671, G loss: 0.6095\n",
      "[484/1762] D loss: 1.1795, G loss: 1.2666\n",
      "[564/1762] D loss: 1.2965, G loss: 0.8181\n",
      "[644/1762] D loss: 1.4145, G loss: 0.5955\n",
      "[724/1762] D loss: 1.2603, G loss: 0.9818\n",
      "[804/1762] D loss: 1.3655, G loss: 0.6161\n",
      "[884/1762] D loss: 1.4049, G loss: 0.6820\n",
      "[964/1762] D loss: 1.3964, G loss: 0.5751\n",
      "[1044/1762] D loss: 1.2330, G loss: 0.6935\n",
      "[1124/1762] D loss: 1.5047, G loss: 0.6768\n",
      "[1204/1762] D loss: 1.5083, G loss: 1.6478\n",
      "[1284/1762] D loss: 1.3537, G loss: 1.1082\n",
      "[1364/1762] D loss: 1.4511, G loss: 0.6735\n",
      "[1444/1762] D loss: 1.0001, G loss: 1.3901\n",
      "[1524/1762] D loss: 1.3280, G loss: 0.8609\n",
      "[1604/1762] D loss: 0.7473, G loss: 1.6474\n",
      "[1684/1762] D loss: 1.4926, G loss: 0.9063\n",
      "[1762/1762] D loss: 1.6120, G loss: 0.9662\n",
      "train error: \n",
      " D loss: 1.387104, G loss: 0.950354, D accuracy: 51.5%, cell accuracy: 99.7%, board accuracy: 77.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.372559, G loss: 0.959479, D accuracy: 52.7%, cell accuracy: 99.7%, board accuracy: 74.5% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.7159, G loss: 0.4591\n",
      "[84/1762] D loss: 1.2987, G loss: 1.0171\n",
      "[164/1762] D loss: 1.3620, G loss: 0.8385\n",
      "[244/1762] D loss: 1.3378, G loss: 1.0591\n",
      "[324/1762] D loss: 1.3815, G loss: 0.7020\n",
      "[404/1762] D loss: 0.8983, G loss: 0.9504\n",
      "[484/1762] D loss: 1.2064, G loss: 0.6623\n",
      "[564/1762] D loss: 1.3835, G loss: 0.9297\n",
      "[644/1762] D loss: 1.4849, G loss: 1.3307\n",
      "[724/1762] D loss: 1.4023, G loss: 0.8071\n",
      "[804/1762] D loss: 1.0758, G loss: 1.0983\n",
      "[884/1762] D loss: 1.3746, G loss: 0.6222\n",
      "[964/1762] D loss: 1.2972, G loss: 0.9832\n",
      "[1044/1762] D loss: 1.3750, G loss: 0.8013\n",
      "[1124/1762] D loss: 1.3954, G loss: 0.9006\n",
      "[1204/1762] D loss: 1.4968, G loss: 0.9251\n",
      "[1284/1762] D loss: 1.4521, G loss: 0.5770\n",
      "[1364/1762] D loss: 1.4085, G loss: 0.5189\n",
      "[1444/1762] D loss: 1.6690, G loss: 0.9978\n",
      "[1524/1762] D loss: 1.2550, G loss: 1.4717\n",
      "[1604/1762] D loss: 1.5148, G loss: 1.2180\n",
      "[1684/1762] D loss: 1.5386, G loss: 1.9684\n",
      "[1762/1762] D loss: 1.1395, G loss: 1.4168\n",
      "train error: \n",
      " D loss: 1.331861, G loss: 0.736316, D accuracy: 57.4%, cell accuracy: 99.7%, board accuracy: 78.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.327159, G loss: 0.751069, D accuracy: 57.6%, cell accuracy: 99.6%, board accuracy: 75.5% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4107, G loss: 0.9188\n",
      "[84/1762] D loss: 1.1338, G loss: 1.3007\n",
      "[164/1762] D loss: 1.4457, G loss: 0.8421\n",
      "[244/1762] D loss: 0.2221, G loss: 2.1037\n",
      "[324/1762] D loss: 1.6905, G loss: 1.1282\n",
      "[404/1762] D loss: 0.7282, G loss: 0.7689\n",
      "[484/1762] D loss: 0.6880, G loss: 0.9634\n",
      "[564/1762] D loss: 1.3891, G loss: 0.6431\n",
      "[644/1762] D loss: 1.1314, G loss: 0.9399\n",
      "[724/1762] D loss: 1.2512, G loss: 1.0240\n",
      "[804/1762] D loss: 0.3554, G loss: 1.6356\n",
      "[884/1762] D loss: 1.5431, G loss: 0.7101\n",
      "[964/1762] D loss: 1.4560, G loss: 0.8165\n",
      "[1044/1762] D loss: 0.9434, G loss: 1.5248\n",
      "[1124/1762] D loss: 1.0788, G loss: 1.0070\n",
      "[1204/1762] D loss: 1.3773, G loss: 0.7541\n",
      "[1284/1762] D loss: 1.2728, G loss: 0.8485\n",
      "[1364/1762] D loss: 1.4713, G loss: 0.6174\n",
      "[1444/1762] D loss: 1.4007, G loss: 0.7541\n",
      "[1524/1762] D loss: 1.3909, G loss: 0.7142\n",
      "[1604/1762] D loss: 0.8760, G loss: 0.7936\n",
      "[1684/1762] D loss: 1.5428, G loss: 1.1985\n",
      "[1762/1762] D loss: 1.5566, G loss: 0.9338\n",
      "train error: \n",
      " D loss: 1.511465, G loss: 0.854627, D accuracy: 48.9%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.531468, G loss: 0.883471, D accuracy: 48.2%, cell accuracy: 99.8%, board accuracy: 81.6% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5113, G loss: 0.8665\n",
      "[84/1762] D loss: 1.4464, G loss: 0.9359\n",
      "[164/1762] D loss: 1.4339, G loss: 0.8029\n",
      "[244/1762] D loss: 1.4340, G loss: 0.4921\n",
      "[324/1762] D loss: 1.5853, G loss: 0.4621\n",
      "[404/1762] D loss: 1.3667, G loss: 0.6053\n",
      "[484/1762] D loss: 1.4463, G loss: 0.7359\n",
      "[564/1762] D loss: 1.3907, G loss: 0.7377\n",
      "[644/1762] D loss: 1.3862, G loss: 0.6099\n",
      "[724/1762] D loss: 1.4177, G loss: 0.5947\n",
      "[804/1762] D loss: 1.4195, G loss: 0.6001\n",
      "[884/1762] D loss: 1.5076, G loss: 1.0115\n",
      "[964/1762] D loss: 0.4330, G loss: 1.3265\n",
      "[1044/1762] D loss: 1.3881, G loss: 0.7357\n",
      "[1124/1762] D loss: 1.4733, G loss: 0.5254\n",
      "[1204/1762] D loss: 1.9256, G loss: 1.8443\n",
      "[1284/1762] D loss: 1.4298, G loss: 0.8166\n",
      "[1364/1762] D loss: 1.4222, G loss: 0.6545\n",
      "[1444/1762] D loss: 1.4335, G loss: 0.9823\n",
      "[1524/1762] D loss: 1.4554, G loss: 0.4874\n",
      "[1604/1762] D loss: 0.2757, G loss: 1.6526\n",
      "[1684/1762] D loss: 1.3892, G loss: 0.7139\n",
      "[1762/1762] D loss: 1.4241, G loss: 0.8461\n",
      "train error: \n",
      " D loss: 1.352937, G loss: 0.636835, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 89.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.336789, G loss: 0.659528, D accuracy: 55.8%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4033, G loss: 0.7473\n",
      "[84/1762] D loss: 1.3876, G loss: 0.7144\n",
      "[164/1762] D loss: 1.3839, G loss: 0.7072\n",
      "[244/1762] D loss: 1.3864, G loss: 0.7000\n",
      "[324/1762] D loss: 1.3988, G loss: 0.6700\n",
      "[404/1762] D loss: 1.3840, G loss: 0.7024\n",
      "[484/1762] D loss: 1.3925, G loss: 0.6822\n",
      "[564/1762] D loss: 1.3912, G loss: 0.6843\n",
      "[644/1762] D loss: 1.2309, G loss: 0.7122\n",
      "[724/1762] D loss: 1.3913, G loss: 0.7566\n",
      "[804/1762] D loss: 1.3901, G loss: 0.7468\n",
      "[884/1762] D loss: 1.3952, G loss: 0.7279\n",
      "[964/1762] D loss: 1.0471, G loss: 0.8044\n",
      "[1044/1762] D loss: 1.3989, G loss: 0.7524\n",
      "[1124/1762] D loss: 1.4183, G loss: 0.7797\n",
      "[1204/1762] D loss: 1.3975, G loss: 0.6214\n",
      "[1284/1762] D loss: 1.3879, G loss: 0.6696\n",
      "[1364/1762] D loss: 1.4144, G loss: 0.8958\n",
      "[1444/1762] D loss: 0.5902, G loss: 0.9574\n",
      "[1524/1762] D loss: 0.6945, G loss: 0.8630\n",
      "[1604/1762] D loss: 0.6137, G loss: 0.9548\n",
      "[1684/1762] D loss: 1.3999, G loss: 0.6550\n",
      "[1762/1762] D loss: 1.3917, G loss: 0.7227\n",
      "train error: \n",
      " D loss: 1.438687, G loss: 0.479782, D accuracy: 51.7%, cell accuracy: 99.8%, board accuracy: 88.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.424970, G loss: 0.488559, D accuracy: 51.7%, cell accuracy: 99.7%, board accuracy: 85.5% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4722, G loss: 0.6263\n",
      "[84/1762] D loss: 1.4223, G loss: 0.8851\n",
      "[164/1762] D loss: 1.4035, G loss: 0.7527\n",
      "[244/1762] D loss: 1.4266, G loss: 0.8981\n",
      "[324/1762] D loss: 1.4191, G loss: 0.8621\n",
      "[404/1762] D loss: 0.7718, G loss: 0.7674\n",
      "[484/1762] D loss: 1.4046, G loss: 0.9515\n",
      "[564/1762] D loss: 0.6119, G loss: 0.8754\n",
      "[644/1762] D loss: 0.4448, G loss: 1.0637\n",
      "[724/1762] D loss: 1.3436, G loss: 0.9196\n",
      "[804/1762] D loss: 1.4259, G loss: 0.8880\n",
      "[884/1762] D loss: 1.4151, G loss: 0.8741\n",
      "[964/1762] D loss: 1.2153, G loss: 1.0317\n",
      "[1044/1762] D loss: 1.4622, G loss: 1.0083\n",
      "[1124/1762] D loss: 1.4263, G loss: 0.9190\n",
      "[1204/1762] D loss: 1.3955, G loss: 0.6765\n",
      "[1284/1762] D loss: 1.5673, G loss: 0.6590\n",
      "[1364/1762] D loss: 1.3728, G loss: 0.9938\n",
      "[1444/1762] D loss: 1.4057, G loss: 0.8161\n",
      "[1524/1762] D loss: 1.4375, G loss: 0.9355\n",
      "[1604/1762] D loss: 0.5740, G loss: 0.8972\n",
      "[1684/1762] D loss: 0.9495, G loss: 1.0962\n",
      "[1762/1762] D loss: 1.5562, G loss: 1.2031\n",
      "train error: \n",
      " D loss: 1.336872, G loss: 0.930125, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.314709, G loss: 0.939342, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3112, G loss: 0.8318\n",
      "[84/1762] D loss: 0.9440, G loss: 0.9962\n",
      "[164/1762] D loss: 1.3995, G loss: 0.8035\n",
      "[244/1762] D loss: 1.4054, G loss: 0.7997\n",
      "[324/1762] D loss: 1.4004, G loss: 0.7213\n",
      "[404/1762] D loss: 1.3886, G loss: 0.7294\n",
      "[484/1762] D loss: 1.4688, G loss: 1.0270\n",
      "[564/1762] D loss: 1.4052, G loss: 0.7839\n",
      "[644/1762] D loss: 1.4204, G loss: 0.6486\n",
      "[724/1762] D loss: 1.4580, G loss: 0.6866\n",
      "[804/1762] D loss: 1.3949, G loss: 0.6959\n",
      "[884/1762] D loss: 1.5289, G loss: 0.5048\n",
      "[964/1762] D loss: 1.4440, G loss: 0.8847\n",
      "[1044/1762] D loss: 1.2881, G loss: 1.3527\n",
      "[1124/1762] D loss: 1.3882, G loss: 0.6944\n",
      "[1204/1762] D loss: 0.3401, G loss: 1.3111\n",
      "[1284/1762] D loss: 0.3636, G loss: 1.1955\n",
      "[1364/1762] D loss: 0.4307, G loss: 1.1544\n",
      "[1444/1762] D loss: 1.3930, G loss: 0.7598\n",
      "[1524/1762] D loss: 1.4405, G loss: 0.9719\n",
      "[1604/1762] D loss: 1.4165, G loss: 0.6763\n",
      "[1684/1762] D loss: 1.3960, G loss: 0.6374\n",
      "[1762/1762] D loss: 1.4113, G loss: 0.7751\n",
      "train error: \n",
      " D loss: 1.339714, G loss: 0.748374, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.317027, G loss: 0.763821, D accuracy: 55.9%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4118, G loss: 0.8263\n",
      "[84/1762] D loss: 1.3893, G loss: 0.7110\n",
      "[164/1762] D loss: 1.3892, G loss: 0.7385\n",
      "[244/1762] D loss: 1.4416, G loss: 0.9428\n",
      "[324/1762] D loss: 0.3369, G loss: 1.3367\n",
      "[404/1762] D loss: 1.4129, G loss: 0.8044\n",
      "[484/1762] D loss: 1.4073, G loss: 0.8177\n",
      "[564/1762] D loss: 0.4639, G loss: 1.0766\n",
      "[644/1762] D loss: 1.3972, G loss: 0.7328\n",
      "[724/1762] D loss: 1.4218, G loss: 0.8197\n",
      "[804/1762] D loss: 1.4236, G loss: 0.6605\n",
      "[884/1762] D loss: 0.4389, G loss: 1.1264\n",
      "[964/1762] D loss: 1.2628, G loss: 0.5632\n",
      "[1044/1762] D loss: 1.5236, G loss: 0.4364\n",
      "[1124/1762] D loss: 0.5813, G loss: 0.9386\n",
      "[1204/1762] D loss: 0.7124, G loss: 0.7673\n",
      "[1284/1762] D loss: 1.4124, G loss: 0.5497\n",
      "[1364/1762] D loss: 0.3146, G loss: 1.3753\n",
      "[1444/1762] D loss: 0.8313, G loss: 1.1734\n",
      "[1524/1762] D loss: 1.4320, G loss: 0.8825\n",
      "[1604/1762] D loss: 1.4274, G loss: 0.7529\n",
      "[1684/1762] D loss: 1.4874, G loss: 1.0328\n",
      "[1762/1762] D loss: 1.4593, G loss: 0.9411\n",
      "train error: \n",
      " D loss: 1.496208, G loss: 0.407497, D accuracy: 51.2%, cell accuracy: 99.8%, board accuracy: 89.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.466859, G loss: 0.421887, D accuracy: 51.4%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4500, G loss: 0.5174\n",
      "[84/1762] D loss: 0.3909, G loss: 1.1336\n",
      "[164/1762] D loss: 1.4014, G loss: 0.7573\n",
      "[244/1762] D loss: 1.4132, G loss: 0.8757\n",
      "[324/1762] D loss: 0.3083, G loss: 1.3638\n",
      "[404/1762] D loss: 1.4464, G loss: 0.8469\n",
      "[484/1762] D loss: 1.4717, G loss: 0.9529\n",
      "[564/1762] D loss: 0.4074, G loss: 1.1103\n",
      "[644/1762] D loss: 1.4292, G loss: 0.8758\n",
      "[724/1762] D loss: 0.2723, G loss: 1.6284\n",
      "[804/1762] D loss: 1.0690, G loss: 1.2291\n",
      "[884/1762] D loss: 1.4353, G loss: 0.5565\n",
      "[964/1762] D loss: 1.2126, G loss: 1.0558\n",
      "[1044/1762] D loss: 0.6084, G loss: 1.0525\n",
      "[1124/1762] D loss: 0.1710, G loss: 2.0338\n",
      "[1204/1762] D loss: 0.1947, G loss: 1.9209\n",
      "[1284/1762] D loss: 1.4141, G loss: 0.9431\n",
      "[1364/1762] D loss: 1.3986, G loss: 0.7610\n",
      "[1444/1762] D loss: 0.3061, G loss: 1.4997\n",
      "[1524/1762] D loss: 1.4833, G loss: 0.8879\n",
      "[1604/1762] D loss: 0.7765, G loss: 1.0991\n",
      "[1684/1762] D loss: 1.3917, G loss: 0.7264\n",
      "[1762/1762] D loss: 1.3892, G loss: 0.6498\n",
      "train error: \n",
      " D loss: 1.446468, G loss: 0.439249, D accuracy: 52.1%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.429418, G loss: 0.447734, D accuracy: 53.0%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3717, G loss: 0.6767\n",
      "[84/1762] D loss: 1.4144, G loss: 0.8380\n",
      "[164/1762] D loss: 1.4181, G loss: 0.5885\n",
      "[244/1762] D loss: 0.2124, G loss: 1.6994\n",
      "[324/1762] D loss: 0.3043, G loss: 1.5252\n",
      "[404/1762] D loss: 0.8509, G loss: 1.7366\n",
      "[484/1762] D loss: 0.3314, G loss: 1.4741\n",
      "[564/1762] D loss: 1.4015, G loss: 0.8102\n",
      "[644/1762] D loss: 1.6116, G loss: 0.3314\n",
      "[724/1762] D loss: 0.7955, G loss: 1.5191\n",
      "[804/1762] D loss: 0.8313, G loss: 1.4156\n",
      "[884/1762] D loss: 0.3977, G loss: 1.1526\n",
      "[964/1762] D loss: 1.4820, G loss: 0.4906\n",
      "[1044/1762] D loss: 1.3980, G loss: 0.7476\n",
      "[1124/1762] D loss: 0.7141, G loss: 1.2307\n",
      "[1204/1762] D loss: 1.4634, G loss: 1.0296\n",
      "[1284/1762] D loss: 1.4837, G loss: 0.9734\n",
      "[1364/1762] D loss: 1.4647, G loss: 0.9364\n",
      "[1444/1762] D loss: 1.4188, G loss: 0.7833\n",
      "[1524/1762] D loss: 1.4668, G loss: 0.9377\n",
      "[1604/1762] D loss: 0.1112, G loss: 2.3050\n",
      "[1684/1762] D loss: 0.2949, G loss: 1.6183\n",
      "[1762/1762] D loss: 0.1477, G loss: 2.1424\n",
      "train error: \n",
      " D loss: 1.490616, G loss: 0.422449, D accuracy: 52.6%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.452551, G loss: 0.444008, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4973, G loss: 1.1461\n",
      "[84/1762] D loss: 1.4077, G loss: 0.7312\n",
      "[164/1762] D loss: 1.5685, G loss: 1.0247\n",
      "[244/1762] D loss: 1.3093, G loss: 0.7518\n",
      "[324/1762] D loss: 1.3943, G loss: 0.7362\n",
      "[404/1762] D loss: 1.2403, G loss: 1.3562\n",
      "[484/1762] D loss: 1.4839, G loss: 0.9797\n",
      "[564/1762] D loss: 1.4075, G loss: 0.8205\n",
      "[644/1762] D loss: 0.2541, G loss: 1.5914\n",
      "[724/1762] D loss: 1.4370, G loss: 0.9473\n",
      "[804/1762] D loss: 1.4275, G loss: 0.8432\n",
      "[884/1762] D loss: 1.4604, G loss: 0.8933\n",
      "[964/1762] D loss: 1.5439, G loss: 0.4925\n",
      "[1044/1762] D loss: 0.2921, G loss: 1.6366\n",
      "[1124/1762] D loss: 0.2677, G loss: 1.5547\n",
      "[1204/1762] D loss: 1.4298, G loss: 0.8778\n",
      "[1284/1762] D loss: 1.3970, G loss: 0.7520\n",
      "[1364/1762] D loss: 1.3876, G loss: 0.6978\n",
      "[1444/1762] D loss: 1.3976, G loss: 0.6773\n",
      "[1524/1762] D loss: 0.7194, G loss: 1.0629\n",
      "[1604/1762] D loss: 1.3447, G loss: 0.6557\n",
      "[1684/1762] D loss: 0.0956, G loss: 2.5848\n",
      "[1762/1762] D loss: 1.4083, G loss: 0.5055\n",
      "train error: \n",
      " D loss: 1.516630, G loss: 0.388948, D accuracy: 51.2%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.485003, G loss: 0.408520, D accuracy: 51.2%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4484, G loss: 0.4612\n",
      "[84/1762] D loss: 0.2673, G loss: 1.5234\n",
      "[164/1762] D loss: 1.3956, G loss: 0.7933\n",
      "[244/1762] D loss: 1.4648, G loss: 0.8310\n",
      "[324/1762] D loss: 1.1610, G loss: 1.0844\n",
      "[404/1762] D loss: 1.5669, G loss: 1.1108\n",
      "[484/1762] D loss: 1.3983, G loss: 0.7629\n",
      "[564/1762] D loss: 1.4137, G loss: 0.7552\n",
      "[644/1762] D loss: 0.6902, G loss: 0.9279\n",
      "[724/1762] D loss: 1.3899, G loss: 0.7103\n",
      "[804/1762] D loss: 0.8551, G loss: 1.4593\n",
      "[884/1762] D loss: 0.3189, G loss: 1.4231\n",
      "[964/1762] D loss: 0.2639, G loss: 1.4659\n",
      "[1044/1762] D loss: 1.3921, G loss: 0.6553\n",
      "[1124/1762] D loss: 1.5313, G loss: 0.3911\n",
      "[1204/1762] D loss: 0.2230, G loss: 1.8036\n",
      "[1284/1762] D loss: 0.1972, G loss: 1.8084\n",
      "[1364/1762] D loss: 0.5151, G loss: 1.1451\n",
      "[1444/1762] D loss: 1.4191, G loss: 0.7738\n",
      "[1524/1762] D loss: 0.1559, G loss: 2.1717\n",
      "[1604/1762] D loss: 1.4062, G loss: 0.5755\n",
      "[1684/1762] D loss: 1.4052, G loss: 0.7552\n",
      "[1762/1762] D loss: 1.5651, G loss: 1.1369\n",
      "train error: \n",
      " D loss: 1.502336, G loss: 0.386721, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.476008, G loss: 0.398967, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0689, G loss: 0.8221\n",
      "[84/1762] D loss: 1.3964, G loss: 0.8022\n",
      "[164/1762] D loss: 1.4467, G loss: 0.9281\n",
      "[244/1762] D loss: 1.7879, G loss: 1.3556\n",
      "[324/1762] D loss: 1.3985, G loss: 0.6414\n",
      "[404/1762] D loss: 0.2464, G loss: 1.6418\n",
      "[484/1762] D loss: 1.4271, G loss: 0.9205\n",
      "[564/1762] D loss: 0.8938, G loss: 1.4218\n",
      "[644/1762] D loss: 0.2173, G loss: 1.8172\n",
      "[724/1762] D loss: 0.4069, G loss: 1.6573\n",
      "[804/1762] D loss: 1.3957, G loss: 0.6930\n",
      "[884/1762] D loss: 0.1511, G loss: 2.1870\n",
      "[964/1762] D loss: 1.4440, G loss: 0.8418\n",
      "[1044/1762] D loss: 0.1504, G loss: 2.1200\n",
      "[1124/1762] D loss: 1.4032, G loss: 0.7026\n",
      "[1204/1762] D loss: 0.1539, G loss: 2.1721\n",
      "[1284/1762] D loss: 1.5213, G loss: 0.9675\n",
      "[1364/1762] D loss: 1.4126, G loss: 0.6690\n",
      "[1444/1762] D loss: 0.9428, G loss: 1.4313\n",
      "[1524/1762] D loss: 0.4703, G loss: 1.7407\n",
      "[1604/1762] D loss: 0.0737, G loss: 2.6515\n",
      "[1684/1762] D loss: 0.2423, G loss: 1.4029\n",
      "[1762/1762] D loss: 1.3866, G loss: 0.6116\n",
      "train error: \n",
      " D loss: 1.607469, G loss: 0.353900, D accuracy: 50.3%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.578068, G loss: 0.366313, D accuracy: 50.5%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4843, G loss: 0.8499\n",
      "[84/1762] D loss: 0.6092, G loss: 1.1228\n",
      "[164/1762] D loss: 1.3906, G loss: 0.7610\n",
      "[244/1762] D loss: 1.4116, G loss: 0.6424\n",
      "[324/1762] D loss: 1.3905, G loss: 0.7535\n",
      "[404/1762] D loss: 1.4403, G loss: 0.8060\n",
      "[484/1762] D loss: 0.2136, G loss: 1.7576\n",
      "[564/1762] D loss: 0.1939, G loss: 1.7891\n",
      "[644/1762] D loss: 0.2783, G loss: 1.5505\n",
      "[724/1762] D loss: 0.5040, G loss: 1.3489\n",
      "[804/1762] D loss: 1.3894, G loss: 0.7811\n",
      "[884/1762] D loss: 1.1660, G loss: 1.1228\n",
      "[964/1762] D loss: 1.3803, G loss: 0.6413\n",
      "[1044/1762] D loss: 0.1765, G loss: 2.0396\n",
      "[1124/1762] D loss: 1.4252, G loss: 0.8076\n",
      "[1204/1762] D loss: 1.5800, G loss: 0.9871\n",
      "[1284/1762] D loss: 1.3982, G loss: 0.6982\n",
      "[1364/1762] D loss: 0.2273, G loss: 1.6855\n",
      "[1444/1762] D loss: 1.4705, G loss: 0.5036\n",
      "[1524/1762] D loss: 0.0341, G loss: 3.5148\n",
      "[1604/1762] D loss: 1.4131, G loss: 0.8805\n",
      "[1684/1762] D loss: 1.4218, G loss: 0.8798\n",
      "[1762/1762] D loss: 1.4294, G loss: 0.8316\n",
      "train error: \n",
      " D loss: 1.687011, G loss: 0.315581, D accuracy: 52.5%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.617996, G loss: 0.344346, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4725, G loss: 0.9474\n",
      "[84/1762] D loss: 1.4093, G loss: 0.5800\n",
      "[164/1762] D loss: 1.4658, G loss: 0.4728\n",
      "[244/1762] D loss: 1.3951, G loss: 0.5574\n",
      "[324/1762] D loss: 0.1522, G loss: 2.0653\n",
      "[404/1762] D loss: 1.3661, G loss: 0.7575\n",
      "[484/1762] D loss: 0.1615, G loss: 2.0327\n",
      "[564/1762] D loss: 1.4245, G loss: 0.7875\n",
      "[644/1762] D loss: 0.1663, G loss: 1.8990\n",
      "[724/1762] D loss: 0.0781, G loss: 2.7336\n",
      "[804/1762] D loss: 1.4042, G loss: 0.7528\n",
      "[884/1762] D loss: 1.4523, G loss: 0.7564\n",
      "[964/1762] D loss: 0.0458, G loss: 3.1882\n",
      "[1044/1762] D loss: 1.4706, G loss: 0.5125\n",
      "[1124/1762] D loss: 0.1236, G loss: 2.3766\n",
      "[1204/1762] D loss: 1.4974, G loss: 1.0237\n",
      "[1284/1762] D loss: 1.4420, G loss: 0.8034\n",
      "[1364/1762] D loss: 1.4270, G loss: 0.9281\n",
      "[1444/1762] D loss: 0.7031, G loss: 0.9933\n",
      "[1524/1762] D loss: 0.1439, G loss: 2.0927\n",
      "[1604/1762] D loss: 1.4802, G loss: 0.4837\n",
      "[1684/1762] D loss: 1.3851, G loss: 0.6839\n",
      "[1762/1762] D loss: 1.4105, G loss: 0.7670\n",
      "train error: \n",
      " D loss: 2.278822, G loss: 0.133036, D accuracy: 50.0%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "test error: \n",
      " D loss: 2.236298, G loss: 0.140807, D accuracy: 50.0%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0402, G loss: 3.2897\n",
      "[84/1762] D loss: 1.4599, G loss: 0.8049\n",
      "[164/1762] D loss: 0.0347, G loss: 3.3873\n",
      "[244/1762] D loss: 0.9522, G loss: 1.7168\n",
      "[324/1762] D loss: 1.4065, G loss: 0.7485\n",
      "[404/1762] D loss: 0.2996, G loss: 1.4296\n",
      "[484/1762] D loss: 1.3910, G loss: 0.6914\n",
      "[564/1762] D loss: 1.3971, G loss: 0.7313\n",
      "[644/1762] D loss: 1.4355, G loss: 0.8990\n",
      "[724/1762] D loss: 1.4134, G loss: 0.8266\n",
      "[804/1762] D loss: 1.4236, G loss: 0.9011\n",
      "[884/1762] D loss: 1.4483, G loss: 0.8160\n",
      "[964/1762] D loss: 1.7018, G loss: 1.2617\n",
      "[1044/1762] D loss: 1.4228, G loss: 0.8474\n",
      "[1124/1762] D loss: 1.1569, G loss: 0.6541\n",
      "[1204/1762] D loss: 0.0245, G loss: 3.8130\n",
      "[1284/1762] D loss: 1.3999, G loss: 0.6655\n",
      "[1364/1762] D loss: 1.4368, G loss: 0.8701\n",
      "[1444/1762] D loss: 1.4111, G loss: 0.7951\n",
      "[1524/1762] D loss: 1.4075, G loss: 0.5895\n",
      "[1604/1762] D loss: 0.0289, G loss: 3.6750\n",
      "[1684/1762] D loss: 0.1198, G loss: 2.2212\n",
      "[1762/1762] D loss: 1.3873, G loss: 0.8133\n",
      "train error: \n",
      " D loss: 1.890011, G loss: 0.225415, D accuracy: 50.5%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.844193, G loss: 0.242084, D accuracy: 50.9%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1397, G loss: 2.4490\n",
      "[84/1762] D loss: 0.2736, G loss: 1.5805\n",
      "[164/1762] D loss: 1.3889, G loss: 0.7605\n",
      "[244/1762] D loss: 1.3984, G loss: 0.6462\n",
      "[324/1762] D loss: 1.4858, G loss: 0.5373\n",
      "[404/1762] D loss: 1.3875, G loss: 0.7409\n",
      "[484/1762] D loss: 0.9840, G loss: 1.5428\n",
      "[564/1762] D loss: 0.1473, G loss: 1.9532\n",
      "[644/1762] D loss: 1.3826, G loss: 0.6831\n",
      "[724/1762] D loss: 1.6346, G loss: 0.6000\n",
      "[804/1762] D loss: 0.1664, G loss: 2.0816\n",
      "[884/1762] D loss: 1.4505, G loss: 0.9259\n",
      "[964/1762] D loss: 0.0288, G loss: 3.7259\n",
      "[1044/1762] D loss: 1.4027, G loss: 0.7962\n",
      "[1124/1762] D loss: 1.3948, G loss: 0.6823\n",
      "[1204/1762] D loss: 1.5586, G loss: 0.4236\n",
      "[1284/1762] D loss: 0.1063, G loss: 2.6501\n",
      "[1364/1762] D loss: 1.4047, G loss: 0.8542\n",
      "[1444/1762] D loss: 1.4327, G loss: 0.7877\n",
      "[1524/1762] D loss: 1.4453, G loss: 0.8662\n",
      "[1604/1762] D loss: 0.2339, G loss: 1.7880\n",
      "[1684/1762] D loss: 0.8736, G loss: 1.2485\n",
      "[1762/1762] D loss: 1.3915, G loss: 0.6290\n",
      "train error: \n",
      " D loss: 1.442593, G loss: 0.470760, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.418684, G loss: 0.497929, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4046, G loss: 0.5876\n",
      "[84/1762] D loss: 1.3853, G loss: 0.6142\n",
      "[164/1762] D loss: 2.2658, G loss: 0.2494\n",
      "[244/1762] D loss: 0.1147, G loss: 2.6534\n",
      "[324/1762] D loss: 1.4309, G loss: 0.7684\n",
      "[404/1762] D loss: 1.4025, G loss: 0.6095\n",
      "[484/1762] D loss: 1.5228, G loss: 1.0371\n",
      "[564/1762] D loss: 0.1041, G loss: 2.5807\n",
      "[644/1762] D loss: 1.3653, G loss: 0.8259\n",
      "[724/1762] D loss: 0.1859, G loss: 1.9287\n",
      "[804/1762] D loss: 1.4616, G loss: 0.4933\n",
      "[884/1762] D loss: 0.1780, G loss: 1.9873\n",
      "[964/1762] D loss: 1.4119, G loss: 0.7894\n",
      "[1044/1762] D loss: 0.3978, G loss: 1.7467\n",
      "[1124/1762] D loss: 1.3955, G loss: 0.7139\n",
      "[1204/1762] D loss: 0.1055, G loss: 2.4517\n",
      "[1284/1762] D loss: 0.6373, G loss: 1.5580\n",
      "[1364/1762] D loss: 1.5267, G loss: 1.0078\n",
      "[1444/1762] D loss: 0.1159, G loss: 2.4136\n",
      "[1524/1762] D loss: 1.4981, G loss: 0.4652\n",
      "[1604/1762] D loss: 1.5698, G loss: 0.4512\n",
      "[1684/1762] D loss: 1.4221, G loss: 0.7184\n",
      "[1762/1762] D loss: 1.3933, G loss: 0.7237\n",
      "train error: \n",
      " D loss: 1.991713, G loss: 0.193826, D accuracy: 50.1%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.951009, G loss: 0.204181, D accuracy: 50.0%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1556, G loss: 2.2228\n",
      "[84/1762] D loss: 1.4137, G loss: 0.8310\n",
      "[164/1762] D loss: 1.2860, G loss: 0.7830\n",
      "[244/1762] D loss: 1.3799, G loss: 0.8832\n",
      "[324/1762] D loss: 0.4411, G loss: 2.0398\n",
      "[404/1762] D loss: 1.4548, G loss: 0.5228\n",
      "[484/1762] D loss: 0.7949, G loss: 1.7439\n",
      "[564/1762] D loss: 0.1692, G loss: 2.1591\n",
      "[644/1762] D loss: 1.3882, G loss: 0.7548\n",
      "[724/1762] D loss: 1.5962, G loss: 1.0754\n",
      "[804/1762] D loss: 1.1104, G loss: 1.0546\n",
      "[884/1762] D loss: 0.1503, G loss: 2.2068\n",
      "[964/1762] D loss: 1.4118, G loss: 0.8376\n",
      "[1044/1762] D loss: 0.1017, G loss: 2.5538\n",
      "[1124/1762] D loss: 1.5094, G loss: 0.4814\n",
      "[1204/1762] D loss: 1.4767, G loss: 0.8945\n",
      "[1284/1762] D loss: 1.3942, G loss: 0.6402\n",
      "[1364/1762] D loss: 0.1711, G loss: 1.9566\n",
      "[1444/1762] D loss: 1.3975, G loss: 0.6465\n",
      "[1524/1762] D loss: 1.3829, G loss: 0.6503\n",
      "[1604/1762] D loss: 1.4219, G loss: 0.6181\n",
      "[1684/1762] D loss: 1.3999, G loss: 0.7086\n",
      "[1762/1762] D loss: 1.4001, G loss: 0.6459\n",
      "train error: \n",
      " D loss: 1.533212, G loss: 0.389800, D accuracy: 51.0%, cell accuracy: 99.8%, board accuracy: 89.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.519412, G loss: 0.404965, D accuracy: 51.0%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0339, G loss: 3.5119\n",
      "[84/1762] D loss: 1.4542, G loss: 0.9415\n",
      "[164/1762] D loss: 1.4025, G loss: 0.7947\n",
      "[244/1762] D loss: 0.1441, G loss: 2.2395\n",
      "[324/1762] D loss: 1.4116, G loss: 0.7116\n",
      "[404/1762] D loss: 0.0893, G loss: 2.5168\n",
      "[484/1762] D loss: 1.4064, G loss: 0.8735\n",
      "[564/1762] D loss: 0.6697, G loss: 1.2217\n",
      "[644/1762] D loss: 0.1378, G loss: 2.8122\n",
      "[724/1762] D loss: 0.9681, G loss: 1.1001\n",
      "[804/1762] D loss: 1.5223, G loss: 0.4094\n",
      "[884/1762] D loss: 0.7378, G loss: 1.3803\n",
      "[964/1762] D loss: 1.3863, G loss: 0.7252\n",
      "[1044/1762] D loss: 1.1597, G loss: 0.9036\n",
      "[1124/1762] D loss: 0.0916, G loss: 2.4466\n",
      "[1204/1762] D loss: 1.4076, G loss: 0.5662\n",
      "[1284/1762] D loss: 0.3974, G loss: 2.5897\n",
      "[1364/1762] D loss: 1.4068, G loss: 0.6456\n",
      "[1444/1762] D loss: 1.4163, G loss: 0.8533\n",
      "[1524/1762] D loss: 0.0543, G loss: 3.2709\n",
      "[1604/1762] D loss: 1.4283, G loss: 0.7110\n",
      "[1684/1762] D loss: 1.5878, G loss: 1.0610\n",
      "[1762/1762] D loss: 0.1119, G loss: 4.2716\n",
      "train error: \n",
      " D loss: 1.362935, G loss: 0.647095, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.355623, G loss: 0.669039, D accuracy: 55.9%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0511, G loss: 3.1723\n",
      "[84/1762] D loss: 1.3931, G loss: 0.6457\n",
      "[164/1762] D loss: 1.3954, G loss: 0.6584\n",
      "[244/1762] D loss: 1.3942, G loss: 0.6106\n",
      "[324/1762] D loss: 0.9129, G loss: 1.2683\n",
      "[404/1762] D loss: 1.8024, G loss: 0.3656\n",
      "[484/1762] D loss: 1.2751, G loss: 1.0875\n",
      "[564/1762] D loss: 0.1967, G loss: 3.5372\n",
      "[644/1762] D loss: 0.0085, G loss: 4.7819\n",
      "[724/1762] D loss: 0.0985, G loss: 2.4047\n",
      "[804/1762] D loss: 1.4619, G loss: 0.7476\n",
      "[884/1762] D loss: 0.4254, G loss: 2.1945\n",
      "[964/1762] D loss: 1.4534, G loss: 0.5905\n",
      "[1044/1762] D loss: 1.4660, G loss: 0.5636\n",
      "[1124/1762] D loss: 1.4217, G loss: 0.9473\n",
      "[1204/1762] D loss: 0.0801, G loss: 2.6752\n",
      "[1284/1762] D loss: 0.1172, G loss: 2.2421\n",
      "[1364/1762] D loss: 1.4124, G loss: 0.6074\n",
      "[1444/1762] D loss: 1.4178, G loss: 0.8288\n",
      "[1524/1762] D loss: 0.0624, G loss: 3.0473\n",
      "[1604/1762] D loss: 0.0851, G loss: 2.6843\n",
      "[1684/1762] D loss: 0.0827, G loss: 2.7667\n",
      "[1762/1762] D loss: 1.6165, G loss: 1.0489\n",
      "train error: \n",
      " D loss: 1.326013, G loss: 0.768774, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 88.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.306580, G loss: 0.798892, D accuracy: 55.7%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4036, G loss: 0.6798\n",
      "[84/1762] D loss: 0.2270, G loss: 2.1896\n",
      "[164/1762] D loss: 1.4649, G loss: 0.9637\n",
      "[244/1762] D loss: 1.3723, G loss: 0.5987\n",
      "[324/1762] D loss: 0.0932, G loss: 2.6565\n",
      "[404/1762] D loss: 1.5463, G loss: 1.2018\n",
      "[484/1762] D loss: 1.4285, G loss: 0.7693\n",
      "[564/1762] D loss: 1.4213, G loss: 0.7686\n",
      "[644/1762] D loss: 1.5056, G loss: 0.4738\n",
      "[724/1762] D loss: 0.1228, G loss: 2.2204\n",
      "[804/1762] D loss: 0.0971, G loss: 2.5540\n",
      "[884/1762] D loss: 0.0997, G loss: 2.4935\n",
      "[964/1762] D loss: 1.4016, G loss: 0.6149\n",
      "[1044/1762] D loss: 0.1291, G loss: 2.2705\n",
      "[1124/1762] D loss: 0.0975, G loss: 2.4785\n",
      "[1204/1762] D loss: 1.6809, G loss: 0.3973\n",
      "[1284/1762] D loss: 1.3966, G loss: 0.6894\n",
      "[1364/1762] D loss: 0.3208, G loss: 2.7331\n",
      "[1444/1762] D loss: 1.4586, G loss: 0.8344\n",
      "[1524/1762] D loss: 0.0954, G loss: 2.5513\n",
      "[1604/1762] D loss: 0.4018, G loss: 1.6342\n",
      "[1684/1762] D loss: 0.3500, G loss: 3.3233\n",
      "[1762/1762] D loss: 1.4052, G loss: 0.6263\n",
      "train error: \n",
      " D loss: 2.312824, G loss: 0.127126, D accuracy: 50.0%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "test error: \n",
      " D loss: 2.255975, G loss: 0.134287, D accuracy: 50.0%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3885, G loss: 0.7281\n",
      "[84/1762] D loss: 1.4015, G loss: 0.6642\n",
      "[164/1762] D loss: 0.0858, G loss: 2.4015\n",
      "[244/1762] D loss: 1.3914, G loss: 0.4606\n",
      "[324/1762] D loss: 1.1876, G loss: 0.6531\n",
      "[404/1762] D loss: 0.2205, G loss: 2.3150\n",
      "[484/1762] D loss: 0.0409, G loss: 3.3748\n",
      "[564/1762] D loss: 1.4265, G loss: 0.8013\n",
      "[644/1762] D loss: 1.4026, G loss: 0.7165\n",
      "[724/1762] D loss: 1.4070, G loss: 0.6650\n",
      "[804/1762] D loss: 1.3992, G loss: 0.6451\n",
      "[884/1762] D loss: 0.0829, G loss: 2.5944\n",
      "[964/1762] D loss: 1.4022, G loss: 0.8377\n",
      "[1044/1762] D loss: 0.0158, G loss: 4.1852\n",
      "[1124/1762] D loss: 1.4305, G loss: 0.7934\n",
      "[1204/1762] D loss: 0.0670, G loss: 2.8419\n",
      "[1284/1762] D loss: 0.0643, G loss: 2.8810\n",
      "[1364/1762] D loss: 1.4388, G loss: 0.6156\n",
      "[1444/1762] D loss: 1.3518, G loss: 0.5706\n",
      "[1524/1762] D loss: 1.4668, G loss: 0.9114\n",
      "[1604/1762] D loss: 0.5327, G loss: 3.4202\n",
      "[1684/1762] D loss: 1.5230, G loss: 0.4812\n",
      "[1762/1762] D loss: 1.4270, G loss: 0.6352\n",
      "train error: \n",
      " D loss: 1.508615, G loss: 0.396150, D accuracy: 50.9%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.500555, G loss: 0.396227, D accuracy: 50.5%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0859, G loss: 2.7527\n",
      "[84/1762] D loss: 0.0912, G loss: 2.6780\n",
      "[164/1762] D loss: 0.1060, G loss: 2.6679\n",
      "[244/1762] D loss: 1.4320, G loss: 0.9100\n",
      "[324/1762] D loss: 1.8345, G loss: 1.3185\n",
      "[404/1762] D loss: 0.0525, G loss: 3.0657\n",
      "[484/1762] D loss: 1.3885, G loss: 0.8014\n",
      "[564/1762] D loss: 0.0735, G loss: 2.5574\n",
      "[644/1762] D loss: 1.2715, G loss: 1.0270\n",
      "[724/1762] D loss: 1.4170, G loss: 0.6397\n",
      "[804/1762] D loss: 1.4618, G loss: 0.8607\n",
      "[884/1762] D loss: 1.5402, G loss: 1.1098\n",
      "[964/1762] D loss: 1.3934, G loss: 0.7111\n",
      "[1044/1762] D loss: 1.3866, G loss: 0.6700\n",
      "[1124/1762] D loss: 0.0917, G loss: 2.5038\n",
      "[1204/1762] D loss: 1.4349, G loss: 0.4840\n",
      "[1284/1762] D loss: 1.3927, G loss: 0.6321\n",
      "[1364/1762] D loss: 0.1364, G loss: 2.2030\n",
      "[1444/1762] D loss: 0.1746, G loss: 1.8667\n",
      "[1524/1762] D loss: 1.4020, G loss: 0.8932\n",
      "[1604/1762] D loss: 1.4292, G loss: 0.8615\n",
      "[1684/1762] D loss: 1.3972, G loss: 0.8294\n",
      "[1762/1762] D loss: 1.4372, G loss: 0.5257\n",
      "train error: \n",
      " D loss: 1.491880, G loss: 0.407084, D accuracy: 52.1%, cell accuracy: 99.8%, board accuracy: 89.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.473770, G loss: 0.423060, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3954, G loss: 0.8074\n",
      "[84/1762] D loss: 1.5343, G loss: 0.5012\n",
      "[164/1762] D loss: 1.4092, G loss: 0.7566\n",
      "[244/1762] D loss: 0.1184, G loss: 2.3746\n",
      "[324/1762] D loss: 0.0614, G loss: 2.9730\n",
      "[404/1762] D loss: 1.4753, G loss: 0.4561\n",
      "[484/1762] D loss: 1.4097, G loss: 0.6904\n",
      "[564/1762] D loss: 1.4251, G loss: 0.9313\n",
      "[644/1762] D loss: 0.9615, G loss: 1.2454\n",
      "[724/1762] D loss: 0.1421, G loss: 2.6223\n",
      "[804/1762] D loss: 0.1202, G loss: 2.1856\n",
      "[884/1762] D loss: 1.4103, G loss: 0.6691\n",
      "[964/1762] D loss: 1.3984, G loss: 0.6584\n",
      "[1044/1762] D loss: 1.5359, G loss: 0.4282\n",
      "[1124/1762] D loss: 0.0620, G loss: 3.1510\n",
      "[1204/1762] D loss: 1.3961, G loss: 0.8210\n",
      "[1284/1762] D loss: 1.4129, G loss: 0.9414\n",
      "[1364/1762] D loss: 1.4500, G loss: 0.9450\n",
      "[1444/1762] D loss: 1.3899, G loss: 0.7568\n",
      "[1524/1762] D loss: 0.0113, G loss: 4.5414\n",
      "[1604/1762] D loss: 1.2852, G loss: 0.9969\n",
      "[1684/1762] D loss: 1.3936, G loss: 0.5849\n",
      "[1762/1762] D loss: 1.4385, G loss: 0.4672\n",
      "train error: \n",
      " D loss: 1.863579, G loss: 0.235838, D accuracy: 49.8%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.843516, G loss: 0.246874, D accuracy: 49.4%, cell accuracy: 99.8%, board accuracy: 85.9% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4065, G loss: 0.5697\n",
      "[84/1762] D loss: 1.4051, G loss: 0.6329\n",
      "[164/1762] D loss: 1.4089, G loss: 0.7307\n",
      "[244/1762] D loss: 0.2874, G loss: 3.1748\n",
      "[324/1762] D loss: 1.9125, G loss: 1.5981\n",
      "[404/1762] D loss: 1.4839, G loss: 0.9466\n",
      "[484/1762] D loss: 1.4296, G loss: 0.5159\n",
      "[564/1762] D loss: 1.4245, G loss: 0.8555\n",
      "[644/1762] D loss: 1.3954, G loss: 0.6438\n",
      "[724/1762] D loss: 0.0417, G loss: 3.3401\n",
      "[804/1762] D loss: 1.5083, G loss: 1.0205\n",
      "[884/1762] D loss: 1.3953, G loss: 0.6285\n",
      "[964/1762] D loss: 1.4853, G loss: 0.5301\n",
      "[1044/1762] D loss: 1.4078, G loss: 0.6115\n",
      "[1124/1762] D loss: 0.0603, G loss: 3.1560\n",
      "[1204/1762] D loss: 0.0687, G loss: 2.9004\n",
      "[1284/1762] D loss: 0.6705, G loss: 2.0113\n",
      "[1364/1762] D loss: 1.3562, G loss: 0.5524\n",
      "[1444/1762] D loss: 1.3761, G loss: 0.7652\n",
      "[1524/1762] D loss: 1.3798, G loss: 0.7163\n",
      "[1604/1762] D loss: 1.4292, G loss: 0.8851\n",
      "[1684/1762] D loss: 0.8220, G loss: 1.0115\n",
      "[1762/1762] D loss: 1.4527, G loss: 0.7934\n",
      "train error: \n",
      " D loss: 1.375729, G loss: 0.775138, D accuracy: 52.6%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.383422, G loss: 0.801031, D accuracy: 52.7%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3982, G loss: 0.6907\n",
      "[84/1762] D loss: 0.0017, G loss: 6.4072\n",
      "[164/1762] D loss: 1.5650, G loss: 0.4863\n",
      "[244/1762] D loss: 1.4675, G loss: 0.4396\n",
      "[324/1762] D loss: 1.5724, G loss: 0.4311\n",
      "[404/1762] D loss: 0.0135, G loss: 4.3193\n",
      "[484/1762] D loss: 0.1119, G loss: 2.2168\n",
      "[564/1762] D loss: 1.5619, G loss: 0.4264\n",
      "[644/1762] D loss: 0.0984, G loss: 2.5888\n",
      "[724/1762] D loss: 0.0704, G loss: 2.8265\n",
      "[804/1762] D loss: 0.0679, G loss: 2.8107\n",
      "[884/1762] D loss: 1.3959, G loss: 0.6217\n",
      "[964/1762] D loss: 0.9310, G loss: 0.8467\n",
      "[1044/1762] D loss: 1.4628, G loss: 0.4772\n",
      "[1124/1762] D loss: 1.3967, G loss: 0.6898\n",
      "[1204/1762] D loss: 1.3943, G loss: 0.8759\n",
      "[1284/1762] D loss: 1.4488, G loss: 0.4939\n",
      "[1364/1762] D loss: 1.4023, G loss: 0.5591\n",
      "[1444/1762] D loss: 1.4386, G loss: 0.5270\n",
      "[1524/1762] D loss: 1.4216, G loss: 0.7503\n",
      "[1604/1762] D loss: 0.0405, G loss: 4.3897\n",
      "[1684/1762] D loss: 1.3968, G loss: 0.6115\n",
      "[1762/1762] D loss: 1.5482, G loss: 0.3792\n",
      "train error: \n",
      " D loss: 1.514692, G loss: 0.411128, D accuracy: 50.5%, cell accuracy: 99.8%, board accuracy: 88.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.510869, G loss: 0.432113, D accuracy: 51.1%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4454, G loss: 0.4914\n",
      "[84/1762] D loss: 1.4367, G loss: 0.5357\n",
      "[164/1762] D loss: 1.4522, G loss: 0.5526\n",
      "[244/1762] D loss: 0.1135, G loss: 2.8432\n",
      "[324/1762] D loss: 0.2114, G loss: 2.1495\n",
      "[404/1762] D loss: 1.4301, G loss: 0.6217\n",
      "[484/1762] D loss: 1.4100, G loss: 0.5808\n",
      "[564/1762] D loss: 1.4593, G loss: 0.6530\n",
      "[644/1762] D loss: 0.0105, G loss: 4.5670\n",
      "[724/1762] D loss: 1.4259, G loss: 0.6411\n",
      "[804/1762] D loss: 0.8734, G loss: 1.6698\n",
      "[884/1762] D loss: 0.7278, G loss: 2.4632\n",
      "[964/1762] D loss: 1.3723, G loss: 0.5718\n",
      "[1044/1762] D loss: 1.4013, G loss: 0.7218\n",
      "[1124/1762] D loss: 0.0874, G loss: 2.4966\n",
      "[1204/1762] D loss: 1.4141, G loss: 0.6335\n",
      "[1284/1762] D loss: 0.1076, G loss: 2.5896\n",
      "[1364/1762] D loss: 0.3457, G loss: 1.8436\n",
      "[1444/1762] D loss: 1.4471, G loss: 0.9118\n",
      "[1524/1762] D loss: 1.3895, G loss: 0.7306\n",
      "[1604/1762] D loss: 0.0111, G loss: 4.5394\n",
      "[1684/1762] D loss: 0.0101, G loss: 4.6805\n",
      "[1762/1762] D loss: 1.4016, G loss: 0.7047\n",
      "train error: \n",
      " D loss: 1.426331, G loss: 0.661947, D accuracy: 52.0%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.449964, G loss: 0.686827, D accuracy: 52.4%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3981, G loss: 0.6889\n",
      "[84/1762] D loss: 0.7872, G loss: 1.3045\n",
      "[164/1762] D loss: 1.4720, G loss: 0.4474\n",
      "[244/1762] D loss: 1.6167, G loss: 0.4102\n",
      "[324/1762] D loss: 1.3855, G loss: 0.6834\n",
      "[404/1762] D loss: 1.4372, G loss: 0.7802\n",
      "[484/1762] D loss: 1.6922, G loss: 0.4045\n",
      "[564/1762] D loss: 0.1788, G loss: 2.5040\n",
      "[644/1762] D loss: 1.3962, G loss: 0.8268\n",
      "[724/1762] D loss: 1.3877, G loss: 0.6888\n",
      "[804/1762] D loss: 0.0506, G loss: 3.0296\n",
      "[884/1762] D loss: 1.3747, G loss: 0.6680\n",
      "[964/1762] D loss: 0.0367, G loss: 3.4034\n",
      "[1044/1762] D loss: 1.7447, G loss: 0.3385\n",
      "[1124/1762] D loss: 1.3877, G loss: 0.7707\n",
      "[1204/1762] D loss: 1.4039, G loss: 0.8253\n",
      "[1284/1762] D loss: 0.1181, G loss: 2.4502\n",
      "[1364/1762] D loss: 0.0325, G loss: 3.5305\n",
      "[1444/1762] D loss: 0.0084, G loss: 4.8127\n",
      "[1524/1762] D loss: 1.4531, G loss: 0.5598\n",
      "[1604/1762] D loss: 1.3873, G loss: 0.6403\n",
      "[1684/1762] D loss: 0.0133, G loss: 4.3477\n",
      "[1762/1762] D loss: 0.0123, G loss: 4.6493\n",
      "train error: \n",
      " D loss: 1.455675, G loss: 0.541060, D accuracy: 52.9%, cell accuracy: 99.8%, board accuracy: 89.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.467928, G loss: 0.565139, D accuracy: 52.7%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4488, G loss: 0.5166\n",
      "[84/1762] D loss: 1.3854, G loss: 0.7882\n",
      "[164/1762] D loss: 1.4010, G loss: 0.6214\n",
      "[244/1762] D loss: 1.4282, G loss: 0.9615\n",
      "[324/1762] D loss: 1.1647, G loss: 0.7099\n",
      "[404/1762] D loss: 1.4100, G loss: 0.5596\n",
      "[484/1762] D loss: 1.3884, G loss: 0.6497\n",
      "[564/1762] D loss: 1.3961, G loss: 0.8321\n",
      "[644/1762] D loss: 1.1893, G loss: 0.7739\n",
      "[724/1762] D loss: 0.0481, G loss: 3.2656\n",
      "[804/1762] D loss: 0.0791, G loss: 2.6886\n",
      "[884/1762] D loss: 1.8185, G loss: 1.4149\n",
      "[964/1762] D loss: 1.3982, G loss: 0.8193\n",
      "[1044/1762] D loss: 1.4882, G loss: 0.9879\n",
      "[1124/1762] D loss: 1.7573, G loss: 1.3411\n",
      "[1204/1762] D loss: 0.8926, G loss: 1.2718\n",
      "[1284/1762] D loss: 0.3970, G loss: 2.3308\n",
      "[1364/1762] D loss: 0.0917, G loss: 3.9962\n",
      "[1444/1762] D loss: 1.4239, G loss: 0.5351\n",
      "[1524/1762] D loss: 1.4641, G loss: 0.4800\n",
      "[1604/1762] D loss: 0.0621, G loss: 3.6717\n",
      "[1684/1762] D loss: 1.5278, G loss: 1.0149\n",
      "[1762/1762] D loss: 1.9192, G loss: 1.1975\n",
      "train error: \n",
      " D loss: 1.464029, G loss: 1.143071, D accuracy: 51.0%, cell accuracy: 99.8%, board accuracy: 89.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.466698, G loss: 1.146680, D accuracy: 51.4%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4732, G loss: 0.7796\n",
      "[84/1762] D loss: 1.4800, G loss: 0.4226\n",
      "[164/1762] D loss: 0.0778, G loss: 2.7499\n",
      "[244/1762] D loss: 0.0327, G loss: 3.6988\n",
      "[324/1762] D loss: 1.4401, G loss: 0.7575\n",
      "[404/1762] D loss: 1.3934, G loss: 0.8670\n",
      "[484/1762] D loss: 0.9689, G loss: 2.8147\n",
      "[564/1762] D loss: 1.4131, G loss: 0.7188\n",
      "[644/1762] D loss: 1.5453, G loss: 0.4017\n",
      "[724/1762] D loss: 1.4414, G loss: 0.5896\n",
      "[804/1762] D loss: 1.4533, G loss: 1.0288\n",
      "[884/1762] D loss: 0.7632, G loss: 3.5175\n",
      "[964/1762] D loss: 0.5847, G loss: 1.0061\n",
      "[1044/1762] D loss: 0.0150, G loss: 4.5713\n",
      "[1124/1762] D loss: 0.0652, G loss: 2.8732\n",
      "[1204/1762] D loss: 0.0440, G loss: 3.0960\n",
      "[1284/1762] D loss: 1.3807, G loss: 0.5812\n",
      "[1364/1762] D loss: 0.8106, G loss: 1.5857\n",
      "[1444/1762] D loss: 0.9898, G loss: 0.6397\n",
      "[1524/1762] D loss: 0.1471, G loss: 2.2113\n",
      "[1604/1762] D loss: 0.0258, G loss: 3.9383\n",
      "[1684/1762] D loss: 1.5861, G loss: 1.1319\n",
      "[1762/1762] D loss: 1.4633, G loss: 0.9425\n",
      "train error: \n",
      " D loss: 1.387335, G loss: 0.709048, D accuracy: 52.6%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.397319, G loss: 0.724848, D accuracy: 52.5%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3894, G loss: 0.6629\n",
      "[84/1762] D loss: 1.3917, G loss: 0.6232\n",
      "[164/1762] D loss: 1.2992, G loss: 0.8141\n",
      "[244/1762] D loss: 1.5152, G loss: 1.0564\n",
      "[324/1762] D loss: 1.3838, G loss: 0.7000\n",
      "[404/1762] D loss: 0.0418, G loss: 3.3875\n",
      "[484/1762] D loss: 1.4056, G loss: 0.7543\n",
      "[564/1762] D loss: 0.8333, G loss: 1.2060\n",
      "[644/1762] D loss: 1.4103, G loss: 0.8768\n",
      "[724/1762] D loss: 0.0817, G loss: 2.8269\n",
      "[804/1762] D loss: 0.0406, G loss: 3.3246\n",
      "[884/1762] D loss: 0.1077, G loss: 2.5644\n",
      "[964/1762] D loss: 1.3944, G loss: 0.7220\n",
      "[1044/1762] D loss: 0.0545, G loss: 2.8340\n",
      "[1124/1762] D loss: 0.0145, G loss: 4.3111\n",
      "[1204/1762] D loss: 0.1535, G loss: 1.9500\n",
      "[1284/1762] D loss: 0.0640, G loss: 2.9295\n",
      "[1364/1762] D loss: 0.1659, G loss: 2.1622\n",
      "[1444/1762] D loss: 1.4028, G loss: 0.8733\n",
      "[1524/1762] D loss: 1.3905, G loss: 0.6685\n",
      "[1604/1762] D loss: 1.4079, G loss: 0.8201\n",
      "[1684/1762] D loss: 1.4775, G loss: 0.4320\n",
      "[1762/1762] D loss: 1.5172, G loss: 0.5064\n",
      "train error: \n",
      " D loss: 2.222447, G loss: 0.152761, D accuracy: 49.8%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "test error: \n",
      " D loss: 2.200711, G loss: 0.162530, D accuracy: 49.5%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4016, G loss: 0.6208\n",
      "[84/1762] D loss: 1.3918, G loss: 0.5891\n",
      "[164/1762] D loss: 1.4062, G loss: 0.6358\n",
      "[244/1762] D loss: 0.0290, G loss: 3.7221\n",
      "[324/1762] D loss: 1.4537, G loss: 0.8105\n",
      "[404/1762] D loss: 1.3923, G loss: 0.7348\n",
      "[484/1762] D loss: 1.0311, G loss: 2.3326\n",
      "[564/1762] D loss: 1.4003, G loss: 0.6484\n",
      "[644/1762] D loss: 1.4223, G loss: 0.6740\n",
      "[724/1762] D loss: 1.3982, G loss: 0.6244\n",
      "[804/1762] D loss: 1.3870, G loss: 0.6513\n",
      "[884/1762] D loss: 1.4032, G loss: 0.7891\n",
      "[964/1762] D loss: 0.0083, G loss: 4.8644\n",
      "[1044/1762] D loss: 0.0151, G loss: 4.3221\n",
      "[1124/1762] D loss: 1.3389, G loss: 1.0067\n",
      "[1204/1762] D loss: 1.2370, G loss: 0.9279\n",
      "[1284/1762] D loss: 1.0813, G loss: 0.7148\n",
      "[1364/1762] D loss: 1.3849, G loss: 0.7101\n",
      "[1444/1762] D loss: 1.3889, G loss: 0.6900\n",
      "[1524/1762] D loss: 0.4064, G loss: 3.5502\n",
      "[1604/1762] D loss: 0.0165, G loss: 4.4628\n",
      "[1684/1762] D loss: 0.1296, G loss: 3.8793\n",
      "[1762/1762] D loss: 1.6074, G loss: 1.1064\n",
      "train error: \n",
      " D loss: 1.482892, G loss: 0.592147, D accuracy: 51.4%, cell accuracy: 99.8%, board accuracy: 89.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.526199, G loss: 0.604864, D accuracy: 51.0%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4249, G loss: 0.5552\n",
      "[84/1762] D loss: 0.1823, G loss: 2.7523\n",
      "[164/1762] D loss: 0.6020, G loss: 1.2027\n",
      "[244/1762] D loss: 1.7194, G loss: 1.2512\n",
      "[324/1762] D loss: 1.8869, G loss: 1.3324\n",
      "[404/1762] D loss: 0.0111, G loss: 4.6189\n",
      "[484/1762] D loss: 0.0279, G loss: 3.6838\n",
      "[564/1762] D loss: 1.4252, G loss: 0.9013\n",
      "[644/1762] D loss: 0.0509, G loss: 3.2275\n",
      "[724/1762] D loss: 1.3981, G loss: 0.8025\n",
      "[804/1762] D loss: 0.0619, G loss: 2.8746\n",
      "[884/1762] D loss: 1.3556, G loss: 0.7737\n",
      "[964/1762] D loss: 1.4018, G loss: 0.6036\n",
      "[1044/1762] D loss: 0.0441, G loss: 3.0751\n",
      "[1124/1762] D loss: 0.0759, G loss: 2.7494\n",
      "[1204/1762] D loss: 0.0082, G loss: 4.8033\n",
      "[1284/1762] D loss: 1.3907, G loss: 0.5678\n",
      "[1364/1762] D loss: 1.4977, G loss: 0.4930\n",
      "[1444/1762] D loss: 0.4564, G loss: 2.8138\n",
      "[1524/1762] D loss: 1.6921, G loss: 0.4349\n",
      "[1604/1762] D loss: 1.4823, G loss: 0.8242\n",
      "[1684/1762] D loss: 1.4202, G loss: 0.8191\n",
      "[1762/1762] D loss: 0.0635, G loss: 4.8909\n",
      "train error: \n",
      " D loss: 1.384777, G loss: 0.659723, D accuracy: 53.1%, cell accuracy: 99.8%, board accuracy: 89.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.405229, G loss: 0.669320, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3889, G loss: 0.6628\n",
      "[84/1762] D loss: 0.0685, G loss: 2.7899\n",
      "[164/1762] D loss: 0.0392, G loss: 3.4144\n",
      "[244/1762] D loss: 0.0236, G loss: 3.9268\n",
      "[324/1762] D loss: 1.3501, G loss: 0.7264\n",
      "[404/1762] D loss: 1.4942, G loss: 0.9936\n",
      "[484/1762] D loss: 1.3850, G loss: 0.8114\n",
      "[564/1762] D loss: 0.9808, G loss: 2.6694\n",
      "[644/1762] D loss: 0.0058, G loss: 5.1493\n",
      "[724/1762] D loss: 0.0480, G loss: 3.1436\n",
      "[804/1762] D loss: 1.3828, G loss: 0.7269\n",
      "[884/1762] D loss: 0.0703, G loss: 2.9766\n",
      "[964/1762] D loss: 1.5673, G loss: 0.3982\n",
      "[1044/1762] D loss: 0.8899, G loss: 1.0371\n",
      "[1124/1762] D loss: 1.4309, G loss: 0.5604\n",
      "[1204/1762] D loss: 0.0068, G loss: 5.0222\n",
      "[1284/1762] D loss: 1.4786, G loss: 2.5933\n",
      "[1364/1762] D loss: 1.5196, G loss: 0.9384\n",
      "[1444/1762] D loss: 1.3921, G loss: 1.0011\n",
      "[1524/1762] D loss: 0.9567, G loss: 2.1658\n",
      "[1604/1762] D loss: 0.0693, G loss: 2.8363\n",
      "[1684/1762] D loss: 1.3737, G loss: 0.6014\n",
      "[1762/1762] D loss: 0.0054, G loss: 5.2832\n",
      "train error: \n",
      " D loss: 2.495589, G loss: 0.103278, D accuracy: 50.1%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "test error: \n",
      " D loss: 2.455153, G loss: 0.110399, D accuracy: 50.0%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3817, G loss: 0.7492\n",
      "[84/1762] D loss: 1.4240, G loss: 1.0020\n",
      "[164/1762] D loss: 1.4857, G loss: 0.9571\n",
      "[244/1762] D loss: 1.3870, G loss: 0.6859\n",
      "[324/1762] D loss: 0.0480, G loss: 3.1492\n",
      "[404/1762] D loss: 1.4231, G loss: 0.8915\n",
      "[484/1762] D loss: 1.4566, G loss: 0.4792\n",
      "[564/1762] D loss: 1.3943, G loss: 0.9331\n",
      "[644/1762] D loss: 1.4602, G loss: 0.7932\n",
      "[724/1762] D loss: 1.4545, G loss: 0.5885\n",
      "[804/1762] D loss: 0.0505, G loss: 3.6457\n",
      "[884/1762] D loss: 1.3873, G loss: 0.6127\n",
      "[964/1762] D loss: 1.4030, G loss: 0.6371\n",
      "[1044/1762] D loss: 1.6004, G loss: 1.2747\n",
      "[1124/1762] D loss: 0.0345, G loss: 3.4855\n",
      "[1204/1762] D loss: 1.3878, G loss: 0.7706\n",
      "[1284/1762] D loss: 1.4322, G loss: 0.5621\n",
      "[1364/1762] D loss: 1.3723, G loss: 0.6657\n",
      "[1444/1762] D loss: 1.3820, G loss: 0.6797\n",
      "[1524/1762] D loss: 1.3938, G loss: 0.6754\n",
      "[1604/1762] D loss: 0.0336, G loss: 3.6088\n",
      "[1684/1762] D loss: 1.4495, G loss: 1.2171\n",
      "[1762/1762] D loss: 0.1499, G loss: 4.2892\n",
      "train error: \n",
      " D loss: 1.857478, G loss: 0.243111, D accuracy: 49.9%, cell accuracy: 99.8%, board accuracy: 90.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.840783, G loss: 0.255597, D accuracy: 49.7%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1285, G loss: 4.9180\n",
      "[84/1762] D loss: 1.4092, G loss: 0.5683\n",
      "[164/1762] D loss: 0.0883, G loss: 2.5293\n",
      "[244/1762] D loss: 0.0039, G loss: 5.5792\n",
      "[324/1762] D loss: 1.4227, G loss: 0.8032\n",
      "[404/1762] D loss: 1.4563, G loss: 1.0181\n",
      "[484/1762] D loss: 1.3954, G loss: 0.5778\n",
      "[564/1762] D loss: 0.0936, G loss: 2.3945\n",
      "[644/1762] D loss: 1.4579, G loss: 0.8583\n",
      "[724/1762] D loss: 0.1557, G loss: 2.2265\n",
      "[804/1762] D loss: 1.5801, G loss: 0.4219\n",
      "[884/1762] D loss: 0.0909, G loss: 2.5326\n",
      "[964/1762] D loss: 0.9363, G loss: 0.9787\n",
      "[1044/1762] D loss: 0.0478, G loss: 3.1772\n",
      "[1124/1762] D loss: 1.3906, G loss: 0.8454\n",
      "[1204/1762] D loss: 1.3250, G loss: 0.5793\n",
      "[1284/1762] D loss: 1.3933, G loss: 0.6342\n",
      "[1364/1762] D loss: 1.3947, G loss: 0.6471\n",
      "[1444/1762] D loss: 1.3729, G loss: 0.7927\n",
      "[1524/1762] D loss: 1.3800, G loss: 0.7358\n",
      "[1604/1762] D loss: 1.3905, G loss: 0.6868\n",
      "[1684/1762] D loss: 1.3770, G loss: 0.8207\n",
      "[1762/1762] D loss: 1.4016, G loss: 0.8012\n",
      "train error: \n",
      " D loss: 2.036187, G loss: 0.188164, D accuracy: 49.6%, cell accuracy: 99.8%, board accuracy: 90.4% \n",
      "\n",
      "test error: \n",
      " D loss: 2.017558, G loss: 0.201273, D accuracy: 49.2%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3810, G loss: 0.6925\n",
      "[84/1762] D loss: 1.3800, G loss: 0.7694\n",
      "[164/1762] D loss: 1.1391, G loss: 0.8954\n",
      "[244/1762] D loss: 1.4226, G loss: 0.6233\n",
      "[324/1762] D loss: 0.0804, G loss: 2.5067\n",
      "[404/1762] D loss: 0.0483, G loss: 3.1421\n",
      "[484/1762] D loss: 1.4562, G loss: 0.9914\n",
      "[564/1762] D loss: 0.8447, G loss: 1.0225\n",
      "[644/1762] D loss: 0.0596, G loss: 2.8317\n",
      "[724/1762] D loss: 0.0056, G loss: 5.2977\n",
      "[804/1762] D loss: 0.0184, G loss: 4.1674\n",
      "[884/1762] D loss: 1.5332, G loss: 0.4554\n",
      "[964/1762] D loss: 1.6764, G loss: 0.4807\n",
      "[1044/1762] D loss: 0.0708, G loss: 2.7941\n",
      "[1124/1762] D loss: 0.1172, G loss: 3.2178\n",
      "[1204/1762] D loss: 0.0404, G loss: 3.4126\n",
      "[1284/1762] D loss: 1.6152, G loss: 0.3459\n",
      "[1364/1762] D loss: 0.0808, G loss: 2.5817\n",
      "[1444/1762] D loss: 1.3597, G loss: 0.6599\n",
      "[1524/1762] D loss: 0.0081, G loss: 4.8466\n",
      "[1604/1762] D loss: 1.4006, G loss: 0.6811\n",
      "[1684/1762] D loss: 1.3887, G loss: 0.6252\n",
      "[1762/1762] D loss: 1.4004, G loss: 0.6899\n",
      "train error: \n",
      " D loss: 1.493012, G loss: 0.692533, D accuracy: 52.7%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.556227, G loss: 0.706791, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.7398\n",
      "[84/1762] D loss: 1.3781, G loss: 0.6083\n",
      "[164/1762] D loss: 0.0733, G loss: 2.7221\n",
      "[244/1762] D loss: 1.5103, G loss: 1.0307\n",
      "[324/1762] D loss: 1.4094, G loss: 0.8060\n",
      "[404/1762] D loss: 0.0099, G loss: 5.1624\n",
      "[484/1762] D loss: 1.3867, G loss: 0.6932\n",
      "[564/1762] D loss: 0.3623, G loss: 3.1086\n",
      "[644/1762] D loss: 1.4430, G loss: 0.4728\n",
      "[724/1762] D loss: 1.3424, G loss: 0.5676\n",
      "[804/1762] D loss: 1.4242, G loss: 0.5169\n",
      "[884/1762] D loss: 1.5560, G loss: 0.4397\n",
      "[964/1762] D loss: 1.3648, G loss: 0.6468\n",
      "[1044/1762] D loss: 1.4219, G loss: 0.7494\n",
      "[1124/1762] D loss: 0.0045, G loss: 5.4136\n",
      "[1204/1762] D loss: 0.3134, G loss: 3.0658\n",
      "[1284/1762] D loss: 0.3919, G loss: 2.2243\n",
      "[1364/1762] D loss: 1.3984, G loss: 0.4700\n",
      "[1444/1762] D loss: 0.0263, G loss: 3.5517\n",
      "[1524/1762] D loss: 1.3989, G loss: 0.8958\n",
      "[1604/1762] D loss: 1.5560, G loss: 1.3148\n",
      "[1684/1762] D loss: 1.5768, G loss: 0.4333\n",
      "[1762/1762] D loss: 1.8154, G loss: 0.3800\n",
      "train error: \n",
      " D loss: 1.622237, G loss: 0.386387, D accuracy: 51.0%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.637234, G loss: 0.410918, D accuracy: 51.6%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4039, G loss: 0.7631\n",
      "[84/1762] D loss: 1.6127, G loss: 1.1603\n",
      "[164/1762] D loss: 0.5437, G loss: 2.4455\n",
      "[244/1762] D loss: 1.1983, G loss: 0.6884\n",
      "[324/1762] D loss: 1.3691, G loss: 0.6834\n",
      "[404/1762] D loss: 0.0848, G loss: 2.7277\n",
      "[484/1762] D loss: 1.4842, G loss: 0.4665\n",
      "[564/1762] D loss: 0.0392, G loss: 3.3799\n",
      "[644/1762] D loss: 0.1888, G loss: 2.5294\n",
      "[724/1762] D loss: 0.0211, G loss: 4.1131\n",
      "[804/1762] D loss: 0.3829, G loss: 1.6475\n",
      "[884/1762] D loss: 1.3648, G loss: 0.7856\n",
      "[964/1762] D loss: 1.4922, G loss: 1.2777\n",
      "[1044/1762] D loss: 0.0420, G loss: 3.0841\n",
      "[1124/1762] D loss: 1.4036, G loss: 0.5301\n",
      "[1204/1762] D loss: 1.4595, G loss: 0.8872\n",
      "[1284/1762] D loss: 1.2550, G loss: 1.0053\n",
      "[1364/1762] D loss: 1.4325, G loss: 1.1938\n",
      "[1444/1762] D loss: 1.3602, G loss: 0.6892\n",
      "[1524/1762] D loss: 1.4155, G loss: 0.5497\n",
      "[1604/1762] D loss: 1.3960, G loss: 0.7404\n",
      "[1684/1762] D loss: 1.3669, G loss: 0.8333\n",
      "[1762/1762] D loss: 1.2964, G loss: 0.7605\n",
      "train error: \n",
      " D loss: 1.971745, G loss: 0.218174, D accuracy: 49.8%, cell accuracy: 99.8%, board accuracy: 89.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.945954, G loss: 0.237633, D accuracy: 49.1%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2833, G loss: 2.9867\n",
      "[84/1762] D loss: 1.5204, G loss: 0.4969\n",
      "[164/1762] D loss: 0.3075, G loss: 2.6129\n",
      "[244/1762] D loss: 0.0061, G loss: 5.0921\n",
      "[324/1762] D loss: 0.0683, G loss: 3.0280\n",
      "[404/1762] D loss: 1.4308, G loss: 1.0178\n",
      "[484/1762] D loss: 1.5885, G loss: 2.2517\n",
      "[564/1762] D loss: 0.0310, G loss: 3.7998\n",
      "[644/1762] D loss: 1.4078, G loss: 0.5935\n",
      "[724/1762] D loss: 1.3930, G loss: 0.6913\n",
      "[804/1762] D loss: 0.0067, G loss: 5.0148\n",
      "[884/1762] D loss: 1.3847, G loss: 0.7481\n",
      "[964/1762] D loss: 1.4155, G loss: 0.8877\n",
      "[1044/1762] D loss: 1.3499, G loss: 0.6358\n",
      "[1124/1762] D loss: 1.3851, G loss: 0.6650\n",
      "[1204/1762] D loss: 1.3860, G loss: 0.6736\n",
      "[1284/1762] D loss: 0.0693, G loss: 4.7271\n",
      "[1364/1762] D loss: 1.4042, G loss: 0.7333\n",
      "[1444/1762] D loss: 1.3972, G loss: 0.7013\n",
      "[1524/1762] D loss: 1.4047, G loss: 0.8068\n",
      "[1604/1762] D loss: 1.4012, G loss: 0.6210\n",
      "[1684/1762] D loss: 1.3452, G loss: 1.0354\n",
      "[1762/1762] D loss: 1.4632, G loss: 0.4434\n",
      "train error: \n",
      " D loss: 3.693865, G loss: 0.030604, D accuracy: 49.6%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.676269, G loss: 0.031706, D accuracy: 49.3%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0999, G loss: 2.3685\n",
      "[84/1762] D loss: 0.0039, G loss: 5.6501\n",
      "[164/1762] D loss: 1.4280, G loss: 0.5469\n",
      "[244/1762] D loss: 0.0298, G loss: 3.5964\n",
      "[324/1762] D loss: 1.3796, G loss: 0.7115\n",
      "[404/1762] D loss: 1.3380, G loss: 0.6112\n",
      "[484/1762] D loss: 1.3921, G loss: 0.6965\n",
      "[564/1762] D loss: 1.2453, G loss: 0.7464\n",
      "[644/1762] D loss: 1.3816, G loss: 0.7827\n",
      "[724/1762] D loss: 0.0367, G loss: 3.5266\n",
      "[804/1762] D loss: 1.4303, G loss: 0.5724\n",
      "[884/1762] D loss: 0.0187, G loss: 4.3134\n",
      "[964/1762] D loss: 1.4394, G loss: 1.0528\n",
      "[1044/1762] D loss: 0.9362, G loss: 0.9127\n",
      "[1124/1762] D loss: 1.5125, G loss: 1.3354\n",
      "[1204/1762] D loss: 0.0573, G loss: 2.8674\n",
      "[1284/1762] D loss: 1.3409, G loss: 0.7656\n",
      "[1364/1762] D loss: 0.0814, G loss: 2.8125\n",
      "[1444/1762] D loss: 1.3976, G loss: 0.6133\n",
      "[1524/1762] D loss: 1.4327, G loss: 0.5989\n",
      "[1604/1762] D loss: 1.4444, G loss: 0.9579\n",
      "[1684/1762] D loss: 0.0255, G loss: 3.6495\n",
      "[1762/1762] D loss: 1.4383, G loss: 0.9531\n",
      "train error: \n",
      " D loss: 1.446839, G loss: 0.570989, D accuracy: 51.9%, cell accuracy: 99.8%, board accuracy: 89.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.482472, G loss: 0.595333, D accuracy: 52.0%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3542, G loss: 0.6302\n",
      "[84/1762] D loss: 1.3712, G loss: 0.6202\n",
      "[164/1762] D loss: 1.3717, G loss: 0.8063\n",
      "[244/1762] D loss: 1.3752, G loss: 0.6674\n",
      "[324/1762] D loss: 0.9209, G loss: 0.8967\n",
      "[404/1762] D loss: 0.0101, G loss: 4.5482\n",
      "[484/1762] D loss: 1.4218, G loss: 0.5355\n",
      "[564/1762] D loss: 1.2511, G loss: 0.7572\n",
      "[644/1762] D loss: 0.0261, G loss: 3.8917\n",
      "[724/1762] D loss: 0.6882, G loss: 1.3376\n",
      "[804/1762] D loss: 1.3964, G loss: 0.4860\n",
      "[884/1762] D loss: 1.3728, G loss: 0.7509\n",
      "[964/1762] D loss: 1.6151, G loss: 1.1760\n",
      "[1044/1762] D loss: 1.4127, G loss: 0.8171\n",
      "[1124/1762] D loss: 0.1097, G loss: 3.1958\n",
      "[1204/1762] D loss: 1.3808, G loss: 0.8198\n",
      "[1284/1762] D loss: 1.3371, G loss: 0.7251\n",
      "[1364/1762] D loss: 0.4284, G loss: 2.4604\n",
      "[1444/1762] D loss: 1.4872, G loss: 0.4334\n",
      "[1524/1762] D loss: 0.4444, G loss: 1.9623\n",
      "[1604/1762] D loss: 0.5762, G loss: 2.0402\n",
      "[1684/1762] D loss: 1.4103, G loss: 0.6615\n",
      "[1762/1762] D loss: 1.3674, G loss: 0.6504\n",
      "train error: \n",
      " D loss: 2.688446, G loss: 0.090348, D accuracy: 47.9%, cell accuracy: 99.8%, board accuracy: 89.2% \n",
      "\n",
      "test error: \n",
      " D loss: 2.671867, G loss: 0.096166, D accuracy: 46.9%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3951, G loss: 0.8188\n",
      "[84/1762] D loss: 1.4692, G loss: 0.5903\n",
      "[164/1762] D loss: 0.0209, G loss: 4.0788\n",
      "[244/1762] D loss: 1.7577, G loss: 1.4995\n",
      "[324/1762] D loss: 0.7294, G loss: 1.4057\n",
      "[404/1762] D loss: 1.3788, G loss: 0.7305\n",
      "[484/1762] D loss: 1.4042, G loss: 0.7370\n",
      "[564/1762] D loss: 1.3941, G loss: 0.5830\n",
      "[644/1762] D loss: 0.0483, G loss: 3.4801\n",
      "[724/1762] D loss: 0.0079, G loss: 4.8422\n",
      "[804/1762] D loss: 1.1791, G loss: 0.7966\n",
      "[884/1762] D loss: 1.3769, G loss: 0.6463\n",
      "[964/1762] D loss: 0.0217, G loss: 4.4065\n",
      "[1044/1762] D loss: 0.0531, G loss: 3.1590\n",
      "[1124/1762] D loss: 1.0783, G loss: 1.2267\n",
      "[1204/1762] D loss: 0.0805, G loss: 3.2464\n",
      "[1284/1762] D loss: 0.0895, G loss: 2.4111\n",
      "[1364/1762] D loss: 0.0035, G loss: 5.7530\n",
      "[1444/1762] D loss: 1.7391, G loss: 1.3742\n",
      "[1524/1762] D loss: 0.0548, G loss: 2.8867\n",
      "[1604/1762] D loss: 1.4606, G loss: 0.5318\n",
      "[1684/1762] D loss: 0.0495, G loss: 3.2768\n",
      "[1762/1762] D loss: 0.0050, G loss: 5.3141\n",
      "train error: \n",
      " D loss: 3.272077, G loss: 0.046033, D accuracy: 48.7%, cell accuracy: 99.8%, board accuracy: 89.7% \n",
      "\n",
      "test error: \n",
      " D loss: 3.273489, G loss: 0.048984, D accuracy: 48.0%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4301, G loss: 0.5305\n",
      "[84/1762] D loss: 0.0419, G loss: 3.3688\n",
      "[164/1762] D loss: 0.0754, G loss: 2.5618\n",
      "[244/1762] D loss: 0.0862, G loss: 2.5940\n",
      "[324/1762] D loss: 0.0055, G loss: 5.2527\n",
      "[404/1762] D loss: 0.0268, G loss: 3.7130\n",
      "[484/1762] D loss: 0.1843, G loss: 3.9228\n",
      "[564/1762] D loss: 1.4723, G loss: 0.7725\n",
      "[644/1762] D loss: 0.0329, G loss: 3.4520\n",
      "[724/1762] D loss: 1.3711, G loss: 0.6831\n",
      "[804/1762] D loss: 1.3244, G loss: 0.7200\n",
      "[884/1762] D loss: 1.4142, G loss: 1.0123\n",
      "[964/1762] D loss: 1.3899, G loss: 0.9123\n",
      "[1044/1762] D loss: 0.0042, G loss: 5.5518\n",
      "[1124/1762] D loss: 0.6905, G loss: 2.0492\n",
      "[1204/1762] D loss: 1.0433, G loss: 1.2624\n",
      "[1284/1762] D loss: 1.3354, G loss: 0.8085\n",
      "[1364/1762] D loss: 1.4995, G loss: 1.0259\n",
      "[1444/1762] D loss: 1.3541, G loss: 0.6823\n",
      "[1524/1762] D loss: 1.6356, G loss: 0.3644\n",
      "[1604/1762] D loss: 1.5810, G loss: 0.4322\n",
      "[1684/1762] D loss: 0.0645, G loss: 2.8381\n",
      "[1762/1762] D loss: 0.0073, G loss: 4.9328\n",
      "train error: \n",
      " D loss: 3.812217, G loss: 0.026231, D accuracy: 50.0%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "test error: \n",
      " D loss: 3.748410, G loss: 0.027794, D accuracy: 49.9%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4335, G loss: 0.5505\n",
      "[84/1762] D loss: 1.4208, G loss: 0.5939\n",
      "[164/1762] D loss: 1.2682, G loss: 0.8628\n",
      "[244/1762] D loss: 1.1942, G loss: 0.8018\n",
      "[324/1762] D loss: 1.3349, G loss: 0.8212\n",
      "[404/1762] D loss: 0.6463, G loss: 1.3206\n",
      "[484/1762] D loss: 1.3738, G loss: 0.6866\n",
      "[564/1762] D loss: 1.3656, G loss: 0.7959\n",
      "[644/1762] D loss: 1.3743, G loss: 0.5926\n",
      "[724/1762] D loss: 1.4068, G loss: 0.7704\n",
      "[804/1762] D loss: 0.0383, G loss: 3.5452\n",
      "[884/1762] D loss: 0.0469, G loss: 3.1481\n",
      "[964/1762] D loss: 0.0383, G loss: 3.3382\n",
      "[1044/1762] D loss: 0.5315, G loss: 3.0420\n",
      "[1124/1762] D loss: 0.3828, G loss: 1.7501\n",
      "[1204/1762] D loss: 1.4179, G loss: 0.4981\n",
      "[1284/1762] D loss: 0.7055, G loss: 1.7239\n",
      "[1364/1762] D loss: 1.3684, G loss: 0.8052\n",
      "[1444/1762] D loss: 1.4709, G loss: 2.4850\n",
      "[1524/1762] D loss: 0.0410, G loss: 3.4891\n",
      "[1604/1762] D loss: 1.4549, G loss: 1.0851\n",
      "[1684/1762] D loss: 0.4720, G loss: 2.8105\n",
      "[1762/1762] D loss: 1.4883, G loss: 0.4824\n",
      "train error: \n",
      " D loss: 1.779291, G loss: 0.287894, D accuracy: 48.0%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.826831, G loss: 0.296057, D accuracy: 47.0%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0582, G loss: 2.9664\n",
      "[84/1762] D loss: 0.3068, G loss: 1.6642\n",
      "[164/1762] D loss: 1.5186, G loss: 0.4532\n",
      "[244/1762] D loss: 1.3901, G loss: 0.6686\n",
      "[324/1762] D loss: 0.1533, G loss: 2.7215\n",
      "[404/1762] D loss: 0.1952, G loss: 3.6841\n",
      "[484/1762] D loss: 0.0165, G loss: 4.3332\n",
      "[564/1762] D loss: 0.0355, G loss: 4.0954\n",
      "[644/1762] D loss: 1.3638, G loss: 0.8037\n",
      "[724/1762] D loss: 1.3485, G loss: 0.6216\n",
      "[804/1762] D loss: 1.4015, G loss: 0.6187\n",
      "[884/1762] D loss: 0.0289, G loss: 3.5951\n",
      "[964/1762] D loss: 0.0276, G loss: 3.5990\n",
      "[1044/1762] D loss: 1.4047, G loss: 0.9394\n",
      "[1124/1762] D loss: 0.8482, G loss: 0.8092\n",
      "[1204/1762] D loss: 1.2480, G loss: 0.7346\n",
      "[1284/1762] D loss: 1.4884, G loss: 0.5818\n",
      "[1364/1762] D loss: 1.5258, G loss: 1.1452\n",
      "[1444/1762] D loss: 1.4000, G loss: 0.7329\n",
      "[1524/1762] D loss: 1.3824, G loss: 0.7734\n",
      "[1604/1762] D loss: 0.0323, G loss: 3.4992\n",
      "[1684/1762] D loss: 0.0921, G loss: 2.3218\n",
      "[1762/1762] D loss: 1.4121, G loss: 0.7420\n",
      "train error: \n",
      " D loss: 1.529737, G loss: 0.595573, D accuracy: 52.9%, cell accuracy: 99.8%, board accuracy: 89.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.593442, G loss: 0.606511, D accuracy: 52.5%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0107, G loss: 4.4917\n",
      "[84/1762] D loss: 0.2464, G loss: 2.9446\n",
      "[164/1762] D loss: 1.3573, G loss: 0.7730\n",
      "[244/1762] D loss: 0.0382, G loss: 3.1302\n",
      "[324/1762] D loss: 0.0121, G loss: 5.3218\n",
      "[404/1762] D loss: 0.0015, G loss: 6.6919\n",
      "[484/1762] D loss: 1.4040, G loss: 0.7628\n",
      "[564/1762] D loss: 0.7252, G loss: 2.2203\n",
      "[644/1762] D loss: 1.3817, G loss: 0.4687\n",
      "[724/1762] D loss: 0.0336, G loss: 3.3467\n",
      "[804/1762] D loss: 1.4568, G loss: 0.5076\n",
      "[884/1762] D loss: 1.3336, G loss: 0.6640\n",
      "[964/1762] D loss: 0.0171, G loss: 4.5047\n",
      "[1044/1762] D loss: 0.0511, G loss: 2.9820\n",
      "[1124/1762] D loss: 1.2972, G loss: 0.7329\n",
      "[1204/1762] D loss: 0.0051, G loss: 5.2606\n",
      "[1284/1762] D loss: 0.0422, G loss: 3.2205\n",
      "[1364/1762] D loss: 1.4234, G loss: 0.4552\n",
      "[1444/1762] D loss: 1.3520, G loss: 0.8969\n",
      "[1524/1762] D loss: 0.1583, G loss: 2.6119\n",
      "[1604/1762] D loss: 0.0062, G loss: 5.1302\n",
      "[1684/1762] D loss: 1.3896, G loss: 0.7974\n",
      "[1762/1762] D loss: 0.5766, G loss: 2.5790\n",
      "train error: \n",
      " D loss: 1.430662, G loss: 0.868469, D accuracy: 56.7%, cell accuracy: 99.8%, board accuracy: 88.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.492754, G loss: 0.903775, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0545, G loss: 3.1803\n",
      "[84/1762] D loss: 1.4015, G loss: 0.5000\n",
      "[164/1762] D loss: 1.4344, G loss: 0.9728\n",
      "[244/1762] D loss: 1.2024, G loss: 0.9329\n",
      "[324/1762] D loss: 1.3335, G loss: 0.7230\n",
      "[404/1762] D loss: 1.1987, G loss: 0.6893\n",
      "[484/1762] D loss: 0.0439, G loss: 3.1042\n",
      "[564/1762] D loss: 1.3097, G loss: 0.8857\n",
      "[644/1762] D loss: 1.3436, G loss: 0.6012\n",
      "[724/1762] D loss: 1.1162, G loss: 1.5924\n",
      "[804/1762] D loss: 0.2904, G loss: 3.2905\n",
      "[884/1762] D loss: 1.3143, G loss: 0.6327\n",
      "[964/1762] D loss: 0.0048, G loss: 5.4238\n",
      "[1044/1762] D loss: 0.0041, G loss: 5.5746\n",
      "[1124/1762] D loss: 1.3585, G loss: 0.8515\n",
      "[1204/1762] D loss: 0.0012, G loss: 6.8547\n",
      "[1284/1762] D loss: 0.0265, G loss: 3.9616\n",
      "[1364/1762] D loss: 1.3427, G loss: 0.6790\n",
      "[1444/1762] D loss: 0.4688, G loss: 4.4113\n",
      "[1524/1762] D loss: 0.0301, G loss: 3.6123\n",
      "[1604/1762] D loss: 0.0264, G loss: 3.5302\n",
      "[1684/1762] D loss: 1.2231, G loss: 0.6862\n",
      "[1762/1762] D loss: 0.0796, G loss: 6.4065\n",
      "train error: \n",
      " D loss: 2.195941, G loss: 0.172443, D accuracy: 50.8%, cell accuracy: 99.8%, board accuracy: 90.4% \n",
      "\n",
      "test error: \n",
      " D loss: 2.152263, G loss: 0.187761, D accuracy: 51.1%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_and_freeze_gen_and_replace_disc(\"freeze_gen_replace_disc_epoch_5\", freeze_epoch=5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even a newly initialized discriminator struggles on this problem. This suggests that the original discriminator is not in a \"locked-in\" state, it just isn't capable of learning the problem with the current setup.\n",
    "\n",
    "To improve the situation, we could reduce the discriminator learning rate, or modify the discriminator architecture. In particular, we could increase the capacity and/or add more batch normalization to it.\n",
    "\n",
    "The gradient histograms for the discriminator show that many layers have weights in the range (-2, 2) or (-5, 5), which is larger than I've seen with other ML models in the past. The final linear layer always tends to have some gradients that are below -3, sometimes even below -10 for one of the training runs. This means the discriminator might be having a mild version of the exploding gradient problem. We could try a different initialization scheme as per the DCGAN paper, or target our architecture changes towards minimising this."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3850, G loss: 0.6712\n",
      "[84/1762] D loss: 0.9374, G loss: 0.9944\n",
      "[164/1762] D loss: 0.4977, G loss: 1.4863\n",
      "[244/1762] D loss: 0.1457, G loss: 2.6692\n",
      "[324/1762] D loss: 0.0961, G loss: 3.0312\n",
      "[404/1762] D loss: 0.0894, G loss: 3.0216\n",
      "[484/1762] D loss: 0.2817, G loss: 3.8023\n",
      "[564/1762] D loss: 0.3669, G loss: 1.7353\n",
      "[644/1762] D loss: 0.4591, G loss: 2.1730\n",
      "[724/1762] D loss: 0.6833, G loss: 2.5311\n",
      "[804/1762] D loss: 0.3689, G loss: 0.9843\n",
      "[884/1762] D loss: 1.4407, G loss: 2.0988\n",
      "[964/1762] D loss: 1.7064, G loss: 1.6584\n",
      "[1044/1762] D loss: 0.7854, G loss: 0.9837\n",
      "[1124/1762] D loss: 1.0819, G loss: 1.3380\n",
      "[1204/1762] D loss: 1.4301, G loss: 0.5185\n",
      "[1284/1762] D loss: 1.2398, G loss: 1.2098\n",
      "[1364/1762] D loss: 1.4596, G loss: 0.9523\n",
      "[1444/1762] D loss: 1.4115, G loss: 0.5996\n",
      "[1524/1762] D loss: 1.0958, G loss: 1.6730\n",
      "[1604/1762] D loss: 1.0966, G loss: 0.7482\n",
      "[1684/1762] D loss: 1.2072, G loss: 0.7445\n",
      "[1762/1762] D loss: 1.3103, G loss: 0.9444\n",
      "train error: \n",
      " D loss: 1.306366, G loss: 1.096631, D accuracy: 58.5%, cell accuracy: 99.8%, board accuracy: 81.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.300315, G loss: 1.131642, D accuracy: 58.6%, cell accuracy: 99.7%, board accuracy: 79.3% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3433, G loss: 1.0804\n",
      "[84/1762] D loss: 1.1450, G loss: 1.1717\n",
      "[164/1762] D loss: 1.1564, G loss: 1.1392\n",
      "[244/1762] D loss: 1.3876, G loss: 0.7399\n",
      "[324/1762] D loss: 1.2735, G loss: 0.8861\n",
      "[404/1762] D loss: 1.4370, G loss: 0.6098\n",
      "[484/1762] D loss: 1.4386, G loss: 0.7219\n",
      "[564/1762] D loss: 1.3603, G loss: 0.7246\n",
      "[644/1762] D loss: 1.1248, G loss: 0.9922\n",
      "[724/1762] D loss: 0.9266, G loss: 0.9781\n",
      "[804/1762] D loss: 1.4210, G loss: 0.9008\n",
      "[884/1762] D loss: 1.3600, G loss: 1.1804\n",
      "[964/1762] D loss: 1.4076, G loss: 0.8065\n",
      "[1044/1762] D loss: 1.2493, G loss: 0.9319\n",
      "[1124/1762] D loss: 1.2864, G loss: 1.1540\n",
      "[1204/1762] D loss: 0.9786, G loss: 1.2115\n",
      "[1284/1762] D loss: 1.3690, G loss: 0.6639\n",
      "[1364/1762] D loss: 1.1232, G loss: 0.8779\n",
      "[1444/1762] D loss: 1.3942, G loss: 0.6680\n",
      "[1524/1762] D loss: 1.3322, G loss: 0.8595\n",
      "[1604/1762] D loss: 1.3596, G loss: 0.7046\n",
      "[1684/1762] D loss: 1.0230, G loss: 0.9685\n",
      "[1762/1762] D loss: 0.6577, G loss: 1.1955\n",
      "train error: \n",
      " D loss: 1.333025, G loss: 0.601944, D accuracy: 60.4%, cell accuracy: 99.5%, board accuracy: 43.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.310648, G loss: 0.631570, D accuracy: 60.5%, cell accuracy: 99.4%, board accuracy: 46.4% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3078, G loss: 0.6778\n",
      "[84/1762] D loss: 1.3741, G loss: 0.7335\n",
      "[164/1762] D loss: 1.0065, G loss: 1.1090\n",
      "[244/1762] D loss: 1.6759, G loss: 1.1101\n",
      "[324/1762] D loss: 1.4975, G loss: 0.8694\n",
      "[404/1762] D loss: 1.2339, G loss: 1.0153\n",
      "[484/1762] D loss: 2.1860, G loss: 0.2525\n",
      "[564/1762] D loss: 1.4038, G loss: 0.9462\n",
      "[644/1762] D loss: 1.2793, G loss: 1.0097\n",
      "[724/1762] D loss: 1.3819, G loss: 0.7011\n",
      "[804/1762] D loss: 1.1936, G loss: 0.7339\n",
      "[884/1762] D loss: 1.2016, G loss: 1.0448\n",
      "[964/1762] D loss: 1.4063, G loss: 0.6167\n",
      "[1044/1762] D loss: 1.4467, G loss: 0.7579\n",
      "[1124/1762] D loss: 1.6934, G loss: 0.5309\n",
      "[1204/1762] D loss: 1.4344, G loss: 0.5797\n",
      "[1284/1762] D loss: 1.2208, G loss: 1.1853\n",
      "[1364/1762] D loss: 1.3977, G loss: 0.8082\n",
      "[1444/1762] D loss: 1.3195, G loss: 0.6944\n",
      "[1524/1762] D loss: 1.1633, G loss: 0.9866\n",
      "[1604/1762] D loss: 1.4323, G loss: 0.5171\n",
      "[1684/1762] D loss: 1.1108, G loss: 0.9383\n",
      "[1762/1762] D loss: 1.3974, G loss: 0.5769\n",
      "train error: \n",
      " D loss: 1.329742, G loss: 0.706306, D accuracy: 56.0%, cell accuracy: 99.8%, board accuracy: 88.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.320072, G loss: 0.720079, D accuracy: 56.7%, cell accuracy: 99.8%, board accuracy: 85.9% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3723, G loss: 0.6299\n",
      "[84/1762] D loss: 1.3877, G loss: 0.7717\n",
      "[164/1762] D loss: 1.0677, G loss: 1.0161\n",
      "[244/1762] D loss: 1.4004, G loss: 0.7933\n",
      "[324/1762] D loss: 1.4504, G loss: 0.9174\n",
      "[404/1762] D loss: 1.3871, G loss: 0.7248\n",
      "[484/1762] D loss: 1.3869, G loss: 0.8176\n",
      "[564/1762] D loss: 0.9037, G loss: 1.2520\n",
      "[644/1762] D loss: 1.7184, G loss: 0.6519\n",
      "[724/1762] D loss: 1.3853, G loss: 0.8636\n",
      "[804/1762] D loss: 1.4013, G loss: 0.5507\n",
      "[884/1762] D loss: 1.3940, G loss: 0.7849\n",
      "[964/1762] D loss: 1.3816, G loss: 0.7315\n",
      "[1044/1762] D loss: 1.3908, G loss: 0.5983\n",
      "[1124/1762] D loss: 1.4171, G loss: 0.8307\n",
      "[1204/1762] D loss: 1.3850, G loss: 0.7072\n",
      "[1284/1762] D loss: 1.2714, G loss: 1.0140\n",
      "[1364/1762] D loss: 0.9798, G loss: 0.8268\n",
      "[1444/1762] D loss: 1.3848, G loss: 0.6483\n",
      "[1524/1762] D loss: 1.3961, G loss: 0.8301\n",
      "[1604/1762] D loss: 1.3877, G loss: 0.7106\n",
      "[1684/1762] D loss: 0.9170, G loss: 0.7088\n",
      "[1762/1762] D loss: 1.2371, G loss: 1.0304\n",
      "train error: \n",
      " D loss: 1.242653, G loss: 0.718627, D accuracy: 65.1%, cell accuracy: 99.4%, board accuracy: 49.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.216588, G loss: 0.731016, D accuracy: 66.2%, cell accuracy: 99.3%, board accuracy: 45.7% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8619, G loss: 0.9136\n",
      "[84/1762] D loss: 1.4184, G loss: 0.6371\n",
      "[164/1762] D loss: 1.4226, G loss: 0.8094\n",
      "[244/1762] D loss: 0.9989, G loss: 0.8538\n",
      "[324/1762] D loss: 1.3938, G loss: 0.5316\n",
      "[404/1762] D loss: 1.3793, G loss: 0.6019\n",
      "[484/1762] D loss: 1.4960, G loss: 0.9496\n",
      "[564/1762] D loss: 0.8276, G loss: 0.9654\n",
      "[644/1762] D loss: 2.3590, G loss: 1.1970\n",
      "[724/1762] D loss: 1.5454, G loss: 0.5541\n",
      "[804/1762] D loss: 1.4606, G loss: 0.8700\n",
      "[884/1762] D loss: 1.4241, G loss: 0.7753\n",
      "[964/1762] D loss: 1.3764, G loss: 0.6963\n",
      "[1044/1762] D loss: 1.3949, G loss: 0.7469\n",
      "[1124/1762] D loss: 1.3912, G loss: 0.8536\n",
      "[1204/1762] D loss: 1.3895, G loss: 0.6878\n",
      "[1284/1762] D loss: 1.4030, G loss: 0.7632\n",
      "[1364/1762] D loss: 1.4121, G loss: 0.7676\n",
      "[1444/1762] D loss: 0.6930, G loss: 1.2187\n",
      "[1524/1762] D loss: 1.4167, G loss: 0.7838\n",
      "[1604/1762] D loss: 0.7801, G loss: 0.9876\n",
      "[1684/1762] D loss: 0.6913, G loss: 1.1355\n",
      "[1762/1762] D loss: 1.4808, G loss: 0.8696\n",
      "train error: \n",
      " D loss: 1.306104, G loss: 0.807719, D accuracy: 55.7%, cell accuracy: 99.8%, board accuracy: 85.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.284995, G loss: 0.822404, D accuracy: 57.6%, cell accuracy: 99.8%, board accuracy: 83.2% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3944, G loss: 0.6789\n",
      "[84/1762] D loss: 1.4016, G loss: 0.6740\n",
      "[164/1762] D loss: 1.3889, G loss: 0.6994\n",
      "[244/1762] D loss: 1.3866, G loss: 0.7088\n",
      "[324/1762] D loss: 1.3969, G loss: 0.7109\n",
      "[404/1762] D loss: 1.3836, G loss: 0.6551\n",
      "[484/1762] D loss: 1.3885, G loss: 0.6988\n",
      "[564/1762] D loss: 1.3879, G loss: 0.6781\n",
      "[644/1762] D loss: 1.3903, G loss: 0.7021\n",
      "[724/1762] D loss: 1.3822, G loss: 0.7246\n",
      "[804/1762] D loss: 1.3888, G loss: 0.6987\n",
      "[884/1762] D loss: 1.3870, G loss: 0.7327\n",
      "[964/1762] D loss: 1.3867, G loss: 0.6763\n",
      "[1044/1762] D loss: 1.3888, G loss: 0.7250\n",
      "[1124/1762] D loss: 1.3881, G loss: 0.6747\n",
      "[1204/1762] D loss: 1.3872, G loss: 0.6814\n",
      "[1284/1762] D loss: 1.3870, G loss: 0.6850\n",
      "[1364/1762] D loss: 1.3880, G loss: 0.6970\n",
      "[1444/1762] D loss: 1.3897, G loss: 0.6785\n",
      "[1524/1762] D loss: 1.3900, G loss: 0.7236\n",
      "[1604/1762] D loss: 1.3932, G loss: 0.6498\n",
      "[1684/1762] D loss: 1.3875, G loss: 0.7048\n",
      "[1762/1762] D loss: 1.3879, G loss: 0.7038\n",
      "train error: \n",
      " D loss: 1.386312, G loss: 0.693796, D accuracy: 51.1%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.385591, G loss: 0.697943, D accuracy: 51.2%, cell accuracy: 99.8%, board accuracy: 82.0% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3870, G loss: 0.7036\n",
      "[84/1762] D loss: 1.3883, G loss: 0.7058\n",
      "[164/1762] D loss: 1.3890, G loss: 0.6799\n",
      "[244/1762] D loss: 1.3774, G loss: 0.7158\n",
      "[324/1762] D loss: 1.3922, G loss: 0.6714\n",
      "[404/1762] D loss: 1.3870, G loss: 0.6970\n",
      "[484/1762] D loss: 1.3869, G loss: 0.6929\n",
      "[564/1762] D loss: 1.3703, G loss: 0.7182\n",
      "[644/1762] D loss: 1.3884, G loss: 0.6752\n",
      "[724/1762] D loss: 1.3881, G loss: 0.6941\n",
      "[804/1762] D loss: 1.3875, G loss: 0.7266\n",
      "[884/1762] D loss: 1.3862, G loss: 0.7246\n",
      "[964/1762] D loss: 1.3881, G loss: 0.7142\n",
      "[1044/1762] D loss: 1.3891, G loss: 0.6913\n",
      "[1124/1762] D loss: 1.3878, G loss: 0.7250\n",
      "[1204/1762] D loss: 1.3874, G loss: 0.6721\n",
      "[1284/1762] D loss: 1.3907, G loss: 0.6755\n",
      "[1364/1762] D loss: 1.3879, G loss: 0.6600\n",
      "[1444/1762] D loss: 1.3857, G loss: 0.6960\n",
      "[1524/1762] D loss: 1.3754, G loss: 0.7179\n",
      "[1604/1762] D loss: 1.3872, G loss: 0.6713\n",
      "[1684/1762] D loss: 1.3894, G loss: 0.7050\n",
      "[1762/1762] D loss: 1.3908, G loss: 0.6897\n",
      "train error: \n",
      " D loss: 1.384684, G loss: 0.704080, D accuracy: 51.8%, cell accuracy: 99.8%, board accuracy: 85.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.383597, G loss: 0.707827, D accuracy: 52.0%, cell accuracy: 99.8%, board accuracy: 80.5% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3857, G loss: 0.7286\n",
      "[84/1762] D loss: 1.3868, G loss: 0.7113\n",
      "[164/1762] D loss: 1.3865, G loss: 0.6919\n",
      "[244/1762] D loss: 1.3871, G loss: 0.7033\n",
      "[324/1762] D loss: 1.3873, G loss: 0.7085\n",
      "[404/1762] D loss: 1.3745, G loss: 0.6936\n",
      "[484/1762] D loss: 1.3872, G loss: 0.6866\n",
      "[564/1762] D loss: 1.3698, G loss: 0.7072\n",
      "[644/1762] D loss: 1.3874, G loss: 0.7005\n",
      "[724/1762] D loss: 1.3866, G loss: 0.6782\n",
      "[804/1762] D loss: 1.3870, G loss: 0.6840\n",
      "[884/1762] D loss: 1.3860, G loss: 0.6577\n",
      "[964/1762] D loss: 1.3702, G loss: 0.6860\n",
      "[1044/1762] D loss: 1.3983, G loss: 0.7141\n",
      "[1124/1762] D loss: 1.3871, G loss: 0.6686\n",
      "[1204/1762] D loss: 1.3907, G loss: 0.7245\n",
      "[1284/1762] D loss: 1.3670, G loss: 0.7109\n",
      "[1364/1762] D loss: 1.3716, G loss: 0.7003\n",
      "[1444/1762] D loss: 1.3869, G loss: 0.7165\n",
      "[1524/1762] D loss: 1.3878, G loss: 0.6966\n",
      "[1604/1762] D loss: 1.3905, G loss: 0.6801\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.7040\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6851\n",
      "train error: \n",
      " D loss: 1.382945, G loss: 0.694101, D accuracy: 52.8%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.381929, G loss: 0.697871, D accuracy: 53.0%, cell accuracy: 99.8%, board accuracy: 81.6% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3842, G loss: 0.7145\n",
      "[84/1762] D loss: 1.3879, G loss: 0.7029\n",
      "[164/1762] D loss: 1.3675, G loss: 0.7077\n",
      "[244/1762] D loss: 1.3874, G loss: 0.7240\n",
      "[324/1762] D loss: 1.3878, G loss: 0.6803\n",
      "[404/1762] D loss: 1.3724, G loss: 0.7566\n",
      "[484/1762] D loss: 1.3624, G loss: 0.7216\n",
      "[564/1762] D loss: 1.3872, G loss: 0.7203\n",
      "[644/1762] D loss: 1.3684, G loss: 0.7126\n",
      "[724/1762] D loss: 1.3883, G loss: 0.6930\n",
      "[804/1762] D loss: 1.3824, G loss: 0.7128\n",
      "[884/1762] D loss: 1.3765, G loss: 0.6971\n",
      "[964/1762] D loss: 1.3856, G loss: 0.6945\n",
      "[1044/1762] D loss: 1.3461, G loss: 0.7549\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.6931\n",
      "[1204/1762] D loss: 1.3645, G loss: 0.6965\n",
      "[1284/1762] D loss: 1.3886, G loss: 0.6704\n",
      "[1364/1762] D loss: 1.3881, G loss: 0.7009\n",
      "[1444/1762] D loss: 1.3877, G loss: 0.7066\n",
      "[1524/1762] D loss: 1.3869, G loss: 0.6954\n",
      "[1604/1762] D loss: 1.3870, G loss: 0.6992\n",
      "[1684/1762] D loss: 1.3626, G loss: 0.7182\n",
      "[1762/1762] D loss: 1.3836, G loss: 0.7181\n",
      "train error: \n",
      " D loss: 1.381946, G loss: 0.707412, D accuracy: 53.0%, cell accuracy: 99.8%, board accuracy: 85.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.381030, G loss: 0.710294, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 80.2% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3904, G loss: 0.6843\n",
      "[84/1762] D loss: 1.3880, G loss: 0.6807\n",
      "[164/1762] D loss: 1.3878, G loss: 0.6853\n",
      "[244/1762] D loss: 1.3868, G loss: 0.6910\n",
      "[324/1762] D loss: 1.3869, G loss: 0.7101\n",
      "[404/1762] D loss: 1.3588, G loss: 0.6937\n",
      "[484/1762] D loss: 1.3873, G loss: 0.6791\n",
      "[564/1762] D loss: 1.3662, G loss: 0.7284\n",
      "[644/1762] D loss: 1.3882, G loss: 0.7035\n",
      "[724/1762] D loss: 1.3876, G loss: 0.6781\n",
      "[804/1762] D loss: 1.3732, G loss: 0.7291\n",
      "[884/1762] D loss: 1.3883, G loss: 0.7151\n",
      "[964/1762] D loss: 1.3866, G loss: 0.6845\n",
      "[1044/1762] D loss: 1.3862, G loss: 0.6891\n",
      "[1124/1762] D loss: 1.3881, G loss: 0.7049\n",
      "[1204/1762] D loss: 1.3870, G loss: 0.7038\n",
      "[1284/1762] D loss: 1.3909, G loss: 0.7356\n",
      "[1364/1762] D loss: 1.3870, G loss: 0.7044\n",
      "[1444/1762] D loss: 1.3590, G loss: 0.7020\n",
      "[1524/1762] D loss: 1.3861, G loss: 0.7118\n",
      "[1604/1762] D loss: 1.3871, G loss: 0.7065\n",
      "[1684/1762] D loss: 1.3879, G loss: 0.7298\n",
      "[1762/1762] D loss: 1.3874, G loss: 0.6607\n",
      "train error: \n",
      " D loss: 1.380211, G loss: 0.697072, D accuracy: 53.0%, cell accuracy: 99.8%, board accuracy: 84.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.378477, G loss: 0.701055, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 82.0% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3885, G loss: 0.6965\n",
      "[84/1762] D loss: 1.3866, G loss: 0.7004\n",
      "[164/1762] D loss: 1.3574, G loss: 0.7214\n",
      "[244/1762] D loss: 1.3857, G loss: 0.6959\n",
      "[324/1762] D loss: 1.3877, G loss: 0.6985\n",
      "[404/1762] D loss: 1.3527, G loss: 0.7137\n",
      "[484/1762] D loss: 1.3821, G loss: 0.7050\n",
      "[564/1762] D loss: 1.3879, G loss: 0.7147\n",
      "[644/1762] D loss: 1.3869, G loss: 0.7303\n",
      "[724/1762] D loss: 1.3869, G loss: 0.6941\n",
      "[804/1762] D loss: 1.3841, G loss: 0.7156\n",
      "[884/1762] D loss: 1.3873, G loss: 0.7037\n",
      "[964/1762] D loss: 1.3872, G loss: 0.6891\n",
      "[1044/1762] D loss: 1.3866, G loss: 0.7082\n",
      "[1124/1762] D loss: 1.3510, G loss: 0.7352\n",
      "[1204/1762] D loss: 1.3875, G loss: 0.6809\n",
      "[1284/1762] D loss: 1.3489, G loss: 0.6718\n",
      "[1364/1762] D loss: 1.3899, G loss: 0.6585\n",
      "[1444/1762] D loss: 1.3887, G loss: 0.6960\n",
      "[1524/1762] D loss: 1.3915, G loss: 0.7108\n",
      "[1604/1762] D loss: 1.3871, G loss: 0.6783\n",
      "[1684/1762] D loss: 1.3868, G loss: 0.7092\n",
      "[1762/1762] D loss: 1.3905, G loss: 0.6643\n",
      "train error: \n",
      " D loss: 1.378783, G loss: 0.698237, D accuracy: 53.1%, cell accuracy: 99.8%, board accuracy: 84.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.376789, G loss: 0.701455, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 80.5% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3878, G loss: 0.7070\n",
      "[84/1762] D loss: 1.3869, G loss: 0.6904\n",
      "[164/1762] D loss: 1.3868, G loss: 0.7056\n",
      "[244/1762] D loss: 1.3840, G loss: 0.7059\n",
      "[324/1762] D loss: 1.3880, G loss: 0.6825\n",
      "[404/1762] D loss: 1.3475, G loss: 0.7293\n",
      "[484/1762] D loss: 1.3869, G loss: 0.7180\n",
      "[564/1762] D loss: 1.3859, G loss: 0.6993\n",
      "[644/1762] D loss: 1.3865, G loss: 0.7113\n",
      "[724/1762] D loss: 1.3873, G loss: 0.6716\n",
      "[804/1762] D loss: 1.3871, G loss: 0.7122\n",
      "[884/1762] D loss: 1.3868, G loss: 0.6992\n",
      "[964/1762] D loss: 1.3849, G loss: 0.6980\n",
      "[1044/1762] D loss: 1.3885, G loss: 0.6586\n",
      "[1124/1762] D loss: 1.3889, G loss: 0.6756\n",
      "[1204/1762] D loss: 1.3355, G loss: 0.6932\n",
      "[1284/1762] D loss: 1.3880, G loss: 0.6950\n",
      "[1364/1762] D loss: 1.3913, G loss: 0.6769\n",
      "[1444/1762] D loss: 1.3875, G loss: 0.6853\n",
      "[1524/1762] D loss: 1.3871, G loss: 0.6751\n",
      "[1604/1762] D loss: 1.3872, G loss: 0.6909\n",
      "[1684/1762] D loss: 1.3866, G loss: 0.6953\n",
      "[1762/1762] D loss: 1.3873, G loss: 0.7258\n",
      "train error: \n",
      " D loss: 1.377371, G loss: 0.704253, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 84.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.374566, G loss: 0.707592, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 82.5% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3922, G loss: 0.7162\n",
      "[84/1762] D loss: 1.3870, G loss: 0.6872\n",
      "[164/1762] D loss: 1.3871, G loss: 0.6958\n",
      "[244/1762] D loss: 1.3886, G loss: 0.6698\n",
      "[324/1762] D loss: 1.3429, G loss: 0.7381\n",
      "[404/1762] D loss: 1.3597, G loss: 0.7013\n",
      "[484/1762] D loss: 1.3871, G loss: 0.7052\n",
      "[564/1762] D loss: 1.3905, G loss: 0.6371\n",
      "[644/1762] D loss: 1.3828, G loss: 0.7141\n",
      "[724/1762] D loss: 1.3880, G loss: 0.7003\n",
      "[804/1762] D loss: 1.3877, G loss: 0.7199\n",
      "[884/1762] D loss: 1.3836, G loss: 0.6933\n",
      "[964/1762] D loss: 1.3868, G loss: 0.7128\n",
      "[1044/1762] D loss: 1.3377, G loss: 0.7440\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.6906\n",
      "[1204/1762] D loss: 1.3850, G loss: 0.7083\n",
      "[1284/1762] D loss: 1.3330, G loss: 0.7455\n",
      "[1364/1762] D loss: 1.3889, G loss: 0.7369\n",
      "[1444/1762] D loss: 1.3871, G loss: 0.7052\n",
      "[1524/1762] D loss: 1.3874, G loss: 0.6825\n",
      "[1604/1762] D loss: 1.3895, G loss: 0.7015\n",
      "[1684/1762] D loss: 1.3892, G loss: 0.6902\n",
      "[1762/1762] D loss: 1.3897, G loss: 0.6377\n",
      "train error: \n",
      " D loss: 1.374018, G loss: 0.701708, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 85.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.370871, G loss: 0.705036, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 82.0% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3870, G loss: 0.6972\n",
      "[84/1762] D loss: 1.3873, G loss: 0.6734\n",
      "[164/1762] D loss: 1.3861, G loss: 0.7135\n",
      "[244/1762] D loss: 1.3874, G loss: 0.7209\n",
      "[324/1762] D loss: 1.3725, G loss: 0.7235\n",
      "[404/1762] D loss: 1.3530, G loss: 0.7255\n",
      "[484/1762] D loss: 1.3864, G loss: 0.7151\n",
      "[564/1762] D loss: 1.2698, G loss: 0.7139\n",
      "[644/1762] D loss: 1.3824, G loss: 0.7667\n",
      "[724/1762] D loss: 1.3894, G loss: 0.6564\n",
      "[804/1762] D loss: 1.3865, G loss: 0.6987\n",
      "[884/1762] D loss: 1.3883, G loss: 0.6863\n",
      "[964/1762] D loss: 1.3868, G loss: 0.7105\n",
      "[1044/1762] D loss: 1.3886, G loss: 0.7072\n",
      "[1124/1762] D loss: 1.3848, G loss: 0.7145\n",
      "[1204/1762] D loss: 1.3507, G loss: 0.6920\n",
      "[1284/1762] D loss: 1.3877, G loss: 0.7284\n",
      "[1364/1762] D loss: 1.3877, G loss: 0.7271\n",
      "[1444/1762] D loss: 1.3872, G loss: 0.7127\n",
      "[1524/1762] D loss: 1.3892, G loss: 0.7057\n",
      "[1604/1762] D loss: 1.3296, G loss: 0.7372\n",
      "[1684/1762] D loss: 1.3881, G loss: 0.7295\n",
      "[1762/1762] D loss: 1.3909, G loss: 0.6398\n",
      "train error: \n",
      " D loss: 1.372514, G loss: 0.704008, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 86.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.368707, G loss: 0.707921, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 82.3% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3831, G loss: 0.6722\n",
      "[84/1762] D loss: 1.3874, G loss: 0.6803\n",
      "[164/1762] D loss: 1.3871, G loss: 0.6791\n",
      "[244/1762] D loss: 1.3759, G loss: 0.7153\n",
      "[324/1762] D loss: 1.3899, G loss: 0.6815\n",
      "[404/1762] D loss: 1.3899, G loss: 0.6939\n",
      "[484/1762] D loss: 1.3849, G loss: 0.7183\n",
      "[564/1762] D loss: 1.3901, G loss: 0.6902\n",
      "[644/1762] D loss: 1.3873, G loss: 0.6773\n",
      "[724/1762] D loss: 1.3867, G loss: 0.7090\n",
      "[804/1762] D loss: 1.3163, G loss: 0.7072\n",
      "[884/1762] D loss: 1.3283, G loss: 0.7048\n",
      "[964/1762] D loss: 1.2945, G loss: 0.7179\n",
      "[1044/1762] D loss: 1.3841, G loss: 0.7481\n",
      "[1124/1762] D loss: 1.3867, G loss: 0.6964\n",
      "[1204/1762] D loss: 1.3812, G loss: 0.6794\n",
      "[1284/1762] D loss: 1.3904, G loss: 0.6720\n",
      "[1364/1762] D loss: 1.3876, G loss: 0.7098\n",
      "[1444/1762] D loss: 1.3851, G loss: 0.6877\n",
      "[1524/1762] D loss: 1.3880, G loss: 0.7262\n",
      "[1604/1762] D loss: 1.3855, G loss: 0.6917\n",
      "[1684/1762] D loss: 1.3900, G loss: 0.7007\n",
      "[1762/1762] D loss: 1.3872, G loss: 0.6756\n",
      "train error: \n",
      " D loss: 1.369291, G loss: 0.700758, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 85.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.364914, G loss: 0.705090, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 80.5% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3868, G loss: 0.6902\n",
      "[84/1762] D loss: 1.3076, G loss: 0.7256\n",
      "[164/1762] D loss: 1.3873, G loss: 0.7105\n",
      "[244/1762] D loss: 1.3883, G loss: 0.7339\n",
      "[324/1762] D loss: 1.3037, G loss: 0.7227\n",
      "[404/1762] D loss: 1.3872, G loss: 0.7161\n",
      "[484/1762] D loss: 1.3920, G loss: 0.6990\n",
      "[564/1762] D loss: 1.3871, G loss: 0.7039\n",
      "[644/1762] D loss: 1.3859, G loss: 0.7278\n",
      "[724/1762] D loss: 1.3874, G loss: 0.6860\n",
      "[804/1762] D loss: 1.3806, G loss: 0.7037\n",
      "[884/1762] D loss: 1.3214, G loss: 0.7319\n",
      "[964/1762] D loss: 1.3857, G loss: 0.7218\n",
      "[1044/1762] D loss: 1.3867, G loss: 0.6926\n",
      "[1124/1762] D loss: 1.3872, G loss: 0.7162\n",
      "[1204/1762] D loss: 1.3870, G loss: 0.7061\n",
      "[1284/1762] D loss: 1.2195, G loss: 0.7852\n",
      "[1364/1762] D loss: 1.3869, G loss: 0.7102\n",
      "[1444/1762] D loss: 1.3870, G loss: 0.7025\n",
      "[1524/1762] D loss: 1.3882, G loss: 0.6964\n",
      "[1604/1762] D loss: 1.3873, G loss: 0.6725\n",
      "[1684/1762] D loss: 1.2990, G loss: 0.7326\n",
      "[1762/1762] D loss: 1.3890, G loss: 0.6918\n",
      "train error: \n",
      " D loss: 1.366183, G loss: 0.710034, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 84.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.361337, G loss: 0.714526, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 82.7% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3077, G loss: 0.7064\n",
      "[84/1762] D loss: 1.3878, G loss: 0.7203\n",
      "[164/1762] D loss: 1.3916, G loss: 0.7581\n",
      "[244/1762] D loss: 1.3857, G loss: 0.7226\n",
      "[324/1762] D loss: 1.3894, G loss: 0.7213\n",
      "[404/1762] D loss: 1.3874, G loss: 0.7103\n",
      "[484/1762] D loss: 1.3436, G loss: 0.7189\n",
      "[564/1762] D loss: 1.3811, G loss: 0.6970\n",
      "[644/1762] D loss: 1.3017, G loss: 0.7281\n",
      "[724/1762] D loss: 1.3931, G loss: 0.6602\n",
      "[804/1762] D loss: 1.3826, G loss: 0.7225\n",
      "[884/1762] D loss: 1.3871, G loss: 0.7007\n",
      "[964/1762] D loss: 1.3914, G loss: 0.6704\n",
      "[1044/1762] D loss: 1.3812, G loss: 0.7008\n",
      "[1124/1762] D loss: 1.3868, G loss: 0.7053\n",
      "[1204/1762] D loss: 1.3971, G loss: 0.7210\n",
      "[1284/1762] D loss: 1.2593, G loss: 0.7198\n",
      "[1364/1762] D loss: 1.2976, G loss: 0.7426\n",
      "[1444/1762] D loss: 1.2918, G loss: 0.7382\n",
      "[1524/1762] D loss: 1.3873, G loss: 0.6807\n",
      "[1604/1762] D loss: 1.2923, G loss: 0.7612\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.6700\n",
      "[1762/1762] D loss: 1.1969, G loss: 0.7613\n",
      "train error: \n",
      " D loss: 1.363726, G loss: 0.716290, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 84.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.357918, G loss: 0.721400, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 82.5% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3808, G loss: 0.7105\n",
      "[84/1762] D loss: 1.3888, G loss: 0.6745\n",
      "[164/1762] D loss: 1.3873, G loss: 0.6937\n",
      "[244/1762] D loss: 1.3871, G loss: 0.6877\n",
      "[324/1762] D loss: 1.3884, G loss: 0.7508\n",
      "[404/1762] D loss: 1.3862, G loss: 0.7127\n",
      "[484/1762] D loss: 1.3033, G loss: 0.7317\n",
      "[564/1762] D loss: 1.3885, G loss: 0.6970\n",
      "[644/1762] D loss: 1.2915, G loss: 0.6995\n",
      "[724/1762] D loss: 1.2931, G loss: 0.7198\n",
      "[804/1762] D loss: 1.2768, G loss: 0.7130\n",
      "[884/1762] D loss: 1.3866, G loss: 0.6980\n",
      "[964/1762] D loss: 1.3920, G loss: 0.6825\n",
      "[1044/1762] D loss: 1.2864, G loss: 0.7693\n",
      "[1124/1762] D loss: 1.2969, G loss: 0.7134\n",
      "[1204/1762] D loss: 1.3910, G loss: 0.7526\n",
      "[1284/1762] D loss: 1.2872, G loss: 0.7111\n",
      "[1364/1762] D loss: 1.3884, G loss: 0.6606\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.6812\n",
      "[1524/1762] D loss: 1.3877, G loss: 0.6802\n",
      "[1604/1762] D loss: 1.3915, G loss: 0.7167\n",
      "[1684/1762] D loss: 1.3892, G loss: 0.7260\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.7022\n",
      "train error: \n",
      " D loss: 1.360759, G loss: 0.703006, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 86.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.354451, G loss: 0.708299, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 84.3% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3877, G loss: 0.7131\n",
      "[84/1762] D loss: 1.2633, G loss: 0.7631\n",
      "[164/1762] D loss: 1.3128, G loss: 0.7390\n",
      "[244/1762] D loss: 1.3923, G loss: 0.7262\n",
      "[324/1762] D loss: 1.3872, G loss: 0.6857\n",
      "[404/1762] D loss: 1.3875, G loss: 0.6859\n",
      "[484/1762] D loss: 1.2606, G loss: 0.7372\n",
      "[564/1762] D loss: 1.3014, G loss: 0.6912\n",
      "[644/1762] D loss: 1.3864, G loss: 0.7294\n",
      "[724/1762] D loss: 1.4002, G loss: 0.7145\n",
      "[804/1762] D loss: 1.3737, G loss: 0.7294\n",
      "[884/1762] D loss: 1.3897, G loss: 0.6695\n",
      "[964/1762] D loss: 1.3875, G loss: 0.7225\n",
      "[1044/1762] D loss: 1.2782, G loss: 0.7084\n",
      "[1124/1762] D loss: 1.3919, G loss: 0.6912\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6885\n",
      "[1284/1762] D loss: 1.2710, G loss: 0.7553\n",
      "[1364/1762] D loss: 1.3939, G loss: 0.7755\n",
      "[1444/1762] D loss: 1.3748, G loss: 0.7519\n",
      "[1524/1762] D loss: 1.2662, G loss: 0.7062\n",
      "[1604/1762] D loss: 1.3869, G loss: 0.6913\n",
      "[1684/1762] D loss: 1.3865, G loss: 0.6893\n",
      "[1762/1762] D loss: 1.3873, G loss: 0.6590\n",
      "train error: \n",
      " D loss: 1.358105, G loss: 0.715961, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 84.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.351402, G loss: 0.721715, D accuracy: 55.0%, cell accuracy: 99.7%, board accuracy: 78.9% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2811, G loss: 0.7587\n",
      "[84/1762] D loss: 1.3891, G loss: 0.6765\n",
      "[164/1762] D loss: 1.2675, G loss: 0.7040\n",
      "[244/1762] D loss: 1.4053, G loss: 0.7075\n",
      "[324/1762] D loss: 1.1433, G loss: 0.7814\n",
      "[404/1762] D loss: 1.3814, G loss: 0.6817\n",
      "[484/1762] D loss: 1.3920, G loss: 0.6990\n",
      "[564/1762] D loss: 1.3900, G loss: 0.6615\n",
      "[644/1762] D loss: 1.2626, G loss: 0.7443\n",
      "[724/1762] D loss: 1.3615, G loss: 0.7459\n",
      "[804/1762] D loss: 1.3886, G loss: 0.7037\n",
      "[884/1762] D loss: 1.3906, G loss: 0.6905\n",
      "[964/1762] D loss: 1.4089, G loss: 0.7187\n",
      "[1044/1762] D loss: 1.1374, G loss: 0.7943\n",
      "[1124/1762] D loss: 1.2681, G loss: 0.7629\n",
      "[1204/1762] D loss: 1.3928, G loss: 0.7484\n",
      "[1284/1762] D loss: 1.3882, G loss: 0.7302\n",
      "[1364/1762] D loss: 1.2410, G loss: 0.7924\n",
      "[1444/1762] D loss: 1.3873, G loss: 0.6926\n",
      "[1524/1762] D loss: 1.3916, G loss: 0.7374\n",
      "[1604/1762] D loss: 1.3845, G loss: 0.6973\n",
      "[1684/1762] D loss: 1.2824, G loss: 0.7275\n",
      "[1762/1762] D loss: 1.3902, G loss: 0.7117\n",
      "train error: \n",
      " D loss: 1.355120, G loss: 0.718962, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 86.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.346582, G loss: 0.726428, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 81.8% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3976, G loss: 0.7169\n",
      "[84/1762] D loss: 1.3857, G loss: 0.6863\n",
      "[164/1762] D loss: 1.2479, G loss: 0.7480\n",
      "[244/1762] D loss: 1.3770, G loss: 0.7206\n",
      "[324/1762] D loss: 1.3813, G loss: 0.7105\n",
      "[404/1762] D loss: 1.3911, G loss: 0.7116\n",
      "[484/1762] D loss: 1.3877, G loss: 0.6678\n",
      "[564/1762] D loss: 1.2535, G loss: 0.7842\n",
      "[644/1762] D loss: 1.3879, G loss: 0.6646\n",
      "[724/1762] D loss: 1.3926, G loss: 0.6706\n",
      "[804/1762] D loss: 1.2520, G loss: 0.7370\n",
      "[884/1762] D loss: 1.3869, G loss: 0.7140\n",
      "[964/1762] D loss: 1.2701, G loss: 0.7408\n",
      "[1044/1762] D loss: 1.3865, G loss: 0.7088\n",
      "[1124/1762] D loss: 1.2983, G loss: 0.7085\n",
      "[1204/1762] D loss: 1.3934, G loss: 0.7261\n",
      "[1284/1762] D loss: 1.3743, G loss: 0.8089\n",
      "[1364/1762] D loss: 1.3911, G loss: 0.6976\n",
      "[1444/1762] D loss: 1.2393, G loss: 0.7340\n",
      "[1524/1762] D loss: 1.3869, G loss: 0.7148\n",
      "[1604/1762] D loss: 1.3869, G loss: 0.7120\n",
      "[1684/1762] D loss: 1.3889, G loss: 0.7254\n",
      "[1762/1762] D loss: 1.3936, G loss: 0.6381\n",
      "train error: \n",
      " D loss: 1.353000, G loss: 0.707651, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 85.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.344993, G loss: 0.714705, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 82.0% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3861, G loss: 0.7172\n",
      "[84/1762] D loss: 1.3870, G loss: 0.7139\n",
      "[164/1762] D loss: 1.3985, G loss: 0.7214\n",
      "[244/1762] D loss: 1.3895, G loss: 0.7225\n",
      "[324/1762] D loss: 1.3882, G loss: 0.7373\n",
      "[404/1762] D loss: 1.3876, G loss: 0.7108\n",
      "[484/1762] D loss: 1.3776, G loss: 0.6739\n",
      "[564/1762] D loss: 1.3794, G loss: 0.7167\n",
      "[644/1762] D loss: 1.3877, G loss: 0.7128\n",
      "[724/1762] D loss: 1.3869, G loss: 0.7277\n",
      "[804/1762] D loss: 1.4015, G loss: 0.7341\n",
      "[884/1762] D loss: 1.3849, G loss: 0.7089\n",
      "[964/1762] D loss: 1.3896, G loss: 0.7424\n",
      "[1044/1762] D loss: 1.2345, G loss: 0.7753\n",
      "[1124/1762] D loss: 1.2688, G loss: 0.7438\n",
      "[1204/1762] D loss: 1.3901, G loss: 0.7359\n",
      "[1284/1762] D loss: 1.3830, G loss: 0.7667\n",
      "[1364/1762] D loss: 1.3897, G loss: 0.6957\n",
      "[1444/1762] D loss: 1.3947, G loss: 0.7795\n",
      "[1524/1762] D loss: 1.2464, G loss: 0.7052\n",
      "[1604/1762] D loss: 1.2409, G loss: 0.8301\n",
      "[1684/1762] D loss: 1.3931, G loss: 0.7202\n",
      "[1762/1762] D loss: 1.3862, G loss: 0.6838\n",
      "train error: \n",
      " D loss: 1.348659, G loss: 0.720691, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 85.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.339349, G loss: 0.728533, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 83.9% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3956, G loss: 0.7092\n",
      "[84/1762] D loss: 1.3771, G loss: 0.6833\n",
      "[164/1762] D loss: 1.3813, G loss: 0.7032\n",
      "[244/1762] D loss: 1.2475, G loss: 0.7342\n",
      "[324/1762] D loss: 1.3876, G loss: 0.7082\n",
      "[404/1762] D loss: 1.3893, G loss: 0.6895\n",
      "[484/1762] D loss: 1.3775, G loss: 0.7554\n",
      "[564/1762] D loss: 1.2249, G loss: 0.7948\n",
      "[644/1762] D loss: 1.3008, G loss: 0.7510\n",
      "[724/1762] D loss: 1.3893, G loss: 0.7201\n",
      "[804/1762] D loss: 1.3899, G loss: 0.7237\n",
      "[884/1762] D loss: 1.3952, G loss: 0.7006\n",
      "[964/1762] D loss: 1.3884, G loss: 0.7314\n",
      "[1044/1762] D loss: 1.0626, G loss: 0.8368\n",
      "[1124/1762] D loss: 1.3868, G loss: 0.6882\n",
      "[1204/1762] D loss: 1.3869, G loss: 0.6953\n",
      "[1284/1762] D loss: 1.3937, G loss: 0.6684\n",
      "[1364/1762] D loss: 1.3892, G loss: 0.7108\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6866\n",
      "[1524/1762] D loss: 1.3871, G loss: 0.6671\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.7088\n",
      "[1684/1762] D loss: 1.4171, G loss: 0.8222\n",
      "[1762/1762] D loss: 1.3892, G loss: 0.6546\n",
      "train error: \n",
      " D loss: 1.347032, G loss: 0.707136, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 84.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.338172, G loss: 0.714022, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 82.5% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3774, G loss: 0.7281\n",
      "[84/1762] D loss: 1.2121, G loss: 0.7718\n",
      "[164/1762] D loss: 1.2379, G loss: 0.7022\n",
      "[244/1762] D loss: 1.3668, G loss: 0.7193\n",
      "[324/1762] D loss: 1.3759, G loss: 0.7693\n",
      "[404/1762] D loss: 1.3941, G loss: 0.7561\n",
      "[484/1762] D loss: 1.3886, G loss: 0.7243\n",
      "[564/1762] D loss: 1.3906, G loss: 0.7375\n",
      "[644/1762] D loss: 1.3890, G loss: 0.7414\n",
      "[724/1762] D loss: 1.0465, G loss: 0.8147\n",
      "[804/1762] D loss: 1.2178, G loss: 0.7533\n",
      "[884/1762] D loss: 1.3890, G loss: 0.7442\n",
      "[964/1762] D loss: 1.3960, G loss: 0.7714\n",
      "[1044/1762] D loss: 1.3890, G loss: 0.6836\n",
      "[1124/1762] D loss: 1.3970, G loss: 0.7329\n",
      "[1204/1762] D loss: 1.1980, G loss: 0.7732\n",
      "[1284/1762] D loss: 1.3923, G loss: 0.7170\n",
      "[1364/1762] D loss: 1.3845, G loss: 0.7153\n",
      "[1444/1762] D loss: 1.3869, G loss: 0.7051\n",
      "[1524/1762] D loss: 1.3974, G loss: 0.6681\n",
      "[1604/1762] D loss: 1.3852, G loss: 0.7306\n",
      "[1684/1762] D loss: 1.3873, G loss: 0.6667\n",
      "[1762/1762] D loss: 1.0353, G loss: 0.8330\n",
      "train error: \n",
      " D loss: 1.344118, G loss: 0.723279, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 84.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.334535, G loss: 0.731369, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 82.5% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2000, G loss: 0.7688\n",
      "[84/1762] D loss: 1.3909, G loss: 0.6998\n",
      "[164/1762] D loss: 1.3894, G loss: 0.7138\n",
      "[244/1762] D loss: 1.3883, G loss: 0.7075\n",
      "[324/1762] D loss: 1.3958, G loss: 0.7872\n",
      "[404/1762] D loss: 1.3893, G loss: 0.7400\n",
      "[484/1762] D loss: 1.3926, G loss: 0.6503\n",
      "[564/1762] D loss: 1.3875, G loss: 0.6970\n",
      "[644/1762] D loss: 1.2016, G loss: 0.7783\n",
      "[724/1762] D loss: 1.3964, G loss: 0.7712\n",
      "[804/1762] D loss: 1.3939, G loss: 0.6643\n",
      "[884/1762] D loss: 1.2197, G loss: 0.7176\n",
      "[964/1762] D loss: 1.3844, G loss: 0.7273\n",
      "[1044/1762] D loss: 1.3920, G loss: 0.6935\n",
      "[1124/1762] D loss: 1.3891, G loss: 0.6848\n",
      "[1204/1762] D loss: 1.2543, G loss: 0.7373\n",
      "[1284/1762] D loss: 1.3945, G loss: 0.7455\n",
      "[1364/1762] D loss: 1.3907, G loss: 0.6954\n",
      "[1444/1762] D loss: 1.1949, G loss: 0.7992\n",
      "[1524/1762] D loss: 1.3933, G loss: 0.7088\n",
      "[1604/1762] D loss: 1.1997, G loss: 0.7694\n",
      "[1684/1762] D loss: 1.3776, G loss: 0.6921\n",
      "[1762/1762] D loss: 1.3886, G loss: 0.6905\n",
      "train error: \n",
      " D loss: 1.342950, G loss: 0.709036, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 83.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.333108, G loss: 0.716396, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 81.8% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3881, G loss: 0.7004\n",
      "[84/1762] D loss: 1.3933, G loss: 0.7669\n",
      "[164/1762] D loss: 1.3913, G loss: 0.7542\n",
      "[244/1762] D loss: 1.2285, G loss: 0.8118\n",
      "[324/1762] D loss: 1.3883, G loss: 0.7425\n",
      "[404/1762] D loss: 1.3829, G loss: 0.7030\n",
      "[484/1762] D loss: 1.1977, G loss: 0.8100\n",
      "[564/1762] D loss: 1.2138, G loss: 0.7485\n",
      "[644/1762] D loss: 1.2028, G loss: 0.7485\n",
      "[724/1762] D loss: 1.3699, G loss: 0.6928\n",
      "[804/1762] D loss: 1.2069, G loss: 0.7806\n",
      "[884/1762] D loss: 1.3890, G loss: 0.7188\n",
      "[964/1762] D loss: 1.3932, G loss: 0.7069\n",
      "[1044/1762] D loss: 1.3873, G loss: 0.7175\n",
      "[1124/1762] D loss: 1.2166, G loss: 0.7417\n",
      "[1204/1762] D loss: 1.3725, G loss: 0.6945\n",
      "[1284/1762] D loss: 1.3862, G loss: 0.7122\n",
      "[1364/1762] D loss: 1.3922, G loss: 0.7204\n",
      "[1444/1762] D loss: 1.3897, G loss: 0.7241\n",
      "[1524/1762] D loss: 1.1991, G loss: 0.7710\n",
      "[1604/1762] D loss: 1.3865, G loss: 0.7049\n",
      "[1684/1762] D loss: 1.3872, G loss: 0.6783\n",
      "[1762/1762] D loss: 1.3936, G loss: 0.7330\n",
      "train error: \n",
      " D loss: 1.340055, G loss: 0.727479, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 85.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.328755, G loss: 0.736144, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 81.4% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3873, G loss: 0.6906\n",
      "[84/1762] D loss: 1.3823, G loss: 0.7307\n",
      "[164/1762] D loss: 1.3894, G loss: 0.7046\n",
      "[244/1762] D loss: 1.3807, G loss: 0.7224\n",
      "[324/1762] D loss: 1.1700, G loss: 0.7910\n",
      "[404/1762] D loss: 1.3811, G loss: 0.7563\n",
      "[484/1762] D loss: 1.3907, G loss: 0.6935\n",
      "[564/1762] D loss: 1.3925, G loss: 0.7232\n",
      "[644/1762] D loss: 1.1831, G loss: 0.7637\n",
      "[724/1762] D loss: 1.2030, G loss: 0.7293\n",
      "[804/1762] D loss: 1.1940, G loss: 0.7514\n",
      "[884/1762] D loss: 1.3879, G loss: 0.7563\n",
      "[964/1762] D loss: 1.3887, G loss: 0.7352\n",
      "[1044/1762] D loss: 1.1857, G loss: 0.8855\n",
      "[1124/1762] D loss: 1.3876, G loss: 0.6793\n",
      "[1204/1762] D loss: 1.3882, G loss: 0.6815\n",
      "[1284/1762] D loss: 1.3882, G loss: 0.7155\n",
      "[1364/1762] D loss: 1.3880, G loss: 0.6679\n",
      "[1444/1762] D loss: 1.3898, G loss: 0.7213\n",
      "[1524/1762] D loss: 1.3886, G loss: 0.7086\n",
      "[1604/1762] D loss: 1.3894, G loss: 0.7106\n",
      "[1684/1762] D loss: 1.3875, G loss: 0.6995\n",
      "[1762/1762] D loss: 1.3700, G loss: 0.8554\n",
      "train error: \n",
      " D loss: 1.337118, G loss: 0.728345, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 85.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.324837, G loss: 0.738045, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 80.2% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3870, G loss: 0.6996\n",
      "[84/1762] D loss: 1.3720, G loss: 0.7708\n",
      "[164/1762] D loss: 1.3870, G loss: 0.6738\n",
      "[244/1762] D loss: 1.3926, G loss: 0.7330\n",
      "[324/1762] D loss: 1.1852, G loss: 0.7676\n",
      "[404/1762] D loss: 1.1713, G loss: 0.8155\n",
      "[484/1762] D loss: 0.9984, G loss: 0.9041\n",
      "[564/1762] D loss: 1.1738, G loss: 0.7875\n",
      "[644/1762] D loss: 1.3939, G loss: 0.7157\n",
      "[724/1762] D loss: 1.3872, G loss: 0.6841\n",
      "[804/1762] D loss: 1.1733, G loss: 0.7335\n",
      "[884/1762] D loss: 1.3938, G loss: 0.7748\n",
      "[964/1762] D loss: 1.3879, G loss: 0.6845\n",
      "[1044/1762] D loss: 1.2787, G loss: 0.7342\n",
      "[1124/1762] D loss: 1.3752, G loss: 0.7074\n",
      "[1204/1762] D loss: 1.3875, G loss: 0.7015\n",
      "[1284/1762] D loss: 1.1643, G loss: 0.7683\n",
      "[1364/1762] D loss: 0.9640, G loss: 0.8725\n",
      "[1444/1762] D loss: 1.1632, G loss: 0.8752\n",
      "[1524/1762] D loss: 1.3816, G loss: 0.7480\n",
      "[1604/1762] D loss: 1.3976, G loss: 0.7008\n",
      "[1684/1762] D loss: 1.3873, G loss: 0.6847\n",
      "[1762/1762] D loss: 1.3897, G loss: 0.6442\n",
      "train error: \n",
      " D loss: 1.335470, G loss: 0.727825, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 83.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.324391, G loss: 0.735404, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 82.3% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3921, G loss: 0.7521\n",
      "[84/1762] D loss: 1.3694, G loss: 0.6659\n",
      "[164/1762] D loss: 1.3905, G loss: 0.7161\n",
      "[244/1762] D loss: 1.3850, G loss: 0.6642\n",
      "[324/1762] D loss: 1.3897, G loss: 0.6931\n",
      "[404/1762] D loss: 1.3888, G loss: 0.6971\n",
      "[484/1762] D loss: 1.3868, G loss: 0.7033\n",
      "[564/1762] D loss: 1.3919, G loss: 0.6821\n",
      "[644/1762] D loss: 1.3740, G loss: 0.7302\n",
      "[724/1762] D loss: 1.3736, G loss: 0.7449\n",
      "[804/1762] D loss: 1.3889, G loss: 0.7343\n",
      "[884/1762] D loss: 1.3959, G loss: 0.7304\n",
      "[964/1762] D loss: 1.3902, G loss: 0.7219\n",
      "[1044/1762] D loss: 1.3940, G loss: 0.7522\n",
      "[1124/1762] D loss: 1.3823, G loss: 0.7048\n",
      "[1204/1762] D loss: 1.3563, G loss: 0.7455\n",
      "[1284/1762] D loss: 1.3892, G loss: 0.7274\n",
      "[1364/1762] D loss: 1.3766, G loss: 0.7534\n",
      "[1444/1762] D loss: 1.3875, G loss: 0.6775\n",
      "[1524/1762] D loss: 1.3833, G loss: 0.7428\n",
      "[1604/1762] D loss: 1.2635, G loss: 0.6820\n",
      "[1684/1762] D loss: 1.3886, G loss: 0.7266\n",
      "[1762/1762] D loss: 1.3972, G loss: 0.8727\n",
      "train error: \n",
      " D loss: 1.333592, G loss: 0.733923, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 84.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.321070, G loss: 0.743053, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 81.8% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3914, G loss: 0.7081\n",
      "[84/1762] D loss: 1.1635, G loss: 0.8090\n",
      "[164/1762] D loss: 1.3851, G loss: 0.7084\n",
      "[244/1762] D loss: 0.9318, G loss: 0.9083\n",
      "[324/1762] D loss: 1.3871, G loss: 0.7021\n",
      "[404/1762] D loss: 1.3891, G loss: 0.6777\n",
      "[484/1762] D loss: 1.3902, G loss: 0.7228\n",
      "[564/1762] D loss: 1.3882, G loss: 0.7133\n",
      "[644/1762] D loss: 1.3868, G loss: 0.6835\n",
      "[724/1762] D loss: 1.1697, G loss: 0.8017\n",
      "[804/1762] D loss: 1.1438, G loss: 0.8139\n",
      "[884/1762] D loss: 1.3975, G loss: 0.7487\n",
      "[964/1762] D loss: 1.3907, G loss: 0.7387\n",
      "[1044/1762] D loss: 1.3731, G loss: 0.7334\n",
      "[1124/1762] D loss: 1.3916, G loss: 0.7522\n",
      "[1204/1762] D loss: 1.3950, G loss: 0.7642\n",
      "[1284/1762] D loss: 1.3907, G loss: 0.6472\n",
      "[1364/1762] D loss: 1.1891, G loss: 0.7565\n",
      "[1444/1762] D loss: 1.3947, G loss: 0.6797\n",
      "[1524/1762] D loss: 1.3862, G loss: 0.6786\n",
      "[1604/1762] D loss: 1.1471, G loss: 0.7812\n",
      "[1684/1762] D loss: 1.3685, G loss: 0.7537\n",
      "[1762/1762] D loss: 1.3869, G loss: 0.7190\n",
      "train error: \n",
      " D loss: 1.330920, G loss: 0.746530, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 86.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.318146, G loss: 0.755961, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 84.3% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1583, G loss: 0.7591\n",
      "[84/1762] D loss: 1.3754, G loss: 0.7587\n",
      "[164/1762] D loss: 1.3717, G loss: 0.7430\n",
      "[244/1762] D loss: 1.3914, G loss: 0.7294\n",
      "[324/1762] D loss: 1.3922, G loss: 0.7054\n",
      "[404/1762] D loss: 1.1927, G loss: 0.8468\n",
      "[484/1762] D loss: 1.3947, G loss: 0.7421\n",
      "[564/1762] D loss: 1.3897, G loss: 0.7397\n",
      "[644/1762] D loss: 1.3983, G loss: 0.7616\n",
      "[724/1762] D loss: 1.3827, G loss: 0.6968\n",
      "[804/1762] D loss: 1.3879, G loss: 0.6655\n",
      "[884/1762] D loss: 1.3744, G loss: 0.7478\n",
      "[964/1762] D loss: 1.1580, G loss: 0.7903\n",
      "[1044/1762] D loss: 1.1463, G loss: 0.8563\n",
      "[1124/1762] D loss: 1.3884, G loss: 0.7126\n",
      "[1204/1762] D loss: 1.3979, G loss: 0.7654\n",
      "[1284/1762] D loss: 1.3904, G loss: 0.7324\n",
      "[1364/1762] D loss: 1.3949, G loss: 0.7473\n",
      "[1444/1762] D loss: 1.1347, G loss: 0.8082\n",
      "[1524/1762] D loss: 1.3899, G loss: 0.7060\n",
      "[1604/1762] D loss: 1.3843, G loss: 0.7283\n",
      "[1684/1762] D loss: 1.1360, G loss: 0.7753\n",
      "[1762/1762] D loss: 0.8984, G loss: 0.9520\n",
      "train error: \n",
      " D loss: 1.327787, G loss: 0.744247, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 84.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.313350, G loss: 0.755579, D accuracy: 55.5%, cell accuracy: 99.7%, board accuracy: 79.8% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1405, G loss: 0.7719\n",
      "[84/1762] D loss: 1.4001, G loss: 0.6489\n",
      "[164/1762] D loss: 1.3931, G loss: 0.7251\n",
      "[244/1762] D loss: 1.3644, G loss: 0.6788\n",
      "[324/1762] D loss: 1.3911, G loss: 0.6776\n",
      "[404/1762] D loss: 1.3876, G loss: 0.7216\n",
      "[484/1762] D loss: 1.3732, G loss: 0.7386\n",
      "[564/1762] D loss: 1.3842, G loss: 0.7035\n",
      "[644/1762] D loss: 1.3897, G loss: 0.7319\n",
      "[724/1762] D loss: 1.3877, G loss: 0.7059\n",
      "[804/1762] D loss: 1.3902, G loss: 0.6761\n",
      "[884/1762] D loss: 1.3893, G loss: 0.7661\n",
      "[964/1762] D loss: 1.3901, G loss: 0.6587\n",
      "[1044/1762] D loss: 1.3807, G loss: 0.7394\n",
      "[1124/1762] D loss: 1.4138, G loss: 0.8398\n",
      "[1204/1762] D loss: 1.3935, G loss: 0.7502\n",
      "[1284/1762] D loss: 1.3938, G loss: 0.7603\n",
      "[1364/1762] D loss: 1.3895, G loss: 0.6887\n",
      "[1444/1762] D loss: 1.3922, G loss: 0.6903\n",
      "[1524/1762] D loss: 1.3801, G loss: 0.8043\n",
      "[1604/1762] D loss: 1.3916, G loss: 0.7642\n",
      "[1684/1762] D loss: 1.3888, G loss: 0.7387\n",
      "[1762/1762] D loss: 1.3813, G loss: 0.6502\n",
      "train error: \n",
      " D loss: 1.327632, G loss: 0.735273, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 84.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.314172, G loss: 0.744959, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 81.6% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2169, G loss: 0.7821\n",
      "[84/1762] D loss: 1.1267, G loss: 0.8229\n",
      "[164/1762] D loss: 1.1194, G loss: 0.9128\n",
      "[244/1762] D loss: 1.3943, G loss: 0.7411\n",
      "[324/1762] D loss: 1.3889, G loss: 0.7299\n",
      "[404/1762] D loss: 1.3898, G loss: 0.6715\n",
      "[484/1762] D loss: 1.3905, G loss: 0.6835\n",
      "[564/1762] D loss: 1.3702, G loss: 0.7142\n",
      "[644/1762] D loss: 1.3907, G loss: 0.6560\n",
      "[724/1762] D loss: 1.1118, G loss: 0.8785\n",
      "[804/1762] D loss: 1.3885, G loss: 0.6861\n",
      "[884/1762] D loss: 0.9106, G loss: 0.9015\n",
      "[964/1762] D loss: 1.1380, G loss: 0.8434\n",
      "[1044/1762] D loss: 1.3992, G loss: 0.7743\n",
      "[1124/1762] D loss: 1.3718, G loss: 0.7647\n",
      "[1204/1762] D loss: 1.3882, G loss: 0.7187\n",
      "[1284/1762] D loss: 0.7476, G loss: 0.9528\n",
      "[1364/1762] D loss: 1.0941, G loss: 0.9314\n",
      "[1444/1762] D loss: 1.4015, G loss: 0.7537\n",
      "[1524/1762] D loss: 1.1378, G loss: 0.8121\n",
      "[1604/1762] D loss: 1.3784, G loss: 0.6963\n",
      "[1684/1762] D loss: 1.3975, G loss: 0.7636\n",
      "[1762/1762] D loss: 1.4207, G loss: 0.8696\n",
      "train error: \n",
      " D loss: 1.324815, G loss: 0.762386, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.311401, G loss: 0.773506, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 83.0% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1440, G loss: 0.8067\n",
      "[84/1762] D loss: 1.1736, G loss: 0.8225\n",
      "[164/1762] D loss: 1.1677, G loss: 0.7149\n",
      "[244/1762] D loss: 1.3887, G loss: 0.6810\n",
      "[324/1762] D loss: 1.3907, G loss: 0.7078\n",
      "[404/1762] D loss: 1.0029, G loss: 0.8804\n",
      "[484/1762] D loss: 1.3881, G loss: 0.7041\n",
      "[564/1762] D loss: 1.1098, G loss: 0.8604\n",
      "[644/1762] D loss: 1.3906, G loss: 0.7077\n",
      "[724/1762] D loss: 1.3845, G loss: 0.6657\n",
      "[804/1762] D loss: 1.3765, G loss: 0.7892\n",
      "[884/1762] D loss: 1.3968, G loss: 0.7368\n",
      "[964/1762] D loss: 0.8621, G loss: 0.9559\n",
      "[1044/1762] D loss: 1.3876, G loss: 0.7086\n",
      "[1124/1762] D loss: 1.3939, G loss: 0.6805\n",
      "[1204/1762] D loss: 1.4157, G loss: 0.7407\n",
      "[1284/1762] D loss: 0.9180, G loss: 0.9282\n",
      "[1364/1762] D loss: 1.1168, G loss: 0.7865\n",
      "[1444/1762] D loss: 1.3917, G loss: 0.7108\n",
      "[1524/1762] D loss: 1.3952, G loss: 0.8056\n",
      "[1604/1762] D loss: 1.3762, G loss: 0.7671\n",
      "[1684/1762] D loss: 1.3731, G loss: 0.7352\n",
      "[1762/1762] D loss: 0.9307, G loss: 0.8942\n",
      "train error: \n",
      " D loss: 1.324836, G loss: 0.735828, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 85.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.310355, G loss: 0.746791, D accuracy: 55.7%, cell accuracy: 99.8%, board accuracy: 81.8% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4175, G loss: 0.7476\n",
      "[84/1762] D loss: 1.0867, G loss: 0.9455\n",
      "[164/1762] D loss: 1.1060, G loss: 0.8112\n",
      "[244/1762] D loss: 1.3864, G loss: 0.7287\n",
      "[324/1762] D loss: 1.3906, G loss: 0.6669\n",
      "[404/1762] D loss: 1.1274, G loss: 0.7977\n",
      "[484/1762] D loss: 1.3928, G loss: 0.7562\n",
      "[564/1762] D loss: 1.3966, G loss: 0.7728\n",
      "[644/1762] D loss: 1.4018, G loss: 0.7894\n",
      "[724/1762] D loss: 1.3838, G loss: 0.7660\n",
      "[804/1762] D loss: 1.3879, G loss: 0.7061\n",
      "[884/1762] D loss: 1.3900, G loss: 0.7507\n",
      "[964/1762] D loss: 1.3911, G loss: 0.7437\n",
      "[1044/1762] D loss: 1.3894, G loss: 0.6770\n",
      "[1124/1762] D loss: 1.3889, G loss: 0.6716\n",
      "[1204/1762] D loss: 1.3969, G loss: 0.7548\n",
      "[1284/1762] D loss: 1.3851, G loss: 0.6899\n",
      "[1364/1762] D loss: 1.3837, G loss: 0.7629\n",
      "[1444/1762] D loss: 1.0904, G loss: 0.9009\n",
      "[1524/1762] D loss: 1.4082, G loss: 0.8249\n",
      "[1604/1762] D loss: 1.3881, G loss: 0.7207\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.7543\n",
      "[1762/1762] D loss: 1.3889, G loss: 0.7305\n",
      "train error: \n",
      " D loss: 1.325039, G loss: 0.738721, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 85.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.310534, G loss: 0.748727, D accuracy: 55.6%, cell accuracy: 99.8%, board accuracy: 83.0% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3398, G loss: 0.7687\n",
      "[84/1762] D loss: 1.4046, G loss: 0.8008\n",
      "[164/1762] D loss: 1.3906, G loss: 0.6925\n",
      "[244/1762] D loss: 1.1124, G loss: 0.8279\n",
      "[324/1762] D loss: 1.3982, G loss: 0.7432\n",
      "[404/1762] D loss: 1.3881, G loss: 0.6696\n",
      "[484/1762] D loss: 1.3826, G loss: 0.8467\n",
      "[564/1762] D loss: 1.3870, G loss: 0.7123\n",
      "[644/1762] D loss: 1.3655, G loss: 0.6852\n",
      "[724/1762] D loss: 1.3914, G loss: 0.7362\n",
      "[804/1762] D loss: 1.3882, G loss: 0.7283\n",
      "[884/1762] D loss: 1.3939, G loss: 0.8138\n",
      "[964/1762] D loss: 1.3887, G loss: 0.6516\n",
      "[1044/1762] D loss: 1.0807, G loss: 0.9134\n",
      "[1124/1762] D loss: 1.3787, G loss: 0.8253\n",
      "[1204/1762] D loss: 1.4205, G loss: 0.7371\n",
      "[1284/1762] D loss: 0.8464, G loss: 0.9344\n",
      "[1364/1762] D loss: 1.3870, G loss: 0.7101\n",
      "[1444/1762] D loss: 1.1387, G loss: 0.8860\n",
      "[1524/1762] D loss: 1.1218, G loss: 0.7713\n",
      "[1604/1762] D loss: 1.3881, G loss: 0.7140\n",
      "[1684/1762] D loss: 1.3868, G loss: 0.7473\n",
      "[1762/1762] D loss: 1.3913, G loss: 0.7602\n",
      "train error: \n",
      " D loss: 1.321502, G loss: 0.733543, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 85.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.305881, G loss: 0.745090, D accuracy: 55.8%, cell accuracy: 99.7%, board accuracy: 79.8% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3893, G loss: 0.6694\n",
      "[84/1762] D loss: 1.3884, G loss: 0.7231\n",
      "[164/1762] D loss: 1.3897, G loss: 0.6420\n",
      "[244/1762] D loss: 1.3917, G loss: 0.7589\n",
      "[324/1762] D loss: 1.3898, G loss: 0.6626\n",
      "[404/1762] D loss: 1.1072, G loss: 0.7911\n",
      "[484/1762] D loss: 0.8851, G loss: 0.9247\n",
      "[564/1762] D loss: 1.3825, G loss: 0.6715\n",
      "[644/1762] D loss: 1.1426, G loss: 0.8588\n",
      "[724/1762] D loss: 1.3800, G loss: 0.6833\n",
      "[804/1762] D loss: 0.8784, G loss: 0.9436\n",
      "[884/1762] D loss: 1.3871, G loss: 0.7052\n",
      "[964/1762] D loss: 1.3883, G loss: 0.7143\n",
      "[1044/1762] D loss: 1.0977, G loss: 0.7973\n",
      "[1124/1762] D loss: 1.3844, G loss: 0.6898\n",
      "[1204/1762] D loss: 1.1149, G loss: 0.8204\n",
      "[1284/1762] D loss: 1.3856, G loss: 0.7557\n",
      "[1364/1762] D loss: 1.3661, G loss: 0.8101\n",
      "[1444/1762] D loss: 1.0652, G loss: 0.8891\n",
      "[1524/1762] D loss: 1.3919, G loss: 0.6976\n",
      "[1604/1762] D loss: 1.3918, G loss: 0.6934\n",
      "[1684/1762] D loss: 1.3957, G loss: 0.7557\n",
      "[1762/1762] D loss: 0.8010, G loss: 0.9716\n",
      "train error: \n",
      " D loss: 1.320151, G loss: 0.778958, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 85.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.305054, G loss: 0.790926, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 82.3% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0660, G loss: 0.8918\n",
      "[84/1762] D loss: 1.3888, G loss: 0.7085\n",
      "[164/1762] D loss: 1.0650, G loss: 0.9317\n",
      "[244/1762] D loss: 1.3674, G loss: 0.6526\n",
      "[324/1762] D loss: 1.3999, G loss: 0.7709\n",
      "[404/1762] D loss: 1.2894, G loss: 0.8713\n",
      "[484/1762] D loss: 1.3870, G loss: 0.6772\n",
      "[564/1762] D loss: 1.3885, G loss: 0.7067\n",
      "[644/1762] D loss: 1.0651, G loss: 0.8606\n",
      "[724/1762] D loss: 1.3881, G loss: 0.6966\n",
      "[804/1762] D loss: 1.3887, G loss: 0.7029\n",
      "[884/1762] D loss: 1.3909, G loss: 0.7408\n",
      "[964/1762] D loss: 1.0590, G loss: 0.8509\n",
      "[1044/1762] D loss: 1.0587, G loss: 0.9348\n",
      "[1124/1762] D loss: 1.3714, G loss: 0.7554\n",
      "[1204/1762] D loss: 1.3857, G loss: 0.7017\n",
      "[1284/1762] D loss: 1.3886, G loss: 0.6486\n",
      "[1364/1762] D loss: 1.3895, G loss: 0.6960\n",
      "[1444/1762] D loss: 1.3589, G loss: 0.7068\n",
      "[1524/1762] D loss: 1.0947, G loss: 0.8921\n",
      "[1604/1762] D loss: 1.3798, G loss: 0.7107\n",
      "[1684/1762] D loss: 1.3942, G loss: 0.7537\n",
      "[1762/1762] D loss: 1.3917, G loss: 0.6394\n",
      "train error: \n",
      " D loss: 1.320871, G loss: 0.727106, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 84.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.304578, G loss: 0.740418, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 82.0% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3759, G loss: 0.7582\n",
      "[84/1762] D loss: 1.3320, G loss: 0.8236\n",
      "[164/1762] D loss: 1.3915, G loss: 0.7495\n",
      "[244/1762] D loss: 1.3470, G loss: 0.7373\n",
      "[324/1762] D loss: 1.1407, G loss: 0.8003\n",
      "[404/1762] D loss: 1.3604, G loss: 0.7378\n",
      "[484/1762] D loss: 1.3650, G loss: 0.7311\n",
      "[564/1762] D loss: 1.3980, G loss: 0.7683\n",
      "[644/1762] D loss: 1.0903, G loss: 0.8426\n",
      "[724/1762] D loss: 1.0602, G loss: 0.8488\n",
      "[804/1762] D loss: 1.0662, G loss: 0.8608\n",
      "[884/1762] D loss: 1.3796, G loss: 0.8722\n",
      "[964/1762] D loss: 1.3870, G loss: 0.6972\n",
      "[1044/1762] D loss: 1.3868, G loss: 0.7337\n",
      "[1124/1762] D loss: 1.0401, G loss: 0.9317\n",
      "[1204/1762] D loss: 1.3759, G loss: 0.7141\n",
      "[1284/1762] D loss: 1.3899, G loss: 0.7420\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6885\n",
      "[1444/1762] D loss: 1.0553, G loss: 0.9080\n",
      "[1524/1762] D loss: 1.3966, G loss: 0.7872\n",
      "[1604/1762] D loss: 1.0574, G loss: 0.8987\n",
      "[1684/1762] D loss: 1.3889, G loss: 0.7443\n",
      "[1762/1762] D loss: 1.3874, G loss: 0.6841\n",
      "train error: \n",
      " D loss: 1.319314, G loss: 0.744688, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 83.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.303779, G loss: 0.756119, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 80.7% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3921, G loss: 0.7627\n",
      "[84/1762] D loss: 1.3912, G loss: 0.7182\n",
      "[164/1762] D loss: 1.4098, G loss: 0.7935\n",
      "[244/1762] D loss: 1.3871, G loss: 0.7192\n",
      "[324/1762] D loss: 1.3912, G loss: 0.7152\n",
      "[404/1762] D loss: 1.3839, G loss: 0.7197\n",
      "[484/1762] D loss: 1.3797, G loss: 0.7351\n",
      "[564/1762] D loss: 1.3889, G loss: 0.7035\n",
      "[644/1762] D loss: 1.3956, G loss: 0.7953\n",
      "[724/1762] D loss: 1.3867, G loss: 0.7105\n",
      "[804/1762] D loss: 1.3877, G loss: 0.7429\n",
      "[884/1762] D loss: 0.7691, G loss: 1.0187\n",
      "[964/1762] D loss: 1.3836, G loss: 0.6721\n",
      "[1044/1762] D loss: 1.3945, G loss: 0.6409\n",
      "[1124/1762] D loss: 1.3704, G loss: 0.6987\n",
      "[1204/1762] D loss: 0.7667, G loss: 1.0409\n",
      "[1284/1762] D loss: 0.8399, G loss: 0.9705\n",
      "[1364/1762] D loss: 1.3799, G loss: 0.7751\n",
      "[1444/1762] D loss: 1.4006, G loss: 0.7863\n",
      "[1524/1762] D loss: 1.0000, G loss: 0.9100\n",
      "[1604/1762] D loss: 1.0163, G loss: 0.8631\n",
      "[1684/1762] D loss: 1.3858, G loss: 0.7078\n",
      "[1762/1762] D loss: 0.7485, G loss: 1.0063\n",
      "train error: \n",
      " D loss: 1.317836, G loss: 0.743075, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.301593, G loss: 0.757170, D accuracy: 56.0%, cell accuracy: 99.8%, board accuracy: 80.7% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3801, G loss: 0.7463\n",
      "[84/1762] D loss: 1.3893, G loss: 0.7451\n",
      "[164/1762] D loss: 1.3946, G loss: 0.7418\n",
      "[244/1762] D loss: 1.3898, G loss: 0.6695\n",
      "[324/1762] D loss: 1.3923, G loss: 0.7371\n",
      "[404/1762] D loss: 1.3892, G loss: 0.7385\n",
      "[484/1762] D loss: 1.3935, G loss: 0.7036\n",
      "[564/1762] D loss: 1.0858, G loss: 0.8403\n",
      "[644/1762] D loss: 1.3962, G loss: 0.7949\n",
      "[724/1762] D loss: 1.3878, G loss: 0.7471\n",
      "[804/1762] D loss: 1.0581, G loss: 0.7749\n",
      "[884/1762] D loss: 1.3764, G loss: 0.7327\n",
      "[964/1762] D loss: 1.3641, G loss: 0.8354\n",
      "[1044/1762] D loss: 1.4165, G loss: 0.8072\n",
      "[1124/1762] D loss: 1.0508, G loss: 0.8811\n",
      "[1204/1762] D loss: 1.3997, G loss: 0.7836\n",
      "[1284/1762] D loss: 1.0803, G loss: 0.7753\n",
      "[1364/1762] D loss: 1.3878, G loss: 0.6982\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.7904\n",
      "[1524/1762] D loss: 1.3745, G loss: 0.7153\n",
      "[1604/1762] D loss: 1.3925, G loss: 0.6895\n",
      "[1684/1762] D loss: 1.3953, G loss: 0.6506\n",
      "[1762/1762] D loss: 1.1410, G loss: 0.9542\n",
      "train error: \n",
      " D loss: 1.318466, G loss: 0.758747, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 85.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.301026, G loss: 0.772372, D accuracy: 55.7%, cell accuracy: 99.8%, board accuracy: 80.0% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3879, G loss: 0.6573\n",
      "[84/1762] D loss: 1.4079, G loss: 0.7326\n",
      "[164/1762] D loss: 1.3900, G loss: 0.7098\n",
      "[244/1762] D loss: 1.3906, G loss: 0.7152\n",
      "[324/1762] D loss: 1.3855, G loss: 0.6670\n",
      "[404/1762] D loss: 1.3983, G loss: 0.7865\n",
      "[484/1762] D loss: 1.3897, G loss: 0.6798\n",
      "[564/1762] D loss: 0.7408, G loss: 1.1040\n",
      "[644/1762] D loss: 1.3666, G loss: 0.7995\n",
      "[724/1762] D loss: 1.3887, G loss: 0.6879\n",
      "[804/1762] D loss: 1.3819, G loss: 0.7147\n",
      "[884/1762] D loss: 1.3866, G loss: 0.6735\n",
      "[964/1762] D loss: 1.3886, G loss: 0.7046\n",
      "[1044/1762] D loss: 1.4056, G loss: 0.8115\n",
      "[1124/1762] D loss: 0.9988, G loss: 0.9445\n",
      "[1204/1762] D loss: 1.4039, G loss: 0.7968\n",
      "[1284/1762] D loss: 1.4129, G loss: 0.7053\n",
      "[1364/1762] D loss: 1.3693, G loss: 0.6907\n",
      "[1444/1762] D loss: 1.3696, G loss: 0.8011\n",
      "[1524/1762] D loss: 1.0507, G loss: 0.8961\n",
      "[1604/1762] D loss: 1.4124, G loss: 0.8854\n",
      "[1684/1762] D loss: 1.3916, G loss: 0.7352\n",
      "[1762/1762] D loss: 1.3886, G loss: 0.6465\n",
      "train error: \n",
      " D loss: 1.317683, G loss: 0.741513, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 86.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.299447, G loss: 0.757461, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 82.0% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9782, G loss: 0.9531\n",
      "[84/1762] D loss: 1.3869, G loss: 0.6551\n",
      "[164/1762] D loss: 1.3662, G loss: 0.6806\n",
      "[244/1762] D loss: 1.3831, G loss: 0.7411\n",
      "[324/1762] D loss: 0.9924, G loss: 0.9209\n",
      "[404/1762] D loss: 1.3901, G loss: 0.6389\n",
      "[484/1762] D loss: 1.3966, G loss: 0.7725\n",
      "[564/1762] D loss: 0.7028, G loss: 1.2137\n",
      "[644/1762] D loss: 1.3945, G loss: 0.7786\n",
      "[724/1762] D loss: 1.3848, G loss: 0.6897\n",
      "[804/1762] D loss: 0.9924, G loss: 0.8617\n",
      "[884/1762] D loss: 1.3725, G loss: 0.8076\n",
      "[964/1762] D loss: 1.3853, G loss: 0.7926\n",
      "[1044/1762] D loss: 1.3960, G loss: 0.7644\n",
      "[1124/1762] D loss: 1.3099, G loss: 0.8304\n",
      "[1204/1762] D loss: 1.3810, G loss: 0.7303\n",
      "[1284/1762] D loss: 1.3938, G loss: 0.7378\n",
      "[1364/1762] D loss: 1.3869, G loss: 0.7005\n",
      "[1444/1762] D loss: 1.3859, G loss: 0.7077\n",
      "[1524/1762] D loss: 1.0500, G loss: 0.8012\n",
      "[1604/1762] D loss: 1.3930, G loss: 0.6393\n",
      "[1684/1762] D loss: 1.0868, G loss: 0.8123\n",
      "[1762/1762] D loss: 1.3903, G loss: 0.7559\n",
      "train error: \n",
      " D loss: 1.315920, G loss: 0.768941, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 86.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.299983, G loss: 0.782589, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 82.0% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3877, G loss: 0.6676\n",
      "[84/1762] D loss: 0.9441, G loss: 0.9178\n",
      "[164/1762] D loss: 1.3878, G loss: 0.6931\n",
      "[244/1762] D loss: 0.9806, G loss: 0.9830\n",
      "[324/1762] D loss: 1.3817, G loss: 0.7545\n",
      "[404/1762] D loss: 1.3914, G loss: 0.6457\n",
      "[484/1762] D loss: 1.3390, G loss: 0.7646\n",
      "[564/1762] D loss: 1.2388, G loss: 0.8265\n",
      "[644/1762] D loss: 1.3874, G loss: 0.6861\n",
      "[724/1762] D loss: 1.3996, G loss: 0.7694\n",
      "[804/1762] D loss: 1.3865, G loss: 0.7213\n",
      "[884/1762] D loss: 1.3882, G loss: 0.7300\n",
      "[964/1762] D loss: 1.3921, G loss: 0.7148\n",
      "[1044/1762] D loss: 1.3877, G loss: 0.6712\n",
      "[1124/1762] D loss: 0.9939, G loss: 0.9554\n",
      "[1204/1762] D loss: 1.3954, G loss: 0.7754\n",
      "[1284/1762] D loss: 1.3875, G loss: 0.6934\n",
      "[1364/1762] D loss: 1.3988, G loss: 0.7881\n",
      "[1444/1762] D loss: 1.3961, G loss: 0.7122\n",
      "[1524/1762] D loss: 0.9682, G loss: 0.9184\n",
      "[1604/1762] D loss: 1.4036, G loss: 0.7167\n",
      "[1684/1762] D loss: 0.9592, G loss: 0.9828\n",
      "[1762/1762] D loss: 1.3870, G loss: 0.6926\n",
      "train error: \n",
      " D loss: 1.315085, G loss: 0.754638, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 85.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.298427, G loss: 0.767737, D accuracy: 55.9%, cell accuracy: 99.8%, board accuracy: 82.3% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3992, G loss: 0.6461\n",
      "[84/1762] D loss: 0.9835, G loss: 0.8725\n",
      "[164/1762] D loss: 1.3934, G loss: 0.7267\n",
      "[244/1762] D loss: 1.3907, G loss: 0.7319\n",
      "[324/1762] D loss: 0.9672, G loss: 0.9486\n",
      "[404/1762] D loss: 1.3650, G loss: 0.7187\n",
      "[484/1762] D loss: 1.0815, G loss: 0.8234\n",
      "[564/1762] D loss: 1.3975, G loss: 0.7552\n",
      "[644/1762] D loss: 0.9791, G loss: 0.8940\n",
      "[724/1762] D loss: 1.3589, G loss: 0.7343\n",
      "[804/1762] D loss: 1.3696, G loss: 0.7217\n",
      "[884/1762] D loss: 1.3928, G loss: 0.7700\n",
      "[964/1762] D loss: 1.0452, G loss: 0.9080\n",
      "[1044/1762] D loss: 1.4213, G loss: 0.8308\n",
      "[1124/1762] D loss: 1.3981, G loss: 0.6194\n",
      "[1204/1762] D loss: 1.3874, G loss: 0.6894\n",
      "[1284/1762] D loss: 0.9748, G loss: 0.8927\n",
      "[1364/1762] D loss: 1.0791, G loss: 0.7787\n",
      "[1444/1762] D loss: 1.3401, G loss: 0.8123\n",
      "[1524/1762] D loss: 0.9540, G loss: 0.9723\n",
      "[1604/1762] D loss: 1.3901, G loss: 0.6979\n",
      "[1684/1762] D loss: 0.9448, G loss: 0.9515\n",
      "[1762/1762] D loss: 0.6941, G loss: 1.0865\n",
      "train error: \n",
      " D loss: 1.317194, G loss: 0.714231, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 84.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.299808, G loss: 0.728671, D accuracy: 56.4%, cell accuracy: 99.7%, board accuracy: 79.5% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3865, G loss: 0.7320\n",
      "[84/1762] D loss: 1.3909, G loss: 0.7425\n",
      "[164/1762] D loss: 1.3878, G loss: 0.7261\n",
      "[244/1762] D loss: 1.3686, G loss: 0.6852\n",
      "[324/1762] D loss: 1.3988, G loss: 0.7845\n",
      "[404/1762] D loss: 0.9828, G loss: 0.8942\n",
      "[484/1762] D loss: 1.3895, G loss: 0.7077\n",
      "[564/1762] D loss: 1.3852, G loss: 0.7075\n",
      "[644/1762] D loss: 1.3932, G loss: 0.7225\n",
      "[724/1762] D loss: 1.4038, G loss: 0.8116\n",
      "[804/1762] D loss: 0.9563, G loss: 0.9701\n",
      "[884/1762] D loss: 1.3926, G loss: 0.6234\n",
      "[964/1762] D loss: 1.3773, G loss: 0.7527\n",
      "[1044/1762] D loss: 0.6452, G loss: 1.1565\n",
      "[1124/1762] D loss: 1.4018, G loss: 0.8092\n",
      "[1204/1762] D loss: 1.4088, G loss: 0.8102\n",
      "[1284/1762] D loss: 1.3771, G loss: 0.8396\n",
      "[1364/1762] D loss: 1.0226, G loss: 0.8911\n",
      "[1444/1762] D loss: 0.7706, G loss: 0.9546\n",
      "[1524/1762] D loss: 0.9112, G loss: 1.0490\n",
      "[1604/1762] D loss: 1.3860, G loss: 0.7120\n",
      "[1684/1762] D loss: 0.9283, G loss: 0.9372\n",
      "[1762/1762] D loss: 1.3879, G loss: 0.6457\n",
      "train error: \n",
      " D loss: 1.313546, G loss: 0.768686, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 85.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.296395, G loss: 0.783589, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 81.1% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3876, G loss: 0.7036\n",
      "[84/1762] D loss: 1.3933, G loss: 0.7276\n",
      "[164/1762] D loss: 1.3484, G loss: 0.7881\n",
      "[244/1762] D loss: 1.3953, G loss: 0.7495\n",
      "[324/1762] D loss: 0.9194, G loss: 0.8968\n",
      "[404/1762] D loss: 1.3987, G loss: 0.7306\n",
      "[484/1762] D loss: 1.3977, G loss: 0.7969\n",
      "[564/1762] D loss: 0.9680, G loss: 0.9955\n",
      "[644/1762] D loss: 1.3938, G loss: 0.6467\n",
      "[724/1762] D loss: 1.0794, G loss: 0.8427\n",
      "[804/1762] D loss: 1.3802, G loss: 0.7389\n",
      "[884/1762] D loss: 1.3619, G loss: 0.8667\n",
      "[964/1762] D loss: 1.4293, G loss: 0.7825\n",
      "[1044/1762] D loss: 1.3941, G loss: 0.7266\n",
      "[1124/1762] D loss: 1.4106, G loss: 0.7889\n",
      "[1204/1762] D loss: 1.3917, G loss: 0.7726\n",
      "[1284/1762] D loss: 1.3912, G loss: 0.7515\n",
      "[1364/1762] D loss: 1.3436, G loss: 0.7594\n",
      "[1444/1762] D loss: 1.3890, G loss: 0.6594\n",
      "[1524/1762] D loss: 0.9281, G loss: 0.9335\n",
      "[1604/1762] D loss: 1.3579, G loss: 0.7193\n",
      "[1684/1762] D loss: 1.3644, G loss: 0.7374\n",
      "[1762/1762] D loss: 1.3878, G loss: 0.6755\n",
      "train error: \n",
      " D loss: 1.312301, G loss: 0.762289, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 85.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.294390, G loss: 0.777485, D accuracy: 56.1%, cell accuracy: 99.8%, board accuracy: 80.5% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3977, G loss: 0.7584\n",
      "[84/1762] D loss: 1.4042, G loss: 0.7729\n",
      "[164/1762] D loss: 1.0416, G loss: 0.7966\n",
      "[244/1762] D loss: 1.3987, G loss: 0.7934\n",
      "[324/1762] D loss: 0.8698, G loss: 1.0173\n",
      "[404/1762] D loss: 1.3764, G loss: 0.7440\n",
      "[484/1762] D loss: 1.3876, G loss: 0.6733\n",
      "[564/1762] D loss: 1.3874, G loss: 0.7142\n",
      "[644/1762] D loss: 1.3898, G loss: 0.7322\n",
      "[724/1762] D loss: 1.4044, G loss: 0.8174\n",
      "[804/1762] D loss: 1.2393, G loss: 0.8466\n",
      "[884/1762] D loss: 1.3892, G loss: 0.7101\n",
      "[964/1762] D loss: 1.3942, G loss: 0.7495\n",
      "[1044/1762] D loss: 1.3913, G loss: 0.8267\n",
      "[1124/1762] D loss: 1.4312, G loss: 0.8943\n",
      "[1204/1762] D loss: 1.3917, G loss: 0.7507\n",
      "[1284/1762] D loss: 1.3958, G loss: 0.7006\n",
      "[1364/1762] D loss: 1.3884, G loss: 0.7144\n",
      "[1444/1762] D loss: 1.3884, G loss: 0.7042\n",
      "[1524/1762] D loss: 1.3894, G loss: 0.6563\n",
      "[1604/1762] D loss: 1.4239, G loss: 0.8980\n",
      "[1684/1762] D loss: 0.9644, G loss: 0.9113\n",
      "[1762/1762] D loss: 1.4120, G loss: 0.6019\n",
      "train error: \n",
      " D loss: 1.312337, G loss: 0.738595, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 84.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.293156, G loss: 0.756110, D accuracy: 56.1%, cell accuracy: 99.8%, board accuracy: 81.8% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3598, G loss: 0.8625\n",
      "[84/1762] D loss: 0.9279, G loss: 0.9293\n",
      "[164/1762] D loss: 1.3927, G loss: 0.6556\n",
      "[244/1762] D loss: 1.3158, G loss: 0.9119\n",
      "[324/1762] D loss: 1.3892, G loss: 0.6365\n",
      "[404/1762] D loss: 1.4348, G loss: 0.8734\n",
      "[484/1762] D loss: 1.3879, G loss: 0.6817\n",
      "[564/1762] D loss: 1.3603, G loss: 0.8209\n",
      "[644/1762] D loss: 1.3820, G loss: 0.7377\n",
      "[724/1762] D loss: 1.3866, G loss: 0.7933\n",
      "[804/1762] D loss: 1.3834, G loss: 0.6465\n",
      "[884/1762] D loss: 0.9195, G loss: 0.9199\n",
      "[964/1762] D loss: 0.8841, G loss: 1.0966\n",
      "[1044/1762] D loss: 1.3837, G loss: 0.6661\n",
      "[1124/1762] D loss: 1.3993, G loss: 0.7134\n",
      "[1204/1762] D loss: 1.3950, G loss: 0.7272\n",
      "[1284/1762] D loss: 0.9653, G loss: 0.8407\n",
      "[1364/1762] D loss: 1.0371, G loss: 0.8788\n",
      "[1444/1762] D loss: 0.8731, G loss: 0.9795\n",
      "[1524/1762] D loss: 0.8595, G loss: 1.1229\n",
      "[1604/1762] D loss: 1.3912, G loss: 0.6836\n",
      "[1684/1762] D loss: 1.3881, G loss: 0.6885\n",
      "[1762/1762] D loss: 1.3808, G loss: 0.6630\n",
      "train error: \n",
      " D loss: 1.312729, G loss: 0.736682, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 83.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.294349, G loss: 0.752324, D accuracy: 56.2%, cell accuracy: 99.7%, board accuracy: 78.0% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3844, G loss: 0.7497\n",
      "[84/1762] D loss: 1.3687, G loss: 0.7286\n",
      "[164/1762] D loss: 1.3946, G loss: 0.7088\n",
      "[244/1762] D loss: 1.3880, G loss: 0.6897\n",
      "[324/1762] D loss: 0.8596, G loss: 0.9769\n",
      "[404/1762] D loss: 1.3892, G loss: 0.6867\n",
      "[484/1762] D loss: 1.4075, G loss: 0.8215\n",
      "[564/1762] D loss: 1.3944, G loss: 0.6589\n",
      "[644/1762] D loss: 0.8672, G loss: 0.9723\n",
      "[724/1762] D loss: 0.8815, G loss: 1.0543\n",
      "[804/1762] D loss: 1.3935, G loss: 0.8241\n",
      "[884/1762] D loss: 1.3923, G loss: 0.7344\n",
      "[964/1762] D loss: 0.5600, G loss: 1.2318\n",
      "[1044/1762] D loss: 1.4330, G loss: 0.9245\n",
      "[1124/1762] D loss: 1.3993, G loss: 0.6595\n",
      "[1204/1762] D loss: 1.4008, G loss: 0.7819\n",
      "[1284/1762] D loss: 1.3890, G loss: 0.7364\n",
      "[1364/1762] D loss: 1.3902, G loss: 0.7442\n",
      "[1444/1762] D loss: 0.9410, G loss: 0.8038\n",
      "[1524/1762] D loss: 1.3926, G loss: 0.7422\n",
      "[1604/1762] D loss: 1.3607, G loss: 0.6554\n",
      "[1684/1762] D loss: 1.3894, G loss: 0.7150\n",
      "[1762/1762] D loss: 1.3879, G loss: 0.7166\n",
      "train error: \n",
      " D loss: 1.310690, G loss: 0.771785, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.290871, G loss: 0.789003, D accuracy: 56.1%, cell accuracy: 99.8%, board accuracy: 80.2% \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_and_freeze_gen_and_replace_disc(\"fgrd_nlr_1em5\", freeze_epoch=5, new_learning_rate=1e-5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A learning rate of 1e-5 for the second discriminator seems to fix the problem. This new discriminator doesn't suffer from any instability, but depending on the training run it either improves its accuracy consistently or stays at about the same accuracy.\n",
    "\n",
    "However, applying this knowledge to the main GAN training might be tricky, because the generator is constantly adapting. If we lower the learning rate of the discriminator, we should probably lower the learning rate of the generator even more so the discriminator doesn't fall behind too easily."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vary discriminator architecture\n",
    "\n",
    "Let's try a few different discriminator architectures to see how it handles the frozen generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TetrisDiscriminator has 5521 parameters.\n",
      "Prediction on real data: tensor([0.1933, 0.1997, 0.2426, 0.2720])\n"
     ]
    }
   ],
   "source": [
    "def check_disc(disc):\n",
    "    print(f\"{disc.__class__.__name__} has {count_parameters(disc)} parameters.\")\n",
    "    X, y = next(iter(train_dataloader))\n",
    "    with torch.no_grad():\n",
    "        pred = disc(X, y)\n",
    "    print(f\"Prediction on real data: {pred}\")\n",
    "\n",
    "check_disc(TetrisDiscriminator().to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiscWithMoreConvBN has 7089 parameters.\n",
      "Prediction on real data: tensor([-0.1519, -0.0263, -0.0626, -0.3540])\n"
     ]
    }
   ],
   "source": [
    "class DiscWithMoreConvBN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.body = nn.Sequential(\n",
    "                nn.Conv2d(4, 16, 3, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2),\n",
    "                nn.Conv2d(16, 16, 3, bias=False),\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(16, 16, 3, bias=False),\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.ReLU(),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(112, 16),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(16, 1),\n",
    "                nn.Flatten(start_dim=0)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        x = torch.cat((x, y), dim=1)\n",
    "        logits = self.body(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "check_disc(DiscWithMoreConvBN().to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiscWithMoreConv has 7057 parameters.\n",
      "Prediction on real data: tensor([0.1698, 0.1646, 0.1693, 0.1697])\n"
     ]
    }
   ],
   "source": [
    "class DiscWithMoreConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.body = nn.Sequential(\n",
    "                nn.Conv2d(4, 16, 3, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2),\n",
    "                nn.Conv2d(16, 16, 3),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(16, 16, 3),\n",
    "                nn.ReLU(),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(112, 16),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(16, 1),\n",
    "                nn.Flatten(start_dim=0)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        x = torch.cat((x, y), dim=1)\n",
    "        logits = self.body(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "check_disc(DiscWithMoreConv().to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiscWithMoreConvBNPad has 9425 parameters.\n",
      "Prediction on real data: tensor([ 0.1754,  0.1373, -0.0601,  0.2204])\n"
     ]
    }
   ],
   "source": [
    "class DiscWithMoreConvBNPad(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.body = nn.Sequential(\n",
    "                nn.Conv2d(4, 16, 3, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2),\n",
    "                nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(16, 16, 3, bias=False),\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(16, 16, 3, bias=False),\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.ReLU(),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(112, 16),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(16, 1),\n",
    "                nn.Flatten(start_dim=0)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        x = torch.cat((x, y), dim=1)\n",
    "        logits = self.body(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "check_disc(DiscWithMoreConvBNPad().to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiscWithMoreConvPad has 9377 parameters.\n",
      "Prediction on real data: tensor([0.1670, 0.1669, 0.1654, 0.1663])\n"
     ]
    }
   ],
   "source": [
    "class DiscWithMoreConvPad(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.body = nn.Sequential(\n",
    "                nn.Conv2d(4, 16, 3, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2),\n",
    "                nn.Conv2d(16, 16, 3, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(16, 16, 3),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(16, 16, 3),\n",
    "                nn.ReLU(),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(112, 16),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(16, 1),\n",
    "                nn.Flatten(start_dim=0)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        x = torch.cat((x, y), dim=1)\n",
    "        logits = self.body(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "check_disc(DiscWithMoreConvPad().to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_freeze_gen_and_replace_disc(run_name=\"\", freeze_epoch=5, new_learning_rate=1e-3, disc_cls=TetrisDiscriminator):\n",
    "    learning_rate = 1e-3\n",
    "    epochs = 50\n",
    "\n",
    "    gen = TetrisModel().to(device)\n",
    "    disc = disc_cls().to(device)\n",
    "\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer_gen = torch.optim.Adam(gen.parameters(), lr=learning_rate)\n",
    "    optimizer_disc = torch.optim.Adam(disc.parameters(), lr=learning_rate)\n",
    "\n",
    "    log_dir = os.path.join(\"runs\", \"experiment_019\")\n",
    "    log_subdir = os.path.join(log_dir, run_name + \"_\" + datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"))\n",
    "    tb_writer = SummaryWriter(log_subdir)\n",
    "\n",
    "    train_examples = find_interesting_examples(train_dataset)\n",
    "    test_examples = find_interesting_examples(test_dataset)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch}\\n-------------------------------\")\n",
    "        if epoch == freeze_epoch:\n",
    "            gen.requires_grad_(False)\n",
    "            disc = disc_cls().to(device)\n",
    "            optimizer_disc = torch.optim.Adam(disc.parameters(), lr=new_learning_rate)\n",
    "        train_loop(train_dataloader, gen, disc, loss_fn, optimizer_gen, optimizer_disc)\n",
    "        test_loop(\"train\", train_dataloader, gen, disc, loss_fn, tb_writer, epoch, train_examples)\n",
    "        test_loop(\"test\", test_dataloader, gen, disc, loss_fn, tb_writer, epoch, test_examples)\n",
    "        for name, weight in disc.named_parameters():\n",
    "            tb_writer.add_histogram(f\"Discriminator weights/{name}\", weight, epoch)\n",
    "            tb_writer.add_histogram(f\"Discriminator gradients/{name}\", weight.grad, epoch)\n",
    "\n",
    "    tb_writer.close()\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3894, G loss: 0.7718\n",
      "[84/1762] D loss: 1.1976, G loss: 0.8137\n",
      "[164/1762] D loss: 0.5615, G loss: 1.5732\n",
      "[244/1762] D loss: 0.3054, G loss: 2.1695\n",
      "[324/1762] D loss: 0.1317, G loss: 3.4589\n",
      "[404/1762] D loss: 0.0304, G loss: 4.5751\n",
      "[484/1762] D loss: 0.0262, G loss: 4.4166\n",
      "[564/1762] D loss: 0.0771, G loss: 5.0794\n",
      "[644/1762] D loss: 0.0238, G loss: 4.7528\n",
      "[724/1762] D loss: 0.0956, G loss: 6.9500\n",
      "[804/1762] D loss: 0.0311, G loss: 5.8188\n",
      "[884/1762] D loss: 0.1161, G loss: 5.9866\n",
      "[964/1762] D loss: 0.0973, G loss: 4.0344\n",
      "[1044/1762] D loss: 0.1484, G loss: 5.8313\n",
      "[1124/1762] D loss: 0.7030, G loss: 5.7809\n",
      "[1204/1762] D loss: 0.0240, G loss: 4.0951\n",
      "[1284/1762] D loss: 0.1479, G loss: 3.2149\n",
      "[1364/1762] D loss: 0.0409, G loss: 4.5501\n",
      "[1444/1762] D loss: 0.0034, G loss: 6.6371\n",
      "[1524/1762] D loss: 0.0058, G loss: 7.1821\n",
      "[1604/1762] D loss: 0.0572, G loss: 5.1598\n",
      "[1684/1762] D loss: 0.3683, G loss: 3.4146\n",
      "[1762/1762] D loss: 0.6881, G loss: 4.0081\n",
      "train error: \n",
      " D loss: 1.374408, G loss: 3.053467, D accuracy: 73.6%, cell accuracy: 97.1%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.358418, G loss: 3.090434, D accuracy: 73.9%, cell accuracy: 97.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1843, G loss: 5.4680\n",
      "[84/1762] D loss: 0.0843, G loss: 6.4418\n",
      "[164/1762] D loss: 0.7989, G loss: 6.0317\n",
      "[244/1762] D loss: 0.1997, G loss: 4.1380\n",
      "[324/1762] D loss: 0.2695, G loss: 2.8993\n",
      "[404/1762] D loss: 0.0591, G loss: 3.6229\n",
      "[484/1762] D loss: 1.4909, G loss: 1.5273\n",
      "[564/1762] D loss: 2.0336, G loss: 3.5073\n",
      "[644/1762] D loss: 1.3827, G loss: 1.6175\n",
      "[724/1762] D loss: 1.1933, G loss: 0.9751\n",
      "[804/1762] D loss: 1.3177, G loss: 0.7993\n",
      "[884/1762] D loss: 1.5348, G loss: 0.4187\n",
      "[964/1762] D loss: 0.9068, G loss: 0.9585\n",
      "[1044/1762] D loss: 1.1574, G loss: 0.9044\n",
      "[1124/1762] D loss: 1.8151, G loss: 1.3821\n",
      "[1204/1762] D loss: 1.3131, G loss: 0.5392\n",
      "[1284/1762] D loss: 0.9311, G loss: 1.3002\n",
      "[1364/1762] D loss: 1.3882, G loss: 0.7343\n",
      "[1444/1762] D loss: 0.8733, G loss: 0.9255\n",
      "[1524/1762] D loss: 1.2256, G loss: 1.3363\n",
      "[1604/1762] D loss: 0.9224, G loss: 1.1513\n",
      "[1684/1762] D loss: 1.5378, G loss: 1.5532\n",
      "[1762/1762] D loss: 0.8038, G loss: 1.4495\n",
      "train error: \n",
      " D loss: 1.448332, G loss: 0.752286, D accuracy: 52.6%, cell accuracy: 99.7%, board accuracy: 79.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.446018, G loss: 0.748153, D accuracy: 54.2%, cell accuracy: 99.6%, board accuracy: 77.0% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1373, G loss: 1.1792\n",
      "[84/1762] D loss: 1.0112, G loss: 1.2801\n",
      "[164/1762] D loss: 1.4988, G loss: 0.4915\n",
      "[244/1762] D loss: 1.3980, G loss: 0.6264\n",
      "[324/1762] D loss: 0.6043, G loss: 1.2904\n",
      "[404/1762] D loss: 0.2955, G loss: 2.1270\n",
      "[484/1762] D loss: 1.4612, G loss: 0.9876\n",
      "[564/1762] D loss: 1.3649, G loss: 0.6673\n",
      "[644/1762] D loss: 1.2892, G loss: 0.9017\n",
      "[724/1762] D loss: 0.2431, G loss: 2.9912\n",
      "[804/1762] D loss: 1.4118, G loss: 0.6130\n",
      "[884/1762] D loss: 1.3594, G loss: 0.5659\n",
      "[964/1762] D loss: 1.1884, G loss: 1.6603\n",
      "[1044/1762] D loss: 1.3434, G loss: 0.4231\n",
      "[1124/1762] D loss: 1.8787, G loss: 0.4624\n",
      "[1204/1762] D loss: 1.3462, G loss: 0.6657\n",
      "[1284/1762] D loss: 1.4686, G loss: 0.9592\n",
      "[1364/1762] D loss: 1.8138, G loss: 1.4412\n",
      "[1444/1762] D loss: 1.2988, G loss: 1.0179\n",
      "[1524/1762] D loss: 0.7001, G loss: 0.8203\n",
      "[1604/1762] D loss: 1.5063, G loss: 0.4248\n",
      "[1684/1762] D loss: 1.4068, G loss: 0.8219\n",
      "[1762/1762] D loss: 1.4493, G loss: 0.5688\n",
      "train error: \n",
      " D loss: 1.389571, G loss: 0.566807, D accuracy: 52.7%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.382226, G loss: 0.567805, D accuracy: 51.1%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4962, G loss: 1.2953\n",
      "[84/1762] D loss: 1.4890, G loss: 1.1234\n",
      "[164/1762] D loss: 1.4335, G loss: 0.9791\n",
      "[244/1762] D loss: 1.4005, G loss: 0.6177\n",
      "[324/1762] D loss: 1.3151, G loss: 0.5372\n",
      "[404/1762] D loss: 1.3724, G loss: 0.7137\n",
      "[484/1762] D loss: 0.4716, G loss: 1.3809\n",
      "[564/1762] D loss: 1.4727, G loss: 0.9286\n",
      "[644/1762] D loss: 0.9999, G loss: 0.8928\n",
      "[724/1762] D loss: 1.4049, G loss: 0.6836\n",
      "[804/1762] D loss: 1.4092, G loss: 0.5914\n",
      "[884/1762] D loss: 0.3836, G loss: 1.5053\n",
      "[964/1762] D loss: 1.3063, G loss: 0.7486\n",
      "[1044/1762] D loss: 0.6534, G loss: 0.9445\n",
      "[1124/1762] D loss: 0.4516, G loss: 1.2979\n",
      "[1204/1762] D loss: 0.4811, G loss: 1.2130\n",
      "[1284/1762] D loss: 1.5062, G loss: 1.0111\n",
      "[1364/1762] D loss: 1.7854, G loss: 1.1768\n",
      "[1444/1762] D loss: 1.2470, G loss: 0.8919\n",
      "[1524/1762] D loss: 1.3907, G loss: 0.6220\n",
      "[1604/1762] D loss: 0.4627, G loss: 1.2238\n",
      "[1684/1762] D loss: 1.1361, G loss: 1.1271\n",
      "[1762/1762] D loss: 2.1116, G loss: 1.7618\n",
      "train error: \n",
      " D loss: 1.339142, G loss: 0.737457, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.323755, G loss: 0.749189, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3383, G loss: 1.7390\n",
      "[84/1762] D loss: 1.4122, G loss: 0.7690\n",
      "[164/1762] D loss: 1.5461, G loss: 1.1415\n",
      "[244/1762] D loss: 1.4036, G loss: 0.8526\n",
      "[324/1762] D loss: 1.4188, G loss: 0.8119\n",
      "[404/1762] D loss: 1.3904, G loss: 0.7314\n",
      "[484/1762] D loss: 1.3790, G loss: 0.6440\n",
      "[564/1762] D loss: 1.6373, G loss: 1.2375\n",
      "[644/1762] D loss: 1.4604, G loss: 1.3678\n",
      "[724/1762] D loss: 1.3220, G loss: 0.8658\n",
      "[804/1762] D loss: 1.5045, G loss: 1.1419\n",
      "[884/1762] D loss: 1.3883, G loss: 0.7413\n",
      "[964/1762] D loss: 0.3663, G loss: 1.6195\n",
      "[1044/1762] D loss: 0.4633, G loss: 1.2208\n",
      "[1124/1762] D loss: 1.4201, G loss: 0.5670\n",
      "[1204/1762] D loss: 0.3224, G loss: 1.5991\n",
      "[1284/1762] D loss: 1.4281, G loss: 0.6771\n",
      "[1364/1762] D loss: 0.2857, G loss: 1.8561\n",
      "[1444/1762] D loss: 1.4034, G loss: 0.7623\n",
      "[1524/1762] D loss: 1.3816, G loss: 0.6837\n",
      "[1604/1762] D loss: 1.3278, G loss: 0.9271\n",
      "[1684/1762] D loss: 1.5384, G loss: 1.1601\n",
      "[1762/1762] D loss: 1.3896, G loss: 0.7070\n",
      "train error: \n",
      " D loss: 1.339153, G loss: 0.681312, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.323313, G loss: 0.693843, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3779, G loss: 0.6966\n",
      "[84/1762] D loss: 1.3873, G loss: 0.6892\n",
      "[164/1762] D loss: 1.3868, G loss: 0.6923\n",
      "[244/1762] D loss: 1.3881, G loss: 0.7068\n",
      "[324/1762] D loss: 1.3876, G loss: 0.7031\n",
      "[404/1762] D loss: 1.3640, G loss: 0.7074\n",
      "[484/1762] D loss: 1.3869, G loss: 0.6923\n",
      "[564/1762] D loss: 1.3874, G loss: 0.7143\n",
      "[644/1762] D loss: 1.2965, G loss: 0.6749\n",
      "[724/1762] D loss: 1.3880, G loss: 0.6968\n",
      "[804/1762] D loss: 1.3922, G loss: 0.6423\n",
      "[884/1762] D loss: 1.3783, G loss: 0.7802\n",
      "[964/1762] D loss: 1.3876, G loss: 0.6878\n",
      "[1044/1762] D loss: 1.3921, G loss: 0.7207\n",
      "[1124/1762] D loss: 1.4075, G loss: 0.6798\n",
      "[1204/1762] D loss: 1.4142, G loss: 0.8109\n",
      "[1284/1762] D loss: 1.4220, G loss: 0.6263\n",
      "[1364/1762] D loss: 1.4124, G loss: 0.7830\n",
      "[1444/1762] D loss: 1.3998, G loss: 0.6620\n",
      "[1524/1762] D loss: 1.4099, G loss: 0.7662\n",
      "[1604/1762] D loss: 1.4686, G loss: 0.9273\n",
      "[1684/1762] D loss: 1.4014, G loss: 0.7688\n",
      "[1762/1762] D loss: 0.7311, G loss: 0.8976\n",
      "train error: \n",
      " D loss: 1.409017, G loss: 0.504063, D accuracy: 51.3%, cell accuracy: 99.8%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.389465, G loss: 0.512337, D accuracy: 51.8%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4090, G loss: 0.8023\n",
      "[84/1762] D loss: 1.4157, G loss: 0.7184\n",
      "[164/1762] D loss: 0.6682, G loss: 0.9407\n",
      "[244/1762] D loss: 1.4380, G loss: 0.9192\n",
      "[324/1762] D loss: 1.4221, G loss: 0.8733\n",
      "[404/1762] D loss: 1.4093, G loss: 0.7285\n",
      "[484/1762] D loss: 1.4521, G loss: 0.8978\n",
      "[564/1762] D loss: 0.6355, G loss: 0.9529\n",
      "[644/1762] D loss: 1.3914, G loss: 0.7096\n",
      "[724/1762] D loss: 1.3935, G loss: 0.7969\n",
      "[804/1762] D loss: 1.3964, G loss: 0.7454\n",
      "[884/1762] D loss: 1.4229, G loss: 0.8676\n",
      "[964/1762] D loss: 1.4357, G loss: 0.9024\n",
      "[1044/1762] D loss: 1.4247, G loss: 0.8740\n",
      "[1124/1762] D loss: 0.5554, G loss: 1.0424\n",
      "[1204/1762] D loss: 0.4249, G loss: 1.2227\n",
      "[1284/1762] D loss: 1.4654, G loss: 0.9771\n",
      "[1364/1762] D loss: 1.4455, G loss: 0.8610\n",
      "[1444/1762] D loss: 1.4809, G loss: 1.0175\n",
      "[1524/1762] D loss: 0.6998, G loss: 0.8029\n",
      "[1604/1762] D loss: 1.4181, G loss: 0.8666\n",
      "[1684/1762] D loss: 1.4272, G loss: 0.8744\n",
      "[1762/1762] D loss: 1.5592, G loss: 1.1656\n",
      "train error: \n",
      " D loss: 1.343324, G loss: 0.711195, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 91.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.329340, G loss: 0.710283, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4893, G loss: 0.9985\n",
      "[84/1762] D loss: 1.4031, G loss: 0.7987\n",
      "[164/1762] D loss: 1.4084, G loss: 0.8243\n",
      "[244/1762] D loss: 1.4308, G loss: 0.8915\n",
      "[324/1762] D loss: 1.4055, G loss: 0.7769\n",
      "[404/1762] D loss: 1.4167, G loss: 0.8561\n",
      "[484/1762] D loss: 1.4054, G loss: 0.7380\n",
      "[564/1762] D loss: 0.4796, G loss: 1.1086\n",
      "[644/1762] D loss: 1.4200, G loss: 0.8962\n",
      "[724/1762] D loss: 1.4410, G loss: 0.9657\n",
      "[804/1762] D loss: 0.5683, G loss: 0.9346\n",
      "[884/1762] D loss: 0.2997, G loss: 1.4957\n",
      "[964/1762] D loss: 0.5137, G loss: 1.0089\n",
      "[1044/1762] D loss: 0.3166, G loss: 1.4138\n",
      "[1124/1762] D loss: 0.4867, G loss: 1.0812\n",
      "[1204/1762] D loss: 1.3912, G loss: 0.6899\n",
      "[1284/1762] D loss: 1.4420, G loss: 0.9577\n",
      "[1364/1762] D loss: 0.6571, G loss: 0.8066\n",
      "[1444/1762] D loss: 1.4257, G loss: 0.8403\n",
      "[1524/1762] D loss: 0.5694, G loss: 0.9120\n",
      "[1604/1762] D loss: 1.4003, G loss: 0.7558\n",
      "[1684/1762] D loss: 1.4607, G loss: 0.8039\n",
      "[1762/1762] D loss: 1.3873, G loss: 0.6979\n",
      "train error: \n",
      " D loss: 1.324682, G loss: 0.790621, D accuracy: 54.7%, cell accuracy: 99.9%, board accuracy: 91.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.302440, G loss: 0.811664, D accuracy: 56.1%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4064, G loss: 0.7465\n",
      "[84/1762] D loss: 0.4208, G loss: 1.2213\n",
      "[164/1762] D loss: 1.4334, G loss: 0.8015\n",
      "[244/1762] D loss: 1.3992, G loss: 0.7633\n",
      "[324/1762] D loss: 1.4296, G loss: 0.8363\n",
      "[404/1762] D loss: 1.4039, G loss: 0.7305\n",
      "[484/1762] D loss: 1.4169, G loss: 0.5425\n",
      "[564/1762] D loss: 1.4282, G loss: 0.8617\n",
      "[644/1762] D loss: 1.3957, G loss: 0.7603\n",
      "[724/1762] D loss: 1.4020, G loss: 0.7854\n",
      "[804/1762] D loss: 1.4251, G loss: 0.8617\n",
      "[884/1762] D loss: 1.3896, G loss: 0.7431\n",
      "[964/1762] D loss: 0.3164, G loss: 1.4879\n",
      "[1044/1762] D loss: 0.3473, G loss: 1.4379\n",
      "[1124/1762] D loss: 1.3953, G loss: 0.6016\n",
      "[1204/1762] D loss: 1.4586, G loss: 0.9733\n",
      "[1284/1762] D loss: 1.3883, G loss: 0.6708\n",
      "[1364/1762] D loss: 1.3744, G loss: 0.7484\n",
      "[1444/1762] D loss: 1.3963, G loss: 0.7051\n",
      "[1524/1762] D loss: 1.4653, G loss: 0.9490\n",
      "[1604/1762] D loss: 0.2176, G loss: 2.0126\n",
      "[1684/1762] D loss: 0.2921, G loss: 1.7799\n",
      "[1762/1762] D loss: 0.8768, G loss: 1.6049\n",
      "train error: \n",
      " D loss: 1.374040, G loss: 0.672258, D accuracy: 52.4%, cell accuracy: 99.9%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.344264, G loss: 0.704186, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4159, G loss: 0.6829\n",
      "[84/1762] D loss: 0.2737, G loss: 1.6877\n",
      "[164/1762] D loss: 1.4241, G loss: 0.8550\n",
      "[244/1762] D loss: 1.3987, G loss: 0.6563\n",
      "[324/1762] D loss: 1.3882, G loss: 0.7363\n",
      "[404/1762] D loss: 0.3232, G loss: 1.5084\n",
      "[484/1762] D loss: 1.4424, G loss: 0.5772\n",
      "[564/1762] D loss: 1.4059, G loss: 0.7419\n",
      "[644/1762] D loss: 1.4399, G loss: 0.9071\n",
      "[724/1762] D loss: 1.3830, G loss: 0.7758\n",
      "[804/1762] D loss: 1.3971, G loss: 0.7113\n",
      "[884/1762] D loss: 1.4107, G loss: 0.8673\n",
      "[964/1762] D loss: 0.1364, G loss: 2.5747\n",
      "[1044/1762] D loss: 1.3915, G loss: 0.6626\n",
      "[1124/1762] D loss: 1.3922, G loss: 0.7835\n",
      "[1204/1762] D loss: 0.3041, G loss: 1.5648\n",
      "[1284/1762] D loss: 1.4223, G loss: 0.7525\n",
      "[1364/1762] D loss: 1.3934, G loss: 0.7600\n",
      "[1444/1762] D loss: 1.4218, G loss: 0.9053\n",
      "[1524/1762] D loss: 1.4129, G loss: 0.8802\n",
      "[1604/1762] D loss: 1.3938, G loss: 0.7306\n",
      "[1684/1762] D loss: 0.1907, G loss: 2.4482\n",
      "[1762/1762] D loss: 1.4706, G loss: 0.9583\n",
      "train error: \n",
      " D loss: 1.336644, G loss: 0.624226, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.308444, G loss: 0.648944, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4097, G loss: 0.6547\n",
      "[84/1762] D loss: 0.2922, G loss: 1.5733\n",
      "[164/1762] D loss: 1.3998, G loss: 0.6849\n",
      "[244/1762] D loss: 1.4157, G loss: 0.8915\n",
      "[324/1762] D loss: 1.3870, G loss: 0.7296\n",
      "[404/1762] D loss: 1.4459, G loss: 0.8225\n",
      "[484/1762] D loss: 1.4359, G loss: 0.8828\n",
      "[564/1762] D loss: 1.3916, G loss: 0.7254\n",
      "[644/1762] D loss: 1.3936, G loss: 0.7777\n",
      "[724/1762] D loss: 1.4333, G loss: 0.6558\n",
      "[804/1762] D loss: 0.2082, G loss: 2.1930\n",
      "[884/1762] D loss: 0.1924, G loss: 2.3543\n",
      "[964/1762] D loss: 0.2106, G loss: 2.2553\n",
      "[1044/1762] D loss: 1.5544, G loss: 0.4383\n",
      "[1124/1762] D loss: 1.3942, G loss: 0.6385\n",
      "[1204/1762] D loss: 1.3981, G loss: 0.7130\n",
      "[1284/1762] D loss: 1.3939, G loss: 0.6157\n",
      "[1364/1762] D loss: 1.5490, G loss: 1.0306\n",
      "[1444/1762] D loss: 1.3987, G loss: 0.7570\n",
      "[1524/1762] D loss: 1.3921, G loss: 0.7364\n",
      "[1604/1762] D loss: 0.1744, G loss: 2.6838\n",
      "[1684/1762] D loss: 0.2964, G loss: 1.6396\n",
      "[1762/1762] D loss: 1.3870, G loss: 0.6952\n",
      "train error: \n",
      " D loss: 1.301808, G loss: 0.819250, D accuracy: 54.0%, cell accuracy: 99.9%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.269844, G loss: 0.882607, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4638, G loss: 0.7103\n",
      "[84/1762] D loss: 1.4118, G loss: 0.8726\n",
      "[164/1762] D loss: 1.4014, G loss: 0.7571\n",
      "[244/1762] D loss: 0.0564, G loss: 3.8918\n",
      "[324/1762] D loss: 1.4716, G loss: 0.9712\n",
      "[404/1762] D loss: 1.4245, G loss: 0.5450\n",
      "[484/1762] D loss: 1.4007, G loss: 0.8160\n",
      "[564/1762] D loss: 1.3940, G loss: 0.6918\n",
      "[644/1762] D loss: 0.1500, G loss: 2.6319\n",
      "[724/1762] D loss: 1.3937, G loss: 0.6552\n",
      "[804/1762] D loss: 1.3907, G loss: 0.6750\n",
      "[884/1762] D loss: 0.1377, G loss: 2.5980\n",
      "[964/1762] D loss: 1.3920, G loss: 0.7894\n",
      "[1044/1762] D loss: 0.2298, G loss: 2.0180\n",
      "[1124/1762] D loss: 0.2656, G loss: 1.8106\n",
      "[1204/1762] D loss: 1.3962, G loss: 0.7310\n",
      "[1284/1762] D loss: 1.4129, G loss: 0.8719\n",
      "[1364/1762] D loss: 1.4056, G loss: 0.6568\n",
      "[1444/1762] D loss: 0.1560, G loss: 2.5011\n",
      "[1524/1762] D loss: 1.4033, G loss: 0.6903\n",
      "[1604/1762] D loss: 1.4049, G loss: 0.6245\n",
      "[1684/1762] D loss: 1.4640, G loss: 0.9770\n",
      "[1762/1762] D loss: 1.4385, G loss: 0.9073\n",
      "train error: \n",
      " D loss: 1.341640, G loss: 0.642953, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.309166, G loss: 0.686254, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3947, G loss: 0.7519\n",
      "[84/1762] D loss: 1.3919, G loss: 0.7142\n",
      "[164/1762] D loss: 1.3999, G loss: 0.5988\n",
      "[244/1762] D loss: 1.4020, G loss: 0.6103\n",
      "[324/1762] D loss: 0.1939, G loss: 2.1099\n",
      "[404/1762] D loss: 1.4032, G loss: 0.7396\n",
      "[484/1762] D loss: 1.4148, G loss: 0.6766\n",
      "[564/1762] D loss: 0.1273, G loss: 2.6467\n",
      "[644/1762] D loss: 1.3880, G loss: 0.7527\n",
      "[724/1762] D loss: 1.3755, G loss: 0.7314\n",
      "[804/1762] D loss: 0.1625, G loss: 2.5983\n",
      "[884/1762] D loss: 1.4166, G loss: 0.8497\n",
      "[964/1762] D loss: 1.3943, G loss: 0.6192\n",
      "[1044/1762] D loss: 1.4003, G loss: 0.7029\n",
      "[1124/1762] D loss: 1.3959, G loss: 0.7282\n",
      "[1204/1762] D loss: 1.4176, G loss: 0.5759\n",
      "[1284/1762] D loss: 1.3931, G loss: 0.7138\n",
      "[1364/1762] D loss: 1.4173, G loss: 0.7560\n",
      "[1444/1762] D loss: 1.4290, G loss: 0.7804\n",
      "[1524/1762] D loss: 1.4797, G loss: 0.9586\n",
      "[1604/1762] D loss: 1.4176, G loss: 0.8411\n",
      "[1684/1762] D loss: 0.1819, G loss: 2.1305\n",
      "[1762/1762] D loss: 1.3918, G loss: 0.7608\n",
      "train error: \n",
      " D loss: 1.299936, G loss: 0.945512, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.267024, G loss: 1.024751, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1510, G loss: 2.4064\n",
      "[84/1762] D loss: 1.4235, G loss: 0.5369\n",
      "[164/1762] D loss: 1.3396, G loss: 0.8159\n",
      "[244/1762] D loss: 1.3984, G loss: 0.6147\n",
      "[324/1762] D loss: 1.4135, G loss: 0.8562\n",
      "[404/1762] D loss: 0.1335, G loss: 2.6615\n",
      "[484/1762] D loss: 1.4116, G loss: 0.7913\n",
      "[564/1762] D loss: 1.4098, G loss: 0.7575\n",
      "[644/1762] D loss: 1.3852, G loss: 0.6819\n",
      "[724/1762] D loss: 1.4573, G loss: 0.9704\n",
      "[804/1762] D loss: 0.1394, G loss: 3.0879\n",
      "[884/1762] D loss: 1.4119, G loss: 0.8226\n",
      "[964/1762] D loss: 1.4127, G loss: 0.5749\n",
      "[1044/1762] D loss: 0.1236, G loss: 2.5547\n",
      "[1124/1762] D loss: 1.4165, G loss: 0.7891\n",
      "[1204/1762] D loss: 0.1766, G loss: 2.5284\n",
      "[1284/1762] D loss: 1.3958, G loss: 0.7282\n",
      "[1364/1762] D loss: 1.4355, G loss: 0.7609\n",
      "[1444/1762] D loss: 1.4396, G loss: 0.6007\n",
      "[1524/1762] D loss: 1.4136, G loss: 0.5560\n",
      "[1604/1762] D loss: 1.4336, G loss: 0.8156\n",
      "[1684/1762] D loss: 1.3936, G loss: 0.6693\n",
      "[1762/1762] D loss: 1.4016, G loss: 0.7418\n",
      "train error: \n",
      " D loss: 1.341099, G loss: 0.762528, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 91.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.302548, G loss: 0.841552, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4262, G loss: 0.6174\n",
      "[84/1762] D loss: 1.4272, G loss: 0.7161\n",
      "[164/1762] D loss: 1.3925, G loss: 0.7331\n",
      "[244/1762] D loss: 1.4115, G loss: 0.6997\n",
      "[324/1762] D loss: 0.1122, G loss: 2.9917\n",
      "[404/1762] D loss: 0.1846, G loss: 2.1518\n",
      "[484/1762] D loss: 1.4351, G loss: 0.5876\n",
      "[564/1762] D loss: 0.1317, G loss: 2.9935\n",
      "[644/1762] D loss: 1.5236, G loss: 0.9812\n",
      "[724/1762] D loss: 1.4618, G loss: 0.7541\n",
      "[804/1762] D loss: 1.4181, G loss: 0.8464\n",
      "[884/1762] D loss: 1.3925, G loss: 0.5995\n",
      "[964/1762] D loss: 1.3647, G loss: 0.6937\n",
      "[1044/1762] D loss: 0.1268, G loss: 2.8883\n",
      "[1124/1762] D loss: 1.4313, G loss: 0.8362\n",
      "[1204/1762] D loss: 1.4007, G loss: 0.6640\n",
      "[1284/1762] D loss: 1.3995, G loss: 0.7637\n",
      "[1364/1762] D loss: 1.4802, G loss: 0.8770\n",
      "[1444/1762] D loss: 1.3860, G loss: 0.7739\n",
      "[1524/1762] D loss: 0.1184, G loss: 2.8046\n",
      "[1604/1762] D loss: 1.4255, G loss: 0.9104\n",
      "[1684/1762] D loss: 1.4090, G loss: 0.8145\n",
      "[1762/1762] D loss: 1.4407, G loss: 0.5889\n",
      "train error: \n",
      " D loss: 1.655956, G loss: 0.548689, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.605675, G loss: 0.637909, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4117, G loss: 0.7640\n",
      "[84/1762] D loss: 1.3966, G loss: 0.6011\n",
      "[164/1762] D loss: 0.1123, G loss: 3.1845\n",
      "[244/1762] D loss: 1.4126, G loss: 0.8466\n",
      "[324/1762] D loss: 1.3872, G loss: 0.7304\n",
      "[404/1762] D loss: 0.8927, G loss: 3.5243\n",
      "[484/1762] D loss: 1.3869, G loss: 0.6803\n",
      "[564/1762] D loss: 1.3950, G loss: 0.6552\n",
      "[644/1762] D loss: 1.4000, G loss: 0.7791\n",
      "[724/1762] D loss: 0.1159, G loss: 3.0831\n",
      "[804/1762] D loss: 1.4051, G loss: 0.7459\n",
      "[884/1762] D loss: 0.0775, G loss: 3.6617\n",
      "[964/1762] D loss: 0.1235, G loss: 2.4433\n",
      "[1044/1762] D loss: 1.4105, G loss: 0.7058\n",
      "[1124/1762] D loss: 1.3902, G loss: 0.7243\n",
      "[1204/1762] D loss: 0.1139, G loss: 2.5930\n",
      "[1284/1762] D loss: 1.3975, G loss: 0.7533\n",
      "[1364/1762] D loss: 1.4055, G loss: 0.7751\n",
      "[1444/1762] D loss: 1.3889, G loss: 0.6478\n",
      "[1524/1762] D loss: 1.3870, G loss: 0.6790\n",
      "[1604/1762] D loss: 1.3930, G loss: 0.6089\n",
      "[1684/1762] D loss: 1.4014, G loss: 0.6941\n",
      "[1762/1762] D loss: 1.4387, G loss: 0.5864\n",
      "train error: \n",
      " D loss: 1.337837, G loss: 0.801319, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 91.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.304269, G loss: 0.904802, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3927, G loss: 0.6369\n",
      "[84/1762] D loss: 0.0780, G loss: 3.5933\n",
      "[164/1762] D loss: 1.3910, G loss: 0.7641\n",
      "[244/1762] D loss: 0.0700, G loss: 3.5955\n",
      "[324/1762] D loss: 1.3850, G loss: 0.7504\n",
      "[404/1762] D loss: 1.3986, G loss: 0.6611\n",
      "[484/1762] D loss: 0.1290, G loss: 2.8630\n",
      "[564/1762] D loss: 1.3916, G loss: 0.6962\n",
      "[644/1762] D loss: 1.3961, G loss: 0.7757\n",
      "[724/1762] D loss: 1.4243, G loss: 0.6988\n",
      "[804/1762] D loss: 1.3713, G loss: 0.6559\n",
      "[884/1762] D loss: 1.3829, G loss: 0.7310\n",
      "[964/1762] D loss: 0.0577, G loss: 4.0239\n",
      "[1044/1762] D loss: 1.3867, G loss: 0.7533\n",
      "[1124/1762] D loss: 0.0887, G loss: 3.6963\n",
      "[1204/1762] D loss: 1.4428, G loss: 0.9480\n",
      "[1284/1762] D loss: 1.4139, G loss: 0.8360\n",
      "[1364/1762] D loss: 0.0770, G loss: 3.7795\n",
      "[1444/1762] D loss: 0.0780, G loss: 3.7953\n",
      "[1524/1762] D loss: 1.4067, G loss: 0.8154\n",
      "[1604/1762] D loss: 0.1097, G loss: 2.9511\n",
      "[1684/1762] D loss: 1.3983, G loss: 0.6660\n",
      "[1762/1762] D loss: 1.3913, G loss: 0.7112\n",
      "train error: \n",
      " D loss: 1.407720, G loss: 0.692627, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.369011, G loss: 0.790929, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0882, G loss: 3.5270\n",
      "[84/1762] D loss: 0.0739, G loss: 3.6805\n",
      "[164/1762] D loss: 1.4205, G loss: 0.6352\n",
      "[244/1762] D loss: 1.3988, G loss: 0.8016\n",
      "[324/1762] D loss: 1.3918, G loss: 0.6930\n",
      "[404/1762] D loss: 0.0718, G loss: 3.3152\n",
      "[484/1762] D loss: 0.0084, G loss: 4.8785\n",
      "[564/1762] D loss: 0.0444, G loss: 3.4859\n",
      "[644/1762] D loss: 0.0703, G loss: 3.1113\n",
      "[724/1762] D loss: 1.4000, G loss: 0.7363\n",
      "[804/1762] D loss: 1.3917, G loss: 0.7944\n",
      "[884/1762] D loss: 1.3787, G loss: 0.7576\n",
      "[964/1762] D loss: 1.3788, G loss: 0.7375\n",
      "[1044/1762] D loss: 1.4437, G loss: 0.7275\n",
      "[1124/1762] D loss: 0.1069, G loss: 2.8259\n",
      "[1204/1762] D loss: 1.4304, G loss: 0.5440\n",
      "[1284/1762] D loss: 1.4053, G loss: 0.6888\n",
      "[1364/1762] D loss: 1.3827, G loss: 0.8023\n",
      "[1444/1762] D loss: 1.4065, G loss: 0.6082\n",
      "[1524/1762] D loss: 1.4101, G loss: 0.6015\n",
      "[1604/1762] D loss: 0.0637, G loss: 3.4100\n",
      "[1684/1762] D loss: 1.3881, G loss: 0.8071\n",
      "[1762/1762] D loss: 1.4120, G loss: 0.6192\n",
      "train error: \n",
      " D loss: 1.412054, G loss: 0.782090, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.376327, G loss: 0.900361, D accuracy: 55.6%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3917, G loss: 0.8377\n",
      "[84/1762] D loss: 0.0763, G loss: 3.9978\n",
      "[164/1762] D loss: 1.4143, G loss: 0.8414\n",
      "[244/1762] D loss: 1.3945, G loss: 0.7727\n",
      "[324/1762] D loss: 1.3870, G loss: 0.6646\n",
      "[404/1762] D loss: 1.4240, G loss: 0.7023\n",
      "[484/1762] D loss: 1.4014, G loss: 0.6746\n",
      "[564/1762] D loss: 0.0829, G loss: 3.3281\n",
      "[644/1762] D loss: 1.4502, G loss: 0.5175\n",
      "[724/1762] D loss: 1.5599, G loss: 0.3994\n",
      "[804/1762] D loss: 1.4077, G loss: 0.6874\n",
      "[884/1762] D loss: 1.3952, G loss: 0.7822\n",
      "[964/1762] D loss: 1.3979, G loss: 0.6621\n",
      "[1044/1762] D loss: 0.0530, G loss: 3.8284\n",
      "[1124/1762] D loss: 1.4141, G loss: 0.7796\n",
      "[1204/1762] D loss: 1.3385, G loss: 0.8473\n",
      "[1284/1762] D loss: 1.3895, G loss: 0.7001\n",
      "[1364/1762] D loss: 0.0073, G loss: 5.7445\n",
      "[1444/1762] D loss: 0.0567, G loss: 3.9625\n",
      "[1524/1762] D loss: 1.3695, G loss: 0.7819\n",
      "[1604/1762] D loss: 0.0909, G loss: 2.8108\n",
      "[1684/1762] D loss: 1.2373, G loss: 0.8756\n",
      "[1762/1762] D loss: 1.4189, G loss: 0.8660\n",
      "train error: \n",
      " D loss: 1.402121, G loss: 0.775275, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 91.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.363926, G loss: 0.891441, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3865, G loss: 0.7045\n",
      "[84/1762] D loss: 0.0803, G loss: 3.4274\n",
      "[164/1762] D loss: 0.0698, G loss: 3.4988\n",
      "[244/1762] D loss: 1.3998, G loss: 0.8091\n",
      "[324/1762] D loss: 1.3849, G loss: 0.7360\n",
      "[404/1762] D loss: 0.0724, G loss: 3.3216\n",
      "[484/1762] D loss: 1.4226, G loss: 0.5776\n",
      "[564/1762] D loss: 0.0440, G loss: 4.0566\n",
      "[644/1762] D loss: 0.0820, G loss: 2.7020\n",
      "[724/1762] D loss: 1.4129, G loss: 0.5400\n",
      "[804/1762] D loss: 0.0078, G loss: 4.9511\n",
      "[884/1762] D loss: 1.3661, G loss: 0.5867\n",
      "[964/1762] D loss: 0.0167, G loss: 4.5977\n",
      "[1044/1762] D loss: 1.4190, G loss: 0.8482\n",
      "[1124/1762] D loss: 1.3073, G loss: 0.8597\n",
      "[1204/1762] D loss: 1.3851, G loss: 0.6971\n",
      "[1284/1762] D loss: 0.0673, G loss: 3.4933\n",
      "[1364/1762] D loss: 1.3675, G loss: 0.6559\n",
      "[1444/1762] D loss: 1.3912, G loss: 0.7247\n",
      "[1524/1762] D loss: 1.3820, G loss: 0.8110\n",
      "[1604/1762] D loss: 1.3867, G loss: 0.7946\n",
      "[1684/1762] D loss: 1.2931, G loss: 0.8545\n",
      "[1762/1762] D loss: 1.3996, G loss: 0.8557\n",
      "train error: \n",
      " D loss: 1.402183, G loss: 0.826523, D accuracy: 54.4%, cell accuracy: 99.9%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.361964, G loss: 0.966252, D accuracy: 55.8%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0343, G loss: 4.2206\n",
      "[84/1762] D loss: 1.3495, G loss: 0.7625\n",
      "[164/1762] D loss: 1.4163, G loss: 0.7330\n",
      "[244/1762] D loss: 1.5145, G loss: 0.4067\n",
      "[324/1762] D loss: 1.3990, G loss: 0.6840\n",
      "[404/1762] D loss: 0.0488, G loss: 3.6089\n",
      "[484/1762] D loss: 1.3930, G loss: 0.7867\n",
      "[564/1762] D loss: 1.3945, G loss: 0.6664\n",
      "[644/1762] D loss: 0.0900, G loss: 3.0818\n",
      "[724/1762] D loss: 1.3997, G loss: 0.7109\n",
      "[804/1762] D loss: 1.4608, G loss: 0.9426\n",
      "[884/1762] D loss: 1.4045, G loss: 0.7399\n",
      "[964/1762] D loss: 1.3681, G loss: 0.7317\n",
      "[1044/1762] D loss: 1.4038, G loss: 0.8074\n",
      "[1124/1762] D loss: 1.4081, G loss: 0.7909\n",
      "[1204/1762] D loss: 1.4023, G loss: 0.8072\n",
      "[1284/1762] D loss: 0.0262, G loss: 4.8729\n",
      "[1364/1762] D loss: 0.0553, G loss: 3.5176\n",
      "[1444/1762] D loss: 1.3854, G loss: 0.5797\n",
      "[1524/1762] D loss: 1.4151, G loss: 0.7975\n",
      "[1604/1762] D loss: 1.3875, G loss: 0.6747\n",
      "[1684/1762] D loss: 1.4025, G loss: 0.6330\n",
      "[1762/1762] D loss: 1.3700, G loss: 0.6634\n",
      "train error: \n",
      " D loss: 1.273567, G loss: 1.035961, D accuracy: 57.5%, cell accuracy: 99.9%, board accuracy: 91.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.248067, G loss: 1.120509, D accuracy: 59.1%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3965, G loss: 0.5843\n",
      "[84/1762] D loss: 1.3642, G loss: 0.7034\n",
      "[164/1762] D loss: 1.5378, G loss: 1.1012\n",
      "[244/1762] D loss: 1.4213, G loss: 0.9416\n",
      "[324/1762] D loss: 0.0667, G loss: 3.9912\n",
      "[404/1762] D loss: 1.3731, G loss: 0.7406\n",
      "[484/1762] D loss: 0.0415, G loss: 4.5043\n",
      "[564/1762] D loss: 1.3690, G loss: 0.6733\n",
      "[644/1762] D loss: 1.4745, G loss: 0.6762\n",
      "[724/1762] D loss: 1.3742, G loss: 0.7631\n",
      "[804/1762] D loss: 1.3813, G loss: 0.9439\n",
      "[884/1762] D loss: 1.4780, G loss: 0.4915\n",
      "[964/1762] D loss: 1.4059, G loss: 0.8228\n",
      "[1044/1762] D loss: 1.3800, G loss: 0.6571\n",
      "[1124/1762] D loss: 1.3774, G loss: 0.7669\n",
      "[1204/1762] D loss: 1.3544, G loss: 0.7033\n",
      "[1284/1762] D loss: 1.2805, G loss: 0.9545\n",
      "[1364/1762] D loss: 1.4981, G loss: 1.1352\n",
      "[1444/1762] D loss: 0.0545, G loss: 3.4498\n",
      "[1524/1762] D loss: 0.0669, G loss: 3.1004\n",
      "[1604/1762] D loss: 1.3886, G loss: 0.5589\n",
      "[1684/1762] D loss: 1.3986, G loss: 0.6723\n",
      "[1762/1762] D loss: 0.0074, G loss: 4.9306\n",
      "train error: \n",
      " D loss: 1.667307, G loss: 0.600202, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.618982, G loss: 0.715983, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5377, G loss: 0.4242\n",
      "[84/1762] D loss: 1.4674, G loss: 0.9296\n",
      "[164/1762] D loss: 1.3356, G loss: 0.6741\n",
      "[244/1762] D loss: 1.3614, G loss: 0.6352\n",
      "[324/1762] D loss: 1.3806, G loss: 0.6344\n",
      "[404/1762] D loss: 1.3729, G loss: 0.6694\n",
      "[484/1762] D loss: 0.0906, G loss: 3.5795\n",
      "[564/1762] D loss: 0.0592, G loss: 3.6039\n",
      "[644/1762] D loss: 1.3857, G loss: 0.6643\n",
      "[724/1762] D loss: 0.0290, G loss: 4.3767\n",
      "[804/1762] D loss: 1.3643, G loss: 0.7047\n",
      "[884/1762] D loss: 1.4118, G loss: 0.6936\n",
      "[964/1762] D loss: 1.4961, G loss: 0.5017\n",
      "[1044/1762] D loss: 1.2857, G loss: 0.8599\n",
      "[1124/1762] D loss: 0.0580, G loss: 4.0033\n",
      "[1204/1762] D loss: 1.4488, G loss: 0.5351\n",
      "[1284/1762] D loss: 1.4181, G loss: 0.6573\n",
      "[1364/1762] D loss: 1.4787, G loss: 1.0030\n",
      "[1444/1762] D loss: 1.3358, G loss: 0.8716\n",
      "[1524/1762] D loss: 1.3206, G loss: 0.7918\n",
      "[1604/1762] D loss: 1.3622, G loss: 0.7540\n",
      "[1684/1762] D loss: 1.4268, G loss: 0.5275\n",
      "[1762/1762] D loss: 1.4187, G loss: 0.7560\n",
      "train error: \n",
      " D loss: 1.326410, G loss: 1.045106, D accuracy: 57.9%, cell accuracy: 99.8%, board accuracy: 91.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.283376, G loss: 1.214258, D accuracy: 58.9%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0345, G loss: 4.5672\n",
      "[84/1762] D loss: 1.2884, G loss: 0.6946\n",
      "[164/1762] D loss: 1.3757, G loss: 0.7668\n",
      "[244/1762] D loss: 1.2819, G loss: 0.7616\n",
      "[324/1762] D loss: 0.0398, G loss: 3.9170\n",
      "[404/1762] D loss: 0.0754, G loss: 3.4548\n",
      "[484/1762] D loss: 1.3370, G loss: 0.6175\n",
      "[564/1762] D loss: 1.3621, G loss: 0.8555\n",
      "[644/1762] D loss: 0.0531, G loss: 3.7868\n",
      "[724/1762] D loss: 1.4365, G loss: 0.7064\n",
      "[804/1762] D loss: 0.0030, G loss: 6.1883\n",
      "[884/1762] D loss: 0.0694, G loss: 3.8005\n",
      "[964/1762] D loss: 0.8098, G loss: 3.6057\n",
      "[1044/1762] D loss: 0.0384, G loss: 3.8755\n",
      "[1124/1762] D loss: 1.2888, G loss: 0.7379\n",
      "[1204/1762] D loss: 1.3564, G loss: 0.6969\n",
      "[1284/1762] D loss: 1.2718, G loss: 1.1548\n",
      "[1364/1762] D loss: 1.3240, G loss: 0.8346\n",
      "[1444/1762] D loss: 0.0421, G loss: 3.7071\n",
      "[1524/1762] D loss: 1.5787, G loss: 0.5507\n",
      "[1604/1762] D loss: 1.1090, G loss: 0.8907\n",
      "[1684/1762] D loss: 1.3115, G loss: 1.0361\n",
      "[1762/1762] D loss: 0.0009, G loss: 7.9421\n",
      "train error: \n",
      " D loss: 1.884791, G loss: 0.664413, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 91.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.789950, G loss: 0.771922, D accuracy: 55.7%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0444, G loss: 4.3873\n",
      "[84/1762] D loss: 0.0034, G loss: 5.4708\n",
      "[164/1762] D loss: 1.3862, G loss: 0.4118\n",
      "[244/1762] D loss: 1.2253, G loss: 0.9792\n",
      "[324/1762] D loss: 1.3490, G loss: 0.6996\n",
      "[404/1762] D loss: 1.3032, G loss: 1.0091\n",
      "[484/1762] D loss: 1.4126, G loss: 0.7267\n",
      "[564/1762] D loss: 1.2513, G loss: 0.8877\n",
      "[644/1762] D loss: 1.4751, G loss: 0.4945\n",
      "[724/1762] D loss: 1.1534, G loss: 0.8947\n",
      "[804/1762] D loss: 1.2830, G loss: 0.7995\n",
      "[884/1762] D loss: 1.2542, G loss: 0.9242\n",
      "[964/1762] D loss: 0.0461, G loss: 4.4217\n",
      "[1044/1762] D loss: 1.2478, G loss: 1.1133\n",
      "[1124/1762] D loss: 1.1258, G loss: 1.4637\n",
      "[1204/1762] D loss: 1.4737, G loss: 0.7990\n",
      "[1284/1762] D loss: 0.0417, G loss: 4.1438\n",
      "[1364/1762] D loss: 0.0386, G loss: 3.9206\n",
      "[1444/1762] D loss: 1.0933, G loss: 1.2171\n",
      "[1524/1762] D loss: 1.4014, G loss: 0.5905\n",
      "[1604/1762] D loss: 1.4034, G loss: 0.5721\n",
      "[1684/1762] D loss: 1.4746, G loss: 1.1862\n",
      "[1762/1762] D loss: 1.2090, G loss: 1.2523\n",
      "train error: \n",
      " D loss: 1.495551, G loss: 1.050793, D accuracy: 56.3%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.418448, G loss: 1.203859, D accuracy: 59.2%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7719, G loss: 1.0734\n",
      "[84/1762] D loss: 1.2062, G loss: 1.0330\n",
      "[164/1762] D loss: 0.9979, G loss: 0.9662\n",
      "[244/1762] D loss: 1.1724, G loss: 0.8925\n",
      "[324/1762] D loss: 1.2207, G loss: 0.7705\n",
      "[404/1762] D loss: 0.0017, G loss: 7.0252\n",
      "[484/1762] D loss: 1.0356, G loss: 0.7625\n",
      "[564/1762] D loss: 0.8197, G loss: 3.5372\n",
      "[644/1762] D loss: 0.7989, G loss: 1.2858\n",
      "[724/1762] D loss: 0.0457, G loss: 4.3359\n",
      "[804/1762] D loss: 0.0027, G loss: 6.5935\n",
      "[884/1762] D loss: 1.3317, G loss: 1.0022\n",
      "[964/1762] D loss: 1.1295, G loss: 0.8272\n",
      "[1044/1762] D loss: 0.0223, G loss: 5.0765\n",
      "[1124/1762] D loss: 0.0325, G loss: 4.2351\n",
      "[1204/1762] D loss: 0.0331, G loss: 4.3008\n",
      "[1284/1762] D loss: 0.9499, G loss: 1.5338\n",
      "[1364/1762] D loss: 1.6596, G loss: 1.6084\n",
      "[1444/1762] D loss: 0.9057, G loss: 1.0197\n",
      "[1524/1762] D loss: 0.0257, G loss: 4.7579\n",
      "[1604/1762] D loss: 0.0388, G loss: 4.2323\n",
      "[1684/1762] D loss: 0.9802, G loss: 2.3125\n",
      "[1762/1762] D loss: 1.0643, G loss: 2.1383\n",
      "train error: \n",
      " D loss: 3.520857, G loss: 0.924261, D accuracy: 49.9%, cell accuracy: 99.9%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 3.367547, G loss: 0.873127, D accuracy: 51.0%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4335, G loss: 2.3329\n",
      "[84/1762] D loss: 0.9153, G loss: 2.1035\n",
      "[164/1762] D loss: 0.9967, G loss: 0.9217\n",
      "[244/1762] D loss: 0.9262, G loss: 1.5182\n",
      "[324/1762] D loss: 0.2349, G loss: 2.4681\n",
      "[404/1762] D loss: 0.0609, G loss: 4.6142\n",
      "[484/1762] D loss: 0.2437, G loss: 3.2414\n",
      "[564/1762] D loss: 1.4258, G loss: 1.5691\n",
      "[644/1762] D loss: 0.1271, G loss: 5.1133\n",
      "[724/1762] D loss: 0.4169, G loss: 1.6306\n",
      "[804/1762] D loss: 0.0471, G loss: 4.6145\n",
      "[884/1762] D loss: 0.9432, G loss: 2.4737\n",
      "[964/1762] D loss: 0.4933, G loss: 1.8553\n",
      "[1044/1762] D loss: 0.1254, G loss: 4.1729\n",
      "[1124/1762] D loss: 0.2594, G loss: 4.8843\n",
      "[1204/1762] D loss: 0.8772, G loss: 1.3615\n",
      "[1284/1762] D loss: 0.5404, G loss: 3.7660\n",
      "[1364/1762] D loss: 0.0258, G loss: 4.7527\n",
      "[1444/1762] D loss: 0.0037, G loss: 6.5585\n",
      "[1524/1762] D loss: 0.0130, G loss: 5.7455\n",
      "[1604/1762] D loss: 0.6662, G loss: 1.4059\n",
      "[1684/1762] D loss: 0.2699, G loss: 2.4043\n",
      "[1762/1762] D loss: 0.0933, G loss: 3.9125\n",
      "train error: \n",
      " D loss: 1.189457, G loss: 1.619161, D accuracy: 68.8%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.177820, G loss: 1.735675, D accuracy: 69.7%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1837, G loss: 3.1061\n",
      "[84/1762] D loss: 0.4058, G loss: 3.1441\n",
      "[164/1762] D loss: 0.4211, G loss: 6.6494\n",
      "[244/1762] D loss: 0.0624, G loss: 4.7648\n",
      "[324/1762] D loss: 0.7152, G loss: 1.5259\n",
      "[404/1762] D loss: 0.0148, G loss: 4.7989\n",
      "[484/1762] D loss: 0.2540, G loss: 2.2644\n",
      "[564/1762] D loss: 0.2891, G loss: 3.2173\n",
      "[644/1762] D loss: 0.0054, G loss: 8.3189\n",
      "[724/1762] D loss: 0.3678, G loss: 4.0520\n",
      "[804/1762] D loss: 0.6728, G loss: 1.8857\n",
      "[884/1762] D loss: 0.1219, G loss: 2.6409\n",
      "[964/1762] D loss: 0.8639, G loss: 4.6023\n",
      "[1044/1762] D loss: 0.3234, G loss: 1.6659\n",
      "[1124/1762] D loss: 0.2174, G loss: 2.6089\n",
      "[1204/1762] D loss: 1.1160, G loss: 0.3090\n",
      "[1284/1762] D loss: 0.0018, G loss: 6.7855\n",
      "[1364/1762] D loss: 0.0568, G loss: 3.5766\n",
      "[1444/1762] D loss: 0.7267, G loss: 1.4519\n",
      "[1524/1762] D loss: 0.3601, G loss: 2.2101\n",
      "[1604/1762] D loss: 0.0481, G loss: 5.1666\n",
      "[1684/1762] D loss: 1.1958, G loss: 3.0880\n",
      "[1762/1762] D loss: 0.0005, G loss: 9.6202\n",
      "train error: \n",
      " D loss: 3.577524, G loss: 0.515938, D accuracy: 52.6%, cell accuracy: 99.8%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 3.385336, G loss: 0.482056, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3360, G loss: 3.0963\n",
      "[84/1762] D loss: 0.4139, G loss: 1.4772\n",
      "[164/1762] D loss: 0.2681, G loss: 3.2310\n",
      "[244/1762] D loss: 1.2097, G loss: 1.3227\n",
      "[324/1762] D loss: 1.2509, G loss: 3.2502\n",
      "[404/1762] D loss: 0.1699, G loss: 5.9964\n",
      "[484/1762] D loss: 0.0963, G loss: 3.7955\n",
      "[564/1762] D loss: 0.0042, G loss: 8.5831\n",
      "[644/1762] D loss: 0.0088, G loss: 5.5491\n",
      "[724/1762] D loss: 0.0025, G loss: 8.0630\n",
      "[804/1762] D loss: 0.5722, G loss: 2.3807\n",
      "[884/1762] D loss: 0.2446, G loss: 5.4964\n",
      "[964/1762] D loss: 0.0713, G loss: 5.6065\n",
      "[1044/1762] D loss: 0.0268, G loss: 7.0632\n",
      "[1124/1762] D loss: 0.0061, G loss: 8.5559\n",
      "[1204/1762] D loss: 0.0069, G loss: 6.8350\n",
      "[1284/1762] D loss: 0.0008, G loss: 8.2394\n",
      "[1364/1762] D loss: 0.0033, G loss: 6.9723\n",
      "[1444/1762] D loss: 0.6651, G loss: 4.0636\n",
      "[1524/1762] D loss: 0.0290, G loss: 5.8607\n",
      "[1604/1762] D loss: 0.0010, G loss: 9.8089\n",
      "[1684/1762] D loss: 0.3611, G loss: 2.6781\n",
      "[1762/1762] D loss: 0.0485, G loss: 4.5755\n",
      "train error: \n",
      " D loss: 17.850441, G loss: 22.995500, D accuracy: 53.1%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 17.387736, G loss: 22.832627, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1531, G loss: 6.8112\n",
      "[84/1762] D loss: 0.7637, G loss: 4.0988\n",
      "[164/1762] D loss: 0.2397, G loss: 2.8992\n",
      "[244/1762] D loss: 0.0914, G loss: 4.4318\n",
      "[324/1762] D loss: 0.1083, G loss: 4.5395\n",
      "[404/1762] D loss: 0.4851, G loss: 3.2446\n",
      "[484/1762] D loss: 0.3675, G loss: 3.8524\n",
      "[564/1762] D loss: 0.0385, G loss: 5.8819\n",
      "[644/1762] D loss: 0.0169, G loss: 6.1814\n",
      "[724/1762] D loss: 0.0037, G loss: 8.4614\n",
      "[804/1762] D loss: 0.0338, G loss: 7.3959\n",
      "[884/1762] D loss: 0.0498, G loss: 7.1592\n",
      "[964/1762] D loss: 0.3056, G loss: 2.8046\n",
      "[1044/1762] D loss: 0.0010, G loss: 9.7287\n",
      "[1124/1762] D loss: 1.2981, G loss: 1.2186\n",
      "[1204/1762] D loss: 0.0560, G loss: 3.4105\n",
      "[1284/1762] D loss: 0.0043, G loss: 6.1926\n",
      "[1364/1762] D loss: 0.0136, G loss: 5.7609\n",
      "[1444/1762] D loss: 0.1486, G loss: 3.9020\n",
      "[1524/1762] D loss: 0.0399, G loss: 6.2375\n",
      "[1604/1762] D loss: 0.0114, G loss: 6.4025\n",
      "[1684/1762] D loss: 0.0242, G loss: 5.0788\n",
      "[1762/1762] D loss: 0.7372, G loss: 1.3119\n",
      "train error: \n",
      " D loss: 1.177251, G loss: 3.109540, D accuracy: 68.2%, cell accuracy: 99.8%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.122993, G loss: 3.393595, D accuracy: 69.8%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5324, G loss: 5.4447\n",
      "[84/1762] D loss: 0.0087, G loss: 6.2887\n",
      "[164/1762] D loss: 0.0059, G loss: 7.5335\n",
      "[244/1762] D loss: 0.0011, G loss: 10.8772\n",
      "[324/1762] D loss: 0.0712, G loss: 5.1270\n",
      "[404/1762] D loss: 0.0132, G loss: 6.8706\n",
      "[484/1762] D loss: 0.0017, G loss: 7.9140\n",
      "[564/1762] D loss: 0.0076, G loss: 6.9585\n",
      "[644/1762] D loss: 0.0404, G loss: 8.4326\n",
      "[724/1762] D loss: 0.0468, G loss: 5.3204\n",
      "[804/1762] D loss: 0.0019, G loss: 8.2357\n",
      "[884/1762] D loss: 0.0162, G loss: 7.1519\n",
      "[964/1762] D loss: 0.0387, G loss: 7.7573\n",
      "[1044/1762] D loss: 0.0565, G loss: 5.0282\n",
      "[1124/1762] D loss: 0.4193, G loss: 6.9493\n",
      "[1204/1762] D loss: 0.0169, G loss: 5.9680\n",
      "[1284/1762] D loss: 0.1748, G loss: 3.0185\n",
      "[1364/1762] D loss: 0.0709, G loss: 5.4351\n",
      "[1444/1762] D loss: 0.3798, G loss: 1.7072\n",
      "[1524/1762] D loss: 1.6580, G loss: 3.5118\n",
      "[1604/1762] D loss: 2.0540, G loss: 3.1376\n",
      "[1684/1762] D loss: 0.2305, G loss: 2.1513\n",
      "[1762/1762] D loss: 0.1064, G loss: 3.1164\n",
      "train error: \n",
      " D loss: 5.388288, G loss: 0.810445, D accuracy: 52.0%, cell accuracy: 99.8%, board accuracy: 91.0% \n",
      "\n",
      "test error: \n",
      " D loss: 5.279337, G loss: 0.903369, D accuracy: 52.4%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0011, G loss: 7.4307\n",
      "[84/1762] D loss: 0.2532, G loss: 2.5118\n",
      "[164/1762] D loss: 0.0118, G loss: 4.9590\n",
      "[244/1762] D loss: 0.1839, G loss: 3.0660\n",
      "[324/1762] D loss: 0.1333, G loss: 4.5562\n",
      "[404/1762] D loss: 0.1084, G loss: 5.9661\n",
      "[484/1762] D loss: 0.0016, G loss: 6.9373\n",
      "[564/1762] D loss: 0.0062, G loss: 6.9511\n",
      "[644/1762] D loss: 0.6106, G loss: 3.7832\n",
      "[724/1762] D loss: 0.3018, G loss: 2.9233\n",
      "[804/1762] D loss: 0.0535, G loss: 4.0146\n",
      "[884/1762] D loss: 0.0010, G loss: 8.5196\n",
      "[964/1762] D loss: 0.0625, G loss: 4.8172\n",
      "[1044/1762] D loss: 0.0120, G loss: 7.3057\n",
      "[1124/1762] D loss: 0.0006, G loss: 8.6744\n",
      "[1204/1762] D loss: 1.5446, G loss: 3.8616\n",
      "[1284/1762] D loss: 0.0635, G loss: 6.3901\n",
      "[1364/1762] D loss: 0.0041, G loss: 5.6056\n",
      "[1444/1762] D loss: 0.0532, G loss: 5.3155\n",
      "[1524/1762] D loss: 0.0986, G loss: 5.9411\n",
      "[1604/1762] D loss: 0.3449, G loss: 3.3048\n",
      "[1684/1762] D loss: 0.0140, G loss: 6.0180\n",
      "[1762/1762] D loss: 0.0061, G loss: 6.6508\n",
      "train error: \n",
      " D loss: 2.883262, G loss: 5.633320, D accuracy: 66.7%, cell accuracy: 99.9%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 2.876874, G loss: 6.002327, D accuracy: 66.5%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0150, G loss: 5.5213\n",
      "[84/1762] D loss: 0.1795, G loss: 3.1233\n",
      "[164/1762] D loss: 0.2541, G loss: 2.5798\n",
      "[244/1762] D loss: 0.0022, G loss: 9.0672\n",
      "[324/1762] D loss: 0.6161, G loss: 2.2071\n",
      "[404/1762] D loss: 0.0209, G loss: 5.2940\n",
      "[484/1762] D loss: 0.6325, G loss: 2.9459\n",
      "[564/1762] D loss: 0.7712, G loss: 2.8836\n",
      "[644/1762] D loss: 0.0017, G loss: 10.5088\n",
      "[724/1762] D loss: 0.0018, G loss: 7.7154\n",
      "[804/1762] D loss: 0.0973, G loss: 4.8297\n",
      "[884/1762] D loss: 0.0012, G loss: 8.9346\n",
      "[964/1762] D loss: 0.0371, G loss: 4.7040\n",
      "[1044/1762] D loss: 1.3112, G loss: 1.8969\n",
      "[1124/1762] D loss: 0.1192, G loss: 3.6753\n",
      "[1204/1762] D loss: 0.0148, G loss: 6.0234\n",
      "[1284/1762] D loss: 0.5905, G loss: 2.0181\n",
      "[1364/1762] D loss: 0.0177, G loss: 8.7405\n",
      "[1444/1762] D loss: 0.0108, G loss: 7.5704\n",
      "[1524/1762] D loss: 0.0002, G loss: 12.3497\n",
      "[1604/1762] D loss: 0.0393, G loss: 4.5177\n",
      "[1684/1762] D loss: 0.0165, G loss: 6.0942\n",
      "[1762/1762] D loss: 0.0045, G loss: 9.6590\n",
      "train error: \n",
      " D loss: 2.244426, G loss: 2.905226, D accuracy: 59.9%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 2.269354, G loss: 3.060909, D accuracy: 61.0%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0012, G loss: 8.0004\n",
      "[84/1762] D loss: 0.0047, G loss: 8.4680\n",
      "[164/1762] D loss: 0.0082, G loss: 9.0357\n",
      "[244/1762] D loss: 0.0027, G loss: 7.4136\n",
      "[324/1762] D loss: 0.0040, G loss: 9.0806\n",
      "[404/1762] D loss: 0.0235, G loss: 8.5215\n",
      "[484/1762] D loss: 0.0161, G loss: 6.6121\n",
      "[564/1762] D loss: 0.0544, G loss: 6.7007\n",
      "[644/1762] D loss: 0.0002, G loss: 12.4569\n",
      "[724/1762] D loss: 0.0010, G loss: 8.5555\n",
      "[804/1762] D loss: 0.0006, G loss: 12.2835\n",
      "[884/1762] D loss: 0.2636, G loss: 2.8378\n",
      "[964/1762] D loss: 0.0018, G loss: 11.6837\n",
      "[1044/1762] D loss: 0.0023, G loss: 7.1785\n",
      "[1124/1762] D loss: 0.0002, G loss: 11.7619\n",
      "[1204/1762] D loss: 0.0002, G loss: 10.1384\n",
      "[1284/1762] D loss: 0.0001, G loss: 10.9316\n",
      "[1364/1762] D loss: 0.1238, G loss: 10.1555\n",
      "[1444/1762] D loss: 0.2353, G loss: 11.5999\n",
      "[1524/1762] D loss: 0.0004, G loss: 12.3423\n",
      "[1604/1762] D loss: 0.1579, G loss: 4.6479\n",
      "[1684/1762] D loss: 0.0002, G loss: 11.0021\n",
      "[1762/1762] D loss: 1.9798, G loss: 1.6727\n",
      "train error: \n",
      " D loss: 4.692780, G loss: 5.992721, D accuracy: 64.1%, cell accuracy: 99.8%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 4.592610, G loss: 6.028159, D accuracy: 63.6%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.9066, G loss: 5.4715\n",
      "[84/1762] D loss: 0.3855, G loss: 4.9255\n",
      "[164/1762] D loss: 0.5917, G loss: 5.2955\n",
      "[244/1762] D loss: 0.0116, G loss: 6.7284\n",
      "[324/1762] D loss: 0.5396, G loss: 2.4810\n",
      "[404/1762] D loss: 0.5606, G loss: 2.7062\n",
      "[484/1762] D loss: 0.0836, G loss: 4.2506\n",
      "[564/1762] D loss: 0.0877, G loss: 7.7109\n",
      "[644/1762] D loss: 0.0258, G loss: 7.7768\n",
      "[724/1762] D loss: 0.0022, G loss: 7.2814\n",
      "[804/1762] D loss: 0.3329, G loss: 5.0012\n",
      "[884/1762] D loss: 0.0007, G loss: 10.8892\n",
      "[964/1762] D loss: 0.1439, G loss: 4.3961\n",
      "[1044/1762] D loss: 0.0799, G loss: 5.8332\n",
      "[1124/1762] D loss: 0.0050, G loss: 7.6478\n",
      "[1204/1762] D loss: 0.0007, G loss: 11.7825\n",
      "[1284/1762] D loss: 0.0141, G loss: 7.0323\n",
      "[1364/1762] D loss: 0.0007, G loss: 8.3021\n",
      "[1444/1762] D loss: 0.0144, G loss: 5.2890\n",
      "[1524/1762] D loss: 0.0002, G loss: 9.4653\n",
      "[1604/1762] D loss: 0.0238, G loss: 7.4342\n",
      "[1684/1762] D loss: 0.0174, G loss: 3.8942\n",
      "[1762/1762] D loss: 0.0029, G loss: 7.1223\n",
      "train error: \n",
      " D loss: 3.348457, G loss: 5.089620, D accuracy: 64.3%, cell accuracy: 99.9%, board accuracy: 91.2% \n",
      "\n",
      "test error: \n",
      " D loss: 3.349649, G loss: 5.155191, D accuracy: 63.6%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0031, G loss: 8.7546\n",
      "[84/1762] D loss: 0.0142, G loss: 8.4532\n",
      "[164/1762] D loss: 0.0013, G loss: 9.8304\n",
      "[244/1762] D loss: 0.0009, G loss: 8.4082\n",
      "[324/1762] D loss: 0.0008, G loss: 10.1656\n",
      "[404/1762] D loss: 0.0087, G loss: 9.0632\n",
      "[484/1762] D loss: 0.4047, G loss: 1.9251\n",
      "[564/1762] D loss: 0.0073, G loss: 9.2736\n",
      "[644/1762] D loss: 0.0028, G loss: 8.9269\n",
      "[724/1762] D loss: 0.0294, G loss: 5.6515\n",
      "[804/1762] D loss: 0.0002, G loss: 9.3112\n",
      "[884/1762] D loss: 0.4303, G loss: 8.0204\n",
      "[964/1762] D loss: 0.1106, G loss: 3.5678\n",
      "[1044/1762] D loss: 0.0015, G loss: 10.6479\n",
      "[1124/1762] D loss: 0.0002, G loss: 12.1208\n",
      "[1204/1762] D loss: 0.0026, G loss: 10.0828\n",
      "[1284/1762] D loss: 0.0056, G loss: 11.3145\n",
      "[1364/1762] D loss: 0.0001, G loss: 11.0916\n",
      "[1444/1762] D loss: 0.0184, G loss: 8.5963\n",
      "[1524/1762] D loss: 0.0028, G loss: 6.4898\n",
      "[1604/1762] D loss: 0.0147, G loss: 5.7695\n",
      "[1684/1762] D loss: 0.0018, G loss: 10.5610\n",
      "[1762/1762] D loss: 0.3148, G loss: 4.3533\n",
      "train error: \n",
      " D loss: 3.936710, G loss: 6.982556, D accuracy: 72.3%, cell accuracy: 99.8%, board accuracy: 91.0% \n",
      "\n",
      "test error: \n",
      " D loss: 4.169964, G loss: 7.079978, D accuracy: 71.9%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0581, G loss: 8.1470\n",
      "[84/1762] D loss: 0.0452, G loss: 6.9159\n",
      "[164/1762] D loss: 0.0004, G loss: 8.5165\n",
      "[244/1762] D loss: 0.0000, G loss: 12.8923\n",
      "[324/1762] D loss: 0.0691, G loss: 7.5938\n",
      "[404/1762] D loss: 0.0014, G loss: 7.8265\n",
      "[484/1762] D loss: 0.0110, G loss: 7.7426\n",
      "[564/1762] D loss: 0.0001, G loss: 12.4968\n",
      "[644/1762] D loss: 0.1405, G loss: 3.0588\n",
      "[724/1762] D loss: 0.0013, G loss: 10.2745\n",
      "[804/1762] D loss: 0.0152, G loss: 8.0750\n",
      "[884/1762] D loss: 0.0010, G loss: 8.8833\n",
      "[964/1762] D loss: 1.6673, G loss: 2.2164\n",
      "[1044/1762] D loss: 0.6521, G loss: 6.1527\n",
      "[1124/1762] D loss: 0.0020, G loss: 10.8145\n",
      "[1204/1762] D loss: 0.0019, G loss: 11.0594\n",
      "[1284/1762] D loss: 0.0007, G loss: 7.9830\n",
      "[1364/1762] D loss: 0.0215, G loss: 7.0375\n",
      "[1444/1762] D loss: 0.0001, G loss: 10.0349\n",
      "[1524/1762] D loss: 0.0672, G loss: 6.1229\n",
      "[1604/1762] D loss: 0.0020, G loss: 9.0691\n",
      "[1684/1762] D loss: 0.3661, G loss: 3.5525\n",
      "[1762/1762] D loss: 0.0098, G loss: 10.7518\n",
      "train error: \n",
      " D loss: 3.854792, G loss: 4.726565, D accuracy: 66.6%, cell accuracy: 99.9%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 3.966498, G loss: 4.945044, D accuracy: 67.0%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9026, G loss: 3.9089\n",
      "[84/1762] D loss: 0.0009, G loss: 9.2289\n",
      "[164/1762] D loss: 0.0048, G loss: 9.6206\n",
      "[244/1762] D loss: 0.0035, G loss: 6.4255\n",
      "[324/1762] D loss: 0.0206, G loss: 8.7370\n",
      "[404/1762] D loss: 0.0035, G loss: 9.4378\n",
      "[484/1762] D loss: 0.0032, G loss: 6.7041\n",
      "[564/1762] D loss: 0.0033, G loss: 9.8907\n",
      "[644/1762] D loss: 0.0307, G loss: 5.8648\n",
      "[724/1762] D loss: 0.0040, G loss: 9.3643\n",
      "[804/1762] D loss: 0.0169, G loss: 6.4602\n",
      "[884/1762] D loss: 0.2179, G loss: 4.8548\n",
      "[964/1762] D loss: 0.0352, G loss: 4.5000\n",
      "[1044/1762] D loss: 0.1145, G loss: 3.7033\n",
      "[1124/1762] D loss: 1.9571, G loss: 0.2617\n",
      "[1204/1762] D loss: 3.7745, G loss: 0.2657\n",
      "[1284/1762] D loss: 0.0054, G loss: 8.8923\n",
      "[1364/1762] D loss: 0.0242, G loss: 5.3450\n",
      "[1444/1762] D loss: 0.0001, G loss: 10.2124\n",
      "[1524/1762] D loss: 0.0090, G loss: 6.1608\n",
      "[1604/1762] D loss: 0.0043, G loss: 9.3654\n",
      "[1684/1762] D loss: 0.0004, G loss: 8.3667\n",
      "[1762/1762] D loss: 0.0257, G loss: 5.2464\n",
      "train error: \n",
      " D loss: 2.223028, G loss: 4.669894, D accuracy: 70.4%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 2.323119, G loss: 4.826237, D accuracy: 70.9%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0002, G loss: 11.3488\n",
      "[84/1762] D loss: 0.1014, G loss: 3.5840\n",
      "[164/1762] D loss: 0.0694, G loss: 2.9779\n",
      "[244/1762] D loss: 0.0029, G loss: 9.9808\n",
      "[324/1762] D loss: 0.0279, G loss: 4.8702\n",
      "[404/1762] D loss: 0.0675, G loss: 6.3318\n",
      "[484/1762] D loss: 0.0003, G loss: 10.6228\n",
      "[564/1762] D loss: 0.0035, G loss: 10.2964\n",
      "[644/1762] D loss: 0.0124, G loss: 8.3481\n",
      "[724/1762] D loss: 0.0093, G loss: 7.1937\n",
      "[804/1762] D loss: 0.0017, G loss: 8.7274\n",
      "[884/1762] D loss: 0.0004, G loss: 9.9516\n",
      "[964/1762] D loss: 2.1837, G loss: 0.8344\n",
      "[1044/1762] D loss: 0.0047, G loss: 6.5286\n",
      "[1124/1762] D loss: 0.0011, G loss: 8.7402\n",
      "[1204/1762] D loss: 0.0277, G loss: 6.9487\n",
      "[1284/1762] D loss: 0.0002, G loss: 11.3745\n",
      "[1364/1762] D loss: 0.0010, G loss: 9.8095\n",
      "[1444/1762] D loss: 0.0032, G loss: 10.1806\n",
      "[1524/1762] D loss: 0.0005, G loss: 10.3277\n",
      "[1604/1762] D loss: 0.0047, G loss: 6.8778\n",
      "[1684/1762] D loss: 0.0012, G loss: 11.9371\n",
      "[1762/1762] D loss: 0.0004, G loss: 9.2230\n",
      "train error: \n",
      " D loss: 2.210452, G loss: 3.110627, D accuracy: 67.6%, cell accuracy: 99.8%, board accuracy: 91.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.249121, G loss: 3.272335, D accuracy: 67.7%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001, G loss: 12.6182\n",
      "[84/1762] D loss: 0.0260, G loss: 6.1535\n",
      "[164/1762] D loss: 0.0371, G loss: 3.7637\n",
      "[244/1762] D loss: 0.9432, G loss: 7.0569\n",
      "[324/1762] D loss: 0.0274, G loss: 7.8044\n",
      "[404/1762] D loss: 0.0010, G loss: 5.1546\n",
      "[484/1762] D loss: 0.2675, G loss: 4.6574\n",
      "[564/1762] D loss: 1.5200, G loss: 1.8154\n",
      "[644/1762] D loss: 0.9110, G loss: 3.2853\n",
      "[724/1762] D loss: 1.1033, G loss: 1.4856\n",
      "[804/1762] D loss: 1.4207, G loss: 1.7952\n",
      "[884/1762] D loss: 0.0010, G loss: 7.5234\n",
      "[964/1762] D loss: 0.0123, G loss: 7.3857\n",
      "[1044/1762] D loss: 0.0040, G loss: 7.6189\n",
      "[1124/1762] D loss: 0.0142, G loss: 6.8648\n",
      "[1204/1762] D loss: 0.0067, G loss: 6.7072\n",
      "[1284/1762] D loss: 0.0228, G loss: 5.9547\n",
      "[1364/1762] D loss: 0.0004, G loss: 10.5895\n",
      "[1444/1762] D loss: 1.2531, G loss: 1.4550\n",
      "[1524/1762] D loss: 0.0828, G loss: 10.2943\n",
      "[1604/1762] D loss: 0.0090, G loss: 7.6870\n",
      "[1684/1762] D loss: 0.0875, G loss: 2.8230\n",
      "[1762/1762] D loss: 0.0040, G loss: 9.7570\n",
      "train error: \n",
      " D loss: 2.970724, G loss: 5.224401, D accuracy: 69.7%, cell accuracy: 99.9%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 3.112264, G loss: 5.423262, D accuracy: 70.5%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0033, G loss: 10.8104\n",
      "[84/1762] D loss: 0.0147, G loss: 7.0268\n",
      "[164/1762] D loss: 0.0122, G loss: 5.9317\n",
      "[244/1762] D loss: 0.0002, G loss: 10.3703\n",
      "[324/1762] D loss: 0.0055, G loss: 8.2397\n",
      "[404/1762] D loss: 0.0001, G loss: 13.4083\n",
      "[484/1762] D loss: 0.0840, G loss: 4.2513\n",
      "[564/1762] D loss: 0.0256, G loss: 6.9472\n",
      "[644/1762] D loss: 0.0019, G loss: 10.1016\n",
      "[724/1762] D loss: 0.0022, G loss: 8.0398\n",
      "[804/1762] D loss: 0.0225, G loss: 7.7749\n",
      "[884/1762] D loss: 0.0029, G loss: 6.8442\n",
      "[964/1762] D loss: 0.0019, G loss: 7.8534\n",
      "[1044/1762] D loss: 0.0067, G loss: 9.9971\n",
      "[1124/1762] D loss: 0.5992, G loss: 4.6100\n",
      "[1204/1762] D loss: 0.1536, G loss: 6.0160\n",
      "[1284/1762] D loss: 0.0024, G loss: 11.2443\n",
      "[1364/1762] D loss: 0.0436, G loss: 4.1458\n",
      "[1444/1762] D loss: 0.0001, G loss: 13.6712\n",
      "[1524/1762] D loss: 0.0051, G loss: 8.4348\n",
      "[1604/1762] D loss: 0.0220, G loss: 11.3062\n",
      "[1684/1762] D loss: 0.0043, G loss: 10.8408\n",
      "[1762/1762] D loss: 0.0012, G loss: 12.8377\n",
      "train error: \n",
      " D loss: 3.905467, G loss: 6.766729, D accuracy: 68.5%, cell accuracy: 99.9%, board accuracy: 91.2% \n",
      "\n",
      "test error: \n",
      " D loss: 4.082862, G loss: 6.917203, D accuracy: 69.5%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001, G loss: 12.3121\n",
      "[84/1762] D loss: 0.0024, G loss: 9.5309\n",
      "[164/1762] D loss: 0.0087, G loss: 8.2849\n",
      "[244/1762] D loss: 0.0213, G loss: 7.3216\n",
      "[324/1762] D loss: 0.8462, G loss: 2.0603\n",
      "[404/1762] D loss: 0.0098, G loss: 9.6595\n",
      "[484/1762] D loss: 0.2279, G loss: 10.5219\n",
      "[564/1762] D loss: 0.4122, G loss: 4.4261\n",
      "[644/1762] D loss: 0.0042, G loss: 8.4267\n",
      "[724/1762] D loss: 0.0207, G loss: 6.1656\n",
      "[804/1762] D loss: 0.0002, G loss: 11.0484\n",
      "[884/1762] D loss: 0.2005, G loss: 9.7678\n",
      "[964/1762] D loss: 0.0306, G loss: 5.4896\n",
      "[1044/1762] D loss: 0.0064, G loss: 10.6430\n",
      "[1124/1762] D loss: 0.0183, G loss: 5.3531\n",
      "[1204/1762] D loss: 0.0050, G loss: 7.0533\n",
      "[1284/1762] D loss: 0.0002, G loss: 10.5564\n",
      "[1364/1762] D loss: 0.0651, G loss: 4.6069\n",
      "[1444/1762] D loss: 0.0004, G loss: 10.4904\n",
      "[1524/1762] D loss: 0.0006, G loss: 10.6677\n",
      "[1604/1762] D loss: 1.2387, G loss: 1.7981\n",
      "[1684/1762] D loss: 0.0001, G loss: 13.5328\n",
      "[1762/1762] D loss: 0.0000, G loss: 14.1630\n",
      "train error: \n",
      " D loss: 2.022921, G loss: 4.079003, D accuracy: 62.4%, cell accuracy: 99.9%, board accuracy: 91.2% \n",
      "\n",
      "test error: \n",
      " D loss: 2.041092, G loss: 4.175944, D accuracy: 61.1%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1657, G loss: 3.5756\n",
      "[84/1762] D loss: 0.0167, G loss: 10.1518\n",
      "[164/1762] D loss: 0.0008, G loss: 10.2829\n",
      "[244/1762] D loss: 0.0013, G loss: 13.3327\n",
      "[324/1762] D loss: 0.0020, G loss: 11.1862\n",
      "[404/1762] D loss: 0.0014, G loss: 11.8140\n",
      "[484/1762] D loss: 0.0024, G loss: 9.3508\n",
      "[564/1762] D loss: 0.0120, G loss: 6.4473\n",
      "[644/1762] D loss: 0.0069, G loss: 13.1975\n",
      "[724/1762] D loss: 0.0004, G loss: 13.5936\n",
      "[804/1762] D loss: 0.0001, G loss: 10.9152\n",
      "[884/1762] D loss: 0.0001, G loss: 13.3066\n",
      "[964/1762] D loss: 0.0001, G loss: 13.4564\n",
      "[1044/1762] D loss: 0.0033, G loss: 11.7384\n",
      "[1124/1762] D loss: 0.0007, G loss: 11.1825\n",
      "[1204/1762] D loss: 0.0024, G loss: 10.9324\n",
      "[1284/1762] D loss: 0.0177, G loss: 7.8015\n",
      "[1364/1762] D loss: 0.0038, G loss: 8.9430\n",
      "[1444/1762] D loss: 0.0058, G loss: 7.8872\n",
      "[1524/1762] D loss: 0.0021, G loss: 8.5525\n",
      "[1604/1762] D loss: 0.0006, G loss: 8.4532\n",
      "[1684/1762] D loss: 0.0134, G loss: 7.9242\n",
      "[1762/1762] D loss: 0.0276, G loss: 8.6534\n",
      "train error: \n",
      " D loss: 4.486973, G loss: 6.470817, D accuracy: 61.6%, cell accuracy: 99.9%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 4.613725, G loss: 6.659613, D accuracy: 63.1%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0064, G loss: 13.8374\n",
      "[84/1762] D loss: 0.0280, G loss: 9.5619\n",
      "[164/1762] D loss: 0.0917, G loss: 6.6991\n",
      "[244/1762] D loss: 0.0647, G loss: 4.5043\n",
      "[324/1762] D loss: 0.0029, G loss: 8.7104\n",
      "[404/1762] D loss: 0.0013, G loss: 8.8946\n",
      "[484/1762] D loss: 0.0026, G loss: 6.7829\n",
      "[564/1762] D loss: 0.0008, G loss: 10.0523\n",
      "[644/1762] D loss: 0.0003, G loss: 11.7148\n",
      "[724/1762] D loss: 0.0006, G loss: 8.2984\n",
      "[804/1762] D loss: 0.0002, G loss: 10.1077\n",
      "[884/1762] D loss: 0.0026, G loss: 8.8602\n",
      "[964/1762] D loss: 0.0767, G loss: 7.4955\n",
      "[1044/1762] D loss: 0.0122, G loss: 9.4970\n",
      "[1124/1762] D loss: 0.0079, G loss: 6.9314\n",
      "[1204/1762] D loss: 0.1338, G loss: 8.3015\n",
      "[1284/1762] D loss: 0.0118, G loss: 7.8463\n",
      "[1364/1762] D loss: 0.0406, G loss: 5.0613\n",
      "[1444/1762] D loss: 0.0005, G loss: 9.2449\n",
      "[1524/1762] D loss: 0.0018, G loss: 8.6669\n",
      "[1604/1762] D loss: 0.0039, G loss: 5.5927\n",
      "[1684/1762] D loss: 0.0021, G loss: 9.0173\n",
      "[1762/1762] D loss: 0.0031, G loss: 10.0158\n",
      "train error: \n",
      " D loss: 3.319780, G loss: 4.242493, D accuracy: 66.2%, cell accuracy: 99.9%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 3.449794, G loss: 4.382507, D accuracy: 66.9%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0073, G loss: 10.2053\n",
      "[84/1762] D loss: 0.0002, G loss: 9.1951\n",
      "[164/1762] D loss: 0.0232, G loss: 6.2535\n",
      "[244/1762] D loss: 0.0032, G loss: 10.3448\n",
      "[324/1762] D loss: 0.0000, G loss: 14.1488\n",
      "[404/1762] D loss: 0.0239, G loss: 12.5504\n",
      "[484/1762] D loss: 0.0096, G loss: 9.3285\n",
      "[564/1762] D loss: 0.0003, G loss: 10.7140\n",
      "[644/1762] D loss: 0.0012, G loss: 10.0509\n",
      "[724/1762] D loss: 0.0005, G loss: 10.2847\n",
      "[804/1762] D loss: 0.0041, G loss: 10.3358\n",
      "[884/1762] D loss: 0.0007, G loss: 10.9651\n",
      "[964/1762] D loss: 0.0002, G loss: 11.0424\n",
      "[1044/1762] D loss: 0.0355, G loss: 4.0876\n",
      "[1124/1762] D loss: 0.0039, G loss: 7.4031\n",
      "[1204/1762] D loss: 0.0007, G loss: 10.0402\n",
      "[1284/1762] D loss: 0.0023, G loss: 12.8213\n",
      "[1364/1762] D loss: 0.4190, G loss: 9.0459\n",
      "[1444/1762] D loss: 0.0000, G loss: 12.7332\n",
      "[1524/1762] D loss: 0.0010, G loss: 12.6369\n",
      "[1604/1762] D loss: 0.0012, G loss: 10.6711\n",
      "[1684/1762] D loss: 0.0000, G loss: 16.1131\n",
      "[1762/1762] D loss: 0.0048, G loss: 7.6510\n",
      "train error: \n",
      " D loss: 4.661329, G loss: 7.759813, D accuracy: 68.2%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "test error: \n",
      " D loss: 4.785418, G loss: 7.863982, D accuracy: 68.4%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0044, G loss: 11.1710\n",
      "[84/1762] D loss: 0.0021, G loss: 9.7892\n",
      "[164/1762] D loss: 0.0419, G loss: 6.5261\n",
      "[244/1762] D loss: 0.0023, G loss: 8.9016\n",
      "[324/1762] D loss: 0.0016, G loss: 11.0123\n",
      "[404/1762] D loss: 0.0008, G loss: 11.3167\n",
      "[484/1762] D loss: 0.0017, G loss: 9.9917\n",
      "[564/1762] D loss: 0.0002, G loss: 12.8826\n",
      "[644/1762] D loss: 0.0001, G loss: 14.0306\n",
      "[724/1762] D loss: 0.0594, G loss: 3.9909\n",
      "[804/1762] D loss: 0.0000, G loss: 13.6944\n",
      "[884/1762] D loss: 0.0012, G loss: 12.3536\n",
      "[964/1762] D loss: 0.0490, G loss: 7.1757\n",
      "[1044/1762] D loss: 0.0010, G loss: 10.6771\n",
      "[1124/1762] D loss: 0.1438, G loss: 5.6505\n",
      "[1204/1762] D loss: 0.0132, G loss: 5.5128\n",
      "[1284/1762] D loss: 0.4268, G loss: 2.7483\n",
      "[1364/1762] D loss: 0.0009, G loss: 12.8945\n",
      "[1444/1762] D loss: 0.3310, G loss: 3.5959\n",
      "[1524/1762] D loss: 0.0031, G loss: 10.2379\n",
      "[1604/1762] D loss: 0.0011, G loss: 10.0179\n",
      "[1684/1762] D loss: 0.0113, G loss: 8.1478\n",
      "[1762/1762] D loss: 0.0001, G loss: 10.7293\n",
      "train error: \n",
      " D loss: 2.994156, G loss: 5.277581, D accuracy: 68.5%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 3.049058, G loss: 5.426475, D accuracy: 69.7%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0014, G loss: 10.0717\n",
      "[84/1762] D loss: 0.0001, G loss: 13.5212\n",
      "[164/1762] D loss: 0.0042, G loss: 6.7012\n",
      "[244/1762] D loss: 1.1060, G loss: 3.8503\n",
      "[324/1762] D loss: 0.0009, G loss: 11.1256\n",
      "[404/1762] D loss: 0.0031, G loss: 13.1022\n",
      "[484/1762] D loss: 0.4844, G loss: 2.5528\n",
      "[564/1762] D loss: 0.0000, G loss: 13.7688\n",
      "[644/1762] D loss: 0.0005, G loss: 9.8663\n",
      "[724/1762] D loss: 0.0634, G loss: 5.5789\n",
      "[804/1762] D loss: 0.0113, G loss: 12.3294\n",
      "[884/1762] D loss: 0.1790, G loss: 8.2910\n",
      "[964/1762] D loss: 0.0056, G loss: 10.3027\n",
      "[1044/1762] D loss: 0.1167, G loss: 7.0147\n",
      "[1124/1762] D loss: 0.0004, G loss: 11.1695\n",
      "[1204/1762] D loss: 0.0004, G loss: 13.2061\n",
      "[1284/1762] D loss: 0.0019, G loss: 10.0818\n",
      "[1364/1762] D loss: 0.0020, G loss: 7.6036\n",
      "[1444/1762] D loss: 0.0004, G loss: 9.6616\n",
      "[1524/1762] D loss: 0.0238, G loss: 12.3455\n",
      "[1604/1762] D loss: 0.0036, G loss: 7.1881\n",
      "[1684/1762] D loss: 0.6292, G loss: 6.0934\n",
      "[1762/1762] D loss: 0.5135, G loss: 10.7955\n",
      "train error: \n",
      " D loss: 7.064337, G loss: 8.883916, D accuracy: 60.6%, cell accuracy: 99.8%, board accuracy: 90.8% \n",
      "\n",
      "test error: \n",
      " D loss: 7.242013, G loss: 9.133654, D accuracy: 59.7%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0015, G loss: 13.3032\n",
      "[84/1762] D loss: 0.0003, G loss: 14.0059\n",
      "[164/1762] D loss: 0.0014, G loss: 11.7467\n",
      "[244/1762] D loss: 0.0013, G loss: 9.9648\n",
      "[324/1762] D loss: 0.0087, G loss: 7.3995\n",
      "[404/1762] D loss: 0.0001, G loss: 11.5136\n",
      "[484/1762] D loss: 0.0001, G loss: 10.6865\n",
      "[564/1762] D loss: 0.0008, G loss: 9.1765\n",
      "[644/1762] D loss: 0.0000, G loss: 15.2931\n",
      "[724/1762] D loss: 0.0126, G loss: 6.8723\n",
      "[804/1762] D loss: 2.1624, G loss: 2.1619\n",
      "[884/1762] D loss: 0.0002, G loss: 10.1799\n",
      "[964/1762] D loss: 0.0003, G loss: 17.3800\n",
      "[1044/1762] D loss: 0.0002, G loss: 14.4975\n",
      "[1124/1762] D loss: 0.0004, G loss: 8.5371\n",
      "[1204/1762] D loss: 0.0274, G loss: 6.2923\n",
      "[1284/1762] D loss: 0.0003, G loss: 11.7088\n",
      "[1364/1762] D loss: 0.0009, G loss: 11.7248\n",
      "[1444/1762] D loss: 0.0000, G loss: 16.0453\n",
      "[1524/1762] D loss: 0.0039, G loss: 7.7808\n",
      "[1604/1762] D loss: 0.0207, G loss: 13.4999\n",
      "[1684/1762] D loss: 0.0000, G loss: 12.8229\n",
      "[1762/1762] D loss: 0.0023, G loss: 9.1508\n",
      "train error: \n",
      " D loss: 5.064498, G loss: 7.816715, D accuracy: 66.1%, cell accuracy: 99.8%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 5.271182, G loss: 7.984813, D accuracy: 65.6%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0002, G loss: 11.4494\n",
      "[84/1762] D loss: 0.0613, G loss: 8.9804\n",
      "[164/1762] D loss: 0.0001, G loss: 13.5363\n",
      "[244/1762] D loss: 0.0000, G loss: 15.9831\n",
      "[324/1762] D loss: 0.0111, G loss: 8.7676\n",
      "[404/1762] D loss: 0.0017, G loss: 14.7951\n",
      "[484/1762] D loss: 0.0038, G loss: 11.4473\n",
      "[564/1762] D loss: 0.0010, G loss: 11.1218\n",
      "[644/1762] D loss: 0.0131, G loss: 10.3079\n",
      "[724/1762] D loss: 0.0076, G loss: 10.3799\n",
      "[804/1762] D loss: 0.0012, G loss: 14.5344\n",
      "[884/1762] D loss: 0.0363, G loss: 2.7682\n",
      "[964/1762] D loss: 0.0179, G loss: 8.7019\n",
      "[1044/1762] D loss: 0.0362, G loss: 5.6706\n",
      "[1124/1762] D loss: 0.0070, G loss: 9.1860\n",
      "[1204/1762] D loss: 0.0037, G loss: 9.8102\n",
      "[1284/1762] D loss: 0.0032, G loss: 5.1098\n",
      "[1364/1762] D loss: 0.2146, G loss: 5.2073\n",
      "[1444/1762] D loss: 0.0005, G loss: 9.5388\n",
      "[1524/1762] D loss: 0.0367, G loss: 4.0919\n",
      "[1604/1762] D loss: 0.0000, G loss: 13.1501\n",
      "[1684/1762] D loss: 0.0000, G loss: 13.7536\n",
      "[1762/1762] D loss: 0.0299, G loss: 3.7256\n",
      "train error: \n",
      " D loss: 4.473320, G loss: 5.425864, D accuracy: 67.4%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "test error: \n",
      " D loss: 4.628686, G loss: 5.645395, D accuracy: 67.5%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0209, G loss: 9.5871\n",
      "[84/1762] D loss: 0.2301, G loss: 4.9112\n",
      "[164/1762] D loss: 0.0015, G loss: 11.5058\n",
      "[244/1762] D loss: 0.0253, G loss: 9.5950\n",
      "[324/1762] D loss: 0.0014, G loss: 9.4056\n",
      "[404/1762] D loss: 0.0786, G loss: 4.6555\n",
      "[484/1762] D loss: 0.0021, G loss: 10.0408\n",
      "[564/1762] D loss: 0.0020, G loss: 12.1564\n",
      "[644/1762] D loss: 0.0186, G loss: 5.7678\n",
      "[724/1762] D loss: 0.0023, G loss: 6.9758\n",
      "[804/1762] D loss: 0.0064, G loss: 11.5264\n",
      "[884/1762] D loss: 0.0000, G loss: 14.1895\n",
      "[964/1762] D loss: 0.0046, G loss: 8.7850\n",
      "[1044/1762] D loss: 0.0005, G loss: 9.3592\n",
      "[1124/1762] D loss: 0.0039, G loss: 8.6817\n",
      "[1204/1762] D loss: 0.0188, G loss: 6.3237\n",
      "[1284/1762] D loss: 0.0004, G loss: 12.7755\n",
      "[1364/1762] D loss: 0.0019, G loss: 11.7503\n",
      "[1444/1762] D loss: 0.0003, G loss: 10.0195\n",
      "[1524/1762] D loss: 0.0020, G loss: 9.0803\n",
      "[1604/1762] D loss: 0.0506, G loss: 7.8425\n",
      "[1684/1762] D loss: 0.5653, G loss: 4.6182\n",
      "[1762/1762] D loss: 0.4582, G loss: 3.7298\n",
      "train error: \n",
      " D loss: 3.120950, G loss: 6.627643, D accuracy: 60.7%, cell accuracy: 99.9%, board accuracy: 91.5% \n",
      "\n",
      "test error: \n",
      " D loss: 3.154780, G loss: 6.829441, D accuracy: 59.3%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3873, G loss: 0.7433\n",
      "[84/1762] D loss: 1.2849, G loss: 0.7850\n",
      "[164/1762] D loss: 0.5853, G loss: 1.5988\n",
      "[244/1762] D loss: 0.0523, G loss: 4.4329\n",
      "[324/1762] D loss: 0.0713, G loss: 2.1706\n",
      "[404/1762] D loss: 0.0899, G loss: 4.0544\n",
      "[484/1762] D loss: 0.1014, G loss: 3.4974\n",
      "[564/1762] D loss: 0.2011, G loss: 1.3714\n",
      "[644/1762] D loss: 0.2747, G loss: 0.5375\n",
      "[724/1762] D loss: 0.9639, G loss: 0.9456\n",
      "[804/1762] D loss: 0.8939, G loss: 1.3905\n",
      "[884/1762] D loss: 0.5545, G loss: 2.8079\n",
      "[964/1762] D loss: 0.6680, G loss: 2.0774\n",
      "[1044/1762] D loss: 0.5113, G loss: 2.0245\n",
      "[1124/1762] D loss: 0.8372, G loss: 1.8183\n",
      "[1204/1762] D loss: 1.8232, G loss: 3.6061\n",
      "[1284/1762] D loss: 1.1389, G loss: 0.5346\n",
      "[1364/1762] D loss: 0.9415, G loss: 3.1815\n",
      "[1444/1762] D loss: 0.7516, G loss: 1.2001\n",
      "[1524/1762] D loss: 0.6606, G loss: 1.6815\n",
      "[1604/1762] D loss: 0.6326, G loss: 1.2602\n",
      "[1684/1762] D loss: 0.7230, G loss: 2.1329\n",
      "[1762/1762] D loss: 1.3635, G loss: 1.8540\n",
      "train error: \n",
      " D loss: 1.063669, G loss: 0.863869, D accuracy: 71.7%, cell accuracy: 97.4%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.091140, G loss: 0.875181, D accuracy: 71.1%, cell accuracy: 97.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8834, G loss: 0.4962\n",
      "[84/1762] D loss: 0.9174, G loss: 1.1211\n",
      "[164/1762] D loss: 1.1548, G loss: 0.7682\n",
      "[244/1762] D loss: 1.0305, G loss: 2.2546\n",
      "[324/1762] D loss: 2.7247, G loss: 2.0759\n",
      "[404/1762] D loss: 1.1519, G loss: 0.3684\n",
      "[484/1762] D loss: 1.6559, G loss: 0.5307\n",
      "[564/1762] D loss: 1.1680, G loss: 0.9986\n",
      "[644/1762] D loss: 1.3014, G loss: 1.0302\n",
      "[724/1762] D loss: 1.3655, G loss: 0.7439\n",
      "[804/1762] D loss: 1.4237, G loss: 0.6824\n",
      "[884/1762] D loss: 1.0686, G loss: 0.5649\n",
      "[964/1762] D loss: 1.1926, G loss: 0.6342\n",
      "[1044/1762] D loss: 1.2320, G loss: 0.4281\n",
      "[1124/1762] D loss: 1.2204, G loss: 0.8138\n",
      "[1204/1762] D loss: 1.2408, G loss: 1.0057\n",
      "[1284/1762] D loss: 1.3308, G loss: 1.3260\n",
      "[1364/1762] D loss: 1.3591, G loss: 0.8291\n",
      "[1444/1762] D loss: 1.4145, G loss: 0.3768\n",
      "[1524/1762] D loss: 1.2542, G loss: 1.0121\n",
      "[1604/1762] D loss: 1.2254, G loss: 1.0921\n",
      "[1684/1762] D loss: 1.3333, G loss: 0.7256\n",
      "[1762/1762] D loss: 1.2080, G loss: 0.6313\n",
      "train error: \n",
      " D loss: 1.355086, G loss: 0.650260, D accuracy: 57.4%, cell accuracy: 99.5%, board accuracy: 56.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.351292, G loss: 0.661582, D accuracy: 58.3%, cell accuracy: 99.4%, board accuracy: 50.9% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3277, G loss: 0.4984\n",
      "[84/1762] D loss: 1.3870, G loss: 0.9551\n",
      "[164/1762] D loss: 1.4336, G loss: 0.7181\n",
      "[244/1762] D loss: 1.3705, G loss: 0.7209\n",
      "[324/1762] D loss: 1.3411, G loss: 0.9892\n",
      "[404/1762] D loss: 1.3221, G loss: 0.7476\n",
      "[484/1762] D loss: 1.3915, G loss: 0.8208\n",
      "[564/1762] D loss: 1.4067, G loss: 0.6035\n",
      "[644/1762] D loss: 1.3909, G loss: 1.3704\n",
      "[724/1762] D loss: 1.3837, G loss: 0.9924\n",
      "[804/1762] D loss: 1.4342, G loss: 0.6423\n",
      "[884/1762] D loss: 1.3792, G loss: 0.9080\n",
      "[964/1762] D loss: 1.3743, G loss: 0.6440\n",
      "[1044/1762] D loss: 1.3997, G loss: 0.7149\n",
      "[1124/1762] D loss: 1.4224, G loss: 0.7514\n",
      "[1204/1762] D loss: 1.3206, G loss: 0.7574\n",
      "[1284/1762] D loss: 1.3500, G loss: 0.5064\n",
      "[1364/1762] D loss: 1.2368, G loss: 0.7201\n",
      "[1444/1762] D loss: 1.3026, G loss: 0.7125\n",
      "[1524/1762] D loss: 1.3152, G loss: 0.7103\n",
      "[1604/1762] D loss: 1.2728, G loss: 0.7206\n",
      "[1684/1762] D loss: 1.4827, G loss: 0.5887\n",
      "[1762/1762] D loss: 1.3301, G loss: 0.7472\n",
      "train error: \n",
      " D loss: 1.352337, G loss: 0.679456, D accuracy: 57.5%, cell accuracy: 99.6%, board accuracy: 66.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.351017, G loss: 0.679461, D accuracy: 57.3%, cell accuracy: 99.5%, board accuracy: 65.0% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3082, G loss: 0.9472\n",
      "[84/1762] D loss: 1.3823, G loss: 0.7221\n",
      "[164/1762] D loss: 1.4171, G loss: 0.4893\n",
      "[244/1762] D loss: 1.1629, G loss: 0.6315\n",
      "[324/1762] D loss: 1.4125, G loss: 0.7549\n",
      "[404/1762] D loss: 1.3593, G loss: 0.8074\n",
      "[484/1762] D loss: 1.3725, G loss: 0.7634\n",
      "[564/1762] D loss: 1.3502, G loss: 0.7274\n",
      "[644/1762] D loss: 1.3889, G loss: 0.6940\n",
      "[724/1762] D loss: 1.4221, G loss: 0.8432\n",
      "[804/1762] D loss: 1.3999, G loss: 0.6231\n",
      "[884/1762] D loss: 1.3270, G loss: 0.8498\n",
      "[964/1762] D loss: 1.3283, G loss: 0.6110\n",
      "[1044/1762] D loss: 1.3898, G loss: 0.7243\n",
      "[1124/1762] D loss: 1.3790, G loss: 0.5909\n",
      "[1204/1762] D loss: 1.3058, G loss: 0.8778\n",
      "[1284/1762] D loss: 1.4104, G loss: 0.8297\n",
      "[1364/1762] D loss: 1.4243, G loss: 0.6979\n",
      "[1444/1762] D loss: 1.3993, G loss: 0.7204\n",
      "[1524/1762] D loss: 1.4259, G loss: 0.6151\n",
      "[1604/1762] D loss: 1.4039, G loss: 0.6506\n",
      "[1684/1762] D loss: 1.4131, G loss: 0.6958\n",
      "[1762/1762] D loss: 1.4857, G loss: 0.8590\n",
      "train error: \n",
      " D loss: 1.434221, G loss: 1.065568, D accuracy: 50.1%, cell accuracy: 99.7%, board accuracy: 72.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.427263, G loss: 1.059802, D accuracy: 50.0%, cell accuracy: 99.6%, board accuracy: 70.0% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4757, G loss: 1.2016\n",
      "[84/1762] D loss: 1.3790, G loss: 1.0564\n",
      "[164/1762] D loss: 1.3514, G loss: 0.8341\n",
      "[244/1762] D loss: 1.2283, G loss: 0.7855\n",
      "[324/1762] D loss: 1.3734, G loss: 0.8114\n",
      "[404/1762] D loss: 1.4563, G loss: 1.1444\n",
      "[484/1762] D loss: 1.1924, G loss: 1.0252\n",
      "[564/1762] D loss: 1.4482, G loss: 0.7386\n",
      "[644/1762] D loss: 1.3997, G loss: 0.9489\n",
      "[724/1762] D loss: 1.4611, G loss: 0.6444\n",
      "[804/1762] D loss: 1.3424, G loss: 0.7995\n",
      "[884/1762] D loss: 1.3252, G loss: 0.5719\n",
      "[964/1762] D loss: 1.4255, G loss: 0.8992\n",
      "[1044/1762] D loss: 1.4108, G loss: 0.5695\n",
      "[1124/1762] D loss: 1.2737, G loss: 0.9151\n",
      "[1204/1762] D loss: 1.3799, G loss: 0.6299\n",
      "[1284/1762] D loss: 1.3773, G loss: 0.7336\n",
      "[1364/1762] D loss: 1.4014, G loss: 0.6425\n",
      "[1444/1762] D loss: 1.3883, G loss: 0.6947\n",
      "[1524/1762] D loss: 1.3790, G loss: 0.7002\n",
      "[1604/1762] D loss: 1.3954, G loss: 0.6671\n",
      "[1684/1762] D loss: 1.3962, G loss: 0.7388\n",
      "[1762/1762] D loss: 1.3963, G loss: 0.6257\n",
      "train error: \n",
      " D loss: 1.358612, G loss: 0.744188, D accuracy: 54.5%, cell accuracy: 99.5%, board accuracy: 58.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.358525, G loss: 0.750164, D accuracy: 54.8%, cell accuracy: 99.4%, board accuracy: 55.7% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3910, G loss: 0.6314\n",
      "[84/1762] D loss: 1.3866, G loss: 0.6802\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6917\n",
      "[244/1762] D loss: 1.3762, G loss: 0.7126\n",
      "[324/1762] D loss: 1.3551, G loss: 0.7484\n",
      "[404/1762] D loss: 1.3356, G loss: 0.6530\n",
      "[484/1762] D loss: 1.2256, G loss: 0.8379\n",
      "[564/1762] D loss: 1.1926, G loss: 0.9796\n",
      "[644/1762] D loss: 1.0420, G loss: 1.2717\n",
      "[724/1762] D loss: 1.0534, G loss: 2.3635\n",
      "[804/1762] D loss: 1.4434, G loss: 0.5189\n",
      "[884/1762] D loss: 1.1630, G loss: 2.2915\n",
      "[964/1762] D loss: 1.4222, G loss: 0.7978\n",
      "[1044/1762] D loss: 1.0842, G loss: 1.9088\n",
      "[1124/1762] D loss: 1.2932, G loss: 0.9185\n",
      "[1204/1762] D loss: 1.0157, G loss: 1.9654\n",
      "[1284/1762] D loss: 1.1837, G loss: 0.9365\n",
      "[1364/1762] D loss: 0.8854, G loss: 2.1131\n",
      "[1444/1762] D loss: 1.2654, G loss: 0.7593\n",
      "[1524/1762] D loss: 0.9627, G loss: 1.7230\n",
      "[1604/1762] D loss: 1.1916, G loss: 2.2506\n",
      "[1684/1762] D loss: 0.7870, G loss: 3.3539\n",
      "[1762/1762] D loss: 1.3851, G loss: 1.0299\n",
      "train error: \n",
      " D loss: 1.095143, G loss: 1.353801, D accuracy: 65.7%, cell accuracy: 99.6%, board accuracy: 63.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.049627, G loss: 1.465326, D accuracy: 68.0%, cell accuracy: 99.5%, board accuracy: 59.8% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3912, G loss: 0.5801\n",
      "[84/1762] D loss: 1.0634, G loss: 1.4652\n",
      "[164/1762] D loss: 1.0783, G loss: 2.1360\n",
      "[244/1762] D loss: 1.2141, G loss: 0.7060\n",
      "[324/1762] D loss: 1.3769, G loss: 0.7725\n",
      "[404/1762] D loss: 1.3836, G loss: 1.0001\n",
      "[484/1762] D loss: 1.3693, G loss: 0.6764\n",
      "[564/1762] D loss: 0.8329, G loss: 1.9868\n",
      "[644/1762] D loss: 1.0203, G loss: 1.8812\n",
      "[724/1762] D loss: 1.0592, G loss: 1.9600\n",
      "[804/1762] D loss: 0.4418, G loss: 2.9534\n",
      "[884/1762] D loss: 0.7719, G loss: 2.5457\n",
      "[964/1762] D loss: 0.7388, G loss: 2.8666\n",
      "[1044/1762] D loss: 1.3622, G loss: 0.5899\n",
      "[1124/1762] D loss: 1.3260, G loss: 0.8950\n",
      "[1204/1762] D loss: 1.3827, G loss: 0.6149\n",
      "[1284/1762] D loss: 1.1355, G loss: 1.2050\n",
      "[1364/1762] D loss: 1.0738, G loss: 2.2462\n",
      "[1444/1762] D loss: 1.0265, G loss: 2.9033\n",
      "[1524/1762] D loss: 1.2910, G loss: 3.1423\n",
      "[1604/1762] D loss: 0.7554, G loss: 3.2432\n",
      "[1684/1762] D loss: 1.0804, G loss: 1.5692\n",
      "[1762/1762] D loss: 0.7008, G loss: 4.4040\n",
      "train error: \n",
      " D loss: 1.057826, G loss: 2.016572, D accuracy: 67.1%, cell accuracy: 99.6%, board accuracy: 65.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.006487, G loss: 2.233771, D accuracy: 69.3%, cell accuracy: 99.5%, board accuracy: 62.0% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6007, G loss: 5.8194\n",
      "[84/1762] D loss: 1.1141, G loss: 1.6244\n",
      "[164/1762] D loss: 1.0846, G loss: 1.3570\n",
      "[244/1762] D loss: 1.0860, G loss: 1.7822\n",
      "[324/1762] D loss: 0.8085, G loss: 2.3480\n",
      "[404/1762] D loss: 1.1179, G loss: 0.9883\n",
      "[484/1762] D loss: 0.9218, G loss: 2.3748\n",
      "[564/1762] D loss: 1.1168, G loss: 3.2121\n",
      "[644/1762] D loss: 1.1140, G loss: 1.4500\n",
      "[724/1762] D loss: 0.6710, G loss: 3.7311\n",
      "[804/1762] D loss: 0.8490, G loss: 3.7740\n",
      "[884/1762] D loss: 1.0681, G loss: 1.6496\n",
      "[964/1762] D loss: 1.1850, G loss: 3.1551\n",
      "[1044/1762] D loss: 0.7430, G loss: 3.0012\n",
      "[1124/1762] D loss: 0.8733, G loss: 1.8956\n",
      "[1204/1762] D loss: 1.1207, G loss: 2.2852\n",
      "[1284/1762] D loss: 1.0530, G loss: 3.5772\n",
      "[1364/1762] D loss: 1.1383, G loss: 1.5355\n",
      "[1444/1762] D loss: 1.2752, G loss: 0.8236\n",
      "[1524/1762] D loss: 1.1733, G loss: 0.8456\n",
      "[1604/1762] D loss: 1.1340, G loss: 2.1784\n",
      "[1684/1762] D loss: 1.1098, G loss: 1.2191\n",
      "[1762/1762] D loss: 1.4603, G loss: 0.9228\n",
      "train error: \n",
      " D loss: 1.173781, G loss: 3.025487, D accuracy: 63.7%, cell accuracy: 99.6%, board accuracy: 64.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.101800, G loss: 3.311253, D accuracy: 65.9%, cell accuracy: 99.5%, board accuracy: 60.7% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3666, G loss: 0.6877\n",
      "[84/1762] D loss: 0.8695, G loss: 2.3195\n",
      "[164/1762] D loss: 0.9657, G loss: 1.7218\n",
      "[244/1762] D loss: 1.1824, G loss: 2.6527\n",
      "[324/1762] D loss: 0.8246, G loss: 2.7896\n",
      "[404/1762] D loss: 1.4059, G loss: 0.6203\n",
      "[484/1762] D loss: 0.9299, G loss: 2.5349\n",
      "[564/1762] D loss: 0.8455, G loss: 3.2171\n",
      "[644/1762] D loss: 1.4057, G loss: 2.0711\n",
      "[724/1762] D loss: 1.2062, G loss: 0.8692\n",
      "[804/1762] D loss: 1.0902, G loss: 1.4072\n",
      "[884/1762] D loss: 1.1133, G loss: 2.3753\n",
      "[964/1762] D loss: 0.5473, G loss: 4.7561\n",
      "[1044/1762] D loss: 0.9314, G loss: 2.2214\n",
      "[1124/1762] D loss: 1.0403, G loss: 2.6420\n",
      "[1204/1762] D loss: 1.1152, G loss: 3.5449\n",
      "[1284/1762] D loss: 1.3225, G loss: 0.9389\n",
      "[1364/1762] D loss: 1.0307, G loss: 3.0894\n",
      "[1444/1762] D loss: 1.1177, G loss: 1.8883\n",
      "[1524/1762] D loss: 1.1041, G loss: 2.1664\n",
      "[1604/1762] D loss: 1.3068, G loss: 0.9017\n",
      "[1684/1762] D loss: 1.0749, G loss: 2.4060\n",
      "[1762/1762] D loss: 1.4431, G loss: 0.7856\n",
      "train error: \n",
      " D loss: 0.929625, G loss: 2.816714, D accuracy: 71.1%, cell accuracy: 99.6%, board accuracy: 63.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.878499, G loss: 3.183560, D accuracy: 72.6%, cell accuracy: 99.5%, board accuracy: 60.0% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7783, G loss: 3.7761\n",
      "[84/1762] D loss: 1.3975, G loss: 0.8410\n",
      "[164/1762] D loss: 0.4355, G loss: 4.7049\n",
      "[244/1762] D loss: 1.8180, G loss: 0.4293\n",
      "[324/1762] D loss: 0.7211, G loss: 3.8132\n",
      "[404/1762] D loss: 1.2311, G loss: 0.8656\n",
      "[484/1762] D loss: 0.5477, G loss: 4.0968\n",
      "[564/1762] D loss: 0.7759, G loss: 2.1674\n",
      "[644/1762] D loss: 1.0470, G loss: 2.4147\n",
      "[724/1762] D loss: 0.9457, G loss: 1.9302\n",
      "[804/1762] D loss: 0.3926, G loss: 3.9447\n",
      "[884/1762] D loss: 0.4963, G loss: 7.3612\n",
      "[964/1762] D loss: 0.8370, G loss: 2.8937\n",
      "[1044/1762] D loss: 1.7634, G loss: 1.0459\n",
      "[1124/1762] D loss: 1.1390, G loss: 3.0463\n",
      "[1204/1762] D loss: 1.1217, G loss: 1.8998\n",
      "[1284/1762] D loss: 1.0499, G loss: 3.0891\n",
      "[1364/1762] D loss: 0.7313, G loss: 4.7518\n",
      "[1444/1762] D loss: 0.4453, G loss: 5.3995\n",
      "[1524/1762] D loss: 0.7615, G loss: 4.1240\n",
      "[1604/1762] D loss: 0.9800, G loss: 2.8745\n",
      "[1684/1762] D loss: 0.7085, G loss: 2.9715\n",
      "[1762/1762] D loss: 0.9130, G loss: 4.8862\n",
      "train error: \n",
      " D loss: 0.978560, G loss: 2.849660, D accuracy: 70.6%, cell accuracy: 99.6%, board accuracy: 64.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.899397, G loss: 3.298076, D accuracy: 73.6%, cell accuracy: 99.5%, board accuracy: 62.3% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5512, G loss: 2.4981\n",
      "[84/1762] D loss: 0.6074, G loss: 3.3050\n",
      "[164/1762] D loss: 0.7958, G loss: 2.6015\n",
      "[244/1762] D loss: 0.7805, G loss: 3.6355\n",
      "[324/1762] D loss: 1.0218, G loss: 2.9316\n",
      "[404/1762] D loss: 1.0797, G loss: 3.9485\n",
      "[484/1762] D loss: 0.8141, G loss: 2.9901\n",
      "[564/1762] D loss: 1.1502, G loss: 2.2890\n",
      "[644/1762] D loss: 0.9386, G loss: 1.2549\n",
      "[724/1762] D loss: 1.2932, G loss: 0.7910\n",
      "[804/1762] D loss: 1.0274, G loss: 2.5515\n",
      "[884/1762] D loss: 0.8229, G loss: 2.6196\n",
      "[964/1762] D loss: 0.9579, G loss: 3.2801\n",
      "[1044/1762] D loss: 0.7081, G loss: 3.4043\n",
      "[1124/1762] D loss: 0.7276, G loss: 3.9164\n",
      "[1204/1762] D loss: 1.2266, G loss: 1.6328\n",
      "[1284/1762] D loss: 0.9083, G loss: 1.4998\n",
      "[1364/1762] D loss: 1.1841, G loss: 0.7479\n",
      "[1444/1762] D loss: 0.8928, G loss: 1.3938\n",
      "[1524/1762] D loss: 0.6769, G loss: 3.2483\n",
      "[1604/1762] D loss: 0.6018, G loss: 5.0341\n",
      "[1684/1762] D loss: 0.8572, G loss: 4.5370\n",
      "[1762/1762] D loss: 1.3739, G loss: 0.5760\n",
      "train error: \n",
      " D loss: 0.912220, G loss: 3.128702, D accuracy: 72.1%, cell accuracy: 99.6%, board accuracy: 64.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.866760, G loss: 3.560175, D accuracy: 73.8%, cell accuracy: 99.5%, board accuracy: 61.1% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9570, G loss: 0.8537\n",
      "[84/1762] D loss: 1.0859, G loss: 1.7396\n",
      "[164/1762] D loss: 0.5051, G loss: 2.5693\n",
      "[244/1762] D loss: 1.0605, G loss: 2.5681\n",
      "[324/1762] D loss: 1.0502, G loss: 2.7316\n",
      "[404/1762] D loss: 0.9266, G loss: 2.5911\n",
      "[484/1762] D loss: 0.9268, G loss: 5.0248\n",
      "[564/1762] D loss: 1.0882, G loss: 3.4076\n",
      "[644/1762] D loss: 1.1742, G loss: 0.8985\n",
      "[724/1762] D loss: 1.0536, G loss: 2.3255\n",
      "[804/1762] D loss: 0.6653, G loss: 4.9441\n",
      "[884/1762] D loss: 0.8372, G loss: 2.5907\n",
      "[964/1762] D loss: 0.2661, G loss: 4.2724\n",
      "[1044/1762] D loss: 0.9505, G loss: 2.8967\n",
      "[1124/1762] D loss: 0.9199, G loss: 1.3050\n",
      "[1204/1762] D loss: 0.7293, G loss: 4.0747\n",
      "[1284/1762] D loss: 0.9281, G loss: 2.9823\n",
      "[1364/1762] D loss: 0.8522, G loss: 2.7833\n",
      "[1444/1762] D loss: 0.6644, G loss: 4.5384\n",
      "[1524/1762] D loss: 1.0890, G loss: 2.6442\n",
      "[1604/1762] D loss: 0.9759, G loss: 1.9068\n",
      "[1684/1762] D loss: 1.0926, G loss: 1.6160\n",
      "[1762/1762] D loss: 1.5267, G loss: 0.4313\n",
      "train error: \n",
      " D loss: 0.912307, G loss: 2.741197, D accuracy: 72.7%, cell accuracy: 99.6%, board accuracy: 64.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.862141, G loss: 3.110384, D accuracy: 74.5%, cell accuracy: 99.5%, board accuracy: 60.5% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1330, G loss: 0.9200\n",
      "[84/1762] D loss: 1.1210, G loss: 1.2542\n",
      "[164/1762] D loss: 0.9343, G loss: 3.3432\n",
      "[244/1762] D loss: 0.5442, G loss: 7.1398\n",
      "[324/1762] D loss: 1.1376, G loss: 0.9801\n",
      "[404/1762] D loss: 0.8629, G loss: 6.7042\n",
      "[484/1762] D loss: 1.3239, G loss: 0.6036\n",
      "[564/1762] D loss: 0.1761, G loss: 6.5965\n",
      "[644/1762] D loss: 0.8317, G loss: 2.8575\n",
      "[724/1762] D loss: 0.7935, G loss: 4.2844\n",
      "[804/1762] D loss: 1.1752, G loss: 4.8945\n",
      "[884/1762] D loss: 1.1021, G loss: 2.3461\n",
      "[964/1762] D loss: 1.0865, G loss: 3.4049\n",
      "[1044/1762] D loss: 0.7172, G loss: 5.3789\n",
      "[1124/1762] D loss: 0.7834, G loss: 3.0411\n",
      "[1204/1762] D loss: 0.4594, G loss: 6.8889\n",
      "[1284/1762] D loss: 1.0824, G loss: 2.8937\n",
      "[1364/1762] D loss: 0.7729, G loss: 3.6888\n",
      "[1444/1762] D loss: 0.1649, G loss: 9.0358\n",
      "[1524/1762] D loss: 1.4124, G loss: 3.3895\n",
      "[1604/1762] D loss: 1.0395, G loss: 7.7946\n",
      "[1684/1762] D loss: 1.1609, G loss: 2.1271\n",
      "[1762/1762] D loss: 0.6956, G loss: 3.4057\n",
      "train error: \n",
      " D loss: 0.851604, G loss: 3.511795, D accuracy: 75.2%, cell accuracy: 99.6%, board accuracy: 63.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.809386, G loss: 4.015761, D accuracy: 77.3%, cell accuracy: 99.5%, board accuracy: 58.6% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0745, G loss: 2.3939\n",
      "[84/1762] D loss: 0.9121, G loss: 2.7064\n",
      "[164/1762] D loss: 1.2022, G loss: 5.5923\n",
      "[244/1762] D loss: 1.0482, G loss: 4.5495\n",
      "[324/1762] D loss: 1.0563, G loss: 4.8591\n",
      "[404/1762] D loss: 1.1068, G loss: 1.2504\n",
      "[484/1762] D loss: 0.5803, G loss: 4.8294\n",
      "[564/1762] D loss: 1.0459, G loss: 3.9597\n",
      "[644/1762] D loss: 1.4626, G loss: 0.6784\n",
      "[724/1762] D loss: 0.9744, G loss: 5.0642\n",
      "[804/1762] D loss: 1.1192, G loss: 2.1511\n",
      "[884/1762] D loss: 0.4955, G loss: 3.9241\n",
      "[964/1762] D loss: 0.5920, G loss: 7.2786\n",
      "[1044/1762] D loss: 0.7034, G loss: 12.5764\n",
      "[1124/1762] D loss: 0.8905, G loss: 1.7302\n",
      "[1204/1762] D loss: 0.7563, G loss: 2.8526\n",
      "[1284/1762] D loss: 0.5837, G loss: 4.6497\n",
      "[1364/1762] D loss: 0.7883, G loss: 4.8599\n",
      "[1444/1762] D loss: 0.6964, G loss: 3.7595\n",
      "[1524/1762] D loss: 0.8373, G loss: 3.3855\n",
      "[1604/1762] D loss: 1.0276, G loss: 2.4199\n",
      "[1684/1762] D loss: 0.9689, G loss: 3.7161\n",
      "[1762/1762] D loss: 0.6928, G loss: 8.0813\n",
      "train error: \n",
      " D loss: 0.856405, G loss: 4.290444, D accuracy: 73.7%, cell accuracy: 99.6%, board accuracy: 65.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.795162, G loss: 4.936329, D accuracy: 76.6%, cell accuracy: 99.5%, board accuracy: 60.9% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3464, G loss: 6.5677\n",
      "[84/1762] D loss: 1.3719, G loss: 0.6464\n",
      "[164/1762] D loss: 1.3462, G loss: 1.3527\n",
      "[244/1762] D loss: 1.0146, G loss: 2.2137\n",
      "[324/1762] D loss: 0.3950, G loss: 6.5224\n",
      "[404/1762] D loss: 0.7531, G loss: 2.1090\n",
      "[484/1762] D loss: 0.7465, G loss: 6.7778\n",
      "[564/1762] D loss: 1.0184, G loss: 2.9628\n",
      "[644/1762] D loss: 1.2353, G loss: 1.6450\n",
      "[724/1762] D loss: 0.3904, G loss: 7.0928\n",
      "[804/1762] D loss: 0.7519, G loss: 3.0435\n",
      "[884/1762] D loss: 1.3784, G loss: 7.5784\n",
      "[964/1762] D loss: 0.9107, G loss: 5.2033\n",
      "[1044/1762] D loss: 0.7215, G loss: 7.1617\n",
      "[1124/1762] D loss: 1.1946, G loss: 1.5022\n",
      "[1204/1762] D loss: 0.4511, G loss: 4.5989\n",
      "[1284/1762] D loss: 0.6732, G loss: 2.7092\n",
      "[1364/1762] D loss: 0.9021, G loss: 5.5623\n",
      "[1444/1762] D loss: 0.9619, G loss: 1.4656\n",
      "[1524/1762] D loss: 0.5241, G loss: 4.0131\n",
      "[1604/1762] D loss: 1.5340, G loss: 0.4525\n",
      "[1684/1762] D loss: 0.9466, G loss: 4.1853\n",
      "[1762/1762] D loss: 0.7018, G loss: 6.0583\n",
      "train error: \n",
      " D loss: 0.854708, G loss: 4.288546, D accuracy: 74.3%, cell accuracy: 99.6%, board accuracy: 65.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.800979, G loss: 4.906180, D accuracy: 75.8%, cell accuracy: 99.5%, board accuracy: 60.5% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8959, G loss: 2.9087\n",
      "[84/1762] D loss: 0.8863, G loss: 1.6626\n",
      "[164/1762] D loss: 0.9613, G loss: 1.2602\n",
      "[244/1762] D loss: 0.5924, G loss: 5.7583\n",
      "[324/1762] D loss: 0.8513, G loss: 2.9365\n",
      "[404/1762] D loss: 1.1447, G loss: 0.9811\n",
      "[484/1762] D loss: 0.6994, G loss: 8.3959\n",
      "[564/1762] D loss: 0.7299, G loss: 6.8548\n",
      "[644/1762] D loss: 1.1187, G loss: 0.7436\n",
      "[724/1762] D loss: 0.8980, G loss: 1.3298\n",
      "[804/1762] D loss: 1.1479, G loss: 1.2406\n",
      "[884/1762] D loss: 0.8531, G loss: 4.1888\n",
      "[964/1762] D loss: 0.6491, G loss: 1.6560\n",
      "[1044/1762] D loss: 1.0115, G loss: 1.5973\n",
      "[1124/1762] D loss: 1.0660, G loss: 5.6284\n",
      "[1204/1762] D loss: 0.3662, G loss: 12.5238\n",
      "[1284/1762] D loss: 1.1712, G loss: 1.3350\n",
      "[1364/1762] D loss: 0.2838, G loss: 11.6053\n",
      "[1444/1762] D loss: 1.0159, G loss: 5.6358\n",
      "[1524/1762] D loss: 0.7441, G loss: 5.0616\n",
      "[1604/1762] D loss: 0.9895, G loss: 2.0811\n",
      "[1684/1762] D loss: 1.0832, G loss: 1.2303\n",
      "[1762/1762] D loss: 1.7279, G loss: 12.2912\n",
      "train error: \n",
      " D loss: 0.817521, G loss: 4.915901, D accuracy: 75.3%, cell accuracy: 99.6%, board accuracy: 65.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.765911, G loss: 5.663805, D accuracy: 77.6%, cell accuracy: 99.5%, board accuracy: 63.0% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6301, G loss: 5.3779\n",
      "[84/1762] D loss: 0.9324, G loss: 2.9354\n",
      "[164/1762] D loss: 0.7211, G loss: 6.3645\n",
      "[244/1762] D loss: 1.0426, G loss: 1.8682\n",
      "[324/1762] D loss: 1.0967, G loss: 1.0876\n",
      "[404/1762] D loss: 0.6531, G loss: 4.1109\n",
      "[484/1762] D loss: 1.5083, G loss: 0.4095\n",
      "[564/1762] D loss: 0.8323, G loss: 4.9642\n",
      "[644/1762] D loss: 1.2385, G loss: 4.8443\n",
      "[724/1762] D loss: 0.3519, G loss: 5.7739\n",
      "[804/1762] D loss: 0.6170, G loss: 6.8748\n",
      "[884/1762] D loss: 0.5732, G loss: 4.8325\n",
      "[964/1762] D loss: 1.1933, G loss: 1.2896\n",
      "[1044/1762] D loss: 0.7040, G loss: 9.7222\n",
      "[1124/1762] D loss: 0.5724, G loss: 4.0134\n",
      "[1204/1762] D loss: 0.4605, G loss: 8.4706\n",
      "[1284/1762] D loss: 0.4471, G loss: 2.4753\n",
      "[1364/1762] D loss: 0.6474, G loss: 4.0129\n",
      "[1444/1762] D loss: 0.7840, G loss: 4.0005\n",
      "[1524/1762] D loss: 1.1872, G loss: 1.2511\n",
      "[1604/1762] D loss: 0.7575, G loss: 3.5358\n",
      "[1684/1762] D loss: 0.8973, G loss: 5.4627\n",
      "[1762/1762] D loss: 0.8180, G loss: 3.6563\n",
      "train error: \n",
      " D loss: 0.800180, G loss: 5.498018, D accuracy: 75.7%, cell accuracy: 99.6%, board accuracy: 65.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.744567, G loss: 6.114711, D accuracy: 76.9%, cell accuracy: 99.5%, board accuracy: 60.9% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9188, G loss: 2.9862\n",
      "[84/1762] D loss: 0.4940, G loss: 6.6256\n",
      "[164/1762] D loss: 1.2066, G loss: 0.9322\n",
      "[244/1762] D loss: 1.4682, G loss: 1.2170\n",
      "[324/1762] D loss: 0.6878, G loss: 10.7102\n",
      "[404/1762] D loss: 0.8306, G loss: 6.4897\n",
      "[484/1762] D loss: 0.8591, G loss: 4.5785\n",
      "[564/1762] D loss: 1.2778, G loss: 1.0278\n",
      "[644/1762] D loss: 0.5344, G loss: 4.8795\n",
      "[724/1762] D loss: 1.3197, G loss: 0.7613\n",
      "[804/1762] D loss: 0.4295, G loss: 8.5619\n",
      "[884/1762] D loss: 0.9659, G loss: 2.2576\n",
      "[964/1762] D loss: 1.1077, G loss: 6.4728\n",
      "[1044/1762] D loss: 1.0119, G loss: 3.0754\n",
      "[1124/1762] D loss: 0.5737, G loss: 6.2644\n",
      "[1204/1762] D loss: 0.5629, G loss: 8.8975\n",
      "[1284/1762] D loss: 0.7814, G loss: 5.2397\n",
      "[1364/1762] D loss: 0.6546, G loss: 7.3201\n",
      "[1444/1762] D loss: 0.8444, G loss: 9.9475\n",
      "[1524/1762] D loss: 1.0790, G loss: 1.1033\n",
      "[1604/1762] D loss: 0.9157, G loss: 3.9331\n",
      "[1684/1762] D loss: 0.4995, G loss: 3.9539\n",
      "[1762/1762] D loss: 1.4002, G loss: 0.6661\n",
      "train error: \n",
      " D loss: 0.806608, G loss: 4.976202, D accuracy: 75.7%, cell accuracy: 99.6%, board accuracy: 65.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.752633, G loss: 5.681791, D accuracy: 78.0%, cell accuracy: 99.5%, board accuracy: 61.1% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4070, G loss: 8.6350\n",
      "[84/1762] D loss: 0.7264, G loss: 5.1975\n",
      "[164/1762] D loss: 1.0679, G loss: 2.8347\n",
      "[244/1762] D loss: 0.3713, G loss: 4.2982\n",
      "[324/1762] D loss: 0.7692, G loss: 1.4358\n",
      "[404/1762] D loss: 0.8154, G loss: 3.2770\n",
      "[484/1762] D loss: 0.7116, G loss: 5.5522\n",
      "[564/1762] D loss: 0.7830, G loss: 8.0026\n",
      "[644/1762] D loss: 0.7624, G loss: 16.0424\n",
      "[724/1762] D loss: 1.0329, G loss: 5.7909\n",
      "[804/1762] D loss: 0.6938, G loss: 6.7096\n",
      "[884/1762] D loss: 0.9207, G loss: 8.1553\n",
      "[964/1762] D loss: 0.7966, G loss: 1.8173\n",
      "[1044/1762] D loss: 0.9669, G loss: 4.4436\n",
      "[1124/1762] D loss: 0.9510, G loss: 2.2200\n",
      "[1204/1762] D loss: 1.2722, G loss: 0.8245\n",
      "[1284/1762] D loss: 0.7917, G loss: 2.9412\n",
      "[1364/1762] D loss: 0.4847, G loss: 4.4873\n",
      "[1444/1762] D loss: 1.1656, G loss: 1.4461\n",
      "[1524/1762] D loss: 0.5246, G loss: 7.4410\n",
      "[1604/1762] D loss: 1.0554, G loss: 5.3993\n",
      "[1684/1762] D loss: 0.8360, G loss: 7.6647\n",
      "[1762/1762] D loss: 0.2089, G loss: 3.8957\n",
      "train error: \n",
      " D loss: 0.853486, G loss: 4.790487, D accuracy: 74.6%, cell accuracy: 99.6%, board accuracy: 64.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.808610, G loss: 5.272257, D accuracy: 76.1%, cell accuracy: 99.5%, board accuracy: 61.6% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4941, G loss: 6.7391\n",
      "[84/1762] D loss: 1.0664, G loss: 4.0623\n",
      "[164/1762] D loss: 0.6692, G loss: 4.7293\n",
      "[244/1762] D loss: 1.5522, G loss: 1.7022\n",
      "[324/1762] D loss: 0.5162, G loss: 4.6932\n",
      "[404/1762] D loss: 0.4911, G loss: 3.5672\n",
      "[484/1762] D loss: 0.6958, G loss: 8.9225\n",
      "[564/1762] D loss: 0.7017, G loss: 5.8944\n",
      "[644/1762] D loss: 1.0903, G loss: 3.6530\n",
      "[724/1762] D loss: 1.1159, G loss: 2.9079\n",
      "[804/1762] D loss: 0.3981, G loss: 6.1485\n",
      "[884/1762] D loss: 0.5017, G loss: 3.0974\n",
      "[964/1762] D loss: 0.9229, G loss: 3.3765\n",
      "[1044/1762] D loss: 0.4497, G loss: 6.5570\n",
      "[1124/1762] D loss: 0.8948, G loss: 3.1760\n",
      "[1204/1762] D loss: 0.8717, G loss: 3.6220\n",
      "[1284/1762] D loss: 0.6403, G loss: 5.4370\n",
      "[1364/1762] D loss: 0.6904, G loss: 4.9855\n",
      "[1444/1762] D loss: 0.9545, G loss: 1.3535\n",
      "[1524/1762] D loss: 0.7570, G loss: 7.5945\n",
      "[1604/1762] D loss: 1.0409, G loss: 6.3015\n",
      "[1684/1762] D loss: 1.2020, G loss: 5.3401\n",
      "[1762/1762] D loss: 0.2715, G loss: 12.3116\n",
      "train error: \n",
      " D loss: 0.772507, G loss: 5.834840, D accuracy: 77.2%, cell accuracy: 99.6%, board accuracy: 65.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.710358, G loss: 6.663032, D accuracy: 78.8%, cell accuracy: 99.5%, board accuracy: 61.1% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0492, G loss: 5.5966\n",
      "[84/1762] D loss: 0.8564, G loss: 3.0829\n",
      "[164/1762] D loss: 1.4563, G loss: 1.5545\n",
      "[244/1762] D loss: 0.6434, G loss: 3.6938\n",
      "[324/1762] D loss: 0.4638, G loss: 9.6266\n",
      "[404/1762] D loss: 1.0198, G loss: 4.0281\n",
      "[484/1762] D loss: 1.1422, G loss: 1.2881\n",
      "[564/1762] D loss: 1.0570, G loss: 8.1938\n",
      "[644/1762] D loss: 1.3720, G loss: 0.8472\n",
      "[724/1762] D loss: 0.4639, G loss: 8.2121\n",
      "[804/1762] D loss: 0.3445, G loss: 16.0462\n",
      "[884/1762] D loss: 1.0179, G loss: 4.4734\n",
      "[964/1762] D loss: 0.9323, G loss: 4.1218\n",
      "[1044/1762] D loss: 1.0899, G loss: 5.8394\n",
      "[1124/1762] D loss: 0.4043, G loss: 8.4221\n",
      "[1204/1762] D loss: 0.4197, G loss: 9.4524\n",
      "[1284/1762] D loss: 1.0434, G loss: 4.4705\n",
      "[1364/1762] D loss: 0.6576, G loss: 6.0991\n",
      "[1444/1762] D loss: 0.8310, G loss: 4.0021\n",
      "[1524/1762] D loss: 1.0563, G loss: 8.5807\n",
      "[1604/1762] D loss: 0.9557, G loss: 5.7656\n",
      "[1684/1762] D loss: 1.4895, G loss: 4.1246\n",
      "[1762/1762] D loss: 1.4587, G loss: 0.6164\n",
      "train error: \n",
      " D loss: 0.745339, G loss: 5.937156, D accuracy: 77.2%, cell accuracy: 99.6%, board accuracy: 63.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.701929, G loss: 6.708939, D accuracy: 79.1%, cell accuracy: 99.5%, board accuracy: 60.2% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9168, G loss: 1.5711\n",
      "[84/1762] D loss: 1.0711, G loss: 6.7569\n",
      "[164/1762] D loss: 0.4389, G loss: 10.2851\n",
      "[244/1762] D loss: 0.7490, G loss: 5.2347\n",
      "[324/1762] D loss: 1.1454, G loss: 5.6362\n",
      "[404/1762] D loss: 0.8660, G loss: 2.3668\n",
      "[484/1762] D loss: 0.9020, G loss: 1.3641\n",
      "[564/1762] D loss: 1.0974, G loss: 2.6251\n",
      "[644/1762] D loss: 1.1367, G loss: 2.3330\n",
      "[724/1762] D loss: 0.2167, G loss: 10.9022\n",
      "[804/1762] D loss: 0.3522, G loss: 13.6178\n",
      "[884/1762] D loss: 0.5083, G loss: 10.1618\n",
      "[964/1762] D loss: 1.2905, G loss: 0.8969\n",
      "[1044/1762] D loss: 1.0579, G loss: 2.4864\n",
      "[1124/1762] D loss: 0.6233, G loss: 8.7989\n",
      "[1204/1762] D loss: 0.4853, G loss: 9.2191\n",
      "[1284/1762] D loss: 1.0151, G loss: 6.2124\n",
      "[1364/1762] D loss: 0.5770, G loss: 9.3040\n",
      "[1444/1762] D loss: 0.9872, G loss: 5.1536\n",
      "[1524/1762] D loss: 1.5184, G loss: 0.6548\n",
      "[1604/1762] D loss: 0.5692, G loss: 7.6002\n",
      "[1684/1762] D loss: 0.8110, G loss: 6.5165\n",
      "[1762/1762] D loss: 1.3603, G loss: 0.6790\n",
      "train error: \n",
      " D loss: 0.738178, G loss: 7.371128, D accuracy: 78.1%, cell accuracy: 99.6%, board accuracy: 65.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.700162, G loss: 8.451637, D accuracy: 78.9%, cell accuracy: 99.5%, board accuracy: 60.7% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7193, G loss: 5.6585\n",
      "[84/1762] D loss: 1.0508, G loss: 4.2037\n",
      "[164/1762] D loss: 0.7031, G loss: 7.4323\n",
      "[244/1762] D loss: 0.9971, G loss: 3.6830\n",
      "[324/1762] D loss: 0.6403, G loss: 2.5292\n",
      "[404/1762] D loss: 0.0002, G loss: 24.4280\n",
      "[484/1762] D loss: 1.0928, G loss: 6.1571\n",
      "[564/1762] D loss: 1.2953, G loss: 0.7692\n",
      "[644/1762] D loss: 0.8188, G loss: 1.3911\n",
      "[724/1762] D loss: 0.5607, G loss: 4.6943\n",
      "[804/1762] D loss: 0.7722, G loss: 13.6509\n",
      "[884/1762] D loss: 1.2070, G loss: 1.3841\n",
      "[964/1762] D loss: 1.2998, G loss: 1.0454\n",
      "[1044/1762] D loss: 1.0642, G loss: 4.0704\n",
      "[1124/1762] D loss: 0.6888, G loss: 10.8916\n",
      "[1204/1762] D loss: 1.0673, G loss: 3.9999\n",
      "[1284/1762] D loss: 1.1366, G loss: 4.1035\n",
      "[1364/1762] D loss: 0.1047, G loss: 12.0709\n",
      "[1444/1762] D loss: 0.7337, G loss: 5.5637\n",
      "[1524/1762] D loss: 0.6937, G loss: 16.9670\n",
      "[1604/1762] D loss: 0.7899, G loss: 7.2904\n",
      "[1684/1762] D loss: 1.0449, G loss: 5.2864\n",
      "[1762/1762] D loss: 0.8081, G loss: 9.2204\n",
      "train error: \n",
      " D loss: 0.832519, G loss: 5.721287, D accuracy: 74.6%, cell accuracy: 99.6%, board accuracy: 64.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.775940, G loss: 6.457884, D accuracy: 77.2%, cell accuracy: 99.5%, board accuracy: 61.6% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1015, G loss: 10.1960\n",
      "[84/1762] D loss: 1.0600, G loss: 2.9389\n",
      "[164/1762] D loss: 0.6818, G loss: 13.3346\n",
      "[244/1762] D loss: 1.4912, G loss: 0.3981\n",
      "[324/1762] D loss: 0.7128, G loss: 5.1130\n",
      "[404/1762] D loss: 0.7863, G loss: 5.4271\n",
      "[484/1762] D loss: 0.0447, G loss: 16.0285\n",
      "[564/1762] D loss: 0.9758, G loss: 7.0337\n",
      "[644/1762] D loss: 1.0761, G loss: 6.7263\n",
      "[724/1762] D loss: 0.7059, G loss: 3.1478\n",
      "[804/1762] D loss: 0.3381, G loss: 23.6307\n",
      "[884/1762] D loss: 1.2467, G loss: 0.9724\n",
      "[964/1762] D loss: 0.0053, G loss: 25.8876\n",
      "[1044/1762] D loss: 1.0294, G loss: 1.4141\n",
      "[1124/1762] D loss: 0.5239, G loss: 6.1628\n",
      "[1204/1762] D loss: 0.7004, G loss: 10.0325\n",
      "[1284/1762] D loss: 0.4621, G loss: 7.6666\n",
      "[1364/1762] D loss: 1.0769, G loss: 2.4355\n",
      "[1444/1762] D loss: 0.4779, G loss: 4.8545\n",
      "[1524/1762] D loss: 0.7314, G loss: 7.6609\n",
      "[1604/1762] D loss: 0.8426, G loss: 10.7646\n",
      "[1684/1762] D loss: 0.6807, G loss: 7.1602\n",
      "[1762/1762] D loss: 0.7605, G loss: 4.9829\n",
      "train error: \n",
      " D loss: 1.002828, G loss: 5.737027, D accuracy: 72.0%, cell accuracy: 99.6%, board accuracy: 66.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.940500, G loss: 6.447076, D accuracy: 74.7%, cell accuracy: 99.5%, board accuracy: 62.3% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4456, G loss: 10.4692\n",
      "[84/1762] D loss: 0.6660, G loss: 4.6413\n",
      "[164/1762] D loss: 0.9230, G loss: 8.2454\n",
      "[244/1762] D loss: 0.3795, G loss: 16.5512\n",
      "[324/1762] D loss: 0.3639, G loss: 9.1934\n",
      "[404/1762] D loss: 0.7505, G loss: 10.8933\n",
      "[484/1762] D loss: 0.7782, G loss: 3.3309\n",
      "[564/1762] D loss: 0.8871, G loss: 1.7550\n",
      "[644/1762] D loss: 1.0711, G loss: 1.7353\n",
      "[724/1762] D loss: 0.7160, G loss: 3.3530\n",
      "[804/1762] D loss: 0.1668, G loss: 12.8075\n",
      "[884/1762] D loss: 0.6625, G loss: 10.2073\n",
      "[964/1762] D loss: 0.5267, G loss: 9.4637\n",
      "[1044/1762] D loss: 0.9717, G loss: 8.5147\n",
      "[1124/1762] D loss: 1.1230, G loss: 5.5070\n",
      "[1204/1762] D loss: 1.2752, G loss: 0.9561\n",
      "[1284/1762] D loss: 0.7952, G loss: 6.8494\n",
      "[1364/1762] D loss: 1.2562, G loss: 0.8143\n",
      "[1444/1762] D loss: 0.7448, G loss: 10.1067\n",
      "[1524/1762] D loss: 0.3823, G loss: 12.4278\n",
      "[1604/1762] D loss: 0.6065, G loss: 14.7781\n",
      "[1684/1762] D loss: 1.1726, G loss: 5.2145\n",
      "[1762/1762] D loss: 1.4380, G loss: 0.8783\n",
      "train error: \n",
      " D loss: 0.776827, G loss: 6.841018, D accuracy: 76.0%, cell accuracy: 99.6%, board accuracy: 65.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.711501, G loss: 7.727371, D accuracy: 78.2%, cell accuracy: 99.5%, board accuracy: 59.1% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2314, G loss: 17.7712\n",
      "[84/1762] D loss: 1.1191, G loss: 1.2639\n",
      "[164/1762] D loss: 0.4035, G loss: 8.5429\n",
      "[244/1762] D loss: 0.4358, G loss: 8.6562\n",
      "[324/1762] D loss: 0.4808, G loss: 15.5867\n",
      "[404/1762] D loss: 0.8820, G loss: 5.4949\n",
      "[484/1762] D loss: 0.7901, G loss: 1.9015\n",
      "[564/1762] D loss: 0.6196, G loss: 14.9715\n",
      "[644/1762] D loss: 1.0727, G loss: 1.2388\n",
      "[724/1762] D loss: 0.7086, G loss: 5.4110\n",
      "[804/1762] D loss: 0.4798, G loss: 14.0918\n",
      "[884/1762] D loss: 0.5599, G loss: 6.5939\n",
      "[964/1762] D loss: 0.3377, G loss: 7.7928\n",
      "[1044/1762] D loss: 1.0399, G loss: 12.9235\n",
      "[1124/1762] D loss: 0.5634, G loss: 7.0943\n",
      "[1204/1762] D loss: 1.1870, G loss: 14.7753\n",
      "[1284/1762] D loss: 0.4266, G loss: 14.9594\n",
      "[1364/1762] D loss: 1.0636, G loss: 0.8752\n",
      "[1444/1762] D loss: 0.8116, G loss: 5.8477\n",
      "[1524/1762] D loss: 0.2727, G loss: 14.9603\n",
      "[1604/1762] D loss: 1.0452, G loss: 2.9453\n",
      "[1684/1762] D loss: 0.7649, G loss: 7.8618\n",
      "[1762/1762] D loss: 1.2703, G loss: 0.9913\n",
      "train error: \n",
      " D loss: 0.728031, G loss: 8.587217, D accuracy: 77.9%, cell accuracy: 99.6%, board accuracy: 64.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.667277, G loss: 9.774188, D accuracy: 80.0%, cell accuracy: 99.5%, board accuracy: 61.6% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0509, G loss: 12.8328\n",
      "[84/1762] D loss: 1.2507, G loss: 1.4366\n",
      "[164/1762] D loss: 0.8959, G loss: 5.9344\n",
      "[244/1762] D loss: 0.9039, G loss: 0.8432\n",
      "[324/1762] D loss: 0.6780, G loss: 6.0785\n",
      "[404/1762] D loss: 0.9997, G loss: 2.2778\n",
      "[484/1762] D loss: 0.7898, G loss: 3.3625\n",
      "[564/1762] D loss: 0.4216, G loss: 7.9635\n",
      "[644/1762] D loss: 0.1753, G loss: 13.4272\n",
      "[724/1762] D loss: 0.7069, G loss: 16.5284\n",
      "[804/1762] D loss: 0.9085, G loss: 12.8850\n",
      "[884/1762] D loss: 2.1215, G loss: 0.3238\n",
      "[964/1762] D loss: 0.4691, G loss: 6.9110\n",
      "[1044/1762] D loss: 0.7404, G loss: 5.7850\n",
      "[1124/1762] D loss: 0.4657, G loss: 7.4080\n",
      "[1204/1762] D loss: 0.8881, G loss: 1.9553\n",
      "[1284/1762] D loss: 1.0517, G loss: 1.2025\n",
      "[1364/1762] D loss: 1.0298, G loss: 2.0354\n",
      "[1444/1762] D loss: 0.9106, G loss: 1.8722\n",
      "[1524/1762] D loss: 0.4671, G loss: 6.1829\n",
      "[1604/1762] D loss: 0.7599, G loss: 5.5246\n",
      "[1684/1762] D loss: 0.3681, G loss: 13.7408\n",
      "[1762/1762] D loss: 0.8985, G loss: 4.4096\n",
      "train error: \n",
      " D loss: 0.677711, G loss: 9.762816, D accuracy: 79.4%, cell accuracy: 99.6%, board accuracy: 63.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.623198, G loss: 11.201721, D accuracy: 81.2%, cell accuracy: 99.5%, board accuracy: 59.8% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1263, G loss: 13.0903\n",
      "[84/1762] D loss: 1.2852, G loss: 0.7794\n",
      "[164/1762] D loss: 0.6943, G loss: 7.9062\n",
      "[244/1762] D loss: 1.0289, G loss: 2.8108\n",
      "[324/1762] D loss: 0.6055, G loss: 4.3065\n",
      "[404/1762] D loss: 0.7128, G loss: 9.1801\n",
      "[484/1762] D loss: 0.6548, G loss: 10.7809\n",
      "[564/1762] D loss: 1.0316, G loss: 7.0038\n",
      "[644/1762] D loss: 0.7260, G loss: 6.8655\n",
      "[724/1762] D loss: 0.6982, G loss: 5.9891\n",
      "[804/1762] D loss: 0.9306, G loss: 1.5773\n",
      "[884/1762] D loss: 1.4735, G loss: 2.0141\n",
      "[964/1762] D loss: 0.6946, G loss: 7.2807\n",
      "[1044/1762] D loss: 0.7716, G loss: 12.0627\n",
      "[1124/1762] D loss: 1.0455, G loss: 7.3866\n",
      "[1204/1762] D loss: 0.5935, G loss: 8.4534\n",
      "[1284/1762] D loss: 0.7380, G loss: 8.1937\n",
      "[1364/1762] D loss: 0.4205, G loss: 16.0506\n",
      "[1444/1762] D loss: 0.7676, G loss: 10.2843\n",
      "[1524/1762] D loss: 1.0684, G loss: 3.5147\n",
      "[1604/1762] D loss: 0.8508, G loss: 11.5358\n",
      "[1684/1762] D loss: 0.8551, G loss: 6.1750\n",
      "[1762/1762] D loss: 0.1848, G loss: 16.3400\n",
      "train error: \n",
      " D loss: 0.701794, G loss: 10.065610, D accuracy: 78.9%, cell accuracy: 99.6%, board accuracy: 64.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.666502, G loss: 11.259240, D accuracy: 80.0%, cell accuracy: 99.5%, board accuracy: 59.3% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5598, G loss: 5.5043\n",
      "[84/1762] D loss: 0.8310, G loss: 2.1053\n",
      "[164/1762] D loss: 0.7443, G loss: 10.9792\n",
      "[244/1762] D loss: 0.3186, G loss: 13.4042\n",
      "[324/1762] D loss: 0.6141, G loss: 12.0167\n",
      "[404/1762] D loss: 0.7350, G loss: 6.1907\n",
      "[484/1762] D loss: 0.7736, G loss: 9.1379\n",
      "[564/1762] D loss: 0.7681, G loss: 9.1575\n",
      "[644/1762] D loss: 1.0903, G loss: 2.8547\n",
      "[724/1762] D loss: 1.0781, G loss: 5.2049\n",
      "[804/1762] D loss: 0.7751, G loss: 4.7680\n",
      "[884/1762] D loss: 0.7755, G loss: 7.7490\n",
      "[964/1762] D loss: 0.3290, G loss: 8.1330\n",
      "[1044/1762] D loss: 0.6178, G loss: 6.6291\n",
      "[1124/1762] D loss: 0.8541, G loss: 3.7672\n",
      "[1204/1762] D loss: 0.6968, G loss: 13.3639\n",
      "[1284/1762] D loss: 0.0735, G loss: 22.3140\n",
      "[1364/1762] D loss: 0.9327, G loss: 9.5610\n",
      "[1444/1762] D loss: 1.0554, G loss: 5.2635\n",
      "[1524/1762] D loss: 0.9499, G loss: 14.1074\n",
      "[1604/1762] D loss: 0.4740, G loss: 19.2843\n",
      "[1684/1762] D loss: 0.5940, G loss: 12.0157\n",
      "[1762/1762] D loss: 0.7328, G loss: 9.6700\n",
      "train error: \n",
      " D loss: 0.728448, G loss: 9.897241, D accuracy: 78.7%, cell accuracy: 99.6%, board accuracy: 64.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.667429, G loss: 11.179148, D accuracy: 80.5%, cell accuracy: 99.5%, board accuracy: 60.0% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9682, G loss: 2.1725\n",
      "[84/1762] D loss: 0.2716, G loss: 10.7731\n",
      "[164/1762] D loss: 0.6804, G loss: 10.6764\n",
      "[244/1762] D loss: 0.0876, G loss: 22.9294\n",
      "[324/1762] D loss: 0.2413, G loss: 12.3690\n",
      "[404/1762] D loss: 1.2840, G loss: 3.0869\n",
      "[484/1762] D loss: 0.1713, G loss: 15.3492\n",
      "[564/1762] D loss: 0.7488, G loss: 12.6663\n",
      "[644/1762] D loss: 0.7841, G loss: 4.1204\n",
      "[724/1762] D loss: 0.8491, G loss: 2.8977\n",
      "[804/1762] D loss: 1.4018, G loss: 1.6048\n",
      "[884/1762] D loss: 1.0915, G loss: 2.7466\n",
      "[964/1762] D loss: 0.1115, G loss: 10.3722\n",
      "[1044/1762] D loss: 0.7051, G loss: 3.6810\n",
      "[1124/1762] D loss: 0.7533, G loss: 5.7788\n",
      "[1204/1762] D loss: 0.4393, G loss: 15.2641\n",
      "[1284/1762] D loss: 1.0844, G loss: 3.8183\n",
      "[1364/1762] D loss: 0.9916, G loss: 1.7721\n",
      "[1444/1762] D loss: 0.8144, G loss: 9.4852\n",
      "[1524/1762] D loss: 0.5429, G loss: 12.0933\n",
      "[1604/1762] D loss: 0.8586, G loss: 5.7481\n",
      "[1684/1762] D loss: 0.6967, G loss: 10.1902\n",
      "[1762/1762] D loss: 0.7856, G loss: 8.6442\n",
      "train error: \n",
      " D loss: 0.783781, G loss: 8.993303, D accuracy: 77.2%, cell accuracy: 99.6%, board accuracy: 65.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.742833, G loss: 10.295759, D accuracy: 78.1%, cell accuracy: 99.5%, board accuracy: 61.6% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7669, G loss: 17.8999\n",
      "[84/1762] D loss: 0.6690, G loss: 9.5315\n",
      "[164/1762] D loss: 0.6265, G loss: 8.3569\n",
      "[244/1762] D loss: 0.0444, G loss: 14.9847\n",
      "[324/1762] D loss: 0.6554, G loss: 18.8192\n",
      "[404/1762] D loss: 0.7753, G loss: 6.0398\n",
      "[484/1762] D loss: 0.6852, G loss: 6.6032\n",
      "[564/1762] D loss: 0.8074, G loss: 9.3414\n",
      "[644/1762] D loss: 1.0296, G loss: 13.1892\n",
      "[724/1762] D loss: 1.0436, G loss: 4.8016\n",
      "[804/1762] D loss: 1.0359, G loss: 2.4583\n",
      "[884/1762] D loss: 0.7484, G loss: 3.8474\n",
      "[964/1762] D loss: 0.7066, G loss: 15.6073\n",
      "[1044/1762] D loss: 0.8569, G loss: 2.3274\n",
      "[1124/1762] D loss: 0.6941, G loss: 14.9486\n",
      "[1204/1762] D loss: 0.1947, G loss: 19.8577\n",
      "[1284/1762] D loss: 1.3813, G loss: 0.8174\n",
      "[1364/1762] D loss: 0.7546, G loss: 5.7604\n",
      "[1444/1762] D loss: 0.3833, G loss: 9.6563\n",
      "[1524/1762] D loss: 0.6252, G loss: 7.8257\n",
      "[1604/1762] D loss: 1.1514, G loss: 1.5158\n",
      "[1684/1762] D loss: 0.5960, G loss: 13.4480\n",
      "[1762/1762] D loss: 0.0279, G loss: 7.9421\n",
      "train error: \n",
      " D loss: 0.681753, G loss: 10.321538, D accuracy: 79.6%, cell accuracy: 99.6%, board accuracy: 64.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.642645, G loss: 11.710567, D accuracy: 80.5%, cell accuracy: 99.5%, board accuracy: 61.4% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4366, G loss: 16.7822\n",
      "[84/1762] D loss: 0.7851, G loss: 19.9388\n",
      "[164/1762] D loss: 1.3123, G loss: 3.8846\n",
      "[244/1762] D loss: 0.6899, G loss: 2.8480\n",
      "[324/1762] D loss: 1.3196, G loss: 0.9342\n",
      "[404/1762] D loss: 0.8916, G loss: 8.4470\n",
      "[484/1762] D loss: 0.6928, G loss: 23.7718\n",
      "[564/1762] D loss: 0.6802, G loss: 15.8283\n",
      "[644/1762] D loss: 0.6946, G loss: 14.9069\n",
      "[724/1762] D loss: 0.4146, G loss: 15.9957\n",
      "[804/1762] D loss: 0.7656, G loss: 1.7424\n",
      "[884/1762] D loss: 0.7457, G loss: 15.3009\n",
      "[964/1762] D loss: 1.0616, G loss: 7.1579\n",
      "[1044/1762] D loss: 0.3661, G loss: 13.2915\n",
      "[1124/1762] D loss: 0.9866, G loss: 16.1843\n",
      "[1204/1762] D loss: 0.0314, G loss: 23.6679\n",
      "[1284/1762] D loss: 0.0414, G loss: 17.0686\n",
      "[1364/1762] D loss: 0.6239, G loss: 4.5342\n",
      "[1444/1762] D loss: 0.9358, G loss: 9.0616\n",
      "[1524/1762] D loss: 1.9084, G loss: 0.8453\n",
      "[1604/1762] D loss: 0.7359, G loss: 4.3985\n",
      "[1684/1762] D loss: 0.7795, G loss: 11.9887\n",
      "[1762/1762] D loss: 0.0211, G loss: 27.8399\n",
      "train error: \n",
      " D loss: 0.705328, G loss: 8.473281, D accuracy: 78.2%, cell accuracy: 99.6%, board accuracy: 65.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.673122, G loss: 9.643545, D accuracy: 79.5%, cell accuracy: 99.5%, board accuracy: 60.2% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6926, G loss: 13.2742\n",
      "[84/1762] D loss: 0.7105, G loss: 10.2316\n",
      "[164/1762] D loss: 0.4667, G loss: 9.5077\n",
      "[244/1762] D loss: 0.4774, G loss: 9.2283\n",
      "[324/1762] D loss: 0.5881, G loss: 8.4775\n",
      "[404/1762] D loss: 0.7533, G loss: 3.2958\n",
      "[484/1762] D loss: 0.5141, G loss: 15.0551\n",
      "[564/1762] D loss: 1.1735, G loss: 4.4107\n",
      "[644/1762] D loss: 0.6956, G loss: 10.6614\n",
      "[724/1762] D loss: 0.6602, G loss: 9.6047\n",
      "[804/1762] D loss: 1.0727, G loss: 7.7245\n",
      "[884/1762] D loss: 0.7683, G loss: 11.1764\n",
      "[964/1762] D loss: 0.8515, G loss: 1.4359\n",
      "[1044/1762] D loss: 0.0135, G loss: 16.2185\n",
      "[1124/1762] D loss: 0.3795, G loss: 6.3265\n",
      "[1204/1762] D loss: 1.2225, G loss: 1.5000\n",
      "[1284/1762] D loss: 0.3488, G loss: 14.4367\n",
      "[1364/1762] D loss: 0.4762, G loss: 8.7575\n",
      "[1444/1762] D loss: 0.3735, G loss: 34.2378\n",
      "[1524/1762] D loss: 1.0513, G loss: 1.7714\n",
      "[1604/1762] D loss: 0.4764, G loss: 10.0630\n",
      "[1684/1762] D loss: 0.4946, G loss: 4.4605\n",
      "[1762/1762] D loss: 0.9483, G loss: 1.4253\n",
      "train error: \n",
      " D loss: 0.759258, G loss: 8.490206, D accuracy: 76.8%, cell accuracy: 99.6%, board accuracy: 66.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.701227, G loss: 9.409285, D accuracy: 78.6%, cell accuracy: 99.5%, board accuracy: 62.5% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6948, G loss: 7.0183\n",
      "[84/1762] D loss: 0.7000, G loss: 4.8696\n",
      "[164/1762] D loss: 0.5091, G loss: 10.9697\n",
      "[244/1762] D loss: 0.6990, G loss: 13.7449\n",
      "[324/1762] D loss: 0.6956, G loss: 18.3254\n",
      "[404/1762] D loss: 0.6980, G loss: 11.2669\n",
      "[484/1762] D loss: 1.0553, G loss: 7.2096\n",
      "[564/1762] D loss: 0.6865, G loss: 8.4779\n",
      "[644/1762] D loss: 0.9953, G loss: 12.3498\n",
      "[724/1762] D loss: 0.7275, G loss: 6.6060\n",
      "[804/1762] D loss: 0.4403, G loss: 9.9674\n",
      "[884/1762] D loss: 0.2318, G loss: 17.2664\n",
      "[964/1762] D loss: 0.6593, G loss: 16.7422\n",
      "[1044/1762] D loss: 0.7077, G loss: 15.4822\n",
      "[1124/1762] D loss: 0.7119, G loss: 14.5661\n",
      "[1204/1762] D loss: 1.0174, G loss: 8.3955\n",
      "[1284/1762] D loss: 0.7218, G loss: 8.6674\n",
      "[1364/1762] D loss: 0.8852, G loss: 14.6273\n",
      "[1444/1762] D loss: 0.8175, G loss: 5.3785\n",
      "[1524/1762] D loss: 0.3626, G loss: 10.9502\n",
      "[1604/1762] D loss: 1.2397, G loss: 9.2483\n",
      "[1684/1762] D loss: 0.7614, G loss: 10.7076\n",
      "[1762/1762] D loss: 0.7782, G loss: 3.1374\n",
      "train error: \n",
      " D loss: 0.703797, G loss: 8.769128, D accuracy: 79.8%, cell accuracy: 99.6%, board accuracy: 63.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.650415, G loss: 9.932697, D accuracy: 81.2%, cell accuracy: 99.5%, board accuracy: 60.9% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6650, G loss: 15.7618\n",
      "[84/1762] D loss: 0.5737, G loss: 2.7560\n",
      "[164/1762] D loss: 1.0059, G loss: 3.7471\n",
      "[244/1762] D loss: 0.3979, G loss: 17.2092\n",
      "[324/1762] D loss: 0.6946, G loss: 12.0858\n",
      "[404/1762] D loss: 0.3707, G loss: 21.6421\n",
      "[484/1762] D loss: 0.7324, G loss: 4.0486\n",
      "[564/1762] D loss: 0.3468, G loss: 12.5223\n",
      "[644/1762] D loss: 0.9567, G loss: 1.3244\n",
      "[724/1762] D loss: 0.6821, G loss: 19.2178\n",
      "[804/1762] D loss: 0.8004, G loss: 3.2765\n",
      "[884/1762] D loss: 0.6855, G loss: 8.0218\n",
      "[964/1762] D loss: 1.0551, G loss: 5.9512\n",
      "[1044/1762] D loss: 0.7491, G loss: 13.3138\n",
      "[1124/1762] D loss: 0.7127, G loss: 14.4668\n",
      "[1204/1762] D loss: 1.0401, G loss: 12.0393\n",
      "[1284/1762] D loss: 1.3905, G loss: 0.8330\n",
      "[1364/1762] D loss: 1.0308, G loss: 10.4006\n",
      "[1444/1762] D loss: 0.8837, G loss: 8.5977\n",
      "[1524/1762] D loss: 0.8176, G loss: 9.0624\n",
      "[1604/1762] D loss: 0.1015, G loss: 14.7978\n",
      "[1684/1762] D loss: 1.0974, G loss: 1.3317\n",
      "[1762/1762] D loss: 1.1440, G loss: 16.8061\n",
      "train error: \n",
      " D loss: 0.743776, G loss: 12.091727, D accuracy: 76.9%, cell accuracy: 99.6%, board accuracy: 64.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.686309, G loss: 13.644891, D accuracy: 79.0%, cell accuracy: 99.5%, board accuracy: 60.2% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0923, G loss: 6.7517\n",
      "[84/1762] D loss: 0.7927, G loss: 10.2778\n",
      "[164/1762] D loss: 0.5717, G loss: 13.0025\n",
      "[244/1762] D loss: 0.8802, G loss: 2.8414\n",
      "[324/1762] D loss: 0.6406, G loss: 16.4306\n",
      "[404/1762] D loss: 0.4028, G loss: 5.8981\n",
      "[484/1762] D loss: 0.6049, G loss: 15.9457\n",
      "[564/1762] D loss: 0.4393, G loss: 12.9225\n",
      "[644/1762] D loss: 0.6058, G loss: 20.1728\n",
      "[724/1762] D loss: 0.5275, G loss: 8.3434\n",
      "[804/1762] D loss: 0.5785, G loss: 27.3060\n",
      "[884/1762] D loss: 1.0368, G loss: 4.3033\n",
      "[964/1762] D loss: 1.0590, G loss: 2.6708\n",
      "[1044/1762] D loss: 0.7559, G loss: 7.4889\n",
      "[1124/1762] D loss: 0.6810, G loss: 13.1906\n",
      "[1204/1762] D loss: 0.7750, G loss: 17.1207\n",
      "[1284/1762] D loss: 1.0303, G loss: 12.3658\n",
      "[1364/1762] D loss: 0.4980, G loss: 20.0190\n",
      "[1444/1762] D loss: 0.5607, G loss: 4.7994\n",
      "[1524/1762] D loss: 0.5228, G loss: 12.9497\n",
      "[1604/1762] D loss: 0.3693, G loss: 14.7757\n",
      "[1684/1762] D loss: 1.1205, G loss: 1.8437\n",
      "[1762/1762] D loss: 1.3902, G loss: 0.6893\n",
      "train error: \n",
      " D loss: 0.661314, G loss: 11.270170, D accuracy: 80.1%, cell accuracy: 99.6%, board accuracy: 64.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.613940, G loss: 12.945293, D accuracy: 81.7%, cell accuracy: 99.5%, board accuracy: 60.7% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7305, G loss: 7.2530\n",
      "[84/1762] D loss: 0.9774, G loss: 5.2486\n",
      "[164/1762] D loss: 0.3753, G loss: 10.6328\n",
      "[244/1762] D loss: 0.9059, G loss: 3.3995\n",
      "[324/1762] D loss: 0.3627, G loss: 17.9302\n",
      "[404/1762] D loss: 0.6404, G loss: 6.3892\n",
      "[484/1762] D loss: 0.5577, G loss: 11.8518\n",
      "[564/1762] D loss: 0.9010, G loss: 10.2673\n",
      "[644/1762] D loss: 0.4965, G loss: 13.9069\n",
      "[724/1762] D loss: 0.7004, G loss: 3.5059\n",
      "[804/1762] D loss: 0.3386, G loss: 11.2734\n",
      "[884/1762] D loss: 0.6334, G loss: 2.9130\n",
      "[964/1762] D loss: 0.3559, G loss: 12.2112\n",
      "[1044/1762] D loss: 0.3441, G loss: 23.6031\n",
      "[1124/1762] D loss: 0.6410, G loss: 17.9248\n",
      "[1204/1762] D loss: 0.7034, G loss: 7.3542\n",
      "[1284/1762] D loss: 1.0304, G loss: 9.6665\n",
      "[1364/1762] D loss: 1.0041, G loss: 11.5434\n",
      "[1444/1762] D loss: 0.4237, G loss: 16.4375\n",
      "[1524/1762] D loss: 0.7608, G loss: 2.3656\n",
      "[1604/1762] D loss: 0.5504, G loss: 11.2144\n",
      "[1684/1762] D loss: 1.0987, G loss: 2.5140\n",
      "[1762/1762] D loss: 1.9998, G loss: 0.3351\n",
      "train error: \n",
      " D loss: 0.739069, G loss: 8.375765, D accuracy: 77.8%, cell accuracy: 99.6%, board accuracy: 63.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.657349, G loss: 9.686692, D accuracy: 80.9%, cell accuracy: 99.5%, board accuracy: 60.2% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0235, G loss: 5.8764\n",
      "[84/1762] D loss: 0.8718, G loss: 2.3144\n",
      "[164/1762] D loss: 0.3968, G loss: 13.8598\n",
      "[244/1762] D loss: 1.0145, G loss: 2.0209\n",
      "[324/1762] D loss: 0.8696, G loss: 8.7061\n",
      "[404/1762] D loss: 0.8834, G loss: 5.6530\n",
      "[484/1762] D loss: 0.7941, G loss: 6.1493\n",
      "[564/1762] D loss: 0.3401, G loss: 12.3926\n",
      "[644/1762] D loss: 0.7819, G loss: 4.0590\n",
      "[724/1762] D loss: 0.8882, G loss: 6.0713\n",
      "[804/1762] D loss: 0.4180, G loss: 14.4771\n",
      "[884/1762] D loss: 0.2707, G loss: 16.1970\n",
      "[964/1762] D loss: 0.8749, G loss: 8.2380\n",
      "[1044/1762] D loss: 1.0331, G loss: 10.5975\n",
      "[1124/1762] D loss: 0.4861, G loss: 11.1994\n",
      "[1204/1762] D loss: 0.3369, G loss: 26.3699\n",
      "[1284/1762] D loss: 0.6537, G loss: 4.0757\n",
      "[1364/1762] D loss: 0.5016, G loss: 5.3538\n",
      "[1444/1762] D loss: 0.7327, G loss: 8.0898\n",
      "[1524/1762] D loss: 0.9512, G loss: 5.0179\n",
      "[1604/1762] D loss: 0.7687, G loss: 10.5748\n",
      "[1684/1762] D loss: 1.2229, G loss: 1.0613\n",
      "[1762/1762] D loss: 0.7149, G loss: 4.9080\n",
      "train error: \n",
      " D loss: 0.697502, G loss: 13.158221, D accuracy: 78.8%, cell accuracy: 99.5%, board accuracy: 61.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.653672, G loss: 14.678037, D accuracy: 81.0%, cell accuracy: 99.5%, board accuracy: 58.9% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7760, G loss: 4.9905\n",
      "[84/1762] D loss: 0.4271, G loss: 10.8831\n",
      "[164/1762] D loss: 1.1845, G loss: 0.8725\n",
      "[244/1762] D loss: 0.5613, G loss: 7.1539\n",
      "[324/1762] D loss: 0.8153, G loss: 9.1871\n",
      "[404/1762] D loss: 0.9186, G loss: 7.6877\n",
      "[484/1762] D loss: 0.4975, G loss: 7.1156\n",
      "[564/1762] D loss: 0.7672, G loss: 7.3782\n",
      "[644/1762] D loss: 0.4378, G loss: 21.3080\n",
      "[724/1762] D loss: 0.2548, G loss: 6.6838\n",
      "[804/1762] D loss: 1.1060, G loss: 3.6492\n",
      "[884/1762] D loss: 0.9719, G loss: 13.1895\n",
      "[964/1762] D loss: 0.4901, G loss: 9.4530\n",
      "[1044/1762] D loss: 0.9594, G loss: 1.2733\n",
      "[1124/1762] D loss: 0.5142, G loss: 4.1944\n",
      "[1204/1762] D loss: 0.6511, G loss: 3.2991\n",
      "[1284/1762] D loss: 0.7551, G loss: 5.5166\n",
      "[1364/1762] D loss: 0.4639, G loss: 8.7782\n",
      "[1444/1762] D loss: 0.7056, G loss: 14.0448\n",
      "[1524/1762] D loss: 0.6969, G loss: 10.5973\n",
      "[1604/1762] D loss: 0.3700, G loss: 14.8098\n",
      "[1684/1762] D loss: 0.7840, G loss: 13.7581\n",
      "[1762/1762] D loss: 0.5131, G loss: 1.8704\n",
      "train error: \n",
      " D loss: 0.696170, G loss: 16.888567, D accuracy: 79.2%, cell accuracy: 99.5%, board accuracy: 62.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.681630, G loss: 18.911324, D accuracy: 80.3%, cell accuracy: 99.4%, board accuracy: 57.0% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3781, G loss: 26.1586\n",
      "[84/1762] D loss: 0.5801, G loss: 6.2890\n",
      "[164/1762] D loss: 1.0709, G loss: 3.5923\n",
      "[244/1762] D loss: 1.5289, G loss: 0.9148\n",
      "[324/1762] D loss: 0.5285, G loss: 11.5931\n",
      "[404/1762] D loss: 0.3265, G loss: 11.9045\n",
      "[484/1762] D loss: 0.8061, G loss: 7.3173\n",
      "[564/1762] D loss: 0.3810, G loss: 21.0817\n",
      "[644/1762] D loss: 1.3188, G loss: 1.0547\n",
      "[724/1762] D loss: 0.8793, G loss: 11.6625\n",
      "[804/1762] D loss: 0.3934, G loss: 40.9082\n",
      "[884/1762] D loss: 0.4705, G loss: 10.9439\n",
      "[964/1762] D loss: 0.0008, G loss: 29.0495\n",
      "[1044/1762] D loss: 0.5897, G loss: 7.6217\n",
      "[1124/1762] D loss: 0.5526, G loss: 14.6502\n",
      "[1204/1762] D loss: 0.4993, G loss: 3.3881\n",
      "[1284/1762] D loss: 1.0399, G loss: 3.5657\n",
      "[1364/1762] D loss: 0.3761, G loss: 28.8489\n",
      "[1444/1762] D loss: 0.3408, G loss: 8.7056\n",
      "[1524/1762] D loss: 0.6298, G loss: 14.3168\n",
      "[1604/1762] D loss: 0.7839, G loss: 8.3336\n",
      "[1684/1762] D loss: 0.1483, G loss: 36.1861\n",
      "[1762/1762] D loss: 0.0563, G loss: 27.4559\n",
      "train error: \n",
      " D loss: 0.644378, G loss: 12.849150, D accuracy: 81.1%, cell accuracy: 99.6%, board accuracy: 64.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.592807, G loss: 14.354305, D accuracy: 82.6%, cell accuracy: 99.5%, board accuracy: 60.2% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0338, G loss: 9.1377\n",
      "[84/1762] D loss: 0.7318, G loss: 11.0752\n",
      "[164/1762] D loss: 1.2171, G loss: 30.2532\n",
      "[244/1762] D loss: 0.4359, G loss: 14.5611\n",
      "[324/1762] D loss: 0.8675, G loss: 1.9994\n",
      "[404/1762] D loss: 0.6978, G loss: 13.6045\n",
      "[484/1762] D loss: 0.5825, G loss: 21.8060\n",
      "[564/1762] D loss: 1.1366, G loss: 2.8561\n",
      "[644/1762] D loss: 0.9992, G loss: 3.2150\n",
      "[724/1762] D loss: 0.3643, G loss: 13.1560\n",
      "[804/1762] D loss: 1.2726, G loss: 1.0394\n",
      "[884/1762] D loss: 0.3471, G loss: 25.1259\n",
      "[964/1762] D loss: 0.4378, G loss: 11.1379\n",
      "[1044/1762] D loss: 0.4420, G loss: 10.4020\n",
      "[1124/1762] D loss: 0.9616, G loss: 3.9478\n",
      "[1204/1762] D loss: 1.0873, G loss: 9.3671\n",
      "[1284/1762] D loss: 1.2038, G loss: 13.8955\n",
      "[1364/1762] D loss: 0.8420, G loss: 1.7629\n",
      "[1444/1762] D loss: 0.0483, G loss: 23.6735\n",
      "[1524/1762] D loss: 1.1993, G loss: 2.9299\n",
      "[1604/1762] D loss: 0.6105, G loss: 3.8084\n",
      "[1684/1762] D loss: 0.9382, G loss: 8.4126\n",
      "[1762/1762] D loss: 1.5549, G loss: 0.5298\n",
      "train error: \n",
      " D loss: 0.630082, G loss: 14.227944, D accuracy: 81.3%, cell accuracy: 99.5%, board accuracy: 61.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.600458, G loss: 16.381287, D accuracy: 82.6%, cell accuracy: 99.5%, board accuracy: 58.0% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8449, G loss: 4.1055\n",
      "[84/1762] D loss: 1.1352, G loss: 11.1894\n",
      "[164/1762] D loss: 0.6466, G loss: 5.5234\n",
      "[244/1762] D loss: 0.4293, G loss: 6.5479\n",
      "[324/1762] D loss: 0.2060, G loss: 8.8068\n",
      "[404/1762] D loss: 0.6247, G loss: 11.6917\n",
      "[484/1762] D loss: 1.0061, G loss: 17.9854\n",
      "[564/1762] D loss: 0.1846, G loss: 10.8983\n",
      "[644/1762] D loss: 0.9396, G loss: 11.6820\n",
      "[724/1762] D loss: 0.5659, G loss: 6.7507\n",
      "[804/1762] D loss: 0.6420, G loss: 14.2492\n",
      "[884/1762] D loss: 0.2539, G loss: 25.2551\n",
      "[964/1762] D loss: 0.9189, G loss: 3.6644\n",
      "[1044/1762] D loss: 0.7610, G loss: 13.1680\n",
      "[1124/1762] D loss: 0.6788, G loss: 7.5462\n",
      "[1204/1762] D loss: 0.3034, G loss: 20.8676\n",
      "[1284/1762] D loss: 0.9795, G loss: 3.6411\n",
      "[1364/1762] D loss: 0.0338, G loss: 16.8656\n",
      "[1444/1762] D loss: 0.0723, G loss: 9.3642\n",
      "[1524/1762] D loss: 0.4361, G loss: 9.8993\n",
      "[1604/1762] D loss: 0.7354, G loss: 6.6712\n",
      "[1684/1762] D loss: 0.5952, G loss: 8.6440\n",
      "[1762/1762] D loss: 0.0025, G loss: 13.3706\n",
      "train error: \n",
      " D loss: 0.666238, G loss: 12.061769, D accuracy: 80.3%, cell accuracy: 99.6%, board accuracy: 65.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.621530, G loss: 13.384220, D accuracy: 81.0%, cell accuracy: 99.5%, board accuracy: 60.5% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7133, G loss: 10.3412\n",
      "[84/1762] D loss: 0.5925, G loss: 11.6955\n",
      "[164/1762] D loss: 0.0074, G loss: 24.0006\n",
      "[244/1762] D loss: 0.3858, G loss: 19.0877\n",
      "[324/1762] D loss: 0.3700, G loss: 10.6280\n",
      "[404/1762] D loss: 0.5929, G loss: 10.7080\n",
      "[484/1762] D loss: 0.6218, G loss: 17.0966\n",
      "[564/1762] D loss: 0.4875, G loss: 5.8703\n",
      "[644/1762] D loss: 0.6822, G loss: 5.0739\n",
      "[724/1762] D loss: 0.3264, G loss: 9.5951\n",
      "[804/1762] D loss: 0.7535, G loss: 7.2106\n",
      "[884/1762] D loss: 0.0047, G loss: 21.5624\n",
      "[964/1762] D loss: 0.0000, G loss: 44.2559\n",
      "[1044/1762] D loss: 1.2809, G loss: 0.7009\n",
      "[1124/1762] D loss: 0.3720, G loss: 16.6075\n",
      "[1204/1762] D loss: 0.5946, G loss: 4.3193\n",
      "[1284/1762] D loss: 0.8858, G loss: 7.8246\n",
      "[1364/1762] D loss: 0.6643, G loss: 12.7229\n",
      "[1444/1762] D loss: 0.9872, G loss: 16.4635\n",
      "[1524/1762] D loss: 0.6773, G loss: 14.5408\n",
      "[1604/1762] D loss: 1.2687, G loss: 13.1844\n",
      "[1684/1762] D loss: 0.6551, G loss: 5.7121\n",
      "[1762/1762] D loss: 0.6716, G loss: 18.0766\n",
      "train error: \n",
      " D loss: 0.616841, G loss: 12.574352, D accuracy: 81.4%, cell accuracy: 99.6%, board accuracy: 64.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.586156, G loss: 14.242998, D accuracy: 83.6%, cell accuracy: 99.5%, board accuracy: 60.5% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2176, G loss: 0.7772\n",
      "[84/1762] D loss: 0.6705, G loss: 7.4564\n",
      "[164/1762] D loss: 0.4285, G loss: 6.4098\n",
      "[244/1762] D loss: 0.7228, G loss: 9.3621\n",
      "[324/1762] D loss: 0.0063, G loss: 17.9132\n",
      "[404/1762] D loss: 0.5468, G loss: 34.2369\n",
      "[484/1762] D loss: 0.1159, G loss: 22.7101\n",
      "[564/1762] D loss: 0.5162, G loss: 15.1985\n",
      "[644/1762] D loss: 0.7471, G loss: 4.1217\n",
      "[724/1762] D loss: 0.7868, G loss: 32.4068\n",
      "[804/1762] D loss: 0.0541, G loss: 18.4285\n",
      "[884/1762] D loss: 0.9112, G loss: 2.2817\n",
      "[964/1762] D loss: 0.7029, G loss: 20.1276\n",
      "[1044/1762] D loss: 0.9565, G loss: 10.1778\n",
      "[1124/1762] D loss: 0.7580, G loss: 7.1376\n",
      "[1204/1762] D loss: 0.2616, G loss: 25.7899\n",
      "[1284/1762] D loss: 0.3017, G loss: 7.7202\n",
      "[1364/1762] D loss: 0.4049, G loss: 11.0203\n",
      "[1444/1762] D loss: 0.0678, G loss: 21.1745\n",
      "[1524/1762] D loss: 0.1094, G loss: 13.5162\n",
      "[1604/1762] D loss: 0.5095, G loss: 10.9677\n",
      "[1684/1762] D loss: 0.7471, G loss: 10.2705\n",
      "[1762/1762] D loss: 0.4933, G loss: 2.2432\n",
      "train error: \n",
      " D loss: 0.627107, G loss: 13.663397, D accuracy: 81.5%, cell accuracy: 99.6%, board accuracy: 64.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.582458, G loss: 15.057103, D accuracy: 83.1%, cell accuracy: 99.5%, board accuracy: 60.2% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0759, G loss: 1.5578\n",
      "[84/1762] D loss: 0.3847, G loss: 21.1690\n",
      "[164/1762] D loss: 0.2304, G loss: 12.0652\n",
      "[244/1762] D loss: 0.3812, G loss: 10.7589\n",
      "[324/1762] D loss: 0.0195, G loss: 25.8778\n",
      "[404/1762] D loss: 0.3554, G loss: 7.9189\n",
      "[484/1762] D loss: 0.7470, G loss: 9.2711\n",
      "[564/1762] D loss: 0.6523, G loss: 15.0496\n",
      "[644/1762] D loss: 0.5959, G loss: 17.4110\n",
      "[724/1762] D loss: 0.3404, G loss: 15.4453\n",
      "[804/1762] D loss: 0.8297, G loss: 4.9222\n",
      "[884/1762] D loss: 1.0889, G loss: 15.7392\n",
      "[964/1762] D loss: 0.5583, G loss: 16.3223\n",
      "[1044/1762] D loss: 0.3796, G loss: 14.0919\n",
      "[1124/1762] D loss: 0.3389, G loss: 23.2308\n",
      "[1204/1762] D loss: 0.8547, G loss: 14.8496\n",
      "[1284/1762] D loss: 0.3721, G loss: 4.4104\n",
      "[1364/1762] D loss: 0.7278, G loss: 11.3154\n",
      "[1444/1762] D loss: 0.6433, G loss: 10.7144\n",
      "[1524/1762] D loss: 0.6502, G loss: 16.3961\n",
      "[1604/1762] D loss: 0.5863, G loss: 5.2535\n",
      "[1684/1762] D loss: 1.1611, G loss: 9.2328\n",
      "[1762/1762] D loss: 0.7782, G loss: 3.4129\n",
      "train error: \n",
      " D loss: 0.645944, G loss: 11.273617, D accuracy: 81.7%, cell accuracy: 99.6%, board accuracy: 64.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.606225, G loss: 12.836779, D accuracy: 82.0%, cell accuracy: 99.5%, board accuracy: 59.5% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3856, G loss: 9.2586\n",
      "[84/1762] D loss: 1.0437, G loss: 3.8165\n",
      "[164/1762] D loss: 1.2820, G loss: 8.7906\n",
      "[244/1762] D loss: 0.3494, G loss: 17.5205\n",
      "[324/1762] D loss: 0.3903, G loss: 4.0249\n",
      "[404/1762] D loss: 0.8415, G loss: 17.9788\n",
      "[484/1762] D loss: 0.6098, G loss: 23.8112\n",
      "[564/1762] D loss: 0.0691, G loss: 10.9003\n",
      "[644/1762] D loss: 0.6924, G loss: 16.5947\n",
      "[724/1762] D loss: 0.8228, G loss: 4.8903\n",
      "[804/1762] D loss: 1.0830, G loss: 1.1422\n",
      "[884/1762] D loss: 0.6313, G loss: 7.9903\n",
      "[964/1762] D loss: 0.6484, G loss: 14.1378\n",
      "[1044/1762] D loss: 0.1240, G loss: 15.1641\n",
      "[1124/1762] D loss: 0.1894, G loss: 12.4732\n",
      "[1204/1762] D loss: 1.1006, G loss: 8.4120\n",
      "[1284/1762] D loss: 0.7699, G loss: 4.5372\n",
      "[1364/1762] D loss: 0.3911, G loss: 15.9333\n",
      "[1444/1762] D loss: 1.0899, G loss: 7.3385\n",
      "[1524/1762] D loss: 0.8716, G loss: 2.1303\n",
      "[1604/1762] D loss: 0.4425, G loss: 7.2100\n",
      "[1684/1762] D loss: 0.6949, G loss: 12.0975\n",
      "[1762/1762] D loss: 0.9662, G loss: 2.8379\n",
      "train error: \n",
      " D loss: 0.743311, G loss: 8.907267, D accuracy: 78.8%, cell accuracy: 99.6%, board accuracy: 64.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.691137, G loss: 10.074786, D accuracy: 79.8%, cell accuracy: 99.5%, board accuracy: 58.9% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6374, G loss: 9.7580\n",
      "[84/1762] D loss: 1.0085, G loss: 11.6623\n",
      "[164/1762] D loss: 0.7099, G loss: 6.7922\n",
      "[244/1762] D loss: 0.5272, G loss: 3.0893\n",
      "[324/1762] D loss: 0.7720, G loss: 9.9043\n",
      "[404/1762] D loss: 0.9616, G loss: 7.6540\n",
      "[484/1762] D loss: 0.0091, G loss: 15.1275\n",
      "[564/1762] D loss: 0.7086, G loss: 4.2744\n",
      "[644/1762] D loss: 0.3474, G loss: 28.4811\n",
      "[724/1762] D loss: 0.5038, G loss: 9.1032\n",
      "[804/1762] D loss: 1.2498, G loss: 3.6421\n",
      "[884/1762] D loss: 0.4015, G loss: 7.6923\n",
      "[964/1762] D loss: 0.7295, G loss: 10.0240\n",
      "[1044/1762] D loss: 0.4747, G loss: 21.3621\n",
      "[1124/1762] D loss: 0.7361, G loss: 10.4237\n",
      "[1204/1762] D loss: 0.8467, G loss: 16.1343\n",
      "[1284/1762] D loss: 0.6622, G loss: 12.4788\n",
      "[1364/1762] D loss: 0.7019, G loss: 19.5212\n",
      "[1444/1762] D loss: 1.0841, G loss: 2.8228\n",
      "[1524/1762] D loss: 0.5677, G loss: 13.2539\n",
      "[1604/1762] D loss: 0.0812, G loss: 33.1362\n",
      "[1684/1762] D loss: 0.6727, G loss: 8.4226\n",
      "[1762/1762] D loss: 0.3644, G loss: 22.6110\n",
      "train error: \n",
      " D loss: 0.617264, G loss: 10.857366, D accuracy: 82.9%, cell accuracy: 99.6%, board accuracy: 65.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.558211, G loss: 12.490329, D accuracy: 84.3%, cell accuracy: 99.5%, board accuracy: 60.9% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4664, G loss: 3.8353\n",
      "[84/1762] D loss: 0.6518, G loss: 3.3210\n",
      "[164/1762] D loss: 0.7877, G loss: 8.4603\n",
      "[244/1762] D loss: 1.1122, G loss: 4.7591\n",
      "[324/1762] D loss: 0.5011, G loss: 7.7413\n",
      "[404/1762] D loss: 0.3900, G loss: 11.3300\n",
      "[484/1762] D loss: 0.4284, G loss: 21.5741\n",
      "[564/1762] D loss: 0.7619, G loss: 1.9008\n",
      "[644/1762] D loss: 0.3452, G loss: 7.9855\n",
      "[724/1762] D loss: 1.0808, G loss: 6.3285\n",
      "[804/1762] D loss: 0.7784, G loss: 1.6729\n",
      "[884/1762] D loss: 0.6993, G loss: 22.8138\n",
      "[964/1762] D loss: 0.3489, G loss: 11.1108\n",
      "[1044/1762] D loss: 0.9058, G loss: 12.1799\n",
      "[1124/1762] D loss: 1.0901, G loss: 17.7015\n",
      "[1204/1762] D loss: 0.6738, G loss: 5.8562\n",
      "[1284/1762] D loss: 0.3700, G loss: 18.7930\n",
      "[1364/1762] D loss: 0.0208, G loss: 22.3504\n",
      "[1444/1762] D loss: 0.4335, G loss: 15.0695\n",
      "[1524/1762] D loss: 1.1161, G loss: 15.4667\n",
      "[1604/1762] D loss: 0.3930, G loss: 17.7207\n",
      "[1684/1762] D loss: 0.3544, G loss: 14.5276\n",
      "[1762/1762] D loss: 1.3609, G loss: 1.2588\n",
      "train error: \n",
      " D loss: 0.573625, G loss: 14.678056, D accuracy: 82.2%, cell accuracy: 99.6%, board accuracy: 63.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.534242, G loss: 16.457736, D accuracy: 83.9%, cell accuracy: 99.5%, board accuracy: 59.3% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3684, G loss: 21.5786\n",
      "[84/1762] D loss: 0.8886, G loss: 6.2235\n",
      "[164/1762] D loss: 0.7125, G loss: 6.3761\n",
      "[244/1762] D loss: 0.4317, G loss: 17.5942\n",
      "[324/1762] D loss: 0.7522, G loss: 9.7935\n",
      "[404/1762] D loss: 1.2261, G loss: 5.8193\n",
      "[484/1762] D loss: 0.7206, G loss: 10.1195\n",
      "[564/1762] D loss: 0.0433, G loss: 16.7306\n",
      "[644/1762] D loss: 0.7392, G loss: 8.6971\n",
      "[724/1762] D loss: 0.0332, G loss: 28.9147\n",
      "[804/1762] D loss: 1.1285, G loss: 7.3842\n",
      "[884/1762] D loss: 0.4034, G loss: 14.6548\n",
      "[964/1762] D loss: 0.3856, G loss: 6.2787\n",
      "[1044/1762] D loss: 0.6874, G loss: 3.4444\n",
      "[1124/1762] D loss: 0.4905, G loss: 4.3492\n",
      "[1204/1762] D loss: 2.2278, G loss: 0.4806\n",
      "[1284/1762] D loss: 0.3542, G loss: 20.6484\n",
      "[1364/1762] D loss: 1.0430, G loss: 8.0718\n",
      "[1444/1762] D loss: 0.3991, G loss: 22.5147\n",
      "[1524/1762] D loss: 0.0160, G loss: 18.1892\n",
      "[1604/1762] D loss: 0.8585, G loss: 14.4665\n",
      "[1684/1762] D loss: 0.9505, G loss: 5.5010\n",
      "[1762/1762] D loss: 0.0586, G loss: 17.8896\n",
      "train error: \n",
      " D loss: 0.634609, G loss: 10.014474, D accuracy: 81.7%, cell accuracy: 99.6%, board accuracy: 63.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.592543, G loss: 11.686801, D accuracy: 82.5%, cell accuracy: 99.5%, board accuracy: 60.0% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0978, G loss: 26.4680\n",
      "[84/1762] D loss: 0.0241, G loss: 23.0902\n",
      "[164/1762] D loss: 0.0929, G loss: 9.6762\n",
      "[244/1762] D loss: 0.1673, G loss: 9.3177\n",
      "[324/1762] D loss: 1.2888, G loss: 5.6943\n",
      "[404/1762] D loss: 0.7338, G loss: 7.8411\n",
      "[484/1762] D loss: 0.2644, G loss: 21.5905\n",
      "[564/1762] D loss: 0.5292, G loss: 11.2260\n",
      "[644/1762] D loss: 0.1021, G loss: 10.4168\n",
      "[724/1762] D loss: 0.5886, G loss: 20.3056\n",
      "[804/1762] D loss: 0.8033, G loss: 2.2010\n",
      "[884/1762] D loss: 0.8438, G loss: 2.4699\n",
      "[964/1762] D loss: 0.8082, G loss: 7.8579\n",
      "[1044/1762] D loss: 0.1047, G loss: 20.7898\n",
      "[1124/1762] D loss: 0.8723, G loss: 2.8612\n",
      "[1204/1762] D loss: 1.3440, G loss: 1.9089\n",
      "[1284/1762] D loss: 0.3813, G loss: 15.9851\n",
      "[1364/1762] D loss: 1.1222, G loss: 17.3619\n",
      "[1444/1762] D loss: 0.6973, G loss: 1.5487\n",
      "[1524/1762] D loss: 1.3100, G loss: 0.6890\n",
      "[1604/1762] D loss: 0.7785, G loss: 9.6072\n",
      "[1684/1762] D loss: 0.3642, G loss: 19.7175\n",
      "[1762/1762] D loss: 0.8698, G loss: 4.1997\n",
      "train error: \n",
      " D loss: 0.564937, G loss: 13.567867, D accuracy: 84.3%, cell accuracy: 99.6%, board accuracy: 65.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.524871, G loss: 15.632298, D accuracy: 85.7%, cell accuracy: 99.5%, board accuracy: 61.8% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4036, G loss: 0.6311\n",
      "[84/1762] D loss: 1.2994, G loss: 0.7982\n",
      "[164/1762] D loss: 0.9515, G loss: 1.1073\n",
      "[244/1762] D loss: 0.3696, G loss: 1.7358\n",
      "[324/1762] D loss: 0.1831, G loss: 2.5430\n",
      "[404/1762] D loss: 0.1528, G loss: 2.9129\n",
      "[484/1762] D loss: 0.0922, G loss: 3.6868\n",
      "[564/1762] D loss: 0.2302, G loss: 3.5221\n",
      "[644/1762] D loss: 0.5387, G loss: 2.8933\n",
      "[724/1762] D loss: 0.2188, G loss: 2.9090\n",
      "[804/1762] D loss: 0.6898, G loss: 2.7097\n",
      "[884/1762] D loss: 0.3047, G loss: 4.6565\n",
      "[964/1762] D loss: 0.0484, G loss: 4.4430\n",
      "[1044/1762] D loss: 3.1143, G loss: 0.9522\n",
      "[1124/1762] D loss: 1.2757, G loss: 0.6662\n",
      "[1204/1762] D loss: 1.1295, G loss: 0.8462\n",
      "[1284/1762] D loss: 1.5160, G loss: 1.5248\n",
      "[1364/1762] D loss: 1.5684, G loss: 0.4069\n",
      "[1444/1762] D loss: 1.1114, G loss: 1.1764\n",
      "[1524/1762] D loss: 0.9259, G loss: 1.0795\n",
      "[1604/1762] D loss: 0.8659, G loss: 1.2113\n",
      "[1684/1762] D loss: 0.8376, G loss: 1.1905\n",
      "[1762/1762] D loss: 3.1853, G loss: 2.8487\n",
      "train error: \n",
      " D loss: 1.227576, G loss: 1.139765, D accuracy: 65.9%, cell accuracy: 98.9%, board accuracy: 9.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.189593, G loss: 1.197948, D accuracy: 69.0%, cell accuracy: 98.7%, board accuracy: 8.4% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3268, G loss: 1.0379\n",
      "[84/1762] D loss: 1.0626, G loss: 1.2326\n",
      "[164/1762] D loss: 1.5938, G loss: 1.2203\n",
      "[244/1762] D loss: 1.4450, G loss: 0.3551\n",
      "[324/1762] D loss: 1.4881, G loss: 1.3287\n",
      "[404/1762] D loss: 1.2903, G loss: 1.3701\n",
      "[484/1762] D loss: 1.3688, G loss: 0.6911\n",
      "[564/1762] D loss: 1.0784, G loss: 0.7968\n",
      "[644/1762] D loss: 1.4445, G loss: 0.5631\n",
      "[724/1762] D loss: 1.3962, G loss: 0.7577\n",
      "[804/1762] D loss: 1.2667, G loss: 1.0715\n",
      "[884/1762] D loss: 0.6165, G loss: 1.2180\n",
      "[964/1762] D loss: 0.7949, G loss: 1.1752\n",
      "[1044/1762] D loss: 1.4339, G loss: 0.6119\n",
      "[1124/1762] D loss: 0.6339, G loss: 1.5162\n",
      "[1204/1762] D loss: 1.3087, G loss: 0.9716\n",
      "[1284/1762] D loss: 1.4072, G loss: 0.5105\n",
      "[1364/1762] D loss: 0.4249, G loss: 1.6758\n",
      "[1444/1762] D loss: 1.3535, G loss: 0.7054\n",
      "[1524/1762] D loss: 0.7420, G loss: 1.2699\n",
      "[1604/1762] D loss: 1.1255, G loss: 0.9273\n",
      "[1684/1762] D loss: 1.3597, G loss: 0.6795\n",
      "[1762/1762] D loss: 1.3947, G loss: 0.7773\n",
      "train error: \n",
      " D loss: 1.303513, G loss: 0.943595, D accuracy: 57.3%, cell accuracy: 99.7%, board accuracy: 68.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.276958, G loss: 0.969756, D accuracy: 56.8%, cell accuracy: 99.7%, board accuracy: 68.0% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1430, G loss: 1.1130\n",
      "[84/1762] D loss: 1.0952, G loss: 0.9626\n",
      "[164/1762] D loss: 1.3534, G loss: 0.6567\n",
      "[244/1762] D loss: 1.4602, G loss: 0.6948\n",
      "[324/1762] D loss: 1.4188, G loss: 0.8840\n",
      "[404/1762] D loss: 0.6694, G loss: 1.0598\n",
      "[484/1762] D loss: 1.4071, G loss: 1.0031\n",
      "[564/1762] D loss: 1.3459, G loss: 0.6806\n",
      "[644/1762] D loss: 1.2829, G loss: 0.6366\n",
      "[724/1762] D loss: 1.4861, G loss: 0.4657\n",
      "[804/1762] D loss: 1.3180, G loss: 0.6664\n",
      "[884/1762] D loss: 1.3949, G loss: 0.6276\n",
      "[964/1762] D loss: 0.6272, G loss: 0.9398\n",
      "[1044/1762] D loss: 1.3841, G loss: 0.6874\n",
      "[1124/1762] D loss: 1.2682, G loss: 0.7292\n",
      "[1204/1762] D loss: 1.4284, G loss: 0.7577\n",
      "[1284/1762] D loss: 1.5201, G loss: 0.7944\n",
      "[1364/1762] D loss: 0.4151, G loss: 1.4405\n",
      "[1444/1762] D loss: 1.3938, G loss: 0.6961\n",
      "[1524/1762] D loss: 0.2051, G loss: 1.8199\n",
      "[1604/1762] D loss: 1.4626, G loss: 0.9494\n",
      "[1684/1762] D loss: 1.6275, G loss: 0.4729\n",
      "[1762/1762] D loss: 1.3649, G loss: 1.1262\n",
      "train error: \n",
      " D loss: 1.351867, G loss: 0.715718, D accuracy: 54.1%, cell accuracy: 99.7%, board accuracy: 65.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.344616, G loss: 0.720831, D accuracy: 54.2%, cell accuracy: 99.6%, board accuracy: 62.0% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3829, G loss: 1.7461\n",
      "[84/1762] D loss: 0.7800, G loss: 0.7654\n",
      "[164/1762] D loss: 0.2552, G loss: 1.6386\n",
      "[244/1762] D loss: 1.7270, G loss: 1.3204\n",
      "[324/1762] D loss: 1.3886, G loss: 0.7372\n",
      "[404/1762] D loss: 1.3925, G loss: 0.6142\n",
      "[484/1762] D loss: 1.3903, G loss: 0.5449\n",
      "[564/1762] D loss: 1.3943, G loss: 0.8339\n",
      "[644/1762] D loss: 1.3938, G loss: 0.6555\n",
      "[724/1762] D loss: 1.4259, G loss: 0.4901\n",
      "[804/1762] D loss: 1.3951, G loss: 0.8360\n",
      "[884/1762] D loss: 1.4093, G loss: 0.7250\n",
      "[964/1762] D loss: 1.4148, G loss: 0.8597\n",
      "[1044/1762] D loss: 0.3557, G loss: 1.3962\n",
      "[1124/1762] D loss: 0.4595, G loss: 1.1791\n",
      "[1204/1762] D loss: 1.4423, G loss: 0.8526\n",
      "[1284/1762] D loss: 1.4394, G loss: 0.5853\n",
      "[1364/1762] D loss: 1.0486, G loss: 1.0467\n",
      "[1444/1762] D loss: 1.3162, G loss: 0.7797\n",
      "[1524/1762] D loss: 1.3869, G loss: 0.7374\n",
      "[1604/1762] D loss: 1.6816, G loss: 0.3895\n",
      "[1684/1762] D loss: 1.3967, G loss: 0.6230\n",
      "[1762/1762] D loss: 1.3961, G loss: 0.8299\n",
      "train error: \n",
      " D loss: 1.328037, G loss: 0.808348, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 87.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.305132, G loss: 0.827095, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 84.3% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4495, G loss: 0.9311\n",
      "[84/1762] D loss: 1.3824, G loss: 0.6225\n",
      "[164/1762] D loss: 1.2506, G loss: 0.7385\n",
      "[244/1762] D loss: 1.6427, G loss: 0.3316\n",
      "[324/1762] D loss: 0.6450, G loss: 0.9605\n",
      "[404/1762] D loss: 1.3434, G loss: 0.9403\n",
      "[484/1762] D loss: 1.1388, G loss: 1.4478\n",
      "[564/1762] D loss: 0.4735, G loss: 1.1492\n",
      "[644/1762] D loss: 1.4107, G loss: 0.9685\n",
      "[724/1762] D loss: 0.4310, G loss: 1.2235\n",
      "[804/1762] D loss: 1.3871, G loss: 0.5713\n",
      "[884/1762] D loss: 1.0571, G loss: 0.9230\n",
      "[964/1762] D loss: 1.4227, G loss: 0.8196\n",
      "[1044/1762] D loss: 1.2718, G loss: 1.1150\n",
      "[1124/1762] D loss: 1.5903, G loss: 0.3423\n",
      "[1204/1762] D loss: 0.3774, G loss: 1.6074\n",
      "[1284/1762] D loss: 1.6098, G loss: 1.1709\n",
      "[1364/1762] D loss: 1.5143, G loss: 0.9963\n",
      "[1444/1762] D loss: 0.4415, G loss: 1.2305\n",
      "[1524/1762] D loss: 0.4586, G loss: 1.1806\n",
      "[1604/1762] D loss: 1.4877, G loss: 0.4421\n",
      "[1684/1762] D loss: 1.4184, G loss: 0.6004\n",
      "[1762/1762] D loss: 1.3987, G loss: 0.5880\n",
      "train error: \n",
      " D loss: 1.388935, G loss: 0.520890, D accuracy: 51.8%, cell accuracy: 99.8%, board accuracy: 89.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.373369, G loss: 0.527216, D accuracy: 52.2%, cell accuracy: 99.7%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3950, G loss: 0.7130\n",
      "[84/1762] D loss: 1.3901, G loss: 0.6984\n",
      "[164/1762] D loss: 1.3854, G loss: 0.6778\n",
      "[244/1762] D loss: 1.3870, G loss: 0.6902\n",
      "[324/1762] D loss: 1.3862, G loss: 0.6858\n",
      "[404/1762] D loss: 1.3871, G loss: 0.6977\n",
      "[484/1762] D loss: 1.3867, G loss: 0.6994\n",
      "[564/1762] D loss: 1.3676, G loss: 0.7022\n",
      "[644/1762] D loss: 1.3874, G loss: 0.7035\n",
      "[724/1762] D loss: 1.3104, G loss: 0.7423\n",
      "[804/1762] D loss: 1.3877, G loss: 0.7172\n",
      "[884/1762] D loss: 1.3962, G loss: 0.7499\n",
      "[964/1762] D loss: 1.0835, G loss: 0.9018\n",
      "[1044/1762] D loss: 1.4075, G loss: 0.7914\n",
      "[1124/1762] D loss: 1.4116, G loss: 0.7770\n",
      "[1204/1762] D loss: 0.7289, G loss: 0.8976\n",
      "[1284/1762] D loss: 0.7971, G loss: 0.8941\n",
      "[1364/1762] D loss: 1.3962, G loss: 0.8807\n",
      "[1444/1762] D loss: 1.3923, G loss: 0.7526\n",
      "[1524/1762] D loss: 1.4459, G loss: 0.9706\n",
      "[1604/1762] D loss: 1.3920, G loss: 0.7638\n",
      "[1684/1762] D loss: 1.4269, G loss: 0.9003\n",
      "[1762/1762] D loss: 0.4914, G loss: 1.0704\n",
      "train error: \n",
      " D loss: 1.407737, G loss: 0.500586, D accuracy: 50.3%, cell accuracy: 99.7%, board accuracy: 88.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.393708, G loss: 0.503593, D accuracy: 50.2%, cell accuracy: 99.7%, board accuracy: 85.2% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4471, G loss: 0.9836\n",
      "[84/1762] D loss: 1.4284, G loss: 0.8620\n",
      "[164/1762] D loss: 1.5223, G loss: 1.0825\n",
      "[244/1762] D loss: 0.8042, G loss: 0.7258\n",
      "[324/1762] D loss: 1.4029, G loss: 0.8212\n",
      "[404/1762] D loss: 1.4030, G loss: 0.8114\n",
      "[484/1762] D loss: 1.4369, G loss: 0.9355\n",
      "[564/1762] D loss: 0.6376, G loss: 0.8884\n",
      "[644/1762] D loss: 1.4125, G loss: 0.8315\n",
      "[724/1762] D loss: 1.4753, G loss: 1.0610\n",
      "[804/1762] D loss: 1.5208, G loss: 1.1265\n",
      "[884/1762] D loss: 1.3837, G loss: 0.8448\n",
      "[964/1762] D loss: 1.4253, G loss: 0.8994\n",
      "[1044/1762] D loss: 1.4570, G loss: 0.9988\n",
      "[1124/1762] D loss: 0.6470, G loss: 0.7899\n",
      "[1204/1762] D loss: 0.6192, G loss: 0.7900\n",
      "[1284/1762] D loss: 1.4660, G loss: 0.9800\n",
      "[1364/1762] D loss: 1.5400, G loss: 1.1824\n",
      "[1444/1762] D loss: 1.4079, G loss: 0.8517\n",
      "[1524/1762] D loss: 1.4014, G loss: 0.8137\n",
      "[1604/1762] D loss: 1.4360, G loss: 0.9330\n",
      "[1684/1762] D loss: 1.3912, G loss: 0.6923\n",
      "[1762/1762] D loss: 1.3905, G loss: 0.7604\n",
      "train error: \n",
      " D loss: 1.333691, G loss: 0.743103, D accuracy: 53.6%, cell accuracy: 99.7%, board accuracy: 86.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.319945, G loss: 0.744627, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 85.2% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3887, G loss: 0.7434\n",
      "[84/1762] D loss: 1.3872, G loss: 0.7117\n",
      "[164/1762] D loss: 1.4625, G loss: 1.0039\n",
      "[244/1762] D loss: 1.4126, G loss: 0.8450\n",
      "[324/1762] D loss: 1.4165, G loss: 0.8905\n",
      "[404/1762] D loss: 1.4046, G loss: 0.8091\n",
      "[484/1762] D loss: 1.4140, G loss: 0.8785\n",
      "[564/1762] D loss: 1.3914, G loss: 0.7616\n",
      "[644/1762] D loss: 1.3626, G loss: 0.7404\n",
      "[724/1762] D loss: 1.4109, G loss: 0.8473\n",
      "[804/1762] D loss: 1.4221, G loss: 0.8827\n",
      "[884/1762] D loss: 1.4008, G loss: 0.7873\n",
      "[964/1762] D loss: 1.4863, G loss: 1.0545\n",
      "[1044/1762] D loss: 0.5367, G loss: 0.8951\n",
      "[1124/1762] D loss: 1.4908, G loss: 1.0519\n",
      "[1204/1762] D loss: 1.4361, G loss: 0.8963\n",
      "[1284/1762] D loss: 0.5876, G loss: 0.8259\n",
      "[1364/1762] D loss: 0.5756, G loss: 0.8438\n",
      "[1444/1762] D loss: 1.3577, G loss: 0.7851\n",
      "[1524/1762] D loss: 1.3895, G loss: 0.7501\n",
      "[1604/1762] D loss: 1.4266, G loss: 0.9171\n",
      "[1684/1762] D loss: 1.4019, G loss: 0.8088\n",
      "[1762/1762] D loss: 1.4191, G loss: 0.8871\n",
      "train error: \n",
      " D loss: 1.333415, G loss: 0.774466, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 89.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.319465, G loss: 0.778031, D accuracy: 55.0%, cell accuracy: 99.7%, board accuracy: 85.5% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5493, G loss: 0.8752\n",
      "[84/1762] D loss: 0.5593, G loss: 0.8624\n",
      "[164/1762] D loss: 1.9290, G loss: 0.6880\n",
      "[244/1762] D loss: 1.3669, G loss: 0.7656\n",
      "[324/1762] D loss: 1.4031, G loss: 0.8187\n",
      "[404/1762] D loss: 1.4330, G loss: 0.9323\n",
      "[484/1762] D loss: 1.3322, G loss: 0.8669\n",
      "[564/1762] D loss: 1.4754, G loss: 0.8140\n",
      "[644/1762] D loss: 0.6296, G loss: 0.8055\n",
      "[724/1762] D loss: 0.5489, G loss: 0.8860\n",
      "[804/1762] D loss: 0.5250, G loss: 0.9065\n",
      "[884/1762] D loss: 0.6709, G loss: 0.7704\n",
      "[964/1762] D loss: 1.4330, G loss: 0.9308\n",
      "[1044/1762] D loss: 1.3384, G loss: 0.7607\n",
      "[1124/1762] D loss: 1.4266, G loss: 0.9172\n",
      "[1204/1762] D loss: 0.5396, G loss: 0.8861\n",
      "[1284/1762] D loss: 1.4004, G loss: 0.8218\n",
      "[1364/1762] D loss: 0.6202, G loss: 0.7922\n",
      "[1444/1762] D loss: 1.4088, G loss: 0.8465\n",
      "[1524/1762] D loss: 0.5604, G loss: 0.8549\n",
      "[1604/1762] D loss: 1.4412, G loss: 0.9482\n",
      "[1684/1762] D loss: 0.5523, G loss: 0.8785\n",
      "[1762/1762] D loss: 1.4173, G loss: 0.8823\n",
      "train error: \n",
      " D loss: 1.334969, G loss: 0.816700, D accuracy: 54.4%, cell accuracy: 99.7%, board accuracy: 86.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.314670, G loss: 0.822456, D accuracy: 56.0%, cell accuracy: 99.6%, board accuracy: 83.6% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4434, G loss: 0.9516\n",
      "[84/1762] D loss: 0.5698, G loss: 0.8522\n",
      "[164/1762] D loss: 1.3771, G loss: 0.8294\n",
      "[244/1762] D loss: 1.4087, G loss: 0.8643\n",
      "[324/1762] D loss: 0.5748, G loss: 0.8350\n",
      "[404/1762] D loss: 1.4109, G loss: 0.8697\n",
      "[484/1762] D loss: 1.4093, G loss: 0.7094\n",
      "[564/1762] D loss: 1.4443, G loss: 0.9693\n",
      "[644/1762] D loss: 1.4114, G loss: 0.8401\n",
      "[724/1762] D loss: 1.4540, G loss: 0.9900\n",
      "[804/1762] D loss: 1.4124, G loss: 0.8561\n",
      "[884/1762] D loss: 1.4024, G loss: 0.8371\n",
      "[964/1762] D loss: 1.4073, G loss: 0.8543\n",
      "[1044/1762] D loss: 0.4769, G loss: 0.9753\n",
      "[1124/1762] D loss: 1.3970, G loss: 0.7771\n",
      "[1204/1762] D loss: 1.4191, G loss: 0.9163\n",
      "[1284/1762] D loss: 0.5229, G loss: 0.9204\n",
      "[1364/1762] D loss: 0.4780, G loss: 1.0143\n",
      "[1444/1762] D loss: 0.4607, G loss: 0.9991\n",
      "[1524/1762] D loss: 1.4183, G loss: 0.8718\n",
      "[1604/1762] D loss: 0.5581, G loss: 0.8643\n",
      "[1684/1762] D loss: 1.4047, G loss: 0.8233\n",
      "[1762/1762] D loss: 1.4080, G loss: 0.8460\n",
      "train error: \n",
      " D loss: 1.540204, G loss: 0.428423, D accuracy: 49.9%, cell accuracy: 99.7%, board accuracy: 86.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.539185, G loss: 0.424553, D accuracy: 50.1%, cell accuracy: 99.6%, board accuracy: 84.5% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3976, G loss: 0.7967\n",
      "[84/1762] D loss: 1.4073, G loss: 0.8448\n",
      "[164/1762] D loss: 1.4132, G loss: 0.8860\n",
      "[244/1762] D loss: 1.3673, G loss: 0.8241\n",
      "[324/1762] D loss: 1.4079, G loss: 0.8533\n",
      "[404/1762] D loss: 0.4883, G loss: 0.9635\n",
      "[484/1762] D loss: 1.4194, G loss: 0.8876\n",
      "[564/1762] D loss: 1.4665, G loss: 0.9994\n",
      "[644/1762] D loss: 1.4123, G loss: 0.8564\n",
      "[724/1762] D loss: 1.4460, G loss: 0.9693\n",
      "[804/1762] D loss: 1.4435, G loss: 0.9546\n",
      "[884/1762] D loss: 1.4020, G loss: 0.8238\n",
      "[964/1762] D loss: 1.3893, G loss: 0.7300\n",
      "[1044/1762] D loss: 1.4472, G loss: 0.9669\n",
      "[1124/1762] D loss: 0.5880, G loss: 0.8164\n",
      "[1204/1762] D loss: 0.5595, G loss: 0.8661\n",
      "[1284/1762] D loss: 1.4077, G loss: 0.8423\n",
      "[1364/1762] D loss: 0.4905, G loss: 0.9740\n",
      "[1444/1762] D loss: 1.1414, G loss: 0.9527\n",
      "[1524/1762] D loss: 1.4447, G loss: 0.9567\n",
      "[1604/1762] D loss: 1.3618, G loss: 0.8191\n",
      "[1684/1762] D loss: 1.3916, G loss: 0.7873\n",
      "[1762/1762] D loss: 1.4212, G loss: 0.8825\n",
      "train error: \n",
      " D loss: 1.344642, G loss: 0.715328, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.333711, G loss: 0.696078, D accuracy: 54.9%, cell accuracy: 99.7%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4052, G loss: 0.8302\n",
      "[84/1762] D loss: 1.4271, G loss: 0.9047\n",
      "[164/1762] D loss: 0.6585, G loss: 0.7616\n",
      "[244/1762] D loss: 1.4118, G loss: 0.8571\n",
      "[324/1762] D loss: 0.5293, G loss: 0.8995\n",
      "[404/1762] D loss: 0.5088, G loss: 0.9334\n",
      "[484/1762] D loss: 1.4085, G loss: 0.8232\n",
      "[564/1762] D loss: 0.4351, G loss: 1.0684\n",
      "[644/1762] D loss: 1.4803, G loss: 0.9126\n",
      "[724/1762] D loss: 1.4825, G loss: 1.0436\n",
      "[804/1762] D loss: 1.4021, G loss: 0.8184\n",
      "[884/1762] D loss: 1.3961, G loss: 0.7976\n",
      "[964/1762] D loss: 1.4202, G loss: 0.8934\n",
      "[1044/1762] D loss: 1.3965, G loss: 0.9315\n",
      "[1124/1762] D loss: 1.3929, G loss: 0.7689\n",
      "[1204/1762] D loss: 0.5618, G loss: 0.8588\n",
      "[1284/1762] D loss: 1.3880, G loss: 0.6700\n",
      "[1364/1762] D loss: 0.5607, G loss: 0.8561\n",
      "[1444/1762] D loss: 1.4467, G loss: 0.9814\n",
      "[1524/1762] D loss: 1.4179, G loss: 0.8721\n",
      "[1604/1762] D loss: 0.5093, G loss: 0.9348\n",
      "[1684/1762] D loss: 0.5162, G loss: 0.9272\n",
      "[1762/1762] D loss: 1.3937, G loss: 0.7706\n",
      "train error: \n",
      " D loss: 1.346213, G loss: 0.686208, D accuracy: 54.4%, cell accuracy: 99.7%, board accuracy: 88.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.327691, G loss: 0.693530, D accuracy: 55.1%, cell accuracy: 99.7%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5359, G loss: 0.9048\n",
      "[84/1762] D loss: 0.5085, G loss: 0.9374\n",
      "[164/1762] D loss: 0.5206, G loss: 0.9184\n",
      "[244/1762] D loss: 0.5264, G loss: 0.9103\n",
      "[324/1762] D loss: 0.5043, G loss: 0.9366\n",
      "[404/1762] D loss: 1.4502, G loss: 0.7970\n",
      "[484/1762] D loss: 1.4358, G loss: 0.8750\n",
      "[564/1762] D loss: 1.4078, G loss: 0.8604\n",
      "[644/1762] D loss: 1.4551, G loss: 0.9595\n",
      "[724/1762] D loss: 0.5294, G loss: 0.9025\n",
      "[804/1762] D loss: 1.3815, G loss: 0.8452\n",
      "[884/1762] D loss: 1.4158, G loss: 0.8767\n",
      "[964/1762] D loss: 0.4977, G loss: 0.9550\n",
      "[1044/1762] D loss: 1.2947, G loss: 0.9704\n",
      "[1124/1762] D loss: 1.3920, G loss: 0.7233\n",
      "[1204/1762] D loss: 1.3995, G loss: 0.8153\n",
      "[1284/1762] D loss: 1.4022, G loss: 0.8148\n",
      "[1364/1762] D loss: 1.3932, G loss: 0.7790\n",
      "[1444/1762] D loss: 0.5255, G loss: 0.9100\n",
      "[1524/1762] D loss: 1.3933, G loss: 0.7757\n",
      "[1604/1762] D loss: 1.3938, G loss: 0.7890\n",
      "[1684/1762] D loss: 0.3876, G loss: 1.1484\n",
      "[1762/1762] D loss: 1.4466, G loss: 0.9659\n",
      "train error: \n",
      " D loss: 1.332328, G loss: 0.823902, D accuracy: 54.4%, cell accuracy: 99.7%, board accuracy: 87.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.313459, G loss: 0.822056, D accuracy: 55.6%, cell accuracy: 99.7%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4347, G loss: 1.0526\n",
      "[84/1762] D loss: 0.5312, G loss: 0.9461\n",
      "[164/1762] D loss: 1.3956, G loss: 0.7853\n",
      "[244/1762] D loss: 1.3360, G loss: 0.6838\n",
      "[324/1762] D loss: 1.4001, G loss: 0.9315\n",
      "[404/1762] D loss: 0.4070, G loss: 1.1097\n",
      "[484/1762] D loss: 1.4195, G loss: 0.8648\n",
      "[564/1762] D loss: 1.4093, G loss: 0.8312\n",
      "[644/1762] D loss: 1.3925, G loss: 0.7540\n",
      "[724/1762] D loss: 1.3956, G loss: 0.7737\n",
      "[804/1762] D loss: 1.3865, G loss: 0.6477\n",
      "[884/1762] D loss: 0.6245, G loss: 0.8033\n",
      "[964/1762] D loss: 1.4070, G loss: 0.8619\n",
      "[1044/1762] D loss: 1.4433, G loss: 0.9264\n",
      "[1124/1762] D loss: 1.4085, G loss: 0.8554\n",
      "[1204/1762] D loss: 1.3898, G loss: 0.7346\n",
      "[1284/1762] D loss: 1.4623, G loss: 0.9964\n",
      "[1364/1762] D loss: 0.4891, G loss: 0.9814\n",
      "[1444/1762] D loss: 0.5960, G loss: 0.8821\n",
      "[1524/1762] D loss: 1.4862, G loss: 1.0772\n",
      "[1604/1762] D loss: 1.3196, G loss: 0.8489\n",
      "[1684/1762] D loss: 1.4212, G loss: 0.8814\n",
      "[1762/1762] D loss: 0.3507, G loss: 1.2118\n",
      "train error: \n",
      " D loss: 1.814500, G loss: 0.296951, D accuracy: 49.9%, cell accuracy: 99.7%, board accuracy: 86.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.842790, G loss: 0.277572, D accuracy: 49.8%, cell accuracy: 99.6%, board accuracy: 83.2% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4186, G loss: 0.8506\n",
      "[84/1762] D loss: 1.4062, G loss: 0.7991\n",
      "[164/1762] D loss: 1.4173, G loss: 0.8745\n",
      "[244/1762] D loss: 1.5683, G loss: 1.2275\n",
      "[324/1762] D loss: 1.4307, G loss: 0.9178\n",
      "[404/1762] D loss: 0.5463, G loss: 0.8868\n",
      "[484/1762] D loss: 1.2487, G loss: 0.8424\n",
      "[564/1762] D loss: 1.4181, G loss: 0.9357\n",
      "[644/1762] D loss: 0.5018, G loss: 0.9542\n",
      "[724/1762] D loss: 0.5518, G loss: 1.0187\n",
      "[804/1762] D loss: 1.4147, G loss: 0.6863\n",
      "[884/1762] D loss: 1.4638, G loss: 0.9765\n",
      "[964/1762] D loss: 1.3928, G loss: 0.7574\n",
      "[1044/1762] D loss: 1.3947, G loss: 0.7586\n",
      "[1124/1762] D loss: 0.5222, G loss: 0.9695\n",
      "[1204/1762] D loss: 1.3903, G loss: 0.7361\n",
      "[1284/1762] D loss: 1.4007, G loss: 0.8237\n",
      "[1364/1762] D loss: 1.3921, G loss: 0.6434\n",
      "[1444/1762] D loss: 1.2993, G loss: 0.9576\n",
      "[1524/1762] D loss: 1.4018, G loss: 0.8035\n",
      "[1604/1762] D loss: 1.3916, G loss: 0.6980\n",
      "[1684/1762] D loss: 1.4324, G loss: 0.9809\n",
      "[1762/1762] D loss: 1.4149, G loss: 0.8742\n",
      "train error: \n",
      " D loss: 1.340508, G loss: 0.775553, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 89.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.323569, G loss: 0.778676, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3973, G loss: 1.1191\n",
      "[84/1762] D loss: 0.9151, G loss: 0.9208\n",
      "[164/1762] D loss: 1.3893, G loss: 0.9882\n",
      "[244/1762] D loss: 1.4385, G loss: 0.9576\n",
      "[324/1762] D loss: 1.4329, G loss: 0.5378\n",
      "[404/1762] D loss: 0.6456, G loss: 0.7904\n",
      "[484/1762] D loss: 0.3160, G loss: 1.3024\n",
      "[564/1762] D loss: 1.4304, G loss: 0.9259\n",
      "[644/1762] D loss: 1.4063, G loss: 0.8420\n",
      "[724/1762] D loss: 1.4160, G loss: 0.8907\n",
      "[804/1762] D loss: 0.4583, G loss: 1.0079\n",
      "[884/1762] D loss: 1.4507, G loss: 0.9517\n",
      "[964/1762] D loss: 0.3850, G loss: 1.1972\n",
      "[1044/1762] D loss: 1.5581, G loss: 1.1848\n",
      "[1124/1762] D loss: 1.4017, G loss: 0.7688\n",
      "[1204/1762] D loss: 1.4097, G loss: 0.8667\n",
      "[1284/1762] D loss: 1.5461, G loss: 1.1463\n",
      "[1364/1762] D loss: 0.5062, G loss: 0.9421\n",
      "[1444/1762] D loss: 1.3370, G loss: 0.8726\n",
      "[1524/1762] D loss: 0.3713, G loss: 1.1759\n",
      "[1604/1762] D loss: 1.4792, G loss: 1.0345\n",
      "[1684/1762] D loss: 1.4584, G loss: 0.9761\n",
      "[1762/1762] D loss: 1.4027, G loss: 0.8110\n",
      "train error: \n",
      " D loss: 1.325718, G loss: 0.752031, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 89.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.307546, G loss: 0.759214, D accuracy: 55.8%, cell accuracy: 99.7%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4857, G loss: 0.9705\n",
      "[84/1762] D loss: 0.3898, G loss: 1.1860\n",
      "[164/1762] D loss: 1.4447, G loss: 0.9091\n",
      "[244/1762] D loss: 1.4144, G loss: 0.8887\n",
      "[324/1762] D loss: 1.4146, G loss: 0.8162\n",
      "[404/1762] D loss: 1.3391, G loss: 0.7947\n",
      "[484/1762] D loss: 0.4171, G loss: 1.1048\n",
      "[564/1762] D loss: 1.4479, G loss: 0.9480\n",
      "[644/1762] D loss: 1.3958, G loss: 0.7488\n",
      "[724/1762] D loss: 0.3660, G loss: 1.2055\n",
      "[804/1762] D loss: 0.4174, G loss: 1.0902\n",
      "[884/1762] D loss: 0.4150, G loss: 1.1634\n",
      "[964/1762] D loss: 0.4624, G loss: 1.0288\n",
      "[1044/1762] D loss: 0.8949, G loss: 0.8422\n",
      "[1124/1762] D loss: 1.4377, G loss: 1.0972\n",
      "[1204/1762] D loss: 0.5359, G loss: 0.9257\n",
      "[1284/1762] D loss: 1.6451, G loss: 1.2711\n",
      "[1364/1762] D loss: 1.4104, G loss: 0.6953\n",
      "[1444/1762] D loss: 1.4441, G loss: 0.9266\n",
      "[1524/1762] D loss: 1.4060, G loss: 0.8440\n",
      "[1604/1762] D loss: 0.5809, G loss: 0.8596\n",
      "[1684/1762] D loss: 1.3312, G loss: 0.8526\n",
      "[1762/1762] D loss: 0.3844, G loss: 1.1472\n",
      "train error: \n",
      " D loss: 1.551219, G loss: 0.367536, D accuracy: 50.0%, cell accuracy: 99.7%, board accuracy: 88.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.554477, G loss: 0.357716, D accuracy: 49.9%, cell accuracy: 99.7%, board accuracy: 85.5% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7175, G loss: 0.6963\n",
      "[84/1762] D loss: 0.7292, G loss: 1.0051\n",
      "[164/1762] D loss: 0.4973, G loss: 0.9493\n",
      "[244/1762] D loss: 1.3899, G loss: 0.7617\n",
      "[324/1762] D loss: 1.4737, G loss: 1.0334\n",
      "[404/1762] D loss: 1.3650, G loss: 0.7314\n",
      "[484/1762] D loss: 1.4589, G loss: 1.0296\n",
      "[564/1762] D loss: 1.4028, G loss: 0.8379\n",
      "[644/1762] D loss: 1.4028, G loss: 0.7466\n",
      "[724/1762] D loss: 0.3036, G loss: 1.3630\n",
      "[804/1762] D loss: 1.3921, G loss: 0.6418\n",
      "[884/1762] D loss: 1.4259, G loss: 0.5571\n",
      "[964/1762] D loss: 1.4576, G loss: 0.9879\n",
      "[1044/1762] D loss: 1.4234, G loss: 0.8848\n",
      "[1124/1762] D loss: 1.4111, G loss: 0.8366\n",
      "[1204/1762] D loss: 1.3381, G loss: 0.7422\n",
      "[1284/1762] D loss: 1.3974, G loss: 0.5839\n",
      "[1364/1762] D loss: 1.3878, G loss: 0.7574\n",
      "[1444/1762] D loss: 0.3456, G loss: 1.2110\n",
      "[1524/1762] D loss: 1.4440, G loss: 0.9435\n",
      "[1604/1762] D loss: 0.8701, G loss: 0.9575\n",
      "[1684/1762] D loss: 1.4824, G loss: 0.9866\n",
      "[1762/1762] D loss: 1.5414, G loss: 1.1268\n",
      "train error: \n",
      " D loss: 1.327217, G loss: 0.811335, D accuracy: 54.3%, cell accuracy: 99.7%, board accuracy: 88.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.308130, G loss: 0.816992, D accuracy: 55.7%, cell accuracy: 99.6%, board accuracy: 84.1% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4135, G loss: 0.5268\n",
      "[84/1762] D loss: 1.3999, G loss: 0.8149\n",
      "[164/1762] D loss: 0.9886, G loss: 1.0423\n",
      "[244/1762] D loss: 0.6585, G loss: 0.8123\n",
      "[324/1762] D loss: 1.3891, G loss: 0.7035\n",
      "[404/1762] D loss: 1.4813, G loss: 1.0288\n",
      "[484/1762] D loss: 1.5348, G loss: 1.1562\n",
      "[564/1762] D loss: 1.4068, G loss: 0.7972\n",
      "[644/1762] D loss: 0.4449, G loss: 1.0732\n",
      "[724/1762] D loss: 1.4212, G loss: 0.8452\n",
      "[804/1762] D loss: 1.3898, G loss: 0.7290\n",
      "[884/1762] D loss: 1.4528, G loss: 0.9499\n",
      "[964/1762] D loss: 1.4350, G loss: 0.9343\n",
      "[1044/1762] D loss: 1.5029, G loss: 1.0682\n",
      "[1124/1762] D loss: 1.3995, G loss: 0.5044\n",
      "[1204/1762] D loss: 1.4381, G loss: 1.0866\n",
      "[1284/1762] D loss: 1.3965, G loss: 0.6550\n",
      "[1364/1762] D loss: 1.4962, G loss: 0.9878\n",
      "[1444/1762] D loss: 0.4161, G loss: 1.1142\n",
      "[1524/1762] D loss: 0.7713, G loss: 0.7679\n",
      "[1604/1762] D loss: 0.1825, G loss: 1.8362\n",
      "[1684/1762] D loss: 0.2787, G loss: 1.4549\n",
      "[1762/1762] D loss: 1.8903, G loss: 1.5551\n",
      "train error: \n",
      " D loss: 1.357979, G loss: 0.618789, D accuracy: 52.2%, cell accuracy: 99.8%, board accuracy: 89.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.343765, G loss: 0.617908, D accuracy: 53.4%, cell accuracy: 99.7%, board accuracy: 85.7% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4440, G loss: 0.9055\n",
      "[84/1762] D loss: 1.4352, G loss: 0.9157\n",
      "[164/1762] D loss: 0.3339, G loss: 1.3532\n",
      "[244/1762] D loss: 0.4712, G loss: 1.0877\n",
      "[324/1762] D loss: 1.3968, G loss: 0.7619\n",
      "[404/1762] D loss: 0.3483, G loss: 1.2716\n",
      "[484/1762] D loss: 0.4830, G loss: 0.9647\n",
      "[564/1762] D loss: 1.3910, G loss: 0.7679\n",
      "[644/1762] D loss: 1.3907, G loss: 0.6411\n",
      "[724/1762] D loss: 1.3885, G loss: 0.6895\n",
      "[804/1762] D loss: 1.4039, G loss: 0.6617\n",
      "[884/1762] D loss: 1.3993, G loss: 0.7584\n",
      "[964/1762] D loss: 0.3658, G loss: 1.2059\n",
      "[1044/1762] D loss: 0.2461, G loss: 1.5572\n",
      "[1124/1762] D loss: 0.2840, G loss: 1.4494\n",
      "[1204/1762] D loss: 1.4238, G loss: 0.8867\n",
      "[1284/1762] D loss: 0.2973, G loss: 1.3562\n",
      "[1364/1762] D loss: 1.3965, G loss: 0.7379\n",
      "[1444/1762] D loss: 0.4908, G loss: 1.0298\n",
      "[1524/1762] D loss: 1.4258, G loss: 0.8694\n",
      "[1604/1762] D loss: 1.4216, G loss: 0.8329\n",
      "[1684/1762] D loss: 0.3941, G loss: 1.1713\n",
      "[1762/1762] D loss: 1.4332, G loss: 0.9073\n",
      "train error: \n",
      " D loss: 1.340223, G loss: 0.617723, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 88.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.324890, G loss: 0.619837, D accuracy: 55.6%, cell accuracy: 99.7%, board accuracy: 85.9% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4082, G loss: 0.8325\n",
      "[84/1762] D loss: 0.7525, G loss: 0.8942\n",
      "[164/1762] D loss: 0.4963, G loss: 0.9699\n",
      "[244/1762] D loss: 1.4764, G loss: 0.9658\n",
      "[324/1762] D loss: 0.3337, G loss: 1.3712\n",
      "[404/1762] D loss: 1.4574, G loss: 1.0367\n",
      "[484/1762] D loss: 1.7260, G loss: 1.3954\n",
      "[564/1762] D loss: 1.5234, G loss: 1.1237\n",
      "[644/1762] D loss: 0.8100, G loss: 0.9798\n",
      "[724/1762] D loss: 1.4424, G loss: 1.0348\n",
      "[804/1762] D loss: 0.3455, G loss: 1.2995\n",
      "[884/1762] D loss: 1.3866, G loss: 0.6500\n",
      "[964/1762] D loss: 0.7545, G loss: 1.0762\n",
      "[1044/1762] D loss: 1.3539, G loss: 0.8375\n",
      "[1124/1762] D loss: 0.3336, G loss: 1.3088\n",
      "[1204/1762] D loss: 1.3887, G loss: 0.7117\n",
      "[1284/1762] D loss: 1.3964, G loss: 0.6080\n",
      "[1364/1762] D loss: 1.3234, G loss: 1.0806\n",
      "[1444/1762] D loss: 1.5018, G loss: 1.1163\n",
      "[1524/1762] D loss: 1.3915, G loss: 1.2818\n",
      "[1604/1762] D loss: 1.4088, G loss: 0.8278\n",
      "[1684/1762] D loss: 0.3278, G loss: 1.3330\n",
      "[1762/1762] D loss: 1.3632, G loss: 0.6791\n",
      "train error: \n",
      " D loss: 1.326533, G loss: 0.662848, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 87.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.312373, G loss: 0.661879, D accuracy: 54.8%, cell accuracy: 99.6%, board accuracy: 83.6% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3894, G loss: 0.6683\n",
      "[84/1762] D loss: 1.5753, G loss: 1.2017\n",
      "[164/1762] D loss: 1.0640, G loss: 0.9032\n",
      "[244/1762] D loss: 1.3897, G loss: 0.6830\n",
      "[324/1762] D loss: 0.1676, G loss: 1.9819\n",
      "[404/1762] D loss: 1.4201, G loss: 0.6190\n",
      "[484/1762] D loss: 0.3465, G loss: 1.2619\n",
      "[564/1762] D loss: 1.4183, G loss: 0.8760\n",
      "[644/1762] D loss: 1.4019, G loss: 0.7811\n",
      "[724/1762] D loss: 1.3934, G loss: 0.8028\n",
      "[804/1762] D loss: 0.3036, G loss: 1.4765\n",
      "[884/1762] D loss: 0.3431, G loss: 1.2600\n",
      "[964/1762] D loss: 1.4350, G loss: 0.9180\n",
      "[1044/1762] D loss: 0.4791, G loss: 1.0177\n",
      "[1124/1762] D loss: 1.3946, G loss: 0.7081\n",
      "[1204/1762] D loss: 1.4731, G loss: 1.0082\n",
      "[1284/1762] D loss: 0.1012, G loss: 2.4136\n",
      "[1364/1762] D loss: 1.3969, G loss: 0.6928\n",
      "[1444/1762] D loss: 1.4073, G loss: 0.6204\n",
      "[1524/1762] D loss: 0.2738, G loss: 1.5450\n",
      "[1604/1762] D loss: 0.2793, G loss: 1.5203\n",
      "[1684/1762] D loss: 1.4440, G loss: 1.1696\n",
      "[1762/1762] D loss: 1.3986, G loss: 0.6681\n",
      "train error: \n",
      " D loss: 1.530135, G loss: 0.375185, D accuracy: 51.2%, cell accuracy: 99.7%, board accuracy: 87.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.527843, G loss: 0.375238, D accuracy: 51.5%, cell accuracy: 99.6%, board accuracy: 83.4% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4842, G loss: 0.4728\n",
      "[84/1762] D loss: 1.3874, G loss: 0.5848\n",
      "[164/1762] D loss: 1.4152, G loss: 0.8603\n",
      "[244/1762] D loss: 1.4072, G loss: 0.5779\n",
      "[324/1762] D loss: 1.5144, G loss: 1.0324\n",
      "[404/1762] D loss: 0.3488, G loss: 1.3978\n",
      "[484/1762] D loss: 1.9591, G loss: 1.7077\n",
      "[564/1762] D loss: 1.3952, G loss: 0.7782\n",
      "[644/1762] D loss: 0.9407, G loss: 1.1880\n",
      "[724/1762] D loss: 1.4340, G loss: 0.8099\n",
      "[804/1762] D loss: 0.2087, G loss: 1.7127\n",
      "[884/1762] D loss: 1.3362, G loss: 0.7133\n",
      "[964/1762] D loss: 0.4024, G loss: 1.2504\n",
      "[1044/1762] D loss: 1.4030, G loss: 0.7607\n",
      "[1124/1762] D loss: 1.5391, G loss: 1.1655\n",
      "[1204/1762] D loss: 1.4161, G loss: 0.8324\n",
      "[1284/1762] D loss: 1.2313, G loss: 0.8722\n",
      "[1364/1762] D loss: 1.3908, G loss: 0.7286\n",
      "[1444/1762] D loss: 1.3902, G loss: 0.6936\n",
      "[1524/1762] D loss: 0.1920, G loss: 1.8287\n",
      "[1604/1762] D loss: 1.3686, G loss: 0.8518\n",
      "[1684/1762] D loss: 0.3844, G loss: 1.1821\n",
      "[1762/1762] D loss: 1.4732, G loss: 1.0491\n",
      "train error: \n",
      " D loss: 1.314842, G loss: 0.837198, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 88.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.296577, G loss: 0.846854, D accuracy: 55.6%, cell accuracy: 99.6%, board accuracy: 85.9% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3880, G loss: 0.6996\n",
      "[84/1762] D loss: 0.4243, G loss: 1.1333\n",
      "[164/1762] D loss: 1.4042, G loss: 0.8373\n",
      "[244/1762] D loss: 1.6089, G loss: 1.2555\n",
      "[324/1762] D loss: 1.3935, G loss: 0.8009\n",
      "[404/1762] D loss: 0.4205, G loss: 1.2075\n",
      "[484/1762] D loss: 0.2217, G loss: 1.6830\n",
      "[564/1762] D loss: 0.4830, G loss: 0.9890\n",
      "[644/1762] D loss: 1.3898, G loss: 0.6885\n",
      "[724/1762] D loss: 1.4003, G loss: 0.6352\n",
      "[804/1762] D loss: 1.3952, G loss: 0.7831\n",
      "[884/1762] D loss: 1.6471, G loss: 1.2678\n",
      "[964/1762] D loss: 1.3866, G loss: 0.6855\n",
      "[1044/1762] D loss: 1.4355, G loss: 0.8863\n",
      "[1124/1762] D loss: 0.4093, G loss: 1.2400\n",
      "[1204/1762] D loss: 0.1466, G loss: 1.9999\n",
      "[1284/1762] D loss: 0.1680, G loss: 1.9325\n",
      "[1364/1762] D loss: 1.2880, G loss: 0.6307\n",
      "[1444/1762] D loss: 0.1582, G loss: 2.0688\n",
      "[1524/1762] D loss: 1.4577, G loss: 1.0163\n",
      "[1604/1762] D loss: 1.2470, G loss: 1.1230\n",
      "[1684/1762] D loss: 1.4071, G loss: 0.7297\n",
      "[1762/1762] D loss: 1.3875, G loss: 0.6492\n",
      "train error: \n",
      " D loss: 1.314466, G loss: 0.765603, D accuracy: 54.9%, cell accuracy: 99.7%, board accuracy: 87.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.296752, G loss: 0.770674, D accuracy: 55.6%, cell accuracy: 99.7%, board accuracy: 83.4% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3928, G loss: 0.7403\n",
      "[84/1762] D loss: 0.3576, G loss: 1.2744\n",
      "[164/1762] D loss: 0.1993, G loss: 1.7990\n",
      "[244/1762] D loss: 0.2605, G loss: 1.5605\n",
      "[324/1762] D loss: 1.4640, G loss: 0.8906\n",
      "[404/1762] D loss: 0.9065, G loss: 0.8825\n",
      "[484/1762] D loss: 1.4244, G loss: 0.7900\n",
      "[564/1762] D loss: 1.4984, G loss: 1.0121\n",
      "[644/1762] D loss: 1.4190, G loss: 0.8315\n",
      "[724/1762] D loss: 1.4611, G loss: 1.0012\n",
      "[804/1762] D loss: 1.4412, G loss: 0.8980\n",
      "[884/1762] D loss: 1.5248, G loss: 1.1132\n",
      "[964/1762] D loss: 1.4335, G loss: 0.8867\n",
      "[1044/1762] D loss: 1.6012, G loss: 1.4403\n",
      "[1124/1762] D loss: 1.2899, G loss: 0.8800\n",
      "[1204/1762] D loss: 1.4298, G loss: 0.8777\n",
      "[1284/1762] D loss: 1.4428, G loss: 0.9166\n",
      "[1364/1762] D loss: 0.1690, G loss: 2.0105\n",
      "[1444/1762] D loss: 1.4104, G loss: 0.5236\n",
      "[1524/1762] D loss: 1.2551, G loss: 1.0288\n",
      "[1604/1762] D loss: 1.3933, G loss: 0.6411\n",
      "[1684/1762] D loss: 1.4190, G loss: 0.5186\n",
      "[1762/1762] D loss: 1.4520, G loss: 0.9395\n",
      "train error: \n",
      " D loss: 1.311815, G loss: 0.707673, D accuracy: 54.6%, cell accuracy: 99.7%, board accuracy: 87.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.296326, G loss: 0.702306, D accuracy: 55.6%, cell accuracy: 99.7%, board accuracy: 85.2% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4288, G loss: 0.9826\n",
      "[84/1762] D loss: 1.3183, G loss: 0.6846\n",
      "[164/1762] D loss: 1.3899, G loss: 0.8074\n",
      "[244/1762] D loss: 1.4175, G loss: 0.5728\n",
      "[324/1762] D loss: 1.5002, G loss: 1.1289\n",
      "[404/1762] D loss: 1.4035, G loss: 0.7099\n",
      "[484/1762] D loss: 1.4186, G loss: 0.5396\n",
      "[564/1762] D loss: 1.3620, G loss: 0.4708\n",
      "[644/1762] D loss: 1.3834, G loss: 1.2600\n",
      "[724/1762] D loss: 0.3705, G loss: 1.2627\n",
      "[804/1762] D loss: 1.4041, G loss: 0.5895\n",
      "[884/1762] D loss: 1.3967, G loss: 0.7844\n",
      "[964/1762] D loss: 0.3067, G loss: 1.5265\n",
      "[1044/1762] D loss: 1.4126, G loss: 0.5702\n",
      "[1124/1762] D loss: 1.4792, G loss: 1.0366\n",
      "[1204/1762] D loss: 1.4738, G loss: 1.0697\n",
      "[1284/1762] D loss: 0.2225, G loss: 1.7226\n",
      "[1364/1762] D loss: 1.4506, G loss: 0.5012\n",
      "[1444/1762] D loss: 1.3069, G loss: 0.8733\n",
      "[1524/1762] D loss: 0.3373, G loss: 1.3415\n",
      "[1604/1762] D loss: 0.4728, G loss: 1.0641\n",
      "[1684/1762] D loss: 1.4088, G loss: 0.6305\n",
      "[1762/1762] D loss: 1.4322, G loss: 0.9742\n",
      "train error: \n",
      " D loss: 1.313387, G loss: 0.689745, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 87.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.289799, G loss: 0.700096, D accuracy: 55.9%, cell accuracy: 99.6%, board accuracy: 83.9% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4858, G loss: 1.0317\n",
      "[84/1762] D loss: 1.3955, G loss: 0.7668\n",
      "[164/1762] D loss: 1.4147, G loss: 0.6278\n",
      "[244/1762] D loss: 1.3947, G loss: 0.6189\n",
      "[324/1762] D loss: 0.2436, G loss: 1.6019\n",
      "[404/1762] D loss: 0.3858, G loss: 1.3193\n",
      "[484/1762] D loss: 0.1322, G loss: 2.1957\n",
      "[564/1762] D loss: 1.6169, G loss: 0.4023\n",
      "[644/1762] D loss: 0.2941, G loss: 1.4980\n",
      "[724/1762] D loss: 1.0895, G loss: 0.9528\n",
      "[804/1762] D loss: 1.5966, G loss: 1.2156\n",
      "[884/1762] D loss: 1.3989, G loss: 0.6355\n",
      "[964/1762] D loss: 0.1962, G loss: 1.8328\n",
      "[1044/1762] D loss: 0.3619, G loss: 1.4478\n",
      "[1124/1762] D loss: 0.1555, G loss: 2.0150\n",
      "[1204/1762] D loss: 1.4239, G loss: 0.8945\n",
      "[1284/1762] D loss: 1.4418, G loss: 0.9039\n",
      "[1364/1762] D loss: 0.1759, G loss: 2.0858\n",
      "[1444/1762] D loss: 0.9670, G loss: 0.6525\n",
      "[1524/1762] D loss: 0.2616, G loss: 1.5857\n",
      "[1604/1762] D loss: 0.1471, G loss: 2.2395\n",
      "[1684/1762] D loss: 1.5302, G loss: 1.0938\n",
      "[1762/1762] D loss: 0.1089, G loss: 2.4345\n",
      "train error: \n",
      " D loss: 2.651360, G loss: 0.107712, D accuracy: 50.4%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "test error: \n",
      " D loss: 2.678216, G loss: 0.108225, D accuracy: 50.2%, cell accuracy: 99.7%, board accuracy: 87.0% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4784, G loss: 1.0481\n",
      "[84/1762] D loss: 0.0344, G loss: 3.6244\n",
      "[164/1762] D loss: 1.4445, G loss: 0.8837\n",
      "[244/1762] D loss: 0.2679, G loss: 1.5929\n",
      "[324/1762] D loss: 1.4148, G loss: 0.8030\n",
      "[404/1762] D loss: 1.3901, G loss: 0.6734\n",
      "[484/1762] D loss: 1.3956, G loss: 0.6564\n",
      "[564/1762] D loss: 1.4121, G loss: 0.8671\n",
      "[644/1762] D loss: 1.4605, G loss: 0.9481\n",
      "[724/1762] D loss: 1.4436, G loss: 0.5394\n",
      "[804/1762] D loss: 1.4238, G loss: 1.2351\n",
      "[884/1762] D loss: 1.4820, G loss: 0.9598\n",
      "[964/1762] D loss: 0.2586, G loss: 1.6339\n",
      "[1044/1762] D loss: 0.6146, G loss: 1.1630\n",
      "[1124/1762] D loss: 1.4344, G loss: 0.4960\n",
      "[1204/1762] D loss: 0.1976, G loss: 1.9702\n",
      "[1284/1762] D loss: 1.3482, G loss: 0.6858\n",
      "[1364/1762] D loss: 1.3878, G loss: 0.6882\n",
      "[1444/1762] D loss: 1.4740, G loss: 0.4446\n",
      "[1524/1762] D loss: 1.4034, G loss: 0.6880\n",
      "[1604/1762] D loss: 0.0323, G loss: 3.5508\n",
      "[1684/1762] D loss: 1.3508, G loss: 0.7301\n",
      "[1762/1762] D loss: 0.0380, G loss: 3.3884\n",
      "train error: \n",
      " D loss: 3.109047, G loss: 0.069365, D accuracy: 50.3%, cell accuracy: 99.7%, board accuracy: 88.7% \n",
      "\n",
      "test error: \n",
      " D loss: 3.152527, G loss: 0.070338, D accuracy: 50.3%, cell accuracy: 99.7%, board accuracy: 85.0% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4326, G loss: 0.9598\n",
      "[84/1762] D loss: 1.2454, G loss: 0.8543\n",
      "[164/1762] D loss: 0.1950, G loss: 1.8717\n",
      "[244/1762] D loss: 0.2075, G loss: 1.9157\n",
      "[324/1762] D loss: 1.4318, G loss: 0.9196\n",
      "[404/1762] D loss: 1.4032, G loss: 0.8115\n",
      "[484/1762] D loss: 1.2438, G loss: 0.7222\n",
      "[564/1762] D loss: 1.5757, G loss: 1.1141\n",
      "[644/1762] D loss: 0.5985, G loss: 1.3031\n",
      "[724/1762] D loss: 0.3533, G loss: 1.3915\n",
      "[804/1762] D loss: 0.5471, G loss: 0.9291\n",
      "[884/1762] D loss: 0.0985, G loss: 2.6320\n",
      "[964/1762] D loss: 1.2612, G loss: 0.7802\n",
      "[1044/1762] D loss: 0.0529, G loss: 3.1372\n",
      "[1124/1762] D loss: 1.3913, G loss: 0.6865\n",
      "[1204/1762] D loss: 1.3980, G loss: 0.7061\n",
      "[1284/1762] D loss: 0.1748, G loss: 2.0756\n",
      "[1364/1762] D loss: 0.3388, G loss: 1.5916\n",
      "[1444/1762] D loss: 1.4142, G loss: 0.6092\n",
      "[1524/1762] D loss: 1.4054, G loss: 0.6163\n",
      "[1604/1762] D loss: 1.4161, G loss: 0.5447\n",
      "[1684/1762] D loss: 0.7631, G loss: 2.0733\n",
      "[1762/1762] D loss: 0.1058, G loss: 2.6875\n",
      "train error: \n",
      " D loss: 1.557889, G loss: 0.399184, D accuracy: 53.0%, cell accuracy: 99.7%, board accuracy: 88.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.563110, G loss: 0.393241, D accuracy: 53.5%, cell accuracy: 99.7%, board accuracy: 85.9% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4012, G loss: 0.7764\n",
      "[84/1762] D loss: 1.4008, G loss: 0.6782\n",
      "[164/1762] D loss: 0.7128, G loss: 0.7211\n",
      "[244/1762] D loss: 0.1733, G loss: 1.8559\n",
      "[324/1762] D loss: 1.3970, G loss: 0.5952\n",
      "[404/1762] D loss: 1.3975, G loss: 0.8491\n",
      "[484/1762] D loss: 0.0920, G loss: 2.5768\n",
      "[564/1762] D loss: 1.6248, G loss: 1.1572\n",
      "[644/1762] D loss: 1.3933, G loss: 0.6637\n",
      "[724/1762] D loss: 1.4378, G loss: 0.9046\n",
      "[804/1762] D loss: 1.2974, G loss: 0.6902\n",
      "[884/1762] D loss: 1.4058, G loss: 0.7698\n",
      "[964/1762] D loss: 1.4310, G loss: 0.8709\n",
      "[1044/1762] D loss: 1.4308, G loss: 0.8593\n",
      "[1124/1762] D loss: 1.4053, G loss: 0.8218\n",
      "[1204/1762] D loss: 1.3945, G loss: 0.5871\n",
      "[1284/1762] D loss: 0.0389, G loss: 3.4516\n",
      "[1364/1762] D loss: 1.4344, G loss: 0.5190\n",
      "[1444/1762] D loss: 1.3248, G loss: 0.6584\n",
      "[1524/1762] D loss: 0.2987, G loss: 1.5908\n",
      "[1604/1762] D loss: 0.0347, G loss: 3.3782\n",
      "[1684/1762] D loss: 0.1316, G loss: 2.1380\n",
      "[1762/1762] D loss: 1.3874, G loss: 0.7477\n",
      "train error: \n",
      " D loss: 1.335558, G loss: 0.632718, D accuracy: 54.6%, cell accuracy: 99.7%, board accuracy: 88.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.316685, G loss: 0.634131, D accuracy: 55.6%, cell accuracy: 99.7%, board accuracy: 83.4% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2741, G loss: 1.1076\n",
      "[84/1762] D loss: 0.0815, G loss: 2.7372\n",
      "[164/1762] D loss: 1.4076, G loss: 0.5724\n",
      "[244/1762] D loss: 0.0347, G loss: 3.5400\n",
      "[324/1762] D loss: 1.3924, G loss: 0.5706\n",
      "[404/1762] D loss: 0.1684, G loss: 2.0543\n",
      "[484/1762] D loss: 1.4488, G loss: 0.5140\n",
      "[564/1762] D loss: 1.3921, G loss: 0.7609\n",
      "[644/1762] D loss: 1.4564, G loss: 1.0048\n",
      "[724/1762] D loss: 1.4434, G loss: 0.9208\n",
      "[804/1762] D loss: 1.3772, G loss: 0.7380\n",
      "[884/1762] D loss: 1.3965, G loss: 0.7046\n",
      "[964/1762] D loss: 0.7295, G loss: 1.2391\n",
      "[1044/1762] D loss: 1.4143, G loss: 0.6502\n",
      "[1124/1762] D loss: 1.4030, G loss: 0.6923\n",
      "[1204/1762] D loss: 0.7743, G loss: 0.8536\n",
      "[1284/1762] D loss: 0.2021, G loss: 1.7652\n",
      "[1364/1762] D loss: 1.3861, G loss: 0.6800\n",
      "[1444/1762] D loss: 1.4227, G loss: 0.7812\n",
      "[1524/1762] D loss: 1.2989, G loss: 0.8812\n",
      "[1604/1762] D loss: 0.2270, G loss: 1.7862\n",
      "[1684/1762] D loss: 1.3958, G loss: 0.6242\n",
      "[1762/1762] D loss: 1.3941, G loss: 0.5266\n",
      "train error: \n",
      " D loss: 1.398518, G loss: 0.506653, D accuracy: 53.1%, cell accuracy: 99.7%, board accuracy: 86.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.387681, G loss: 0.502738, D accuracy: 54.3%, cell accuracy: 99.6%, board accuracy: 82.5% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1396, G loss: 2.0598\n",
      "[84/1762] D loss: 1.4042, G loss: 0.8201\n",
      "[164/1762] D loss: 0.2924, G loss: 1.7022\n",
      "[244/1762] D loss: 0.2610, G loss: 2.8165\n",
      "[324/1762] D loss: 0.6629, G loss: 2.4580\n",
      "[404/1762] D loss: 0.1250, G loss: 2.5136\n",
      "[484/1762] D loss: 1.4115, G loss: 0.7042\n",
      "[564/1762] D loss: 0.2256, G loss: 1.6297\n",
      "[644/1762] D loss: 0.0287, G loss: 3.7783\n",
      "[724/1762] D loss: 0.0879, G loss: 2.5359\n",
      "[804/1762] D loss: 0.1152, G loss: 2.3827\n",
      "[884/1762] D loss: 1.3632, G loss: 0.7859\n",
      "[964/1762] D loss: 1.3970, G loss: 0.6926\n",
      "[1044/1762] D loss: 0.3196, G loss: 1.5728\n",
      "[1124/1762] D loss: 0.7322, G loss: 1.1698\n",
      "[1204/1762] D loss: 1.4121, G loss: 0.8307\n",
      "[1284/1762] D loss: 0.2521, G loss: 2.0149\n",
      "[1364/1762] D loss: 0.1413, G loss: 2.7381\n",
      "[1444/1762] D loss: 1.5472, G loss: 1.0059\n",
      "[1524/1762] D loss: 1.4165, G loss: 0.6420\n",
      "[1604/1762] D loss: 0.3873, G loss: 3.5538\n",
      "[1684/1762] D loss: 1.6228, G loss: 0.3600\n",
      "[1762/1762] D loss: 1.3413, G loss: 0.6772\n",
      "train error: \n",
      " D loss: 1.424945, G loss: 0.499168, D accuracy: 53.6%, cell accuracy: 99.7%, board accuracy: 88.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.416958, G loss: 0.500953, D accuracy: 54.2%, cell accuracy: 99.7%, board accuracy: 84.5% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1841, G loss: 0.9785\n",
      "[84/1762] D loss: 0.2325, G loss: 4.0354\n",
      "[164/1762] D loss: 0.0222, G loss: 4.4465\n",
      "[244/1762] D loss: 1.0902, G loss: 1.7243\n",
      "[324/1762] D loss: 1.3940, G loss: 0.6478\n",
      "[404/1762] D loss: 0.0649, G loss: 2.7427\n",
      "[484/1762] D loss: 1.3981, G loss: 0.6087\n",
      "[564/1762] D loss: 0.1866, G loss: 2.0650\n",
      "[644/1762] D loss: 0.0592, G loss: 3.3710\n",
      "[724/1762] D loss: 1.4787, G loss: 0.4807\n",
      "[804/1762] D loss: 1.5396, G loss: 1.0724\n",
      "[884/1762] D loss: 1.3738, G loss: 0.8052\n",
      "[964/1762] D loss: 1.3918, G loss: 0.6596\n",
      "[1044/1762] D loss: 1.4321, G loss: 0.8546\n",
      "[1124/1762] D loss: 1.4567, G loss: 0.6857\n",
      "[1204/1762] D loss: 1.4399, G loss: 0.4986\n",
      "[1284/1762] D loss: 1.4156, G loss: 0.8309\n",
      "[1364/1762] D loss: 0.1110, G loss: 2.5943\n",
      "[1444/1762] D loss: 1.4175, G loss: 0.5572\n",
      "[1524/1762] D loss: 0.0655, G loss: 3.2133\n",
      "[1604/1762] D loss: 1.4924, G loss: 0.9274\n",
      "[1684/1762] D loss: 1.4482, G loss: 0.9258\n",
      "[1762/1762] D loss: 1.3648, G loss: 0.7294\n",
      "train error: \n",
      " D loss: 1.484789, G loss: 0.425113, D accuracy: 52.4%, cell accuracy: 99.7%, board accuracy: 87.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.468529, G loss: 0.428787, D accuracy: 52.5%, cell accuracy: 99.7%, board accuracy: 84.5% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3933, G loss: 0.6763\n",
      "[84/1762] D loss: 1.4155, G loss: 0.6138\n",
      "[164/1762] D loss: 1.2925, G loss: 0.7235\n",
      "[244/1762] D loss: 1.4503, G loss: 0.8818\n",
      "[324/1762] D loss: 0.0045, G loss: 5.8826\n",
      "[404/1762] D loss: 0.4787, G loss: 1.1057\n",
      "[484/1762] D loss: 1.4074, G loss: 0.8102\n",
      "[564/1762] D loss: 0.0241, G loss: 4.0299\n",
      "[644/1762] D loss: 0.1851, G loss: 2.0207\n",
      "[724/1762] D loss: 1.4092, G loss: 0.7987\n",
      "[804/1762] D loss: 1.4083, G loss: 0.6631\n",
      "[884/1762] D loss: 0.0568, G loss: 2.9715\n",
      "[964/1762] D loss: 1.1679, G loss: 1.0732\n",
      "[1044/1762] D loss: 0.4864, G loss: 1.4024\n",
      "[1124/1762] D loss: 0.1457, G loss: 2.1083\n",
      "[1204/1762] D loss: 0.0255, G loss: 4.7613\n",
      "[1284/1762] D loss: 0.0374, G loss: 3.3160\n",
      "[1364/1762] D loss: 0.0133, G loss: 4.5150\n",
      "[1444/1762] D loss: 0.1362, G loss: 2.5033\n",
      "[1524/1762] D loss: 1.4363, G loss: 0.6318\n",
      "[1604/1762] D loss: 1.3507, G loss: 0.6967\n",
      "[1684/1762] D loss: 1.3997, G loss: 0.5978\n",
      "[1762/1762] D loss: 1.4189, G loss: 0.8291\n",
      "train error: \n",
      " D loss: 1.331304, G loss: 0.890420, D accuracy: 55.0%, cell accuracy: 99.7%, board accuracy: 88.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.309484, G loss: 0.892181, D accuracy: 55.6%, cell accuracy: 99.7%, board accuracy: 85.9% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4191, G loss: 0.8127\n",
      "[84/1762] D loss: 0.0264, G loss: 3.8655\n",
      "[164/1762] D loss: 1.4260, G loss: 0.6171\n",
      "[244/1762] D loss: 1.3866, G loss: 0.7776\n",
      "[324/1762] D loss: 0.0529, G loss: 3.0175\n",
      "[404/1762] D loss: 1.3976, G loss: 0.7794\n",
      "[484/1762] D loss: 1.5097, G loss: 0.4270\n",
      "[564/1762] D loss: 1.4506, G loss: 0.9174\n",
      "[644/1762] D loss: 1.3865, G loss: 0.7290\n",
      "[724/1762] D loss: 1.2860, G loss: 1.3643\n",
      "[804/1762] D loss: 1.3938, G loss: 0.7579\n",
      "[884/1762] D loss: 1.0886, G loss: 1.6492\n",
      "[964/1762] D loss: 0.0165, G loss: 4.3801\n",
      "[1044/1762] D loss: 1.3293, G loss: 0.7071\n",
      "[1124/1762] D loss: 1.2459, G loss: 0.7194\n",
      "[1204/1762] D loss: 0.1644, G loss: 4.6373\n",
      "[1284/1762] D loss: 1.0961, G loss: 0.8299\n",
      "[1364/1762] D loss: 0.0224, G loss: 6.1170\n",
      "[1444/1762] D loss: 1.3850, G loss: 0.6177\n",
      "[1524/1762] D loss: 0.0621, G loss: 2.8981\n",
      "[1604/1762] D loss: 0.0660, G loss: 2.7882\n",
      "[1684/1762] D loss: 1.4185, G loss: 0.5629\n",
      "[1762/1762] D loss: 0.0073, G loss: 5.3236\n",
      "train error: \n",
      " D loss: 1.652346, G loss: 0.324185, D accuracy: 51.5%, cell accuracy: 99.7%, board accuracy: 87.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.659779, G loss: 0.320814, D accuracy: 51.4%, cell accuracy: 99.6%, board accuracy: 83.2% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0355, G loss: 3.5785\n",
      "[84/1762] D loss: 0.0366, G loss: 3.3864\n",
      "[164/1762] D loss: 1.3869, G loss: 0.7343\n",
      "[244/1762] D loss: 0.0292, G loss: 3.7199\n",
      "[324/1762] D loss: 0.1610, G loss: 1.9154\n",
      "[404/1762] D loss: 0.1289, G loss: 2.3501\n",
      "[484/1762] D loss: 1.6343, G loss: 1.1971\n",
      "[564/1762] D loss: 1.3913, G loss: 0.6560\n",
      "[644/1762] D loss: 1.5517, G loss: 1.1212\n",
      "[724/1762] D loss: 1.3798, G loss: 0.7089\n",
      "[804/1762] D loss: 1.3790, G loss: 0.7596\n",
      "[884/1762] D loss: 0.6876, G loss: 2.1472\n",
      "[964/1762] D loss: 1.5132, G loss: 0.7445\n",
      "[1044/1762] D loss: 0.2613, G loss: 1.7445\n",
      "[1124/1762] D loss: 1.4166, G loss: 0.8772\n",
      "[1204/1762] D loss: 1.3989, G loss: 0.8105\n",
      "[1284/1762] D loss: 0.1758, G loss: 3.7101\n",
      "[1364/1762] D loss: 0.6228, G loss: 2.0131\n",
      "[1444/1762] D loss: 1.4942, G loss: 0.8931\n",
      "[1524/1762] D loss: 1.0812, G loss: 0.9301\n",
      "[1604/1762] D loss: 1.4368, G loss: 0.4938\n",
      "[1684/1762] D loss: 1.3793, G loss: 0.7756\n",
      "[1762/1762] D loss: 1.1908, G loss: 0.5662\n",
      "train error: \n",
      " D loss: 1.485249, G loss: 0.478737, D accuracy: 52.0%, cell accuracy: 99.7%, board accuracy: 86.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.444853, G loss: 0.489010, D accuracy: 52.4%, cell accuracy: 99.6%, board accuracy: 82.7% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4220, G loss: 0.5759\n",
      "[84/1762] D loss: 1.4028, G loss: 0.8550\n",
      "[164/1762] D loss: 0.1556, G loss: 2.7512\n",
      "[244/1762] D loss: 0.0057, G loss: 5.4028\n",
      "[324/1762] D loss: 1.4121, G loss: 0.7896\n",
      "[404/1762] D loss: 0.0516, G loss: 3.4811\n",
      "[484/1762] D loss: 0.0734, G loss: 2.7461\n",
      "[564/1762] D loss: 1.4016, G loss: 0.8122\n",
      "[644/1762] D loss: 1.2724, G loss: 0.6137\n",
      "[724/1762] D loss: 1.3879, G loss: 0.7432\n",
      "[804/1762] D loss: 1.3965, G loss: 0.6440\n",
      "[884/1762] D loss: 0.2625, G loss: 1.7599\n",
      "[964/1762] D loss: 1.4177, G loss: 0.8495\n",
      "[1044/1762] D loss: 1.3878, G loss: 0.6789\n",
      "[1124/1762] D loss: 1.4074, G loss: 0.7903\n",
      "[1204/1762] D loss: 0.1018, G loss: 3.2245\n",
      "[1284/1762] D loss: 1.2255, G loss: 0.8151\n",
      "[1364/1762] D loss: 1.4284, G loss: 0.9221\n",
      "[1444/1762] D loss: 1.3936, G loss: 0.5979\n",
      "[1524/1762] D loss: 1.3862, G loss: 0.5408\n",
      "[1604/1762] D loss: 0.0641, G loss: 3.0345\n",
      "[1684/1762] D loss: 0.0283, G loss: 3.7067\n",
      "[1762/1762] D loss: 0.0033, G loss: 5.7620\n",
      "train error: \n",
      " D loss: 1.851226, G loss: 0.256362, D accuracy: 51.0%, cell accuracy: 99.7%, board accuracy: 87.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.856587, G loss: 0.259660, D accuracy: 51.0%, cell accuracy: 99.6%, board accuracy: 84.3% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3214, G loss: 0.6361\n",
      "[84/1762] D loss: 0.0074, G loss: 4.9749\n",
      "[164/1762] D loss: 1.4098, G loss: 0.5888\n",
      "[244/1762] D loss: 1.2162, G loss: 0.7545\n",
      "[324/1762] D loss: 1.4181, G loss: 0.6131\n",
      "[404/1762] D loss: 0.3730, G loss: 1.3845\n",
      "[484/1762] D loss: 1.3844, G loss: 0.6993\n",
      "[564/1762] D loss: 1.3933, G loss: 0.7395\n",
      "[644/1762] D loss: 1.1894, G loss: 1.2056\n",
      "[724/1762] D loss: 1.4549, G loss: 0.8896\n",
      "[804/1762] D loss: 0.6756, G loss: 2.1175\n",
      "[884/1762] D loss: 0.8880, G loss: 1.7790\n",
      "[964/1762] D loss: 1.3217, G loss: 0.6498\n",
      "[1044/1762] D loss: 0.1641, G loss: 2.5882\n",
      "[1124/1762] D loss: 1.3929, G loss: 0.7479\n",
      "[1204/1762] D loss: 0.4717, G loss: 5.0353\n",
      "[1284/1762] D loss: 0.3787, G loss: 1.2453\n",
      "[1364/1762] D loss: 0.0984, G loss: 2.6035\n",
      "[1444/1762] D loss: 1.1311, G loss: 0.8543\n",
      "[1524/1762] D loss: 0.1352, G loss: 2.5946\n",
      "[1604/1762] D loss: 0.0675, G loss: 2.9661\n",
      "[1684/1762] D loss: 1.4101, G loss: 0.5986\n",
      "[1762/1762] D loss: 1.4298, G loss: 0.5339\n",
      "train error: \n",
      " D loss: 1.387304, G loss: 0.545987, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 89.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.370656, G loss: 0.550568, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 85.7% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2891, G loss: 0.6808\n",
      "[84/1762] D loss: 1.4098, G loss: 0.7918\n",
      "[164/1762] D loss: 1.3888, G loss: 0.7217\n",
      "[244/1762] D loss: 0.9490, G loss: 1.1460\n",
      "[324/1762] D loss: 0.1154, G loss: 2.4910\n",
      "[404/1762] D loss: 1.2025, G loss: 0.6519\n",
      "[484/1762] D loss: 1.3709, G loss: 0.7169\n",
      "[564/1762] D loss: 0.1119, G loss: 3.4367\n",
      "[644/1762] D loss: 0.0009, G loss: 7.1158\n",
      "[724/1762] D loss: 1.1722, G loss: 0.6858\n",
      "[804/1762] D loss: 1.3658, G loss: 0.6900\n",
      "[884/1762] D loss: 0.8695, G loss: 1.5838\n",
      "[964/1762] D loss: 0.0532, G loss: 3.4298\n",
      "[1044/1762] D loss: 1.4115, G loss: 0.5357\n",
      "[1124/1762] D loss: 1.4138, G loss: 0.5660\n",
      "[1204/1762] D loss: 0.4370, G loss: 5.8169\n",
      "[1284/1762] D loss: 0.0314, G loss: 3.8920\n",
      "[1364/1762] D loss: 1.3866, G loss: 0.6330\n",
      "[1444/1762] D loss: 1.4068, G loss: 0.5854\n",
      "[1524/1762] D loss: 1.4176, G loss: 0.5832\n",
      "[1604/1762] D loss: 0.0064, G loss: 6.3346\n",
      "[1684/1762] D loss: 0.1647, G loss: 4.7291\n",
      "[1762/1762] D loss: 1.3870, G loss: 0.6673\n",
      "train error: \n",
      " D loss: 1.325837, G loss: 0.844436, D accuracy: 54.9%, cell accuracy: 99.7%, board accuracy: 87.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.329436, G loss: 0.860931, D accuracy: 55.5%, cell accuracy: 99.6%, board accuracy: 84.5% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0076, G loss: 7.5161\n",
      "[84/1762] D loss: 1.5380, G loss: 0.4061\n",
      "[164/1762] D loss: 0.0031, G loss: 6.0808\n",
      "[244/1762] D loss: 1.4429, G loss: 0.8847\n",
      "[324/1762] D loss: 0.0012, G loss: 6.9635\n",
      "[404/1762] D loss: 1.4009, G loss: 0.6724\n",
      "[484/1762] D loss: 0.2021, G loss: 2.1304\n",
      "[564/1762] D loss: 0.1699, G loss: 2.1844\n",
      "[644/1762] D loss: 1.4004, G loss: 0.6253\n",
      "[724/1762] D loss: 1.4976, G loss: 0.9582\n",
      "[804/1762] D loss: 0.0006, G loss: 7.4845\n",
      "[884/1762] D loss: 1.3938, G loss: 0.6184\n",
      "[964/1762] D loss: 0.1313, G loss: 2.2091\n",
      "[1044/1762] D loss: 1.4795, G loss: 0.9828\n",
      "[1124/1762] D loss: 1.3925, G loss: 0.7757\n",
      "[1204/1762] D loss: 1.3926, G loss: 0.6163\n",
      "[1284/1762] D loss: 1.1757, G loss: 1.1314\n",
      "[1364/1762] D loss: 1.3993, G loss: 0.6025\n",
      "[1444/1762] D loss: 1.3822, G loss: 0.7133\n",
      "[1524/1762] D loss: 0.2598, G loss: 2.4284\n",
      "[1604/1762] D loss: 1.3822, G loss: 0.6351\n",
      "[1684/1762] D loss: 0.4988, G loss: 2.7386\n",
      "[1762/1762] D loss: 1.3989, G loss: 0.7009\n",
      "train error: \n",
      " D loss: 1.342005, G loss: 0.666822, D accuracy: 53.5%, cell accuracy: 99.7%, board accuracy: 88.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.328089, G loss: 0.678118, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 85.2% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5786, G loss: 2.1701\n",
      "[84/1762] D loss: 1.3911, G loss: 0.9426\n",
      "[164/1762] D loss: 1.3970, G loss: 0.8859\n",
      "[244/1762] D loss: 1.4221, G loss: 0.8430\n",
      "[324/1762] D loss: 0.0379, G loss: 4.3585\n",
      "[404/1762] D loss: 1.5413, G loss: 0.9520\n",
      "[484/1762] D loss: 1.3974, G loss: 0.5944\n",
      "[564/1762] D loss: 1.4361, G loss: 0.6804\n",
      "[644/1762] D loss: 1.4786, G loss: 0.8677\n",
      "[724/1762] D loss: 0.0028, G loss: 6.0019\n",
      "[804/1762] D loss: 0.0380, G loss: 3.5633\n",
      "[884/1762] D loss: 1.3893, G loss: 0.7325\n",
      "[964/1762] D loss: 0.1613, G loss: 2.0203\n",
      "[1044/1762] D loss: 0.0002, G loss: 9.2101\n",
      "[1124/1762] D loss: 0.1532, G loss: 2.1399\n",
      "[1204/1762] D loss: 1.4952, G loss: 0.9721\n",
      "[1284/1762] D loss: 0.0120, G loss: 5.6594\n",
      "[1364/1762] D loss: 0.9470, G loss: 2.1307\n",
      "[1444/1762] D loss: 1.4241, G loss: 0.6141\n",
      "[1524/1762] D loss: 0.2259, G loss: 1.9935\n",
      "[1604/1762] D loss: 1.6529, G loss: 0.9138\n",
      "[1684/1762] D loss: 1.2829, G loss: 2.3035\n",
      "[1762/1762] D loss: 1.5309, G loss: 0.4264\n",
      "train error: \n",
      " D loss: 1.312837, G loss: 0.783476, D accuracy: 55.3%, cell accuracy: 99.7%, board accuracy: 88.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.292958, G loss: 0.787145, D accuracy: 56.7%, cell accuracy: 99.7%, board accuracy: 85.7% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0702, G loss: 3.3745\n",
      "[84/1762] D loss: 0.0185, G loss: 4.3578\n",
      "[164/1762] D loss: 0.0610, G loss: 2.8805\n",
      "[244/1762] D loss: 0.0345, G loss: 3.3827\n",
      "[324/1762] D loss: 0.0431, G loss: 3.3265\n",
      "[404/1762] D loss: 0.6941, G loss: 3.1657\n",
      "[484/1762] D loss: 1.6226, G loss: 1.1133\n",
      "[564/1762] D loss: 1.5799, G loss: 0.5215\n",
      "[644/1762] D loss: 0.8068, G loss: 1.1894\n",
      "[724/1762] D loss: 0.0033, G loss: 6.2386\n",
      "[804/1762] D loss: 0.1395, G loss: 4.3241\n",
      "[884/1762] D loss: 1.4113, G loss: 0.4998\n",
      "[964/1762] D loss: 1.6328, G loss: 1.0980\n",
      "[1044/1762] D loss: 1.3952, G loss: 0.7980\n",
      "[1124/1762] D loss: 0.0217, G loss: 3.7746\n",
      "[1204/1762] D loss: 1.5667, G loss: 0.4675\n",
      "[1284/1762] D loss: 1.2323, G loss: 1.0765\n",
      "[1364/1762] D loss: 0.0136, G loss: 6.0316\n",
      "[1444/1762] D loss: 1.0419, G loss: 1.3124\n",
      "[1524/1762] D loss: 0.1099, G loss: 2.5203\n",
      "[1604/1762] D loss: 1.0646, G loss: 1.0393\n",
      "[1684/1762] D loss: 1.4234, G loss: 0.6072\n",
      "[1762/1762] D loss: 1.4557, G loss: 0.4956\n",
      "train error: \n",
      " D loss: 1.381222, G loss: 0.586929, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 88.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.371859, G loss: 0.605262, D accuracy: 54.9%, cell accuracy: 99.7%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5017, G loss: 0.4281\n",
      "[84/1762] D loss: 1.4141, G loss: 0.8377\n",
      "[164/1762] D loss: 0.1229, G loss: 2.3421\n",
      "[244/1762] D loss: 0.8327, G loss: 2.6975\n",
      "[324/1762] D loss: 0.0143, G loss: 4.3743\n",
      "[404/1762] D loss: 1.3274, G loss: 1.0730\n",
      "[484/1762] D loss: 1.3848, G loss: 0.7532\n",
      "[564/1762] D loss: 1.3461, G loss: 0.7483\n",
      "[644/1762] D loss: 1.3406, G loss: 0.5152\n",
      "[724/1762] D loss: 1.3902, G loss: 0.7003\n",
      "[804/1762] D loss: 0.7850, G loss: 1.4936\n",
      "[884/1762] D loss: 1.4590, G loss: 0.4706\n",
      "[964/1762] D loss: 0.7822, G loss: 2.0605\n",
      "[1044/1762] D loss: 0.0083, G loss: 4.7597\n",
      "[1124/1762] D loss: 1.3960, G loss: 0.7027\n",
      "[1204/1762] D loss: 1.3913, G loss: 0.6655\n",
      "[1284/1762] D loss: 0.0342, G loss: 3.8678\n",
      "[1364/1762] D loss: 1.3902, G loss: 0.5947\n",
      "[1444/1762] D loss: 1.4222, G loss: 0.5566\n",
      "[1524/1762] D loss: 0.8341, G loss: 1.3634\n",
      "[1604/1762] D loss: 0.1208, G loss: 4.9564\n",
      "[1684/1762] D loss: 1.5632, G loss: 0.6088\n",
      "[1762/1762] D loss: 1.4082, G loss: 0.5617\n",
      "train error: \n",
      " D loss: 1.360992, G loss: 0.795123, D accuracy: 53.8%, cell accuracy: 99.7%, board accuracy: 88.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.339165, G loss: 0.795050, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5179, G loss: 0.8648\n",
      "[84/1762] D loss: 1.0129, G loss: 1.7067\n",
      "[164/1762] D loss: 1.4033, G loss: 0.5599\n",
      "[244/1762] D loss: 1.3881, G loss: 0.7673\n",
      "[324/1762] D loss: 1.3675, G loss: 0.6352\n",
      "[404/1762] D loss: 1.3848, G loss: 0.6993\n",
      "[484/1762] D loss: 0.6343, G loss: 3.4281\n",
      "[564/1762] D loss: 1.3547, G loss: 0.5367\n",
      "[644/1762] D loss: 0.3301, G loss: 2.1362\n",
      "[724/1762] D loss: 1.2591, G loss: 0.5171\n",
      "[804/1762] D loss: 1.6635, G loss: 1.0382\n",
      "[884/1762] D loss: 1.3139, G loss: 0.5667\n",
      "[964/1762] D loss: 1.3946, G loss: 0.7466\n",
      "[1044/1762] D loss: 1.3730, G loss: 0.5997\n",
      "[1124/1762] D loss: 0.1226, G loss: 2.4844\n",
      "[1204/1762] D loss: 0.0436, G loss: 3.5543\n",
      "[1284/1762] D loss: 1.0838, G loss: 0.8498\n",
      "[1364/1762] D loss: 1.2649, G loss: 0.6080\n",
      "[1444/1762] D loss: 1.4808, G loss: 0.4726\n",
      "[1524/1762] D loss: 1.3905, G loss: 0.7344\n",
      "[1604/1762] D loss: 1.2413, G loss: 0.9439\n",
      "[1684/1762] D loss: 0.3063, G loss: 1.5973\n",
      "[1762/1762] D loss: 1.3958, G loss: 0.7009\n",
      "train error: \n",
      " D loss: 1.400760, G loss: 0.647513, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 88.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.405721, G loss: 0.660391, D accuracy: 55.3%, cell accuracy: 99.6%, board accuracy: 85.2% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3222, G loss: 0.5159\n",
      "[84/1762] D loss: 0.0290, G loss: 4.0367\n",
      "[164/1762] D loss: 0.0078, G loss: 4.9820\n",
      "[244/1762] D loss: 1.4015, G loss: 0.6303\n",
      "[324/1762] D loss: 1.4315, G loss: 0.9107\n",
      "[404/1762] D loss: 1.2994, G loss: 0.9539\n",
      "[484/1762] D loss: 1.4075, G loss: 0.5760\n",
      "[564/1762] D loss: 0.5077, G loss: 1.8156\n",
      "[644/1762] D loss: 1.6332, G loss: 0.8771\n",
      "[724/1762] D loss: 1.3903, G loss: 0.7348\n",
      "[804/1762] D loss: 0.3379, G loss: 2.1923\n",
      "[884/1762] D loss: 0.2415, G loss: 1.8602\n",
      "[964/1762] D loss: 0.0008, G loss: 7.3742\n",
      "[1044/1762] D loss: 0.1417, G loss: 6.7678\n",
      "[1124/1762] D loss: 1.4043, G loss: 0.5024\n",
      "[1204/1762] D loss: 0.1050, G loss: 2.7344\n",
      "[1284/1762] D loss: 1.3979, G loss: 0.5641\n",
      "[1364/1762] D loss: 1.3942, G loss: 0.6150\n",
      "[1444/1762] D loss: 1.1868, G loss: 1.1482\n",
      "[1524/1762] D loss: 1.3967, G loss: 0.5759\n",
      "[1604/1762] D loss: 1.3848, G loss: 0.6206\n",
      "[1684/1762] D loss: 0.0269, G loss: 3.7075\n",
      "[1762/1762] D loss: 1.4015, G loss: 0.6580\n",
      "train error: \n",
      " D loss: 1.346860, G loss: 0.633322, D accuracy: 55.0%, cell accuracy: 99.7%, board accuracy: 87.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.353383, G loss: 0.635250, D accuracy: 55.3%, cell accuracy: 99.7%, board accuracy: 85.7% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3918, G loss: 0.6273\n",
      "[84/1762] D loss: 1.4612, G loss: 0.9473\n",
      "[164/1762] D loss: 0.0066, G loss: 5.3188\n",
      "[244/1762] D loss: 0.0156, G loss: 4.4162\n",
      "[324/1762] D loss: 1.4103, G loss: 0.5480\n",
      "[404/1762] D loss: 0.0073, G loss: 5.2693\n",
      "[484/1762] D loss: 0.0062, G loss: 5.0941\n",
      "[564/1762] D loss: 1.4078, G loss: 0.5583\n",
      "[644/1762] D loss: 1.9128, G loss: 0.2336\n",
      "[724/1762] D loss: 1.3962, G loss: 0.7912\n",
      "[804/1762] D loss: 1.3960, G loss: 0.7944\n",
      "[884/1762] D loss: 1.4012, G loss: 0.5934\n",
      "[964/1762] D loss: 0.0459, G loss: 3.5303\n",
      "[1044/1762] D loss: 0.0086, G loss: 5.1901\n",
      "[1124/1762] D loss: 1.3948, G loss: 0.6623\n",
      "[1204/1762] D loss: 1.0840, G loss: 1.0709\n",
      "[1284/1762] D loss: 0.0002, G loss: 8.5570\n",
      "[1364/1762] D loss: 1.4138, G loss: 0.5648\n",
      "[1444/1762] D loss: 1.4165, G loss: 0.7552\n",
      "[1524/1762] D loss: 1.3985, G loss: 0.6688\n",
      "[1604/1762] D loss: 0.0312, G loss: 4.0540\n",
      "[1684/1762] D loss: 0.0413, G loss: 3.6831\n",
      "[1762/1762] D loss: 0.0039, G loss: 5.6353\n",
      "train error: \n",
      " D loss: 1.374866, G loss: 0.556800, D accuracy: 54.6%, cell accuracy: 99.7%, board accuracy: 89.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.381531, G loss: 0.545244, D accuracy: 55.5%, cell accuracy: 99.6%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3872, G loss: 0.6516\n",
      "[84/1762] D loss: 0.0001, G loss: 9.6811\n",
      "[164/1762] D loss: 0.6331, G loss: 3.0677\n",
      "[244/1762] D loss: 0.4424, G loss: 3.4946\n",
      "[324/1762] D loss: 1.3740, G loss: 0.7260\n",
      "[404/1762] D loss: 0.0209, G loss: 6.7386\n",
      "[484/1762] D loss: 1.3387, G loss: 0.5914\n",
      "[564/1762] D loss: 1.3919, G loss: 0.6715\n",
      "[644/1762] D loss: 1.3796, G loss: 0.7188\n",
      "[724/1762] D loss: 1.4331, G loss: 0.9978\n",
      "[804/1762] D loss: 1.7593, G loss: 0.3414\n",
      "[884/1762] D loss: 1.1335, G loss: 4.1008\n",
      "[964/1762] D loss: 0.4726, G loss: 8.6892\n",
      "[1044/1762] D loss: 1.4560, G loss: 1.1106\n",
      "[1124/1762] D loss: 0.8342, G loss: 2.3554\n",
      "[1204/1762] D loss: 1.1372, G loss: 0.6501\n",
      "[1284/1762] D loss: 0.3361, G loss: 3.8988\n",
      "[1364/1762] D loss: 1.4889, G loss: 0.4785\n",
      "[1444/1762] D loss: 0.1396, G loss: 2.4601\n",
      "[1524/1762] D loss: 1.1714, G loss: 1.0297\n",
      "[1604/1762] D loss: 1.4429, G loss: 0.5070\n",
      "[1684/1762] D loss: 0.1076, G loss: 6.7243\n",
      "[1762/1762] D loss: 1.1469, G loss: 0.6573\n",
      "train error: \n",
      " D loss: 1.406945, G loss: 0.553340, D accuracy: 52.7%, cell accuracy: 99.7%, board accuracy: 86.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.392866, G loss: 0.552663, D accuracy: 53.5%, cell accuracy: 99.6%, board accuracy: 82.3% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0592, G loss: 3.1221\n",
      "[84/1762] D loss: 0.0990, G loss: 2.5580\n",
      "[164/1762] D loss: 1.3508, G loss: 0.6689\n",
      "[244/1762] D loss: 0.4914, G loss: 1.0103\n",
      "[324/1762] D loss: 1.4332, G loss: 0.5017\n",
      "[404/1762] D loss: 0.0006, G loss: 7.9399\n",
      "[484/1762] D loss: 1.4431, G loss: 0.9043\n",
      "[564/1762] D loss: 1.1472, G loss: 0.9769\n",
      "[644/1762] D loss: 0.0828, G loss: 3.0796\n",
      "[724/1762] D loss: 1.3983, G loss: 0.7203\n",
      "[804/1762] D loss: 1.4344, G loss: 0.8826\n",
      "[884/1762] D loss: 0.0045, G loss: 5.7448\n",
      "[964/1762] D loss: 1.4000, G loss: 0.6822\n",
      "[1044/1762] D loss: 1.4062, G loss: 0.8561\n",
      "[1124/1762] D loss: 0.0179, G loss: 5.2334\n",
      "[1204/1762] D loss: 1.3883, G loss: 0.6644\n",
      "[1284/1762] D loss: 1.3957, G loss: 0.7435\n",
      "[1364/1762] D loss: 0.7864, G loss: 1.0679\n",
      "[1444/1762] D loss: 0.0099, G loss: 4.8182\n",
      "[1524/1762] D loss: 0.0439, G loss: 3.5835\n",
      "[1604/1762] D loss: 0.0299, G loss: 4.4772\n",
      "[1684/1762] D loss: 1.3828, G loss: 0.5527\n",
      "[1762/1762] D loss: 1.5920, G loss: 1.0078\n",
      "train error: \n",
      " D loss: 1.329985, G loss: 0.880154, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 87.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.331576, G loss: 0.894748, D accuracy: 55.7%, cell accuracy: 99.7%, board accuracy: 84.1% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5434, G loss: 0.9773\n",
      "[84/1762] D loss: 0.0005, G loss: 9.4183\n",
      "[164/1762] D loss: 1.3225, G loss: 0.7969\n",
      "[244/1762] D loss: 1.2395, G loss: 0.8410\n",
      "[324/1762] D loss: 0.0005, G loss: 8.0179\n",
      "[404/1762] D loss: 1.3953, G loss: 0.5409\n",
      "[484/1762] D loss: 0.0024, G loss: 6.7301\n",
      "[564/1762] D loss: 0.0099, G loss: 5.7981\n",
      "[644/1762] D loss: 1.4771, G loss: 0.4506\n",
      "[724/1762] D loss: 1.3975, G loss: 0.7901\n",
      "[804/1762] D loss: 0.0875, G loss: 2.8204\n",
      "[884/1762] D loss: 1.3870, G loss: 0.7118\n",
      "[964/1762] D loss: 1.4260, G loss: 0.6934\n",
      "[1044/1762] D loss: 0.0110, G loss: 7.9047\n",
      "[1124/1762] D loss: 1.3699, G loss: 0.6194\n",
      "[1204/1762] D loss: 0.0074, G loss: 5.9804\n",
      "[1284/1762] D loss: 1.3966, G loss: 0.6565\n",
      "[1364/1762] D loss: 0.0890, G loss: 2.8472\n",
      "[1444/1762] D loss: 0.0011, G loss: 7.3189\n",
      "[1524/1762] D loss: 1.3918, G loss: 0.7853\n",
      "[1604/1762] D loss: 1.0875, G loss: 1.5480\n",
      "[1684/1762] D loss: 0.5615, G loss: 4.3402\n",
      "[1762/1762] D loss: 1.3931, G loss: 0.6706\n",
      "train error: \n",
      " D loss: 1.338772, G loss: 0.675118, D accuracy: 54.3%, cell accuracy: 99.7%, board accuracy: 89.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.337329, G loss: 0.673389, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8397, G loss: 2.4784\n",
      "[84/1762] D loss: 0.1077, G loss: 4.0887\n",
      "[164/1762] D loss: 1.4123, G loss: 0.8456\n",
      "[244/1762] D loss: 1.4135, G loss: 0.5274\n",
      "[324/1762] D loss: 1.2308, G loss: 0.8117\n",
      "[404/1762] D loss: 1.4018, G loss: 0.5078\n",
      "[484/1762] D loss: 1.3944, G loss: 0.5937\n",
      "[564/1762] D loss: 1.3797, G loss: 0.6491\n",
      "[644/1762] D loss: 1.4089, G loss: 0.7964\n",
      "[724/1762] D loss: 1.3889, G loss: 0.6284\n",
      "[804/1762] D loss: 1.5761, G loss: 1.0734\n",
      "[884/1762] D loss: 1.7044, G loss: 0.3656\n",
      "[964/1762] D loss: 1.3863, G loss: 0.7159\n",
      "[1044/1762] D loss: 1.3943, G loss: 0.6097\n",
      "[1124/1762] D loss: 0.0579, G loss: 3.6899\n",
      "[1204/1762] D loss: 0.6081, G loss: 3.6341\n",
      "[1284/1762] D loss: 0.3353, G loss: 4.8435\n",
      "[1364/1762] D loss: 1.4986, G loss: 0.4699\n",
      "[1444/1762] D loss: 1.4054, G loss: 0.4327\n",
      "[1524/1762] D loss: 0.0066, G loss: 5.5280\n",
      "[1604/1762] D loss: 1.3980, G loss: 0.5636\n",
      "[1684/1762] D loss: 0.0465, G loss: 6.3944\n",
      "[1762/1762] D loss: 0.0467, G loss: 5.6135\n",
      "train error: \n",
      " D loss: 1.413117, G loss: 1.192508, D accuracy: 54.4%, cell accuracy: 99.7%, board accuracy: 88.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.421109, G loss: 1.228098, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 83.2% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3879, G loss: 0.6484\n",
      "[84/1762] D loss: 1.2831, G loss: 0.7010\n",
      "[164/1762] D loss: 0.6550, G loss: 2.2400\n",
      "[244/1762] D loss: 0.7634, G loss: 2.8984\n",
      "[324/1762] D loss: 0.2353, G loss: 3.1779\n",
      "[404/1762] D loss: 0.9963, G loss: 4.2428\n",
      "[484/1762] D loss: 0.5379, G loss: 1.7028\n",
      "[564/1762] D loss: 0.7107, G loss: 2.2119\n",
      "[644/1762] D loss: 0.4564, G loss: 2.2781\n",
      "[724/1762] D loss: 0.7651, G loss: 2.3977\n",
      "[804/1762] D loss: 0.4632, G loss: 2.0294\n",
      "[884/1762] D loss: 1.1401, G loss: 2.5723\n",
      "[964/1762] D loss: 1.6003, G loss: 0.4145\n",
      "[1044/1762] D loss: 0.8407, G loss: 1.4769\n",
      "[1124/1762] D loss: 1.0738, G loss: 1.6458\n",
      "[1204/1762] D loss: 1.3419, G loss: 0.4215\n",
      "[1284/1762] D loss: 1.3128, G loss: 0.7766\n",
      "[1364/1762] D loss: 1.4964, G loss: 0.4299\n",
      "[1444/1762] D loss: 1.1685, G loss: 0.8190\n",
      "[1524/1762] D loss: 1.0152, G loss: 1.1147\n",
      "[1604/1762] D loss: 0.9677, G loss: 1.3426\n",
      "[1684/1762] D loss: 1.0190, G loss: 0.6894\n",
      "[1762/1762] D loss: 0.9479, G loss: 1.7743\n",
      "train error: \n",
      " D loss: 1.157997, G loss: 1.885831, D accuracy: 60.4%, cell accuracy: 97.1%, board accuracy: 0.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.197152, G loss: 1.877917, D accuracy: 60.2%, cell accuracy: 97.1%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1531, G loss: 1.8397\n",
      "[84/1762] D loss: 1.3742, G loss: 1.0012\n",
      "[164/1762] D loss: 1.1880, G loss: 0.9471\n",
      "[244/1762] D loss: 1.1673, G loss: 0.7475\n",
      "[324/1762] D loss: 1.2476, G loss: 0.5754\n",
      "[404/1762] D loss: 1.1750, G loss: 0.7321\n",
      "[484/1762] D loss: 1.1953, G loss: 1.1296\n",
      "[564/1762] D loss: 1.1887, G loss: 1.1364\n",
      "[644/1762] D loss: 1.0614, G loss: 0.9758\n",
      "[724/1762] D loss: 1.4120, G loss: 1.1899\n",
      "[804/1762] D loss: 1.3244, G loss: 1.1578\n",
      "[884/1762] D loss: 1.2117, G loss: 0.5643\n",
      "[964/1762] D loss: 1.1766, G loss: 1.3182\n",
      "[1044/1762] D loss: 1.2369, G loss: 0.7782\n",
      "[1124/1762] D loss: 1.3575, G loss: 1.0361\n",
      "[1204/1762] D loss: 1.2815, G loss: 0.9679\n",
      "[1284/1762] D loss: 1.2920, G loss: 0.5113\n",
      "[1364/1762] D loss: 1.7294, G loss: 1.5754\n",
      "[1444/1762] D loss: 1.3997, G loss: 0.9929\n",
      "[1524/1762] D loss: 1.3603, G loss: 0.5146\n",
      "[1604/1762] D loss: 1.3521, G loss: 0.8412\n",
      "[1684/1762] D loss: 1.3300, G loss: 0.7462\n",
      "[1762/1762] D loss: 1.3431, G loss: 0.7397\n",
      "train error: \n",
      " D loss: 1.331259, G loss: 0.747980, D accuracy: 59.9%, cell accuracy: 99.3%, board accuracy: 57.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.340178, G loss: 0.744384, D accuracy: 59.2%, cell accuracy: 99.3%, board accuracy: 53.2% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3632, G loss: 0.7448\n",
      "[84/1762] D loss: 1.3501, G loss: 0.6867\n",
      "[164/1762] D loss: 1.3817, G loss: 0.8699\n",
      "[244/1762] D loss: 1.3861, G loss: 0.9211\n",
      "[324/1762] D loss: 1.4564, G loss: 0.9898\n",
      "[404/1762] D loss: 1.3656, G loss: 0.7682\n",
      "[484/1762] D loss: 1.3657, G loss: 0.7381\n",
      "[564/1762] D loss: 1.3823, G loss: 0.8399\n",
      "[644/1762] D loss: 1.3787, G loss: 0.7667\n",
      "[724/1762] D loss: 1.3487, G loss: 0.6434\n",
      "[804/1762] D loss: 1.3558, G loss: 0.6991\n",
      "[884/1762] D loss: 1.3765, G loss: 0.7586\n",
      "[964/1762] D loss: 1.3353, G loss: 0.7156\n",
      "[1044/1762] D loss: 1.3750, G loss: 0.7174\n",
      "[1124/1762] D loss: 1.3813, G loss: 0.7207\n",
      "[1204/1762] D loss: 1.3684, G loss: 0.6910\n",
      "[1284/1762] D loss: 1.3903, G loss: 0.5484\n",
      "[1364/1762] D loss: 1.3808, G loss: 0.7177\n",
      "[1444/1762] D loss: 1.3785, G loss: 0.6440\n",
      "[1524/1762] D loss: 1.3922, G loss: 0.6047\n",
      "[1604/1762] D loss: 1.3612, G loss: 0.6738\n",
      "[1684/1762] D loss: 1.3778, G loss: 0.6666\n",
      "[1762/1762] D loss: 1.4194, G loss: 0.5920\n",
      "train error: \n",
      " D loss: 1.377359, G loss: 0.567353, D accuracy: 54.2%, cell accuracy: 99.5%, board accuracy: 69.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.374539, G loss: 0.571607, D accuracy: 55.2%, cell accuracy: 99.5%, board accuracy: 67.5% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4130, G loss: 0.5036\n",
      "[84/1762] D loss: 1.3923, G loss: 0.8140\n",
      "[164/1762] D loss: 1.3779, G loss: 0.6931\n",
      "[244/1762] D loss: 1.3748, G loss: 0.7262\n",
      "[324/1762] D loss: 1.3547, G loss: 0.6961\n",
      "[404/1762] D loss: 1.3535, G loss: 0.8017\n",
      "[484/1762] D loss: 1.3740, G loss: 0.7347\n",
      "[564/1762] D loss: 1.4126, G loss: 0.5925\n",
      "[644/1762] D loss: 1.2953, G loss: 0.7363\n",
      "[724/1762] D loss: 1.3907, G loss: 0.6070\n",
      "[804/1762] D loss: 1.3473, G loss: 0.8043\n",
      "[884/1762] D loss: 1.3741, G loss: 0.5734\n",
      "[964/1762] D loss: 1.3950, G loss: 0.6665\n",
      "[1044/1762] D loss: 1.3184, G loss: 0.7047\n",
      "[1124/1762] D loss: 1.3593, G loss: 0.6915\n",
      "[1204/1762] D loss: 1.3812, G loss: 0.6492\n",
      "[1284/1762] D loss: 1.3710, G loss: 0.7906\n",
      "[1364/1762] D loss: 1.3884, G loss: 0.5826\n",
      "[1444/1762] D loss: 1.3923, G loss: 0.6931\n",
      "[1524/1762] D loss: 1.2917, G loss: 0.7092\n",
      "[1604/1762] D loss: 1.2840, G loss: 0.7990\n",
      "[1684/1762] D loss: 1.2985, G loss: 0.8544\n",
      "[1762/1762] D loss: 1.3993, G loss: 0.6648\n",
      "train error: \n",
      " D loss: 1.341442, G loss: 0.754758, D accuracy: 57.0%, cell accuracy: 99.6%, board accuracy: 70.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.336051, G loss: 0.760433, D accuracy: 57.5%, cell accuracy: 99.6%, board accuracy: 69.1% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2718, G loss: 0.7505\n",
      "[84/1762] D loss: 1.3821, G loss: 0.6295\n",
      "[164/1762] D loss: 1.3831, G loss: 0.8652\n",
      "[244/1762] D loss: 1.4416, G loss: 0.5584\n",
      "[324/1762] D loss: 1.3837, G loss: 0.7197\n",
      "[404/1762] D loss: 1.3430, G loss: 0.6996\n",
      "[484/1762] D loss: 1.4027, G loss: 0.6534\n",
      "[564/1762] D loss: 1.5884, G loss: 1.0343\n",
      "[644/1762] D loss: 1.3879, G loss: 0.5309\n",
      "[724/1762] D loss: 1.3721, G loss: 0.7946\n",
      "[804/1762] D loss: 1.3932, G loss: 0.7408\n",
      "[884/1762] D loss: 1.4411, G loss: 0.6608\n",
      "[964/1762] D loss: 1.3765, G loss: 0.7171\n",
      "[1044/1762] D loss: 1.3834, G loss: 0.6844\n",
      "[1124/1762] D loss: 1.3692, G loss: 0.6239\n",
      "[1204/1762] D loss: 1.3987, G loss: 0.6714\n",
      "[1284/1762] D loss: 1.2297, G loss: 1.0072\n",
      "[1364/1762] D loss: 1.3923, G loss: 0.8294\n",
      "[1444/1762] D loss: 1.4048, G loss: 0.9085\n",
      "[1524/1762] D loss: 1.3419, G loss: 0.6027\n",
      "[1604/1762] D loss: 1.4839, G loss: 0.7959\n",
      "[1684/1762] D loss: 1.5404, G loss: 0.3983\n",
      "[1762/1762] D loss: 1.3158, G loss: 0.9525\n",
      "train error: \n",
      " D loss: 1.274343, G loss: 0.719375, D accuracy: 65.3%, cell accuracy: 95.7%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.275827, G loss: 0.722890, D accuracy: 65.1%, cell accuracy: 95.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3868, G loss: 0.7086\n",
      "[84/1762] D loss: 1.3659, G loss: 0.7060\n",
      "[164/1762] D loss: 0.9757, G loss: 1.0132\n",
      "[244/1762] D loss: 0.0166, G loss: 5.1539\n",
      "[324/1762] D loss: 0.0257, G loss: 3.5729\n",
      "[404/1762] D loss: 0.2258, G loss: 7.4662\n",
      "[484/1762] D loss: 0.1344, G loss: 3.9496\n",
      "[564/1762] D loss: 0.0099, G loss: 7.8674\n",
      "[644/1762] D loss: 0.0062, G loss: 6.2045\n",
      "[724/1762] D loss: 0.0049, G loss: 6.8125\n",
      "[804/1762] D loss: 0.0032, G loss: 8.1923\n",
      "[884/1762] D loss: 0.0026, G loss: 8.9169\n",
      "[964/1762] D loss: 0.0023, G loss: 7.7575\n",
      "[1044/1762] D loss: 0.0005, G loss: 9.1690\n",
      "[1124/1762] D loss: 0.0696, G loss: 8.3377\n",
      "[1204/1762] D loss: 0.0056, G loss: 7.4329\n",
      "[1284/1762] D loss: 0.0009, G loss: 7.8114\n",
      "[1364/1762] D loss: 0.0015, G loss: 8.2081\n",
      "[1444/1762] D loss: 0.0537, G loss: 5.9178\n",
      "[1524/1762] D loss: 0.0033, G loss: 6.6217\n",
      "[1604/1762] D loss: 0.0036, G loss: 7.4645\n",
      "[1684/1762] D loss: 0.0023, G loss: 7.5460\n",
      "[1762/1762] D loss: 0.0016, G loss: 7.4379\n",
      "train error: \n",
      " D loss: 0.318819, G loss: 6.856165, D accuracy: 96.7%, cell accuracy: 95.7%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.420360, G loss: 6.684788, D accuracy: 95.0%, cell accuracy: 95.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0041, G loss: 7.1677\n",
      "[84/1762] D loss: 0.0024, G loss: 8.8277\n",
      "[164/1762] D loss: 0.0096, G loss: 6.9400\n",
      "[244/1762] D loss: 0.0010, G loss: 7.6184\n",
      "[324/1762] D loss: 0.0009, G loss: 8.7632\n",
      "[404/1762] D loss: 0.0005, G loss: 8.1835\n",
      "[484/1762] D loss: 0.0010, G loss: 8.0017\n",
      "[564/1762] D loss: 0.0009, G loss: 7.3389\n",
      "[644/1762] D loss: 0.6755, G loss: 4.7419\n",
      "[724/1762] D loss: 0.4879, G loss: 6.2094\n",
      "[804/1762] D loss: 0.0066, G loss: 6.5029\n",
      "[884/1762] D loss: 0.0046, G loss: 7.7532\n",
      "[964/1762] D loss: 0.0031, G loss: 7.3410\n",
      "[1044/1762] D loss: 0.0024, G loss: 7.4350\n",
      "[1124/1762] D loss: 0.0020, G loss: 8.7874\n",
      "[1204/1762] D loss: 0.0003, G loss: 8.4757\n",
      "[1284/1762] D loss: 0.0028, G loss: 9.2212\n",
      "[1364/1762] D loss: 0.0016, G loss: 9.5757\n",
      "[1444/1762] D loss: 0.0003, G loss: 8.2006\n",
      "[1524/1762] D loss: 0.0053, G loss: 7.5069\n",
      "[1604/1762] D loss: 0.0229, G loss: 7.7254\n",
      "[1684/1762] D loss: 0.0010, G loss: 8.6952\n",
      "[1762/1762] D loss: 0.0026, G loss: 7.1491\n",
      "train error: \n",
      " D loss: 0.242625, G loss: 8.083719, D accuracy: 97.4%, cell accuracy: 95.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.257661, G loss: 8.074480, D accuracy: 97.4%, cell accuracy: 95.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0018, G loss: 8.0869\n",
      "[84/1762] D loss: 0.0025, G loss: 8.8932\n",
      "[164/1762] D loss: 0.0035, G loss: 9.2035\n",
      "[244/1762] D loss: 0.0003, G loss: 9.6967\n",
      "[324/1762] D loss: 0.0003, G loss: 10.1466\n",
      "[404/1762] D loss: 0.0031, G loss: 8.8848\n",
      "[484/1762] D loss: 0.0020, G loss: 8.4384\n",
      "[564/1762] D loss: 0.0216, G loss: 7.0896\n",
      "[644/1762] D loss: 0.0022, G loss: 8.5193\n",
      "[724/1762] D loss: 0.0007, G loss: 8.8489\n",
      "[804/1762] D loss: 0.0003, G loss: 9.2736\n",
      "[884/1762] D loss: 0.0011, G loss: 9.2121\n",
      "[964/1762] D loss: 0.0003, G loss: 8.7069\n",
      "[1044/1762] D loss: 0.0018, G loss: 7.3995\n",
      "[1124/1762] D loss: 0.0138, G loss: 6.5061\n",
      "[1204/1762] D loss: 0.0021, G loss: 7.9205\n",
      "[1284/1762] D loss: 0.0028, G loss: 7.8439\n",
      "[1364/1762] D loss: 0.0005, G loss: 9.3753\n",
      "[1444/1762] D loss: 0.0008, G loss: 9.9782\n",
      "[1524/1762] D loss: 0.0003, G loss: 10.5447\n",
      "[1604/1762] D loss: 0.0005, G loss: 10.8045\n",
      "[1684/1762] D loss: 0.8158, G loss: 8.4462\n",
      "[1762/1762] D loss: 0.0002, G loss: 8.4549\n",
      "train error: \n",
      " D loss: 0.202886, G loss: 7.500361, D accuracy: 97.6%, cell accuracy: 95.7%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.253968, G loss: 7.517571, D accuracy: 97.5%, cell accuracy: 95.7%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0023, G loss: 7.1061\n",
      "[84/1762] D loss: 0.0076, G loss: 5.8488\n",
      "[164/1762] D loss: 0.0028, G loss: 7.6121\n",
      "[244/1762] D loss: 0.0004, G loss: 8.3980\n",
      "[324/1762] D loss: 0.0007, G loss: 8.9751\n",
      "[404/1762] D loss: 0.0003, G loss: 8.5494\n",
      "[484/1762] D loss: 0.0004, G loss: 9.1766\n",
      "[564/1762] D loss: 0.0014, G loss: 9.7364\n",
      "[644/1762] D loss: 0.0002, G loss: 9.3964\n",
      "[724/1762] D loss: 0.0053, G loss: 7.5058\n",
      "[804/1762] D loss: 0.0022, G loss: 7.9809\n",
      "[884/1762] D loss: 0.0011, G loss: 9.1641\n",
      "[964/1762] D loss: 0.0012, G loss: 9.2545\n",
      "[1044/1762] D loss: 0.0002, G loss: 9.9472\n",
      "[1124/1762] D loss: 0.0001, G loss: 10.1856\n",
      "[1204/1762] D loss: 0.0004, G loss: 10.0769\n",
      "[1284/1762] D loss: 0.0017, G loss: 10.2861\n",
      "[1364/1762] D loss: 0.0003, G loss: 11.4989\n",
      "[1444/1762] D loss: 0.5070, G loss: 7.9072\n",
      "[1524/1762] D loss: 0.0078, G loss: 8.2359\n",
      "[1604/1762] D loss: 0.0001, G loss: 9.2478\n",
      "[1684/1762] D loss: 0.3508, G loss: 7.6189\n",
      "[1762/1762] D loss: 0.0007, G loss: 9.8999\n",
      "train error: \n",
      " D loss: 0.138117, G loss: 8.883404, D accuracy: 98.4%, cell accuracy: 95.7%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.153847, G loss: 8.893359, D accuracy: 98.5%, cell accuracy: 95.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0009, G loss: 9.2463\n",
      "[84/1762] D loss: 0.0001, G loss: 9.5817\n",
      "[164/1762] D loss: 0.0014, G loss: 7.9445\n",
      "[244/1762] D loss: 0.1452, G loss: 6.6224\n",
      "[324/1762] D loss: 0.0028, G loss: 6.6930\n",
      "[404/1762] D loss: 0.0008, G loss: 7.8095\n",
      "[484/1762] D loss: 0.0009, G loss: 9.3510\n",
      "[564/1762] D loss: 0.0034, G loss: 10.1613\n",
      "[644/1762] D loss: 0.0001, G loss: 9.9396\n",
      "[724/1762] D loss: 0.0002, G loss: 9.6238\n",
      "[804/1762] D loss: 0.0001, G loss: 10.3379\n",
      "[884/1762] D loss: 0.0001, G loss: 10.3690\n",
      "[964/1762] D loss: 0.0001, G loss: 10.5509\n",
      "[1044/1762] D loss: 0.0001, G loss: 11.4320\n",
      "[1124/1762] D loss: 0.0001, G loss: 11.7045\n",
      "[1204/1762] D loss: 0.0004, G loss: 11.8248\n",
      "[1284/1762] D loss: 0.0001, G loss: 12.0598\n",
      "[1364/1762] D loss: 0.0005, G loss: 12.0329\n",
      "[1444/1762] D loss: 0.0001, G loss: 12.3477\n",
      "[1524/1762] D loss: 0.0006, G loss: 11.5367\n",
      "[1604/1762] D loss: 0.0001, G loss: 11.3167\n",
      "[1684/1762] D loss: 0.0001, G loss: 9.5408\n",
      "[1762/1762] D loss: 0.0002, G loss: 10.0463\n",
      "train error: \n",
      " D loss: 0.156622, G loss: 9.087035, D accuracy: 98.4%, cell accuracy: 95.8%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.144491, G loss: 9.106744, D accuracy: 98.4%, cell accuracy: 95.8%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0003, G loss: 9.9478\n",
      "[84/1762] D loss: 0.0092, G loss: 9.8184\n",
      "[164/1762] D loss: 0.0003, G loss: 10.2484\n",
      "[244/1762] D loss: 0.0060, G loss: 7.2432\n",
      "[324/1762] D loss: 0.0036, G loss: 8.0875\n",
      "[404/1762] D loss: 0.0004, G loss: 9.4767\n",
      "[484/1762] D loss: 0.0002, G loss: 10.0281\n",
      "[564/1762] D loss: 0.0003, G loss: 10.0489\n",
      "[644/1762] D loss: 0.0002, G loss: 10.6581\n",
      "[724/1762] D loss: 0.0001, G loss: 10.8335\n",
      "[804/1762] D loss: 0.0001, G loss: 11.7072\n",
      "[884/1762] D loss: 0.0009, G loss: 11.2140\n",
      "[964/1762] D loss: 0.0160, G loss: 4.9665\n",
      "[1044/1762] D loss: 0.0019, G loss: 7.0660\n",
      "[1124/1762] D loss: 0.0004, G loss: 8.6546\n",
      "[1204/1762] D loss: 0.0005, G loss: 9.3135\n",
      "[1284/1762] D loss: 0.0002, G loss: 8.8806\n",
      "[1364/1762] D loss: 0.4633, G loss: 7.3980\n",
      "[1444/1762] D loss: 0.0004, G loss: 8.8993\n",
      "[1524/1762] D loss: 0.0004, G loss: 8.0849\n",
      "[1604/1762] D loss: 0.0013, G loss: 8.4981\n",
      "[1684/1762] D loss: 0.0003, G loss: 8.8252\n",
      "[1762/1762] D loss: 0.0007, G loss: 9.1778\n",
      "train error: \n",
      " D loss: 0.616458, G loss: 8.234232, D accuracy: 96.1%, cell accuracy: 95.6%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.599678, G loss: 8.334691, D accuracy: 96.0%, cell accuracy: 95.5%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0006, G loss: 8.6320\n",
      "[84/1762] D loss: 0.0002, G loss: 9.3870\n",
      "[164/1762] D loss: 0.0048, G loss: 6.9892\n",
      "[244/1762] D loss: 0.0018, G loss: 7.0591\n",
      "[324/1762] D loss: 0.0005, G loss: 9.1609\n",
      "[404/1762] D loss: 0.0001, G loss: 9.5247\n",
      "[484/1762] D loss: 0.0005, G loss: 9.3816\n",
      "[564/1762] D loss: 0.0001, G loss: 10.0495\n",
      "[644/1762] D loss: 0.0001, G loss: 10.5295\n",
      "[724/1762] D loss: 0.0001, G loss: 9.8454\n",
      "[804/1762] D loss: 0.0000, G loss: 11.8195\n",
      "[884/1762] D loss: 0.0000, G loss: 11.6244\n",
      "[964/1762] D loss: 0.0002, G loss: 11.6748\n",
      "[1044/1762] D loss: 0.0001, G loss: 12.1367\n",
      "[1124/1762] D loss: 0.0000, G loss: 11.9548\n",
      "[1204/1762] D loss: 0.0197, G loss: 11.4517\n",
      "[1284/1762] D loss: 0.0007, G loss: 11.1458\n",
      "[1364/1762] D loss: 0.0001, G loss: 11.5900\n",
      "[1444/1762] D loss: 0.0000, G loss: 10.5103\n",
      "[1524/1762] D loss: 0.0004, G loss: 8.1496\n",
      "[1604/1762] D loss: 0.1120, G loss: 7.4453\n",
      "[1684/1762] D loss: 0.0040, G loss: 8.5381\n",
      "[1762/1762] D loss: 0.0050, G loss: 7.7008\n",
      "train error: \n",
      " D loss: 0.057935, G loss: 7.232707, D accuracy: 99.3%, cell accuracy: 95.7%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.097183, G loss: 7.082323, D accuracy: 98.4%, cell accuracy: 95.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0127, G loss: 7.8876\n",
      "[84/1762] D loss: 0.0042, G loss: 9.1813\n",
      "[164/1762] D loss: 0.0005, G loss: 10.1601\n",
      "[244/1762] D loss: 0.0001, G loss: 10.3047\n",
      "[324/1762] D loss: 0.0013, G loss: 8.6527\n",
      "[404/1762] D loss: 0.0079, G loss: 7.8474\n",
      "[484/1762] D loss: 0.0024, G loss: 7.5799\n",
      "[564/1762] D loss: 0.0016, G loss: 8.4818\n",
      "[644/1762] D loss: 0.0056, G loss: 8.3411\n",
      "[724/1762] D loss: 0.0019, G loss: 9.7489\n",
      "[804/1762] D loss: 0.0002, G loss: 10.5186\n",
      "[884/1762] D loss: 0.0000, G loss: 10.7301\n",
      "[964/1762] D loss: 0.0000, G loss: 12.3146\n",
      "[1044/1762] D loss: 0.0008, G loss: 13.2280\n",
      "[1124/1762] D loss: 0.0004, G loss: 11.3938\n",
      "[1204/1762] D loss: 0.0053, G loss: 9.4747\n",
      "[1284/1762] D loss: 0.0025, G loss: 9.4821\n",
      "[1364/1762] D loss: 0.0008, G loss: 11.3660\n",
      "[1444/1762] D loss: 0.0005, G loss: 8.8662\n",
      "[1524/1762] D loss: 0.0013, G loss: 9.4717\n",
      "[1604/1762] D loss: 0.0709, G loss: 10.3596\n",
      "[1684/1762] D loss: 0.0002, G loss: 11.2889\n",
      "[1762/1762] D loss: 0.0008, G loss: 11.7665\n",
      "train error: \n",
      " D loss: 0.071439, G loss: 11.048134, D accuracy: 99.1%, cell accuracy: 95.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.050022, G loss: 11.098006, D accuracy: 99.2%, cell accuracy: 95.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001, G loss: 11.2431\n",
      "[84/1762] D loss: 0.0001, G loss: 11.9565\n",
      "[164/1762] D loss: 0.0009, G loss: 11.4071\n",
      "[244/1762] D loss: 0.0000, G loss: 12.3973\n",
      "[324/1762] D loss: 0.0000, G loss: 12.3293\n",
      "[404/1762] D loss: 0.0004, G loss: 12.2140\n",
      "[484/1762] D loss: 0.0000, G loss: 11.6185\n",
      "[564/1762] D loss: 0.0000, G loss: 12.9816\n",
      "[644/1762] D loss: 0.2817, G loss: 10.3643\n",
      "[724/1762] D loss: 0.0011, G loss: 8.8426\n",
      "[804/1762] D loss: 0.0009, G loss: 9.9736\n",
      "[884/1762] D loss: 0.0003, G loss: 10.8169\n",
      "[964/1762] D loss: 0.0005, G loss: 11.8311\n",
      "[1044/1762] D loss: 0.0001, G loss: 12.3848\n",
      "[1124/1762] D loss: 0.0000, G loss: 12.5225\n",
      "[1204/1762] D loss: 0.0000, G loss: 12.2236\n",
      "[1284/1762] D loss: 0.0197, G loss: 13.5258\n",
      "[1364/1762] D loss: 0.0000, G loss: 12.7700\n",
      "[1444/1762] D loss: 0.0000, G loss: 13.2242\n",
      "[1524/1762] D loss: 0.0000, G loss: 14.1457\n",
      "[1604/1762] D loss: 0.0001, G loss: 12.2219\n",
      "[1684/1762] D loss: 0.0098, G loss: 14.7617\n",
      "[1762/1762] D loss: 0.0016, G loss: 7.1607\n",
      "train error: \n",
      " D loss: 0.142927, G loss: 7.257617, D accuracy: 98.5%, cell accuracy: 95.7%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.151930, G loss: 7.230510, D accuracy: 98.1%, cell accuracy: 95.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0116, G loss: 6.3939\n",
      "[84/1762] D loss: 0.0066, G loss: 6.7587\n",
      "[164/1762] D loss: 0.0041, G loss: 7.7432\n",
      "[244/1762] D loss: 0.0005, G loss: 10.3021\n",
      "[324/1762] D loss: 0.0001, G loss: 12.0356\n",
      "[404/1762] D loss: 0.0005, G loss: 13.3408\n",
      "[484/1762] D loss: 0.0003, G loss: 11.7960\n",
      "[564/1762] D loss: 0.0000, G loss: 13.2720\n",
      "[644/1762] D loss: 0.0013, G loss: 11.8417\n",
      "[724/1762] D loss: 0.0079, G loss: 13.3517\n",
      "[804/1762] D loss: 0.0000, G loss: 14.8069\n",
      "[884/1762] D loss: 0.0090, G loss: 7.2643\n",
      "[964/1762] D loss: 0.0096, G loss: 6.3395\n",
      "[1044/1762] D loss: 0.0008, G loss: 8.3216\n",
      "[1124/1762] D loss: 0.0002, G loss: 9.0335\n",
      "[1204/1762] D loss: 0.0000, G loss: 11.1716\n",
      "[1284/1762] D loss: 0.0007, G loss: 9.3938\n",
      "[1364/1762] D loss: 0.0011, G loss: 9.7953\n",
      "[1444/1762] D loss: 0.0164, G loss: 9.5337\n",
      "[1524/1762] D loss: 0.0001, G loss: 10.0692\n",
      "[1604/1762] D loss: 0.0010, G loss: 9.7449\n",
      "[1684/1762] D loss: 0.0011, G loss: 7.2129\n",
      "[1762/1762] D loss: 0.0002, G loss: 9.1468\n",
      "train error: \n",
      " D loss: 0.232701, G loss: 8.626671, D accuracy: 98.1%, cell accuracy: 95.7%, board accuracy: 0.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.107982, G loss: 8.972539, D accuracy: 99.0%, cell accuracy: 95.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0002, G loss: 9.6320\n",
      "[84/1762] D loss: 0.0002, G loss: 9.4067\n",
      "[164/1762] D loss: 0.0002, G loss: 10.7112\n",
      "[244/1762] D loss: 0.0001, G loss: 10.5875\n",
      "[324/1762] D loss: 0.0001, G loss: 10.0386\n",
      "[404/1762] D loss: 0.0001, G loss: 11.4665\n",
      "[484/1762] D loss: 0.0000, G loss: 11.4521\n",
      "[564/1762] D loss: 0.0141, G loss: 10.6960\n",
      "[644/1762] D loss: 0.0014, G loss: 8.1024\n",
      "[724/1762] D loss: 0.0005, G loss: 8.9237\n",
      "[804/1762] D loss: 0.0003, G loss: 9.5258\n",
      "[884/1762] D loss: 0.0007, G loss: 8.8300\n",
      "[964/1762] D loss: 0.0001, G loss: 10.0324\n",
      "[1044/1762] D loss: 0.0052, G loss: 8.9330\n",
      "[1124/1762] D loss: 0.0010, G loss: 9.0858\n",
      "[1204/1762] D loss: 0.0029, G loss: 11.2546\n",
      "[1284/1762] D loss: 0.0001, G loss: 11.5338\n",
      "[1364/1762] D loss: 0.0002, G loss: 9.8797\n",
      "[1444/1762] D loss: 0.0000, G loss: 11.5856\n",
      "[1524/1762] D loss: 0.0000, G loss: 10.2406\n",
      "[1604/1762] D loss: 0.0013, G loss: 6.7293\n",
      "[1684/1762] D loss: 0.0008, G loss: 7.6411\n",
      "[1762/1762] D loss: 0.0001, G loss: 9.8559\n",
      "train error: \n",
      " D loss: 0.693682, G loss: 8.078502, D accuracy: 95.6%, cell accuracy: 95.6%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.515617, G loss: 8.237247, D accuracy: 96.1%, cell accuracy: 95.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0007, G loss: 8.0662\n",
      "[84/1762] D loss: 0.0020, G loss: 8.3313\n",
      "[164/1762] D loss: 0.0001, G loss: 10.2477\n",
      "[244/1762] D loss: 0.0001, G loss: 9.9620\n",
      "[324/1762] D loss: 0.0006, G loss: 10.2202\n",
      "[404/1762] D loss: 0.0003, G loss: 10.2624\n",
      "[484/1762] D loss: 0.0011, G loss: 8.3803\n",
      "[564/1762] D loss: 0.0008, G loss: 9.6632\n",
      "[644/1762] D loss: 0.0001, G loss: 9.4574\n",
      "[724/1762] D loss: 0.0001, G loss: 9.4705\n",
      "[804/1762] D loss: 0.0001, G loss: 9.9883\n",
      "[884/1762] D loss: 0.0001, G loss: 10.8782\n",
      "[964/1762] D loss: 0.0001, G loss: 9.9895\n",
      "[1044/1762] D loss: 0.0001, G loss: 11.1702\n",
      "[1124/1762] D loss: 0.0001, G loss: 10.7731\n",
      "[1204/1762] D loss: 0.0001, G loss: 10.3936\n",
      "[1284/1762] D loss: 0.0000, G loss: 11.1992\n",
      "[1364/1762] D loss: 0.0784, G loss: 7.7528\n",
      "[1444/1762] D loss: 0.0013, G loss: 8.0661\n",
      "[1524/1762] D loss: 0.0004, G loss: 9.2686\n",
      "[1604/1762] D loss: 0.0019, G loss: 10.1568\n",
      "[1684/1762] D loss: 0.0000, G loss: 10.7361\n",
      "[1762/1762] D loss: 0.0000, G loss: 10.8295\n",
      "train error: \n",
      " D loss: 0.362723, G loss: 10.136598, D accuracy: 97.2%, cell accuracy: 95.7%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.260472, G loss: 10.426862, D accuracy: 97.7%, cell accuracy: 95.7%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0003, G loss: 11.2267\n",
      "[84/1762] D loss: 0.0000, G loss: 10.9783\n",
      "[164/1762] D loss: 0.0005, G loss: 11.6562\n",
      "[244/1762] D loss: 0.0008, G loss: 10.0591\n",
      "[324/1762] D loss: 0.0005, G loss: 11.8842\n",
      "[404/1762] D loss: 0.0001, G loss: 10.9098\n",
      "[484/1762] D loss: 0.0000, G loss: 12.1418\n",
      "[564/1762] D loss: 0.0252, G loss: 11.0517\n",
      "[644/1762] D loss: 0.0035, G loss: 11.6473\n",
      "[724/1762] D loss: 0.0007, G loss: 12.1414\n",
      "[804/1762] D loss: 0.0000, G loss: 11.7303\n",
      "[884/1762] D loss: 0.0001, G loss: 13.4668\n",
      "[964/1762] D loss: 0.0000, G loss: 13.7061\n",
      "[1044/1762] D loss: 0.0000, G loss: 13.6599\n",
      "[1124/1762] D loss: 0.0000, G loss: 14.8069\n",
      "[1204/1762] D loss: 0.0000, G loss: 14.4036\n",
      "[1284/1762] D loss: 0.0000, G loss: 14.1635\n",
      "[1364/1762] D loss: 0.0000, G loss: 13.8555\n",
      "[1444/1762] D loss: 0.0000, G loss: 13.4167\n",
      "[1524/1762] D loss: 0.0000, G loss: 13.0730\n",
      "[1604/1762] D loss: 0.0002, G loss: 12.9488\n",
      "[1684/1762] D loss: 0.0001, G loss: 14.3960\n",
      "[1762/1762] D loss: 0.0000, G loss: 14.2665\n",
      "train error: \n",
      " D loss: 0.302883, G loss: 13.256152, D accuracy: 98.0%, cell accuracy: 95.6%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.316473, G loss: 13.264064, D accuracy: 98.1%, cell accuracy: 95.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 14.4172\n",
      "[84/1762] D loss: 0.0000, G loss: 13.5430\n",
      "[164/1762] D loss: 0.0000, G loss: 14.6459\n",
      "[244/1762] D loss: 0.0000, G loss: 15.1435\n",
      "[324/1762] D loss: 0.0037, G loss: 7.6831\n",
      "[404/1762] D loss: 0.0003, G loss: 10.2437\n",
      "[484/1762] D loss: 0.0001, G loss: 10.1770\n",
      "[564/1762] D loss: 0.0037, G loss: 9.9705\n",
      "[644/1762] D loss: 0.0001, G loss: 12.0067\n",
      "[724/1762] D loss: 0.0001, G loss: 11.7419\n",
      "[804/1762] D loss: 0.0002, G loss: 11.7447\n",
      "[884/1762] D loss: 0.0092, G loss: 7.8395\n",
      "[964/1762] D loss: 0.0048, G loss: 6.1333\n",
      "[1044/1762] D loss: 0.0007, G loss: 8.9093\n",
      "[1124/1762] D loss: 0.0001, G loss: 10.0150\n",
      "[1204/1762] D loss: 0.0724, G loss: 9.0088\n",
      "[1284/1762] D loss: 0.0000, G loss: 12.1374\n",
      "[1364/1762] D loss: 0.0000, G loss: 12.8499\n",
      "[1444/1762] D loss: 0.0002, G loss: 11.4198\n",
      "[1524/1762] D loss: 0.0034, G loss: 10.4825\n",
      "[1604/1762] D loss: 0.0000, G loss: 11.7641\n",
      "[1684/1762] D loss: 0.0000, G loss: 11.3382\n",
      "[1762/1762] D loss: 0.0017, G loss: 11.4318\n",
      "train error: \n",
      " D loss: 0.140093, G loss: 9.308883, D accuracy: 98.5%, cell accuracy: 95.6%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.136231, G loss: 9.320319, D accuracy: 98.4%, cell accuracy: 95.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0012, G loss: 9.2378\n",
      "[84/1762] D loss: 0.0003, G loss: 10.4322\n",
      "[164/1762] D loss: 0.0001, G loss: 10.9073\n",
      "[244/1762] D loss: 0.0255, G loss: 7.5237\n",
      "[324/1762] D loss: 0.0007, G loss: 9.8559\n",
      "[404/1762] D loss: 0.0011, G loss: 10.2484\n",
      "[484/1762] D loss: 0.0018, G loss: 11.1469\n",
      "[564/1762] D loss: 0.0000, G loss: 11.6981\n",
      "[644/1762] D loss: 0.0003, G loss: 11.8363\n",
      "[724/1762] D loss: 0.0016, G loss: 9.2280\n",
      "[804/1762] D loss: 0.0001, G loss: 12.3703\n",
      "[884/1762] D loss: 0.0001, G loss: 12.6453\n",
      "[964/1762] D loss: 0.0000, G loss: 13.4732\n",
      "[1044/1762] D loss: 0.0002, G loss: 12.2098\n",
      "[1124/1762] D loss: 0.0000, G loss: 14.8655\n",
      "[1204/1762] D loss: 0.0000, G loss: 14.9383\n",
      "[1284/1762] D loss: 0.0000, G loss: 15.8698\n",
      "[1364/1762] D loss: 0.0002, G loss: 12.3599\n",
      "[1444/1762] D loss: 0.0000, G loss: 15.2794\n",
      "[1524/1762] D loss: 0.0000, G loss: 16.6813\n",
      "[1604/1762] D loss: 0.0008, G loss: 14.3588\n",
      "[1684/1762] D loss: 0.0000, G loss: 12.8640\n",
      "[1762/1762] D loss: 0.0014, G loss: 8.3253\n",
      "train error: \n",
      " D loss: 0.087808, G loss: 7.282492, D accuracy: 98.4%, cell accuracy: 95.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.118271, G loss: 7.275460, D accuracy: 98.3%, cell accuracy: 95.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0031, G loss: 7.1926\n",
      "[84/1762] D loss: 0.0096, G loss: 7.7991\n",
      "[164/1762] D loss: 0.0008, G loss: 10.1862\n",
      "[244/1762] D loss: 0.0003, G loss: 11.5191\n",
      "[324/1762] D loss: 0.0006, G loss: 10.3880\n",
      "[404/1762] D loss: 0.0003, G loss: 10.1841\n",
      "[484/1762] D loss: 0.0005, G loss: 10.0467\n",
      "[564/1762] D loss: 0.0541, G loss: 11.2683\n",
      "[644/1762] D loss: 0.0001, G loss: 11.4633\n",
      "[724/1762] D loss: 0.0001, G loss: 11.1605\n",
      "[804/1762] D loss: 0.0000, G loss: 12.3615\n",
      "[884/1762] D loss: 0.0006, G loss: 11.1481\n",
      "[964/1762] D loss: 0.0003, G loss: 12.3311\n",
      "[1044/1762] D loss: 0.0000, G loss: 12.9121\n",
      "[1124/1762] D loss: 0.0001, G loss: 12.2281\n",
      "[1204/1762] D loss: 0.0000, G loss: 13.3554\n",
      "[1284/1762] D loss: 0.0000, G loss: 13.1692\n",
      "[1364/1762] D loss: 0.0000, G loss: 14.9226\n",
      "[1444/1762] D loss: 0.0008, G loss: 16.0847\n",
      "[1524/1762] D loss: 0.0000, G loss: 15.7658\n",
      "[1604/1762] D loss: 0.0000, G loss: 15.2882\n",
      "[1684/1762] D loss: 0.0000, G loss: 15.3284\n",
      "[1762/1762] D loss: 0.0000, G loss: 15.1008\n",
      "train error: \n",
      " D loss: 0.055276, G loss: 15.060581, D accuracy: 99.5%, cell accuracy: 95.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.109111, G loss: 15.140962, D accuracy: 99.4%, cell accuracy: 95.7%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 14.5674\n",
      "[84/1762] D loss: 0.0000, G loss: 11.2154\n",
      "[164/1762] D loss: 0.0048, G loss: 11.3138\n",
      "[244/1762] D loss: 0.0000, G loss: 13.3536\n",
      "[324/1762] D loss: 0.0000, G loss: 12.8211\n",
      "[404/1762] D loss: 0.0000, G loss: 12.7417\n",
      "[484/1762] D loss: 0.0007, G loss: 11.8374\n",
      "[564/1762] D loss: 0.3444, G loss: 10.6064\n",
      "[644/1762] D loss: 0.0003, G loss: 9.5314\n",
      "[724/1762] D loss: 0.0002, G loss: 10.2258\n",
      "[804/1762] D loss: 0.0001, G loss: 10.8979\n",
      "[884/1762] D loss: 0.0000, G loss: 12.0619\n",
      "[964/1762] D loss: 0.0000, G loss: 12.3220\n",
      "[1044/1762] D loss: 0.0001, G loss: 12.4284\n",
      "[1124/1762] D loss: 0.0000, G loss: 14.1468\n",
      "[1204/1762] D loss: 0.0000, G loss: 14.8791\n",
      "[1284/1762] D loss: 0.0000, G loss: 17.1512\n",
      "[1364/1762] D loss: 0.0000, G loss: 15.9566\n",
      "[1444/1762] D loss: 0.0000, G loss: 16.5189\n",
      "[1524/1762] D loss: 0.0000, G loss: 16.4215\n",
      "[1604/1762] D loss: 0.0001, G loss: 18.5810\n",
      "[1684/1762] D loss: 0.0000, G loss: 16.4072\n",
      "[1762/1762] D loss: 0.0274, G loss: 15.2602\n",
      "train error: \n",
      " D loss: 0.159309, G loss: 15.580694, D accuracy: 98.7%, cell accuracy: 95.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.149128, G loss: 15.584764, D accuracy: 98.5%, cell accuracy: 95.8%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 16.8334\n",
      "[84/1762] D loss: 0.0000, G loss: 15.3637\n",
      "[164/1762] D loss: 0.0000, G loss: 17.7499\n",
      "[244/1762] D loss: 0.0000, G loss: 21.6029\n",
      "[324/1762] D loss: 0.0000, G loss: 22.2435\n",
      "[404/1762] D loss: 0.0000, G loss: 20.9652\n",
      "[484/1762] D loss: 0.0000, G loss: 19.6321\n",
      "[564/1762] D loss: 0.0000, G loss: 21.6636\n",
      "[644/1762] D loss: 0.0000, G loss: 18.0765\n",
      "[724/1762] D loss: 0.0000, G loss: 15.6934\n",
      "[804/1762] D loss: 0.0001, G loss: 14.0138\n",
      "[884/1762] D loss: 0.0010, G loss: 13.3441\n",
      "[964/1762] D loss: 0.3075, G loss: 10.1363\n",
      "[1044/1762] D loss: 0.0001, G loss: 10.4015\n",
      "[1124/1762] D loss: 0.0000, G loss: 11.4728\n",
      "[1204/1762] D loss: 0.0002, G loss: 10.3717\n",
      "[1284/1762] D loss: 0.0000, G loss: 12.4330\n",
      "[1364/1762] D loss: 0.0000, G loss: 10.5899\n",
      "[1444/1762] D loss: 0.0001, G loss: 11.3075\n",
      "[1524/1762] D loss: 0.0000, G loss: 12.8924\n",
      "[1604/1762] D loss: 0.0000, G loss: 10.6721\n",
      "[1684/1762] D loss: 0.0001, G loss: 10.4822\n",
      "[1762/1762] D loss: 0.0005, G loss: 11.4301\n",
      "train error: \n",
      " D loss: 0.072608, G loss: 10.768593, D accuracy: 98.8%, cell accuracy: 95.7%, board accuracy: 0.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.056554, G loss: 10.959373, D accuracy: 99.0%, cell accuracy: 95.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0016, G loss: 10.7069\n",
      "[84/1762] D loss: 0.0042, G loss: 7.4130\n",
      "[164/1762] D loss: 0.0008, G loss: 8.0341\n",
      "[244/1762] D loss: 0.0007, G loss: 9.6430\n",
      "[324/1762] D loss: 0.0026, G loss: 7.4867\n",
      "[404/1762] D loss: 0.0045, G loss: 7.7404\n",
      "[484/1762] D loss: 0.0038, G loss: 8.4660\n",
      "[564/1762] D loss: 0.1234, G loss: 10.9000\n",
      "[644/1762] D loss: 0.0003, G loss: 10.1944\n",
      "[724/1762] D loss: 0.0006, G loss: 11.4821\n",
      "[804/1762] D loss: 0.0004, G loss: 11.0766\n",
      "[884/1762] D loss: 0.0004, G loss: 10.4017\n",
      "[964/1762] D loss: 0.0001, G loss: 11.6579\n",
      "[1044/1762] D loss: 0.0005, G loss: 11.6552\n",
      "[1124/1762] D loss: 0.0000, G loss: 11.6987\n",
      "[1204/1762] D loss: 0.0000, G loss: 12.0279\n",
      "[1284/1762] D loss: 0.0001, G loss: 12.1540\n",
      "[1364/1762] D loss: 0.0000, G loss: 13.0868\n",
      "[1444/1762] D loss: 0.0001, G loss: 11.7964\n",
      "[1524/1762] D loss: 0.0000, G loss: 13.3863\n",
      "[1604/1762] D loss: 0.0000, G loss: 13.2979\n",
      "[1684/1762] D loss: 0.0001, G loss: 12.9604\n",
      "[1762/1762] D loss: 0.0000, G loss: 14.3924\n",
      "train error: \n",
      " D loss: 0.097628, G loss: 12.771799, D accuracy: 99.1%, cell accuracy: 95.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.134497, G loss: 12.628263, D accuracy: 98.6%, cell accuracy: 95.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 12.3042\n",
      "[84/1762] D loss: 0.0033, G loss: 12.0742\n",
      "[164/1762] D loss: 0.0000, G loss: 13.5747\n",
      "[244/1762] D loss: 0.0001, G loss: 11.4102\n",
      "[324/1762] D loss: 0.0001, G loss: 13.4582\n",
      "[404/1762] D loss: 0.0009, G loss: 13.9592\n",
      "[484/1762] D loss: 0.0000, G loss: 13.3543\n",
      "[564/1762] D loss: 0.0007, G loss: 14.5958\n",
      "[644/1762] D loss: 0.0000, G loss: 13.7091\n",
      "[724/1762] D loss: 0.0002, G loss: 15.6723\n",
      "[804/1762] D loss: 0.0087, G loss: 9.4148\n",
      "[884/1762] D loss: 0.0019, G loss: 10.1462\n",
      "[964/1762] D loss: 0.0005, G loss: 9.6219\n",
      "[1044/1762] D loss: 0.0538, G loss: 13.3866\n",
      "[1124/1762] D loss: 0.0001, G loss: 13.8785\n",
      "[1204/1762] D loss: 0.0001, G loss: 13.5100\n",
      "[1284/1762] D loss: 0.0000, G loss: 14.7432\n",
      "[1364/1762] D loss: 0.0008, G loss: 14.9689\n",
      "[1444/1762] D loss: 0.0000, G loss: 14.9644\n",
      "[1524/1762] D loss: 0.0000, G loss: 16.7216\n",
      "[1604/1762] D loss: 0.0000, G loss: 15.4437\n",
      "[1684/1762] D loss: 0.0000, G loss: 16.4913\n",
      "[1762/1762] D loss: 0.0000, G loss: 17.5664\n",
      "train error: \n",
      " D loss: 0.108767, G loss: 15.591044, D accuracy: 99.1%, cell accuracy: 95.8%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.160866, G loss: 15.279635, D accuracy: 98.3%, cell accuracy: 95.7%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 16.3259\n",
      "[84/1762] D loss: 0.0000, G loss: 16.9029\n",
      "[164/1762] D loss: 0.0000, G loss: 17.0941\n",
      "[244/1762] D loss: 0.0001, G loss: 16.8542\n",
      "[324/1762] D loss: 0.0002, G loss: 19.3969\n",
      "[404/1762] D loss: 0.0000, G loss: 18.2136\n",
      "[484/1762] D loss: 0.0000, G loss: 13.1958\n",
      "[564/1762] D loss: 0.0000, G loss: 12.6284\n",
      "[644/1762] D loss: 0.0000, G loss: 13.1609\n",
      "[724/1762] D loss: 0.0001, G loss: 14.3798\n",
      "[804/1762] D loss: 0.0001, G loss: 12.4912\n",
      "[884/1762] D loss: 0.0001, G loss: 12.2063\n",
      "[964/1762] D loss: 0.0001, G loss: 12.7247\n",
      "[1044/1762] D loss: 0.0000, G loss: 13.6438\n",
      "[1124/1762] D loss: 0.0002, G loss: 11.2818\n",
      "[1204/1762] D loss: 0.0024, G loss: 12.7711\n",
      "[1284/1762] D loss: 0.0000, G loss: 12.7280\n",
      "[1364/1762] D loss: 0.0000, G loss: 13.5091\n",
      "[1444/1762] D loss: 0.0000, G loss: 14.4286\n",
      "[1524/1762] D loss: 0.0000, G loss: 15.3847\n",
      "[1604/1762] D loss: 0.0003, G loss: 14.7026\n",
      "[1684/1762] D loss: 0.0000, G loss: 15.7586\n",
      "[1762/1762] D loss: 0.0000, G loss: 15.0114\n",
      "train error: \n",
      " D loss: 0.149397, G loss: 14.025276, D accuracy: 98.8%, cell accuracy: 95.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.112270, G loss: 14.130533, D accuracy: 99.2%, cell accuracy: 95.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 13.5212\n",
      "[84/1762] D loss: 0.0000, G loss: 14.6917\n",
      "[164/1762] D loss: 0.0000, G loss: 15.0945\n",
      "[244/1762] D loss: 0.0000, G loss: 13.2908\n",
      "[324/1762] D loss: 0.0000, G loss: 13.2816\n",
      "[404/1762] D loss: 0.0000, G loss: 14.4587\n",
      "[484/1762] D loss: 0.0000, G loss: 14.9528\n",
      "[564/1762] D loss: 0.0000, G loss: 15.3653\n",
      "[644/1762] D loss: 0.0002, G loss: 11.4043\n",
      "[724/1762] D loss: 0.1266, G loss: 8.3989\n",
      "[804/1762] D loss: 0.0000, G loss: 11.7341\n",
      "[884/1762] D loss: 0.0001, G loss: 16.5944\n",
      "[964/1762] D loss: 0.0000, G loss: 15.5113\n",
      "[1044/1762] D loss: 0.0000, G loss: 11.2528\n",
      "[1124/1762] D loss: 0.0000, G loss: 11.5597\n",
      "[1204/1762] D loss: 0.0000, G loss: 11.3374\n",
      "[1284/1762] D loss: 0.0002, G loss: 12.9245\n",
      "[1364/1762] D loss: 0.0000, G loss: 11.5487\n",
      "[1444/1762] D loss: 0.0003, G loss: 11.9440\n",
      "[1524/1762] D loss: 0.0001, G loss: 12.8750\n",
      "[1604/1762] D loss: 0.0000, G loss: 12.7359\n",
      "[1684/1762] D loss: 0.0000, G loss: 13.1621\n",
      "[1762/1762] D loss: 0.0000, G loss: 11.9079\n",
      "train error: \n",
      " D loss: 0.050616, G loss: 12.249392, D accuracy: 99.3%, cell accuracy: 95.8%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.129844, G loss: 12.115230, D accuracy: 99.0%, cell accuracy: 95.8%, board accuracy: 0.5% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 13.5370\n",
      "[84/1762] D loss: 0.0000, G loss: 12.0127\n",
      "[164/1762] D loss: 0.0000, G loss: 11.5852\n",
      "[244/1762] D loss: 0.0000, G loss: 13.0106\n",
      "[324/1762] D loss: 0.0000, G loss: 13.6782\n",
      "[404/1762] D loss: 0.0000, G loss: 12.3336\n",
      "[484/1762] D loss: 0.0000, G loss: 12.9572\n",
      "[564/1762] D loss: 0.0010, G loss: 10.8775\n",
      "[644/1762] D loss: 0.0199, G loss: 10.0367\n",
      "[724/1762] D loss: 0.0000, G loss: 10.9739\n",
      "[804/1762] D loss: 0.0017, G loss: 12.4832\n",
      "[884/1762] D loss: 0.0000, G loss: 11.4025\n",
      "[964/1762] D loss: 0.0001, G loss: 11.4508\n",
      "[1044/1762] D loss: 0.0001, G loss: 9.4184\n",
      "[1124/1762] D loss: 0.0001, G loss: 9.8668\n",
      "[1204/1762] D loss: 0.0001, G loss: 10.0413\n",
      "[1284/1762] D loss: 0.0006, G loss: 10.1364\n",
      "[1364/1762] D loss: 0.0007, G loss: 11.5605\n",
      "[1444/1762] D loss: 0.0000, G loss: 11.4071\n",
      "[1524/1762] D loss: 0.0002, G loss: 11.2772\n",
      "[1604/1762] D loss: 0.0000, G loss: 10.6326\n",
      "[1684/1762] D loss: 0.0019, G loss: 11.0725\n",
      "[1762/1762] D loss: 0.0018, G loss: 12.0728\n",
      "train error: \n",
      " D loss: 0.478471, G loss: 9.862545, D accuracy: 96.5%, cell accuracy: 95.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.600316, G loss: 9.511539, D accuracy: 95.2%, cell accuracy: 95.5%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0190, G loss: 8.8189\n",
      "[84/1762] D loss: 0.0001, G loss: 10.4709\n",
      "[164/1762] D loss: 0.0001, G loss: 10.9700\n",
      "[244/1762] D loss: 0.0001, G loss: 10.8335\n",
      "[324/1762] D loss: 0.0000, G loss: 10.8066\n",
      "[404/1762] D loss: 0.0001, G loss: 10.7662\n",
      "[484/1762] D loss: 0.0260, G loss: 9.3170\n",
      "[564/1762] D loss: 0.0025, G loss: 10.0508\n",
      "[644/1762] D loss: 0.0012, G loss: 10.2450\n",
      "[724/1762] D loss: 0.0002, G loss: 10.0411\n",
      "[804/1762] D loss: 0.0099, G loss: 9.2580\n",
      "[884/1762] D loss: 0.0001, G loss: 11.5744\n",
      "[964/1762] D loss: 0.0003, G loss: 11.1889\n",
      "[1044/1762] D loss: 0.0001, G loss: 11.2122\n",
      "[1124/1762] D loss: 0.0001, G loss: 11.9938\n",
      "[1204/1762] D loss: 0.0000, G loss: 11.8397\n",
      "[1284/1762] D loss: 0.0001, G loss: 12.2823\n",
      "[1364/1762] D loss: 0.0000, G loss: 12.3278\n",
      "[1444/1762] D loss: 0.0010, G loss: 13.0606\n",
      "[1524/1762] D loss: 0.0001, G loss: 14.1682\n",
      "[1604/1762] D loss: 0.0000, G loss: 13.9509\n",
      "[1684/1762] D loss: 0.0001, G loss: 13.2441\n",
      "[1762/1762] D loss: 0.0000, G loss: 17.2790\n",
      "train error: \n",
      " D loss: 0.387296, G loss: 16.480949, D accuracy: 97.8%, cell accuracy: 95.6%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.534821, G loss: 16.016230, D accuracy: 97.3%, cell accuracy: 95.5%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 18.9146\n",
      "[84/1762] D loss: 0.0000, G loss: 17.5308\n",
      "[164/1762] D loss: 0.0000, G loss: 17.2833\n",
      "[244/1762] D loss: 0.0000, G loss: 19.2098\n",
      "[324/1762] D loss: 0.0000, G loss: 18.4798\n",
      "[404/1762] D loss: 0.0000, G loss: 18.3631\n",
      "[484/1762] D loss: 0.0000, G loss: 19.0350\n",
      "[564/1762] D loss: 0.0000, G loss: 18.2613\n",
      "[644/1762] D loss: 0.0000, G loss: 18.0428\n",
      "[724/1762] D loss: 0.0000, G loss: 15.6816\n",
      "[804/1762] D loss: 0.0009, G loss: 10.4441\n",
      "[884/1762] D loss: 0.3742, G loss: 10.9256\n",
      "[964/1762] D loss: 0.0008, G loss: 9.8062\n",
      "[1044/1762] D loss: 0.0001, G loss: 9.7267\n",
      "[1124/1762] D loss: 0.0002, G loss: 11.6430\n",
      "[1204/1762] D loss: 0.0007, G loss: 11.0046\n",
      "[1284/1762] D loss: 0.0003, G loss: 11.0750\n",
      "[1364/1762] D loss: 0.0029, G loss: 10.8523\n",
      "[1444/1762] D loss: 0.0002, G loss: 11.8036\n",
      "[1524/1762] D loss: 0.0002, G loss: 11.2778\n",
      "[1604/1762] D loss: 0.0001, G loss: 12.5204\n",
      "[1684/1762] D loss: 0.0001, G loss: 11.5180\n",
      "[1762/1762] D loss: 0.0001, G loss: 18.9378\n",
      "train error: \n",
      " D loss: 0.035427, G loss: 13.025169, D accuracy: 99.6%, cell accuracy: 95.7%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.061201, G loss: 12.957048, D accuracy: 99.4%, cell accuracy: 95.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001, G loss: 13.9603\n",
      "[84/1762] D loss: 0.0001, G loss: 13.1440\n",
      "[164/1762] D loss: 0.0001, G loss: 13.8545\n",
      "[244/1762] D loss: 0.0000, G loss: 10.1319\n",
      "[324/1762] D loss: 0.0000, G loss: 11.7613\n",
      "[404/1762] D loss: 0.0001, G loss: 10.6684\n",
      "[484/1762] D loss: 0.0002, G loss: 12.7986\n",
      "[564/1762] D loss: 0.0000, G loss: 11.7064\n",
      "[644/1762] D loss: 0.0000, G loss: 13.1576\n",
      "[724/1762] D loss: 0.0000, G loss: 11.5465\n",
      "[804/1762] D loss: 0.0000, G loss: 12.9161\n",
      "[884/1762] D loss: 0.0000, G loss: 13.6632\n",
      "[964/1762] D loss: 0.0000, G loss: 13.5915\n",
      "[1044/1762] D loss: 0.0000, G loss: 15.0943\n",
      "[1124/1762] D loss: 0.0000, G loss: 12.6960\n",
      "[1204/1762] D loss: 0.0002, G loss: 12.5741\n",
      "[1284/1762] D loss: 0.0023, G loss: 10.5727\n",
      "[1364/1762] D loss: 0.0008, G loss: 8.5901\n",
      "[1444/1762] D loss: 0.0001, G loss: 10.7972\n",
      "[1524/1762] D loss: 0.0001, G loss: 10.1608\n",
      "[1604/1762] D loss: 0.0088, G loss: 7.0373\n",
      "[1684/1762] D loss: 0.0047, G loss: 7.9127\n",
      "[1762/1762] D loss: 0.0006, G loss: 9.3140\n",
      "train error: \n",
      " D loss: 0.025385, G loss: 9.909719, D accuracy: 99.6%, cell accuracy: 95.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.026874, G loss: 9.890877, D accuracy: 99.5%, cell accuracy: 95.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0007, G loss: 9.8543\n",
      "[84/1762] D loss: 0.0023, G loss: 10.7139\n",
      "[164/1762] D loss: 0.0002, G loss: 10.9487\n",
      "[244/1762] D loss: 0.0001, G loss: 13.4644\n",
      "[324/1762] D loss: 0.0001, G loss: 13.6698\n",
      "[404/1762] D loss: 0.0030, G loss: 11.5664\n",
      "[484/1762] D loss: 0.0000, G loss: 14.0607\n",
      "[564/1762] D loss: 0.0005, G loss: 9.4424\n",
      "[644/1762] D loss: 0.0015, G loss: 8.1518\n",
      "[724/1762] D loss: 0.0185, G loss: 11.5743\n",
      "[804/1762] D loss: 0.0000, G loss: 15.8701\n",
      "[884/1762] D loss: 0.0000, G loss: 14.4254\n",
      "[964/1762] D loss: 0.0000, G loss: 17.5891\n",
      "[1044/1762] D loss: 0.0000, G loss: 15.7065\n",
      "[1124/1762] D loss: 0.0000, G loss: 16.7997\n",
      "[1204/1762] D loss: 0.0194, G loss: 8.4880\n",
      "[1284/1762] D loss: 0.0040, G loss: 7.1960\n",
      "[1364/1762] D loss: 0.0003, G loss: 11.4328\n",
      "[1444/1762] D loss: 0.0002, G loss: 13.6765\n",
      "[1524/1762] D loss: 0.0007, G loss: 15.3909\n",
      "[1604/1762] D loss: 0.0017, G loss: 11.1845\n",
      "[1684/1762] D loss: 0.1422, G loss: 10.8175\n",
      "[1762/1762] D loss: 0.0004, G loss: 15.4248\n",
      "train error: \n",
      " D loss: 0.068647, G loss: 13.542937, D accuracy: 99.0%, cell accuracy: 95.8%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.082936, G loss: 13.222302, D accuracy: 98.9%, cell accuracy: 95.8%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0002, G loss: 13.1347\n",
      "[84/1762] D loss: 0.0001, G loss: 14.4091\n",
      "[164/1762] D loss: 0.0000, G loss: 15.6354\n",
      "[244/1762] D loss: 0.0000, G loss: 15.0344\n",
      "[324/1762] D loss: 0.0000, G loss: 17.1339\n",
      "[404/1762] D loss: 0.0000, G loss: 18.3884\n",
      "[484/1762] D loss: 0.0001, G loss: 15.8888\n",
      "[564/1762] D loss: 0.0217, G loss: 13.7201\n",
      "[644/1762] D loss: 0.0002, G loss: 13.6193\n",
      "[724/1762] D loss: 0.0001, G loss: 11.2508\n",
      "[804/1762] D loss: 0.0001, G loss: 13.6320\n",
      "[884/1762] D loss: 0.0002, G loss: 13.0744\n",
      "[964/1762] D loss: 0.0002, G loss: 12.4680\n",
      "[1044/1762] D loss: 0.0001, G loss: 15.2832\n",
      "[1124/1762] D loss: 0.0001, G loss: 15.9068\n",
      "[1204/1762] D loss: 0.0054, G loss: 11.7979\n",
      "[1284/1762] D loss: 0.0001, G loss: 13.0532\n",
      "[1364/1762] D loss: 0.0001, G loss: 14.3447\n",
      "[1444/1762] D loss: 0.0000, G loss: 15.5636\n",
      "[1524/1762] D loss: 0.0001, G loss: 15.5050\n",
      "[1604/1762] D loss: 0.0000, G loss: 15.0198\n",
      "[1684/1762] D loss: 0.0025, G loss: 17.7303\n",
      "[1762/1762] D loss: 0.0000, G loss: 13.5764\n",
      "train error: \n",
      " D loss: 0.195522, G loss: 14.844698, D accuracy: 98.3%, cell accuracy: 95.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.165695, G loss: 14.975157, D accuracy: 98.3%, cell accuracy: 95.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001, G loss: 17.5474\n",
      "[84/1762] D loss: 0.0001, G loss: 14.4928\n",
      "[164/1762] D loss: 0.0002, G loss: 10.6246\n",
      "[244/1762] D loss: 0.0001, G loss: 12.6297\n",
      "[324/1762] D loss: 0.0001, G loss: 13.9005\n",
      "[404/1762] D loss: 0.0000, G loss: 12.8009\n",
      "[484/1762] D loss: 0.0000, G loss: 14.2878\n",
      "[564/1762] D loss: 0.0000, G loss: 13.7685\n",
      "[644/1762] D loss: 0.0000, G loss: 14.8329\n",
      "[724/1762] D loss: 0.0002, G loss: 10.7765\n",
      "[804/1762] D loss: 0.0003, G loss: 12.6027\n",
      "[884/1762] D loss: 0.0000, G loss: 13.5298\n",
      "[964/1762] D loss: 0.0002, G loss: 13.4920\n",
      "[1044/1762] D loss: 0.0000, G loss: 15.1989\n",
      "[1124/1762] D loss: 0.0000, G loss: 15.7754\n",
      "[1204/1762] D loss: 0.0000, G loss: 17.0887\n",
      "[1284/1762] D loss: 0.0000, G loss: 17.1556\n",
      "[1364/1762] D loss: 0.0000, G loss: 18.2618\n",
      "[1444/1762] D loss: 0.0000, G loss: 21.7874\n",
      "[1524/1762] D loss: 0.0000, G loss: 19.1906\n",
      "[1604/1762] D loss: 0.0000, G loss: 19.2460\n",
      "[1684/1762] D loss: 0.0000, G loss: 20.7844\n",
      "[1762/1762] D loss: 0.0000, G loss: 23.3555\n",
      "train error: \n",
      " D loss: 0.141619, G loss: 19.400305, D accuracy: 99.0%, cell accuracy: 95.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.335247, G loss: 19.008224, D accuracy: 98.0%, cell accuracy: 95.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 21.9210\n",
      "[84/1762] D loss: 0.0000, G loss: 21.3762\n",
      "[164/1762] D loss: 0.0000, G loss: 14.2737\n",
      "[244/1762] D loss: 0.1484, G loss: 4.4016\n",
      "[324/1762] D loss: 0.0001, G loss: 14.6515\n",
      "[404/1762] D loss: 0.0000, G loss: 16.6756\n",
      "[484/1762] D loss: 0.0000, G loss: 17.0041\n",
      "[564/1762] D loss: 0.0000, G loss: 16.8885\n",
      "[644/1762] D loss: 0.0000, G loss: 17.6739\n",
      "[724/1762] D loss: 0.0000, G loss: 17.8061\n",
      "[804/1762] D loss: 0.0000, G loss: 17.9387\n",
      "[884/1762] D loss: 0.0000, G loss: 18.4250\n",
      "[964/1762] D loss: 0.0000, G loss: 19.7395\n",
      "[1044/1762] D loss: 0.0000, G loss: 18.8184\n",
      "[1124/1762] D loss: 0.0000, G loss: 20.1942\n",
      "[1204/1762] D loss: 0.0000, G loss: 19.7838\n",
      "[1284/1762] D loss: 0.0000, G loss: 18.4055\n",
      "[1364/1762] D loss: 0.0000, G loss: 19.9544\n",
      "[1444/1762] D loss: 1.2894, G loss: 14.1863\n",
      "[1524/1762] D loss: 0.0170, G loss: 10.0230\n",
      "[1604/1762] D loss: 0.0044, G loss: 10.5004\n",
      "[1684/1762] D loss: 0.2589, G loss: 10.0451\n",
      "[1762/1762] D loss: 0.0000, G loss: 13.5806\n",
      "train error: \n",
      " D loss: 0.063978, G loss: 13.107096, D accuracy: 99.1%, cell accuracy: 95.8%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.089227, G loss: 13.030726, D accuracy: 98.8%, cell accuracy: 95.8%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001, G loss: 13.3331\n",
      "[84/1762] D loss: 0.0001, G loss: 15.2096\n",
      "[164/1762] D loss: 0.0000, G loss: 15.0809\n",
      "[244/1762] D loss: 0.0000, G loss: 16.3643\n",
      "[324/1762] D loss: 0.0000, G loss: 17.9293\n",
      "[404/1762] D loss: 0.0000, G loss: 20.3159\n",
      "[484/1762] D loss: 0.0000, G loss: 17.6669\n",
      "[564/1762] D loss: 0.0000, G loss: 16.8063\n",
      "[644/1762] D loss: 0.0000, G loss: 17.0047\n",
      "[724/1762] D loss: 0.0000, G loss: 20.7288\n",
      "[804/1762] D loss: 0.0001, G loss: 18.6554\n",
      "[884/1762] D loss: 0.0000, G loss: 15.8443\n",
      "[964/1762] D loss: 0.0000, G loss: 18.1288\n",
      "[1044/1762] D loss: 0.0000, G loss: 17.5634\n",
      "[1124/1762] D loss: 0.0000, G loss: 17.0809\n",
      "[1204/1762] D loss: 0.0000, G loss: 18.1750\n",
      "[1284/1762] D loss: 0.0000, G loss: 16.8196\n",
      "[1364/1762] D loss: 0.0000, G loss: 20.5538\n",
      "[1444/1762] D loss: 0.0000, G loss: 16.6214\n",
      "[1524/1762] D loss: 0.0001, G loss: 16.0612\n",
      "[1604/1762] D loss: 0.0000, G loss: 22.7186\n",
      "[1684/1762] D loss: 0.0009, G loss: 8.9770\n",
      "[1762/1762] D loss: 0.0015, G loss: 11.2524\n",
      "train error: \n",
      " D loss: 0.021263, G loss: 10.617499, D accuracy: 99.7%, cell accuracy: 95.8%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.034710, G loss: 10.564902, D accuracy: 99.5%, cell accuracy: 95.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0007, G loss: 10.2003\n",
      "[84/1762] D loss: 0.0006, G loss: 10.0175\n",
      "[164/1762] D loss: 0.0007, G loss: 13.2297\n",
      "[244/1762] D loss: 0.0004, G loss: 13.7300\n",
      "[324/1762] D loss: 0.0003, G loss: 13.0552\n",
      "[404/1762] D loss: 0.0000, G loss: 17.3466\n",
      "[484/1762] D loss: 0.0020, G loss: 18.3880\n",
      "[564/1762] D loss: 0.0000, G loss: 18.7380\n",
      "[644/1762] D loss: 0.0001, G loss: 19.3514\n",
      "[724/1762] D loss: 0.0000, G loss: 20.4565\n",
      "[804/1762] D loss: 0.0006, G loss: 21.2796\n",
      "[884/1762] D loss: 0.0000, G loss: 21.9433\n",
      "[964/1762] D loss: 0.0000, G loss: 17.2561\n",
      "[1044/1762] D loss: 0.0000, G loss: 15.9155\n",
      "[1124/1762] D loss: 0.0000, G loss: 16.8025\n",
      "[1204/1762] D loss: 0.0000, G loss: 20.5802\n",
      "[1284/1762] D loss: 0.0000, G loss: 25.4189\n",
      "[1364/1762] D loss: 0.0000, G loss: 24.7183\n",
      "[1444/1762] D loss: 0.0000, G loss: 22.7603\n",
      "[1524/1762] D loss: 0.0002, G loss: 22.3493\n",
      "[1604/1762] D loss: 0.0000, G loss: 23.3588\n",
      "[1684/1762] D loss: 0.0000, G loss: 21.5829\n",
      "[1762/1762] D loss: 0.0000, G loss: 22.3044\n",
      "train error: \n",
      " D loss: 0.156993, G loss: 21.788469, D accuracy: 98.9%, cell accuracy: 95.8%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.226167, G loss: 21.657345, D accuracy: 98.3%, cell accuracy: 95.8%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001, G loss: 25.2139\n",
      "[84/1762] D loss: 0.0034, G loss: 24.4314\n",
      "[164/1762] D loss: 0.0000, G loss: 23.2228\n",
      "[244/1762] D loss: 0.0023, G loss: 20.3283\n",
      "[324/1762] D loss: 0.0030, G loss: 17.9783\n",
      "[404/1762] D loss: 0.0006, G loss: 9.6822\n",
      "[484/1762] D loss: 0.0188, G loss: 15.3062\n",
      "[564/1762] D loss: 0.0000, G loss: 17.6141\n",
      "[644/1762] D loss: 0.0000, G loss: 18.8435\n",
      "[724/1762] D loss: 0.0000, G loss: 22.7553\n",
      "[804/1762] D loss: 0.0000, G loss: 18.1235\n",
      "[884/1762] D loss: 0.0013, G loss: 11.3615\n",
      "[964/1762] D loss: 0.0009, G loss: 13.8995\n",
      "[1044/1762] D loss: 0.0000, G loss: 14.2744\n",
      "[1124/1762] D loss: 0.0000, G loss: 19.0684\n",
      "[1204/1762] D loss: 0.0000, G loss: 23.5007\n",
      "[1284/1762] D loss: 0.0000, G loss: 22.9188\n",
      "[1364/1762] D loss: 0.0000, G loss: 23.6309\n",
      "[1444/1762] D loss: 0.0000, G loss: 26.3097\n",
      "[1524/1762] D loss: 0.0001, G loss: 27.9628\n",
      "[1604/1762] D loss: 0.0000, G loss: 29.9988\n",
      "[1684/1762] D loss: 0.0001, G loss: 25.5965\n",
      "[1762/1762] D loss: 0.0000, G loss: 29.4054\n",
      "train error: \n",
      " D loss: 0.109402, G loss: 27.757835, D accuracy: 99.1%, cell accuracy: 95.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.172460, G loss: 27.425151, D accuracy: 98.6%, cell accuracy: 95.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 24.4301\n",
      "[84/1762] D loss: 0.0033, G loss: 29.0775\n",
      "[164/1762] D loss: 0.0000, G loss: 33.8355\n",
      "[244/1762] D loss: 0.0000, G loss: 30.8127\n",
      "[324/1762] D loss: 0.0001, G loss: 22.5567\n",
      "[404/1762] D loss: 0.0000, G loss: 19.1170\n",
      "[484/1762] D loss: 0.0000, G loss: 20.9222\n",
      "[564/1762] D loss: 0.0000, G loss: 20.5830\n",
      "[644/1762] D loss: 0.0000, G loss: 21.4459\n",
      "[724/1762] D loss: 0.0000, G loss: 23.8610\n",
      "[804/1762] D loss: 0.0000, G loss: 24.1306\n",
      "[884/1762] D loss: 0.0000, G loss: 20.6560\n",
      "[964/1762] D loss: 0.0000, G loss: 24.7531\n",
      "[1044/1762] D loss: 0.0000, G loss: 26.8678\n",
      "[1124/1762] D loss: 0.0000, G loss: 23.8371\n",
      "[1204/1762] D loss: 0.0000, G loss: 25.5651\n",
      "[1284/1762] D loss: 0.0000, G loss: 24.1296\n",
      "[1364/1762] D loss: 0.0000, G loss: 27.6186\n",
      "[1444/1762] D loss: 0.0000, G loss: 25.8550\n",
      "[1524/1762] D loss: 0.0000, G loss: 24.3226\n",
      "[1604/1762] D loss: 0.0005, G loss: 24.6640\n",
      "[1684/1762] D loss: 0.0000, G loss: 24.8647\n",
      "[1762/1762] D loss: 0.0000, G loss: 27.6061\n",
      "train error: \n",
      " D loss: 0.019711, G loss: 22.732736, D accuracy: 99.7%, cell accuracy: 95.8%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.010052, G loss: 22.987425, D accuracy: 99.8%, cell accuracy: 95.8%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 22.9963\n",
      "[84/1762] D loss: 0.0000, G loss: 22.5151\n",
      "[164/1762] D loss: 0.0000, G loss: 22.3882\n",
      "[244/1762] D loss: 0.0000, G loss: 24.0099\n",
      "[324/1762] D loss: 0.0000, G loss: 19.9549\n",
      "[404/1762] D loss: 0.0008, G loss: 17.9134\n",
      "[484/1762] D loss: 0.0000, G loss: 17.7301\n",
      "[564/1762] D loss: 0.0000, G loss: 17.2734\n",
      "[644/1762] D loss: 0.0062, G loss: 18.7442\n",
      "[724/1762] D loss: 0.0002, G loss: 17.3073\n",
      "[804/1762] D loss: 0.0000, G loss: 19.8903\n",
      "[884/1762] D loss: 0.0000, G loss: 16.3919\n",
      "[964/1762] D loss: 0.0000, G loss: 22.7150\n",
      "[1044/1762] D loss: 0.0000, G loss: 22.2796\n",
      "[1124/1762] D loss: 0.0000, G loss: 22.2249\n",
      "[1204/1762] D loss: 0.0000, G loss: 20.9479\n",
      "[1284/1762] D loss: 0.0000, G loss: 18.5899\n",
      "[1364/1762] D loss: 0.0000, G loss: 20.7103\n",
      "[1444/1762] D loss: 0.0000, G loss: 19.6466\n",
      "[1524/1762] D loss: 0.0000, G loss: 20.6939\n",
      "[1604/1762] D loss: 0.0000, G loss: 22.6504\n",
      "[1684/1762] D loss: 0.0000, G loss: 21.9810\n",
      "[1762/1762] D loss: 0.0000, G loss: 22.2224\n",
      "train error: \n",
      " D loss: 0.111922, G loss: 22.466676, D accuracy: 99.1%, cell accuracy: 95.8%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.141659, G loss: 22.133164, D accuracy: 98.6%, cell accuracy: 95.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 20.6187\n",
      "[84/1762] D loss: 0.0000, G loss: 23.9985\n",
      "[164/1762] D loss: 0.0000, G loss: 23.2774\n",
      "[244/1762] D loss: 0.0000, G loss: 20.7638\n",
      "[324/1762] D loss: 0.2472, G loss: 20.9135\n",
      "[404/1762] D loss: 0.0000, G loss: 22.2744\n",
      "[484/1762] D loss: 0.0000, G loss: 20.1351\n",
      "[564/1762] D loss: 0.0000, G loss: 21.5507\n",
      "[644/1762] D loss: 0.0000, G loss: 23.2689\n",
      "[724/1762] D loss: 0.0000, G loss: 21.1238\n",
      "[804/1762] D loss: 0.0001, G loss: 22.6680\n",
      "[884/1762] D loss: 0.0000, G loss: 21.8028\n",
      "[964/1762] D loss: 0.0000, G loss: 20.5680\n",
      "[1044/1762] D loss: 0.0000, G loss: 22.0473\n",
      "[1124/1762] D loss: 0.0000, G loss: 22.7587\n",
      "[1204/1762] D loss: 0.0000, G loss: 23.2910\n",
      "[1284/1762] D loss: 0.0000, G loss: 18.3725\n",
      "[1364/1762] D loss: 0.0000, G loss: 22.4376\n",
      "[1444/1762] D loss: 0.0000, G loss: 20.8703\n",
      "[1524/1762] D loss: 0.0000, G loss: 23.8644\n",
      "[1604/1762] D loss: 0.0000, G loss: 22.3665\n",
      "[1684/1762] D loss: 0.0000, G loss: 24.9713\n",
      "[1762/1762] D loss: 0.0000, G loss: 25.3471\n",
      "train error: \n",
      " D loss: 0.258773, G loss: 21.318070, D accuracy: 98.0%, cell accuracy: 95.6%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.390069, G loss: 21.126848, D accuracy: 97.7%, cell accuracy: 95.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001, G loss: 21.8950\n",
      "[84/1762] D loss: 0.0000, G loss: 21.2398\n",
      "[164/1762] D loss: 0.0000, G loss: 21.3676\n",
      "[244/1762] D loss: 0.0000, G loss: 23.2361\n",
      "[324/1762] D loss: 0.0000, G loss: 22.2217\n",
      "[404/1762] D loss: 0.0000, G loss: 25.7239\n",
      "[484/1762] D loss: 0.0000, G loss: 22.7089\n",
      "[564/1762] D loss: 0.0000, G loss: 24.4474\n",
      "[644/1762] D loss: 0.0000, G loss: 25.4281\n",
      "[724/1762] D loss: 0.0001, G loss: 21.7572\n",
      "[804/1762] D loss: 0.0000, G loss: 25.0091\n",
      "[884/1762] D loss: 0.0229, G loss: 24.5962\n",
      "[964/1762] D loss: 0.0000, G loss: 26.7996\n",
      "[1044/1762] D loss: 0.0000, G loss: 25.2617\n",
      "[1124/1762] D loss: 0.0000, G loss: 26.1208\n",
      "[1204/1762] D loss: 0.0000, G loss: 25.6078\n",
      "[1284/1762] D loss: 0.0000, G loss: 22.6332\n",
      "[1364/1762] D loss: 0.0001, G loss: 15.2605\n",
      "[1444/1762] D loss: 0.0001, G loss: 14.2624\n",
      "[1524/1762] D loss: 0.0003, G loss: 15.6961\n",
      "[1604/1762] D loss: 0.0001, G loss: 15.8665\n",
      "[1684/1762] D loss: 0.0000, G loss: 19.3427\n",
      "[1762/1762] D loss: 0.0001, G loss: 19.9476\n",
      "train error: \n",
      " D loss: 0.007021, G loss: 18.631330, D accuracy: 99.9%, cell accuracy: 95.8%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.041286, G loss: 18.581476, D accuracy: 99.4%, cell accuracy: 95.8%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 17.5194\n",
      "[84/1762] D loss: 0.0000, G loss: 18.8927\n",
      "[164/1762] D loss: 0.0000, G loss: 18.3616\n",
      "[244/1762] D loss: 0.0000, G loss: 21.4198\n",
      "[324/1762] D loss: 0.0000, G loss: 19.9729\n",
      "[404/1762] D loss: 0.0000, G loss: 16.6657\n",
      "[484/1762] D loss: 0.0001, G loss: 18.5443\n",
      "[564/1762] D loss: 0.0000, G loss: 17.0742\n",
      "[644/1762] D loss: 0.0000, G loss: 16.1426\n",
      "[724/1762] D loss: 0.0010, G loss: 19.3547\n",
      "[804/1762] D loss: 0.0161, G loss: 17.2276\n",
      "[884/1762] D loss: 0.0000, G loss: 16.1747\n",
      "[964/1762] D loss: 0.0001, G loss: 16.4284\n",
      "[1044/1762] D loss: 0.0000, G loss: 16.6612\n",
      "[1124/1762] D loss: 0.0007, G loss: 15.7079\n",
      "[1204/1762] D loss: 0.0002, G loss: 15.6662\n",
      "[1284/1762] D loss: 0.0004, G loss: 17.7855\n",
      "[1364/1762] D loss: 0.0002, G loss: 22.1604\n",
      "[1444/1762] D loss: 0.0001, G loss: 18.1928\n",
      "[1524/1762] D loss: 0.0000, G loss: 16.9483\n",
      "[1604/1762] D loss: 0.0000, G loss: 17.3760\n",
      "[1684/1762] D loss: 0.0000, G loss: 18.8932\n",
      "[1762/1762] D loss: 0.0000, G loss: 22.1873\n",
      "train error: \n",
      " D loss: 0.030605, G loss: 19.092329, D accuracy: 99.6%, cell accuracy: 95.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.037698, G loss: 19.251574, D accuracy: 99.5%, cell accuracy: 95.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 17.9122\n",
      "[84/1762] D loss: 0.0010, G loss: 18.3980\n",
      "[164/1762] D loss: 0.0000, G loss: 19.6878\n",
      "[244/1762] D loss: 0.0001, G loss: 21.0924\n",
      "[324/1762] D loss: 0.0000, G loss: 20.9990\n",
      "[404/1762] D loss: 0.0000, G loss: 20.4723\n",
      "[484/1762] D loss: 0.0000, G loss: 20.6200\n",
      "[564/1762] D loss: 0.0000, G loss: 21.2800\n",
      "[644/1762] D loss: 0.2719, G loss: 27.9906\n",
      "[724/1762] D loss: 0.0002, G loss: 29.7900\n",
      "[804/1762] D loss: 0.0000, G loss: 30.7166\n",
      "[884/1762] D loss: 0.0000, G loss: 32.6232\n",
      "[964/1762] D loss: 0.0000, G loss: 33.9527\n",
      "[1044/1762] D loss: 1.0138, G loss: 22.9188\n",
      "[1124/1762] D loss: 0.0000, G loss: 22.4725\n",
      "[1204/1762] D loss: 0.0000, G loss: 26.0669\n",
      "[1284/1762] D loss: 0.0000, G loss: 27.0383\n",
      "[1364/1762] D loss: 0.0000, G loss: 28.2924\n",
      "[1444/1762] D loss: 0.0000, G loss: 26.6353\n",
      "[1524/1762] D loss: 0.0001, G loss: 22.2901\n",
      "[1604/1762] D loss: 0.0000, G loss: 25.5910\n",
      "[1684/1762] D loss: 0.0000, G loss: 26.1673\n",
      "[1762/1762] D loss: 0.0000, G loss: 25.5461\n",
      "train error: \n",
      " D loss: 0.020031, G loss: 24.047943, D accuracy: 99.7%, cell accuracy: 95.8%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.054234, G loss: 24.145182, D accuracy: 99.5%, cell accuracy: 95.8%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 24.5424\n",
      "[84/1762] D loss: 0.0000, G loss: 24.5495\n",
      "[164/1762] D loss: 0.0002, G loss: 18.9440\n",
      "[244/1762] D loss: 0.0001, G loss: 22.9673\n",
      "[324/1762] D loss: 0.0001, G loss: 21.9415\n",
      "[404/1762] D loss: 0.0000, G loss: 21.2297\n",
      "[484/1762] D loss: 0.0094, G loss: 23.2012\n",
      "[564/1762] D loss: 0.0000, G loss: 21.3433\n",
      "[644/1762] D loss: 0.0005, G loss: 22.9800\n",
      "[724/1762] D loss: 0.0000, G loss: 22.8169\n",
      "[804/1762] D loss: 0.0000, G loss: 25.4664\n",
      "[884/1762] D loss: 0.0015, G loss: 24.1663\n",
      "[964/1762] D loss: 0.0000, G loss: 25.8322\n",
      "[1044/1762] D loss: 0.0000, G loss: 24.5133\n",
      "[1124/1762] D loss: 0.0000, G loss: 24.9593\n",
      "[1204/1762] D loss: 0.0002, G loss: 27.7068\n",
      "[1284/1762] D loss: 0.0000, G loss: 24.0017\n",
      "[1364/1762] D loss: 0.0002, G loss: 24.9050\n",
      "[1444/1762] D loss: 0.0000, G loss: 24.3961\n",
      "[1524/1762] D loss: 0.0000, G loss: 24.6858\n",
      "[1604/1762] D loss: 0.0000, G loss: 25.9910\n",
      "[1684/1762] D loss: 0.0000, G loss: 24.1595\n",
      "[1762/1762] D loss: 0.0000, G loss: 23.9653\n",
      "train error: \n",
      " D loss: 0.063989, G loss: 24.853380, D accuracy: 99.5%, cell accuracy: 95.8%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.029660, G loss: 25.039430, D accuracy: 99.8%, cell accuracy: 95.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 26.4286\n",
      "[84/1762] D loss: 0.0000, G loss: 26.0675\n",
      "[164/1762] D loss: 0.0000, G loss: 27.0804\n",
      "[244/1762] D loss: 0.0000, G loss: 24.3436\n",
      "[324/1762] D loss: 0.0000, G loss: 24.4307\n",
      "[404/1762] D loss: 0.0000, G loss: 26.4235\n",
      "[484/1762] D loss: 0.0000, G loss: 25.4003\n",
      "[564/1762] D loss: 0.0000, G loss: 26.3046\n",
      "[644/1762] D loss: 0.0000, G loss: 27.7991\n",
      "[724/1762] D loss: 0.0000, G loss: 27.4250\n",
      "[804/1762] D loss: 0.0000, G loss: 26.0492\n",
      "[884/1762] D loss: 0.0000, G loss: 29.0472\n",
      "[964/1762] D loss: 0.0000, G loss: 27.4986\n",
      "[1044/1762] D loss: 0.0000, G loss: 29.5297\n",
      "[1124/1762] D loss: 0.0000, G loss: 28.9063\n",
      "[1204/1762] D loss: 0.0003, G loss: 15.0990\n",
      "[1284/1762] D loss: 0.0001, G loss: 17.5013\n",
      "[1364/1762] D loss: 0.0000, G loss: 15.3403\n",
      "[1444/1762] D loss: 0.0000, G loss: 19.2227\n",
      "[1524/1762] D loss: 0.0000, G loss: 14.7433\n",
      "[1604/1762] D loss: 0.0000, G loss: 20.3098\n",
      "[1684/1762] D loss: 0.0000, G loss: 19.6529\n",
      "[1762/1762] D loss: 0.0001, G loss: 40.4327\n",
      "train error: \n",
      " D loss: 0.228595, G loss: 28.897119, D accuracy: 98.5%, cell accuracy: 95.7%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.182976, G loss: 29.763421, D accuracy: 98.9%, cell accuracy: 95.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 33.0958\n",
      "[84/1762] D loss: 0.0000, G loss: 42.9844\n",
      "[164/1762] D loss: 0.0000, G loss: 42.2716\n",
      "[244/1762] D loss: 0.0000, G loss: 33.6647\n",
      "[324/1762] D loss: 0.0000, G loss: 29.1965\n",
      "[404/1762] D loss: 0.0000, G loss: 30.8553\n",
      "[484/1762] D loss: 0.0000, G loss: 31.2132\n",
      "[564/1762] D loss: 0.0071, G loss: 24.7950\n",
      "[644/1762] D loss: 0.0032, G loss: 29.3238\n",
      "[724/1762] D loss: 0.0000, G loss: 29.9165\n",
      "[804/1762] D loss: 0.0003, G loss: 30.0619\n",
      "[884/1762] D loss: 0.0000, G loss: 28.8647\n",
      "[964/1762] D loss: 0.0000, G loss: 28.0044\n",
      "[1044/1762] D loss: 0.0000, G loss: 29.8437\n",
      "[1124/1762] D loss: 0.0000, G loss: 30.8681\n",
      "[1204/1762] D loss: 0.0000, G loss: 29.1659\n",
      "[1284/1762] D loss: 0.0007, G loss: 28.8678\n",
      "[1364/1762] D loss: 0.0000, G loss: 29.7544\n",
      "[1444/1762] D loss: 0.0000, G loss: 31.3209\n",
      "[1524/1762] D loss: 0.0000, G loss: 29.1933\n",
      "[1604/1762] D loss: 0.0000, G loss: 34.1717\n",
      "[1684/1762] D loss: 0.0000, G loss: 31.7770\n",
      "[1762/1762] D loss: 0.0000, G loss: 33.7106\n",
      "train error: \n",
      " D loss: 0.254934, G loss: 28.686108, D accuracy: 98.4%, cell accuracy: 95.7%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.238230, G loss: 28.578234, D accuracy: 98.3%, cell accuracy: 95.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 31.9837\n",
      "[84/1762] D loss: 0.0001, G loss: 31.5220\n",
      "[164/1762] D loss: 0.0002, G loss: 30.2628\n",
      "[244/1762] D loss: 0.0000, G loss: 30.6255\n",
      "[324/1762] D loss: 0.0000, G loss: 34.7717\n",
      "[404/1762] D loss: 0.0000, G loss: 32.1677\n",
      "[484/1762] D loss: 0.0000, G loss: 29.1847\n",
      "[564/1762] D loss: 0.0133, G loss: 29.1924\n",
      "[644/1762] D loss: 0.0000, G loss: 28.0723\n",
      "[724/1762] D loss: 0.0000, G loss: 29.1754\n",
      "[804/1762] D loss: 0.0000, G loss: 32.4480\n",
      "[884/1762] D loss: 0.0000, G loss: 30.9945\n",
      "[964/1762] D loss: 0.0000, G loss: 27.9270\n",
      "[1044/1762] D loss: 0.0000, G loss: 28.4920\n",
      "[1124/1762] D loss: 0.0001, G loss: 24.9233\n",
      "[1204/1762] D loss: 0.0000, G loss: 25.5670\n",
      "[1284/1762] D loss: 0.0000, G loss: 24.0931\n",
      "[1364/1762] D loss: 0.0000, G loss: 20.6198\n",
      "[1444/1762] D loss: 0.0000, G loss: 22.9733\n",
      "[1524/1762] D loss: 0.0000, G loss: 23.8971\n",
      "[1604/1762] D loss: 0.0001, G loss: 21.8819\n",
      "[1684/1762] D loss: 0.0000, G loss: 22.2085\n",
      "[1762/1762] D loss: 0.0000, G loss: 22.7129\n",
      "train error: \n",
      " D loss: 0.106412, G loss: 22.877823, D accuracy: 99.0%, cell accuracy: 95.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.095607, G loss: 23.326582, D accuracy: 99.2%, cell accuracy: 95.7%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 21.8630\n",
      "[84/1762] D loss: 0.0000, G loss: 24.6089\n",
      "[164/1762] D loss: 0.0000, G loss: 25.3606\n",
      "[244/1762] D loss: 0.0000, G loss: 24.8260\n",
      "[324/1762] D loss: 0.0000, G loss: 24.7709\n",
      "[404/1762] D loss: 0.0000, G loss: 24.1397\n",
      "[484/1762] D loss: 0.0000, G loss: 22.6698\n",
      "[564/1762] D loss: 0.0000, G loss: 26.0368\n",
      "[644/1762] D loss: 0.0000, G loss: 23.2046\n",
      "[724/1762] D loss: 0.0000, G loss: 22.1770\n",
      "[804/1762] D loss: 0.0000, G loss: 22.5285\n",
      "[884/1762] D loss: 0.0000, G loss: 24.0222\n",
      "[964/1762] D loss: 0.0000, G loss: 22.5191\n",
      "[1044/1762] D loss: 0.0000, G loss: 22.9087\n",
      "[1124/1762] D loss: 0.0000, G loss: 27.2490\n",
      "[1204/1762] D loss: 0.0000, G loss: 23.5861\n",
      "[1284/1762] D loss: 0.0000, G loss: 24.8259\n",
      "[1364/1762] D loss: 0.0000, G loss: 23.8038\n",
      "[1444/1762] D loss: 0.0000, G loss: 23.6008\n",
      "[1524/1762] D loss: 0.0000, G loss: 24.8775\n",
      "[1604/1762] D loss: 0.0000, G loss: 24.6502\n",
      "[1684/1762] D loss: 0.0000, G loss: 22.8013\n",
      "[1762/1762] D loss: 0.0000, G loss: 22.6718\n",
      "train error: \n",
      " D loss: 0.107041, G loss: 23.837553, D accuracy: 99.1%, cell accuracy: 95.7%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.086171, G loss: 23.844107, D accuracy: 99.2%, cell accuracy: 95.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 25.9806\n",
      "[84/1762] D loss: 0.0125, G loss: 14.4692\n",
      "[164/1762] D loss: 0.0163, G loss: 16.7389\n",
      "[244/1762] D loss: 0.0000, G loss: 19.2506\n",
      "[324/1762] D loss: 0.0000, G loss: 25.7626\n",
      "[404/1762] D loss: 0.0000, G loss: 24.9965\n",
      "[484/1762] D loss: 0.0012, G loss: 19.1192\n",
      "[564/1762] D loss: 0.0000, G loss: 16.8054\n",
      "[644/1762] D loss: 0.0002, G loss: 17.4077\n",
      "[724/1762] D loss: 0.0000, G loss: 17.9898\n",
      "[804/1762] D loss: 0.0001, G loss: 16.0010\n",
      "[884/1762] D loss: 0.0027, G loss: 15.1035\n",
      "[964/1762] D loss: 0.0000, G loss: 14.8563\n",
      "[1044/1762] D loss: 0.0000, G loss: 16.8002\n",
      "[1124/1762] D loss: 0.0000, G loss: 17.3980\n",
      "[1204/1762] D loss: 0.0000, G loss: 17.4026\n",
      "[1284/1762] D loss: 0.0001, G loss: 15.9042\n",
      "[1364/1762] D loss: 0.0033, G loss: 12.0005\n",
      "[1444/1762] D loss: 0.0023, G loss: 12.5127\n",
      "[1524/1762] D loss: 0.0002, G loss: 12.5057\n",
      "[1604/1762] D loss: 0.0020, G loss: 12.8017\n",
      "[1684/1762] D loss: 0.0000, G loss: 13.6408\n",
      "[1762/1762] D loss: 0.0009, G loss: 14.3443\n",
      "train error: \n",
      " D loss: 0.105410, G loss: 13.668929, D accuracy: 98.7%, cell accuracy: 95.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.120436, G loss: 13.823310, D accuracy: 98.8%, cell accuracy: 95.6%, board accuracy: 0.0% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4085, G loss: 0.6565\n",
      "[84/1762] D loss: 1.2136, G loss: 0.6994\n",
      "[164/1762] D loss: 1.0133, G loss: 0.8054\n",
      "[244/1762] D loss: 0.8960, G loss: 0.9987\n",
      "[324/1762] D loss: 0.2441, G loss: 2.0397\n",
      "[404/1762] D loss: 0.2756, G loss: 2.5846\n",
      "[484/1762] D loss: 0.1504, G loss: 3.1353\n",
      "[564/1762] D loss: 0.1017, G loss: 3.5469\n",
      "[644/1762] D loss: 1.0834, G loss: 2.8024\n",
      "[724/1762] D loss: 0.4737, G loss: 3.1322\n",
      "[804/1762] D loss: 0.2412, G loss: 4.5380\n",
      "[884/1762] D loss: 1.2864, G loss: 2.1662\n",
      "[964/1762] D loss: 0.4261, G loss: 2.4135\n",
      "[1044/1762] D loss: 0.4756, G loss: 1.2415\n",
      "[1124/1762] D loss: 0.7502, G loss: 1.4141\n",
      "[1204/1762] D loss: 0.4634, G loss: 1.9651\n",
      "[1284/1762] D loss: 0.9273, G loss: 1.2845\n",
      "[1364/1762] D loss: 0.9209, G loss: 1.1042\n",
      "[1444/1762] D loss: 1.6662, G loss: 0.6438\n",
      "[1524/1762] D loss: 1.0359, G loss: 1.4384\n",
      "[1604/1762] D loss: 1.3600, G loss: 0.8631\n",
      "[1684/1762] D loss: 1.3086, G loss: 0.9771\n",
      "[1762/1762] D loss: 1.7528, G loss: 1.4884\n",
      "train error: \n",
      " D loss: 1.603156, G loss: 1.461985, D accuracy: 54.6%, cell accuracy: 99.6%, board accuracy: 69.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.596842, G loss: 1.462367, D accuracy: 55.2%, cell accuracy: 99.5%, board accuracy: 67.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1254, G loss: 1.0364\n",
      "[84/1762] D loss: 1.3732, G loss: 0.7577\n",
      "[164/1762] D loss: 1.4628, G loss: 1.0129\n",
      "[244/1762] D loss: 1.2108, G loss: 0.7723\n",
      "[324/1762] D loss: 1.1487, G loss: 0.7000\n",
      "[404/1762] D loss: 1.4195, G loss: 0.9390\n",
      "[484/1762] D loss: 1.5003, G loss: 0.8519\n",
      "[564/1762] D loss: 1.4377, G loss: 0.8222\n",
      "[644/1762] D loss: 1.2643, G loss: 0.8870\n",
      "[724/1762] D loss: 1.4466, G loss: 0.7433\n",
      "[804/1762] D loss: 0.8973, G loss: 1.0626\n",
      "[884/1762] D loss: 1.0016, G loss: 0.9526\n",
      "[964/1762] D loss: 0.9151, G loss: 0.8613\n",
      "[1044/1762] D loss: 1.4659, G loss: 0.6621\n",
      "[1124/1762] D loss: 1.4169, G loss: 0.9430\n",
      "[1204/1762] D loss: 1.4628, G loss: 0.5742\n",
      "[1284/1762] D loss: 1.4030, G loss: 0.5794\n",
      "[1364/1762] D loss: 1.3543, G loss: 0.9772\n",
      "[1444/1762] D loss: 1.5404, G loss: 0.9854\n",
      "[1524/1762] D loss: 1.4001, G loss: 0.7021\n",
      "[1604/1762] D loss: 1.4583, G loss: 0.9460\n",
      "[1684/1762] D loss: 1.3814, G loss: 0.8763\n",
      "[1762/1762] D loss: 1.2988, G loss: 0.7831\n",
      "train error: \n",
      " D loss: 1.339333, G loss: 0.810085, D accuracy: 54.3%, cell accuracy: 99.7%, board accuracy: 78.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.323648, G loss: 0.841039, D accuracy: 57.3%, cell accuracy: 99.7%, board accuracy: 77.5% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3753, G loss: 0.5964\n",
      "[84/1762] D loss: 1.3680, G loss: 0.6850\n",
      "[164/1762] D loss: 1.4178, G loss: 0.7403\n",
      "[244/1762] D loss: 1.5107, G loss: 1.0348\n",
      "[324/1762] D loss: 1.4278, G loss: 0.8023\n",
      "[404/1762] D loss: 1.4910, G loss: 0.9150\n",
      "[484/1762] D loss: 1.0610, G loss: 1.9921\n",
      "[564/1762] D loss: 0.2408, G loss: 3.2918\n",
      "[644/1762] D loss: 1.2345, G loss: 0.5807\n",
      "[724/1762] D loss: 1.3777, G loss: 0.8268\n",
      "[804/1762] D loss: 0.9672, G loss: 0.8360\n",
      "[884/1762] D loss: 1.0045, G loss: 0.7338\n",
      "[964/1762] D loss: 0.9145, G loss: 1.2193\n",
      "[1044/1762] D loss: 1.2212, G loss: 1.5236\n",
      "[1124/1762] D loss: 1.5172, G loss: 0.4783\n",
      "[1204/1762] D loss: 1.4177, G loss: 0.8411\n",
      "[1284/1762] D loss: 1.4244, G loss: 1.0276\n",
      "[1364/1762] D loss: 1.3652, G loss: 0.9887\n",
      "[1444/1762] D loss: 1.4264, G loss: 0.8706\n",
      "[1524/1762] D loss: 1.3173, G loss: 0.5971\n",
      "[1604/1762] D loss: 1.4846, G loss: 0.4942\n",
      "[1684/1762] D loss: 1.4135, G loss: 0.5975\n",
      "[1762/1762] D loss: 1.4456, G loss: 0.7846\n",
      "train error: \n",
      " D loss: 1.337542, G loss: 0.773456, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 88.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.316701, G loss: 0.785544, D accuracy: 56.6%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3062, G loss: 0.7323\n",
      "[84/1762] D loss: 1.3581, G loss: 0.8041\n",
      "[164/1762] D loss: 1.5480, G loss: 1.1792\n",
      "[244/1762] D loss: 0.6572, G loss: 1.1372\n",
      "[324/1762] D loss: 1.3176, G loss: 0.8268\n",
      "[404/1762] D loss: 0.7389, G loss: 1.3533\n",
      "[484/1762] D loss: 1.3826, G loss: 0.7448\n",
      "[564/1762] D loss: 1.4860, G loss: 0.7042\n",
      "[644/1762] D loss: 0.7344, G loss: 1.0252\n",
      "[724/1762] D loss: 1.2097, G loss: 0.8082\n",
      "[804/1762] D loss: 1.1900, G loss: 0.7577\n",
      "[884/1762] D loss: 1.9490, G loss: 0.9333\n",
      "[964/1762] D loss: 1.4014, G loss: 0.7022\n",
      "[1044/1762] D loss: 0.9404, G loss: 1.3802\n",
      "[1124/1762] D loss: 1.4749, G loss: 0.7834\n",
      "[1204/1762] D loss: 0.4923, G loss: 1.5178\n",
      "[1284/1762] D loss: 1.5364, G loss: 0.4299\n",
      "[1364/1762] D loss: 1.3602, G loss: 0.8424\n",
      "[1444/1762] D loss: 1.3896, G loss: 0.8153\n",
      "[1524/1762] D loss: 1.4162, G loss: 0.8103\n",
      "[1604/1762] D loss: 1.3685, G loss: 0.5969\n",
      "[1684/1762] D loss: 1.4055, G loss: 0.7630\n",
      "[1762/1762] D loss: 0.3516, G loss: 1.4221\n",
      "train error: \n",
      " D loss: 1.325888, G loss: 0.681594, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.305736, G loss: 0.706144, D accuracy: 55.7%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3838, G loss: 0.7196\n",
      "[84/1762] D loss: 0.5529, G loss: 1.3278\n",
      "[164/1762] D loss: 1.3600, G loss: 0.6030\n",
      "[244/1762] D loss: 0.2586, G loss: 1.7075\n",
      "[324/1762] D loss: 1.5065, G loss: 0.9770\n",
      "[404/1762] D loss: 1.4761, G loss: 0.9182\n",
      "[484/1762] D loss: 1.4390, G loss: 0.7284\n",
      "[564/1762] D loss: 1.2243, G loss: 1.0383\n",
      "[644/1762] D loss: 1.4763, G loss: 0.4730\n",
      "[724/1762] D loss: 1.0039, G loss: 1.0312\n",
      "[804/1762] D loss: 1.4233, G loss: 0.7495\n",
      "[884/1762] D loss: 1.3221, G loss: 0.9772\n",
      "[964/1762] D loss: 1.2307, G loss: 0.8987\n",
      "[1044/1762] D loss: 0.7315, G loss: 0.8473\n",
      "[1124/1762] D loss: 1.4075, G loss: 0.6478\n",
      "[1204/1762] D loss: 1.3999, G loss: 0.7701\n",
      "[1284/1762] D loss: 1.3881, G loss: 0.8089\n",
      "[1364/1762] D loss: 1.4019, G loss: 0.7000\n",
      "[1444/1762] D loss: 1.4277, G loss: 0.7345\n",
      "[1524/1762] D loss: 1.4005, G loss: 0.9006\n",
      "[1604/1762] D loss: 1.6047, G loss: 1.1440\n",
      "[1684/1762] D loss: 1.1874, G loss: 0.9936\n",
      "[1762/1762] D loss: 1.5429, G loss: 1.0648\n",
      "train error: \n",
      " D loss: 1.319742, G loss: 0.906702, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 84.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.298920, G loss: 0.924955, D accuracy: 55.6%, cell accuracy: 99.7%, board accuracy: 82.3% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4065, G loss: 0.7466\n",
      "[84/1762] D loss: 1.3865, G loss: 0.6842\n",
      "[164/1762] D loss: 1.3872, G loss: 0.6716\n",
      "[244/1762] D loss: 1.3902, G loss: 0.7060\n",
      "[324/1762] D loss: 1.3847, G loss: 0.6756\n",
      "[404/1762] D loss: 1.3870, G loss: 0.6891\n",
      "[484/1762] D loss: 1.3884, G loss: 0.7064\n",
      "[564/1762] D loss: 1.3388, G loss: 0.7353\n",
      "[644/1762] D loss: 1.3825, G loss: 0.6847\n",
      "[724/1762] D loss: 1.3873, G loss: 0.7156\n",
      "[804/1762] D loss: 1.3903, G loss: 0.6976\n",
      "[884/1762] D loss: 1.3875, G loss: 0.6626\n",
      "[964/1762] D loss: 1.3919, G loss: 0.6985\n",
      "[1044/1762] D loss: 1.4196, G loss: 0.7993\n",
      "[1124/1762] D loss: 1.0808, G loss: 0.8063\n",
      "[1204/1762] D loss: 1.0151, G loss: 0.7766\n",
      "[1284/1762] D loss: 0.9722, G loss: 0.8151\n",
      "[1364/1762] D loss: 1.3987, G loss: 0.7159\n",
      "[1444/1762] D loss: 0.9097, G loss: 0.9090\n",
      "[1524/1762] D loss: 1.4323, G loss: 0.7762\n",
      "[1604/1762] D loss: 1.4260, G loss: 0.8389\n",
      "[1684/1762] D loss: 1.4301, G loss: 0.9326\n",
      "[1762/1762] D loss: 0.5151, G loss: 1.0513\n",
      "train error: \n",
      " D loss: 1.341857, G loss: 0.695071, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 85.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.327073, G loss: 0.702391, D accuracy: 54.4%, cell accuracy: 99.7%, board accuracy: 83.9% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7696, G loss: 0.9470\n",
      "[84/1762] D loss: 1.4163, G loss: 0.8095\n",
      "[164/1762] D loss: 1.4635, G loss: 0.9668\n",
      "[244/1762] D loss: 1.4235, G loss: 0.9598\n",
      "[324/1762] D loss: 1.4042, G loss: 0.6894\n",
      "[404/1762] D loss: 0.6191, G loss: 0.9045\n",
      "[484/1762] D loss: 1.3959, G loss: 0.6288\n",
      "[564/1762] D loss: 1.4464, G loss: 0.9564\n",
      "[644/1762] D loss: 0.5407, G loss: 0.9628\n",
      "[724/1762] D loss: 1.5204, G loss: 0.9913\n",
      "[804/1762] D loss: 0.6871, G loss: 0.8345\n",
      "[884/1762] D loss: 1.4271, G loss: 0.9100\n",
      "[964/1762] D loss: 1.3954, G loss: 0.7547\n",
      "[1044/1762] D loss: 1.3936, G loss: 0.6878\n",
      "[1124/1762] D loss: 1.4023, G loss: 0.8077\n",
      "[1204/1762] D loss: 1.3952, G loss: 0.6893\n",
      "[1284/1762] D loss: 0.5107, G loss: 1.0103\n",
      "[1364/1762] D loss: 1.4344, G loss: 0.9315\n",
      "[1444/1762] D loss: 1.4509, G loss: 0.8156\n",
      "[1524/1762] D loss: 1.4192, G loss: 0.7955\n",
      "[1604/1762] D loss: 1.3912, G loss: 0.7309\n",
      "[1684/1762] D loss: 1.4848, G loss: 1.0261\n",
      "[1762/1762] D loss: 1.3986, G loss: 0.7659\n",
      "train error: \n",
      " D loss: 1.340007, G loss: 0.639680, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.330446, G loss: 0.640372, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 85.9% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5881, G loss: 0.8856\n",
      "[84/1762] D loss: 1.3939, G loss: 0.7786\n",
      "[164/1762] D loss: 1.4073, G loss: 0.7948\n",
      "[244/1762] D loss: 1.4760, G loss: 0.9312\n",
      "[324/1762] D loss: 0.5849, G loss: 0.8757\n",
      "[404/1762] D loss: 0.5375, G loss: 0.9461\n",
      "[484/1762] D loss: 1.3937, G loss: 0.7481\n",
      "[564/1762] D loss: 1.4029, G loss: 0.8065\n",
      "[644/1762] D loss: 0.5575, G loss: 0.9290\n",
      "[724/1762] D loss: 1.4213, G loss: 0.7673\n",
      "[804/1762] D loss: 0.4625, G loss: 1.0406\n",
      "[884/1762] D loss: 0.3965, G loss: 1.1621\n",
      "[964/1762] D loss: 1.4030, G loss: 0.5872\n",
      "[1044/1762] D loss: 1.4672, G loss: 0.9660\n",
      "[1124/1762] D loss: 1.4435, G loss: 0.8910\n",
      "[1204/1762] D loss: 0.5943, G loss: 0.9297\n",
      "[1284/1762] D loss: 1.4091, G loss: 0.6409\n",
      "[1364/1762] D loss: 1.4217, G loss: 0.8816\n",
      "[1444/1762] D loss: 0.6406, G loss: 0.8198\n",
      "[1524/1762] D loss: 1.4489, G loss: 0.9458\n",
      "[1604/1762] D loss: 1.3901, G loss: 0.7469\n",
      "[1684/1762] D loss: 1.3929, G loss: 0.7707\n",
      "[1762/1762] D loss: 1.4042, G loss: 0.8581\n",
      "train error: \n",
      " D loss: 1.327527, G loss: 0.736097, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.309692, G loss: 0.746355, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2367, G loss: 0.9338\n",
      "[84/1762] D loss: 0.4941, G loss: 1.0040\n",
      "[164/1762] D loss: 1.4210, G loss: 0.8965\n",
      "[244/1762] D loss: 1.4268, G loss: 0.9080\n",
      "[324/1762] D loss: 1.3983, G loss: 0.8301\n",
      "[404/1762] D loss: 1.4412, G loss: 0.9105\n",
      "[484/1762] D loss: 1.4029, G loss: 0.7427\n",
      "[564/1762] D loss: 1.3993, G loss: 0.7854\n",
      "[644/1762] D loss: 0.3897, G loss: 1.2326\n",
      "[724/1762] D loss: 1.3982, G loss: 0.7501\n",
      "[804/1762] D loss: 1.3967, G loss: 0.9090\n",
      "[884/1762] D loss: 1.4317, G loss: 0.9099\n",
      "[964/1762] D loss: 0.4393, G loss: 1.0862\n",
      "[1044/1762] D loss: 1.4140, G loss: 0.8345\n",
      "[1124/1762] D loss: 1.3127, G loss: 0.7776\n",
      "[1204/1762] D loss: 1.3896, G loss: 0.6979\n",
      "[1284/1762] D loss: 1.4353, G loss: 0.9972\n",
      "[1364/1762] D loss: 1.4408, G loss: 0.9951\n",
      "[1444/1762] D loss: 1.3947, G loss: 0.7353\n",
      "[1524/1762] D loss: 0.3418, G loss: 1.4194\n",
      "[1604/1762] D loss: 1.4114, G loss: 0.8243\n",
      "[1684/1762] D loss: 1.4339, G loss: 0.9427\n",
      "[1762/1762] D loss: 1.4084, G loss: 0.8611\n",
      "train error: \n",
      " D loss: 1.308015, G loss: 0.787048, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 85.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.286850, G loss: 0.819291, D accuracy: 55.8%, cell accuracy: 99.7%, board accuracy: 83.6% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4147, G loss: 0.8919\n",
      "[84/1762] D loss: 0.3893, G loss: 1.2704\n",
      "[164/1762] D loss: 0.5142, G loss: 0.9846\n",
      "[244/1762] D loss: 0.5335, G loss: 0.9693\n",
      "[324/1762] D loss: 1.4043, G loss: 0.7090\n",
      "[404/1762] D loss: 0.5562, G loss: 0.9698\n",
      "[484/1762] D loss: 1.4317, G loss: 0.5672\n",
      "[564/1762] D loss: 0.4143, G loss: 1.2696\n",
      "[644/1762] D loss: 1.3275, G loss: 0.5933\n",
      "[724/1762] D loss: 0.5129, G loss: 1.0101\n",
      "[804/1762] D loss: 1.4110, G loss: 0.8805\n",
      "[884/1762] D loss: 1.3963, G loss: 0.7791\n",
      "[964/1762] D loss: 1.4125, G loss: 0.8280\n",
      "[1044/1762] D loss: 0.5198, G loss: 1.0587\n",
      "[1124/1762] D loss: 1.3567, G loss: 1.2246\n",
      "[1204/1762] D loss: 1.3961, G loss: 0.7648\n",
      "[1284/1762] D loss: 1.4059, G loss: 0.8276\n",
      "[1364/1762] D loss: 1.3358, G loss: 0.9104\n",
      "[1444/1762] D loss: 1.4234, G loss: 0.8981\n",
      "[1524/1762] D loss: 1.4201, G loss: 0.8574\n",
      "[1604/1762] D loss: 0.3823, G loss: 1.5119\n",
      "[1684/1762] D loss: 1.3949, G loss: 0.6676\n",
      "[1762/1762] D loss: 1.4141, G loss: 0.8122\n",
      "train error: \n",
      " D loss: 1.656738, G loss: 0.445454, D accuracy: 55.0%, cell accuracy: 99.7%, board accuracy: 84.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.612756, G loss: 0.464611, D accuracy: 55.8%, cell accuracy: 99.7%, board accuracy: 81.8% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3837, G loss: 0.6839\n",
      "[84/1762] D loss: 1.4457, G loss: 0.9598\n",
      "[164/1762] D loss: 1.4024, G loss: 0.8086\n",
      "[244/1762] D loss: 1.3759, G loss: 0.7388\n",
      "[324/1762] D loss: 1.4116, G loss: 0.7658\n",
      "[404/1762] D loss: 1.3648, G loss: 0.6939\n",
      "[484/1762] D loss: 1.3892, G loss: 0.7206\n",
      "[564/1762] D loss: 1.4058, G loss: 0.6065\n",
      "[644/1762] D loss: 1.4098, G loss: 0.8411\n",
      "[724/1762] D loss: 1.3748, G loss: 1.0891\n",
      "[804/1762] D loss: 1.4010, G loss: 0.7991\n",
      "[884/1762] D loss: 1.3947, G loss: 0.7507\n",
      "[964/1762] D loss: 1.4267, G loss: 0.9150\n",
      "[1044/1762] D loss: 1.4431, G loss: 0.9434\n",
      "[1124/1762] D loss: 1.6344, G loss: 1.1316\n",
      "[1204/1762] D loss: 1.2580, G loss: 1.2372\n",
      "[1284/1762] D loss: 0.3261, G loss: 1.6471\n",
      "[1364/1762] D loss: 1.4201, G loss: 0.6913\n",
      "[1444/1762] D loss: 1.0676, G loss: 1.3460\n",
      "[1524/1762] D loss: 1.1308, G loss: 1.2558\n",
      "[1604/1762] D loss: 1.5131, G loss: 0.9597\n",
      "[1684/1762] D loss: 0.3554, G loss: 1.3747\n",
      "[1762/1762] D loss: 1.5335, G loss: 1.1071\n",
      "train error: \n",
      " D loss: 1.300718, G loss: 1.083710, D accuracy: 55.7%, cell accuracy: 99.7%, board accuracy: 84.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.295307, G loss: 1.114926, D accuracy: 55.3%, cell accuracy: 99.7%, board accuracy: 83.9% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3191, G loss: 1.5962\n",
      "[84/1762] D loss: 1.3837, G loss: 0.6975\n",
      "[164/1762] D loss: 1.4094, G loss: 0.7842\n",
      "[244/1762] D loss: 0.2939, G loss: 1.6811\n",
      "[324/1762] D loss: 1.3843, G loss: 0.7260\n",
      "[404/1762] D loss: 1.4711, G loss: 0.8847\n",
      "[484/1762] D loss: 0.2886, G loss: 1.8801\n",
      "[564/1762] D loss: 1.3749, G loss: 0.7894\n",
      "[644/1762] D loss: 1.3374, G loss: 1.0295\n",
      "[724/1762] D loss: 1.3990, G loss: 0.7119\n",
      "[804/1762] D loss: 1.3651, G loss: 0.6611\n",
      "[884/1762] D loss: 1.3983, G loss: 0.7856\n",
      "[964/1762] D loss: 0.3720, G loss: 1.3569\n",
      "[1044/1762] D loss: 1.4961, G loss: 0.9986\n",
      "[1124/1762] D loss: 1.4166, G loss: 0.6905\n",
      "[1204/1762] D loss: 1.3339, G loss: 0.9277\n",
      "[1284/1762] D loss: 0.3682, G loss: 1.3231\n",
      "[1364/1762] D loss: 1.3993, G loss: 0.6140\n",
      "[1444/1762] D loss: 1.4600, G loss: 0.9849\n",
      "[1524/1762] D loss: 0.4861, G loss: 1.1363\n",
      "[1604/1762] D loss: 1.4264, G loss: 0.8080\n",
      "[1684/1762] D loss: 0.6222, G loss: 2.1461\n",
      "[1762/1762] D loss: 1.4738, G loss: 1.1294\n",
      "train error: \n",
      " D loss: 2.615161, G loss: 2.671928, D accuracy: 53.4%, cell accuracy: 99.7%, board accuracy: 85.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.551088, G loss: 2.628800, D accuracy: 54.4%, cell accuracy: 99.7%, board accuracy: 83.6% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1928, G loss: 1.4643\n",
      "[84/1762] D loss: 1.4284, G loss: 0.8585\n",
      "[164/1762] D loss: 1.4106, G loss: 0.7896\n",
      "[244/1762] D loss: 1.2547, G loss: 0.8921\n",
      "[324/1762] D loss: 0.3330, G loss: 1.7054\n",
      "[404/1762] D loss: 1.3533, G loss: 0.8749\n",
      "[484/1762] D loss: 1.3573, G loss: 0.6662\n",
      "[564/1762] D loss: 0.2608, G loss: 1.9448\n",
      "[644/1762] D loss: 0.3795, G loss: 1.3871\n",
      "[724/1762] D loss: 0.3263, G loss: 1.5055\n",
      "[804/1762] D loss: 1.3593, G loss: 0.7970\n",
      "[884/1762] D loss: 1.3511, G loss: 0.7367\n",
      "[964/1762] D loss: 1.3784, G loss: 0.7720\n",
      "[1044/1762] D loss: 0.2980, G loss: 1.7887\n",
      "[1124/1762] D loss: 0.2967, G loss: 1.9361\n",
      "[1204/1762] D loss: 1.3542, G loss: 0.6456\n",
      "[1284/1762] D loss: 0.2989, G loss: 2.0232\n",
      "[1364/1762] D loss: 1.2089, G loss: 1.1089\n",
      "[1444/1762] D loss: 1.3888, G loss: 0.6826\n",
      "[1524/1762] D loss: 1.3783, G loss: 0.7564\n",
      "[1604/1762] D loss: 1.3853, G loss: 0.6790\n",
      "[1684/1762] D loss: 1.3257, G loss: 0.7780\n",
      "[1762/1762] D loss: 1.4922, G loss: 0.4611\n",
      "train error: \n",
      " D loss: 1.312580, G loss: 0.969034, D accuracy: 55.4%, cell accuracy: 99.8%, board accuracy: 86.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.283645, G loss: 1.034026, D accuracy: 56.1%, cell accuracy: 99.7%, board accuracy: 85.2% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4369, G loss: 0.8297\n",
      "[84/1762] D loss: 1.4683, G loss: 0.8360\n",
      "[164/1762] D loss: 1.4171, G loss: 0.8523\n",
      "[244/1762] D loss: 1.4824, G loss: 0.4358\n",
      "[324/1762] D loss: 1.4013, G loss: 0.8348\n",
      "[404/1762] D loss: 0.2014, G loss: 2.4297\n",
      "[484/1762] D loss: 1.2912, G loss: 0.9079\n",
      "[564/1762] D loss: 1.3892, G loss: 0.7063\n",
      "[644/1762] D loss: 1.4351, G loss: 0.8579\n",
      "[724/1762] D loss: 1.3603, G loss: 0.8903\n",
      "[804/1762] D loss: 0.9273, G loss: 1.2166\n",
      "[884/1762] D loss: 1.3315, G loss: 0.7130\n",
      "[964/1762] D loss: 0.2506, G loss: 2.0530\n",
      "[1044/1762] D loss: 1.4483, G loss: 0.7127\n",
      "[1124/1762] D loss: 1.0260, G loss: 1.6702\n",
      "[1204/1762] D loss: 1.3888, G loss: 0.6591\n",
      "[1284/1762] D loss: 0.0463, G loss: 3.7032\n",
      "[1364/1762] D loss: 0.1971, G loss: 2.0307\n",
      "[1444/1762] D loss: 1.4197, G loss: 0.8501\n",
      "[1524/1762] D loss: 1.4242, G loss: 0.6684\n",
      "[1604/1762] D loss: 0.1759, G loss: 2.7319\n",
      "[1684/1762] D loss: 0.2333, G loss: 2.3335\n",
      "[1762/1762] D loss: 1.4077, G loss: 0.7629\n",
      "train error: \n",
      " D loss: 1.289537, G loss: 0.968103, D accuracy: 56.1%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.269697, G loss: 1.017929, D accuracy: 55.9%, cell accuracy: 99.7%, board accuracy: 85.0% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4802, G loss: 0.6948\n",
      "[84/1762] D loss: 0.3963, G loss: 1.4648\n",
      "[164/1762] D loss: 1.3749, G loss: 0.7413\n",
      "[244/1762] D loss: 1.4337, G loss: 0.5309\n",
      "[324/1762] D loss: 0.3355, G loss: 1.8025\n",
      "[404/1762] D loss: 1.4048, G loss: 0.6546\n",
      "[484/1762] D loss: 0.2790, G loss: 2.3646\n",
      "[564/1762] D loss: 0.1864, G loss: 2.7041\n",
      "[644/1762] D loss: 0.9741, G loss: 3.0238\n",
      "[724/1762] D loss: 1.3030, G loss: 0.8427\n",
      "[804/1762] D loss: 1.0854, G loss: 0.8459\n",
      "[884/1762] D loss: 1.3772, G loss: 0.9045\n",
      "[964/1762] D loss: 1.5169, G loss: 0.8963\n",
      "[1044/1762] D loss: 1.2755, G loss: 0.7306\n",
      "[1124/1762] D loss: 1.3677, G loss: 0.6840\n",
      "[1204/1762] D loss: 1.4002, G loss: 0.6158\n",
      "[1284/1762] D loss: 0.2351, G loss: 1.8063\n",
      "[1364/1762] D loss: 1.4320, G loss: 0.6254\n",
      "[1444/1762] D loss: 1.3843, G loss: 0.6457\n",
      "[1524/1762] D loss: 1.4130, G loss: 0.7150\n",
      "[1604/1762] D loss: 0.2181, G loss: 2.3281\n",
      "[1684/1762] D loss: 0.1619, G loss: 2.5688\n",
      "[1762/1762] D loss: 1.3752, G loss: 0.8836\n",
      "train error: \n",
      " D loss: 1.429224, G loss: 0.686784, D accuracy: 55.8%, cell accuracy: 99.8%, board accuracy: 87.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.445830, G loss: 0.678566, D accuracy: 55.6%, cell accuracy: 99.8%, board accuracy: 85.9% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4431, G loss: 1.4205\n",
      "[84/1762] D loss: 0.1598, G loss: 2.7092\n",
      "[164/1762] D loss: 1.3845, G loss: 0.7525\n",
      "[244/1762] D loss: 1.3955, G loss: 0.4990\n",
      "[324/1762] D loss: 1.4776, G loss: 0.4323\n",
      "[404/1762] D loss: 0.7496, G loss: 3.6550\n",
      "[484/1762] D loss: 0.4216, G loss: 1.3366\n",
      "[564/1762] D loss: 1.4664, G loss: 0.7551\n",
      "[644/1762] D loss: 1.4097, G loss: 0.6798\n",
      "[724/1762] D loss: 0.2697, G loss: 1.9736\n",
      "[804/1762] D loss: 0.1242, G loss: 2.7397\n",
      "[884/1762] D loss: 1.4469, G loss: 0.5516\n",
      "[964/1762] D loss: 1.4031, G loss: 0.9999\n",
      "[1044/1762] D loss: 1.6105, G loss: 1.1625\n",
      "[1124/1762] D loss: 0.0703, G loss: 3.6692\n",
      "[1204/1762] D loss: 0.1876, G loss: 2.6345\n",
      "[1284/1762] D loss: 0.1056, G loss: 3.1301\n",
      "[1364/1762] D loss: 0.7004, G loss: 1.9781\n",
      "[1444/1762] D loss: 0.1921, G loss: 2.7681\n",
      "[1524/1762] D loss: 1.3988, G loss: 0.5449\n",
      "[1604/1762] D loss: 1.1773, G loss: 0.6779\n",
      "[1684/1762] D loss: 0.9060, G loss: 2.0195\n",
      "[1762/1762] D loss: 1.5714, G loss: 0.9729\n",
      "train error: \n",
      " D loss: 1.255054, G loss: 1.118112, D accuracy: 59.1%, cell accuracy: 99.8%, board accuracy: 86.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.229845, G loss: 1.214605, D accuracy: 59.5%, cell accuracy: 99.7%, board accuracy: 84.5% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1012, G loss: 1.1172\n",
      "[84/1762] D loss: 1.1322, G loss: 1.3619\n",
      "[164/1762] D loss: 1.3778, G loss: 0.7583\n",
      "[244/1762] D loss: 1.4210, G loss: 0.5985\n",
      "[324/1762] D loss: 0.1632, G loss: 2.5212\n",
      "[404/1762] D loss: 0.0935, G loss: 2.9577\n",
      "[484/1762] D loss: 1.4484, G loss: 0.7848\n",
      "[564/1762] D loss: 0.1548, G loss: 2.5568\n",
      "[644/1762] D loss: 1.4017, G loss: 0.7113\n",
      "[724/1762] D loss: 0.2745, G loss: 1.9073\n",
      "[804/1762] D loss: 0.7535, G loss: 3.3521\n",
      "[884/1762] D loss: 1.4031, G loss: 0.5979\n",
      "[964/1762] D loss: 1.3457, G loss: 0.7194\n",
      "[1044/1762] D loss: 1.3786, G loss: 0.7784\n",
      "[1124/1762] D loss: 1.4296, G loss: 0.8359\n",
      "[1204/1762] D loss: 1.1111, G loss: 0.9230\n",
      "[1284/1762] D loss: 0.0178, G loss: 4.4096\n",
      "[1364/1762] D loss: 0.3017, G loss: 1.6367\n",
      "[1444/1762] D loss: 0.0070, G loss: 5.3044\n",
      "[1524/1762] D loss: 1.7315, G loss: 1.3590\n",
      "[1604/1762] D loss: 0.3971, G loss: 1.9250\n",
      "[1684/1762] D loss: 0.4443, G loss: 1.4059\n",
      "[1762/1762] D loss: 0.4191, G loss: 5.3147\n",
      "train error: \n",
      " D loss: 1.393258, G loss: 1.480732, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.361017, G loss: 1.510610, D accuracy: 55.7%, cell accuracy: 99.7%, board accuracy: 87.0% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3162, G loss: 0.6383\n",
      "[84/1762] D loss: 1.4497, G loss: 0.6208\n",
      "[164/1762] D loss: 1.4393, G loss: 0.9181\n",
      "[244/1762] D loss: 0.5993, G loss: 1.4750\n",
      "[324/1762] D loss: 1.3601, G loss: 0.5126\n",
      "[404/1762] D loss: 0.9600, G loss: 2.1757\n",
      "[484/1762] D loss: 1.4207, G loss: 0.7918\n",
      "[564/1762] D loss: 1.4186, G loss: 0.6571\n",
      "[644/1762] D loss: 0.7263, G loss: 3.0543\n",
      "[724/1762] D loss: 1.3925, G loss: 0.6199\n",
      "[804/1762] D loss: 1.4267, G loss: 0.5342\n",
      "[884/1762] D loss: 0.0088, G loss: 5.5873\n",
      "[964/1762] D loss: 2.3666, G loss: 1.8012\n",
      "[1044/1762] D loss: 0.4184, G loss: 1.3322\n",
      "[1124/1762] D loss: 1.1287, G loss: 1.0321\n",
      "[1204/1762] D loss: 1.4005, G loss: 0.7186\n",
      "[1284/1762] D loss: 1.4059, G loss: 0.7540\n",
      "[1364/1762] D loss: 0.9217, G loss: 4.3120\n",
      "[1444/1762] D loss: 1.3670, G loss: 0.7577\n",
      "[1524/1762] D loss: 0.2359, G loss: 2.1406\n",
      "[1604/1762] D loss: 1.4368, G loss: 0.9018\n",
      "[1684/1762] D loss: 1.1205, G loss: 1.1088\n",
      "[1762/1762] D loss: 1.4370, G loss: 0.8950\n",
      "train error: \n",
      " D loss: 1.333346, G loss: 1.130082, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 87.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.328144, G loss: 1.202710, D accuracy: 56.0%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1763, G loss: 0.9311\n",
      "[84/1762] D loss: 1.3683, G loss: 0.5673\n",
      "[164/1762] D loss: 1.0629, G loss: 0.9740\n",
      "[244/1762] D loss: 1.2965, G loss: 0.9464\n",
      "[324/1762] D loss: 1.0004, G loss: 1.4479\n",
      "[404/1762] D loss: 0.0882, G loss: 3.5899\n",
      "[484/1762] D loss: 1.4538, G loss: 0.5604\n",
      "[564/1762] D loss: 1.4381, G loss: 0.5604\n",
      "[644/1762] D loss: 0.1196, G loss: 2.9527\n",
      "[724/1762] D loss: 2.4831, G loss: 1.5954\n",
      "[804/1762] D loss: 0.7278, G loss: 0.9449\n",
      "[884/1762] D loss: 1.3767, G loss: 0.7835\n",
      "[964/1762] D loss: 0.4173, G loss: 1.5475\n",
      "[1044/1762] D loss: 0.1672, G loss: 2.3795\n",
      "[1124/1762] D loss: 1.4067, G loss: 0.6265\n",
      "[1204/1762] D loss: 0.3326, G loss: 1.9292\n",
      "[1284/1762] D loss: 0.2989, G loss: 2.0681\n",
      "[1364/1762] D loss: 1.4326, G loss: 0.5201\n",
      "[1444/1762] D loss: 1.3439, G loss: 2.2301\n",
      "[1524/1762] D loss: 1.3998, G loss: 0.6850\n",
      "[1604/1762] D loss: 1.4035, G loss: 0.5834\n",
      "[1684/1762] D loss: 0.0968, G loss: 3.1003\n",
      "[1762/1762] D loss: 0.0349, G loss: 4.0250\n",
      "train error: \n",
      " D loss: 1.389068, G loss: 1.009659, D accuracy: 56.4%, cell accuracy: 99.8%, board accuracy: 86.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.401158, G loss: 1.054249, D accuracy: 56.6%, cell accuracy: 99.8%, board accuracy: 85.9% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4214, G loss: 0.5960\n",
      "[84/1762] D loss: 1.3623, G loss: 0.6483\n",
      "[164/1762] D loss: 1.4843, G loss: 0.6133\n",
      "[244/1762] D loss: 1.5189, G loss: 0.5873\n",
      "[324/1762] D loss: 0.8320, G loss: 1.5151\n",
      "[404/1762] D loss: 1.3729, G loss: 1.1001\n",
      "[484/1762] D loss: 0.3310, G loss: 2.0544\n",
      "[564/1762] D loss: 1.0969, G loss: 0.9981\n",
      "[644/1762] D loss: 0.1002, G loss: 3.1527\n",
      "[724/1762] D loss: 0.9732, G loss: 1.2636\n",
      "[804/1762] D loss: 0.1530, G loss: 2.5281\n",
      "[884/1762] D loss: 1.4182, G loss: 0.8635\n",
      "[964/1762] D loss: 1.6180, G loss: 0.6478\n",
      "[1044/1762] D loss: 1.4305, G loss: 0.6957\n",
      "[1124/1762] D loss: 0.0543, G loss: 3.2690\n",
      "[1204/1762] D loss: 0.9413, G loss: 2.2786\n",
      "[1284/1762] D loss: 1.3967, G loss: 0.6173\n",
      "[1364/1762] D loss: 0.0730, G loss: 3.6976\n",
      "[1444/1762] D loss: 0.5341, G loss: 2.9035\n",
      "[1524/1762] D loss: 0.0868, G loss: 3.3984\n",
      "[1604/1762] D loss: 0.5166, G loss: 2.7819\n",
      "[1684/1762] D loss: 0.0222, G loss: 5.2648\n",
      "[1762/1762] D loss: 1.6578, G loss: 0.4058\n",
      "train error: \n",
      " D loss: 1.297728, G loss: 1.327303, D accuracy: 56.8%, cell accuracy: 99.7%, board accuracy: 84.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.273793, G loss: 1.300093, D accuracy: 58.1%, cell accuracy: 99.7%, board accuracy: 83.4% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4131, G loss: 0.5597\n",
      "[84/1762] D loss: 1.5795, G loss: 0.3795\n",
      "[164/1762] D loss: 1.3588, G loss: 0.6458\n",
      "[244/1762] D loss: 1.0892, G loss: 1.0194\n",
      "[324/1762] D loss: 0.1653, G loss: 2.4699\n",
      "[404/1762] D loss: 0.0846, G loss: 3.5777\n",
      "[484/1762] D loss: 0.1481, G loss: 3.0801\n",
      "[564/1762] D loss: 0.7215, G loss: 1.8628\n",
      "[644/1762] D loss: 1.3675, G loss: 0.7428\n",
      "[724/1762] D loss: 1.3662, G loss: 0.6415\n",
      "[804/1762] D loss: 1.3789, G loss: 0.7185\n",
      "[884/1762] D loss: 0.2456, G loss: 1.9835\n",
      "[964/1762] D loss: 0.0585, G loss: 3.6675\n",
      "[1044/1762] D loss: 0.0236, G loss: 3.9590\n",
      "[1124/1762] D loss: 1.4105, G loss: 0.5133\n",
      "[1204/1762] D loss: 0.7930, G loss: 1.8222\n",
      "[1284/1762] D loss: 0.0183, G loss: 5.8402\n",
      "[1364/1762] D loss: 1.6345, G loss: 0.4130\n",
      "[1444/1762] D loss: 0.1043, G loss: 3.1253\n",
      "[1524/1762] D loss: 1.3929, G loss: 0.8050\n",
      "[1604/1762] D loss: 0.0618, G loss: 3.4675\n",
      "[1684/1762] D loss: 1.4247, G loss: 0.7055\n",
      "[1762/1762] D loss: 1.5105, G loss: 0.4579\n",
      "train error: \n",
      " D loss: 1.300930, G loss: 1.920264, D accuracy: 57.6%, cell accuracy: 99.7%, board accuracy: 84.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.298562, G loss: 2.116326, D accuracy: 58.0%, cell accuracy: 99.7%, board accuracy: 81.8% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7102, G loss: 4.1517\n",
      "[84/1762] D loss: 0.2199, G loss: 2.2850\n",
      "[164/1762] D loss: 1.5296, G loss: 0.4085\n",
      "[244/1762] D loss: 0.0252, G loss: 4.7296\n",
      "[324/1762] D loss: 0.0994, G loss: 2.7671\n",
      "[404/1762] D loss: 0.6888, G loss: 3.5121\n",
      "[484/1762] D loss: 1.3644, G loss: 0.7181\n",
      "[564/1762] D loss: 1.4452, G loss: 0.4935\n",
      "[644/1762] D loss: 0.9923, G loss: 2.6027\n",
      "[724/1762] D loss: 0.7454, G loss: 1.8757\n",
      "[804/1762] D loss: 0.6914, G loss: 2.3434\n",
      "[884/1762] D loss: 0.6482, G loss: 1.8803\n",
      "[964/1762] D loss: 1.3833, G loss: 0.6637\n",
      "[1044/1762] D loss: 1.3882, G loss: 0.6506\n",
      "[1124/1762] D loss: 0.6337, G loss: 4.4480\n",
      "[1204/1762] D loss: 1.3981, G loss: 0.7875\n",
      "[1284/1762] D loss: 1.3554, G loss: 0.9171\n",
      "[1364/1762] D loss: 1.4559, G loss: 0.6315\n",
      "[1444/1762] D loss: 1.4186, G loss: 0.5759\n",
      "[1524/1762] D loss: 1.4043, G loss: 0.4699\n",
      "[1604/1762] D loss: 0.1763, G loss: 2.6955\n",
      "[1684/1762] D loss: 0.0532, G loss: 4.0331\n",
      "[1762/1762] D loss: 1.4966, G loss: 0.6427\n",
      "train error: \n",
      " D loss: 1.230385, G loss: 1.383118, D accuracy: 59.2%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.192744, G loss: 1.565386, D accuracy: 60.9%, cell accuracy: 99.7%, board accuracy: 84.1% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7832, G loss: 2.9211\n",
      "[84/1762] D loss: 0.7059, G loss: 2.6729\n",
      "[164/1762] D loss: 0.6706, G loss: 3.1168\n",
      "[244/1762] D loss: 1.5808, G loss: 0.4040\n",
      "[324/1762] D loss: 0.2400, G loss: 2.9555\n",
      "[404/1762] D loss: 1.4597, G loss: 0.8164\n",
      "[484/1762] D loss: 1.5301, G loss: 1.7141\n",
      "[564/1762] D loss: 0.7844, G loss: 2.6782\n",
      "[644/1762] D loss: 1.4606, G loss: 0.5970\n",
      "[724/1762] D loss: 0.8515, G loss: 2.2249\n",
      "[804/1762] D loss: 1.2654, G loss: 0.7870\n",
      "[884/1762] D loss: 1.4230, G loss: 0.7503\n",
      "[964/1762] D loss: 1.0472, G loss: 1.0057\n",
      "[1044/1762] D loss: 1.4422, G loss: 0.8489\n",
      "[1124/1762] D loss: 1.4182, G loss: 1.0032\n",
      "[1204/1762] D loss: 1.4385, G loss: 0.5456\n",
      "[1284/1762] D loss: 1.3830, G loss: 0.6110\n",
      "[1364/1762] D loss: 0.6992, G loss: 2.6478\n",
      "[1444/1762] D loss: 1.3869, G loss: 0.6936\n",
      "[1524/1762] D loss: 1.4773, G loss: 0.4252\n",
      "[1604/1762] D loss: 1.3970, G loss: 0.7818\n",
      "[1684/1762] D loss: 1.4345, G loss: 0.5195\n",
      "[1762/1762] D loss: 1.4122, G loss: 0.5759\n",
      "train error: \n",
      " D loss: 1.740065, G loss: 2.693230, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.735893, G loss: 2.716970, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 85.2% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9649, G loss: 1.4919\n",
      "[84/1762] D loss: 0.3027, G loss: 2.7065\n",
      "[164/1762] D loss: 1.3123, G loss: 0.6074\n",
      "[244/1762] D loss: 0.0114, G loss: 5.4194\n",
      "[324/1762] D loss: 1.0957, G loss: 0.8634\n",
      "[404/1762] D loss: 1.5389, G loss: 0.9678\n",
      "[484/1762] D loss: 1.5757, G loss: 0.3987\n",
      "[564/1762] D loss: 1.3654, G loss: 0.5029\n",
      "[644/1762] D loss: 1.4990, G loss: 0.9560\n",
      "[724/1762] D loss: 1.4085, G loss: 0.5976\n",
      "[804/1762] D loss: 1.3577, G loss: 0.5712\n",
      "[884/1762] D loss: 1.4003, G loss: 0.5742\n",
      "[964/1762] D loss: 0.7496, G loss: 1.9440\n",
      "[1044/1762] D loss: 1.4846, G loss: 0.5654\n",
      "[1124/1762] D loss: 1.4753, G loss: 0.4865\n",
      "[1204/1762] D loss: 1.4428, G loss: 0.5133\n",
      "[1284/1762] D loss: 0.5338, G loss: 4.2500\n",
      "[1364/1762] D loss: 1.2867, G loss: 0.6874\n",
      "[1444/1762] D loss: 1.0379, G loss: 1.4101\n",
      "[1524/1762] D loss: 0.5089, G loss: 1.5224\n",
      "[1604/1762] D loss: 1.3924, G loss: 0.6168\n",
      "[1684/1762] D loss: 1.1553, G loss: 1.0573\n",
      "[1762/1762] D loss: 1.3696, G loss: 0.6912\n",
      "train error: \n",
      " D loss: 1.286917, G loss: 1.115662, D accuracy: 56.8%, cell accuracy: 99.8%, board accuracy: 87.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.269593, G loss: 1.183932, D accuracy: 57.2%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3853, G loss: 0.6958\n",
      "[84/1762] D loss: 1.3921, G loss: 0.5244\n",
      "[164/1762] D loss: 1.4045, G loss: 0.8925\n",
      "[244/1762] D loss: 0.0923, G loss: 3.1614\n",
      "[324/1762] D loss: 1.3720, G loss: 0.5997\n",
      "[404/1762] D loss: 0.8685, G loss: 2.2114\n",
      "[484/1762] D loss: 0.3987, G loss: 4.4640\n",
      "[564/1762] D loss: 1.3866, G loss: 1.0168\n",
      "[644/1762] D loss: 0.0185, G loss: 5.5508\n",
      "[724/1762] D loss: 1.4242, G loss: 0.6346\n",
      "[804/1762] D loss: 0.5255, G loss: 3.4374\n",
      "[884/1762] D loss: 1.4061, G loss: 0.8118\n",
      "[964/1762] D loss: 0.6167, G loss: 4.8983\n",
      "[1044/1762] D loss: 1.3640, G loss: 0.6341\n",
      "[1124/1762] D loss: 1.4084, G loss: 0.5965\n",
      "[1204/1762] D loss: 0.8389, G loss: 1.6850\n",
      "[1284/1762] D loss: 1.4031, G loss: 0.6509\n",
      "[1364/1762] D loss: 1.4159, G loss: 0.7292\n",
      "[1444/1762] D loss: 0.9809, G loss: 0.8557\n",
      "[1524/1762] D loss: 0.0084, G loss: 6.3916\n",
      "[1604/1762] D loss: 0.2714, G loss: 4.6881\n",
      "[1684/1762] D loss: 0.5212, G loss: 3.4152\n",
      "[1762/1762] D loss: 2.2622, G loss: 0.1509\n",
      "train error: \n",
      " D loss: 1.262802, G loss: 1.852122, D accuracy: 59.6%, cell accuracy: 99.8%, board accuracy: 85.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.258362, G loss: 2.083613, D accuracy: 59.3%, cell accuracy: 99.7%, board accuracy: 84.5% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8026, G loss: 1.2907\n",
      "[84/1762] D loss: 0.9168, G loss: 2.1286\n",
      "[164/1762] D loss: 1.4101, G loss: 0.7862\n",
      "[244/1762] D loss: 1.3756, G loss: 0.7185\n",
      "[324/1762] D loss: 1.3070, G loss: 0.5594\n",
      "[404/1762] D loss: 0.0246, G loss: 5.5210\n",
      "[484/1762] D loss: 0.0709, G loss: 3.9527\n",
      "[564/1762] D loss: 0.1891, G loss: 2.4052\n",
      "[644/1762] D loss: 1.4650, G loss: 0.4845\n",
      "[724/1762] D loss: 0.0132, G loss: 6.2742\n",
      "[804/1762] D loss: 0.0981, G loss: 3.1886\n",
      "[884/1762] D loss: 0.6749, G loss: 3.2343\n",
      "[964/1762] D loss: 0.5609, G loss: 2.0014\n",
      "[1044/1762] D loss: 1.3799, G loss: 0.7120\n",
      "[1124/1762] D loss: 0.0652, G loss: 3.6187\n",
      "[1204/1762] D loss: 0.3887, G loss: 6.0833\n",
      "[1284/1762] D loss: 1.4345, G loss: 0.5593\n",
      "[1364/1762] D loss: 0.4788, G loss: 4.0494\n",
      "[1444/1762] D loss: 0.8232, G loss: 2.3877\n",
      "[1524/1762] D loss: 0.1037, G loss: 3.4409\n",
      "[1604/1762] D loss: 0.2236, G loss: 4.5964\n",
      "[1684/1762] D loss: 1.3399, G loss: 0.7558\n",
      "[1762/1762] D loss: 0.0058, G loss: 5.2484\n",
      "train error: \n",
      " D loss: 1.279244, G loss: 1.559227, D accuracy: 56.7%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.251410, G loss: 1.677963, D accuracy: 57.2%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3817, G loss: 0.5016\n",
      "[84/1762] D loss: 0.0770, G loss: 3.3471\n",
      "[164/1762] D loss: 1.4252, G loss: 0.5613\n",
      "[244/1762] D loss: 0.8380, G loss: 1.7931\n",
      "[324/1762] D loss: 0.0125, G loss: 5.5894\n",
      "[404/1762] D loss: 0.0015, G loss: 8.4235\n",
      "[484/1762] D loss: 0.0382, G loss: 4.1535\n",
      "[564/1762] D loss: 0.5875, G loss: 1.6654\n",
      "[644/1762] D loss: 0.4263, G loss: 3.2312\n",
      "[724/1762] D loss: 0.0102, G loss: 5.6511\n",
      "[804/1762] D loss: 1.7977, G loss: 0.4201\n",
      "[884/1762] D loss: 0.5521, G loss: 3.4007\n",
      "[964/1762] D loss: 0.0008, G loss: 7.9888\n",
      "[1044/1762] D loss: 1.3976, G loss: 0.9367\n",
      "[1124/1762] D loss: 1.5074, G loss: 0.5112\n",
      "[1204/1762] D loss: 0.3737, G loss: 6.6551\n",
      "[1284/1762] D loss: 0.4055, G loss: 7.0409\n",
      "[1364/1762] D loss: 1.8760, G loss: 0.3287\n",
      "[1444/1762] D loss: 0.1214, G loss: 2.4681\n",
      "[1524/1762] D loss: 0.0390, G loss: 4.7661\n",
      "[1604/1762] D loss: 1.4010, G loss: 0.7023\n",
      "[1684/1762] D loss: 1.4054, G loss: 0.5314\n",
      "[1762/1762] D loss: 0.5789, G loss: 1.7099\n",
      "train error: \n",
      " D loss: 1.778278, G loss: 2.574023, D accuracy: 55.6%, cell accuracy: 99.8%, board accuracy: 87.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.735471, G loss: 2.640221, D accuracy: 56.6%, cell accuracy: 99.8%, board accuracy: 85.9% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3530, G loss: 0.6436\n",
      "[84/1762] D loss: 1.4308, G loss: 0.5957\n",
      "[164/1762] D loss: 1.4558, G loss: 0.8827\n",
      "[244/1762] D loss: 0.0386, G loss: 3.3536\n",
      "[324/1762] D loss: 1.3620, G loss: 0.6653\n",
      "[404/1762] D loss: 0.0126, G loss: 6.1534\n",
      "[484/1762] D loss: 1.3721, G loss: 0.6466\n",
      "[564/1762] D loss: 1.4891, G loss: 1.1741\n",
      "[644/1762] D loss: 1.0926, G loss: 1.0307\n",
      "[724/1762] D loss: 0.7409, G loss: 4.2541\n",
      "[804/1762] D loss: 0.0142, G loss: 6.3561\n",
      "[884/1762] D loss: 1.0667, G loss: 1.5349\n",
      "[964/1762] D loss: 0.6228, G loss: 5.1559\n",
      "[1044/1762] D loss: 1.3732, G loss: 0.8354\n",
      "[1124/1762] D loss: 1.4556, G loss: 0.5095\n",
      "[1204/1762] D loss: 0.0029, G loss: 7.6067\n",
      "[1284/1762] D loss: 0.8046, G loss: 1.4754\n",
      "[1364/1762] D loss: 0.0051, G loss: 5.6902\n",
      "[1444/1762] D loss: 1.5213, G loss: 0.4301\n",
      "[1524/1762] D loss: 1.3997, G loss: 0.5671\n",
      "[1604/1762] D loss: 0.2547, G loss: 8.0288\n",
      "[1684/1762] D loss: 1.4542, G loss: 1.2085\n",
      "[1762/1762] D loss: 1.4763, G loss: 0.4789\n",
      "train error: \n",
      " D loss: 1.331444, G loss: 1.422392, D accuracy: 57.2%, cell accuracy: 99.8%, board accuracy: 87.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.317690, G loss: 1.436813, D accuracy: 58.1%, cell accuracy: 99.8%, board accuracy: 84.8% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4819, G loss: 0.5777\n",
      "[84/1762] D loss: 0.0857, G loss: 3.3329\n",
      "[164/1762] D loss: 0.0109, G loss: 6.7204\n",
      "[244/1762] D loss: 1.2774, G loss: 0.7510\n",
      "[324/1762] D loss: 1.2761, G loss: 0.6381\n",
      "[404/1762] D loss: 0.4536, G loss: 7.9338\n",
      "[484/1762] D loss: 1.4308, G loss: 0.8660\n",
      "[564/1762] D loss: 0.7311, G loss: 2.8337\n",
      "[644/1762] D loss: 1.1495, G loss: 1.1513\n",
      "[724/1762] D loss: 1.2871, G loss: 0.6474\n",
      "[804/1762] D loss: 1.0961, G loss: 0.9026\n",
      "[884/1762] D loss: 0.0244, G loss: 5.5555\n",
      "[964/1762] D loss: 1.3240, G loss: 0.6617\n",
      "[1044/1762] D loss: 1.3731, G loss: 0.5735\n",
      "[1124/1762] D loss: 1.4105, G loss: 0.7976\n",
      "[1204/1762] D loss: 1.2892, G loss: 0.7390\n",
      "[1284/1762] D loss: 1.6585, G loss: 0.3117\n",
      "[1364/1762] D loss: 1.4288, G loss: 0.5609\n",
      "[1444/1762] D loss: 1.5115, G loss: 0.5540\n",
      "[1524/1762] D loss: 0.6756, G loss: 0.8092\n",
      "[1604/1762] D loss: 1.3417, G loss: 1.0497\n",
      "[1684/1762] D loss: 1.3888, G loss: 0.7342\n",
      "[1762/1762] D loss: 1.3682, G loss: 0.7437\n",
      "train error: \n",
      " D loss: 1.295125, G loss: 1.438216, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.274593, G loss: 1.525793, D accuracy: 55.7%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3732, G loss: 0.7416\n",
      "[84/1762] D loss: 0.4092, G loss: 4.1118\n",
      "[164/1762] D loss: 1.3717, G loss: 0.6492\n",
      "[244/1762] D loss: 0.0387, G loss: 4.5190\n",
      "[324/1762] D loss: 0.2707, G loss: 5.5015\n",
      "[404/1762] D loss: 1.0246, G loss: 3.4820\n",
      "[484/1762] D loss: 0.3625, G loss: 2.8676\n",
      "[564/1762] D loss: 1.4094, G loss: 0.6285\n",
      "[644/1762] D loss: 0.9932, G loss: 0.9624\n",
      "[724/1762] D loss: 0.4215, G loss: 4.2660\n",
      "[804/1762] D loss: 0.2655, G loss: 2.9699\n",
      "[884/1762] D loss: 1.3948, G loss: 1.2398\n",
      "[964/1762] D loss: 0.0136, G loss: 6.3561\n",
      "[1044/1762] D loss: 0.3795, G loss: 6.6040\n",
      "[1124/1762] D loss: 0.1768, G loss: 2.8287\n",
      "[1204/1762] D loss: 0.1420, G loss: 3.1670\n",
      "[1284/1762] D loss: 1.3051, G loss: 0.7104\n",
      "[1364/1762] D loss: 0.3171, G loss: 6.4952\n",
      "[1444/1762] D loss: 1.4293, G loss: 0.5822\n",
      "[1524/1762] D loss: 0.6350, G loss: 7.4318\n",
      "[1604/1762] D loss: 1.3934, G loss: 0.6546\n",
      "[1684/1762] D loss: 0.0013, G loss: 7.7757\n",
      "[1762/1762] D loss: 0.0001, G loss: 9.4417\n",
      "train error: \n",
      " D loss: 1.413674, G loss: 2.429153, D accuracy: 56.9%, cell accuracy: 99.7%, board accuracy: 81.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.378892, G loss: 2.599258, D accuracy: 57.4%, cell accuracy: 99.7%, board accuracy: 80.5% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1131, G loss: 0.7857\n",
      "[84/1762] D loss: 1.3105, G loss: 0.8236\n",
      "[164/1762] D loss: 1.4265, G loss: 0.6594\n",
      "[244/1762] D loss: 1.4634, G loss: 0.4238\n",
      "[324/1762] D loss: 1.5601, G loss: 0.5628\n",
      "[404/1762] D loss: 0.3452, G loss: 5.5815\n",
      "[484/1762] D loss: 1.3901, G loss: 0.8537\n",
      "[564/1762] D loss: 1.3842, G loss: 0.6483\n",
      "[644/1762] D loss: 0.0019, G loss: 6.9432\n",
      "[724/1762] D loss: 0.4102, G loss: 4.0739\n",
      "[804/1762] D loss: 0.2483, G loss: 5.6799\n",
      "[884/1762] D loss: 1.3407, G loss: 0.8644\n",
      "[964/1762] D loss: 0.1314, G loss: 3.7862\n",
      "[1044/1762] D loss: 1.4215, G loss: 0.5740\n",
      "[1124/1762] D loss: 1.3983, G loss: 0.5576\n",
      "[1204/1762] D loss: 0.0012, G loss: 8.4093\n",
      "[1284/1762] D loss: 1.0957, G loss: 2.0221\n",
      "[1364/1762] D loss: 0.8020, G loss: 1.3125\n",
      "[1444/1762] D loss: 0.0013, G loss: 8.1242\n",
      "[1524/1762] D loss: 0.0179, G loss: 5.6570\n",
      "[1604/1762] D loss: 1.0121, G loss: 1.0419\n",
      "[1684/1762] D loss: 1.2795, G loss: 0.8750\n",
      "[1762/1762] D loss: 1.4013, G loss: 0.6502\n",
      "train error: \n",
      " D loss: 1.333307, G loss: 1.691108, D accuracy: 57.3%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.303041, G loss: 1.818515, D accuracy: 57.7%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4273, G loss: 0.5127\n",
      "[84/1762] D loss: 1.0922, G loss: 0.9195\n",
      "[164/1762] D loss: 0.5731, G loss: 2.3218\n",
      "[244/1762] D loss: 0.7278, G loss: 6.8617\n",
      "[324/1762] D loss: 0.5172, G loss: 8.4889\n",
      "[404/1762] D loss: 0.4994, G loss: 7.4741\n",
      "[484/1762] D loss: 1.5711, G loss: 0.3511\n",
      "[564/1762] D loss: 0.5794, G loss: 4.6106\n",
      "[644/1762] D loss: 0.9192, G loss: 1.0327\n",
      "[724/1762] D loss: 1.3495, G loss: 0.5980\n",
      "[804/1762] D loss: 0.0542, G loss: 6.6668\n",
      "[884/1762] D loss: 1.4878, G loss: 0.4643\n",
      "[964/1762] D loss: 1.2653, G loss: 0.7567\n",
      "[1044/1762] D loss: 0.0142, G loss: 4.2366\n",
      "[1124/1762] D loss: 0.0876, G loss: 3.6645\n",
      "[1204/1762] D loss: 0.1930, G loss: 3.6198\n",
      "[1284/1762] D loss: 1.6346, G loss: 0.7590\n",
      "[1364/1762] D loss: 1.7174, G loss: 0.3562\n",
      "[1444/1762] D loss: 1.4094, G loss: 0.7760\n",
      "[1524/1762] D loss: 1.4237, G loss: 0.4666\n",
      "[1604/1762] D loss: 1.1833, G loss: 3.0348\n",
      "[1684/1762] D loss: 0.7223, G loss: 4.5326\n",
      "[1762/1762] D loss: 1.4081, G loss: 0.5659\n",
      "train error: \n",
      " D loss: 1.398529, G loss: 1.583699, D accuracy: 56.7%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.340706, G loss: 1.665616, D accuracy: 58.5%, cell accuracy: 99.7%, board accuracy: 85.5% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0150, G loss: 7.3234\n",
      "[84/1762] D loss: 0.8800, G loss: 2.0317\n",
      "[164/1762] D loss: 1.3983, G loss: 0.7133\n",
      "[244/1762] D loss: 0.6777, G loss: 1.9417\n",
      "[324/1762] D loss: 1.3430, G loss: 1.1343\n",
      "[404/1762] D loss: 0.8333, G loss: 1.9890\n",
      "[484/1762] D loss: 1.4110, G loss: 0.5700\n",
      "[564/1762] D loss: 1.3660, G loss: 0.6078\n",
      "[644/1762] D loss: 0.0038, G loss: 8.2768\n",
      "[724/1762] D loss: 0.6864, G loss: 2.3618\n",
      "[804/1762] D loss: 1.5447, G loss: 0.4336\n",
      "[884/1762] D loss: 1.4704, G loss: 0.6527\n",
      "[964/1762] D loss: 0.0057, G loss: 7.0906\n",
      "[1044/1762] D loss: 1.3881, G loss: 0.8451\n",
      "[1124/1762] D loss: 1.3793, G loss: 0.6135\n",
      "[1204/1762] D loss: 1.3521, G loss: 0.6588\n",
      "[1284/1762] D loss: 1.3885, G loss: 0.7565\n",
      "[1364/1762] D loss: 0.9804, G loss: 1.7558\n",
      "[1444/1762] D loss: 1.4088, G loss: 0.5305\n",
      "[1524/1762] D loss: 1.4169, G loss: 0.7332\n",
      "[1604/1762] D loss: 1.4206, G loss: 0.5161\n",
      "[1684/1762] D loss: 1.4681, G loss: 0.5061\n",
      "[1762/1762] D loss: 2.3259, G loss: 1.2260\n",
      "train error: \n",
      " D loss: 1.376308, G loss: 1.950919, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.331189, G loss: 2.028540, D accuracy: 56.2%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5933, G loss: 7.6280\n",
      "[84/1762] D loss: 1.2937, G loss: 0.5967\n",
      "[164/1762] D loss: 0.0221, G loss: 9.1570\n",
      "[244/1762] D loss: 0.4129, G loss: 1.6457\n",
      "[324/1762] D loss: 0.0013, G loss: 8.1326\n",
      "[404/1762] D loss: 1.2648, G loss: 0.7130\n",
      "[484/1762] D loss: 1.3790, G loss: 0.8827\n",
      "[564/1762] D loss: 0.0013, G loss: 9.6148\n",
      "[644/1762] D loss: 1.3738, G loss: 0.6803\n",
      "[724/1762] D loss: 0.0017, G loss: 6.6029\n",
      "[804/1762] D loss: 1.4984, G loss: 0.4893\n",
      "[884/1762] D loss: 0.0011, G loss: 9.8952\n",
      "[964/1762] D loss: 1.4698, G loss: 0.4464\n",
      "[1044/1762] D loss: 1.2984, G loss: 0.8729\n",
      "[1124/1762] D loss: 0.0112, G loss: 5.3795\n",
      "[1204/1762] D loss: 0.2908, G loss: 6.3679\n",
      "[1284/1762] D loss: 1.5537, G loss: 0.4735\n",
      "[1364/1762] D loss: 1.4648, G loss: 0.5979\n",
      "[1444/1762] D loss: 1.8035, G loss: 1.0721\n",
      "[1524/1762] D loss: 0.5751, G loss: 1.6351\n",
      "[1604/1762] D loss: 0.0032, G loss: 5.6789\n",
      "[1684/1762] D loss: 0.0503, G loss: 3.9014\n",
      "[1762/1762] D loss: 1.4491, G loss: 0.5645\n",
      "train error: \n",
      " D loss: 1.255769, G loss: 2.614219, D accuracy: 58.8%, cell accuracy: 99.7%, board accuracy: 82.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.231652, G loss: 2.914077, D accuracy: 59.0%, cell accuracy: 99.7%, board accuracy: 79.8% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3275, G loss: 0.6229\n",
      "[84/1762] D loss: 1.2863, G loss: 0.6879\n",
      "[164/1762] D loss: 1.7383, G loss: 0.2453\n",
      "[244/1762] D loss: 0.0057, G loss: 6.6409\n",
      "[324/1762] D loss: 0.4598, G loss: 2.1229\n",
      "[404/1762] D loss: 1.3478, G loss: 0.7034\n",
      "[484/1762] D loss: 1.3780, G loss: 1.0656\n",
      "[564/1762] D loss: 0.3267, G loss: 2.9536\n",
      "[644/1762] D loss: 0.0003, G loss: 10.7821\n",
      "[724/1762] D loss: 0.0005, G loss: 9.5260\n",
      "[804/1762] D loss: 1.3663, G loss: 0.6648\n",
      "[884/1762] D loss: 0.1488, G loss: 2.6244\n",
      "[964/1762] D loss: 1.0501, G loss: 0.9885\n",
      "[1044/1762] D loss: 1.0381, G loss: 2.3188\n",
      "[1124/1762] D loss: 0.0071, G loss: 6.2573\n",
      "[1204/1762] D loss: 1.3062, G loss: 0.8375\n",
      "[1284/1762] D loss: 1.4378, G loss: 0.5740\n",
      "[1364/1762] D loss: 1.1764, G loss: 0.8569\n",
      "[1444/1762] D loss: 0.8467, G loss: 1.7518\n",
      "[1524/1762] D loss: 1.3472, G loss: 0.7050\n",
      "[1604/1762] D loss: 0.0005, G loss: 8.0713\n",
      "[1684/1762] D loss: 1.4308, G loss: 0.6082\n",
      "[1762/1762] D loss: 0.2457, G loss: 7.4758\n",
      "train error: \n",
      " D loss: 1.849180, G loss: 1.718805, D accuracy: 51.7%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.967204, G loss: 1.871195, D accuracy: 51.6%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3978, G loss: 0.5864\n",
      "[84/1762] D loss: 1.1997, G loss: 0.6225\n",
      "[164/1762] D loss: 1.3905, G loss: 0.6514\n",
      "[244/1762] D loss: 1.4027, G loss: 0.5553\n",
      "[324/1762] D loss: 1.3895, G loss: 0.6176\n",
      "[404/1762] D loss: 1.3495, G loss: 0.7440\n",
      "[484/1762] D loss: 1.3985, G loss: 0.6032\n",
      "[564/1762] D loss: 0.2126, G loss: 3.2299\n",
      "[644/1762] D loss: 1.2148, G loss: 1.2458\n",
      "[724/1762] D loss: 1.3747, G loss: 0.6686\n",
      "[804/1762] D loss: 1.6707, G loss: 0.3206\n",
      "[884/1762] D loss: 0.4004, G loss: 4.7068\n",
      "[964/1762] D loss: 1.4258, G loss: 0.6074\n",
      "[1044/1762] D loss: 1.4113, G loss: 0.8009\n",
      "[1124/1762] D loss: 0.3346, G loss: 7.8871\n",
      "[1204/1762] D loss: 0.5289, G loss: 4.7341\n",
      "[1284/1762] D loss: 1.3222, G loss: 2.5168\n",
      "[1364/1762] D loss: 0.0990, G loss: 2.7761\n",
      "[1444/1762] D loss: 1.2822, G loss: 0.9969\n",
      "[1524/1762] D loss: 0.2331, G loss: 8.7817\n",
      "[1604/1762] D loss: 0.8230, G loss: 2.8737\n",
      "[1684/1762] D loss: 0.0040, G loss: 6.7606\n",
      "[1762/1762] D loss: 0.6896, G loss: 7.4792\n",
      "train error: \n",
      " D loss: 1.774318, G loss: 2.439896, D accuracy: 51.8%, cell accuracy: 99.8%, board accuracy: 87.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.836997, G loss: 2.593952, D accuracy: 51.8%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3769, G loss: 0.5980\n",
      "[84/1762] D loss: 0.2080, G loss: 8.2462\n",
      "[164/1762] D loss: 1.2497, G loss: 0.8636\n",
      "[244/1762] D loss: 1.4167, G loss: 0.5357\n",
      "[324/1762] D loss: 1.3764, G loss: 0.6107\n",
      "[404/1762] D loss: 0.0067, G loss: 6.8824\n",
      "[484/1762] D loss: 1.3343, G loss: 0.6135\n",
      "[564/1762] D loss: 1.3377, G loss: 0.8121\n",
      "[644/1762] D loss: 1.5630, G loss: 0.3919\n",
      "[724/1762] D loss: 0.3999, G loss: 2.4100\n",
      "[804/1762] D loss: 0.0007, G loss: 9.6182\n",
      "[884/1762] D loss: 1.5032, G loss: 0.4282\n",
      "[964/1762] D loss: 1.4326, G loss: 0.5462\n",
      "[1044/1762] D loss: 0.0041, G loss: 7.0651\n",
      "[1124/1762] D loss: 1.3885, G loss: 0.5406\n",
      "[1204/1762] D loss: 0.0631, G loss: 4.9424\n",
      "[1284/1762] D loss: 0.4999, G loss: 2.4070\n",
      "[1364/1762] D loss: 1.4948, G loss: 0.8014\n",
      "[1444/1762] D loss: 0.2939, G loss: 6.1669\n",
      "[1524/1762] D loss: 1.0855, G loss: 0.9636\n",
      "[1604/1762] D loss: 0.8399, G loss: 1.6285\n",
      "[1684/1762] D loss: 1.4162, G loss: 0.5040\n",
      "[1762/1762] D loss: 0.0001, G loss: 9.1522\n",
      "train error: \n",
      " D loss: 2.116829, G loss: 2.542240, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 87.2% \n",
      "\n",
      "test error: \n",
      " D loss: 2.077006, G loss: 2.545213, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 85.9% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4949, G loss: 0.4627\n",
      "[84/1762] D loss: 1.6538, G loss: 0.3399\n",
      "[164/1762] D loss: 0.4208, G loss: 2.5919\n",
      "[244/1762] D loss: 1.5800, G loss: 0.5526\n",
      "[324/1762] D loss: 0.3857, G loss: 3.9931\n",
      "[404/1762] D loss: 1.1391, G loss: 1.1396\n",
      "[484/1762] D loss: 0.0022, G loss: 7.4615\n",
      "[564/1762] D loss: 1.4847, G loss: 0.6010\n",
      "[644/1762] D loss: 1.4032, G loss: 0.6625\n",
      "[724/1762] D loss: 1.0527, G loss: 0.8925\n",
      "[804/1762] D loss: 0.0978, G loss: 3.8060\n",
      "[884/1762] D loss: 1.4372, G loss: 0.4828\n",
      "[964/1762] D loss: 0.2675, G loss: 2.1576\n",
      "[1044/1762] D loss: 1.3809, G loss: 0.7767\n",
      "[1124/1762] D loss: 1.4736, G loss: 0.4643\n",
      "[1204/1762] D loss: 0.7163, G loss: 1.8579\n",
      "[1284/1762] D loss: 0.7538, G loss: 1.6508\n",
      "[1364/1762] D loss: 1.4019, G loss: 0.5939\n",
      "[1444/1762] D loss: 1.4519, G loss: 0.5253\n",
      "[1524/1762] D loss: 1.3800, G loss: 0.9375\n",
      "[1604/1762] D loss: 0.0005, G loss: 9.2773\n",
      "[1684/1762] D loss: 1.4319, G loss: 0.5123\n",
      "[1762/1762] D loss: 1.5335, G loss: 0.5537\n",
      "train error: \n",
      " D loss: 1.559526, G loss: 2.064862, D accuracy: 57.0%, cell accuracy: 99.8%, board accuracy: 87.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.659378, G loss: 2.370379, D accuracy: 56.1%, cell accuracy: 99.7%, board accuracy: 85.0% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9462, G loss: 2.3164\n",
      "[84/1762] D loss: 1.4899, G loss: 0.4232\n",
      "[164/1762] D loss: 1.6320, G loss: 0.2990\n",
      "[244/1762] D loss: 0.0004, G loss: 10.3815\n",
      "[324/1762] D loss: 0.1180, G loss: 4.2446\n",
      "[404/1762] D loss: 0.2731, G loss: 6.9805\n",
      "[484/1762] D loss: 1.3538, G loss: 0.6943\n",
      "[564/1762] D loss: 0.0508, G loss: 4.7974\n",
      "[644/1762] D loss: 0.3184, G loss: 4.6758\n",
      "[724/1762] D loss: 0.6209, G loss: 3.2400\n",
      "[804/1762] D loss: 0.0799, G loss: 4.7951\n",
      "[884/1762] D loss: 2.0991, G loss: 0.1979\n",
      "[964/1762] D loss: 0.1257, G loss: 2.9813\n",
      "[1044/1762] D loss: 0.4847, G loss: 6.1419\n",
      "[1124/1762] D loss: 1.4922, G loss: 0.9395\n",
      "[1204/1762] D loss: 1.4330, G loss: 0.5491\n",
      "[1284/1762] D loss: 1.4720, G loss: 0.5125\n",
      "[1364/1762] D loss: 1.0770, G loss: 1.2592\n",
      "[1444/1762] D loss: 1.3716, G loss: 0.6795\n",
      "[1524/1762] D loss: 1.6751, G loss: 0.3950\n",
      "[1604/1762] D loss: 0.1554, G loss: 3.2915\n",
      "[1684/1762] D loss: 1.3793, G loss: 0.5970\n",
      "[1762/1762] D loss: 0.1532, G loss: 6.1045\n",
      "train error: \n",
      " D loss: 2.905365, G loss: 3.250291, D accuracy: 51.7%, cell accuracy: 99.8%, board accuracy: 85.8% \n",
      "\n",
      "test error: \n",
      " D loss: 3.195555, G loss: 3.286657, D accuracy: 51.5%, cell accuracy: 99.7%, board accuracy: 83.6% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1938, G loss: 2.2202\n",
      "[84/1762] D loss: 0.3112, G loss: 2.5306\n",
      "[164/1762] D loss: 0.1767, G loss: 2.9003\n",
      "[244/1762] D loss: 1.5322, G loss: 0.9466\n",
      "[324/1762] D loss: 0.9384, G loss: 1.3175\n",
      "[404/1762] D loss: 1.4012, G loss: 0.7055\n",
      "[484/1762] D loss: 1.1926, G loss: 1.9885\n",
      "[564/1762] D loss: 1.4750, G loss: 0.4896\n",
      "[644/1762] D loss: 0.6375, G loss: 2.8826\n",
      "[724/1762] D loss: 0.0955, G loss: 2.9102\n",
      "[804/1762] D loss: 0.0288, G loss: 3.5506\n",
      "[884/1762] D loss: 0.2341, G loss: 6.9480\n",
      "[964/1762] D loss: 1.4928, G loss: 0.4285\n",
      "[1044/1762] D loss: 1.3905, G loss: 0.5884\n",
      "[1124/1762] D loss: 0.2975, G loss: 3.9135\n",
      "[1204/1762] D loss: 0.3339, G loss: 4.7420\n",
      "[1284/1762] D loss: 1.4578, G loss: 0.4547\n",
      "[1364/1762] D loss: 1.6579, G loss: 1.0115\n",
      "[1444/1762] D loss: 0.0206, G loss: 8.1988\n",
      "[1524/1762] D loss: 0.3633, G loss: 5.9025\n",
      "[1604/1762] D loss: 0.4512, G loss: 2.2127\n",
      "[1684/1762] D loss: 1.5792, G loss: 0.4073\n",
      "[1762/1762] D loss: 1.8833, G loss: 0.5419\n",
      "train error: \n",
      " D loss: 1.502839, G loss: 2.600244, D accuracy: 57.3%, cell accuracy: 99.8%, board accuracy: 86.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.486259, G loss: 2.588479, D accuracy: 58.0%, cell accuracy: 99.7%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3373, G loss: 0.7232\n",
      "[84/1762] D loss: 0.5008, G loss: 5.0239\n",
      "[164/1762] D loss: 1.3538, G loss: 0.7679\n",
      "[244/1762] D loss: 1.5957, G loss: 0.3632\n",
      "[324/1762] D loss: 1.6714, G loss: 0.5815\n",
      "[404/1762] D loss: 0.5910, G loss: 2.2763\n",
      "[484/1762] D loss: 1.3709, G loss: 0.7427\n",
      "[564/1762] D loss: 1.5571, G loss: 0.5166\n",
      "[644/1762] D loss: 1.4448, G loss: 0.5355\n",
      "[724/1762] D loss: 1.3187, G loss: 0.6938\n",
      "[804/1762] D loss: 0.0010, G loss: 9.5554\n",
      "[884/1762] D loss: 0.2889, G loss: 6.0073\n",
      "[964/1762] D loss: 0.4863, G loss: 2.4405\n",
      "[1044/1762] D loss: 1.5660, G loss: 0.5092\n",
      "[1124/1762] D loss: 0.0767, G loss: 3.0569\n",
      "[1204/1762] D loss: 0.1477, G loss: 2.9366\n",
      "[1284/1762] D loss: 0.0103, G loss: 5.5785\n",
      "[1364/1762] D loss: 0.0008, G loss: 11.2224\n",
      "[1444/1762] D loss: 0.9802, G loss: 5.2762\n",
      "[1524/1762] D loss: 1.6117, G loss: 0.3162\n",
      "[1604/1762] D loss: 1.3420, G loss: 0.7568\n",
      "[1684/1762] D loss: 1.3949, G loss: 0.5188\n",
      "[1762/1762] D loss: 1.3891, G loss: 0.8798\n",
      "train error: \n",
      " D loss: 1.726623, G loss: 2.822901, D accuracy: 55.7%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.921719, G loss: 2.882038, D accuracy: 55.9%, cell accuracy: 99.7%, board accuracy: 85.0% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3089, G loss: 1.0231\n",
      "[84/1762] D loss: 0.6076, G loss: 3.4228\n",
      "[164/1762] D loss: 0.0007, G loss: 9.2914\n",
      "[244/1762] D loss: 0.8872, G loss: 2.0734\n",
      "[324/1762] D loss: 0.0001, G loss: 11.0778\n",
      "[404/1762] D loss: 1.5241, G loss: 0.9392\n",
      "[484/1762] D loss: 0.0010, G loss: 8.6663\n",
      "[564/1762] D loss: 0.1552, G loss: 6.5731\n",
      "[644/1762] D loss: 0.4374, G loss: 2.7298\n",
      "[724/1762] D loss: 1.4657, G loss: 1.1051\n",
      "[804/1762] D loss: 0.0279, G loss: 4.8939\n",
      "[884/1762] D loss: 0.2857, G loss: 2.5533\n",
      "[964/1762] D loss: 0.0006, G loss: 10.7658\n",
      "[1044/1762] D loss: 0.0083, G loss: 8.2469\n",
      "[1124/1762] D loss: 0.0021, G loss: 10.0779\n",
      "[1204/1762] D loss: 0.1836, G loss: 2.3872\n",
      "[1284/1762] D loss: 1.3897, G loss: 0.6239\n",
      "[1364/1762] D loss: 1.4065, G loss: 0.6925\n",
      "[1444/1762] D loss: 0.2965, G loss: 3.8937\n",
      "[1524/1762] D loss: 1.3887, G loss: 0.5964\n",
      "[1604/1762] D loss: 0.0958, G loss: 3.0071\n",
      "[1684/1762] D loss: 1.5632, G loss: 0.8923\n",
      "[1762/1762] D loss: 1.4876, G loss: 0.4115\n",
      "train error: \n",
      " D loss: 1.354417, G loss: 1.977091, D accuracy: 59.3%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.375654, G loss: 2.089466, D accuracy: 59.0%, cell accuracy: 99.7%, board accuracy: 85.7% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0024, G loss: 7.6511\n",
      "[84/1762] D loss: 0.0680, G loss: 3.9867\n",
      "[164/1762] D loss: 0.4862, G loss: 2.1767\n",
      "[244/1762] D loss: 0.5612, G loss: 4.1080\n",
      "[324/1762] D loss: 0.8195, G loss: 7.6805\n",
      "[404/1762] D loss: 1.3431, G loss: 0.6507\n",
      "[484/1762] D loss: 1.1964, G loss: 1.6705\n",
      "[564/1762] D loss: 0.7314, G loss: 1.6648\n",
      "[644/1762] D loss: 1.2131, G loss: 1.0054\n",
      "[724/1762] D loss: 0.1140, G loss: 2.4813\n",
      "[804/1762] D loss: 0.0003, G loss: 9.9966\n",
      "[884/1762] D loss: 0.1855, G loss: 4.4604\n",
      "[964/1762] D loss: 0.2969, G loss: 5.2195\n",
      "[1044/1762] D loss: 0.1428, G loss: 3.7229\n",
      "[1124/1762] D loss: 1.5293, G loss: 0.4065\n",
      "[1204/1762] D loss: 1.4241, G loss: 0.5078\n",
      "[1284/1762] D loss: 0.0194, G loss: 6.0186\n",
      "[1364/1762] D loss: 1.4338, G loss: 0.9191\n",
      "[1444/1762] D loss: 0.2162, G loss: 6.2431\n",
      "[1524/1762] D loss: 1.4670, G loss: 0.5514\n",
      "[1604/1762] D loss: 0.0209, G loss: 4.9014\n",
      "[1684/1762] D loss: 1.7663, G loss: 0.2857\n",
      "[1762/1762] D loss: 0.9934, G loss: 1.1461\n",
      "train error: \n",
      " D loss: 1.467448, G loss: 2.949763, D accuracy: 59.2%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.457599, G loss: 3.337278, D accuracy: 60.1%, cell accuracy: 99.7%, board accuracy: 83.6% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9055, G loss: 3.0954\n",
      "[84/1762] D loss: 1.0492, G loss: 2.8582\n",
      "[164/1762] D loss: 0.0458, G loss: 4.3548\n",
      "[244/1762] D loss: 1.3884, G loss: 0.6689\n",
      "[324/1762] D loss: 1.4969, G loss: 0.3999\n",
      "[404/1762] D loss: 0.3608, G loss: 7.3171\n",
      "[484/1762] D loss: 1.4079, G loss: 0.6838\n",
      "[564/1762] D loss: 0.0882, G loss: 3.0062\n",
      "[644/1762] D loss: 0.3589, G loss: 6.8802\n",
      "[724/1762] D loss: 1.3646, G loss: 0.6258\n",
      "[804/1762] D loss: 0.8792, G loss: 1.4678\n",
      "[884/1762] D loss: 0.1858, G loss: 5.5296\n",
      "[964/1762] D loss: 0.9593, G loss: 4.0288\n",
      "[1044/1762] D loss: 1.4194, G loss: 0.5538\n",
      "[1124/1762] D loss: 0.2172, G loss: 4.5319\n",
      "[1204/1762] D loss: 1.3970, G loss: 0.8516\n",
      "[1284/1762] D loss: 1.3505, G loss: 0.5735\n",
      "[1364/1762] D loss: 0.0461, G loss: 3.5683\n",
      "[1444/1762] D loss: 0.4422, G loss: 6.8909\n",
      "[1524/1762] D loss: 1.0845, G loss: 1.3040\n",
      "[1604/1762] D loss: 1.5999, G loss: 0.3969\n",
      "[1684/1762] D loss: 0.0045, G loss: 7.2052\n",
      "[1762/1762] D loss: 1.4709, G loss: 0.4563\n",
      "train error: \n",
      " D loss: 1.324057, G loss: 2.736765, D accuracy: 59.9%, cell accuracy: 99.7%, board accuracy: 84.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.350315, G loss: 2.661478, D accuracy: 59.5%, cell accuracy: 99.7%, board accuracy: 83.6% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4977, G loss: 0.4536\n",
      "[84/1762] D loss: 1.4613, G loss: 0.4900\n",
      "[164/1762] D loss: 0.4397, G loss: 3.5052\n",
      "[244/1762] D loss: 0.0060, G loss: 10.7775\n",
      "[324/1762] D loss: 1.4714, G loss: 0.4711\n",
      "[404/1762] D loss: 1.7882, G loss: 0.2703\n",
      "[484/1762] D loss: 0.0174, G loss: 4.4821\n",
      "[564/1762] D loss: 1.5170, G loss: 0.4278\n",
      "[644/1762] D loss: 1.3873, G loss: 1.0334\n",
      "[724/1762] D loss: 0.5518, G loss: 2.5120\n",
      "[804/1762] D loss: 0.0401, G loss: 3.5012\n",
      "[884/1762] D loss: 0.2409, G loss: 8.0372\n",
      "[964/1762] D loss: 0.5687, G loss: 7.3970\n",
      "[1044/1762] D loss: 1.3307, G loss: 0.7577\n",
      "[1124/1762] D loss: 1.3350, G loss: 0.5727\n",
      "[1204/1762] D loss: 0.0180, G loss: 4.7565\n",
      "[1284/1762] D loss: 1.2119, G loss: 0.8426\n",
      "[1364/1762] D loss: 0.0062, G loss: 6.2139\n",
      "[1444/1762] D loss: 0.0586, G loss: 3.7389\n",
      "[1524/1762] D loss: 0.6701, G loss: 1.6205\n",
      "[1604/1762] D loss: 0.0096, G loss: 5.0521\n",
      "[1684/1762] D loss: 0.3487, G loss: 7.5553\n",
      "[1762/1762] D loss: 1.4396, G loss: 0.8278\n",
      "train error: \n",
      " D loss: 1.335778, G loss: 2.160715, D accuracy: 60.2%, cell accuracy: 99.7%, board accuracy: 84.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.346119, G loss: 2.354901, D accuracy: 60.7%, cell accuracy: 99.7%, board accuracy: 82.7% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2864, G loss: 0.7654\n",
      "[84/1762] D loss: 1.0930, G loss: 1.0450\n",
      "[164/1762] D loss: 1.4219, G loss: 0.6479\n",
      "[244/1762] D loss: 1.4280, G loss: 0.8755\n",
      "[324/1762] D loss: 1.1978, G loss: 0.6831\n",
      "[404/1762] D loss: 0.0966, G loss: 2.7357\n",
      "[484/1762] D loss: 0.1529, G loss: 3.2280\n",
      "[564/1762] D loss: 1.4294, G loss: 0.7680\n",
      "[644/1762] D loss: 1.7055, G loss: 3.0357\n",
      "[724/1762] D loss: 0.3370, G loss: 6.3668\n",
      "[804/1762] D loss: 1.2847, G loss: 0.6946\n",
      "[884/1762] D loss: 0.1142, G loss: 7.3226\n",
      "[964/1762] D loss: 1.4046, G loss: 0.4840\n",
      "[1044/1762] D loss: 0.6463, G loss: 3.4036\n",
      "[1124/1762] D loss: 0.0044, G loss: 9.1127\n",
      "[1204/1762] D loss: 1.3962, G loss: 0.5784\n",
      "[1284/1762] D loss: 1.5315, G loss: 0.4836\n",
      "[1364/1762] D loss: 0.1220, G loss: 2.6958\n",
      "[1444/1762] D loss: 1.7199, G loss: 1.1602\n",
      "[1524/1762] D loss: 0.1742, G loss: 3.4812\n",
      "[1604/1762] D loss: 1.3564, G loss: 0.9013\n",
      "[1684/1762] D loss: 0.2119, G loss: 4.0139\n",
      "[1762/1762] D loss: 1.3953, G loss: 0.6701\n",
      "train error: \n",
      " D loss: 2.206336, G loss: 2.837630, D accuracy: 51.6%, cell accuracy: 99.8%, board accuracy: 86.3% \n",
      "\n",
      "test error: \n",
      " D loss: 2.350066, G loss: 3.081610, D accuracy: 51.6%, cell accuracy: 99.7%, board accuracy: 83.9% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2866, G loss: 0.7272\n",
      "[84/1762] D loss: 1.2270, G loss: 0.6807\n",
      "[164/1762] D loss: 1.3937, G loss: 0.6766\n",
      "[244/1762] D loss: 0.0090, G loss: 9.5612\n",
      "[324/1762] D loss: 1.3807, G loss: 1.1262\n",
      "[404/1762] D loss: 1.5447, G loss: 0.8376\n",
      "[484/1762] D loss: 0.0829, G loss: 3.1524\n",
      "[564/1762] D loss: 1.3607, G loss: 0.7301\n",
      "[644/1762] D loss: 1.4898, G loss: 0.4774\n",
      "[724/1762] D loss: 0.1175, G loss: 9.8847\n",
      "[804/1762] D loss: 0.3607, G loss: 3.7947\n",
      "[884/1762] D loss: 1.4562, G loss: 0.5119\n",
      "[964/1762] D loss: 0.2203, G loss: 6.3395\n",
      "[1044/1762] D loss: 1.3937, G loss: 0.4968\n",
      "[1124/1762] D loss: 1.4520, G loss: 0.6781\n",
      "[1204/1762] D loss: 1.4943, G loss: 0.9505\n",
      "[1284/1762] D loss: 0.0733, G loss: 3.4589\n",
      "[1364/1762] D loss: 0.0003, G loss: 9.4634\n",
      "[1444/1762] D loss: 1.3750, G loss: 0.7207\n",
      "[1524/1762] D loss: 1.0903, G loss: 1.1600\n",
      "[1604/1762] D loss: 0.2155, G loss: 2.1906\n",
      "[1684/1762] D loss: 0.9957, G loss: 1.3332\n",
      "[1762/1762] D loss: 1.3805, G loss: 0.7122\n",
      "train error: \n",
      " D loss: 1.833407, G loss: 1.712083, D accuracy: 58.6%, cell accuracy: 99.8%, board accuracy: 87.9% \n",
      "\n",
      "test error: \n",
      " D loss: 2.051218, G loss: 1.759699, D accuracy: 57.0%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4825, G loss: 0.4311\n",
      "[84/1762] D loss: 0.1278, G loss: 3.9234\n",
      "[164/1762] D loss: 0.0886, G loss: 8.0380\n",
      "[244/1762] D loss: 0.5248, G loss: 6.6387\n",
      "[324/1762] D loss: 1.3485, G loss: 0.6609\n",
      "[404/1762] D loss: 0.1889, G loss: 8.4157\n",
      "[484/1762] D loss: 0.0095, G loss: 9.0248\n",
      "[564/1762] D loss: 1.2368, G loss: 0.9181\n",
      "[644/1762] D loss: 0.0008, G loss: 9.1274\n",
      "[724/1762] D loss: 0.3776, G loss: 4.5117\n",
      "[804/1762] D loss: 0.3934, G loss: 9.2810\n",
      "[884/1762] D loss: 1.5978, G loss: 0.8500\n",
      "[964/1762] D loss: 1.4309, G loss: 0.6037\n",
      "[1044/1762] D loss: 0.0002, G loss: 9.6284\n",
      "[1124/1762] D loss: 0.0007, G loss: 8.8085\n",
      "[1204/1762] D loss: 1.4151, G loss: 0.6699\n",
      "[1284/1762] D loss: 1.5296, G loss: 1.0660\n",
      "[1364/1762] D loss: 0.3505, G loss: 4.1432\n",
      "[1444/1762] D loss: 0.8253, G loss: 8.2075\n",
      "[1524/1762] D loss: 1.2552, G loss: 0.8395\n",
      "[1604/1762] D loss: 1.4684, G loss: 0.4902\n",
      "[1684/1762] D loss: 0.2427, G loss: 4.5591\n",
      "[1762/1762] D loss: 0.4284, G loss: 6.5030\n",
      "train error: \n",
      " D loss: 2.250284, G loss: 2.502931, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 86.5% \n",
      "\n",
      "test error: \n",
      " D loss: 2.465065, G loss: 2.640279, D accuracy: 53.5%, cell accuracy: 99.7%, board accuracy: 85.2% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1214, G loss: 4.5729\n",
      "[84/1762] D loss: 0.3434, G loss: 4.3989\n",
      "[164/1762] D loss: 0.0020, G loss: 6.7125\n",
      "[244/1762] D loss: 0.1197, G loss: 3.1325\n",
      "[324/1762] D loss: 0.2556, G loss: 3.0809\n",
      "[404/1762] D loss: 0.0767, G loss: 3.5673\n",
      "[484/1762] D loss: 0.8025, G loss: 1.5294\n",
      "[564/1762] D loss: 0.2753, G loss: 4.8401\n",
      "[644/1762] D loss: 0.9677, G loss: 1.5559\n",
      "[724/1762] D loss: 1.4009, G loss: 0.5166\n",
      "[804/1762] D loss: 1.3087, G loss: 0.8635\n",
      "[884/1762] D loss: 1.3436, G loss: 0.7564\n",
      "[964/1762] D loss: 0.2122, G loss: 7.7865\n",
      "[1044/1762] D loss: 1.4064, G loss: 0.7275\n",
      "[1124/1762] D loss: 0.2154, G loss: 4.9277\n",
      "[1204/1762] D loss: 1.2987, G loss: 0.6355\n",
      "[1284/1762] D loss: 0.0554, G loss: 3.9436\n",
      "[1364/1762] D loss: 0.6629, G loss: 3.7876\n",
      "[1444/1762] D loss: 1.0990, G loss: 0.8548\n",
      "[1524/1762] D loss: 1.4443, G loss: 0.4945\n",
      "[1604/1762] D loss: 1.4071, G loss: 0.5600\n",
      "[1684/1762] D loss: 1.3778, G loss: 0.6369\n",
      "[1762/1762] D loss: 1.4720, G loss: 0.5504\n",
      "train error: \n",
      " D loss: 1.876790, G loss: 2.140998, D accuracy: 56.9%, cell accuracy: 99.8%, board accuracy: 86.7% \n",
      "\n",
      "test error: \n",
      " D loss: 2.088940, G loss: 2.139109, D accuracy: 57.0%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.3071, G loss: 0.3964\n",
      "[84/1762] D loss: 1.0726, G loss: 0.8160\n",
      "[164/1762] D loss: 0.0008, G loss: 7.8877\n",
      "[244/1762] D loss: 0.7243, G loss: 1.9195\n",
      "[324/1762] D loss: 0.0572, G loss: 3.2652\n",
      "[404/1762] D loss: 0.0014, G loss: 7.2405\n",
      "[484/1762] D loss: 1.4858, G loss: 0.5114\n",
      "[564/1762] D loss: 0.5165, G loss: 9.5223\n",
      "[644/1762] D loss: 1.3631, G loss: 1.0554\n",
      "[724/1762] D loss: 1.1204, G loss: 0.9851\n",
      "[804/1762] D loss: 0.3949, G loss: 2.8645\n",
      "[884/1762] D loss: 0.0822, G loss: 3.5478\n",
      "[964/1762] D loss: 0.0106, G loss: 5.6222\n",
      "[1044/1762] D loss: 0.0008, G loss: 8.3928\n",
      "[1124/1762] D loss: 0.0014, G loss: 10.0557\n",
      "[1204/1762] D loss: 1.5828, G loss: 0.8006\n",
      "[1284/1762] D loss: 0.8433, G loss: 2.0983\n",
      "[1364/1762] D loss: 1.6139, G loss: 0.3558\n",
      "[1444/1762] D loss: 0.0139, G loss: 9.7493\n",
      "[1524/1762] D loss: 1.4276, G loss: 0.5234\n",
      "[1604/1762] D loss: 0.0370, G loss: 4.8414\n",
      "[1684/1762] D loss: 0.6965, G loss: 5.3509\n",
      "[1762/1762] D loss: 0.0000, G loss: 13.7517\n",
      "train error: \n",
      " D loss: 1.735754, G loss: 2.304471, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.857044, G loss: 2.372968, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 85.5% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3883, G loss: 0.6843\n",
      "[84/1762] D loss: 1.3031, G loss: 0.6349\n",
      "[164/1762] D loss: 1.0911, G loss: 0.6820\n",
      "[244/1762] D loss: 0.6039, G loss: 1.2485\n",
      "[324/1762] D loss: 0.4074, G loss: 2.2558\n",
      "[404/1762] D loss: 0.3129, G loss: 3.6522\n",
      "[484/1762] D loss: 0.4393, G loss: 3.0803\n",
      "[564/1762] D loss: 0.9468, G loss: 1.8416\n",
      "[644/1762] D loss: 0.6729, G loss: 2.0034\n",
      "[724/1762] D loss: 0.5236, G loss: 1.6519\n",
      "[804/1762] D loss: 0.5955, G loss: 1.5515\n",
      "[884/1762] D loss: 0.8917, G loss: 2.0192\n",
      "[964/1762] D loss: 0.8156, G loss: 1.6739\n",
      "[1044/1762] D loss: 0.5899, G loss: 2.1450\n",
      "[1124/1762] D loss: 0.7102, G loss: 1.9178\n",
      "[1204/1762] D loss: 1.5324, G loss: 1.2748\n",
      "[1284/1762] D loss: 1.0022, G loss: 1.7924\n",
      "[1364/1762] D loss: 0.8476, G loss: 1.8518\n",
      "[1444/1762] D loss: 0.6394, G loss: 1.8796\n",
      "[1524/1762] D loss: 0.7369, G loss: 1.6222\n",
      "[1604/1762] D loss: 0.8157, G loss: 1.2188\n",
      "[1684/1762] D loss: 1.0599, G loss: 1.2076\n",
      "[1762/1762] D loss: 1.2698, G loss: 2.5014\n",
      "train error: \n",
      " D loss: 1.134614, G loss: 2.096865, D accuracy: 59.4%, cell accuracy: 96.2%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.151970, G loss: 2.146124, D accuracy: 58.8%, cell accuracy: 96.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0744, G loss: 1.9982\n",
      "[84/1762] D loss: 0.6070, G loss: 1.6749\n",
      "[164/1762] D loss: 0.8294, G loss: 1.6466\n",
      "[244/1762] D loss: 1.1731, G loss: 1.4928\n",
      "[324/1762] D loss: 1.1632, G loss: 1.6043\n",
      "[404/1762] D loss: 1.2818, G loss: 1.1279\n",
      "[484/1762] D loss: 1.3617, G loss: 0.9082\n",
      "[564/1762] D loss: 0.7999, G loss: 2.0035\n",
      "[644/1762] D loss: 1.2778, G loss: 0.8053\n",
      "[724/1762] D loss: 1.0997, G loss: 1.0107\n",
      "[804/1762] D loss: 1.1515, G loss: 0.5380\n",
      "[884/1762] D loss: 1.4789, G loss: 0.3633\n",
      "[964/1762] D loss: 1.1035, G loss: 1.1436\n",
      "[1044/1762] D loss: 1.3438, G loss: 0.7048\n",
      "[1124/1762] D loss: 1.2535, G loss: 0.6944\n",
      "[1204/1762] D loss: 1.3583, G loss: 0.8072\n",
      "[1284/1762] D loss: 1.4136, G loss: 0.7074\n",
      "[1364/1762] D loss: 1.3744, G loss: 0.8052\n",
      "[1444/1762] D loss: 1.3742, G loss: 0.6949\n",
      "[1524/1762] D loss: 1.3846, G loss: 0.6733\n",
      "[1604/1762] D loss: 1.3624, G loss: 0.7156\n",
      "[1684/1762] D loss: 1.3792, G loss: 0.5091\n",
      "[1762/1762] D loss: 1.3836, G loss: 0.5806\n",
      "train error: \n",
      " D loss: 1.388951, G loss: 0.568739, D accuracy: 55.2%, cell accuracy: 99.7%, board accuracy: 82.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.386108, G loss: 0.577260, D accuracy: 55.5%, cell accuracy: 99.7%, board accuracy: 79.5% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4253, G loss: 0.5352\n",
      "[84/1762] D loss: 1.2604, G loss: 0.7058\n",
      "[164/1762] D loss: 1.3498, G loss: 0.8123\n",
      "[244/1762] D loss: 1.3126, G loss: 0.8137\n",
      "[324/1762] D loss: 1.3928, G loss: 0.7007\n",
      "[404/1762] D loss: 1.3543, G loss: 0.6206\n",
      "[484/1762] D loss: 1.3139, G loss: 0.7357\n",
      "[564/1762] D loss: 1.3849, G loss: 0.7493\n",
      "[644/1762] D loss: 1.2884, G loss: 0.8138\n",
      "[724/1762] D loss: 1.3770, G loss: 0.8011\n",
      "[804/1762] D loss: 1.3931, G loss: 0.7090\n",
      "[884/1762] D loss: 1.3687, G loss: 0.6692\n",
      "[964/1762] D loss: 1.5851, G loss: 0.5883\n",
      "[1044/1762] D loss: 1.3804, G loss: 0.9426\n",
      "[1124/1762] D loss: 1.3812, G loss: 0.7298\n",
      "[1204/1762] D loss: 1.4037, G loss: 0.6185\n",
      "[1284/1762] D loss: 1.3008, G loss: 0.8083\n",
      "[1364/1762] D loss: 1.3109, G loss: 0.8304\n",
      "[1444/1762] D loss: 1.2717, G loss: 0.7357\n",
      "[1524/1762] D loss: 1.3005, G loss: 0.8260\n",
      "[1604/1762] D loss: 1.4146, G loss: 0.7099\n",
      "[1684/1762] D loss: 1.3929, G loss: 0.6439\n",
      "[1762/1762] D loss: 1.3701, G loss: 0.8373\n",
      "train error: \n",
      " D loss: 1.354400, G loss: 0.766582, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 81.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.348766, G loss: 0.780014, D accuracy: 55.9%, cell accuracy: 99.7%, board accuracy: 79.5% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3159, G loss: 0.7247\n",
      "[84/1762] D loss: 1.3348, G loss: 0.6892\n",
      "[164/1762] D loss: 1.4011, G loss: 0.7259\n",
      "[244/1762] D loss: 1.3978, G loss: 0.7543\n",
      "[324/1762] D loss: 1.3946, G loss: 0.7301\n",
      "[404/1762] D loss: 1.3887, G loss: 0.8314\n",
      "[484/1762] D loss: 1.3952, G loss: 0.6771\n",
      "[564/1762] D loss: 1.3919, G loss: 0.7924\n",
      "[644/1762] D loss: 1.3213, G loss: 0.8314\n",
      "[724/1762] D loss: 1.4100, G loss: 0.6452\n",
      "[804/1762] D loss: 1.4155, G loss: 0.5936\n",
      "[884/1762] D loss: 1.3434, G loss: 0.7236\n",
      "[964/1762] D loss: 1.3832, G loss: 0.6481\n",
      "[1044/1762] D loss: 1.3775, G loss: 0.7189\n",
      "[1124/1762] D loss: 1.3507, G loss: 0.7591\n",
      "[1204/1762] D loss: 1.3014, G loss: 0.7336\n",
      "[1284/1762] D loss: 1.2045, G loss: 0.8795\n",
      "[1364/1762] D loss: 1.2800, G loss: 0.5958\n",
      "[1444/1762] D loss: 1.2682, G loss: 1.0049\n",
      "[1524/1762] D loss: 1.4183, G loss: 0.6243\n",
      "[1604/1762] D loss: 1.3405, G loss: 0.8524\n",
      "[1684/1762] D loss: 1.2825, G loss: 0.9296\n",
      "[1762/1762] D loss: 1.1536, G loss: 1.0222\n",
      "train error: \n",
      " D loss: 1.338416, G loss: 0.779995, D accuracy: 55.6%, cell accuracy: 99.7%, board accuracy: 82.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.327500, G loss: 0.795621, D accuracy: 56.0%, cell accuracy: 99.7%, board accuracy: 79.1% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3745, G loss: 0.6536\n",
      "[84/1762] D loss: 1.3348, G loss: 0.7022\n",
      "[164/1762] D loss: 1.4051, G loss: 0.8113\n",
      "[244/1762] D loss: 1.1142, G loss: 0.8436\n",
      "[324/1762] D loss: 1.4250, G loss: 0.7509\n",
      "[404/1762] D loss: 1.5091, G loss: 0.4858\n",
      "[484/1762] D loss: 1.3893, G loss: 0.7198\n",
      "[564/1762] D loss: 1.3781, G loss: 0.6303\n",
      "[644/1762] D loss: 1.2168, G loss: 0.9795\n",
      "[724/1762] D loss: 1.3321, G loss: 0.6460\n",
      "[804/1762] D loss: 1.3938, G loss: 0.6730\n",
      "[884/1762] D loss: 1.2749, G loss: 0.9606\n",
      "[964/1762] D loss: 1.4236, G loss: 0.8350\n",
      "[1044/1762] D loss: 1.3764, G loss: 0.6094\n",
      "[1124/1762] D loss: 1.3807, G loss: 0.7380\n",
      "[1204/1762] D loss: 1.1723, G loss: 0.7542\n",
      "[1284/1762] D loss: 1.4408, G loss: 0.7845\n",
      "[1364/1762] D loss: 1.6940, G loss: 0.5893\n",
      "[1444/1762] D loss: 1.1093, G loss: 0.8862\n",
      "[1524/1762] D loss: 0.8096, G loss: 1.1235\n",
      "[1604/1762] D loss: 0.3772, G loss: 1.9710\n",
      "[1684/1762] D loss: 1.5259, G loss: 1.4437\n",
      "[1762/1762] D loss: 1.2742, G loss: 0.5341\n",
      "train error: \n",
      " D loss: 1.385933, G loss: 0.557945, D accuracy: 57.3%, cell accuracy: 99.5%, board accuracy: 41.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.397617, G loss: 0.567927, D accuracy: 58.5%, cell accuracy: 99.5%, board accuracy: 39.1% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3885, G loss: 0.6510\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6919\n",
      "[164/1762] D loss: 1.3861, G loss: 0.6918\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6966\n",
      "[324/1762] D loss: 1.3847, G loss: 0.6877\n",
      "[404/1762] D loss: 1.3775, G loss: 0.7052\n",
      "[484/1762] D loss: 1.2393, G loss: 0.8278\n",
      "[564/1762] D loss: 1.3475, G loss: 0.7537\n",
      "[644/1762] D loss: 1.1153, G loss: 1.1899\n",
      "[724/1762] D loss: 1.2156, G loss: 0.7820\n",
      "[804/1762] D loss: 1.3722, G loss: 0.9021\n",
      "[884/1762] D loss: 1.0077, G loss: 1.6341\n",
      "[964/1762] D loss: 1.0340, G loss: 0.8355\n",
      "[1044/1762] D loss: 1.0290, G loss: 0.9519\n",
      "[1124/1762] D loss: 1.1619, G loss: 1.2039\n",
      "[1204/1762] D loss: 0.7819, G loss: 1.2048\n",
      "[1284/1762] D loss: 1.3117, G loss: 0.6420\n",
      "[1364/1762] D loss: 0.4584, G loss: 2.0197\n",
      "[1444/1762] D loss: 0.9377, G loss: 1.1481\n",
      "[1524/1762] D loss: 0.1555, G loss: 2.7449\n",
      "[1604/1762] D loss: 1.2373, G loss: 1.2103\n",
      "[1684/1762] D loss: 0.3570, G loss: 2.1730\n",
      "[1762/1762] D loss: 0.8174, G loss: 1.9452\n",
      "train error: \n",
      " D loss: 0.631369, G loss: 2.004639, D accuracy: 87.9%, cell accuracy: 99.4%, board accuracy: 26.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.665211, G loss: 1.920456, D accuracy: 85.7%, cell accuracy: 99.4%, board accuracy: 26.6% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5812, G loss: 0.5929\n",
      "[84/1762] D loss: 0.7419, G loss: 1.6430\n",
      "[164/1762] D loss: 1.0661, G loss: 1.4184\n",
      "[244/1762] D loss: 0.4825, G loss: 2.4928\n",
      "[324/1762] D loss: 0.8696, G loss: 1.8765\n",
      "[404/1762] D loss: 0.4766, G loss: 2.0533\n",
      "[484/1762] D loss: 0.3918, G loss: 2.7714\n",
      "[564/1762] D loss: 0.5663, G loss: 2.0290\n",
      "[644/1762] D loss: 0.3269, G loss: 2.6878\n",
      "[724/1762] D loss: 0.8450, G loss: 1.8802\n",
      "[804/1762] D loss: 1.2489, G loss: 0.7258\n",
      "[884/1762] D loss: 0.9595, G loss: 1.2170\n",
      "[964/1762] D loss: 1.0442, G loss: 1.7553\n",
      "[1044/1762] D loss: 0.3358, G loss: 3.2942\n",
      "[1124/1762] D loss: 0.8125, G loss: 2.0211\n",
      "[1204/1762] D loss: 0.1737, G loss: 3.9963\n",
      "[1284/1762] D loss: 0.5796, G loss: 3.0567\n",
      "[1364/1762] D loss: 0.5017, G loss: 3.1185\n",
      "[1444/1762] D loss: 0.2086, G loss: 4.4513\n",
      "[1524/1762] D loss: 0.1104, G loss: 3.5275\n",
      "[1604/1762] D loss: 0.4015, G loss: 3.3927\n",
      "[1684/1762] D loss: 1.2750, G loss: 0.9067\n",
      "[1762/1762] D loss: 1.0912, G loss: 1.1707\n",
      "train error: \n",
      " D loss: 0.580217, G loss: 3.220423, D accuracy: 87.5%, cell accuracy: 99.5%, board accuracy: 30.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.616943, G loss: 3.148406, D accuracy: 84.9%, cell accuracy: 99.4%, board accuracy: 27.3% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5590, G loss: 3.4725\n",
      "[84/1762] D loss: 0.8468, G loss: 2.2838\n",
      "[164/1762] D loss: 0.0443, G loss: 4.4217\n",
      "[244/1762] D loss: 0.5602, G loss: 1.8578\n",
      "[324/1762] D loss: 0.1555, G loss: 4.4115\n",
      "[404/1762] D loss: 0.0591, G loss: 4.5360\n",
      "[484/1762] D loss: 0.4185, G loss: 3.9668\n",
      "[564/1762] D loss: 0.7225, G loss: 3.2027\n",
      "[644/1762] D loss: 0.7917, G loss: 2.8412\n",
      "[724/1762] D loss: 0.9114, G loss: 2.5267\n",
      "[804/1762] D loss: 0.1097, G loss: 4.4164\n",
      "[884/1762] D loss: 0.2695, G loss: 4.2239\n",
      "[964/1762] D loss: 0.6108, G loss: 2.5689\n",
      "[1044/1762] D loss: 1.4702, G loss: 1.4572\n",
      "[1124/1762] D loss: 0.9130, G loss: 3.8549\n",
      "[1204/1762] D loss: 0.6236, G loss: 2.5781\n",
      "[1284/1762] D loss: 1.0169, G loss: 2.6953\n",
      "[1364/1762] D loss: 0.9772, G loss: 2.9272\n",
      "[1444/1762] D loss: 0.4300, G loss: 2.7160\n",
      "[1524/1762] D loss: 0.5959, G loss: 2.3962\n",
      "[1604/1762] D loss: 0.5642, G loss: 3.4546\n",
      "[1684/1762] D loss: 0.1433, G loss: 4.0860\n",
      "[1762/1762] D loss: 0.6831, G loss: 2.4661\n",
      "train error: \n",
      " D loss: 0.610714, G loss: 2.939336, D accuracy: 85.1%, cell accuracy: 99.5%, board accuracy: 37.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.601644, G loss: 2.947009, D accuracy: 85.3%, cell accuracy: 99.4%, board accuracy: 33.4% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2093, G loss: 1.5486\n",
      "[84/1762] D loss: 0.5673, G loss: 2.9720\n",
      "[164/1762] D loss: 0.3846, G loss: 4.2129\n",
      "[244/1762] D loss: 1.0002, G loss: 2.3957\n",
      "[324/1762] D loss: 0.7719, G loss: 2.2752\n",
      "[404/1762] D loss: 0.4453, G loss: 5.7034\n",
      "[484/1762] D loss: 0.0960, G loss: 3.4628\n",
      "[564/1762] D loss: 0.2249, G loss: 5.2822\n",
      "[644/1762] D loss: 0.1195, G loss: 6.9036\n",
      "[724/1762] D loss: 0.0910, G loss: 4.1065\n",
      "[804/1762] D loss: 0.6074, G loss: 2.8050\n",
      "[884/1762] D loss: 0.5356, G loss: 3.6406\n",
      "[964/1762] D loss: 0.2449, G loss: 3.3260\n",
      "[1044/1762] D loss: 0.1937, G loss: 3.7248\n",
      "[1124/1762] D loss: 0.2097, G loss: 4.7156\n",
      "[1204/1762] D loss: 0.6765, G loss: 3.7926\n",
      "[1284/1762] D loss: 1.2443, G loss: 1.5688\n",
      "[1364/1762] D loss: 0.7035, G loss: 2.4277\n",
      "[1444/1762] D loss: 0.3748, G loss: 3.8746\n",
      "[1524/1762] D loss: 0.3711, G loss: 3.8133\n",
      "[1604/1762] D loss: 0.3182, G loss: 4.5154\n",
      "[1684/1762] D loss: 0.1422, G loss: 5.1289\n",
      "[1762/1762] D loss: 0.0282, G loss: 7.9139\n",
      "train error: \n",
      " D loss: 0.596745, G loss: 3.547993, D accuracy: 85.5%, cell accuracy: 99.5%, board accuracy: 38.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.588902, G loss: 3.530176, D accuracy: 84.7%, cell accuracy: 99.4%, board accuracy: 37.5% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3758, G loss: 4.1472\n",
      "[84/1762] D loss: 0.8974, G loss: 3.6265\n",
      "[164/1762] D loss: 0.7643, G loss: 3.3342\n",
      "[244/1762] D loss: 0.7484, G loss: 2.6655\n",
      "[324/1762] D loss: 0.7787, G loss: 2.2592\n",
      "[404/1762] D loss: 0.2919, G loss: 3.2818\n",
      "[484/1762] D loss: 0.1614, G loss: 5.5066\n",
      "[564/1762] D loss: 1.0910, G loss: 1.6896\n",
      "[644/1762] D loss: 1.5552, G loss: 1.7360\n",
      "[724/1762] D loss: 0.1898, G loss: 3.6630\n",
      "[804/1762] D loss: 0.8395, G loss: 3.4858\n",
      "[884/1762] D loss: 0.1755, G loss: 5.0091\n",
      "[964/1762] D loss: 0.3906, G loss: 4.1510\n",
      "[1044/1762] D loss: 0.0767, G loss: 4.7389\n",
      "[1124/1762] D loss: 0.5941, G loss: 2.1705\n",
      "[1204/1762] D loss: 0.6149, G loss: 4.7390\n",
      "[1284/1762] D loss: 0.5184, G loss: 6.4211\n",
      "[1364/1762] D loss: 1.5991, G loss: 1.4455\n",
      "[1444/1762] D loss: 0.0696, G loss: 5.0243\n",
      "[1524/1762] D loss: 0.4848, G loss: 3.7028\n",
      "[1604/1762] D loss: 0.4795, G loss: 4.8617\n",
      "[1684/1762] D loss: 0.4660, G loss: 3.4069\n",
      "[1762/1762] D loss: 1.2646, G loss: 0.8880\n",
      "train error: \n",
      " D loss: 0.472838, G loss: 4.409363, D accuracy: 89.4%, cell accuracy: 99.5%, board accuracy: 39.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.471724, G loss: 4.195911, D accuracy: 89.1%, cell accuracy: 99.5%, board accuracy: 36.6% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6849, G loss: 3.2320\n",
      "[84/1762] D loss: 1.1946, G loss: 2.0031\n",
      "[164/1762] D loss: 0.4416, G loss: 4.2941\n",
      "[244/1762] D loss: 1.1948, G loss: 2.0306\n",
      "[324/1762] D loss: 0.3240, G loss: 6.1578\n",
      "[404/1762] D loss: 0.5978, G loss: 5.8329\n",
      "[484/1762] D loss: 0.1310, G loss: 4.1742\n",
      "[564/1762] D loss: 0.7467, G loss: 4.5624\n",
      "[644/1762] D loss: 0.4398, G loss: 2.9682\n",
      "[724/1762] D loss: 0.5607, G loss: 4.1934\n",
      "[804/1762] D loss: 0.3903, G loss: 3.5886\n",
      "[884/1762] D loss: 0.3697, G loss: 5.5731\n",
      "[964/1762] D loss: 1.0723, G loss: 1.6529\n",
      "[1044/1762] D loss: 1.1982, G loss: 3.6717\n",
      "[1124/1762] D loss: 0.3815, G loss: 3.1787\n",
      "[1204/1762] D loss: 0.0346, G loss: 5.7252\n",
      "[1284/1762] D loss: 0.4161, G loss: 4.0095\n",
      "[1364/1762] D loss: 0.3622, G loss: 5.0442\n",
      "[1444/1762] D loss: 0.5509, G loss: 5.6209\n",
      "[1524/1762] D loss: 0.2339, G loss: 5.1032\n",
      "[1604/1762] D loss: 1.4271, G loss: 0.7800\n",
      "[1684/1762] D loss: 0.7177, G loss: 3.6460\n",
      "[1762/1762] D loss: 0.2730, G loss: 5.2270\n",
      "train error: \n",
      " D loss: 0.496308, G loss: 4.201702, D accuracy: 87.8%, cell accuracy: 99.5%, board accuracy: 40.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.533268, G loss: 4.155017, D accuracy: 86.1%, cell accuracy: 99.5%, board accuracy: 37.5% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3604, G loss: 4.9965\n",
      "[84/1762] D loss: 0.0837, G loss: 3.2973\n",
      "[164/1762] D loss: 0.3879, G loss: 5.7335\n",
      "[244/1762] D loss: 0.4435, G loss: 3.3162\n",
      "[324/1762] D loss: 0.8384, G loss: 2.2265\n",
      "[404/1762] D loss: 0.0595, G loss: 5.2703\n",
      "[484/1762] D loss: 0.5897, G loss: 4.2956\n",
      "[564/1762] D loss: 0.7177, G loss: 3.8011\n",
      "[644/1762] D loss: 0.4454, G loss: 3.6737\n",
      "[724/1762] D loss: 0.6069, G loss: 3.1291\n",
      "[804/1762] D loss: 0.1915, G loss: 7.4455\n",
      "[884/1762] D loss: 1.4058, G loss: 1.3973\n",
      "[964/1762] D loss: 0.0311, G loss: 6.1930\n",
      "[1044/1762] D loss: 0.2978, G loss: 5.4368\n",
      "[1124/1762] D loss: 0.7214, G loss: 1.8907\n",
      "[1204/1762] D loss: 0.0529, G loss: 7.5280\n",
      "[1284/1762] D loss: 0.3727, G loss: 4.3573\n",
      "[1364/1762] D loss: 0.3274, G loss: 7.0024\n",
      "[1444/1762] D loss: 0.1786, G loss: 5.5713\n",
      "[1524/1762] D loss: 0.6250, G loss: 4.2320\n",
      "[1604/1762] D loss: 0.5834, G loss: 5.2119\n",
      "[1684/1762] D loss: 0.6043, G loss: 3.2422\n",
      "[1762/1762] D loss: 0.2806, G loss: 4.0410\n",
      "train error: \n",
      " D loss: 0.388737, G loss: 5.387533, D accuracy: 92.0%, cell accuracy: 99.5%, board accuracy: 35.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.424237, G loss: 5.272276, D accuracy: 90.9%, cell accuracy: 99.5%, board accuracy: 34.8% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6097, G loss: 3.6239\n",
      "[84/1762] D loss: 0.3589, G loss: 7.4365\n",
      "[164/1762] D loss: 0.8642, G loss: 2.5428\n",
      "[244/1762] D loss: 0.2616, G loss: 3.5954\n",
      "[324/1762] D loss: 0.0678, G loss: 8.0326\n",
      "[404/1762] D loss: 0.1153, G loss: 5.4770\n",
      "[484/1762] D loss: 0.6326, G loss: 4.3696\n",
      "[564/1762] D loss: 0.7145, G loss: 3.7053\n",
      "[644/1762] D loss: 0.6191, G loss: 4.8495\n",
      "[724/1762] D loss: 0.0616, G loss: 4.2249\n",
      "[804/1762] D loss: 0.4334, G loss: 4.7494\n",
      "[884/1762] D loss: 0.2349, G loss: 4.1227\n",
      "[964/1762] D loss: 0.4466, G loss: 4.7230\n",
      "[1044/1762] D loss: 0.3120, G loss: 3.3047\n",
      "[1124/1762] D loss: 0.3963, G loss: 5.4326\n",
      "[1204/1762] D loss: 0.4583, G loss: 5.7701\n",
      "[1284/1762] D loss: 0.0717, G loss: 6.4000\n",
      "[1364/1762] D loss: 0.5479, G loss: 4.5890\n",
      "[1444/1762] D loss: 0.1525, G loss: 7.7005\n",
      "[1524/1762] D loss: 0.0940, G loss: 5.7890\n",
      "[1604/1762] D loss: 0.2250, G loss: 5.8522\n",
      "[1684/1762] D loss: 0.0733, G loss: 7.6863\n",
      "[1762/1762] D loss: 0.0645, G loss: 4.5444\n",
      "train error: \n",
      " D loss: 0.393670, G loss: 5.036530, D accuracy: 92.7%, cell accuracy: 99.5%, board accuracy: 33.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.412038, G loss: 4.722043, D accuracy: 91.5%, cell accuracy: 99.4%, board accuracy: 31.6% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8784, G loss: 3.6085\n",
      "[84/1762] D loss: 1.4760, G loss: 0.4453\n",
      "[164/1762] D loss: 0.4168, G loss: 5.9281\n",
      "[244/1762] D loss: 0.0228, G loss: 6.2991\n",
      "[324/1762] D loss: 0.4443, G loss: 4.6707\n",
      "[404/1762] D loss: 0.6568, G loss: 3.6956\n",
      "[484/1762] D loss: 0.6562, G loss: 3.2014\n",
      "[564/1762] D loss: 0.2876, G loss: 4.7553\n",
      "[644/1762] D loss: 0.0888, G loss: 5.0165\n",
      "[724/1762] D loss: 0.2172, G loss: 6.6491\n",
      "[804/1762] D loss: 0.7746, G loss: 3.1636\n",
      "[884/1762] D loss: 0.6900, G loss: 4.4822\n",
      "[964/1762] D loss: 0.1292, G loss: 4.3914\n",
      "[1044/1762] D loss: 0.2484, G loss: 6.4883\n",
      "[1124/1762] D loss: 0.4393, G loss: 3.6594\n",
      "[1204/1762] D loss: 0.7381, G loss: 2.7705\n",
      "[1284/1762] D loss: 0.5053, G loss: 3.5877\n",
      "[1364/1762] D loss: 0.0440, G loss: 7.3424\n",
      "[1444/1762] D loss: 0.9779, G loss: 3.1937\n",
      "[1524/1762] D loss: 0.3286, G loss: 3.8263\n",
      "[1604/1762] D loss: 0.6479, G loss: 3.8072\n",
      "[1684/1762] D loss: 0.2522, G loss: 6.0436\n",
      "[1762/1762] D loss: 0.0606, G loss: 9.5281\n",
      "train error: \n",
      " D loss: 0.310394, G loss: 6.175847, D accuracy: 93.3%, cell accuracy: 99.5%, board accuracy: 31.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.367363, G loss: 6.041381, D accuracy: 91.5%, cell accuracy: 99.4%, board accuracy: 30.2% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0498, G loss: 6.7583\n",
      "[84/1762] D loss: 0.4776, G loss: 5.2518\n",
      "[164/1762] D loss: 0.1766, G loss: 6.9205\n",
      "[244/1762] D loss: 0.5889, G loss: 4.7142\n",
      "[324/1762] D loss: 0.8982, G loss: 6.8055\n",
      "[404/1762] D loss: 0.1019, G loss: 7.0192\n",
      "[484/1762] D loss: 0.2022, G loss: 6.3729\n",
      "[564/1762] D loss: 0.3035, G loss: 6.0693\n",
      "[644/1762] D loss: 0.1158, G loss: 8.5468\n",
      "[724/1762] D loss: 0.6245, G loss: 7.1194\n",
      "[804/1762] D loss: 0.0988, G loss: 8.3840\n",
      "[884/1762] D loss: 0.3666, G loss: 5.9444\n",
      "[964/1762] D loss: 0.3633, G loss: 5.9542\n",
      "[1044/1762] D loss: 0.0255, G loss: 6.3486\n",
      "[1124/1762] D loss: 0.9748, G loss: 2.8607\n",
      "[1204/1762] D loss: 0.0404, G loss: 6.9087\n",
      "[1284/1762] D loss: 1.1000, G loss: 3.4185\n",
      "[1364/1762] D loss: 0.0370, G loss: 6.3511\n",
      "[1444/1762] D loss: 0.1871, G loss: 3.4627\n",
      "[1524/1762] D loss: 0.0572, G loss: 5.3570\n",
      "[1604/1762] D loss: 0.1075, G loss: 6.6654\n",
      "[1684/1762] D loss: 0.8187, G loss: 3.6716\n",
      "[1762/1762] D loss: 0.0340, G loss: 6.2831\n",
      "train error: \n",
      " D loss: 0.389960, G loss: 5.524548, D accuracy: 91.0%, cell accuracy: 99.5%, board accuracy: 34.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.427852, G loss: 5.241826, D accuracy: 89.3%, cell accuracy: 99.5%, board accuracy: 33.9% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0229, G loss: 4.8170\n",
      "[84/1762] D loss: 0.4724, G loss: 4.0440\n",
      "[164/1762] D loss: 0.0463, G loss: 7.1700\n",
      "[244/1762] D loss: 0.5245, G loss: 2.5098\n",
      "[324/1762] D loss: 0.5377, G loss: 7.9334\n",
      "[404/1762] D loss: 0.6546, G loss: 7.0089\n",
      "[484/1762] D loss: 0.0433, G loss: 8.0927\n",
      "[564/1762] D loss: 0.6733, G loss: 5.5984\n",
      "[644/1762] D loss: 0.6428, G loss: 5.6143\n",
      "[724/1762] D loss: 0.1226, G loss: 6.0148\n",
      "[804/1762] D loss: 0.6106, G loss: 3.4292\n",
      "[884/1762] D loss: 0.5241, G loss: 5.2009\n",
      "[964/1762] D loss: 0.0496, G loss: 5.1697\n",
      "[1044/1762] D loss: 0.1880, G loss: 7.5228\n",
      "[1124/1762] D loss: 0.8807, G loss: 3.1181\n",
      "[1204/1762] D loss: 0.1160, G loss: 4.6613\n",
      "[1284/1762] D loss: 0.3122, G loss: 8.9505\n",
      "[1364/1762] D loss: 0.3496, G loss: 6.7741\n",
      "[1444/1762] D loss: 0.6469, G loss: 7.5520\n",
      "[1524/1762] D loss: 0.1548, G loss: 5.4843\n",
      "[1604/1762] D loss: 0.6371, G loss: 8.1052\n",
      "[1684/1762] D loss: 0.1150, G loss: 6.0430\n",
      "[1762/1762] D loss: 1.5070, G loss: 1.5212\n",
      "train error: \n",
      " D loss: 0.321215, G loss: 5.682862, D accuracy: 93.0%, cell accuracy: 99.5%, board accuracy: 37.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.352850, G loss: 5.334593, D accuracy: 91.8%, cell accuracy: 99.5%, board accuracy: 35.2% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7006, G loss: 3.6050\n",
      "[84/1762] D loss: 0.0431, G loss: 9.4485\n",
      "[164/1762] D loss: 0.9951, G loss: 3.7028\n",
      "[244/1762] D loss: 0.4185, G loss: 5.0061\n",
      "[324/1762] D loss: 0.7126, G loss: 3.8561\n",
      "[404/1762] D loss: 0.5308, G loss: 5.5771\n",
      "[484/1762] D loss: 0.0429, G loss: 6.0834\n",
      "[564/1762] D loss: 0.7766, G loss: 4.8365\n",
      "[644/1762] D loss: 0.6086, G loss: 7.7747\n",
      "[724/1762] D loss: 0.1695, G loss: 8.3411\n",
      "[804/1762] D loss: 0.0312, G loss: 7.4307\n",
      "[884/1762] D loss: 0.1096, G loss: 5.2715\n",
      "[964/1762] D loss: 0.4214, G loss: 4.4133\n",
      "[1044/1762] D loss: 0.0921, G loss: 7.2735\n",
      "[1124/1762] D loss: 0.3955, G loss: 5.0368\n",
      "[1204/1762] D loss: 0.5842, G loss: 4.0977\n",
      "[1284/1762] D loss: 0.0089, G loss: 7.1112\n",
      "[1364/1762] D loss: 0.0479, G loss: 9.5869\n",
      "[1444/1762] D loss: 0.0416, G loss: 10.6546\n",
      "[1524/1762] D loss: 0.0782, G loss: 7.3607\n",
      "[1604/1762] D loss: 1.1871, G loss: 3.1021\n",
      "[1684/1762] D loss: 1.3566, G loss: 1.7342\n",
      "[1762/1762] D loss: 0.0610, G loss: 6.7840\n",
      "train error: \n",
      " D loss: 0.385512, G loss: 4.444632, D accuracy: 92.5%, cell accuracy: 99.5%, board accuracy: 42.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.409115, G loss: 4.317693, D accuracy: 91.0%, cell accuracy: 99.5%, board accuracy: 36.8% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1202, G loss: 7.2303\n",
      "[84/1762] D loss: 0.1437, G loss: 7.4005\n",
      "[164/1762] D loss: 0.6076, G loss: 1.7594\n",
      "[244/1762] D loss: 1.5163, G loss: 3.4249\n",
      "[324/1762] D loss: 0.0497, G loss: 5.0431\n",
      "[404/1762] D loss: 1.5549, G loss: 3.3942\n",
      "[484/1762] D loss: 1.1773, G loss: 2.6426\n",
      "[564/1762] D loss: 0.6767, G loss: 5.1402\n",
      "[644/1762] D loss: 0.0672, G loss: 9.9320\n",
      "[724/1762] D loss: 0.1776, G loss: 6.3381\n",
      "[804/1762] D loss: 0.0205, G loss: 7.4220\n",
      "[884/1762] D loss: 0.6774, G loss: 6.9959\n",
      "[964/1762] D loss: 0.3214, G loss: 4.0876\n",
      "[1044/1762] D loss: 0.1738, G loss: 7.3980\n",
      "[1124/1762] D loss: 0.2670, G loss: 7.1150\n",
      "[1204/1762] D loss: 0.0698, G loss: 7.2436\n",
      "[1284/1762] D loss: 0.4324, G loss: 8.1242\n",
      "[1364/1762] D loss: 0.1058, G loss: 6.4101\n",
      "[1444/1762] D loss: 0.0742, G loss: 7.3809\n",
      "[1524/1762] D loss: 0.0585, G loss: 8.2224\n",
      "[1604/1762] D loss: 0.3051, G loss: 8.9195\n",
      "[1684/1762] D loss: 1.0211, G loss: 5.0143\n",
      "[1762/1762] D loss: 0.1555, G loss: 8.6589\n",
      "train error: \n",
      " D loss: 0.325959, G loss: 5.981369, D accuracy: 93.6%, cell accuracy: 99.5%, board accuracy: 34.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.364680, G loss: 5.541729, D accuracy: 91.7%, cell accuracy: 99.4%, board accuracy: 33.4% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0719, G loss: 4.2183\n",
      "[84/1762] D loss: 0.2834, G loss: 8.0708\n",
      "[164/1762] D loss: 0.6417, G loss: 3.8595\n",
      "[244/1762] D loss: 0.5919, G loss: 2.0798\n",
      "[324/1762] D loss: 0.3757, G loss: 7.9329\n",
      "[404/1762] D loss: 1.4250, G loss: 2.7096\n",
      "[484/1762] D loss: 0.8155, G loss: 2.7815\n",
      "[564/1762] D loss: 0.2726, G loss: 4.9659\n",
      "[644/1762] D loss: 0.0062, G loss: 9.3072\n",
      "[724/1762] D loss: 0.0333, G loss: 6.6337\n",
      "[804/1762] D loss: 0.1285, G loss: 4.9796\n",
      "[884/1762] D loss: 0.0184, G loss: 7.9716\n",
      "[964/1762] D loss: 0.0315, G loss: 9.6284\n",
      "[1044/1762] D loss: 0.4915, G loss: 6.7944\n",
      "[1124/1762] D loss: 0.1534, G loss: 5.3795\n",
      "[1204/1762] D loss: 0.0719, G loss: 5.9502\n",
      "[1284/1762] D loss: 0.0701, G loss: 9.2873\n",
      "[1364/1762] D loss: 0.1442, G loss: 8.4471\n",
      "[1444/1762] D loss: 0.1401, G loss: 5.8781\n",
      "[1524/1762] D loss: 0.0416, G loss: 8.4558\n",
      "[1604/1762] D loss: 0.1289, G loss: 3.7859\n",
      "[1684/1762] D loss: 0.1017, G loss: 7.2002\n",
      "[1762/1762] D loss: 0.0060, G loss: 8.4924\n",
      "train error: \n",
      " D loss: 0.355629, G loss: 6.705846, D accuracy: 92.3%, cell accuracy: 99.5%, board accuracy: 41.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.382514, G loss: 6.521680, D accuracy: 92.0%, cell accuracy: 99.4%, board accuracy: 37.7% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1994, G loss: 6.0198\n",
      "[84/1762] D loss: 1.0185, G loss: 3.1345\n",
      "[164/1762] D loss: 0.0585, G loss: 7.3609\n",
      "[244/1762] D loss: 0.4280, G loss: 9.3805\n",
      "[324/1762] D loss: 0.3131, G loss: 7.1920\n",
      "[404/1762] D loss: 0.3730, G loss: 7.2629\n",
      "[484/1762] D loss: 0.0039, G loss: 10.6533\n",
      "[564/1762] D loss: 0.1070, G loss: 7.7339\n",
      "[644/1762] D loss: 0.6500, G loss: 7.3286\n",
      "[724/1762] D loss: 0.5909, G loss: 9.1651\n",
      "[804/1762] D loss: 0.5972, G loss: 7.2398\n",
      "[884/1762] D loss: 0.1596, G loss: 10.5341\n",
      "[964/1762] D loss: 0.1861, G loss: 5.3874\n",
      "[1044/1762] D loss: 0.4792, G loss: 4.3487\n",
      "[1124/1762] D loss: 0.1861, G loss: 6.0185\n",
      "[1204/1762] D loss: 0.1626, G loss: 11.7277\n",
      "[1284/1762] D loss: 0.1480, G loss: 9.6676\n",
      "[1364/1762] D loss: 0.0517, G loss: 6.0396\n",
      "[1444/1762] D loss: 0.6184, G loss: 4.6187\n",
      "[1524/1762] D loss: 0.9918, G loss: 4.2519\n",
      "[1604/1762] D loss: 0.3821, G loss: 6.0787\n",
      "[1684/1762] D loss: 0.0365, G loss: 9.2984\n",
      "[1762/1762] D loss: 0.5576, G loss: 1.3921\n",
      "train error: \n",
      " D loss: 0.356143, G loss: 5.366191, D accuracy: 91.3%, cell accuracy: 99.4%, board accuracy: 37.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.349337, G loss: 5.427453, D accuracy: 91.4%, cell accuracy: 99.4%, board accuracy: 33.2% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0383, G loss: 6.8463\n",
      "[84/1762] D loss: 0.7330, G loss: 3.5031\n",
      "[164/1762] D loss: 0.3545, G loss: 5.4726\n",
      "[244/1762] D loss: 0.0826, G loss: 11.9895\n",
      "[324/1762] D loss: 0.6251, G loss: 4.0617\n",
      "[404/1762] D loss: 0.2098, G loss: 7.8686\n",
      "[484/1762] D loss: 0.6218, G loss: 5.1864\n",
      "[564/1762] D loss: 0.0155, G loss: 6.1232\n",
      "[644/1762] D loss: 0.5411, G loss: 5.8319\n",
      "[724/1762] D loss: 0.2162, G loss: 7.2254\n",
      "[804/1762] D loss: 0.3502, G loss: 7.6432\n",
      "[884/1762] D loss: 0.0506, G loss: 7.8167\n",
      "[964/1762] D loss: 0.0802, G loss: 7.0677\n",
      "[1044/1762] D loss: 0.1247, G loss: 4.7755\n",
      "[1124/1762] D loss: 0.1315, G loss: 4.9741\n",
      "[1204/1762] D loss: 0.0694, G loss: 8.8419\n",
      "[1284/1762] D loss: 0.9082, G loss: 5.1963\n",
      "[1364/1762] D loss: 0.0527, G loss: 13.7538\n",
      "[1444/1762] D loss: 0.0845, G loss: 11.0399\n",
      "[1524/1762] D loss: 0.1175, G loss: 7.6537\n",
      "[1604/1762] D loss: 0.0451, G loss: 9.2430\n",
      "[1684/1762] D loss: 0.0159, G loss: 9.0571\n",
      "[1762/1762] D loss: 0.0074, G loss: 7.8891\n",
      "train error: \n",
      " D loss: 0.440247, G loss: 6.569361, D accuracy: 89.7%, cell accuracy: 99.5%, board accuracy: 40.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.527938, G loss: 6.428108, D accuracy: 87.6%, cell accuracy: 99.4%, board accuracy: 38.4% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0262, G loss: 5.5685\n",
      "[84/1762] D loss: 0.0073, G loss: 8.7794\n",
      "[164/1762] D loss: 0.4600, G loss: 4.8005\n",
      "[244/1762] D loss: 0.3919, G loss: 4.0900\n",
      "[324/1762] D loss: 0.1556, G loss: 7.1115\n",
      "[404/1762] D loss: 0.0720, G loss: 7.1213\n",
      "[484/1762] D loss: 0.0412, G loss: 7.0190\n",
      "[564/1762] D loss: 1.1559, G loss: 3.7199\n",
      "[644/1762] D loss: 0.0226, G loss: 7.5174\n",
      "[724/1762] D loss: 0.3480, G loss: 6.9274\n",
      "[804/1762] D loss: 0.5418, G loss: 4.9502\n",
      "[884/1762] D loss: 0.2745, G loss: 5.7367\n",
      "[964/1762] D loss: 0.4631, G loss: 4.6784\n",
      "[1044/1762] D loss: 0.0281, G loss: 13.4071\n",
      "[1124/1762] D loss: 0.6533, G loss: 3.9626\n",
      "[1204/1762] D loss: 0.1978, G loss: 10.0494\n",
      "[1284/1762] D loss: 0.0653, G loss: 8.1309\n",
      "[1364/1762] D loss: 0.4475, G loss: 7.0638\n",
      "[1444/1762] D loss: 0.0194, G loss: 9.6309\n",
      "[1524/1762] D loss: 0.2697, G loss: 8.0008\n",
      "[1604/1762] D loss: 0.0581, G loss: 8.0661\n",
      "[1684/1762] D loss: 0.2346, G loss: 5.0832\n",
      "[1762/1762] D loss: 0.8781, G loss: 3.1835\n",
      "train error: \n",
      " D loss: 0.383997, G loss: 6.703969, D accuracy: 90.5%, cell accuracy: 99.5%, board accuracy: 34.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.360703, G loss: 6.466303, D accuracy: 91.0%, cell accuracy: 99.4%, board accuracy: 31.8% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6684, G loss: 6.3701\n",
      "[84/1762] D loss: 0.5100, G loss: 4.2399\n",
      "[164/1762] D loss: 0.1172, G loss: 4.2329\n",
      "[244/1762] D loss: 0.4059, G loss: 4.4257\n",
      "[324/1762] D loss: 0.1135, G loss: 7.2969\n",
      "[404/1762] D loss: 0.0385, G loss: 8.7166\n",
      "[484/1762] D loss: 0.2733, G loss: 10.2785\n",
      "[564/1762] D loss: 0.2635, G loss: 6.8036\n",
      "[644/1762] D loss: 0.1205, G loss: 8.2540\n",
      "[724/1762] D loss: 0.3459, G loss: 4.3555\n",
      "[804/1762] D loss: 0.6650, G loss: 4.1054\n",
      "[884/1762] D loss: 0.0599, G loss: 7.7864\n",
      "[964/1762] D loss: 0.0059, G loss: 7.0409\n",
      "[1044/1762] D loss: 1.7336, G loss: 3.7226\n",
      "[1124/1762] D loss: 0.1568, G loss: 4.2873\n",
      "[1204/1762] D loss: 0.0585, G loss: 7.6861\n",
      "[1284/1762] D loss: 0.1450, G loss: 11.2672\n",
      "[1364/1762] D loss: 0.0787, G loss: 8.8940\n",
      "[1444/1762] D loss: 0.0667, G loss: 7.0617\n",
      "[1524/1762] D loss: 0.0558, G loss: 7.7116\n",
      "[1604/1762] D loss: 0.0529, G loss: 11.5570\n",
      "[1684/1762] D loss: 0.0491, G loss: 7.9507\n",
      "[1762/1762] D loss: 0.0185, G loss: 4.6363\n",
      "train error: \n",
      " D loss: 0.629634, G loss: 4.564889, D accuracy: 88.0%, cell accuracy: 99.5%, board accuracy: 42.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.714489, G loss: 4.325282, D accuracy: 86.7%, cell accuracy: 99.5%, board accuracy: 39.8% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0356, G loss: 4.2870\n",
      "[84/1762] D loss: 0.5739, G loss: 3.1663\n",
      "[164/1762] D loss: 0.1985, G loss: 8.8029\n",
      "[244/1762] D loss: 0.0059, G loss: 6.7800\n",
      "[324/1762] D loss: 0.2997, G loss: 7.5976\n",
      "[404/1762] D loss: 1.0828, G loss: 6.5706\n",
      "[484/1762] D loss: 0.2527, G loss: 8.4484\n",
      "[564/1762] D loss: 0.0138, G loss: 9.0263\n",
      "[644/1762] D loss: 0.0448, G loss: 13.6137\n",
      "[724/1762] D loss: 0.0059, G loss: 10.4082\n",
      "[804/1762] D loss: 0.2783, G loss: 6.1913\n",
      "[884/1762] D loss: 0.0357, G loss: 6.9924\n",
      "[964/1762] D loss: 1.1826, G loss: 6.5169\n",
      "[1044/1762] D loss: 0.0661, G loss: 10.0908\n",
      "[1124/1762] D loss: 0.1861, G loss: 10.4466\n",
      "[1204/1762] D loss: 0.4079, G loss: 3.8209\n",
      "[1284/1762] D loss: 0.0130, G loss: 8.4509\n",
      "[1364/1762] D loss: 0.2461, G loss: 10.0349\n",
      "[1444/1762] D loss: 0.0074, G loss: 9.1656\n",
      "[1524/1762] D loss: 0.0994, G loss: 7.5745\n",
      "[1604/1762] D loss: 0.2195, G loss: 7.5931\n",
      "[1684/1762] D loss: 0.1002, G loss: 5.9223\n",
      "[1762/1762] D loss: 0.0300, G loss: 12.1415\n",
      "train error: \n",
      " D loss: 0.286281, G loss: 7.488764, D accuracy: 94.0%, cell accuracy: 99.5%, board accuracy: 31.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.352146, G loss: 7.128869, D accuracy: 92.6%, cell accuracy: 99.4%, board accuracy: 29.5% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5783, G loss: 7.0744\n",
      "[84/1762] D loss: 0.0123, G loss: 11.5656\n",
      "[164/1762] D loss: 1.0470, G loss: 7.0928\n",
      "[244/1762] D loss: 0.4532, G loss: 4.1552\n",
      "[324/1762] D loss: 0.2302, G loss: 6.3983\n",
      "[404/1762] D loss: 0.1461, G loss: 5.6190\n",
      "[484/1762] D loss: 0.0279, G loss: 7.9841\n",
      "[564/1762] D loss: 0.0388, G loss: 11.3823\n",
      "[644/1762] D loss: 0.1570, G loss: 7.8290\n",
      "[724/1762] D loss: 0.0783, G loss: 10.3472\n",
      "[804/1762] D loss: 0.3242, G loss: 7.4158\n",
      "[884/1762] D loss: 0.1053, G loss: 5.2447\n",
      "[964/1762] D loss: 0.0695, G loss: 9.9441\n",
      "[1044/1762] D loss: 0.3459, G loss: 6.5446\n",
      "[1124/1762] D loss: 0.1765, G loss: 9.0841\n",
      "[1204/1762] D loss: 0.0937, G loss: 7.3663\n",
      "[1284/1762] D loss: 0.6567, G loss: 4.5100\n",
      "[1364/1762] D loss: 0.0108, G loss: 9.9666\n",
      "[1444/1762] D loss: 0.3396, G loss: 8.7584\n",
      "[1524/1762] D loss: 0.3026, G loss: 9.5152\n",
      "[1604/1762] D loss: 0.0191, G loss: 9.2510\n",
      "[1684/1762] D loss: 0.1154, G loss: 6.2223\n",
      "[1762/1762] D loss: 0.0229, G loss: 8.7522\n",
      "train error: \n",
      " D loss: 0.208190, G loss: 7.904960, D accuracy: 95.4%, cell accuracy: 99.4%, board accuracy: 21.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.216532, G loss: 7.295118, D accuracy: 95.2%, cell accuracy: 99.4%, board accuracy: 23.9% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3598, G loss: 4.8634\n",
      "[84/1762] D loss: 0.1534, G loss: 8.9944\n",
      "[164/1762] D loss: 0.0237, G loss: 10.2513\n",
      "[244/1762] D loss: 0.9973, G loss: 7.4013\n",
      "[324/1762] D loss: 0.6576, G loss: 4.7619\n",
      "[404/1762] D loss: 0.0461, G loss: 7.4276\n",
      "[484/1762] D loss: 0.0612, G loss: 8.9090\n",
      "[564/1762] D loss: 0.0999, G loss: 7.1922\n",
      "[644/1762] D loss: 0.3560, G loss: 5.3566\n",
      "[724/1762] D loss: 0.2161, G loss: 4.3361\n",
      "[804/1762] D loss: 0.1463, G loss: 6.9874\n",
      "[884/1762] D loss: 0.7261, G loss: 7.8079\n",
      "[964/1762] D loss: 0.4041, G loss: 10.5375\n",
      "[1044/1762] D loss: 0.0209, G loss: 6.5863\n",
      "[1124/1762] D loss: 0.0605, G loss: 9.3021\n",
      "[1204/1762] D loss: 0.4668, G loss: 9.1426\n",
      "[1284/1762] D loss: 1.0588, G loss: 6.1279\n",
      "[1364/1762] D loss: 0.0350, G loss: 9.6500\n",
      "[1444/1762] D loss: 0.4949, G loss: 4.6376\n",
      "[1524/1762] D loss: 0.0023, G loss: 9.7190\n",
      "[1604/1762] D loss: 0.0042, G loss: 8.9470\n",
      "[1684/1762] D loss: 0.2575, G loss: 9.0445\n",
      "[1762/1762] D loss: 0.0662, G loss: 3.6874\n",
      "train error: \n",
      " D loss: 0.245359, G loss: 6.717325, D accuracy: 94.0%, cell accuracy: 99.5%, board accuracy: 40.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.269784, G loss: 6.434628, D accuracy: 93.8%, cell accuracy: 99.5%, board accuracy: 39.1% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0561, G loss: 9.9005\n",
      "[84/1762] D loss: 0.0166, G loss: 7.9651\n",
      "[164/1762] D loss: 0.3755, G loss: 5.7849\n",
      "[244/1762] D loss: 0.0216, G loss: 9.6979\n",
      "[324/1762] D loss: 0.0444, G loss: 10.5294\n",
      "[404/1762] D loss: 0.1294, G loss: 13.5331\n",
      "[484/1762] D loss: 0.5987, G loss: 7.9083\n",
      "[564/1762] D loss: 0.8518, G loss: 3.9065\n",
      "[644/1762] D loss: 0.0214, G loss: 7.0287\n",
      "[724/1762] D loss: 0.4889, G loss: 3.2639\n",
      "[804/1762] D loss: 0.0267, G loss: 4.4605\n",
      "[884/1762] D loss: 0.0885, G loss: 7.4178\n",
      "[964/1762] D loss: 0.3821, G loss: 7.5858\n",
      "[1044/1762] D loss: 0.3623, G loss: 7.6698\n",
      "[1124/1762] D loss: 0.0208, G loss: 10.9497\n",
      "[1204/1762] D loss: 0.0114, G loss: 8.9398\n",
      "[1284/1762] D loss: 0.0066, G loss: 9.7412\n",
      "[1364/1762] D loss: 0.5088, G loss: 5.9624\n",
      "[1444/1762] D loss: 1.3952, G loss: 0.8296\n",
      "[1524/1762] D loss: 0.7004, G loss: 6.1546\n",
      "[1604/1762] D loss: 0.6080, G loss: 3.3095\n",
      "[1684/1762] D loss: 0.2137, G loss: 6.8319\n",
      "[1762/1762] D loss: 0.0697, G loss: 5.6588\n",
      "train error: \n",
      " D loss: 0.179031, G loss: 8.428829, D accuracy: 96.3%, cell accuracy: 99.5%, board accuracy: 34.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.196116, G loss: 7.984791, D accuracy: 95.8%, cell accuracy: 99.4%, board accuracy: 31.4% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0854, G loss: 4.1333\n",
      "[84/1762] D loss: 0.0046, G loss: 11.1670\n",
      "[164/1762] D loss: 0.1037, G loss: 7.6080\n",
      "[244/1762] D loss: 0.0737, G loss: 8.5160\n",
      "[324/1762] D loss: 0.0164, G loss: 11.5018\n",
      "[404/1762] D loss: 0.0155, G loss: 10.1693\n",
      "[484/1762] D loss: 0.1286, G loss: 7.9936\n",
      "[564/1762] D loss: 0.8575, G loss: 7.3612\n",
      "[644/1762] D loss: 0.9028, G loss: 11.9194\n",
      "[724/1762] D loss: 0.1863, G loss: 7.9001\n",
      "[804/1762] D loss: 0.3851, G loss: 8.1003\n",
      "[884/1762] D loss: 0.2635, G loss: 8.1538\n",
      "[964/1762] D loss: 0.5896, G loss: 6.3534\n",
      "[1044/1762] D loss: 0.0567, G loss: 8.0821\n",
      "[1124/1762] D loss: 0.0446, G loss: 10.9342\n",
      "[1204/1762] D loss: 0.0140, G loss: 8.0059\n",
      "[1284/1762] D loss: 0.1530, G loss: 9.3108\n",
      "[1364/1762] D loss: 0.1817, G loss: 7.5582\n",
      "[1444/1762] D loss: 0.1167, G loss: 6.0827\n",
      "[1524/1762] D loss: 0.0015, G loss: 10.3448\n",
      "[1604/1762] D loss: 0.0719, G loss: 10.5709\n",
      "[1684/1762] D loss: 0.0353, G loss: 13.7033\n",
      "[1762/1762] D loss: 0.1486, G loss: 4.5450\n",
      "train error: \n",
      " D loss: 0.254193, G loss: 7.030513, D accuracy: 94.9%, cell accuracy: 99.5%, board accuracy: 35.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.288010, G loss: 6.555605, D accuracy: 93.5%, cell accuracy: 99.4%, board accuracy: 33.0% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0109, G loss: 9.2254\n",
      "[84/1762] D loss: 0.0783, G loss: 4.6425\n",
      "[164/1762] D loss: 1.1167, G loss: 7.1435\n",
      "[244/1762] D loss: 0.0522, G loss: 9.6304\n",
      "[324/1762] D loss: 0.4600, G loss: 8.0425\n",
      "[404/1762] D loss: 0.1083, G loss: 8.8397\n",
      "[484/1762] D loss: 0.0442, G loss: 8.3367\n",
      "[564/1762] D loss: 0.6697, G loss: 5.5083\n",
      "[644/1762] D loss: 0.1174, G loss: 9.3201\n",
      "[724/1762] D loss: 0.2578, G loss: 8.5896\n",
      "[804/1762] D loss: 0.0316, G loss: 8.6954\n",
      "[884/1762] D loss: 0.2236, G loss: 6.6808\n",
      "[964/1762] D loss: 0.1422, G loss: 9.6918\n",
      "[1044/1762] D loss: 0.0541, G loss: 11.9350\n",
      "[1124/1762] D loss: 0.0747, G loss: 9.2875\n",
      "[1204/1762] D loss: 0.0384, G loss: 8.4876\n",
      "[1284/1762] D loss: 0.0401, G loss: 7.6297\n",
      "[1364/1762] D loss: 0.0595, G loss: 9.8784\n",
      "[1444/1762] D loss: 0.0280, G loss: 13.3482\n",
      "[1524/1762] D loss: 0.0697, G loss: 12.3683\n",
      "[1604/1762] D loss: 0.1167, G loss: 7.0948\n",
      "[1684/1762] D loss: 0.6838, G loss: 5.3145\n",
      "[1762/1762] D loss: 0.0087, G loss: 11.6586\n",
      "train error: \n",
      " D loss: 0.241744, G loss: 8.011190, D accuracy: 94.6%, cell accuracy: 99.5%, board accuracy: 32.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.277420, G loss: 7.481988, D accuracy: 93.5%, cell accuracy: 99.4%, board accuracy: 30.5% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0114, G loss: 9.3130\n",
      "[84/1762] D loss: 0.0093, G loss: 9.1954\n",
      "[164/1762] D loss: 0.7020, G loss: 4.8292\n",
      "[244/1762] D loss: 0.0229, G loss: 14.2388\n",
      "[324/1762] D loss: 0.0542, G loss: 9.5416\n",
      "[404/1762] D loss: 0.0030, G loss: 14.1396\n",
      "[484/1762] D loss: 0.2628, G loss: 8.4518\n",
      "[564/1762] D loss: 0.0019, G loss: 9.3111\n",
      "[644/1762] D loss: 0.1113, G loss: 13.1156\n",
      "[724/1762] D loss: 0.0486, G loss: 8.3609\n",
      "[804/1762] D loss: 0.2393, G loss: 9.4273\n",
      "[884/1762] D loss: 0.4415, G loss: 4.6886\n",
      "[964/1762] D loss: 0.0540, G loss: 8.5150\n",
      "[1044/1762] D loss: 0.0560, G loss: 7.9657\n",
      "[1124/1762] D loss: 0.3239, G loss: 6.0368\n",
      "[1204/1762] D loss: 0.0353, G loss: 7.0859\n",
      "[1284/1762] D loss: 0.0156, G loss: 11.7516\n",
      "[1364/1762] D loss: 0.0583, G loss: 8.5397\n",
      "[1444/1762] D loss: 0.9232, G loss: 8.0161\n",
      "[1524/1762] D loss: 0.1034, G loss: 7.6649\n",
      "[1604/1762] D loss: 0.5536, G loss: 6.8985\n",
      "[1684/1762] D loss: 0.1016, G loss: 6.8690\n",
      "[1762/1762] D loss: 0.0025, G loss: 22.0044\n",
      "train error: \n",
      " D loss: 0.266827, G loss: 7.880190, D accuracy: 94.4%, cell accuracy: 99.5%, board accuracy: 37.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.258813, G loss: 7.731994, D accuracy: 94.4%, cell accuracy: 99.4%, board accuracy: 33.9% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6655, G loss: 5.4247\n",
      "[84/1762] D loss: 0.4092, G loss: 7.5858\n",
      "[164/1762] D loss: 0.1926, G loss: 9.1901\n",
      "[244/1762] D loss: 0.3116, G loss: 5.9007\n",
      "[324/1762] D loss: 0.6905, G loss: 10.0695\n",
      "[404/1762] D loss: 0.3754, G loss: 5.0596\n",
      "[484/1762] D loss: 0.0241, G loss: 12.1322\n",
      "[564/1762] D loss: 0.4493, G loss: 8.2560\n",
      "[644/1762] D loss: 0.7410, G loss: 7.6224\n",
      "[724/1762] D loss: 0.0083, G loss: 10.0500\n",
      "[804/1762] D loss: 0.3797, G loss: 5.9708\n",
      "[884/1762] D loss: 0.0298, G loss: 6.6996\n",
      "[964/1762] D loss: 0.0074, G loss: 20.1153\n",
      "[1044/1762] D loss: 0.5560, G loss: 7.3695\n",
      "[1124/1762] D loss: 0.0355, G loss: 7.5783\n",
      "[1204/1762] D loss: 0.0197, G loss: 11.4889\n",
      "[1284/1762] D loss: 0.1213, G loss: 12.5587\n",
      "[1364/1762] D loss: 0.1133, G loss: 7.8444\n",
      "[1444/1762] D loss: 0.0340, G loss: 6.8417\n",
      "[1524/1762] D loss: 0.9806, G loss: 7.3716\n",
      "[1604/1762] D loss: 0.3530, G loss: 6.2488\n",
      "[1684/1762] D loss: 0.0162, G loss: 9.9348\n",
      "[1762/1762] D loss: 0.0048, G loss: 14.5724\n",
      "train error: \n",
      " D loss: 0.265874, G loss: 6.227143, D accuracy: 93.5%, cell accuracy: 99.5%, board accuracy: 38.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.271262, G loss: 6.043622, D accuracy: 93.4%, cell accuracy: 99.4%, board accuracy: 34.8% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4394, G loss: 4.2571\n",
      "[84/1762] D loss: 0.7406, G loss: 9.4796\n",
      "[164/1762] D loss: 0.3537, G loss: 7.0767\n",
      "[244/1762] D loss: 0.0101, G loss: 10.5420\n",
      "[324/1762] D loss: 0.0619, G loss: 5.1649\n",
      "[404/1762] D loss: 0.0124, G loss: 6.6979\n",
      "[484/1762] D loss: 1.0156, G loss: 3.9160\n",
      "[564/1762] D loss: 0.1077, G loss: 6.7571\n",
      "[644/1762] D loss: 0.4781, G loss: 6.4061\n",
      "[724/1762] D loss: 0.5069, G loss: 6.7085\n",
      "[804/1762] D loss: 0.1360, G loss: 6.6633\n",
      "[884/1762] D loss: 0.0145, G loss: 12.1554\n",
      "[964/1762] D loss: 0.2471, G loss: 8.2946\n",
      "[1044/1762] D loss: 0.0773, G loss: 5.0670\n",
      "[1124/1762] D loss: 0.0049, G loss: 8.3781\n",
      "[1204/1762] D loss: 0.0448, G loss: 7.7966\n",
      "[1284/1762] D loss: 0.0133, G loss: 11.0042\n",
      "[1364/1762] D loss: 0.0379, G loss: 8.6850\n",
      "[1444/1762] D loss: 0.5293, G loss: 6.6765\n",
      "[1524/1762] D loss: 0.0046, G loss: 9.5430\n",
      "[1604/1762] D loss: 0.0399, G loss: 10.0629\n",
      "[1684/1762] D loss: 0.0649, G loss: 5.6471\n",
      "[1762/1762] D loss: 0.0476, G loss: 10.4727\n",
      "train error: \n",
      " D loss: 0.202252, G loss: 8.675447, D accuracy: 96.0%, cell accuracy: 99.5%, board accuracy: 37.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.235638, G loss: 8.212821, D accuracy: 94.9%, cell accuracy: 99.5%, board accuracy: 37.0% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0113, G loss: 9.3414\n",
      "[84/1762] D loss: 0.5450, G loss: 7.4676\n",
      "[164/1762] D loss: 0.1054, G loss: 7.6386\n",
      "[244/1762] D loss: 0.1320, G loss: 7.1357\n",
      "[324/1762] D loss: 0.0173, G loss: 9.9607\n",
      "[404/1762] D loss: 0.5162, G loss: 5.7255\n",
      "[484/1762] D loss: 0.6030, G loss: 4.4932\n",
      "[564/1762] D loss: 0.0404, G loss: 13.2924\n",
      "[644/1762] D loss: 0.0075, G loss: 15.0251\n",
      "[724/1762] D loss: 0.0052, G loss: 7.7984\n",
      "[804/1762] D loss: 0.0496, G loss: 13.9871\n",
      "[884/1762] D loss: 0.0389, G loss: 13.2320\n",
      "[964/1762] D loss: 0.6380, G loss: 5.8153\n",
      "[1044/1762] D loss: 0.8372, G loss: 6.5912\n",
      "[1124/1762] D loss: 0.4759, G loss: 6.7929\n",
      "[1204/1762] D loss: 0.0358, G loss: 9.9232\n",
      "[1284/1762] D loss: 0.0252, G loss: 7.7191\n",
      "[1364/1762] D loss: 0.4805, G loss: 6.8078\n",
      "[1444/1762] D loss: 0.3557, G loss: 5.6806\n",
      "[1524/1762] D loss: 0.0275, G loss: 12.9904\n",
      "[1604/1762] D loss: 0.0623, G loss: 16.9485\n",
      "[1684/1762] D loss: 0.1555, G loss: 14.8303\n",
      "[1762/1762] D loss: 0.4607, G loss: 15.4547\n",
      "train error: \n",
      " D loss: 0.177968, G loss: 10.207644, D accuracy: 95.8%, cell accuracy: 99.5%, board accuracy: 42.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.218371, G loss: 9.791501, D accuracy: 94.7%, cell accuracy: 99.5%, board accuracy: 36.8% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6645, G loss: 10.0194\n",
      "[84/1762] D loss: 0.0524, G loss: 10.4333\n",
      "[164/1762] D loss: 0.4329, G loss: 4.4036\n",
      "[244/1762] D loss: 0.0536, G loss: 5.7415\n",
      "[324/1762] D loss: 0.6044, G loss: 5.4054\n",
      "[404/1762] D loss: 0.0116, G loss: 10.4391\n",
      "[484/1762] D loss: 0.0846, G loss: 7.2701\n",
      "[564/1762] D loss: 0.0114, G loss: 5.2524\n",
      "[644/1762] D loss: 0.0211, G loss: 14.3744\n",
      "[724/1762] D loss: 0.0058, G loss: 13.3632\n",
      "[804/1762] D loss: 0.0045, G loss: 8.2794\n",
      "[884/1762] D loss: 0.0528, G loss: 13.2857\n",
      "[964/1762] D loss: 0.4266, G loss: 7.4486\n",
      "[1044/1762] D loss: 0.1937, G loss: 5.2859\n",
      "[1124/1762] D loss: 0.0452, G loss: 10.3350\n",
      "[1204/1762] D loss: 0.0079, G loss: 9.7851\n",
      "[1284/1762] D loss: 0.4051, G loss: 6.0627\n",
      "[1364/1762] D loss: 0.3503, G loss: 9.0389\n",
      "[1444/1762] D loss: 0.4847, G loss: 13.2432\n",
      "[1524/1762] D loss: 0.0036, G loss: 13.5530\n",
      "[1604/1762] D loss: 0.2532, G loss: 10.6165\n",
      "[1684/1762] D loss: 0.2476, G loss: 10.7996\n",
      "[1762/1762] D loss: 0.0754, G loss: 4.0887\n",
      "train error: \n",
      " D loss: 0.179558, G loss: 9.179218, D accuracy: 95.8%, cell accuracy: 99.5%, board accuracy: 37.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.184402, G loss: 8.825010, D accuracy: 95.3%, cell accuracy: 99.5%, board accuracy: 35.2% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0074, G loss: 7.8955\n",
      "[84/1762] D loss: 0.5142, G loss: 6.4457\n",
      "[164/1762] D loss: 0.0028, G loss: 12.0887\n",
      "[244/1762] D loss: 0.0049, G loss: 10.5723\n",
      "[324/1762] D loss: 0.0067, G loss: 7.9927\n",
      "[404/1762] D loss: 0.1023, G loss: 7.6006\n",
      "[484/1762] D loss: 0.1351, G loss: 8.6660\n",
      "[564/1762] D loss: 0.1456, G loss: 7.8329\n",
      "[644/1762] D loss: 0.0167, G loss: 7.8631\n",
      "[724/1762] D loss: 0.0040, G loss: 8.9169\n",
      "[804/1762] D loss: 0.3000, G loss: 7.0968\n",
      "[884/1762] D loss: 0.0100, G loss: 10.2301\n",
      "[964/1762] D loss: 0.0188, G loss: 14.3271\n",
      "[1044/1762] D loss: 0.0601, G loss: 12.6155\n",
      "[1124/1762] D loss: 0.3185, G loss: 3.4140\n",
      "[1204/1762] D loss: 0.2066, G loss: 8.2474\n",
      "[1284/1762] D loss: 0.2719, G loss: 6.5129\n",
      "[1364/1762] D loss: 0.1749, G loss: 9.5347\n",
      "[1444/1762] D loss: 0.0065, G loss: 14.3485\n",
      "[1524/1762] D loss: 0.0511, G loss: 16.3773\n",
      "[1604/1762] D loss: 0.0347, G loss: 10.1352\n",
      "[1684/1762] D loss: 0.4326, G loss: 8.6982\n",
      "[1762/1762] D loss: 0.0182, G loss: 13.5528\n",
      "train error: \n",
      " D loss: 0.136300, G loss: 10.773580, D accuracy: 97.0%, cell accuracy: 99.5%, board accuracy: 35.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.156139, G loss: 10.104130, D accuracy: 96.2%, cell accuracy: 99.5%, board accuracy: 35.2% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4154, G loss: 5.3148\n",
      "[84/1762] D loss: 0.1415, G loss: 8.8310\n",
      "[164/1762] D loss: 0.0007, G loss: 14.6856\n",
      "[244/1762] D loss: 0.0846, G loss: 10.4509\n",
      "[324/1762] D loss: 0.0237, G loss: 9.3233\n",
      "[404/1762] D loss: 0.0131, G loss: 9.5341\n",
      "[484/1762] D loss: 0.1173, G loss: 12.4817\n",
      "[564/1762] D loss: 0.0212, G loss: 9.2969\n",
      "[644/1762] D loss: 0.1074, G loss: 11.6569\n",
      "[724/1762] D loss: 0.1389, G loss: 10.2163\n",
      "[804/1762] D loss: 0.0065, G loss: 10.6649\n",
      "[884/1762] D loss: 0.0376, G loss: 9.4597\n",
      "[964/1762] D loss: 0.0416, G loss: 10.9942\n",
      "[1044/1762] D loss: 0.0654, G loss: 15.3732\n",
      "[1124/1762] D loss: 1.1447, G loss: 6.5830\n",
      "[1204/1762] D loss: 0.0475, G loss: 13.5399\n",
      "[1284/1762] D loss: 0.1864, G loss: 10.6691\n",
      "[1364/1762] D loss: 0.0918, G loss: 9.9558\n",
      "[1444/1762] D loss: 0.0226, G loss: 11.3754\n",
      "[1524/1762] D loss: 0.0971, G loss: 11.0181\n",
      "[1604/1762] D loss: 0.0184, G loss: 13.9133\n",
      "[1684/1762] D loss: 0.0170, G loss: 6.0167\n",
      "[1762/1762] D loss: 0.1648, G loss: 10.2821\n",
      "train error: \n",
      " D loss: 0.153372, G loss: 9.711354, D accuracy: 96.6%, cell accuracy: 99.5%, board accuracy: 32.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.170045, G loss: 9.295245, D accuracy: 95.6%, cell accuracy: 99.4%, board accuracy: 28.6% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0641, G loss: 5.9995\n",
      "[84/1762] D loss: 0.5779, G loss: 6.2163\n",
      "[164/1762] D loss: 0.0265, G loss: 8.5389\n",
      "[244/1762] D loss: 0.0416, G loss: 9.7607\n",
      "[324/1762] D loss: 0.0020, G loss: 9.5008\n",
      "[404/1762] D loss: 0.0108, G loss: 7.9910\n",
      "[484/1762] D loss: 0.0789, G loss: 7.5193\n",
      "[564/1762] D loss: 0.0643, G loss: 8.5211\n",
      "[644/1762] D loss: 0.5072, G loss: 5.5052\n",
      "[724/1762] D loss: 0.1938, G loss: 9.3686\n",
      "[804/1762] D loss: 0.0048, G loss: 11.0766\n",
      "[884/1762] D loss: 0.2813, G loss: 10.8405\n",
      "[964/1762] D loss: 1.9924, G loss: 14.6858\n",
      "[1044/1762] D loss: 0.0302, G loss: 5.2391\n",
      "[1124/1762] D loss: 0.0129, G loss: 12.2078\n",
      "[1204/1762] D loss: 0.0355, G loss: 14.5506\n",
      "[1284/1762] D loss: 0.0973, G loss: 9.1941\n",
      "[1364/1762] D loss: 0.0041, G loss: 14.1157\n",
      "[1444/1762] D loss: 0.0159, G loss: 11.8245\n",
      "[1524/1762] D loss: 0.2543, G loss: 11.0116\n",
      "[1604/1762] D loss: 0.0270, G loss: 9.8536\n",
      "[1684/1762] D loss: 0.0089, G loss: 14.5234\n",
      "[1762/1762] D loss: 0.0065, G loss: 16.0181\n",
      "train error: \n",
      " D loss: 0.161139, G loss: 10.040896, D accuracy: 96.8%, cell accuracy: 99.5%, board accuracy: 39.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.187010, G loss: 9.585748, D accuracy: 95.8%, cell accuracy: 99.5%, board accuracy: 35.9% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0197, G loss: 11.9863\n",
      "[84/1762] D loss: 0.6233, G loss: 9.6777\n",
      "[164/1762] D loss: 0.0598, G loss: 11.9505\n",
      "[244/1762] D loss: 0.3209, G loss: 8.9453\n",
      "[324/1762] D loss: 0.0217, G loss: 15.5089\n",
      "[404/1762] D loss: 0.0140, G loss: 9.8785\n",
      "[484/1762] D loss: 0.2441, G loss: 11.9223\n",
      "[564/1762] D loss: 0.4034, G loss: 6.4338\n",
      "[644/1762] D loss: 0.0593, G loss: 8.3058\n",
      "[724/1762] D loss: 0.5330, G loss: 3.6803\n",
      "[804/1762] D loss: 0.0224, G loss: 11.1208\n",
      "[884/1762] D loss: 0.0044, G loss: 9.0506\n",
      "[964/1762] D loss: 0.2187, G loss: 10.3684\n",
      "[1044/1762] D loss: 0.0107, G loss: 14.5770\n",
      "[1124/1762] D loss: 0.1372, G loss: 5.7491\n",
      "[1204/1762] D loss: 0.2659, G loss: 5.4734\n",
      "[1284/1762] D loss: 0.0052, G loss: 11.5027\n",
      "[1364/1762] D loss: 0.0200, G loss: 15.0602\n",
      "[1444/1762] D loss: 0.0259, G loss: 11.9460\n",
      "[1524/1762] D loss: 0.0006, G loss: 12.9763\n",
      "[1604/1762] D loss: 0.0417, G loss: 5.8262\n",
      "[1684/1762] D loss: 0.0185, G loss: 20.4544\n",
      "[1762/1762] D loss: 0.0025, G loss: 10.0510\n",
      "train error: \n",
      " D loss: 0.256138, G loss: 7.833037, D accuracy: 94.2%, cell accuracy: 99.5%, board accuracy: 39.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.306147, G loss: 7.294034, D accuracy: 93.1%, cell accuracy: 99.5%, board accuracy: 37.5% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9673, G loss: 5.9314\n",
      "[84/1762] D loss: 0.0540, G loss: 11.7732\n",
      "[164/1762] D loss: 0.1298, G loss: 5.6522\n",
      "[244/1762] D loss: 0.0161, G loss: 9.4923\n",
      "[324/1762] D loss: 0.0236, G loss: 12.2698\n",
      "[404/1762] D loss: 0.0152, G loss: 11.7127\n",
      "[484/1762] D loss: 0.2958, G loss: 16.3238\n",
      "[564/1762] D loss: 0.4108, G loss: 11.2120\n",
      "[644/1762] D loss: 0.0043, G loss: 13.1559\n",
      "[724/1762] D loss: 0.0048, G loss: 12.6433\n",
      "[804/1762] D loss: 0.6914, G loss: 9.6941\n",
      "[884/1762] D loss: 0.1919, G loss: 5.5285\n",
      "[964/1762] D loss: 0.0098, G loss: 15.9079\n",
      "[1044/1762] D loss: 0.0859, G loss: 7.4582\n",
      "[1124/1762] D loss: 0.1101, G loss: 6.4062\n",
      "[1204/1762] D loss: 0.0188, G loss: 8.8929\n",
      "[1284/1762] D loss: 0.0203, G loss: 14.6108\n",
      "[1364/1762] D loss: 0.0807, G loss: 11.0072\n",
      "[1444/1762] D loss: 0.0146, G loss: 9.9766\n",
      "[1524/1762] D loss: 0.0023, G loss: 19.5006\n",
      "[1604/1762] D loss: 0.0569, G loss: 9.4726\n",
      "[1684/1762] D loss: 1.0075, G loss: 6.4305\n",
      "[1762/1762] D loss: 0.0247, G loss: 9.3587\n",
      "train error: \n",
      " D loss: 0.161715, G loss: 9.875236, D accuracy: 96.6%, cell accuracy: 99.5%, board accuracy: 38.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.202453, G loss: 9.371061, D accuracy: 95.6%, cell accuracy: 99.5%, board accuracy: 35.2% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0317, G loss: 11.6872\n",
      "[84/1762] D loss: 0.0141, G loss: 8.0903\n",
      "[164/1762] D loss: 0.1892, G loss: 6.6640\n",
      "[244/1762] D loss: 0.4214, G loss: 8.4040\n",
      "[324/1762] D loss: 0.0054, G loss: 15.7312\n",
      "[404/1762] D loss: 0.0023, G loss: 14.0206\n",
      "[484/1762] D loss: 0.2850, G loss: 5.2545\n",
      "[564/1762] D loss: 0.0105, G loss: 11.6619\n",
      "[644/1762] D loss: 0.2769, G loss: 15.6185\n",
      "[724/1762] D loss: 0.0062, G loss: 9.2580\n",
      "[804/1762] D loss: 0.0449, G loss: 8.6123\n",
      "[884/1762] D loss: 0.0039, G loss: 14.7385\n",
      "[964/1762] D loss: 0.1863, G loss: 7.0471\n",
      "[1044/1762] D loss: 0.1139, G loss: 7.9117\n",
      "[1124/1762] D loss: 0.0153, G loss: 12.0041\n",
      "[1204/1762] D loss: 0.0326, G loss: 9.5483\n",
      "[1284/1762] D loss: 0.4439, G loss: 15.6023\n",
      "[1364/1762] D loss: 0.0172, G loss: 11.4547\n",
      "[1444/1762] D loss: 0.0226, G loss: 8.5159\n",
      "[1524/1762] D loss: 0.0396, G loss: 6.7202\n",
      "[1604/1762] D loss: 0.0930, G loss: 5.9539\n",
      "[1684/1762] D loss: 0.1262, G loss: 6.4595\n",
      "[1762/1762] D loss: 0.0053, G loss: 7.4794\n",
      "train error: \n",
      " D loss: 0.191003, G loss: 9.121746, D accuracy: 96.2%, cell accuracy: 99.5%, board accuracy: 37.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.203375, G loss: 8.491777, D accuracy: 95.9%, cell accuracy: 99.4%, board accuracy: 36.6% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7235, G loss: 8.0355\n",
      "[84/1762] D loss: 0.0069, G loss: 10.7374\n",
      "[164/1762] D loss: 0.1619, G loss: 7.1427\n",
      "[244/1762] D loss: 0.1031, G loss: 7.9494\n",
      "[324/1762] D loss: 0.5645, G loss: 13.2802\n",
      "[404/1762] D loss: 0.0065, G loss: 11.8475\n",
      "[484/1762] D loss: 0.0207, G loss: 7.0733\n",
      "[564/1762] D loss: 0.2617, G loss: 13.8998\n",
      "[644/1762] D loss: 0.4229, G loss: 4.8440\n",
      "[724/1762] D loss: 0.0513, G loss: 10.5873\n",
      "[804/1762] D loss: 0.3614, G loss: 6.4907\n",
      "[884/1762] D loss: 0.1337, G loss: 9.1244\n",
      "[964/1762] D loss: 0.0123, G loss: 10.8366\n",
      "[1044/1762] D loss: 0.0095, G loss: 8.7948\n",
      "[1124/1762] D loss: 0.0026, G loss: 19.3536\n",
      "[1204/1762] D loss: 0.0449, G loss: 12.3142\n",
      "[1284/1762] D loss: 0.0830, G loss: 7.0426\n",
      "[1364/1762] D loss: 0.0916, G loss: 12.9937\n",
      "[1444/1762] D loss: 0.0178, G loss: 15.6264\n",
      "[1524/1762] D loss: 0.0131, G loss: 10.2521\n",
      "[1604/1762] D loss: 0.0284, G loss: 18.7650\n",
      "[1684/1762] D loss: 0.0245, G loss: 12.6694\n",
      "[1762/1762] D loss: 0.0020, G loss: 12.6642\n",
      "train error: \n",
      " D loss: 0.256036, G loss: 10.985499, D accuracy: 95.2%, cell accuracy: 99.5%, board accuracy: 40.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.325187, G loss: 10.403622, D accuracy: 93.9%, cell accuracy: 99.5%, board accuracy: 37.3% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0865, G loss: 9.4980\n",
      "[84/1762] D loss: 0.1442, G loss: 10.2804\n",
      "[164/1762] D loss: 0.0390, G loss: 9.7074\n",
      "[244/1762] D loss: 0.0080, G loss: 7.0095\n",
      "[324/1762] D loss: 0.0044, G loss: 23.6009\n",
      "[404/1762] D loss: 0.0085, G loss: 16.2545\n",
      "[484/1762] D loss: 0.0010, G loss: 13.7762\n",
      "[564/1762] D loss: 0.0236, G loss: 7.8322\n",
      "[644/1762] D loss: 0.2051, G loss: 7.2003\n",
      "[724/1762] D loss: 0.0704, G loss: 11.1500\n",
      "[804/1762] D loss: 0.0390, G loss: 13.5854\n",
      "[884/1762] D loss: 0.0044, G loss: 14.8769\n",
      "[964/1762] D loss: 0.0154, G loss: 11.7672\n",
      "[1044/1762] D loss: 0.0087, G loss: 15.0912\n",
      "[1124/1762] D loss: 2.0408, G loss: 4.9529\n",
      "[1204/1762] D loss: 0.4314, G loss: 3.0781\n",
      "[1284/1762] D loss: 0.9240, G loss: 5.3366\n",
      "[1364/1762] D loss: 0.0072, G loss: 6.4783\n",
      "[1444/1762] D loss: 0.0857, G loss: 7.0992\n",
      "[1524/1762] D loss: 0.1533, G loss: 4.8927\n",
      "[1604/1762] D loss: 0.5237, G loss: 7.2223\n",
      "[1684/1762] D loss: 0.7375, G loss: 9.2989\n",
      "[1762/1762] D loss: 0.0333, G loss: 9.2646\n",
      "train error: \n",
      " D loss: 0.146237, G loss: 10.564428, D accuracy: 97.6%, cell accuracy: 99.5%, board accuracy: 33.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.187840, G loss: 9.859448, D accuracy: 96.6%, cell accuracy: 99.4%, board accuracy: 34.3% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2341, G loss: 8.1992\n",
      "[84/1762] D loss: 0.0886, G loss: 14.3795\n",
      "[164/1762] D loss: 0.5473, G loss: 3.9768\n",
      "[244/1762] D loss: 0.0426, G loss: 11.7592\n",
      "[324/1762] D loss: 0.0548, G loss: 5.8852\n",
      "[404/1762] D loss: 0.0013, G loss: 8.5580\n",
      "[484/1762] D loss: 0.0117, G loss: 6.2511\n",
      "[564/1762] D loss: 0.0399, G loss: 10.8772\n",
      "[644/1762] D loss: 0.0184, G loss: 12.7411\n",
      "[724/1762] D loss: 0.0057, G loss: 12.8141\n",
      "[804/1762] D loss: 0.7852, G loss: 7.5982\n",
      "[884/1762] D loss: 1.5192, G loss: 5.3767\n",
      "[964/1762] D loss: 0.0237, G loss: 17.9427\n",
      "[1044/1762] D loss: 0.0432, G loss: 12.4017\n",
      "[1124/1762] D loss: 0.0350, G loss: 11.5178\n",
      "[1204/1762] D loss: 0.0013, G loss: 13.7263\n",
      "[1284/1762] D loss: 0.0070, G loss: 12.4257\n",
      "[1364/1762] D loss: 0.0039, G loss: 14.7449\n",
      "[1444/1762] D loss: 0.3214, G loss: 11.5657\n",
      "[1524/1762] D loss: 0.0070, G loss: 12.8732\n",
      "[1604/1762] D loss: 0.1065, G loss: 11.2886\n",
      "[1684/1762] D loss: 0.3859, G loss: 10.1419\n",
      "[1762/1762] D loss: 0.0121, G loss: 15.3814\n",
      "train error: \n",
      " D loss: 0.155950, G loss: 9.027766, D accuracy: 97.1%, cell accuracy: 99.5%, board accuracy: 34.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.205920, G loss: 8.433617, D accuracy: 95.3%, cell accuracy: 99.5%, board accuracy: 35.5% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0120, G loss: 11.5721\n",
      "[84/1762] D loss: 0.0833, G loss: 9.1039\n",
      "[164/1762] D loss: 0.0559, G loss: 8.9554\n",
      "[244/1762] D loss: 0.0048, G loss: 7.4071\n",
      "[324/1762] D loss: 0.0083, G loss: 14.5896\n",
      "[404/1762] D loss: 0.3991, G loss: 16.4099\n",
      "[484/1762] D loss: 0.0056, G loss: 14.2768\n",
      "[564/1762] D loss: 0.4391, G loss: 7.7341\n",
      "[644/1762] D loss: 0.6649, G loss: 8.9388\n",
      "[724/1762] D loss: 0.8726, G loss: 18.2961\n",
      "[804/1762] D loss: 1.1232, G loss: 5.5778\n",
      "[884/1762] D loss: 0.2918, G loss: 13.7556\n",
      "[964/1762] D loss: 0.2930, G loss: 4.9841\n",
      "[1044/1762] D loss: 0.0865, G loss: 8.9191\n",
      "[1124/1762] D loss: 0.1406, G loss: 6.1486\n",
      "[1204/1762] D loss: 0.2985, G loss: 8.4338\n",
      "[1284/1762] D loss: 0.5299, G loss: 16.2379\n",
      "[1364/1762] D loss: 0.0946, G loss: 12.1763\n",
      "[1444/1762] D loss: 0.0547, G loss: 6.5920\n",
      "[1524/1762] D loss: 1.0509, G loss: 4.0339\n",
      "[1604/1762] D loss: 0.2001, G loss: 8.5107\n",
      "[1684/1762] D loss: 0.0144, G loss: 9.8405\n",
      "[1762/1762] D loss: 0.0011, G loss: 13.2368\n",
      "train error: \n",
      " D loss: 0.215112, G loss: 12.334836, D accuracy: 95.3%, cell accuracy: 99.5%, board accuracy: 35.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.246867, G loss: 11.355749, D accuracy: 95.1%, cell accuracy: 99.4%, board accuracy: 34.1% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0038, G loss: 14.5295\n",
      "[84/1762] D loss: 0.1115, G loss: 13.9277\n",
      "[164/1762] D loss: 0.0351, G loss: 11.7092\n",
      "[244/1762] D loss: 0.1063, G loss: 6.2987\n",
      "[324/1762] D loss: 0.0557, G loss: 12.9474\n",
      "[404/1762] D loss: 0.4308, G loss: 8.2026\n",
      "[484/1762] D loss: 0.0271, G loss: 10.4138\n",
      "[564/1762] D loss: 0.3415, G loss: 7.8106\n",
      "[644/1762] D loss: 0.1386, G loss: 14.7131\n",
      "[724/1762] D loss: 0.0027, G loss: 10.7147\n",
      "[804/1762] D loss: 0.0095, G loss: 10.8203\n",
      "[884/1762] D loss: 0.0190, G loss: 12.6392\n",
      "[964/1762] D loss: 0.0098, G loss: 12.8261\n",
      "[1044/1762] D loss: 0.0155, G loss: 12.7444\n",
      "[1124/1762] D loss: 0.0192, G loss: 14.6604\n",
      "[1204/1762] D loss: 0.0486, G loss: 10.3074\n",
      "[1284/1762] D loss: 0.0528, G loss: 11.9343\n",
      "[1364/1762] D loss: 0.5668, G loss: 3.7899\n",
      "[1444/1762] D loss: 0.0170, G loss: 11.0852\n",
      "[1524/1762] D loss: 0.2478, G loss: 11.5750\n",
      "[1604/1762] D loss: 0.0026, G loss: 11.4627\n",
      "[1684/1762] D loss: 0.0206, G loss: 13.1324\n",
      "[1762/1762] D loss: 0.0085, G loss: 25.9970\n",
      "train error: \n",
      " D loss: 0.211781, G loss: 10.781400, D accuracy: 95.1%, cell accuracy: 99.5%, board accuracy: 42.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.218064, G loss: 10.524121, D accuracy: 94.8%, cell accuracy: 99.4%, board accuracy: 38.2% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4020, G loss: 12.9454\n",
      "[84/1762] D loss: 0.0018, G loss: 14.2680\n",
      "[164/1762] D loss: 0.7703, G loss: 3.6511\n",
      "[244/1762] D loss: 0.0606, G loss: 12.8456\n",
      "[324/1762] D loss: 0.0019, G loss: 17.5630\n",
      "[404/1762] D loss: 0.0045, G loss: 16.1998\n",
      "[484/1762] D loss: 0.0025, G loss: 10.6563\n",
      "[564/1762] D loss: 0.7282, G loss: 9.1679\n",
      "[644/1762] D loss: 0.0750, G loss: 12.8081\n",
      "[724/1762] D loss: 0.0164, G loss: 7.6564\n",
      "[804/1762] D loss: 0.0011, G loss: 12.0178\n",
      "[884/1762] D loss: 0.0761, G loss: 7.8733\n",
      "[964/1762] D loss: 0.0499, G loss: 8.4586\n",
      "[1044/1762] D loss: 0.5619, G loss: 8.5531\n",
      "[1124/1762] D loss: 0.0556, G loss: 11.4917\n",
      "[1204/1762] D loss: 0.0381, G loss: 16.5713\n",
      "[1284/1762] D loss: 0.1036, G loss: 8.6594\n",
      "[1364/1762] D loss: 0.0031, G loss: 13.4612\n",
      "[1444/1762] D loss: 0.0127, G loss: 13.6110\n",
      "[1524/1762] D loss: 0.0191, G loss: 10.3248\n",
      "[1604/1762] D loss: 0.0014, G loss: 16.7121\n",
      "[1684/1762] D loss: 0.0071, G loss: 12.9014\n",
      "[1762/1762] D loss: 0.0392, G loss: 10.2088\n",
      "train error: \n",
      " D loss: 0.163412, G loss: 14.783848, D accuracy: 96.2%, cell accuracy: 99.5%, board accuracy: 38.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.251090, G loss: 13.659326, D accuracy: 94.3%, cell accuracy: 99.5%, board accuracy: 36.4% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4135, G loss: 7.0392\n",
      "[84/1762] D loss: 0.0044, G loss: 19.0395\n",
      "[164/1762] D loss: 0.0052, G loss: 15.7668\n",
      "[244/1762] D loss: 0.2748, G loss: 13.1956\n",
      "[324/1762] D loss: 0.9495, G loss: 17.9673\n",
      "[404/1762] D loss: 0.0038, G loss: 7.0066\n",
      "[484/1762] D loss: 0.3819, G loss: 11.9122\n",
      "[564/1762] D loss: 0.3500, G loss: 9.6916\n",
      "[644/1762] D loss: 0.3433, G loss: 7.4137\n",
      "[724/1762] D loss: 0.0036, G loss: 6.9076\n",
      "[804/1762] D loss: 0.0204, G loss: 7.0094\n",
      "[884/1762] D loss: 0.0173, G loss: 9.0790\n",
      "[964/1762] D loss: 0.0218, G loss: 11.2419\n",
      "[1044/1762] D loss: 0.0049, G loss: 7.3243\n",
      "[1124/1762] D loss: 0.0063, G loss: 17.1447\n",
      "[1204/1762] D loss: 0.3702, G loss: 5.7526\n",
      "[1284/1762] D loss: 0.0747, G loss: 10.5211\n",
      "[1364/1762] D loss: 0.0027, G loss: 13.6529\n",
      "[1444/1762] D loss: 0.6918, G loss: 8.7236\n",
      "[1524/1762] D loss: 0.0357, G loss: 7.3614\n",
      "[1604/1762] D loss: 0.0394, G loss: 10.4919\n",
      "[1684/1762] D loss: 0.0036, G loss: 14.5844\n",
      "[1762/1762] D loss: 0.0208, G loss: 5.6367\n",
      "train error: \n",
      " D loss: 0.160254, G loss: 12.182331, D accuracy: 96.8%, cell accuracy: 99.5%, board accuracy: 30.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.189244, G loss: 11.162385, D accuracy: 96.2%, cell accuracy: 99.4%, board accuracy: 28.2% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4719, G loss: 12.7311\n",
      "[84/1762] D loss: 0.0002, G loss: 9.6517\n",
      "[164/1762] D loss: 0.0682, G loss: 9.2182\n",
      "[244/1762] D loss: 0.0023, G loss: 8.0601\n",
      "[324/1762] D loss: 0.0373, G loss: 9.5691\n",
      "[404/1762] D loss: 0.2077, G loss: 7.3630\n",
      "[484/1762] D loss: 0.0070, G loss: 19.6452\n",
      "[564/1762] D loss: 0.0100, G loss: 21.3498\n",
      "[644/1762] D loss: 0.0145, G loss: 9.0837\n",
      "[724/1762] D loss: 0.0920, G loss: 13.2457\n",
      "[804/1762] D loss: 0.0332, G loss: 19.1763\n",
      "[884/1762] D loss: 1.0515, G loss: 10.8797\n",
      "[964/1762] D loss: 0.0087, G loss: 7.7608\n",
      "[1044/1762] D loss: 0.0255, G loss: 14.8893\n",
      "[1124/1762] D loss: 0.0358, G loss: 10.8901\n",
      "[1204/1762] D loss: 0.0091, G loss: 10.4278\n",
      "[1284/1762] D loss: 0.0624, G loss: 10.1690\n",
      "[1364/1762] D loss: 0.3554, G loss: 7.2915\n",
      "[1444/1762] D loss: 0.0010, G loss: 10.9416\n",
      "[1524/1762] D loss: 0.0219, G loss: 9.4118\n",
      "[1604/1762] D loss: 0.3391, G loss: 13.3576\n",
      "[1684/1762] D loss: 0.0057, G loss: 28.9261\n",
      "[1762/1762] D loss: 0.0204, G loss: 9.3133\n",
      "train error: \n",
      " D loss: 0.155835, G loss: 10.678480, D accuracy: 96.2%, cell accuracy: 99.5%, board accuracy: 37.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.191921, G loss: 10.190376, D accuracy: 95.3%, cell accuracy: 99.4%, board accuracy: 34.3% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0125, G loss: 15.4035\n",
      "[84/1762] D loss: 0.7326, G loss: 3.9092\n",
      "[164/1762] D loss: 0.0232, G loss: 15.7073\n",
      "[244/1762] D loss: 0.0083, G loss: 12.4726\n",
      "[324/1762] D loss: 0.0329, G loss: 14.4534\n",
      "[404/1762] D loss: 0.0036, G loss: 11.3966\n",
      "[484/1762] D loss: 0.1977, G loss: 8.1332\n",
      "[564/1762] D loss: 0.0400, G loss: 11.7383\n",
      "[644/1762] D loss: 0.2810, G loss: 10.1194\n",
      "[724/1762] D loss: 0.5005, G loss: 8.6940\n",
      "[804/1762] D loss: 0.0010, G loss: 15.4336\n",
      "[884/1762] D loss: 0.5838, G loss: 8.6410\n",
      "[964/1762] D loss: 0.0160, G loss: 13.3609\n",
      "[1044/1762] D loss: 0.0344, G loss: 11.5245\n",
      "[1124/1762] D loss: 0.0038, G loss: 18.1979\n",
      "[1204/1762] D loss: 0.0159, G loss: 15.5769\n",
      "[1284/1762] D loss: 0.0066, G loss: 11.9914\n",
      "[1364/1762] D loss: 0.0018, G loss: 23.3568\n",
      "[1444/1762] D loss: 0.2325, G loss: 8.3998\n",
      "[1524/1762] D loss: 0.0071, G loss: 12.2046\n",
      "[1604/1762] D loss: 0.1001, G loss: 13.4490\n",
      "[1684/1762] D loss: 0.0116, G loss: 8.1926\n",
      "[1762/1762] D loss: 0.0045, G loss: 13.7225\n",
      "train error: \n",
      " D loss: 0.133847, G loss: 11.582614, D accuracy: 97.3%, cell accuracy: 99.4%, board accuracy: 25.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.161498, G loss: 10.580808, D accuracy: 96.7%, cell accuracy: 99.4%, board accuracy: 27.7% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0107, G loss: 20.1391\n",
      "[84/1762] D loss: 0.7664, G loss: 8.2671\n",
      "[164/1762] D loss: 0.0735, G loss: 23.5252\n",
      "[244/1762] D loss: 0.0042, G loss: 10.1731\n",
      "[324/1762] D loss: 0.0123, G loss: 7.6280\n",
      "[404/1762] D loss: 0.0007, G loss: 13.9797\n",
      "[484/1762] D loss: 0.0015, G loss: 19.4216\n",
      "[564/1762] D loss: 0.0226, G loss: 11.4020\n",
      "[644/1762] D loss: 0.0215, G loss: 33.9946\n",
      "[724/1762] D loss: 0.0329, G loss: 21.5773\n",
      "[804/1762] D loss: 0.3001, G loss: 9.1891\n",
      "[884/1762] D loss: 0.0183, G loss: 12.9035\n",
      "[964/1762] D loss: 0.0031, G loss: 13.4887\n",
      "[1044/1762] D loss: 0.1804, G loss: 13.5463\n",
      "[1124/1762] D loss: 0.0076, G loss: 8.3014\n",
      "[1204/1762] D loss: 0.2422, G loss: 10.6280\n",
      "[1284/1762] D loss: 0.0364, G loss: 11.3211\n",
      "[1364/1762] D loss: 0.0645, G loss: 10.1230\n",
      "[1444/1762] D loss: 0.2609, G loss: 9.5476\n",
      "[1524/1762] D loss: 0.0077, G loss: 9.5060\n",
      "[1604/1762] D loss: 0.0101, G loss: 10.0500\n",
      "[1684/1762] D loss: 0.0865, G loss: 7.8857\n",
      "[1762/1762] D loss: 0.5911, G loss: 11.6515\n",
      "train error: \n",
      " D loss: 0.113232, G loss: 13.470884, D accuracy: 98.1%, cell accuracy: 99.5%, board accuracy: 34.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.146868, G loss: 12.481236, D accuracy: 97.4%, cell accuracy: 99.4%, board accuracy: 33.9% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4176, G loss: 0.8039\n",
      "[84/1762] D loss: 1.1297, G loss: 0.8456\n",
      "[164/1762] D loss: 0.5987, G loss: 1.3591\n",
      "[244/1762] D loss: 0.1771, G loss: 2.5940\n",
      "[324/1762] D loss: 0.0387, G loss: 3.8885\n",
      "[404/1762] D loss: 0.0371, G loss: 3.9451\n",
      "[484/1762] D loss: 0.0512, G loss: 4.7744\n",
      "[564/1762] D loss: 0.2372, G loss: 5.6584\n",
      "[644/1762] D loss: 2.6565, G loss: 5.9162\n",
      "[724/1762] D loss: 1.3968, G loss: 4.4109\n",
      "[804/1762] D loss: 0.1192, G loss: 4.2095\n",
      "[884/1762] D loss: 0.9133, G loss: 2.9300\n",
      "[964/1762] D loss: 1.1846, G loss: 0.6482\n",
      "[1044/1762] D loss: 1.5739, G loss: 0.7561\n",
      "[1124/1762] D loss: 0.4628, G loss: 2.9152\n",
      "[1204/1762] D loss: 1.3585, G loss: 0.6368\n",
      "[1284/1762] D loss: 1.0046, G loss: 0.7558\n",
      "[1364/1762] D loss: 0.9111, G loss: 1.5888\n",
      "[1444/1762] D loss: 0.9071, G loss: 0.8692\n",
      "[1524/1762] D loss: 1.5017, G loss: 0.7606\n",
      "[1604/1762] D loss: 1.0891, G loss: 2.0307\n",
      "[1684/1762] D loss: 1.8455, G loss: 0.2753\n",
      "[1762/1762] D loss: 1.8363, G loss: 1.5014\n",
      "train error: \n",
      " D loss: 1.334303, G loss: 1.202333, D accuracy: 58.0%, cell accuracy: 99.6%, board accuracy: 56.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.303689, G loss: 1.216031, D accuracy: 59.7%, cell accuracy: 99.6%, board accuracy: 59.3% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.6385, G loss: 1.1289\n",
      "[84/1762] D loss: 0.8160, G loss: 1.1646\n",
      "[164/1762] D loss: 1.3508, G loss: 0.9405\n",
      "[244/1762] D loss: 1.4159, G loss: 0.8461\n",
      "[324/1762] D loss: 1.3427, G loss: 0.8620\n",
      "[404/1762] D loss: 1.2751, G loss: 0.7661\n",
      "[484/1762] D loss: 0.7123, G loss: 0.9965\n",
      "[564/1762] D loss: 1.4271, G loss: 0.4539\n",
      "[644/1762] D loss: 0.8804, G loss: 1.0721\n",
      "[724/1762] D loss: 1.3533, G loss: 0.7628\n",
      "[804/1762] D loss: 0.6642, G loss: 1.2890\n",
      "[884/1762] D loss: 0.6788, G loss: 1.9592\n",
      "[964/1762] D loss: 0.5744, G loss: 1.3702\n",
      "[1044/1762] D loss: 1.4746, G loss: 0.7181\n",
      "[1124/1762] D loss: 0.8230, G loss: 1.3282\n",
      "[1204/1762] D loss: 1.4050, G loss: 0.7785\n",
      "[1284/1762] D loss: 1.4128, G loss: 0.7667\n",
      "[1364/1762] D loss: 0.6057, G loss: 1.0551\n",
      "[1444/1762] D loss: 0.6948, G loss: 1.9169\n",
      "[1524/1762] D loss: 1.3879, G loss: 0.8095\n",
      "[1604/1762] D loss: 0.8285, G loss: 0.9500\n",
      "[1684/1762] D loss: 0.9571, G loss: 0.7300\n",
      "[1762/1762] D loss: 0.5189, G loss: 2.0164\n",
      "train error: \n",
      " D loss: 1.324015, G loss: 0.818801, D accuracy: 56.0%, cell accuracy: 99.7%, board accuracy: 68.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.301776, G loss: 0.834496, D accuracy: 57.3%, cell accuracy: 99.6%, board accuracy: 63.0% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3267, G loss: 1.0340\n",
      "[84/1762] D loss: 0.8648, G loss: 1.0028\n",
      "[164/1762] D loss: 0.8336, G loss: 0.9836\n",
      "[244/1762] D loss: 0.6234, G loss: 1.1633\n",
      "[324/1762] D loss: 1.2612, G loss: 0.6681\n",
      "[404/1762] D loss: 0.6961, G loss: 0.9950\n",
      "[484/1762] D loss: 1.4897, G loss: 0.4384\n",
      "[564/1762] D loss: 1.4833, G loss: 0.9093\n",
      "[644/1762] D loss: 1.4921, G loss: 1.0633\n",
      "[724/1762] D loss: 1.4302, G loss: 0.9315\n",
      "[804/1762] D loss: 1.3677, G loss: 0.6216\n",
      "[884/1762] D loss: 0.3113, G loss: 1.9762\n",
      "[964/1762] D loss: 0.4075, G loss: 1.5125\n",
      "[1044/1762] D loss: 1.4219, G loss: 0.5263\n",
      "[1124/1762] D loss: 1.3595, G loss: 0.6071\n",
      "[1204/1762] D loss: 1.4240, G loss: 0.8493\n",
      "[1284/1762] D loss: 1.5768, G loss: 0.4443\n",
      "[1364/1762] D loss: 1.4338, G loss: 0.9786\n",
      "[1444/1762] D loss: 1.3689, G loss: 0.8599\n",
      "[1524/1762] D loss: 1.4081, G loss: 0.5966\n",
      "[1604/1762] D loss: 1.4474, G loss: 0.6765\n",
      "[1684/1762] D loss: 1.6024, G loss: 1.2372\n",
      "[1762/1762] D loss: 1.3810, G loss: 0.8038\n",
      "train error: \n",
      " D loss: 1.331031, G loss: 0.702373, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.310718, G loss: 0.710903, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4089, G loss: 1.5550\n",
      "[84/1762] D loss: 1.3797, G loss: 0.6271\n",
      "[164/1762] D loss: 1.3944, G loss: 0.8272\n",
      "[244/1762] D loss: 1.4155, G loss: 0.5432\n",
      "[324/1762] D loss: 1.4776, G loss: 0.4717\n",
      "[404/1762] D loss: 1.6724, G loss: 1.4249\n",
      "[484/1762] D loss: 1.4164, G loss: 0.6143\n",
      "[564/1762] D loss: 0.3987, G loss: 1.4195\n",
      "[644/1762] D loss: 1.4186, G loss: 0.6482\n",
      "[724/1762] D loss: 0.0955, G loss: 2.5668\n",
      "[804/1762] D loss: 1.3912, G loss: 0.7703\n",
      "[884/1762] D loss: 1.4242, G loss: 0.5550\n",
      "[964/1762] D loss: 1.3724, G loss: 0.7221\n",
      "[1044/1762] D loss: 0.4866, G loss: 1.1233\n",
      "[1124/1762] D loss: 1.2389, G loss: 0.8170\n",
      "[1204/1762] D loss: 1.4491, G loss: 0.5285\n",
      "[1284/1762] D loss: 1.3635, G loss: 0.8462\n",
      "[1364/1762] D loss: 1.4486, G loss: 0.9222\n",
      "[1444/1762] D loss: 0.2996, G loss: 1.6949\n",
      "[1524/1762] D loss: 0.4363, G loss: 1.3635\n",
      "[1604/1762] D loss: 1.4286, G loss: 0.5536\n",
      "[1684/1762] D loss: 1.3890, G loss: 0.8952\n",
      "[1762/1762] D loss: 1.9136, G loss: 1.5217\n",
      "train error: \n",
      " D loss: 1.331642, G loss: 0.838942, D accuracy: 53.0%, cell accuracy: 99.7%, board accuracy: 88.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.312358, G loss: 0.862832, D accuracy: 54.0%, cell accuracy: 99.6%, board accuracy: 85.9% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4800, G loss: 1.1139\n",
      "[84/1762] D loss: 1.4448, G loss: 0.9057\n",
      "[164/1762] D loss: 0.4787, G loss: 1.1384\n",
      "[244/1762] D loss: 1.4556, G loss: 0.8525\n",
      "[324/1762] D loss: 1.5269, G loss: 1.0356\n",
      "[404/1762] D loss: 1.4358, G loss: 0.8322\n",
      "[484/1762] D loss: 1.4404, G loss: 0.8799\n",
      "[564/1762] D loss: 0.3274, G loss: 1.5510\n",
      "[644/1762] D loss: 1.3903, G loss: 0.5943\n",
      "[724/1762] D loss: 0.4923, G loss: 1.0844\n",
      "[804/1762] D loss: 1.4114, G loss: 0.9818\n",
      "[884/1762] D loss: 1.4190, G loss: 0.8430\n",
      "[964/1762] D loss: 1.5024, G loss: 1.1246\n",
      "[1044/1762] D loss: 1.3990, G loss: 0.6280\n",
      "[1124/1762] D loss: 1.3948, G loss: 0.8294\n",
      "[1204/1762] D loss: 1.5018, G loss: 1.0310\n",
      "[1284/1762] D loss: 1.4291, G loss: 0.9291\n",
      "[1364/1762] D loss: 1.5450, G loss: 1.0895\n",
      "[1444/1762] D loss: 1.5314, G loss: 1.0959\n",
      "[1524/1762] D loss: 0.7407, G loss: 0.8841\n",
      "[1604/1762] D loss: 1.2133, G loss: 1.2974\n",
      "[1684/1762] D loss: 0.1346, G loss: 2.4597\n",
      "[1762/1762] D loss: 1.4217, G loss: 1.0057\n",
      "train error: \n",
      " D loss: 1.324767, G loss: 0.832386, D accuracy: 54.8%, cell accuracy: 99.5%, board accuracy: 65.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.315031, G loss: 0.831883, D accuracy: 54.5%, cell accuracy: 99.5%, board accuracy: 65.5% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3693, G loss: 0.7024\n",
      "[84/1762] D loss: 1.3813, G loss: 0.6906\n",
      "[164/1762] D loss: 1.3790, G loss: 0.6811\n",
      "[244/1762] D loss: 1.3900, G loss: 0.7424\n",
      "[324/1762] D loss: 1.3688, G loss: 0.6426\n",
      "[404/1762] D loss: 1.2503, G loss: 0.7477\n",
      "[484/1762] D loss: 1.3881, G loss: 0.7785\n",
      "[564/1762] D loss: 1.3989, G loss: 0.6136\n",
      "[644/1762] D loss: 1.3894, G loss: 0.6814\n",
      "[724/1762] D loss: 1.4279, G loss: 0.8753\n",
      "[804/1762] D loss: 1.3128, G loss: 0.7096\n",
      "[884/1762] D loss: 1.3559, G loss: 0.7155\n",
      "[964/1762] D loss: 1.3145, G loss: 0.7950\n",
      "[1044/1762] D loss: 1.1472, G loss: 1.1367\n",
      "[1124/1762] D loss: 1.3371, G loss: 0.8862\n",
      "[1204/1762] D loss: 1.4905, G loss: 1.0008\n",
      "[1284/1762] D loss: 1.5358, G loss: 1.0931\n",
      "[1364/1762] D loss: 0.8133, G loss: 0.8644\n",
      "[1444/1762] D loss: 1.5030, G loss: 1.0958\n",
      "[1524/1762] D loss: 0.7206, G loss: 0.9134\n",
      "[1604/1762] D loss: 0.5813, G loss: 1.2653\n",
      "[1684/1762] D loss: 0.5343, G loss: 1.2238\n",
      "[1762/1762] D loss: 1.4464, G loss: 0.8618\n",
      "train error: \n",
      " D loss: 1.276814, G loss: 0.795643, D accuracy: 58.9%, cell accuracy: 99.6%, board accuracy: 65.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.277614, G loss: 0.802488, D accuracy: 58.4%, cell accuracy: 99.5%, board accuracy: 64.8% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3108, G loss: 0.4722\n",
      "[84/1762] D loss: 0.5621, G loss: 0.9853\n",
      "[164/1762] D loss: 1.4027, G loss: 1.3977\n",
      "[244/1762] D loss: 1.4223, G loss: 0.9183\n",
      "[324/1762] D loss: 1.2819, G loss: 1.0825\n",
      "[404/1762] D loss: 1.5200, G loss: 1.0837\n",
      "[484/1762] D loss: 1.5769, G loss: 1.2699\n",
      "[564/1762] D loss: 0.9366, G loss: 1.3465\n",
      "[644/1762] D loss: 0.4840, G loss: 1.3030\n",
      "[724/1762] D loss: 1.4302, G loss: 1.0028\n",
      "[804/1762] D loss: 1.4145, G loss: 0.8941\n",
      "[884/1762] D loss: 0.8676, G loss: 1.4212\n",
      "[964/1762] D loss: 0.5176, G loss: 1.4332\n",
      "[1044/1762] D loss: 1.5860, G loss: 1.3188\n",
      "[1124/1762] D loss: 1.1612, G loss: 0.6663\n",
      "[1204/1762] D loss: 1.7641, G loss: 1.4929\n",
      "[1284/1762] D loss: 0.3249, G loss: 1.3659\n",
      "[1364/1762] D loss: 1.8495, G loss: 1.5985\n",
      "[1444/1762] D loss: 0.7127, G loss: 0.7757\n",
      "[1524/1762] D loss: 0.3967, G loss: 1.2044\n",
      "[1604/1762] D loss: 1.5019, G loss: 1.0705\n",
      "[1684/1762] D loss: 0.2899, G loss: 1.4593\n",
      "[1762/1762] D loss: 2.1371, G loss: 0.2882\n",
      "train error: \n",
      " D loss: 1.914716, G loss: 0.209049, D accuracy: 50.0%, cell accuracy: 99.6%, board accuracy: 68.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.895454, G loss: 0.212137, D accuracy: 50.0%, cell accuracy: 99.6%, board accuracy: 67.5% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.7960, G loss: 0.1872\n",
      "[84/1762] D loss: 1.2224, G loss: 0.7629\n",
      "[164/1762] D loss: 0.2409, G loss: 1.6999\n",
      "[244/1762] D loss: 1.5446, G loss: 1.2244\n",
      "[324/1762] D loss: 0.3688, G loss: 1.4810\n",
      "[404/1762] D loss: 0.2587, G loss: 1.5858\n",
      "[484/1762] D loss: 0.4341, G loss: 1.2348\n",
      "[564/1762] D loss: 1.7330, G loss: 1.5249\n",
      "[644/1762] D loss: 0.7649, G loss: 1.1135\n",
      "[724/1762] D loss: 0.5158, G loss: 1.2129\n",
      "[804/1762] D loss: 0.3002, G loss: 1.4310\n",
      "[884/1762] D loss: 0.2472, G loss: 1.5978\n",
      "[964/1762] D loss: 1.8469, G loss: 1.5854\n",
      "[1044/1762] D loss: 0.3019, G loss: 1.4341\n",
      "[1124/1762] D loss: 0.4239, G loss: 1.1153\n",
      "[1204/1762] D loss: 0.3851, G loss: 1.1683\n",
      "[1284/1762] D loss: 0.6410, G loss: 1.0369\n",
      "[1364/1762] D loss: 0.3371, G loss: 1.2869\n",
      "[1444/1762] D loss: 1.3724, G loss: 0.6904\n",
      "[1524/1762] D loss: 0.1992, G loss: 1.7821\n",
      "[1604/1762] D loss: 1.6387, G loss: 1.6390\n",
      "[1684/1762] D loss: 0.4116, G loss: 1.1479\n",
      "[1762/1762] D loss: 1.5498, G loss: 1.1586\n",
      "train error: \n",
      " D loss: 1.342635, G loss: 0.522279, D accuracy: 52.6%, cell accuracy: 99.5%, board accuracy: 62.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.349876, G loss: 0.516960, D accuracy: 51.0%, cell accuracy: 99.4%, board accuracy: 63.2% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1810, G loss: 1.1691\n",
      "[84/1762] D loss: 0.3072, G loss: 1.3822\n",
      "[164/1762] D loss: 1.4680, G loss: 1.0683\n",
      "[244/1762] D loss: 0.5359, G loss: 0.9444\n",
      "[324/1762] D loss: 0.3324, G loss: 1.3252\n",
      "[404/1762] D loss: 0.2979, G loss: 1.4000\n",
      "[484/1762] D loss: 0.3860, G loss: 1.2383\n",
      "[564/1762] D loss: 0.7938, G loss: 0.9586\n",
      "[644/1762] D loss: 0.3928, G loss: 1.1673\n",
      "[724/1762] D loss: 1.6565, G loss: 1.4237\n",
      "[804/1762] D loss: 0.2623, G loss: 1.5310\n",
      "[884/1762] D loss: 1.0102, G loss: 1.0256\n",
      "[964/1762] D loss: 1.4231, G loss: 0.5702\n",
      "[1044/1762] D loss: 0.9134, G loss: 1.3607\n",
      "[1124/1762] D loss: 0.2832, G loss: 1.5084\n",
      "[1204/1762] D loss: 1.0305, G loss: 0.9474\n",
      "[1284/1762] D loss: 1.5216, G loss: 1.0744\n",
      "[1364/1762] D loss: 0.5603, G loss: 0.9101\n",
      "[1444/1762] D loss: 0.5874, G loss: 1.0290\n",
      "[1524/1762] D loss: 1.2110, G loss: 1.5295\n",
      "[1604/1762] D loss: 0.5081, G loss: 1.5124\n",
      "[1684/1762] D loss: 2.0679, G loss: 1.9396\n",
      "[1762/1762] D loss: 0.2122, G loss: 1.7568\n",
      "train error: \n",
      " D loss: 1.889652, G loss: 0.205410, D accuracy: 50.0%, cell accuracy: 99.5%, board accuracy: 63.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.891866, G loss: 0.205087, D accuracy: 50.0%, cell accuracy: 99.5%, board accuracy: 61.1% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.0087, G loss: 1.8574\n",
      "[84/1762] D loss: 1.7060, G loss: 1.4094\n",
      "[164/1762] D loss: 1.4856, G loss: 1.1546\n",
      "[244/1762] D loss: 1.5820, G loss: 1.5415\n",
      "[324/1762] D loss: 1.7507, G loss: 1.5999\n",
      "[404/1762] D loss: 0.5912, G loss: 0.9763\n",
      "[484/1762] D loss: 0.2941, G loss: 1.4470\n",
      "[564/1762] D loss: 1.4806, G loss: 0.4795\n",
      "[644/1762] D loss: 0.3132, G loss: 1.5447\n",
      "[724/1762] D loss: 0.3780, G loss: 1.2294\n",
      "[804/1762] D loss: 0.7044, G loss: 1.0186\n",
      "[884/1762] D loss: 1.3538, G loss: 0.6453\n",
      "[964/1762] D loss: 0.3356, G loss: 1.3963\n",
      "[1044/1762] D loss: 0.1781, G loss: 1.9045\n",
      "[1124/1762] D loss: 0.1647, G loss: 1.9330\n",
      "[1204/1762] D loss: 1.7517, G loss: 0.3856\n",
      "[1284/1762] D loss: 2.3210, G loss: 0.1826\n",
      "[1364/1762] D loss: 2.1068, G loss: 1.8935\n",
      "[1444/1762] D loss: 1.8197, G loss: 1.6490\n",
      "[1524/1762] D loss: 0.1920, G loss: 1.9184\n",
      "[1604/1762] D loss: 0.2336, G loss: 1.5619\n",
      "[1684/1762] D loss: 1.8628, G loss: 1.7105\n",
      "[1762/1762] D loss: 1.7945, G loss: 1.4254\n",
      "train error: \n",
      " D loss: 1.373683, G loss: 0.491844, D accuracy: 50.3%, cell accuracy: 99.6%, board accuracy: 67.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.356141, G loss: 0.504673, D accuracy: 51.1%, cell accuracy: 99.5%, board accuracy: 68.6% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2568, G loss: 1.5509\n",
      "[84/1762] D loss: 1.7711, G loss: 1.5378\n",
      "[164/1762] D loss: 0.8048, G loss: 1.5526\n",
      "[244/1762] D loss: 0.3933, G loss: 2.0455\n",
      "[324/1762] D loss: 0.3314, G loss: 2.0333\n",
      "[404/1762] D loss: 0.6717, G loss: 1.0106\n",
      "[484/1762] D loss: 1.6724, G loss: 1.9019\n",
      "[564/1762] D loss: 1.6459, G loss: 1.6172\n",
      "[644/1762] D loss: 0.3746, G loss: 1.1968\n",
      "[724/1762] D loss: 0.2611, G loss: 1.6500\n",
      "[804/1762] D loss: 0.4375, G loss: 1.2265\n",
      "[884/1762] D loss: 0.5453, G loss: 1.6727\n",
      "[964/1762] D loss: 0.2060, G loss: 1.8147\n",
      "[1044/1762] D loss: 0.2948, G loss: 1.3976\n",
      "[1124/1762] D loss: 0.3092, G loss: 1.3781\n",
      "[1204/1762] D loss: 0.2874, G loss: 1.4266\n",
      "[1284/1762] D loss: 0.5177, G loss: 1.3884\n",
      "[1364/1762] D loss: 0.2454, G loss: 1.6285\n",
      "[1444/1762] D loss: 0.2989, G loss: 1.8171\n",
      "[1524/1762] D loss: 1.7293, G loss: 1.5445\n",
      "[1604/1762] D loss: 0.2795, G loss: 1.4362\n",
      "[1684/1762] D loss: 1.9109, G loss: 1.8926\n",
      "[1762/1762] D loss: 0.3013, G loss: 1.4367\n",
      "train error: \n",
      " D loss: 3.181334, G loss: 0.047917, D accuracy: 50.0%, cell accuracy: 99.5%, board accuracy: 63.7% \n",
      "\n",
      "test error: \n",
      " D loss: 3.172518, G loss: 0.048691, D accuracy: 50.0%, cell accuracy: 99.4%, board accuracy: 61.6% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1078, G loss: 0.5735\n",
      "[84/1762] D loss: 1.5804, G loss: 1.6995\n",
      "[164/1762] D loss: 0.7136, G loss: 0.9182\n",
      "[244/1762] D loss: 1.7069, G loss: 1.3721\n",
      "[324/1762] D loss: 0.3937, G loss: 1.3090\n",
      "[404/1762] D loss: 2.1275, G loss: 2.0035\n",
      "[484/1762] D loss: 0.1911, G loss: 1.8058\n",
      "[564/1762] D loss: 0.2495, G loss: 1.7130\n",
      "[644/1762] D loss: 0.8078, G loss: 1.1442\n",
      "[724/1762] D loss: 0.3923, G loss: 1.5953\n",
      "[804/1762] D loss: 0.7037, G loss: 1.3865\n",
      "[884/1762] D loss: 0.4150, G loss: 1.4149\n",
      "[964/1762] D loss: 1.5839, G loss: 1.5274\n",
      "[1044/1762] D loss: 1.3716, G loss: 1.1984\n",
      "[1124/1762] D loss: 0.2701, G loss: 1.7895\n",
      "[1204/1762] D loss: 0.1366, G loss: 2.1352\n",
      "[1284/1762] D loss: 1.6961, G loss: 1.4621\n",
      "[1364/1762] D loss: 0.3310, G loss: 1.5956\n",
      "[1444/1762] D loss: 0.1428, G loss: 2.3161\n",
      "[1524/1762] D loss: 0.1872, G loss: 2.1598\n",
      "[1604/1762] D loss: 0.1710, G loss: 1.9258\n",
      "[1684/1762] D loss: 0.1519, G loss: 2.0502\n",
      "[1762/1762] D loss: 3.5889, G loss: 0.6483\n",
      "train error: \n",
      " D loss: 2.159328, G loss: 0.147878, D accuracy: 50.0%, cell accuracy: 99.5%, board accuracy: 64.8% \n",
      "\n",
      "test error: \n",
      " D loss: 2.160203, G loss: 0.148825, D accuracy: 50.0%, cell accuracy: 99.5%, board accuracy: 64.3% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1801, G loss: 2.1866\n",
      "[84/1762] D loss: 0.8886, G loss: 0.8117\n",
      "[164/1762] D loss: 0.2615, G loss: 1.6226\n",
      "[244/1762] D loss: 0.1132, G loss: 2.2991\n",
      "[324/1762] D loss: 0.1394, G loss: 2.1160\n",
      "[404/1762] D loss: 0.3133, G loss: 1.7172\n",
      "[484/1762] D loss: 0.1538, G loss: 1.9896\n",
      "[564/1762] D loss: 0.2957, G loss: 1.5066\n",
      "[644/1762] D loss: 0.2537, G loss: 1.5904\n",
      "[724/1762] D loss: 0.9631, G loss: 1.6697\n",
      "[804/1762] D loss: 0.2225, G loss: 1.6750\n",
      "[884/1762] D loss: 0.4174, G loss: 1.5246\n",
      "[964/1762] D loss: 0.2275, G loss: 1.7580\n",
      "[1044/1762] D loss: 0.2681, G loss: 1.4888\n",
      "[1124/1762] D loss: 0.1773, G loss: 1.8787\n",
      "[1204/1762] D loss: 1.3053, G loss: 1.3535\n",
      "[1284/1762] D loss: 0.1587, G loss: 2.0030\n",
      "[1364/1762] D loss: 0.4208, G loss: 2.2524\n",
      "[1444/1762] D loss: 0.1577, G loss: 2.0795\n",
      "[1524/1762] D loss: 0.2191, G loss: 1.7352\n",
      "[1604/1762] D loss: 0.1347, G loss: 2.1156\n",
      "[1684/1762] D loss: 0.8060, G loss: 2.2480\n",
      "[1762/1762] D loss: 1.8786, G loss: 2.6225\n",
      "train error: \n",
      " D loss: 1.385303, G loss: 0.461859, D accuracy: 50.3%, cell accuracy: 99.5%, board accuracy: 60.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.378183, G loss: 0.470442, D accuracy: 50.8%, cell accuracy: 99.4%, board accuracy: 60.9% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1851, G loss: 1.7734\n",
      "[84/1762] D loss: 0.1250, G loss: 2.2382\n",
      "[164/1762] D loss: 1.7619, G loss: 1.2312\n",
      "[244/1762] D loss: 1.3247, G loss: 1.8435\n",
      "[324/1762] D loss: 0.2438, G loss: 1.6047\n",
      "[404/1762] D loss: 0.2303, G loss: 1.6249\n",
      "[484/1762] D loss: 0.7635, G loss: 0.9086\n",
      "[564/1762] D loss: 1.8893, G loss: 1.4684\n",
      "[644/1762] D loss: 0.1885, G loss: 1.8176\n",
      "[724/1762] D loss: 1.4536, G loss: 1.4500\n",
      "[804/1762] D loss: 0.3403, G loss: 1.6531\n",
      "[884/1762] D loss: 0.3567, G loss: 1.8549\n",
      "[964/1762] D loss: 0.2892, G loss: 2.2498\n",
      "[1044/1762] D loss: 1.3899, G loss: 1.9580\n",
      "[1124/1762] D loss: 0.4225, G loss: 1.7927\n",
      "[1204/1762] D loss: 0.1761, G loss: 2.0169\n",
      "[1284/1762] D loss: 0.3537, G loss: 2.2933\n",
      "[1364/1762] D loss: 0.2980, G loss: 1.5381\n",
      "[1444/1762] D loss: 2.8092, G loss: 2.6986\n",
      "[1524/1762] D loss: 0.1824, G loss: 1.8721\n",
      "[1604/1762] D loss: 0.3059, G loss: 2.1633\n",
      "[1684/1762] D loss: 0.2740, G loss: 1.6389\n",
      "[1762/1762] D loss: 0.1181, G loss: 2.2017\n",
      "train error: \n",
      " D loss: 2.481525, G loss: 0.102547, D accuracy: 50.0%, cell accuracy: 99.5%, board accuracy: 65.1% \n",
      "\n",
      "test error: \n",
      " D loss: 2.471017, G loss: 0.104331, D accuracy: 50.0%, cell accuracy: 99.5%, board accuracy: 65.2% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5482, G loss: 1.4074\n",
      "[84/1762] D loss: 1.2453, G loss: 1.4852\n",
      "[164/1762] D loss: 0.3362, G loss: 1.2867\n",
      "[244/1762] D loss: 1.6340, G loss: 1.6790\n",
      "[324/1762] D loss: 0.1246, G loss: 2.2318\n",
      "[404/1762] D loss: 0.5170, G loss: 1.2331\n",
      "[484/1762] D loss: 0.1572, G loss: 2.0485\n",
      "[564/1762] D loss: 0.9694, G loss: 2.1112\n",
      "[644/1762] D loss: 0.1211, G loss: 2.5962\n",
      "[724/1762] D loss: 1.6865, G loss: 0.8028\n",
      "[804/1762] D loss: 0.1683, G loss: 1.9075\n",
      "[884/1762] D loss: 0.1014, G loss: 2.4499\n",
      "[964/1762] D loss: 0.3308, G loss: 1.5100\n",
      "[1044/1762] D loss: 3.0037, G loss: 2.9076\n",
      "[1124/1762] D loss: 0.1837, G loss: 1.8667\n",
      "[1204/1762] D loss: 1.2022, G loss: 0.9942\n",
      "[1284/1762] D loss: 0.1468, G loss: 2.0643\n",
      "[1364/1762] D loss: 0.2200, G loss: 2.3502\n",
      "[1444/1762] D loss: 0.2875, G loss: 1.4111\n",
      "[1524/1762] D loss: 0.3161, G loss: 1.3642\n",
      "[1604/1762] D loss: 0.1948, G loss: 1.8387\n",
      "[1684/1762] D loss: 0.2437, G loss: 1.6933\n",
      "[1762/1762] D loss: 0.3599, G loss: 1.5848\n",
      "train error: \n",
      " D loss: 1.244612, G loss: 0.948930, D accuracy: 62.3%, cell accuracy: 99.6%, board accuracy: 69.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.252924, G loss: 0.954171, D accuracy: 61.6%, cell accuracy: 99.5%, board accuracy: 66.4% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2302, G loss: 1.6932\n",
      "[84/1762] D loss: 0.1595, G loss: 1.9557\n",
      "[164/1762] D loss: 0.2805, G loss: 1.4932\n",
      "[244/1762] D loss: 0.3323, G loss: 1.8482\n",
      "[324/1762] D loss: 0.3411, G loss: 2.0818\n",
      "[404/1762] D loss: 0.5707, G loss: 1.3472\n",
      "[484/1762] D loss: 0.1915, G loss: 1.7999\n",
      "[564/1762] D loss: 0.0927, G loss: 2.4853\n",
      "[644/1762] D loss: 0.1284, G loss: 2.1189\n",
      "[724/1762] D loss: 0.1763, G loss: 2.2112\n",
      "[804/1762] D loss: 1.8859, G loss: 1.9059\n",
      "[884/1762] D loss: 0.2666, G loss: 1.5548\n",
      "[964/1762] D loss: 0.2065, G loss: 1.7563\n",
      "[1044/1762] D loss: 1.7036, G loss: 1.9379\n",
      "[1124/1762] D loss: 0.1812, G loss: 2.1731\n",
      "[1204/1762] D loss: 0.3595, G loss: 1.2494\n",
      "[1284/1762] D loss: 0.1453, G loss: 2.0698\n",
      "[1364/1762] D loss: 0.1388, G loss: 2.0645\n",
      "[1444/1762] D loss: 1.0416, G loss: 1.4155\n",
      "[1524/1762] D loss: 0.6595, G loss: 2.1583\n",
      "[1604/1762] D loss: 0.1233, G loss: 2.2108\n",
      "[1684/1762] D loss: 1.2982, G loss: 0.6042\n",
      "[1762/1762] D loss: 0.1922, G loss: 1.8412\n",
      "train error: \n",
      " D loss: 2.483879, G loss: 0.104245, D accuracy: 50.0%, cell accuracy: 99.5%, board accuracy: 63.1% \n",
      "\n",
      "test error: \n",
      " D loss: 2.476911, G loss: 0.103825, D accuracy: 50.0%, cell accuracy: 99.4%, board accuracy: 60.9% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4074, G loss: 1.5451\n",
      "[84/1762] D loss: 1.8676, G loss: 2.0965\n",
      "[164/1762] D loss: 0.1584, G loss: 2.0313\n",
      "[244/1762] D loss: 0.1592, G loss: 2.3001\n",
      "[324/1762] D loss: 0.1651, G loss: 1.9400\n",
      "[404/1762] D loss: 2.5799, G loss: 2.5049\n",
      "[484/1762] D loss: 0.1147, G loss: 2.2602\n",
      "[564/1762] D loss: 0.8014, G loss: 1.0445\n",
      "[644/1762] D loss: 0.1199, G loss: 2.1758\n",
      "[724/1762] D loss: 0.1175, G loss: 2.2122\n",
      "[804/1762] D loss: 1.3695, G loss: 0.9871\n",
      "[884/1762] D loss: 1.6254, G loss: 1.6448\n",
      "[964/1762] D loss: 0.1148, G loss: 2.2967\n",
      "[1044/1762] D loss: 0.1406, G loss: 2.1457\n",
      "[1124/1762] D loss: 1.5655, G loss: 1.4709\n",
      "[1204/1762] D loss: 1.3855, G loss: 0.6894\n",
      "[1284/1762] D loss: 0.1405, G loss: 2.1785\n",
      "[1364/1762] D loss: 0.5089, G loss: 1.0420\n",
      "[1444/1762] D loss: 0.1857, G loss: 1.7877\n",
      "[1524/1762] D loss: 0.1533, G loss: 1.9647\n",
      "[1604/1762] D loss: 0.2388, G loss: 1.5547\n",
      "[1684/1762] D loss: 1.1975, G loss: 1.7685\n",
      "[1762/1762] D loss: 2.4324, G loss: 2.3249\n",
      "train error: \n",
      " D loss: 2.117771, G loss: 0.152636, D accuracy: 49.9%, cell accuracy: 99.5%, board accuracy: 62.2% \n",
      "\n",
      "test error: \n",
      " D loss: 2.117348, G loss: 0.154140, D accuracy: 49.9%, cell accuracy: 99.4%, board accuracy: 62.5% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.9823, G loss: 1.7925\n",
      "[84/1762] D loss: 0.1219, G loss: 2.1884\n",
      "[164/1762] D loss: 1.9054, G loss: 1.8567\n",
      "[244/1762] D loss: 1.3973, G loss: 0.8769\n",
      "[324/1762] D loss: 0.2143, G loss: 1.6914\n",
      "[404/1762] D loss: 0.1173, G loss: 2.2828\n",
      "[484/1762] D loss: 1.9307, G loss: 2.1008\n",
      "[564/1762] D loss: 0.8943, G loss: 2.0767\n",
      "[644/1762] D loss: 0.2754, G loss: 1.5149\n",
      "[724/1762] D loss: 0.3181, G loss: 1.4254\n",
      "[804/1762] D loss: 0.2594, G loss: 1.7753\n",
      "[884/1762] D loss: 0.1217, G loss: 2.3135\n",
      "[964/1762] D loss: 0.0882, G loss: 2.5534\n",
      "[1044/1762] D loss: 0.5668, G loss: 1.0637\n",
      "[1124/1762] D loss: 0.2103, G loss: 1.6205\n",
      "[1204/1762] D loss: 0.2806, G loss: 1.4996\n",
      "[1284/1762] D loss: 0.1183, G loss: 2.1563\n",
      "[1364/1762] D loss: 0.0792, G loss: 2.6886\n",
      "[1444/1762] D loss: 0.0982, G loss: 2.4216\n",
      "[1524/1762] D loss: 0.1374, G loss: 2.1374\n",
      "[1604/1762] D loss: 0.3036, G loss: 1.6170\n",
      "[1684/1762] D loss: 0.0636, G loss: 2.8667\n",
      "[1762/1762] D loss: 1.8992, G loss: 1.6622\n",
      "train error: \n",
      " D loss: 1.931834, G loss: 0.202954, D accuracy: 50.0%, cell accuracy: 99.5%, board accuracy: 63.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.946514, G loss: 0.199325, D accuracy: 50.0%, cell accuracy: 99.5%, board accuracy: 65.5% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2665, G loss: 1.5644\n",
      "[84/1762] D loss: 1.0488, G loss: 2.9781\n",
      "[164/1762] D loss: 1.0443, G loss: 1.2547\n",
      "[244/1762] D loss: 2.1721, G loss: 2.0586\n",
      "[324/1762] D loss: 0.2617, G loss: 1.6539\n",
      "[404/1762] D loss: 1.4012, G loss: 1.1371\n",
      "[484/1762] D loss: 0.4303, G loss: 2.1743\n",
      "[564/1762] D loss: 0.1395, G loss: 2.0897\n",
      "[644/1762] D loss: 0.3321, G loss: 1.4122\n",
      "[724/1762] D loss: 0.1662, G loss: 1.9522\n",
      "[804/1762] D loss: 0.2254, G loss: 2.6992\n",
      "[884/1762] D loss: 0.1742, G loss: 2.3911\n",
      "[964/1762] D loss: 0.1032, G loss: 2.4333\n",
      "[1044/1762] D loss: 0.9918, G loss: 1.6820\n",
      "[1124/1762] D loss: 2.0530, G loss: 2.9264\n",
      "[1204/1762] D loss: 0.1853, G loss: 2.0234\n",
      "[1284/1762] D loss: 0.1907, G loss: 2.0251\n",
      "[1364/1762] D loss: 1.8771, G loss: 1.7249\n",
      "[1444/1762] D loss: 0.3334, G loss: 1.4415\n",
      "[1524/1762] D loss: 1.0835, G loss: 0.5774\n",
      "[1604/1762] D loss: 0.0913, G loss: 2.5316\n",
      "[1684/1762] D loss: 0.0789, G loss: 3.0040\n",
      "[1762/1762] D loss: 0.9854, G loss: 2.3601\n",
      "train error: \n",
      " D loss: 1.761545, G loss: 0.243069, D accuracy: 50.0%, cell accuracy: 99.6%, board accuracy: 69.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.774331, G loss: 0.242238, D accuracy: 50.1%, cell accuracy: 99.6%, board accuracy: 68.9% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0886, G loss: 2.6612\n",
      "[84/1762] D loss: 0.1328, G loss: 2.1780\n",
      "[164/1762] D loss: 0.1880, G loss: 2.0783\n",
      "[244/1762] D loss: 0.2283, G loss: 1.5671\n",
      "[324/1762] D loss: 0.4010, G loss: 1.6569\n",
      "[404/1762] D loss: 0.1122, G loss: 2.5026\n",
      "[484/1762] D loss: 0.1840, G loss: 1.8492\n",
      "[564/1762] D loss: 1.7030, G loss: 1.3354\n",
      "[644/1762] D loss: 0.2394, G loss: 1.6046\n",
      "[724/1762] D loss: 0.6035, G loss: 1.0217\n",
      "[804/1762] D loss: 0.0661, G loss: 2.9230\n",
      "[884/1762] D loss: 1.8387, G loss: 2.1767\n",
      "[964/1762] D loss: 0.2789, G loss: 2.7217\n",
      "[1044/1762] D loss: 1.0491, G loss: 0.9643\n",
      "[1124/1762] D loss: 0.1568, G loss: 2.1614\n",
      "[1204/1762] D loss: 0.1381, G loss: 2.2685\n",
      "[1284/1762] D loss: 0.1072, G loss: 2.1473\n",
      "[1364/1762] D loss: 0.0788, G loss: 2.6622\n",
      "[1444/1762] D loss: 0.2608, G loss: 1.8603\n",
      "[1524/1762] D loss: 0.1986, G loss: 1.6350\n",
      "[1604/1762] D loss: 0.1402, G loss: 2.2744\n",
      "[1684/1762] D loss: 0.3429, G loss: 1.4014\n",
      "[1762/1762] D loss: 1.3279, G loss: 1.0639\n",
      "train error: \n",
      " D loss: 1.398966, G loss: 0.486084, D accuracy: 51.2%, cell accuracy: 99.5%, board accuracy: 64.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.405237, G loss: 0.484648, D accuracy: 51.1%, cell accuracy: 99.5%, board accuracy: 65.0% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1365, G loss: 2.6922\n",
      "[84/1762] D loss: 1.1584, G loss: 1.9785\n",
      "[164/1762] D loss: 1.3467, G loss: 0.8362\n",
      "[244/1762] D loss: 0.1942, G loss: 1.7646\n",
      "[324/1762] D loss: 0.1961, G loss: 2.0159\n",
      "[404/1762] D loss: 1.4206, G loss: 0.8164\n",
      "[484/1762] D loss: 1.1950, G loss: 1.1960\n",
      "[564/1762] D loss: 0.1389, G loss: 2.0445\n",
      "[644/1762] D loss: 0.0753, G loss: 2.7503\n",
      "[724/1762] D loss: 0.2421, G loss: 1.9212\n",
      "[804/1762] D loss: 0.0608, G loss: 2.8684\n",
      "[884/1762] D loss: 0.0679, G loss: 2.7786\n",
      "[964/1762] D loss: 0.4282, G loss: 1.9372\n",
      "[1044/1762] D loss: 0.1752, G loss: 2.0317\n",
      "[1124/1762] D loss: 0.2010, G loss: 2.0429\n",
      "[1204/1762] D loss: 0.0796, G loss: 2.5961\n",
      "[1284/1762] D loss: 2.5323, G loss: 2.3795\n",
      "[1364/1762] D loss: 0.0845, G loss: 2.5539\n",
      "[1444/1762] D loss: 1.7847, G loss: 1.5201\n",
      "[1524/1762] D loss: 0.1023, G loss: 2.7012\n",
      "[1604/1762] D loss: 0.0373, G loss: 3.3866\n",
      "[1684/1762] D loss: 0.8308, G loss: 0.9676\n",
      "[1762/1762] D loss: 0.0464, G loss: 3.1555\n",
      "train error: \n",
      " D loss: 1.858779, G loss: 0.216399, D accuracy: 50.0%, cell accuracy: 99.5%, board accuracy: 63.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.857579, G loss: 0.218745, D accuracy: 50.0%, cell accuracy: 99.5%, board accuracy: 63.6% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.6480, G loss: 2.5507\n",
      "[84/1762] D loss: 0.4651, G loss: 1.2654\n",
      "[164/1762] D loss: 0.0941, G loss: 2.5242\n",
      "[244/1762] D loss: 0.3313, G loss: 1.5721\n",
      "[324/1762] D loss: 0.0482, G loss: 3.1035\n",
      "[404/1762] D loss: 0.1243, G loss: 2.1132\n",
      "[484/1762] D loss: 2.3985, G loss: 2.3679\n",
      "[564/1762] D loss: 1.4987, G loss: 0.4632\n",
      "[644/1762] D loss: 2.1922, G loss: 2.0422\n",
      "[724/1762] D loss: 0.0843, G loss: 2.7044\n",
      "[804/1762] D loss: 0.4174, G loss: 1.1934\n",
      "[884/1762] D loss: 0.3229, G loss: 1.5127\n",
      "[964/1762] D loss: 0.3806, G loss: 2.4078\n",
      "[1044/1762] D loss: 0.2494, G loss: 1.8771\n",
      "[1124/1762] D loss: 0.4753, G loss: 1.1888\n",
      "[1204/1762] D loss: 0.1574, G loss: 1.9834\n",
      "[1284/1762] D loss: 2.1054, G loss: 2.2422\n",
      "[1364/1762] D loss: 0.0773, G loss: 2.6423\n",
      "[1444/1762] D loss: 1.1059, G loss: 0.7711\n",
      "[1524/1762] D loss: 0.0555, G loss: 3.0496\n",
      "[1604/1762] D loss: 2.1034, G loss: 2.0160\n",
      "[1684/1762] D loss: 0.7412, G loss: 2.7021\n",
      "[1762/1762] D loss: 2.8034, G loss: 2.7292\n",
      "train error: \n",
      " D loss: 1.593585, G loss: 0.326708, D accuracy: 50.1%, cell accuracy: 99.6%, board accuracy: 71.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.595628, G loss: 0.324090, D accuracy: 50.1%, cell accuracy: 99.6%, board accuracy: 72.0% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7348, G loss: 2.5046\n",
      "[84/1762] D loss: 1.0811, G loss: 0.5319\n",
      "[164/1762] D loss: 0.0800, G loss: 2.6552\n",
      "[244/1762] D loss: 0.3674, G loss: 1.8425\n",
      "[324/1762] D loss: 2.9188, G loss: 2.9171\n",
      "[404/1762] D loss: 0.3208, G loss: 2.3608\n",
      "[484/1762] D loss: 0.2084, G loss: 1.7858\n",
      "[564/1762] D loss: 0.0557, G loss: 3.0442\n",
      "[644/1762] D loss: 0.6915, G loss: 2.1875\n",
      "[724/1762] D loss: 0.4647, G loss: 1.1157\n",
      "[804/1762] D loss: 0.1409, G loss: 2.2787\n",
      "[884/1762] D loss: 0.3307, G loss: 1.9473\n",
      "[964/1762] D loss: 0.1062, G loss: 3.2156\n",
      "[1044/1762] D loss: 0.1211, G loss: 2.5558\n",
      "[1124/1762] D loss: 0.1902, G loss: 1.8010\n",
      "[1204/1762] D loss: 0.2251, G loss: 2.3838\n",
      "[1284/1762] D loss: 2.0479, G loss: 1.7497\n",
      "[1364/1762] D loss: 0.6462, G loss: 1.2478\n",
      "[1444/1762] D loss: 0.0970, G loss: 2.5515\n",
      "[1524/1762] D loss: 0.0524, G loss: 2.9899\n",
      "[1604/1762] D loss: 0.0658, G loss: 2.7966\n",
      "[1684/1762] D loss: 0.1024, G loss: 2.5732\n",
      "[1762/1762] D loss: 0.0384, G loss: 3.3434\n",
      "train error: \n",
      " D loss: 2.776281, G loss: 0.072387, D accuracy: 50.0%, cell accuracy: 99.6%, board accuracy: 65.1% \n",
      "\n",
      "test error: \n",
      " D loss: 2.779020, G loss: 0.072453, D accuracy: 50.0%, cell accuracy: 99.5%, board accuracy: 66.6% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0823, G loss: 3.1983\n",
      "[84/1762] D loss: 0.1635, G loss: 2.0565\n",
      "[164/1762] D loss: 1.7328, G loss: 1.4616\n",
      "[244/1762] D loss: 0.5709, G loss: 2.2839\n",
      "[324/1762] D loss: 1.0787, G loss: 0.7352\n",
      "[404/1762] D loss: 0.2224, G loss: 2.1437\n",
      "[484/1762] D loss: 0.0373, G loss: 3.4005\n",
      "[564/1762] D loss: 1.6862, G loss: 0.7548\n",
      "[644/1762] D loss: 0.0387, G loss: 3.4046\n",
      "[724/1762] D loss: 0.6732, G loss: 1.3158\n",
      "[804/1762] D loss: 1.5865, G loss: 1.4178\n",
      "[884/1762] D loss: 0.3106, G loss: 1.4391\n",
      "[964/1762] D loss: 0.3689, G loss: 1.3698\n",
      "[1044/1762] D loss: 0.0922, G loss: 2.2774\n",
      "[1124/1762] D loss: 0.0859, G loss: 2.7842\n",
      "[1204/1762] D loss: 1.4501, G loss: 1.4256\n",
      "[1284/1762] D loss: 1.4908, G loss: 0.3126\n",
      "[1364/1762] D loss: 0.3194, G loss: 3.2790\n",
      "[1444/1762] D loss: 0.3556, G loss: 1.3857\n",
      "[1524/1762] D loss: 0.0681, G loss: 2.8277\n",
      "[1604/1762] D loss: 0.0642, G loss: 2.8062\n",
      "[1684/1762] D loss: 2.6817, G loss: 2.6387\n",
      "[1762/1762] D loss: 1.7756, G loss: 1.4758\n",
      "train error: \n",
      " D loss: 1.716237, G loss: 0.268132, D accuracy: 49.7%, cell accuracy: 99.6%, board accuracy: 69.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.732739, G loss: 0.265591, D accuracy: 50.0%, cell accuracy: 99.6%, board accuracy: 70.5% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1440, G loss: 2.1317\n",
      "[84/1762] D loss: 0.0619, G loss: 2.9543\n",
      "[164/1762] D loss: 1.4968, G loss: 0.4600\n",
      "[244/1762] D loss: 0.0645, G loss: 3.1439\n",
      "[324/1762] D loss: 2.4596, G loss: 0.1359\n",
      "[404/1762] D loss: 0.0404, G loss: 3.2566\n",
      "[484/1762] D loss: 2.5581, G loss: 2.3967\n",
      "[564/1762] D loss: 0.1806, G loss: 2.0707\n",
      "[644/1762] D loss: 0.1145, G loss: 2.2306\n",
      "[724/1762] D loss: 0.1234, G loss: 2.2934\n",
      "[804/1762] D loss: 0.1834, G loss: 2.4229\n",
      "[884/1762] D loss: 0.0544, G loss: 2.9625\n",
      "[964/1762] D loss: 2.2158, G loss: 2.5308\n",
      "[1044/1762] D loss: 0.1123, G loss: 2.2260\n",
      "[1124/1762] D loss: 1.7655, G loss: 1.8121\n",
      "[1204/1762] D loss: 0.2888, G loss: 1.5724\n",
      "[1284/1762] D loss: 0.1521, G loss: 2.0071\n",
      "[1364/1762] D loss: 1.2675, G loss: 0.4839\n",
      "[1444/1762] D loss: 0.2482, G loss: 1.6128\n",
      "[1524/1762] D loss: 0.5316, G loss: 1.6070\n",
      "[1604/1762] D loss: 2.3642, G loss: 2.1630\n",
      "[1684/1762] D loss: 1.2997, G loss: 2.9781\n",
      "[1762/1762] D loss: 0.0259, G loss: 3.6655\n",
      "train error: \n",
      " D loss: 3.124584, G loss: 0.053342, D accuracy: 50.0%, cell accuracy: 99.5%, board accuracy: 60.9% \n",
      "\n",
      "test error: \n",
      " D loss: 3.117698, G loss: 0.053927, D accuracy: 50.0%, cell accuracy: 99.4%, board accuracy: 62.3% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0568, G loss: 3.0182\n",
      "[84/1762] D loss: 0.0746, G loss: 2.6380\n",
      "[164/1762] D loss: 0.0792, G loss: 2.5770\n",
      "[244/1762] D loss: 0.2974, G loss: 1.5262\n",
      "[324/1762] D loss: 0.2009, G loss: 1.9204\n",
      "[404/1762] D loss: 0.6846, G loss: 1.1225\n",
      "[484/1762] D loss: 0.0655, G loss: 3.3884\n",
      "[564/1762] D loss: 0.7305, G loss: 0.9109\n",
      "[644/1762] D loss: 0.1556, G loss: 2.0990\n",
      "[724/1762] D loss: 0.2044, G loss: 1.8733\n",
      "[804/1762] D loss: 1.3885, G loss: 0.9946\n",
      "[884/1762] D loss: 0.0182, G loss: 4.1978\n",
      "[964/1762] D loss: 0.0350, G loss: 3.6089\n",
      "[1044/1762] D loss: 0.0403, G loss: 3.2671\n",
      "[1124/1762] D loss: 0.0759, G loss: 2.8407\n",
      "[1204/1762] D loss: 0.0888, G loss: 2.8541\n",
      "[1284/1762] D loss: 0.1249, G loss: 2.2284\n",
      "[1364/1762] D loss: 0.2428, G loss: 2.6945\n",
      "[1444/1762] D loss: 0.0903, G loss: 2.7328\n",
      "[1524/1762] D loss: 0.0921, G loss: 2.9489\n",
      "[1604/1762] D loss: 0.0968, G loss: 2.7701\n",
      "[1684/1762] D loss: 0.2943, G loss: 1.4068\n",
      "[1762/1762] D loss: 2.5173, G loss: 2.1556\n",
      "train error: \n",
      " D loss: 1.812633, G loss: 1.786984, D accuracy: 53.5%, cell accuracy: 99.6%, board accuracy: 69.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.788122, G loss: 1.777253, D accuracy: 54.4%, cell accuracy: 99.6%, board accuracy: 73.9% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0506, G loss: 2.9998\n",
      "[84/1762] D loss: 1.1372, G loss: 1.0652\n",
      "[164/1762] D loss: 0.1344, G loss: 2.2048\n",
      "[244/1762] D loss: 1.1553, G loss: 2.2648\n",
      "[324/1762] D loss: 0.6071, G loss: 2.1719\n",
      "[404/1762] D loss: 0.0518, G loss: 3.1167\n",
      "[484/1762] D loss: 1.4424, G loss: 1.4373\n",
      "[564/1762] D loss: 1.3066, G loss: 2.2073\n",
      "[644/1762] D loss: 0.7449, G loss: 1.8294\n",
      "[724/1762] D loss: 0.0795, G loss: 2.7468\n",
      "[804/1762] D loss: 1.3929, G loss: 0.8659\n",
      "[884/1762] D loss: 0.3056, G loss: 1.7289\n",
      "[964/1762] D loss: 0.0738, G loss: 3.1112\n",
      "[1044/1762] D loss: 0.4860, G loss: 2.9391\n",
      "[1124/1762] D loss: 0.0337, G loss: 3.8000\n",
      "[1204/1762] D loss: 0.5763, G loss: 2.6533\n",
      "[1284/1762] D loss: 0.4964, G loss: 1.3057\n",
      "[1364/1762] D loss: 0.1605, G loss: 2.2658\n",
      "[1444/1762] D loss: 0.1293, G loss: 2.3117\n",
      "[1524/1762] D loss: 2.1753, G loss: 1.8429\n",
      "[1604/1762] D loss: 0.0399, G loss: 3.3820\n",
      "[1684/1762] D loss: 1.1092, G loss: 0.7851\n",
      "[1762/1762] D loss: 0.0323, G loss: 3.7645\n",
      "train error: \n",
      " D loss: 3.180452, G loss: 0.049888, D accuracy: 50.0%, cell accuracy: 99.5%, board accuracy: 59.5% \n",
      "\n",
      "test error: \n",
      " D loss: 3.174633, G loss: 0.051045, D accuracy: 50.0%, cell accuracy: 99.4%, board accuracy: 59.1% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0332, G loss: 3.5463\n",
      "[84/1762] D loss: 0.0482, G loss: 3.0209\n",
      "[164/1762] D loss: 0.1144, G loss: 2.5241\n",
      "[244/1762] D loss: 0.1877, G loss: 2.5246\n",
      "[324/1762] D loss: 0.0325, G loss: 3.6149\n",
      "[404/1762] D loss: 0.0397, G loss: 3.3638\n",
      "[484/1762] D loss: 0.0735, G loss: 2.9327\n",
      "[564/1762] D loss: 0.0260, G loss: 3.8416\n",
      "[644/1762] D loss: 1.1400, G loss: 0.7185\n",
      "[724/1762] D loss: 0.8864, G loss: 1.5666\n",
      "[804/1762] D loss: 0.0520, G loss: 3.3842\n",
      "[884/1762] D loss: 0.0780, G loss: 2.6287\n",
      "[964/1762] D loss: 0.0347, G loss: 3.5916\n",
      "[1044/1762] D loss: 0.1610, G loss: 3.0838\n",
      "[1124/1762] D loss: 0.1107, G loss: 3.1167\n",
      "[1204/1762] D loss: 0.1858, G loss: 1.8210\n",
      "[1284/1762] D loss: 0.5043, G loss: 1.4798\n",
      "[1364/1762] D loss: 3.2926, G loss: 0.0835\n",
      "[1444/1762] D loss: 0.0941, G loss: 2.5124\n",
      "[1524/1762] D loss: 0.2943, G loss: 1.4660\n",
      "[1604/1762] D loss: 1.2424, G loss: 1.6685\n",
      "[1684/1762] D loss: 0.0235, G loss: 3.8873\n",
      "[1762/1762] D loss: 0.0550, G loss: 2.9362\n",
      "train error: \n",
      " D loss: 2.824292, G loss: 0.071176, D accuracy: 50.0%, cell accuracy: 99.5%, board accuracy: 61.9% \n",
      "\n",
      "test error: \n",
      " D loss: 2.827792, G loss: 0.071402, D accuracy: 50.0%, cell accuracy: 99.4%, board accuracy: 60.5% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0822, G loss: 2.5054\n",
      "[84/1762] D loss: 0.0248, G loss: 3.9945\n",
      "[164/1762] D loss: 0.0441, G loss: 3.2864\n",
      "[244/1762] D loss: 0.0621, G loss: 2.9992\n",
      "[324/1762] D loss: 0.3823, G loss: 1.6229\n",
      "[404/1762] D loss: 0.3974, G loss: 1.6349\n",
      "[484/1762] D loss: 0.0398, G loss: 3.2363\n",
      "[564/1762] D loss: 0.0905, G loss: 2.5311\n",
      "[644/1762] D loss: 0.1905, G loss: 1.8096\n",
      "[724/1762] D loss: 0.0266, G loss: 3.8132\n",
      "[804/1762] D loss: 0.0383, G loss: 3.4086\n",
      "[884/1762] D loss: 0.1112, G loss: 2.5258\n",
      "[964/1762] D loss: 0.0466, G loss: 3.4200\n",
      "[1044/1762] D loss: 0.1081, G loss: 3.3628\n",
      "[1124/1762] D loss: 0.3209, G loss: 1.8802\n",
      "[1204/1762] D loss: 0.0402, G loss: 3.4424\n",
      "[1284/1762] D loss: 0.0315, G loss: 3.4271\n",
      "[1364/1762] D loss: 0.0254, G loss: 4.0315\n",
      "[1444/1762] D loss: 0.0313, G loss: 3.7850\n",
      "[1524/1762] D loss: 0.4471, G loss: 1.8012\n",
      "[1604/1762] D loss: 0.4735, G loss: 2.7487\n",
      "[1684/1762] D loss: 0.2011, G loss: 1.8911\n",
      "[1762/1762] D loss: 0.3493, G loss: 1.2656\n",
      "train error: \n",
      " D loss: 1.549914, G loss: 0.374496, D accuracy: 49.7%, cell accuracy: 99.5%, board accuracy: 65.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.568666, G loss: 0.370560, D accuracy: 49.0%, cell accuracy: 99.5%, board accuracy: 64.3% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5709, G loss: 0.8932\n",
      "[84/1762] D loss: 0.0678, G loss: 2.8257\n",
      "[164/1762] D loss: 0.0238, G loss: 3.9359\n",
      "[244/1762] D loss: 0.1193, G loss: 2.3732\n",
      "[324/1762] D loss: 0.1014, G loss: 2.5623\n",
      "[404/1762] D loss: 2.6192, G loss: 0.8982\n",
      "[484/1762] D loss: 0.2825, G loss: 1.3520\n",
      "[564/1762] D loss: 0.3575, G loss: 2.1990\n",
      "[644/1762] D loss: 0.2028, G loss: 1.8527\n",
      "[724/1762] D loss: 0.6149, G loss: 1.8471\n",
      "[804/1762] D loss: 0.0620, G loss: 3.0900\n",
      "[884/1762] D loss: 0.0270, G loss: 3.6274\n",
      "[964/1762] D loss: 0.8284, G loss: 0.8287\n",
      "[1044/1762] D loss: 3.1645, G loss: 2.9470\n",
      "[1124/1762] D loss: 0.0530, G loss: 3.4206\n",
      "[1204/1762] D loss: 0.4171, G loss: 2.0616\n",
      "[1284/1762] D loss: 0.2368, G loss: 2.5106\n",
      "[1364/1762] D loss: 0.5529, G loss: 0.9588\n",
      "[1444/1762] D loss: 0.1429, G loss: 2.1386\n",
      "[1524/1762] D loss: 0.9435, G loss: 0.7468\n",
      "[1604/1762] D loss: 0.1482, G loss: 2.0627\n",
      "[1684/1762] D loss: 1.9198, G loss: 3.3555\n",
      "[1762/1762] D loss: 1.9137, G loss: 2.9240\n",
      "train error: \n",
      " D loss: 2.279387, G loss: 0.143036, D accuracy: 49.9%, cell accuracy: 99.6%, board accuracy: 68.3% \n",
      "\n",
      "test error: \n",
      " D loss: 2.243303, G loss: 0.147439, D accuracy: 49.9%, cell accuracy: 99.6%, board accuracy: 68.9% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1744, G loss: 2.1846\n",
      "[84/1762] D loss: 1.7587, G loss: 2.8032\n",
      "[164/1762] D loss: 0.1194, G loss: 2.4307\n",
      "[244/1762] D loss: 0.2722, G loss: 1.6716\n",
      "[324/1762] D loss: 0.0511, G loss: 3.1848\n",
      "[404/1762] D loss: 0.1705, G loss: 2.0992\n",
      "[484/1762] D loss: 0.5748, G loss: 1.0060\n",
      "[564/1762] D loss: 1.8673, G loss: 2.2529\n",
      "[644/1762] D loss: 0.1739, G loss: 2.0788\n",
      "[724/1762] D loss: 0.1730, G loss: 2.0178\n",
      "[804/1762] D loss: 0.0260, G loss: 3.9359\n",
      "[884/1762] D loss: 0.0185, G loss: 4.0903\n",
      "[964/1762] D loss: 0.0231, G loss: 4.1919\n",
      "[1044/1762] D loss: 0.1038, G loss: 2.3799\n",
      "[1124/1762] D loss: 0.0322, G loss: 3.8341\n",
      "[1204/1762] D loss: 0.9078, G loss: 0.6790\n",
      "[1284/1762] D loss: 0.0339, G loss: 3.8092\n",
      "[1364/1762] D loss: 0.0272, G loss: 3.7616\n",
      "[1444/1762] D loss: 0.0316, G loss: 3.8879\n",
      "[1524/1762] D loss: 0.0326, G loss: 3.6523\n",
      "[1604/1762] D loss: 2.9126, G loss: 0.1671\n",
      "[1684/1762] D loss: 0.1567, G loss: 1.9311\n",
      "[1762/1762] D loss: 0.0073, G loss: 4.9808\n",
      "train error: \n",
      " D loss: 3.726810, G loss: 0.029054, D accuracy: 50.0%, cell accuracy: 99.5%, board accuracy: 60.3% \n",
      "\n",
      "test error: \n",
      " D loss: 3.677461, G loss: 0.030402, D accuracy: 50.0%, cell accuracy: 99.4%, board accuracy: 59.3% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0502, G loss: 3.1620\n",
      "[84/1762] D loss: 0.0231, G loss: 4.2351\n",
      "[164/1762] D loss: 0.0572, G loss: 3.3227\n",
      "[244/1762] D loss: 0.2270, G loss: 1.6915\n",
      "[324/1762] D loss: 1.3184, G loss: 0.6271\n",
      "[404/1762] D loss: 0.0432, G loss: 3.3426\n",
      "[484/1762] D loss: 0.2233, G loss: 1.8492\n",
      "[564/1762] D loss: 0.5958, G loss: 1.6815\n",
      "[644/1762] D loss: 0.0555, G loss: 3.0860\n",
      "[724/1762] D loss: 0.4244, G loss: 1.9135\n",
      "[804/1762] D loss: 0.2031, G loss: 2.0225\n",
      "[884/1762] D loss: 1.6250, G loss: 0.3651\n",
      "[964/1762] D loss: 0.0663, G loss: 2.9171\n",
      "[1044/1762] D loss: 0.0556, G loss: 3.1916\n",
      "[1124/1762] D loss: 0.0133, G loss: 5.1264\n",
      "[1204/1762] D loss: 0.3621, G loss: 1.4311\n",
      "[1284/1762] D loss: 0.5609, G loss: 1.1592\n",
      "[1364/1762] D loss: 0.5290, G loss: 1.2721\n",
      "[1444/1762] D loss: 0.3587, G loss: 1.3911\n",
      "[1524/1762] D loss: 0.0191, G loss: 3.8333\n",
      "[1604/1762] D loss: 0.2914, G loss: 1.6886\n",
      "[1684/1762] D loss: 0.0084, G loss: 5.0260\n",
      "[1762/1762] D loss: 0.0088, G loss: 4.7570\n",
      "train error: \n",
      " D loss: 1.562861, G loss: 0.564315, D accuracy: 53.3%, cell accuracy: 99.5%, board accuracy: 62.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.533830, G loss: 0.565258, D accuracy: 54.2%, cell accuracy: 99.5%, board accuracy: 61.1% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0194, G loss: 4.1760\n",
      "[84/1762] D loss: 0.8444, G loss: 3.3089\n",
      "[164/1762] D loss: 0.4326, G loss: 1.5456\n",
      "[244/1762] D loss: 0.0427, G loss: 3.4210\n",
      "[324/1762] D loss: 0.0699, G loss: 2.9616\n",
      "[404/1762] D loss: 0.1077, G loss: 2.2434\n",
      "[484/1762] D loss: 0.0241, G loss: 4.0705\n",
      "[564/1762] D loss: 0.0529, G loss: 3.1293\n",
      "[644/1762] D loss: 0.0244, G loss: 3.7876\n",
      "[724/1762] D loss: 0.0238, G loss: 4.0346\n",
      "[804/1762] D loss: 0.1094, G loss: 2.3084\n",
      "[884/1762] D loss: 0.0083, G loss: 4.8580\n",
      "[964/1762] D loss: 0.3408, G loss: 2.1685\n",
      "[1044/1762] D loss: 0.0421, G loss: 3.2030\n",
      "[1124/1762] D loss: 0.0587, G loss: 4.1802\n",
      "[1204/1762] D loss: 0.0096, G loss: 5.0583\n",
      "[1284/1762] D loss: 0.2058, G loss: 1.6946\n",
      "[1364/1762] D loss: 1.7072, G loss: 1.9753\n",
      "[1444/1762] D loss: 0.5884, G loss: 1.2919\n",
      "[1524/1762] D loss: 0.0105, G loss: 5.2857\n",
      "[1604/1762] D loss: 0.9501, G loss: 0.8430\n",
      "[1684/1762] D loss: 0.0382, G loss: 3.5553\n",
      "[1762/1762] D loss: 0.0057, G loss: 5.5580\n",
      "train error: \n",
      " D loss: 1.770832, G loss: 0.300865, D accuracy: 51.0%, cell accuracy: 99.5%, board accuracy: 63.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.761484, G loss: 0.296663, D accuracy: 50.6%, cell accuracy: 99.4%, board accuracy: 60.9% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2110, G loss: 2.0214\n",
      "[84/1762] D loss: 0.3261, G loss: 2.7966\n",
      "[164/1762] D loss: 0.0106, G loss: 4.7744\n",
      "[244/1762] D loss: 0.0596, G loss: 3.6641\n",
      "[324/1762] D loss: 0.0144, G loss: 4.3662\n",
      "[404/1762] D loss: 0.2187, G loss: 1.7961\n",
      "[484/1762] D loss: 0.0814, G loss: 2.9609\n",
      "[564/1762] D loss: 0.0151, G loss: 4.6654\n",
      "[644/1762] D loss: 0.1360, G loss: 2.1590\n",
      "[724/1762] D loss: 0.1113, G loss: 2.4238\n",
      "[804/1762] D loss: 0.1150, G loss: 2.4421\n",
      "[884/1762] D loss: 0.9086, G loss: 3.7295\n",
      "[964/1762] D loss: 1.2982, G loss: 2.1504\n",
      "[1044/1762] D loss: 0.1099, G loss: 3.5559\n",
      "[1124/1762] D loss: 3.1775, G loss: 0.1278\n",
      "[1204/1762] D loss: 0.0265, G loss: 3.8980\n",
      "[1284/1762] D loss: 0.7049, G loss: 1.2647\n",
      "[1364/1762] D loss: 0.0170, G loss: 4.2608\n",
      "[1444/1762] D loss: 0.0109, G loss: 5.3122\n",
      "[1524/1762] D loss: 0.0152, G loss: 4.5166\n",
      "[1604/1762] D loss: 1.8007, G loss: 1.3619\n",
      "[1684/1762] D loss: 0.0090, G loss: 5.0326\n",
      "[1762/1762] D loss: 1.6510, G loss: 0.4645\n",
      "train error: \n",
      " D loss: 1.526441, G loss: 0.595905, D accuracy: 56.6%, cell accuracy: 99.6%, board accuracy: 70.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.479002, G loss: 0.617318, D accuracy: 57.5%, cell accuracy: 99.6%, board accuracy: 69.1% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0562, G loss: 3.1697\n",
      "[84/1762] D loss: 0.5120, G loss: 1.0769\n",
      "[164/1762] D loss: 0.0079, G loss: 5.5073\n",
      "[244/1762] D loss: 0.2026, G loss: 2.4062\n",
      "[324/1762] D loss: 0.0332, G loss: 4.0630\n",
      "[404/1762] D loss: 1.5248, G loss: 0.8935\n",
      "[484/1762] D loss: 0.5001, G loss: 2.3945\n",
      "[564/1762] D loss: 0.0181, G loss: 4.5028\n",
      "[644/1762] D loss: 0.0551, G loss: 3.1790\n",
      "[724/1762] D loss: 1.8018, G loss: 2.1654\n",
      "[804/1762] D loss: 0.0133, G loss: 4.5347\n",
      "[884/1762] D loss: 0.0163, G loss: 4.2620\n",
      "[964/1762] D loss: 2.1032, G loss: 2.8529\n",
      "[1044/1762] D loss: 0.0216, G loss: 3.9561\n",
      "[1124/1762] D loss: 0.0598, G loss: 3.8676\n",
      "[1204/1762] D loss: 0.0869, G loss: 3.5011\n",
      "[1284/1762] D loss: 0.0247, G loss: 3.9593\n",
      "[1364/1762] D loss: 0.0915, G loss: 2.6332\n",
      "[1444/1762] D loss: 0.0106, G loss: 4.9319\n",
      "[1524/1762] D loss: 0.0345, G loss: 3.6024\n",
      "[1604/1762] D loss: 1.9750, G loss: 3.7183\n",
      "[1684/1762] D loss: 1.8905, G loss: 1.6611\n",
      "[1762/1762] D loss: 2.9533, G loss: 2.6794\n",
      "train error: \n",
      " D loss: 1.549303, G loss: 1.234546, D accuracy: 58.5%, cell accuracy: 99.6%, board accuracy: 66.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.498823, G loss: 1.257789, D accuracy: 60.3%, cell accuracy: 99.5%, board accuracy: 65.5% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0097, G loss: 4.8621\n",
      "[84/1762] D loss: 0.1841, G loss: 2.1026\n",
      "[164/1762] D loss: 0.0891, G loss: 2.6798\n",
      "[244/1762] D loss: 0.0814, G loss: 3.1559\n",
      "[324/1762] D loss: 0.0261, G loss: 4.8062\n",
      "[404/1762] D loss: 0.0127, G loss: 4.7428\n",
      "[484/1762] D loss: 0.0567, G loss: 3.1499\n",
      "[564/1762] D loss: 0.1435, G loss: 1.9895\n",
      "[644/1762] D loss: 0.0342, G loss: 3.8489\n",
      "[724/1762] D loss: 0.0955, G loss: 2.4573\n",
      "[804/1762] D loss: 0.0631, G loss: 2.8175\n",
      "[884/1762] D loss: 0.3939, G loss: 1.1797\n",
      "[964/1762] D loss: 0.0771, G loss: 4.8408\n",
      "[1044/1762] D loss: 0.0532, G loss: 3.6796\n",
      "[1124/1762] D loss: 0.0059, G loss: 5.5119\n",
      "[1204/1762] D loss: 0.4105, G loss: 1.6762\n",
      "[1284/1762] D loss: 0.1838, G loss: 3.3900\n",
      "[1364/1762] D loss: 0.1100, G loss: 2.4010\n",
      "[1444/1762] D loss: 0.0216, G loss: 3.8493\n",
      "[1524/1762] D loss: 0.1739, G loss: 2.4112\n",
      "[1604/1762] D loss: 0.1957, G loss: 2.3487\n",
      "[1684/1762] D loss: 0.0558, G loss: 2.7938\n",
      "[1762/1762] D loss: 0.9159, G loss: 2.2339\n",
      "train error: \n",
      " D loss: 1.461154, G loss: 1.061503, D accuracy: 58.2%, cell accuracy: 99.6%, board accuracy: 69.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.461643, G loss: 1.057121, D accuracy: 57.6%, cell accuracy: 99.6%, board accuracy: 65.5% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0089, G loss: 5.1483\n",
      "[84/1762] D loss: 0.0038, G loss: 5.6978\n",
      "[164/1762] D loss: 0.5494, G loss: 0.9466\n",
      "[244/1762] D loss: 4.2458, G loss: 0.2810\n",
      "[324/1762] D loss: 0.0492, G loss: 3.7276\n",
      "[404/1762] D loss: 0.0353, G loss: 3.5265\n",
      "[484/1762] D loss: 0.1081, G loss: 2.3286\n",
      "[564/1762] D loss: 0.5517, G loss: 1.8183\n",
      "[644/1762] D loss: 0.0417, G loss: 3.9677\n",
      "[724/1762] D loss: 0.0105, G loss: 5.2317\n",
      "[804/1762] D loss: 0.0025, G loss: 6.8922\n",
      "[884/1762] D loss: 0.2171, G loss: 3.9758\n",
      "[964/1762] D loss: 0.0383, G loss: 6.5290\n",
      "[1044/1762] D loss: 0.4449, G loss: 1.3022\n",
      "[1124/1762] D loss: 0.5632, G loss: 0.9657\n",
      "[1204/1762] D loss: 0.6574, G loss: 1.0283\n",
      "[1284/1762] D loss: 0.3937, G loss: 1.2870\n",
      "[1364/1762] D loss: 0.5971, G loss: 1.1964\n",
      "[1444/1762] D loss: 0.0051, G loss: 5.9608\n",
      "[1524/1762] D loss: 0.0042, G loss: 6.1969\n",
      "[1604/1762] D loss: 0.0517, G loss: 2.9236\n",
      "[1684/1762] D loss: 1.3278, G loss: 0.6471\n",
      "[1762/1762] D loss: 0.9361, G loss: 1.2900\n",
      "train error: \n",
      " D loss: 1.236746, G loss: 0.866475, D accuracy: 62.3%, cell accuracy: 99.5%, board accuracy: 61.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.246825, G loss: 0.866116, D accuracy: 60.5%, cell accuracy: 99.4%, board accuracy: 60.9% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0353, G loss: 3.9456\n",
      "[84/1762] D loss: 1.3028, G loss: 3.9644\n",
      "[164/1762] D loss: 0.3374, G loss: 2.1082\n",
      "[244/1762] D loss: 0.0030, G loss: 6.5798\n",
      "[324/1762] D loss: 1.9445, G loss: 1.9507\n",
      "[404/1762] D loss: 0.3093, G loss: 1.5368\n",
      "[484/1762] D loss: 0.0910, G loss: 2.8970\n",
      "[564/1762] D loss: 0.6086, G loss: 1.2911\n",
      "[644/1762] D loss: 0.7849, G loss: 3.7260\n",
      "[724/1762] D loss: 0.0164, G loss: 4.3736\n",
      "[804/1762] D loss: 0.0057, G loss: 5.4965\n",
      "[884/1762] D loss: 0.0201, G loss: 4.2769\n",
      "[964/1762] D loss: 0.2024, G loss: 2.0124\n",
      "[1044/1762] D loss: 0.1360, G loss: 5.8741\n",
      "[1124/1762] D loss: 0.1362, G loss: 2.2306\n",
      "[1204/1762] D loss: 0.0025, G loss: 6.5630\n",
      "[1284/1762] D loss: 0.0030, G loss: 6.0499\n",
      "[1364/1762] D loss: 1.5031, G loss: 1.5808\n",
      "[1444/1762] D loss: 0.1460, G loss: 5.7562\n",
      "[1524/1762] D loss: 0.0060, G loss: 5.2739\n",
      "[1604/1762] D loss: 4.1284, G loss: 3.6667\n",
      "[1684/1762] D loss: 0.1879, G loss: 1.9735\n",
      "[1762/1762] D loss: 0.0013, G loss: 6.8741\n",
      "train error: \n",
      " D loss: 1.560551, G loss: 0.780433, D accuracy: 56.1%, cell accuracy: 99.5%, board accuracy: 64.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.545864, G loss: 0.768767, D accuracy: 54.3%, cell accuracy: 99.5%, board accuracy: 62.7% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0930, G loss: 3.4674\n",
      "[84/1762] D loss: 0.0185, G loss: 4.2319\n",
      "[164/1762] D loss: 0.0031, G loss: 6.6552\n",
      "[244/1762] D loss: 0.0878, G loss: 2.6231\n",
      "[324/1762] D loss: 0.0585, G loss: 4.5980\n",
      "[404/1762] D loss: 0.0994, G loss: 2.8551\n",
      "[484/1762] D loss: 0.1911, G loss: 2.3230\n",
      "[564/1762] D loss: 0.8633, G loss: 1.7495\n",
      "[644/1762] D loss: 0.0474, G loss: 3.5707\n",
      "[724/1762] D loss: 0.2951, G loss: 5.8320\n",
      "[804/1762] D loss: 0.0039, G loss: 6.5957\n",
      "[884/1762] D loss: 0.2704, G loss: 4.2240\n",
      "[964/1762] D loss: 0.0119, G loss: 6.5104\n",
      "[1044/1762] D loss: 0.6744, G loss: 1.0150\n",
      "[1124/1762] D loss: 0.0316, G loss: 3.9858\n",
      "[1204/1762] D loss: 1.2034, G loss: 1.3647\n",
      "[1284/1762] D loss: 0.0027, G loss: 6.3935\n",
      "[1364/1762] D loss: 0.0122, G loss: 4.5082\n",
      "[1444/1762] D loss: 0.0033, G loss: 6.0484\n",
      "[1524/1762] D loss: 0.0042, G loss: 6.1818\n",
      "[1604/1762] D loss: 0.3549, G loss: 1.3602\n",
      "[1684/1762] D loss: 0.1142, G loss: 2.6359\n",
      "[1762/1762] D loss: 0.0017, G loss: 6.6809\n",
      "train error: \n",
      " D loss: 1.933739, G loss: 0.269983, D accuracy: 51.9%, cell accuracy: 99.6%, board accuracy: 66.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.899377, G loss: 0.272112, D accuracy: 51.8%, cell accuracy: 99.5%, board accuracy: 65.5% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0082, G loss: 5.2042\n",
      "[84/1762] D loss: 0.1072, G loss: 2.5733\n",
      "[164/1762] D loss: 0.0327, G loss: 3.8429\n",
      "[244/1762] D loss: 0.0053, G loss: 5.8886\n",
      "[324/1762] D loss: 0.0066, G loss: 5.4556\n",
      "[404/1762] D loss: 0.0888, G loss: 4.1696\n",
      "[484/1762] D loss: 1.8269, G loss: 0.5263\n",
      "[564/1762] D loss: 0.0022, G loss: 6.2467\n",
      "[644/1762] D loss: 0.0294, G loss: 4.5927\n",
      "[724/1762] D loss: 0.0683, G loss: 5.6699\n",
      "[804/1762] D loss: 0.1124, G loss: 2.4534\n",
      "[884/1762] D loss: 0.0294, G loss: 3.9488\n",
      "[964/1762] D loss: 0.0383, G loss: 3.7834\n",
      "[1044/1762] D loss: 0.0103, G loss: 5.2618\n",
      "[1124/1762] D loss: 0.0143, G loss: 4.8718\n",
      "[1204/1762] D loss: 0.5556, G loss: 5.8704\n",
      "[1284/1762] D loss: 0.4967, G loss: 2.5110\n",
      "[1364/1762] D loss: 0.1107, G loss: 2.8420\n",
      "[1444/1762] D loss: 0.0938, G loss: 3.4497\n",
      "[1524/1762] D loss: 0.1864, G loss: 2.4591\n",
      "[1604/1762] D loss: 0.9472, G loss: 1.2549\n",
      "[1684/1762] D loss: 1.3951, G loss: 0.4611\n",
      "[1762/1762] D loss: 0.0557, G loss: 7.1995\n",
      "train error: \n",
      " D loss: 2.256727, G loss: 2.553397, D accuracy: 52.9%, cell accuracy: 99.6%, board accuracy: 66.4% \n",
      "\n",
      "test error: \n",
      " D loss: 2.168293, G loss: 2.532183, D accuracy: 53.9%, cell accuracy: 99.5%, board accuracy: 66.8% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4372, G loss: 1.1372\n",
      "[84/1762] D loss: 0.7496, G loss: 1.7801\n",
      "[164/1762] D loss: 0.1037, G loss: 2.5962\n",
      "[244/1762] D loss: 0.0034, G loss: 5.8306\n",
      "[324/1762] D loss: 0.0014, G loss: 7.5254\n",
      "[404/1762] D loss: 0.0021, G loss: 6.4921\n",
      "[484/1762] D loss: 0.0026, G loss: 6.6025\n",
      "[564/1762] D loss: 0.0070, G loss: 5.3625\n",
      "[644/1762] D loss: 0.0345, G loss: 3.4407\n",
      "[724/1762] D loss: 0.0326, G loss: 4.1309\n",
      "[804/1762] D loss: 0.0018, G loss: 7.0518\n",
      "[884/1762] D loss: 0.0017, G loss: 7.0373\n",
      "[964/1762] D loss: 0.0723, G loss: 5.3378\n",
      "[1044/1762] D loss: 0.0155, G loss: 4.4732\n",
      "[1124/1762] D loss: 0.0086, G loss: 5.4638\n",
      "[1204/1762] D loss: 1.4342, G loss: 0.8946\n",
      "[1284/1762] D loss: 0.1168, G loss: 2.0779\n",
      "[1364/1762] D loss: 1.0150, G loss: 1.3076\n",
      "[1444/1762] D loss: 0.0045, G loss: 6.3829\n",
      "[1524/1762] D loss: 0.0037, G loss: 6.2367\n",
      "[1604/1762] D loss: 0.0018, G loss: 6.8772\n",
      "[1684/1762] D loss: 0.0217, G loss: 6.5416\n",
      "[1762/1762] D loss: 0.0122, G loss: 4.5687\n",
      "train error: \n",
      " D loss: 1.533904, G loss: 0.525068, D accuracy: 56.3%, cell accuracy: 99.5%, board accuracy: 62.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.521792, G loss: 0.516018, D accuracy: 55.7%, cell accuracy: 99.5%, board accuracy: 62.0% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0029, G loss: 6.1916\n",
      "[84/1762] D loss: 0.1045, G loss: 3.6912\n",
      "[164/1762] D loss: 0.0420, G loss: 3.6480\n",
      "[244/1762] D loss: 0.1756, G loss: 3.4895\n",
      "[324/1762] D loss: 0.6671, G loss: 1.7289\n",
      "[404/1762] D loss: 0.0051, G loss: 6.8684\n",
      "[484/1762] D loss: 0.9112, G loss: 1.3566\n",
      "[564/1762] D loss: 0.0029, G loss: 6.4432\n",
      "[644/1762] D loss: 3.1383, G loss: 0.5096\n",
      "[724/1762] D loss: 0.0046, G loss: 6.1242\n",
      "[804/1762] D loss: 0.0739, G loss: 2.7215\n",
      "[884/1762] D loss: 0.0199, G loss: 6.6310\n",
      "[964/1762] D loss: 1.6078, G loss: 0.8999\n",
      "[1044/1762] D loss: 0.0087, G loss: 5.3301\n",
      "[1124/1762] D loss: 0.0054, G loss: 5.5236\n",
      "[1204/1762] D loss: 0.0126, G loss: 6.2264\n",
      "[1284/1762] D loss: 0.9484, G loss: 1.1267\n",
      "[1364/1762] D loss: 0.0091, G loss: 5.1940\n",
      "[1444/1762] D loss: 0.0040, G loss: 6.0649\n",
      "[1524/1762] D loss: 0.0212, G loss: 4.0039\n",
      "[1604/1762] D loss: 1.6895, G loss: 2.4515\n",
      "[1684/1762] D loss: 0.1591, G loss: 2.6929\n",
      "[1762/1762] D loss: 1.0821, G loss: 4.4110\n",
      "train error: \n",
      " D loss: 2.186078, G loss: 2.475404, D accuracy: 51.2%, cell accuracy: 99.5%, board accuracy: 62.5% \n",
      "\n",
      "test error: \n",
      " D loss: 2.190487, G loss: 2.498605, D accuracy: 51.1%, cell accuracy: 99.5%, board accuracy: 60.9% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0025, G loss: 6.3082\n",
      "[84/1762] D loss: 0.0415, G loss: 4.1846\n",
      "[164/1762] D loss: 1.3774, G loss: 0.3633\n",
      "[244/1762] D loss: 0.0381, G loss: 5.3837\n",
      "[324/1762] D loss: 0.0348, G loss: 3.8753\n",
      "[404/1762] D loss: 0.0725, G loss: 3.1431\n",
      "[484/1762] D loss: 0.0044, G loss: 6.4201\n",
      "[564/1762] D loss: 0.0004, G loss: 9.3792\n",
      "[644/1762] D loss: 0.0013, G loss: 7.9129\n",
      "[724/1762] D loss: 1.3345, G loss: 0.8835\n",
      "[804/1762] D loss: 0.0023, G loss: 6.7978\n",
      "[884/1762] D loss: 0.0016, G loss: 7.3242\n",
      "[964/1762] D loss: 0.0168, G loss: 5.8134\n",
      "[1044/1762] D loss: 0.0718, G loss: 5.6122\n",
      "[1124/1762] D loss: 0.3167, G loss: 1.7679\n",
      "[1204/1762] D loss: 0.0161, G loss: 6.2218\n",
      "[1284/1762] D loss: 1.2563, G loss: 0.8854\n",
      "[1364/1762] D loss: 0.0036, G loss: 6.3930\n",
      "[1444/1762] D loss: 0.0034, G loss: 6.1888\n",
      "[1524/1762] D loss: 0.0012, G loss: 7.8118\n",
      "[1604/1762] D loss: 0.0238, G loss: 4.6911\n",
      "[1684/1762] D loss: 0.1740, G loss: 1.9454\n",
      "[1762/1762] D loss: 0.0010, G loss: 7.0521\n",
      "train error: \n",
      " D loss: 1.446569, G loss: 0.518538, D accuracy: 56.7%, cell accuracy: 99.5%, board accuracy: 63.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.437852, G loss: 0.508819, D accuracy: 55.8%, cell accuracy: 99.4%, board accuracy: 61.8% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2535, G loss: 0.6724\n",
      "[84/1762] D loss: 0.8580, G loss: 0.9766\n",
      "[164/1762] D loss: 0.0030, G loss: 6.1377\n",
      "[244/1762] D loss: 0.0070, G loss: 6.6536\n",
      "[324/1762] D loss: 0.0196, G loss: 4.4782\n",
      "[404/1762] D loss: 0.0894, G loss: 2.6821\n",
      "[484/1762] D loss: 0.2259, G loss: 2.5974\n",
      "[564/1762] D loss: 0.2513, G loss: 1.8525\n",
      "[644/1762] D loss: 0.0343, G loss: 5.6860\n",
      "[724/1762] D loss: 0.0041, G loss: 6.0904\n",
      "[804/1762] D loss: 0.0280, G loss: 4.6206\n",
      "[884/1762] D loss: 0.0015, G loss: 7.0856\n",
      "[964/1762] D loss: 0.2279, G loss: 1.8453\n",
      "[1044/1762] D loss: 0.0112, G loss: 5.2603\n",
      "[1124/1762] D loss: 0.0016, G loss: 7.2599\n",
      "[1204/1762] D loss: 0.0027, G loss: 8.1093\n",
      "[1284/1762] D loss: 0.0202, G loss: 4.7900\n",
      "[1364/1762] D loss: 0.0018, G loss: 7.8032\n",
      "[1444/1762] D loss: 0.4835, G loss: 1.6377\n",
      "[1524/1762] D loss: 0.0228, G loss: 4.4280\n",
      "[1604/1762] D loss: 0.0803, G loss: 6.4645\n",
      "[1684/1762] D loss: 0.0038, G loss: 6.2077\n",
      "[1762/1762] D loss: 0.0009, G loss: 7.6614\n",
      "train error: \n",
      " D loss: 1.701401, G loss: 2.007066, D accuracy: 59.2%, cell accuracy: 99.6%, board accuracy: 67.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.722936, G loss: 2.009915, D accuracy: 59.5%, cell accuracy: 99.5%, board accuracy: 67.5% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0010, G loss: 8.5719\n",
      "[84/1762] D loss: 0.0026, G loss: 7.0514\n",
      "[164/1762] D loss: 0.0013, G loss: 7.2024\n",
      "[244/1762] D loss: 0.0011, G loss: 6.9852\n",
      "[324/1762] D loss: 0.9299, G loss: 6.8483\n",
      "[404/1762] D loss: 0.0038, G loss: 5.7154\n",
      "[484/1762] D loss: 1.0843, G loss: 1.7123\n",
      "[564/1762] D loss: 0.2393, G loss: 1.9334\n",
      "[644/1762] D loss: 0.6358, G loss: 0.7894\n",
      "[724/1762] D loss: 0.2413, G loss: 2.4206\n",
      "[804/1762] D loss: 0.2677, G loss: 5.2804\n",
      "[884/1762] D loss: 0.0012, G loss: 7.5798\n",
      "[964/1762] D loss: 0.0038, G loss: 6.7819\n",
      "[1044/1762] D loss: 0.2436, G loss: 2.0147\n",
      "[1124/1762] D loss: 0.1800, G loss: 2.4163\n",
      "[1204/1762] D loss: 0.0288, G loss: 3.8886\n",
      "[1284/1762] D loss: 1.6159, G loss: 0.3762\n",
      "[1364/1762] D loss: 0.0675, G loss: 3.5091\n",
      "[1444/1762] D loss: 0.4429, G loss: 2.7652\n",
      "[1524/1762] D loss: 0.0172, G loss: 5.9959\n",
      "[1604/1762] D loss: 0.5451, G loss: 1.7864\n",
      "[1684/1762] D loss: 0.8115, G loss: 1.0182\n",
      "[1762/1762] D loss: 0.0101, G loss: 4.9058\n",
      "train error: \n",
      " D loss: 1.545320, G loss: 0.610820, D accuracy: 59.7%, cell accuracy: 99.5%, board accuracy: 63.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.534125, G loss: 0.589693, D accuracy: 56.8%, cell accuracy: 99.5%, board accuracy: 63.2% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0108, G loss: 4.9659\n",
      "[84/1762] D loss: 1.7097, G loss: 1.1806\n",
      "[164/1762] D loss: 0.0125, G loss: 8.1263\n",
      "[244/1762] D loss: 0.0074, G loss: 7.1349\n",
      "[324/1762] D loss: 0.0697, G loss: 7.1043\n",
      "[404/1762] D loss: 0.8784, G loss: 4.2545\n",
      "[484/1762] D loss: 0.1914, G loss: 1.3548\n",
      "[564/1762] D loss: 1.1190, G loss: 2.2359\n",
      "[644/1762] D loss: 0.5217, G loss: 3.4649\n",
      "[724/1762] D loss: 0.0032, G loss: 7.1326\n",
      "[804/1762] D loss: 0.0037, G loss: 6.9895\n",
      "[884/1762] D loss: 0.0452, G loss: 3.8817\n",
      "[964/1762] D loss: 0.0054, G loss: 5.9745\n",
      "[1044/1762] D loss: 0.1611, G loss: 7.1361\n",
      "[1124/1762] D loss: 0.0048, G loss: 6.3305\n",
      "[1204/1762] D loss: 0.0602, G loss: 7.0507\n",
      "[1284/1762] D loss: 0.0273, G loss: 4.4576\n",
      "[1364/1762] D loss: 0.4679, G loss: 3.5514\n",
      "[1444/1762] D loss: 0.0021, G loss: 6.8552\n",
      "[1524/1762] D loss: 0.0041, G loss: 6.1116\n",
      "[1604/1762] D loss: 1.4257, G loss: 0.9029\n",
      "[1684/1762] D loss: 0.0044, G loss: 6.0919\n",
      "[1762/1762] D loss: 3.1067, G loss: 0.1357\n",
      "train error: \n",
      " D loss: 2.114354, G loss: 0.221757, D accuracy: 51.6%, cell accuracy: 99.5%, board accuracy: 62.2% \n",
      "\n",
      "test error: \n",
      " D loss: 2.092808, G loss: 0.207816, D accuracy: 51.1%, cell accuracy: 99.5%, board accuracy: 63.4% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0417, G loss: 3.3388\n",
      "[84/1762] D loss: 0.0666, G loss: 3.0652\n",
      "[164/1762] D loss: 0.5142, G loss: 3.7309\n",
      "[244/1762] D loss: 0.0016, G loss: 7.0281\n",
      "[324/1762] D loss: 1.6965, G loss: 0.4845\n",
      "[404/1762] D loss: 0.0259, G loss: 4.0619\n",
      "[484/1762] D loss: 0.5093, G loss: 1.1756\n",
      "[564/1762] D loss: 0.0229, G loss: 7.0068\n",
      "[644/1762] D loss: 2.3888, G loss: 2.3800\n",
      "[724/1762] D loss: 0.0505, G loss: 3.3250\n",
      "[804/1762] D loss: 0.8185, G loss: 1.1989\n",
      "[884/1762] D loss: 0.0041, G loss: 5.8824\n",
      "[964/1762] D loss: 0.0662, G loss: 3.0274\n",
      "[1044/1762] D loss: 0.0023, G loss: 6.7111\n",
      "[1124/1762] D loss: 0.8969, G loss: 0.8713\n",
      "[1204/1762] D loss: 0.0374, G loss: 4.0241\n",
      "[1284/1762] D loss: 0.0364, G loss: 3.5232\n",
      "[1364/1762] D loss: 0.0022, G loss: 7.1102\n",
      "[1444/1762] D loss: 0.0006, G loss: 8.0082\n",
      "[1524/1762] D loss: 0.7005, G loss: 4.3075\n",
      "[1604/1762] D loss: 0.0328, G loss: 4.1757\n",
      "[1684/1762] D loss: 0.0025, G loss: 6.4361\n",
      "[1762/1762] D loss: 1.6138, G loss: 1.2328\n",
      "train error: \n",
      " D loss: 1.751344, G loss: 0.650331, D accuracy: 58.5%, cell accuracy: 99.5%, board accuracy: 61.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.710660, G loss: 0.671804, D accuracy: 58.3%, cell accuracy: 99.4%, board accuracy: 60.7% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0008, G loss: 7.5532\n",
      "[84/1762] D loss: 0.0029, G loss: 6.2808\n",
      "[164/1762] D loss: 0.0012, G loss: 7.4350\n",
      "[244/1762] D loss: 0.0029, G loss: 6.7530\n",
      "[324/1762] D loss: 0.0065, G loss: 5.3438\n",
      "[404/1762] D loss: 0.2661, G loss: 1.8083\n",
      "[484/1762] D loss: 0.4755, G loss: 3.2885\n",
      "[564/1762] D loss: 0.1841, G loss: 3.6776\n",
      "[644/1762] D loss: 0.0018, G loss: 6.9979\n",
      "[724/1762] D loss: 0.0097, G loss: 5.1829\n",
      "[804/1762] D loss: 0.0086, G loss: 5.0463\n",
      "[884/1762] D loss: 0.0134, G loss: 5.7594\n",
      "[964/1762] D loss: 0.0146, G loss: 4.3545\n",
      "[1044/1762] D loss: 0.0050, G loss: 5.4851\n",
      "[1124/1762] D loss: 0.0063, G loss: 5.7507\n",
      "[1204/1762] D loss: 0.1284, G loss: 2.3055\n",
      "[1284/1762] D loss: 0.0058, G loss: 5.5082\n",
      "[1364/1762] D loss: 0.0027, G loss: 6.3881\n",
      "[1444/1762] D loss: 0.3978, G loss: 4.6056\n",
      "[1524/1762] D loss: 0.0048, G loss: 5.8631\n",
      "[1604/1762] D loss: 0.0018, G loss: 7.0158\n",
      "[1684/1762] D loss: 0.4610, G loss: 4.8889\n",
      "[1762/1762] D loss: 0.0761, G loss: 3.5722\n",
      "train error: \n",
      " D loss: 1.485514, G loss: 1.571063, D accuracy: 62.1%, cell accuracy: 99.6%, board accuracy: 65.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.511728, G loss: 1.544494, D accuracy: 60.1%, cell accuracy: 99.5%, board accuracy: 67.0% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.6514, G loss: 1.4068\n",
      "[84/1762] D loss: 0.0031, G loss: 6.0750\n",
      "[164/1762] D loss: 0.0063, G loss: 5.4414\n",
      "[244/1762] D loss: 0.1168, G loss: 5.2394\n",
      "[324/1762] D loss: 0.0028, G loss: 7.2989\n",
      "[404/1762] D loss: 1.1361, G loss: 1.9761\n",
      "[484/1762] D loss: 0.6352, G loss: 2.0794\n",
      "[564/1762] D loss: 0.0019, G loss: 6.3894\n",
      "[644/1762] D loss: 2.7094, G loss: 0.6914\n",
      "[724/1762] D loss: 0.0054, G loss: 7.0756\n",
      "[804/1762] D loss: 0.0121, G loss: 4.6556\n",
      "[884/1762] D loss: 2.3558, G loss: 2.3059\n",
      "[964/1762] D loss: 0.0191, G loss: 4.4722\n",
      "[1044/1762] D loss: 0.0114, G loss: 8.1363\n",
      "[1124/1762] D loss: 0.1457, G loss: 2.3126\n",
      "[1204/1762] D loss: 0.0016, G loss: 6.8869\n",
      "[1284/1762] D loss: 0.7264, G loss: 2.0639\n",
      "[1364/1762] D loss: 0.0013, G loss: 8.1003\n",
      "[1444/1762] D loss: 0.0098, G loss: 5.2952\n",
      "[1524/1762] D loss: 0.2348, G loss: 5.3146\n",
      "[1604/1762] D loss: 1.0091, G loss: 0.6906\n",
      "[1684/1762] D loss: 0.0038, G loss: 6.2481\n",
      "[1762/1762] D loss: 0.5063, G loss: 2.0455\n",
      "train error: \n",
      " D loss: 1.264511, G loss: 0.945882, D accuracy: 60.1%, cell accuracy: 99.5%, board accuracy: 65.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.272153, G loss: 0.997323, D accuracy: 59.7%, cell accuracy: 99.5%, board accuracy: 66.8% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0255, G loss: 5.3221\n",
      "[84/1762] D loss: 0.9544, G loss: 0.7649\n",
      "[164/1762] D loss: 0.0056, G loss: 6.4973\n",
      "[244/1762] D loss: 1.3535, G loss: 1.0559\n",
      "[324/1762] D loss: 1.5589, G loss: 1.1245\n",
      "[404/1762] D loss: 0.8124, G loss: 1.7904\n",
      "[484/1762] D loss: 0.1241, G loss: 3.7186\n",
      "[564/1762] D loss: 0.0056, G loss: 6.3257\n",
      "[644/1762] D loss: 0.6570, G loss: 2.1033\n",
      "[724/1762] D loss: 0.0017, G loss: 6.3995\n",
      "[804/1762] D loss: 0.1392, G loss: 2.5448\n",
      "[884/1762] D loss: 0.1077, G loss: 3.0291\n",
      "[964/1762] D loss: 0.0055, G loss: 6.2846\n",
      "[1044/1762] D loss: 0.0006, G loss: 7.7658\n",
      "[1124/1762] D loss: 0.0040, G loss: 6.2197\n",
      "[1204/1762] D loss: 0.0009, G loss: 7.7629\n",
      "[1284/1762] D loss: 0.0011, G loss: 7.4641\n",
      "[1364/1762] D loss: 0.0030, G loss: 6.3635\n",
      "[1444/1762] D loss: 0.0010, G loss: 8.0992\n",
      "[1524/1762] D loss: 3.3484, G loss: 0.0835\n",
      "[1604/1762] D loss: 1.0813, G loss: 1.3885\n",
      "[1684/1762] D loss: 0.4167, G loss: 3.5195\n",
      "[1762/1762] D loss: 0.0074, G loss: 5.7726\n",
      "train error: \n",
      " D loss: 1.341931, G loss: 0.721983, D accuracy: 59.5%, cell accuracy: 99.5%, board accuracy: 64.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.342104, G loss: 0.714607, D accuracy: 60.5%, cell accuracy: 99.5%, board accuracy: 62.5% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3881, G loss: 0.6730\n",
      "[84/1762] D loss: 1.1588, G loss: 1.0000\n",
      "[164/1762] D loss: 0.3097, G loss: 3.7814\n",
      "[244/1762] D loss: 0.1127, G loss: 8.4949\n",
      "[324/1762] D loss: 0.0714, G loss: 6.0999\n",
      "[404/1762] D loss: 0.0612, G loss: 6.0592\n",
      "[484/1762] D loss: 0.0618, G loss: 5.9050\n",
      "[564/1762] D loss: 1.1352, G loss: 2.3440\n",
      "[644/1762] D loss: 0.3860, G loss: 2.2267\n",
      "[724/1762] D loss: 0.2463, G loss: 1.9093\n",
      "[804/1762] D loss: 1.4402, G loss: 6.9475\n",
      "[884/1762] D loss: 0.2250, G loss: 3.2329\n",
      "[964/1762] D loss: 0.0463, G loss: 5.1364\n",
      "[1044/1762] D loss: 0.2027, G loss: 2.8334\n",
      "[1124/1762] D loss: 0.1970, G loss: 3.0804\n",
      "[1204/1762] D loss: 0.2197, G loss: 2.3776\n",
      "[1284/1762] D loss: 0.1574, G loss: 6.2877\n",
      "[1364/1762] D loss: 0.0540, G loss: 4.0971\n",
      "[1444/1762] D loss: 0.0943, G loss: 3.9034\n",
      "[1524/1762] D loss: 0.2836, G loss: 3.7218\n",
      "[1604/1762] D loss: 0.3156, G loss: 10.1711\n",
      "[1684/1762] D loss: 0.8129, G loss: 3.8136\n",
      "[1762/1762] D loss: 0.0037, G loss: 6.4533\n",
      "train error: \n",
      " D loss: 0.075890, G loss: 4.896885, D accuracy: 99.9%, cell accuracy: 87.8%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.081412, G loss: 4.937447, D accuracy: 100.0%, cell accuracy: 87.5%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1082, G loss: 3.4612\n",
      "[84/1762] D loss: 0.0358, G loss: 5.1789\n",
      "[164/1762] D loss: 0.2243, G loss: 7.0120\n",
      "[244/1762] D loss: 0.0609, G loss: 7.1061\n",
      "[324/1762] D loss: 0.0629, G loss: 2.8257\n",
      "[404/1762] D loss: 0.2948, G loss: 5.5172\n",
      "[484/1762] D loss: 0.6747, G loss: 4.9793\n",
      "[564/1762] D loss: 0.5962, G loss: 4.0700\n",
      "[644/1762] D loss: 0.0511, G loss: 4.7167\n",
      "[724/1762] D loss: 0.1339, G loss: 7.2369\n",
      "[804/1762] D loss: 0.2389, G loss: 4.1343\n",
      "[884/1762] D loss: 0.1245, G loss: 4.7954\n",
      "[964/1762] D loss: 0.6785, G loss: 3.8323\n",
      "[1044/1762] D loss: 0.2095, G loss: 6.0339\n",
      "[1124/1762] D loss: 0.4284, G loss: 3.8365\n",
      "[1204/1762] D loss: 0.1348, G loss: 6.5848\n",
      "[1284/1762] D loss: 0.2109, G loss: 3.5407\n",
      "[1364/1762] D loss: 1.7461, G loss: 6.9097\n",
      "[1444/1762] D loss: 0.0645, G loss: 5.6400\n",
      "[1524/1762] D loss: 0.1885, G loss: 4.5612\n",
      "[1604/1762] D loss: 0.5083, G loss: 4.3701\n",
      "[1684/1762] D loss: 0.2865, G loss: 7.4789\n",
      "[1762/1762] D loss: 0.0027, G loss: 8.6126\n",
      "train error: \n",
      " D loss: 0.279595, G loss: 6.961391, D accuracy: 93.0%, cell accuracy: 94.6%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.326379, G loss: 7.030875, D accuracy: 91.7%, cell accuracy: 94.4%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8219, G loss: 2.8320\n",
      "[84/1762] D loss: 0.2662, G loss: 6.1958\n",
      "[164/1762] D loss: 0.1063, G loss: 3.8875\n",
      "[244/1762] D loss: 0.0779, G loss: 4.6884\n",
      "[324/1762] D loss: 0.1851, G loss: 4.4151\n",
      "[404/1762] D loss: 0.3005, G loss: 3.6129\n",
      "[484/1762] D loss: 0.0371, G loss: 5.1556\n",
      "[564/1762] D loss: 0.2476, G loss: 5.0165\n",
      "[644/1762] D loss: 0.0929, G loss: 6.0795\n",
      "[724/1762] D loss: 0.0557, G loss: 5.7838\n",
      "[804/1762] D loss: 0.0990, G loss: 6.4210\n",
      "[884/1762] D loss: 0.0701, G loss: 7.0999\n",
      "[964/1762] D loss: 0.0087, G loss: 8.4274\n",
      "[1044/1762] D loss: 0.5574, G loss: 6.5562\n",
      "[1124/1762] D loss: 0.0706, G loss: 6.6211\n",
      "[1204/1762] D loss: 0.0046, G loss: 9.2124\n",
      "[1284/1762] D loss: 0.0088, G loss: 5.9074\n",
      "[1364/1762] D loss: 0.3391, G loss: 7.9328\n",
      "[1444/1762] D loss: 0.0558, G loss: 8.2128\n",
      "[1524/1762] D loss: 3.2875, G loss: 0.4533\n",
      "[1604/1762] D loss: 0.1695, G loss: 3.3090\n",
      "[1684/1762] D loss: 0.0886, G loss: 6.2605\n",
      "[1762/1762] D loss: 0.1218, G loss: 3.7977\n",
      "train error: \n",
      " D loss: 0.258499, G loss: 6.795564, D accuracy: 92.4%, cell accuracy: 96.4%, board accuracy: 0.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.302132, G loss: 6.863026, D accuracy: 91.0%, cell accuracy: 96.4%, board accuracy: 0.5% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0305, G loss: 7.9329\n",
      "[84/1762] D loss: 1.2735, G loss: 8.6262\n",
      "[164/1762] D loss: 1.0721, G loss: 5.1512\n",
      "[244/1762] D loss: 0.0878, G loss: 3.5268\n",
      "[324/1762] D loss: 0.3904, G loss: 2.4273\n",
      "[404/1762] D loss: 0.0150, G loss: 5.9036\n",
      "[484/1762] D loss: 0.0683, G loss: 7.7277\n",
      "[564/1762] D loss: 0.6981, G loss: 5.5552\n",
      "[644/1762] D loss: 0.0746, G loss: 3.5497\n",
      "[724/1762] D loss: 0.0058, G loss: 5.9954\n",
      "[804/1762] D loss: 0.1474, G loss: 4.5186\n",
      "[884/1762] D loss: 0.4713, G loss: 4.1198\n",
      "[964/1762] D loss: 0.0150, G loss: 8.3520\n",
      "[1044/1762] D loss: 0.0045, G loss: 8.6683\n",
      "[1124/1762] D loss: 0.0027, G loss: 8.1520\n",
      "[1204/1762] D loss: 0.0566, G loss: 5.5914\n",
      "[1284/1762] D loss: 0.0029, G loss: 6.5151\n",
      "[1364/1762] D loss: 0.0541, G loss: 6.1732\n",
      "[1444/1762] D loss: 0.0030, G loss: 5.2943\n",
      "[1524/1762] D loss: 1.5831, G loss: 4.2817\n",
      "[1604/1762] D loss: 0.0216, G loss: 10.8526\n",
      "[1684/1762] D loss: 0.0207, G loss: 4.2780\n",
      "[1762/1762] D loss: 0.0442, G loss: 5.2119\n",
      "train error: \n",
      " D loss: 0.261387, G loss: 3.811802, D accuracy: 96.8%, cell accuracy: 97.1%, board accuracy: 11.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.270407, G loss: 3.889242, D accuracy: 95.8%, cell accuracy: 96.9%, board accuracy: 8.6% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2197, G loss: 5.5613\n",
      "[84/1762] D loss: 0.2041, G loss: 5.4105\n",
      "[164/1762] D loss: 0.2879, G loss: 5.3081\n",
      "[244/1762] D loss: 0.5168, G loss: 4.8815\n",
      "[324/1762] D loss: 0.0654, G loss: 3.5920\n",
      "[404/1762] D loss: 0.1072, G loss: 5.8584\n",
      "[484/1762] D loss: 0.0000, G loss: 10.8555\n",
      "[564/1762] D loss: 0.2943, G loss: 7.5554\n",
      "[644/1762] D loss: 0.1678, G loss: 5.0522\n",
      "[724/1762] D loss: 0.1458, G loss: 6.8606\n",
      "[804/1762] D loss: 0.1154, G loss: 2.9404\n",
      "[884/1762] D loss: 1.0239, G loss: 4.6187\n",
      "[964/1762] D loss: 0.6866, G loss: 3.4057\n",
      "[1044/1762] D loss: 0.1415, G loss: 8.9658\n",
      "[1124/1762] D loss: 0.1142, G loss: 4.7258\n",
      "[1204/1762] D loss: 0.0078, G loss: 7.9534\n",
      "[1284/1762] D loss: 0.0906, G loss: 4.8124\n",
      "[1364/1762] D loss: 0.0239, G loss: 4.1921\n",
      "[1444/1762] D loss: 0.0021, G loss: 8.5617\n",
      "[1524/1762] D loss: 0.0552, G loss: 7.9109\n",
      "[1604/1762] D loss: 0.0227, G loss: 1.2870\n",
      "[1684/1762] D loss: 0.7273, G loss: 1.5003\n",
      "[1762/1762] D loss: 0.2730, G loss: 2.8230\n",
      "train error: \n",
      " D loss: 0.383272, G loss: 1.879807, D accuracy: 95.8%, cell accuracy: 96.6%, board accuracy: 0.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.406582, G loss: 1.874192, D accuracy: 95.0%, cell accuracy: 96.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3916, G loss: 0.7634\n",
      "[84/1762] D loss: 1.3746, G loss: 0.6669\n",
      "[164/1762] D loss: 1.1490, G loss: 0.7316\n",
      "[244/1762] D loss: 0.7197, G loss: 0.8133\n",
      "[324/1762] D loss: 0.8001, G loss: 0.8686\n",
      "[404/1762] D loss: 0.3630, G loss: 1.3067\n",
      "[484/1762] D loss: 0.4441, G loss: 1.9944\n",
      "[564/1762] D loss: 0.1806, G loss: 2.6170\n",
      "[644/1762] D loss: 0.1931, G loss: 2.5153\n",
      "[724/1762] D loss: 0.0899, G loss: 3.3992\n",
      "[804/1762] D loss: 1.5890, G loss: 1.7159\n",
      "[884/1762] D loss: 0.0289, G loss: 3.9437\n",
      "[964/1762] D loss: 0.4100, G loss: 2.9305\n",
      "[1044/1762] D loss: 0.1051, G loss: 4.8559\n",
      "[1124/1762] D loss: 0.2840, G loss: 3.1083\n",
      "[1204/1762] D loss: 0.9916, G loss: 4.3892\n",
      "[1284/1762] D loss: 0.0985, G loss: 2.8837\n",
      "[1364/1762] D loss: 0.0741, G loss: 4.5181\n",
      "[1444/1762] D loss: 0.0103, G loss: 5.7299\n",
      "[1524/1762] D loss: 0.2150, G loss: 6.2119\n",
      "[1604/1762] D loss: 0.0291, G loss: 3.8121\n",
      "[1684/1762] D loss: 0.3040, G loss: 3.7451\n",
      "[1762/1762] D loss: 0.0131, G loss: 6.1652\n",
      "train error: \n",
      " D loss: 0.115478, G loss: 4.841541, D accuracy: 98.0%, cell accuracy: 97.0%, board accuracy: 0.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.123240, G loss: 4.881543, D accuracy: 97.6%, cell accuracy: 96.9%, board accuracy: 0.9% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0043, G loss: 5.9794\n",
      "[84/1762] D loss: 0.0613, G loss: 4.7344\n",
      "[164/1762] D loss: 0.2877, G loss: 5.5965\n",
      "[244/1762] D loss: 0.0599, G loss: 4.2224\n",
      "[324/1762] D loss: 0.0201, G loss: 6.3421\n",
      "[404/1762] D loss: 0.0005, G loss: 8.9983\n",
      "[484/1762] D loss: 0.0591, G loss: 4.6130\n",
      "[564/1762] D loss: 0.0095, G loss: 4.5798\n",
      "[644/1762] D loss: 0.0114, G loss: 7.7241\n",
      "[724/1762] D loss: 0.0106, G loss: 8.5392\n",
      "[804/1762] D loss: 0.0172, G loss: 8.5536\n",
      "[884/1762] D loss: 1.5903, G loss: 3.8213\n",
      "[964/1762] D loss: 0.0046, G loss: 7.3582\n",
      "[1044/1762] D loss: 0.0107, G loss: 6.0936\n",
      "[1124/1762] D loss: 0.0082, G loss: 5.3148\n",
      "[1204/1762] D loss: 0.0009, G loss: 8.9223\n",
      "[1284/1762] D loss: 0.1745, G loss: 5.4850\n",
      "[1364/1762] D loss: 0.0041, G loss: 8.0905\n",
      "[1444/1762] D loss: 0.0063, G loss: 7.6997\n",
      "[1524/1762] D loss: 0.2201, G loss: 2.4898\n",
      "[1604/1762] D loss: 0.0195, G loss: 6.3282\n",
      "[1684/1762] D loss: 0.0030, G loss: 7.4332\n",
      "[1762/1762] D loss: 0.0218, G loss: 3.8310\n",
      "train error: \n",
      " D loss: 0.049952, G loss: 6.256889, D accuracy: 99.1%, cell accuracy: 97.1%, board accuracy: 0.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.082808, G loss: 6.267506, D accuracy: 98.3%, cell accuracy: 97.0%, board accuracy: 1.4% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0124, G loss: 5.2017\n",
      "[84/1762] D loss: 0.0057, G loss: 7.7418\n",
      "[164/1762] D loss: 0.0104, G loss: 7.7260\n",
      "[244/1762] D loss: 0.0026, G loss: 8.6053\n",
      "[324/1762] D loss: 0.0008, G loss: 11.1795\n",
      "[404/1762] D loss: 0.0008, G loss: 10.7199\n",
      "[484/1762] D loss: 0.0006, G loss: 10.2467\n",
      "[564/1762] D loss: 0.0049, G loss: 7.7610\n",
      "[644/1762] D loss: 0.0021, G loss: 9.6253\n",
      "[724/1762] D loss: 0.3439, G loss: 6.6527\n",
      "[804/1762] D loss: 0.0004, G loss: 8.8272\n",
      "[884/1762] D loss: 0.0307, G loss: 7.0132\n",
      "[964/1762] D loss: 0.0002, G loss: 11.2387\n",
      "[1044/1762] D loss: 0.0022, G loss: 6.4699\n",
      "[1124/1762] D loss: 0.1397, G loss: 3.7936\n",
      "[1204/1762] D loss: 0.0250, G loss: 10.8822\n",
      "[1284/1762] D loss: 0.0011, G loss: 7.3541\n",
      "[1364/1762] D loss: 0.0004, G loss: 12.8052\n",
      "[1444/1762] D loss: 0.0033, G loss: 8.6369\n",
      "[1524/1762] D loss: 0.0042, G loss: 8.1257\n",
      "[1604/1762] D loss: 0.0001, G loss: 11.7764\n",
      "[1684/1762] D loss: 0.0251, G loss: 4.8731\n",
      "[1762/1762] D loss: 0.0260, G loss: 5.0075\n",
      "train error: \n",
      " D loss: 0.020762, G loss: 8.051445, D accuracy: 99.7%, cell accuracy: 97.1%, board accuracy: 0.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.023846, G loss: 8.124811, D accuracy: 99.7%, cell accuracy: 97.0%, board accuracy: 0.5% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0002, G loss: 10.7481\n",
      "[84/1762] D loss: 0.1544, G loss: 7.4356\n",
      "[164/1762] D loss: 0.3154, G loss: 4.8456\n",
      "[244/1762] D loss: 0.0005, G loss: 10.6976\n",
      "[324/1762] D loss: 0.0039, G loss: 8.3746\n",
      "[404/1762] D loss: 0.0160, G loss: 5.9382\n",
      "[484/1762] D loss: 0.0040, G loss: 6.0855\n",
      "[564/1762] D loss: 0.0011, G loss: 7.4566\n",
      "[644/1762] D loss: 0.0004, G loss: 15.6893\n",
      "[724/1762] D loss: 0.0001, G loss: 15.6200\n",
      "[804/1762] D loss: 0.0007, G loss: 9.3643\n",
      "[884/1762] D loss: 0.0001, G loss: 10.8342\n",
      "[964/1762] D loss: 0.0003, G loss: 13.3854\n",
      "[1044/1762] D loss: 0.0001, G loss: 12.5576\n",
      "[1124/1762] D loss: 0.0105, G loss: 10.5652\n",
      "[1204/1762] D loss: 0.0023, G loss: 8.9848\n",
      "[1284/1762] D loss: 0.0043, G loss: 7.4088\n",
      "[1364/1762] D loss: 0.0032, G loss: 7.6944\n",
      "[1444/1762] D loss: 0.2371, G loss: 10.3277\n",
      "[1524/1762] D loss: 0.0234, G loss: 7.2933\n",
      "[1604/1762] D loss: 0.0036, G loss: 7.5760\n",
      "[1684/1762] D loss: 0.0106, G loss: 6.5481\n",
      "[1762/1762] D loss: 0.0135, G loss: 5.0848\n",
      "train error: \n",
      " D loss: 0.030019, G loss: 8.637267, D accuracy: 99.4%, cell accuracy: 97.1%, board accuracy: 0.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.054892, G loss: 8.557272, D accuracy: 99.1%, cell accuracy: 97.0%, board accuracy: 0.7% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0063, G loss: 6.0508\n",
      "[84/1762] D loss: 0.0005, G loss: 10.4515\n",
      "[164/1762] D loss: 0.0008, G loss: 15.1973\n",
      "[244/1762] D loss: 0.0001, G loss: 13.9228\n",
      "[324/1762] D loss: 0.0032, G loss: 10.2349\n",
      "[404/1762] D loss: 0.0038, G loss: 9.4242\n",
      "[484/1762] D loss: 0.0019, G loss: 12.7441\n",
      "[564/1762] D loss: 0.0001, G loss: 13.4012\n",
      "[644/1762] D loss: 0.0097, G loss: 10.4243\n",
      "[724/1762] D loss: 0.0173, G loss: 8.4405\n",
      "[804/1762] D loss: 0.0003, G loss: 12.3947\n",
      "[884/1762] D loss: 0.0070, G loss: 8.8294\n",
      "[964/1762] D loss: 0.0020, G loss: 8.6763\n",
      "[1044/1762] D loss: 0.0020, G loss: 7.6340\n",
      "[1124/1762] D loss: 0.0009, G loss: 10.0457\n",
      "[1204/1762] D loss: 0.0000, G loss: 15.2024\n",
      "[1284/1762] D loss: 0.0006, G loss: 12.7131\n",
      "[1364/1762] D loss: 0.0016, G loss: 9.4431\n",
      "[1444/1762] D loss: 0.0008, G loss: 12.4761\n",
      "[1524/1762] D loss: 0.0012, G loss: 8.1962\n",
      "[1604/1762] D loss: 0.0001, G loss: 11.0206\n",
      "[1684/1762] D loss: 0.0101, G loss: 6.1897\n",
      "[1762/1762] D loss: 0.0221, G loss: 11.1626\n",
      "train error: \n",
      " D loss: 0.239914, G loss: 11.645467, D accuracy: 93.8%, cell accuracy: 97.0%, board accuracy: 0.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.226483, G loss: 11.566863, D accuracy: 94.2%, cell accuracy: 97.0%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0171, G loss: 10.7883\n",
      "[84/1762] D loss: 1.6061, G loss: 5.9759\n",
      "[164/1762] D loss: 0.0202, G loss: 7.6049\n",
      "[244/1762] D loss: 0.0045, G loss: 14.0363\n",
      "[324/1762] D loss: 0.0012, G loss: 13.7842\n",
      "[404/1762] D loss: 0.2379, G loss: 13.7504\n",
      "[484/1762] D loss: 0.0005, G loss: 9.3072\n",
      "[564/1762] D loss: 0.0160, G loss: 12.6855\n",
      "[644/1762] D loss: 0.0054, G loss: 6.2723\n",
      "[724/1762] D loss: 0.0039, G loss: 11.9047\n",
      "[804/1762] D loss: 0.0026, G loss: 6.4085\n",
      "[884/1762] D loss: 0.0014, G loss: 8.8894\n",
      "[964/1762] D loss: 0.0041, G loss: 7.4967\n",
      "[1044/1762] D loss: 0.9177, G loss: 6.1681\n",
      "[1124/1762] D loss: 0.0023, G loss: 7.7707\n",
      "[1204/1762] D loss: 0.0031, G loss: 11.4363\n",
      "[1284/1762] D loss: 0.0028, G loss: 9.2480\n",
      "[1364/1762] D loss: 0.0041, G loss: 7.9030\n",
      "[1444/1762] D loss: 0.0007, G loss: 15.0655\n",
      "[1524/1762] D loss: 0.0012, G loss: 7.5460\n",
      "[1604/1762] D loss: 0.0000, G loss: 20.3615\n",
      "[1684/1762] D loss: 0.0117, G loss: 13.2487\n",
      "[1762/1762] D loss: 0.0013, G loss: 9.3413\n",
      "train error: \n",
      " D loss: 0.014714, G loss: 9.797907, D accuracy: 99.7%, cell accuracy: 97.0%, board accuracy: 0.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.018523, G loss: 9.773843, D accuracy: 99.7%, cell accuracy: 96.9%, board accuracy: 0.5% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0202, G loss: 10.7529\n",
      "[84/1762] D loss: 0.0009, G loss: 10.3099\n",
      "[164/1762] D loss: 0.0071, G loss: 9.1844\n",
      "[244/1762] D loss: 0.0037, G loss: 8.3969\n",
      "[324/1762] D loss: 0.0001, G loss: 15.6947\n",
      "[404/1762] D loss: 0.0318, G loss: 11.6521\n",
      "[484/1762] D loss: 0.0022, G loss: 11.6112\n",
      "[564/1762] D loss: 0.0033, G loss: 9.6828\n",
      "[644/1762] D loss: 0.0034, G loss: 11.3834\n",
      "[724/1762] D loss: 0.0068, G loss: 10.6038\n",
      "[804/1762] D loss: 0.0044, G loss: 10.9801\n",
      "[884/1762] D loss: 0.0013, G loss: 19.0381\n",
      "[964/1762] D loss: 0.0033, G loss: 8.3398\n",
      "[1044/1762] D loss: 0.0007, G loss: 14.4456\n",
      "[1124/1762] D loss: 0.0010, G loss: 14.3183\n",
      "[1204/1762] D loss: 0.0006, G loss: 18.1132\n",
      "[1284/1762] D loss: 0.0741, G loss: 9.0475\n",
      "[1364/1762] D loss: 0.0002, G loss: 10.8713\n",
      "[1444/1762] D loss: 0.0000, G loss: 14.0384\n",
      "[1524/1762] D loss: 0.0004, G loss: 12.9861\n",
      "[1604/1762] D loss: 0.0002, G loss: 14.3219\n",
      "[1684/1762] D loss: 0.0001, G loss: 15.2087\n",
      "[1762/1762] D loss: 0.0001, G loss: 9.2794\n",
      "train error: \n",
      " D loss: 0.022042, G loss: 12.605254, D accuracy: 99.6%, cell accuracy: 97.0%, board accuracy: 0.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.069092, G loss: 12.436249, D accuracy: 99.0%, cell accuracy: 97.0%, board accuracy: 1.6% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0009, G loss: 13.4062\n",
      "[84/1762] D loss: 0.0000, G loss: 25.2165\n",
      "[164/1762] D loss: 0.0001, G loss: 12.6370\n",
      "[244/1762] D loss: 0.0010, G loss: 9.1667\n",
      "[324/1762] D loss: 0.0072, G loss: 14.9506\n",
      "[404/1762] D loss: 0.0009, G loss: 12.0109\n",
      "[484/1762] D loss: 0.0009, G loss: 13.9527\n",
      "[564/1762] D loss: 0.0001, G loss: 16.2506\n",
      "[644/1762] D loss: 0.0017, G loss: 19.3620\n",
      "[724/1762] D loss: 0.0001, G loss: 23.4144\n",
      "[804/1762] D loss: 0.0000, G loss: 22.9046\n",
      "[884/1762] D loss: 0.0000, G loss: 16.5166\n",
      "[964/1762] D loss: 0.0007, G loss: 9.3914\n",
      "[1044/1762] D loss: 0.0549, G loss: 10.9111\n",
      "[1124/1762] D loss: 0.0001, G loss: 11.5144\n",
      "[1204/1762] D loss: 0.0000, G loss: 16.3911\n",
      "[1284/1762] D loss: 0.0565, G loss: 12.8417\n",
      "[1364/1762] D loss: 0.0002, G loss: 11.1824\n",
      "[1444/1762] D loss: 0.0000, G loss: 22.3904\n",
      "[1524/1762] D loss: 0.0002, G loss: 10.8281\n",
      "[1604/1762] D loss: 0.0077, G loss: 7.8965\n",
      "[1684/1762] D loss: 0.0000, G loss: 20.4982\n",
      "[1762/1762] D loss: 0.0002, G loss: 18.3908\n",
      "train error: \n",
      " D loss: 0.013235, G loss: 15.893998, D accuracy: 99.7%, cell accuracy: 97.0%, board accuracy: 0.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.008985, G loss: 15.905847, D accuracy: 99.8%, cell accuracy: 97.0%, board accuracy: 0.5% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 22.5678\n",
      "[84/1762] D loss: 0.0001, G loss: 19.4791\n",
      "[164/1762] D loss: 0.0002, G loss: 22.0340\n",
      "[244/1762] D loss: 0.0000, G loss: 18.8874\n",
      "[324/1762] D loss: 0.0000, G loss: 12.2912\n",
      "[404/1762] D loss: 0.0006, G loss: 14.8153\n",
      "[484/1762] D loss: 0.0096, G loss: 13.2710\n",
      "[564/1762] D loss: 0.0002, G loss: 9.8336\n",
      "[644/1762] D loss: 0.6639, G loss: 11.2190\n",
      "[724/1762] D loss: 0.0020, G loss: 12.9489\n",
      "[804/1762] D loss: 0.0051, G loss: 6.0797\n",
      "[884/1762] D loss: 0.0032, G loss: 10.7188\n",
      "[964/1762] D loss: 0.0020, G loss: 6.8839\n",
      "[1044/1762] D loss: 0.0010, G loss: 10.4417\n",
      "[1124/1762] D loss: 0.0075, G loss: 7.4391\n",
      "[1204/1762] D loss: 0.1832, G loss: 11.3894\n",
      "[1284/1762] D loss: 0.0010, G loss: 12.5241\n",
      "[1364/1762] D loss: 0.0004, G loss: 11.7858\n",
      "[1444/1762] D loss: 0.0063, G loss: 10.2664\n",
      "[1524/1762] D loss: 0.0006, G loss: 9.1522\n",
      "[1604/1762] D loss: 0.0002, G loss: 17.3531\n",
      "[1684/1762] D loss: 0.0003, G loss: 14.0221\n",
      "[1762/1762] D loss: 0.0003, G loss: 9.6975\n",
      "train error: \n",
      " D loss: 0.007695, G loss: 14.124068, D accuracy: 99.8%, cell accuracy: 97.0%, board accuracy: 0.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.002112, G loss: 14.187226, D accuracy: 100.0%, cell accuracy: 96.9%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0005, G loss: 12.4808\n",
      "[84/1762] D loss: 0.0009, G loss: 8.1083\n",
      "[164/1762] D loss: 0.0002, G loss: 14.9292\n",
      "[244/1762] D loss: 0.0017, G loss: 10.1432\n",
      "[324/1762] D loss: 0.0011, G loss: 15.5081\n",
      "[404/1762] D loss: 0.0000, G loss: 23.3475\n",
      "[484/1762] D loss: 0.0006, G loss: 8.5391\n",
      "[564/1762] D loss: 0.0001, G loss: 17.9688\n",
      "[644/1762] D loss: 0.0008, G loss: 18.2234\n",
      "[724/1762] D loss: 0.0003, G loss: 10.1698\n",
      "[804/1762] D loss: 0.0044, G loss: 12.2161\n",
      "[884/1762] D loss: 0.1330, G loss: 4.8614\n",
      "[964/1762] D loss: 0.0014, G loss: 11.6193\n",
      "[1044/1762] D loss: 0.0562, G loss: 6.2738\n",
      "[1124/1762] D loss: 0.0001, G loss: 14.4834\n",
      "[1204/1762] D loss: 0.0185, G loss: 11.2901\n",
      "[1284/1762] D loss: 0.0005, G loss: 13.7369\n",
      "[1364/1762] D loss: 0.0013, G loss: 9.4840\n",
      "[1444/1762] D loss: 0.0001, G loss: 11.0150\n",
      "[1524/1762] D loss: 0.0002, G loss: 15.9586\n",
      "[1604/1762] D loss: 0.0004, G loss: 9.3600\n",
      "[1684/1762] D loss: 0.0004, G loss: 15.1179\n",
      "[1762/1762] D loss: 0.0001, G loss: 13.9403\n",
      "train error: \n",
      " D loss: 0.006141, G loss: 14.470953, D accuracy: 99.9%, cell accuracy: 97.0%, board accuracy: 0.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.038731, G loss: 14.306354, D accuracy: 99.4%, cell accuracy: 97.0%, board accuracy: 1.8% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0002, G loss: 16.0554\n",
      "[84/1762] D loss: 0.0002, G loss: 16.1600\n",
      "[164/1762] D loss: 0.3492, G loss: 13.5009\n",
      "[244/1762] D loss: 0.0006, G loss: 13.9098\n",
      "[324/1762] D loss: 0.0000, G loss: 28.0596\n",
      "[404/1762] D loss: 0.0000, G loss: 12.8298\n",
      "[484/1762] D loss: 0.0002, G loss: 14.5279\n",
      "[564/1762] D loss: 0.0009, G loss: 11.8580\n",
      "[644/1762] D loss: 0.0011, G loss: 12.2867\n",
      "[724/1762] D loss: 0.0164, G loss: 15.0037\n",
      "[804/1762] D loss: 0.0074, G loss: 10.8269\n",
      "[884/1762] D loss: 0.0007, G loss: 13.4322\n",
      "[964/1762] D loss: 0.0023, G loss: 9.4932\n",
      "[1044/1762] D loss: 0.0001, G loss: 15.5807\n",
      "[1124/1762] D loss: 0.0001, G loss: 12.9671\n",
      "[1204/1762] D loss: 0.0152, G loss: 13.4066\n",
      "[1284/1762] D loss: 0.0000, G loss: 21.3265\n",
      "[1364/1762] D loss: 0.0005, G loss: 13.9229\n",
      "[1444/1762] D loss: 0.0937, G loss: 10.7468\n",
      "[1524/1762] D loss: 0.0099, G loss: 14.3863\n",
      "[1604/1762] D loss: 0.0001, G loss: 13.4839\n",
      "[1684/1762] D loss: 0.0002, G loss: 18.2615\n",
      "[1762/1762] D loss: 0.0001, G loss: 15.6375\n",
      "train error: \n",
      " D loss: 0.005962, G loss: 13.079632, D accuracy: 99.9%, cell accuracy: 97.0%, board accuracy: 0.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.014246, G loss: 12.877610, D accuracy: 99.8%, cell accuracy: 97.0%, board accuracy: 1.4% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0003, G loss: 17.6255\n",
      "[84/1762] D loss: 0.0000, G loss: 20.1818\n",
      "[164/1762] D loss: 0.0001, G loss: 17.5654\n",
      "[244/1762] D loss: 0.0022, G loss: 8.9507\n",
      "[324/1762] D loss: 0.0187, G loss: 10.4484\n",
      "[404/1762] D loss: 0.0105, G loss: 6.7958\n",
      "[484/1762] D loss: 0.0005, G loss: 10.3693\n",
      "[564/1762] D loss: 0.0081, G loss: 8.2528\n",
      "[644/1762] D loss: 0.0003, G loss: 12.0710\n",
      "[724/1762] D loss: 0.0003, G loss: 10.2722\n",
      "[804/1762] D loss: 0.0189, G loss: 20.8017\n",
      "[884/1762] D loss: 0.0020, G loss: 13.3184\n",
      "[964/1762] D loss: 0.0005, G loss: 11.5998\n",
      "[1044/1762] D loss: 1.1719, G loss: 6.4561\n",
      "[1124/1762] D loss: 0.0000, G loss: 19.3273\n",
      "[1204/1762] D loss: 0.0182, G loss: 20.7156\n",
      "[1284/1762] D loss: 0.0112, G loss: 9.7885\n",
      "[1364/1762] D loss: 0.1502, G loss: 9.8888\n",
      "[1444/1762] D loss: 0.0008, G loss: 12.5904\n",
      "[1524/1762] D loss: 0.0009, G loss: 9.1064\n",
      "[1604/1762] D loss: 0.0009, G loss: 9.5375\n",
      "[1684/1762] D loss: 0.0010, G loss: 11.4776\n",
      "[1762/1762] D loss: 0.0000, G loss: 24.1624\n",
      "train error: \n",
      " D loss: 0.009439, G loss: 14.656766, D accuracy: 99.8%, cell accuracy: 97.0%, board accuracy: 1.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.006705, G loss: 14.839321, D accuracy: 99.9%, cell accuracy: 96.9%, board accuracy: 0.9% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0003, G loss: 14.7625\n",
      "[84/1762] D loss: 0.0005, G loss: 13.4305\n",
      "[164/1762] D loss: 0.0000, G loss: 17.9968\n",
      "[244/1762] D loss: 0.0010, G loss: 7.7434\n",
      "[324/1762] D loss: 0.0001, G loss: 13.6155\n",
      "[404/1762] D loss: 0.0013, G loss: 8.9228\n",
      "[484/1762] D loss: 0.0000, G loss: 19.5998\n",
      "[564/1762] D loss: 0.0000, G loss: 15.4128\n",
      "[644/1762] D loss: 0.0007, G loss: 13.5201\n",
      "[724/1762] D loss: 0.0003, G loss: 10.2777\n",
      "[804/1762] D loss: 0.0000, G loss: 19.5544\n",
      "[884/1762] D loss: 0.0001, G loss: 11.7930\n",
      "[964/1762] D loss: 0.0000, G loss: 17.1321\n",
      "[1044/1762] D loss: 0.0001, G loss: 14.7462\n",
      "[1124/1762] D loss: 0.0006, G loss: 21.7101\n",
      "[1204/1762] D loss: 0.0010, G loss: 9.7573\n",
      "[1284/1762] D loss: 0.0001, G loss: 20.6193\n",
      "[1364/1762] D loss: 0.0003, G loss: 15.6316\n",
      "[1444/1762] D loss: 0.0015, G loss: 14.5083\n",
      "[1524/1762] D loss: 0.0000, G loss: 15.2619\n",
      "[1604/1762] D loss: 0.0555, G loss: 10.0347\n",
      "[1684/1762] D loss: 0.0071, G loss: 12.7067\n",
      "[1762/1762] D loss: 0.0001, G loss: 18.4036\n",
      "train error: \n",
      " D loss: 0.006587, G loss: 14.260461, D accuracy: 100.0%, cell accuracy: 97.1%, board accuracy: 0.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.008207, G loss: 14.087637, D accuracy: 100.0%, cell accuracy: 97.0%, board accuracy: 1.1% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0004, G loss: 15.0199\n",
      "[84/1762] D loss: 0.0001, G loss: 10.3295\n",
      "[164/1762] D loss: 0.0003, G loss: 9.8246\n",
      "[244/1762] D loss: 0.0000, G loss: 25.7323\n",
      "[324/1762] D loss: 0.0001, G loss: 15.7613\n",
      "[404/1762] D loss: 0.0001, G loss: 13.4964\n",
      "[484/1762] D loss: 0.0047, G loss: 11.7632\n",
      "[564/1762] D loss: 0.0000, G loss: 24.0605\n",
      "[644/1762] D loss: 0.0002, G loss: 25.9801\n",
      "[724/1762] D loss: 0.0034, G loss: 8.0774\n",
      "[804/1762] D loss: 0.0001, G loss: 16.3049\n",
      "[884/1762] D loss: 0.0038, G loss: 6.5203\n",
      "[964/1762] D loss: 0.0000, G loss: 27.9239\n",
      "[1044/1762] D loss: 0.0010, G loss: 16.3531\n",
      "[1124/1762] D loss: 0.0003, G loss: 22.9019\n",
      "[1204/1762] D loss: 0.0001, G loss: 21.9878\n",
      "[1284/1762] D loss: 0.0001, G loss: 24.1352\n",
      "[1364/1762] D loss: 0.0008, G loss: 19.3341\n",
      "[1444/1762] D loss: 0.0001, G loss: 11.2778\n",
      "[1524/1762] D loss: 0.0009, G loss: 25.5881\n",
      "[1604/1762] D loss: 0.0000, G loss: 23.1497\n",
      "[1684/1762] D loss: 0.0043, G loss: 11.1241\n",
      "[1762/1762] D loss: 0.0003, G loss: 17.7221\n",
      "train error: \n",
      " D loss: 0.005025, G loss: 20.876878, D accuracy: 99.9%, cell accuracy: 96.9%, board accuracy: 0.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.011479, G loss: 20.938710, D accuracy: 99.8%, cell accuracy: 96.9%, board accuracy: 1.4% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0006, G loss: 18.1038\n",
      "[84/1762] D loss: 0.0000, G loss: 17.7523\n",
      "[164/1762] D loss: 0.0002, G loss: 21.5445\n",
      "[244/1762] D loss: 0.0000, G loss: 20.9545\n",
      "[324/1762] D loss: 0.0000, G loss: 24.1473\n",
      "[404/1762] D loss: 0.0000, G loss: 17.9920\n",
      "[484/1762] D loss: 0.0000, G loss: 20.8579\n",
      "[564/1762] D loss: 0.0000, G loss: 21.9876\n",
      "[644/1762] D loss: 0.0001, G loss: 13.3248\n",
      "[724/1762] D loss: 0.0000, G loss: 19.0319\n",
      "[804/1762] D loss: 0.0000, G loss: 18.2932\n",
      "[884/1762] D loss: 0.0002, G loss: 19.8029\n",
      "[964/1762] D loss: 0.0001, G loss: 20.7154\n",
      "[1044/1762] D loss: 0.0002, G loss: 15.7802\n",
      "[1124/1762] D loss: 0.0000, G loss: 25.1552\n",
      "[1204/1762] D loss: 0.0001, G loss: 12.9164\n",
      "[1284/1762] D loss: 0.0001, G loss: 14.5397\n",
      "[1364/1762] D loss: 0.0199, G loss: 9.8457\n",
      "[1444/1762] D loss: 0.0000, G loss: 22.7826\n",
      "[1524/1762] D loss: 0.0000, G loss: 15.1666\n",
      "[1604/1762] D loss: 0.0000, G loss: 27.1950\n",
      "[1684/1762] D loss: 0.0001, G loss: 28.1388\n",
      "[1762/1762] D loss: 0.0004, G loss: 21.3903\n",
      "train error: \n",
      " D loss: 0.001470, G loss: 19.849054, D accuracy: 100.0%, cell accuracy: 97.0%, board accuracy: 0.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.001346, G loss: 20.072317, D accuracy: 100.0%, cell accuracy: 96.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 22.2492\n",
      "[84/1762] D loss: 0.0003, G loss: 11.7232\n",
      "[164/1762] D loss: 0.0002, G loss: 15.0817\n",
      "[244/1762] D loss: 0.0001, G loss: 21.3011\n",
      "[324/1762] D loss: 0.0000, G loss: 26.4491\n",
      "[404/1762] D loss: 0.0000, G loss: 28.5796\n",
      "[484/1762] D loss: 0.0001, G loss: 16.4777\n",
      "[564/1762] D loss: 0.0000, G loss: 18.0199\n",
      "[644/1762] D loss: 0.0000, G loss: 27.9032\n",
      "[724/1762] D loss: 0.0000, G loss: 19.2941\n",
      "[804/1762] D loss: 0.0000, G loss: 28.5219\n",
      "[884/1762] D loss: 0.0000, G loss: 27.1538\n",
      "[964/1762] D loss: 0.0000, G loss: 14.2416\n",
      "[1044/1762] D loss: 0.0001, G loss: 14.5202\n",
      "[1124/1762] D loss: 0.0000, G loss: 25.6218\n",
      "[1204/1762] D loss: 0.0008, G loss: 15.1770\n",
      "[1284/1762] D loss: 0.0016, G loss: 10.9319\n",
      "[1364/1762] D loss: 0.0012, G loss: 7.9419\n",
      "[1444/1762] D loss: 0.0029, G loss: 13.6399\n",
      "[1524/1762] D loss: 0.0005, G loss: 14.3412\n",
      "[1604/1762] D loss: 0.0005, G loss: 18.7130\n",
      "[1684/1762] D loss: 0.0023, G loss: 22.2273\n",
      "[1762/1762] D loss: 0.2421, G loss: 5.4066\n",
      "train error: \n",
      " D loss: 0.014788, G loss: 14.216939, D accuracy: 99.8%, cell accuracy: 97.0%, board accuracy: 0.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.010272, G loss: 14.367718, D accuracy: 99.9%, cell accuracy: 97.0%, board accuracy: 0.7% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0083, G loss: 21.6710\n",
      "[84/1762] D loss: 0.0222, G loss: 15.3984\n",
      "[164/1762] D loss: 0.0001, G loss: 12.5164\n",
      "[244/1762] D loss: 0.0005, G loss: 21.6784\n",
      "[324/1762] D loss: 0.0002, G loss: 12.2500\n",
      "[404/1762] D loss: 0.0005, G loss: 11.4496\n",
      "[484/1762] D loss: 0.0005, G loss: 13.4811\n",
      "[564/1762] D loss: 0.0002, G loss: 15.6635\n",
      "[644/1762] D loss: 0.0016, G loss: 8.5193\n",
      "[724/1762] D loss: 0.0019, G loss: 11.1908\n",
      "[804/1762] D loss: 0.0019, G loss: 11.8843\n",
      "[884/1762] D loss: 0.0017, G loss: 10.0735\n",
      "[964/1762] D loss: 0.0004, G loss: 10.2800\n",
      "[1044/1762] D loss: 0.0009, G loss: 11.8345\n",
      "[1124/1762] D loss: 0.0002, G loss: 12.7541\n",
      "[1204/1762] D loss: 0.0002, G loss: 14.2812\n",
      "[1284/1762] D loss: 0.0001, G loss: 12.6834\n",
      "[1364/1762] D loss: 0.0009, G loss: 9.5042\n",
      "[1444/1762] D loss: 0.0000, G loss: 25.0949\n",
      "[1524/1762] D loss: 0.0001, G loss: 17.3239\n",
      "[1604/1762] D loss: 0.0001, G loss: 18.6414\n",
      "[1684/1762] D loss: 0.0002, G loss: 12.7475\n",
      "[1762/1762] D loss: 0.0503, G loss: 9.8372\n",
      "train error: \n",
      " D loss: 0.013198, G loss: 12.219034, D accuracy: 99.9%, cell accuracy: 97.0%, board accuracy: 0.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.011830, G loss: 12.253934, D accuracy: 99.9%, cell accuracy: 97.0%, board accuracy: 0.5% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 12.1230\n",
      "[84/1762] D loss: 0.0008, G loss: 10.1524\n",
      "[164/1762] D loss: 0.0278, G loss: 8.2714\n",
      "[244/1762] D loss: 0.0032, G loss: 21.9606\n",
      "[324/1762] D loss: 0.0002, G loss: 10.4667\n",
      "[404/1762] D loss: 0.0017, G loss: 15.1795\n",
      "[484/1762] D loss: 0.0042, G loss: 9.1455\n",
      "[564/1762] D loss: 0.0019, G loss: 9.3427\n",
      "[644/1762] D loss: 0.0000, G loss: 16.0126\n",
      "[724/1762] D loss: 0.0000, G loss: 27.5040\n",
      "[804/1762] D loss: 0.0003, G loss: 21.2256\n",
      "[884/1762] D loss: 0.0000, G loss: 22.7056\n",
      "[964/1762] D loss: 0.0000, G loss: 22.1702\n",
      "[1044/1762] D loss: 0.0000, G loss: 27.1374\n",
      "[1124/1762] D loss: 0.0000, G loss: 24.3073\n",
      "[1204/1762] D loss: 0.0000, G loss: 45.1538\n",
      "[1284/1762] D loss: 0.0000, G loss: 28.0665\n",
      "[1364/1762] D loss: 0.0000, G loss: 30.4053\n",
      "[1444/1762] D loss: 0.0002, G loss: 20.9268\n",
      "[1524/1762] D loss: 0.0000, G loss: 26.3012\n",
      "[1604/1762] D loss: 0.0000, G loss: 36.8662\n",
      "[1684/1762] D loss: 0.0000, G loss: 17.6161\n",
      "[1762/1762] D loss: 0.0000, G loss: 18.1425\n",
      "train error: \n",
      " D loss: 0.004668, G loss: 24.668425, D accuracy: 99.9%, cell accuracy: 97.0%, board accuracy: 0.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.001024, G loss: 24.913200, D accuracy: 100.0%, cell accuracy: 97.0%, board accuracy: 0.9% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0003, G loss: 30.0577\n",
      "[84/1762] D loss: 0.0006, G loss: 15.8461\n",
      "[164/1762] D loss: 0.0001, G loss: 13.0465\n",
      "[244/1762] D loss: 0.0000, G loss: 30.3271\n",
      "[324/1762] D loss: 0.0000, G loss: 27.7558\n",
      "[404/1762] D loss: 0.0000, G loss: 18.1003\n",
      "[484/1762] D loss: 0.0001, G loss: 29.6358\n",
      "[564/1762] D loss: 0.0003, G loss: 22.8569\n",
      "[644/1762] D loss: 0.0001, G loss: 22.8529\n",
      "[724/1762] D loss: 0.1865, G loss: 11.4883\n",
      "[804/1762] D loss: 0.0011, G loss: 12.8691\n",
      "[884/1762] D loss: 0.0000, G loss: 18.7282\n",
      "[964/1762] D loss: 0.0004, G loss: 21.2596\n",
      "[1044/1762] D loss: 0.0003, G loss: 10.9235\n",
      "[1124/1762] D loss: 0.0003, G loss: 11.6065\n",
      "[1204/1762] D loss: 0.0004, G loss: 18.7060\n",
      "[1284/1762] D loss: 0.0002, G loss: 12.6054\n",
      "[1364/1762] D loss: 0.0015, G loss: 12.1010\n",
      "[1444/1762] D loss: 0.0011, G loss: 16.6682\n",
      "[1524/1762] D loss: 0.0005, G loss: 9.4068\n",
      "[1604/1762] D loss: 0.0013, G loss: 22.6594\n",
      "[1684/1762] D loss: 0.0000, G loss: 20.8589\n",
      "[1762/1762] D loss: 0.0003, G loss: 8.9277\n",
      "train error: \n",
      " D loss: 0.006409, G loss: 15.824835, D accuracy: 99.9%, cell accuracy: 97.0%, board accuracy: 0.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.003784, G loss: 16.030988, D accuracy: 100.0%, cell accuracy: 97.0%, board accuracy: 0.9% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0003, G loss: 15.1055\n",
      "[84/1762] D loss: 0.0004, G loss: 13.3007\n",
      "[164/1762] D loss: 0.0001, G loss: 16.2138\n",
      "[244/1762] D loss: 0.0000, G loss: 17.4804\n",
      "[324/1762] D loss: 0.0001, G loss: 13.1391\n",
      "[404/1762] D loss: 0.0000, G loss: 22.4412\n",
      "[484/1762] D loss: 0.0001, G loss: 16.8475\n",
      "[564/1762] D loss: 0.0001, G loss: 13.9086\n",
      "[644/1762] D loss: 0.0000, G loss: 20.9029\n",
      "[724/1762] D loss: 0.0000, G loss: 20.2231\n",
      "[804/1762] D loss: 0.0000, G loss: 32.3335\n",
      "[884/1762] D loss: 0.0000, G loss: 34.0605\n",
      "[964/1762] D loss: 0.0031, G loss: 10.8804\n",
      "[1044/1762] D loss: 0.0001, G loss: 29.8719\n",
      "[1124/1762] D loss: 0.0002, G loss: 17.1500\n",
      "[1204/1762] D loss: 0.0029, G loss: 8.5815\n",
      "[1284/1762] D loss: 0.0234, G loss: 20.1427\n",
      "[1364/1762] D loss: 0.0001, G loss: 25.1430\n",
      "[1444/1762] D loss: 0.0006, G loss: 16.5961\n",
      "[1524/1762] D loss: 0.0002, G loss: 10.3031\n",
      "[1604/1762] D loss: 0.0015, G loss: 25.5449\n",
      "[1684/1762] D loss: 0.0001, G loss: 23.4143\n",
      "[1762/1762] D loss: 0.0008, G loss: 14.2950\n",
      "train error: \n",
      " D loss: 0.006728, G loss: 17.470380, D accuracy: 99.9%, cell accuracy: 97.0%, board accuracy: 0.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.011603, G loss: 17.448127, D accuracy: 99.8%, cell accuracy: 96.9%, board accuracy: 0.9% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0010, G loss: 13.1755\n",
      "[84/1762] D loss: 0.0001, G loss: 25.8594\n",
      "[164/1762] D loss: 0.0004, G loss: 16.1262\n",
      "[244/1762] D loss: 0.0009, G loss: 11.9335\n",
      "[324/1762] D loss: 0.0000, G loss: 30.8368\n",
      "[404/1762] D loss: 0.0001, G loss: 13.0752\n",
      "[484/1762] D loss: 0.0086, G loss: 13.0126\n",
      "[564/1762] D loss: 0.0002, G loss: 12.0350\n",
      "[644/1762] D loss: 0.0010, G loss: 7.9033\n",
      "[724/1762] D loss: 0.0000, G loss: 26.7217\n",
      "[804/1762] D loss: 0.0000, G loss: 19.9795\n",
      "[884/1762] D loss: 0.0000, G loss: 22.4818\n",
      "[964/1762] D loss: 0.0000, G loss: 21.9463\n",
      "[1044/1762] D loss: 0.0003, G loss: 24.4844\n",
      "[1124/1762] D loss: 0.0001, G loss: 18.5314\n",
      "[1204/1762] D loss: 0.0001, G loss: 26.3465\n",
      "[1284/1762] D loss: 0.0000, G loss: 34.2744\n",
      "[1364/1762] D loss: 0.0000, G loss: 25.5266\n",
      "[1444/1762] D loss: 0.0012, G loss: 19.4186\n",
      "[1524/1762] D loss: 0.0006, G loss: 12.0411\n",
      "[1604/1762] D loss: 0.0008, G loss: 26.8154\n",
      "[1684/1762] D loss: 0.0000, G loss: 36.4084\n",
      "[1762/1762] D loss: 0.0000, G loss: 56.7444\n",
      "train error: \n",
      " D loss: 0.003187, G loss: 22.655514, D accuracy: 99.9%, cell accuracy: 96.9%, board accuracy: 0.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.003356, G loss: 22.556652, D accuracy: 99.9%, cell accuracy: 96.9%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0003, G loss: 22.9661\n",
      "[84/1762] D loss: 0.0008, G loss: 30.9739\n",
      "[164/1762] D loss: 0.0067, G loss: 8.2925\n",
      "[244/1762] D loss: 0.0025, G loss: 16.2742\n",
      "[324/1762] D loss: 0.0007, G loss: 12.6834\n",
      "[404/1762] D loss: 0.0003, G loss: 12.5923\n",
      "[484/1762] D loss: 0.0016, G loss: 15.1682\n",
      "[564/1762] D loss: 0.0003, G loss: 15.8776\n",
      "[644/1762] D loss: 0.0000, G loss: 23.7966\n",
      "[724/1762] D loss: 0.0003, G loss: 14.5802\n",
      "[804/1762] D loss: 0.0144, G loss: 18.2851\n",
      "[884/1762] D loss: 0.0001, G loss: 10.0691\n",
      "[964/1762] D loss: 0.0001, G loss: 21.3288\n",
      "[1044/1762] D loss: 0.0007, G loss: 19.6239\n",
      "[1124/1762] D loss: 0.0000, G loss: 30.8526\n",
      "[1204/1762] D loss: 0.0001, G loss: 12.0813\n",
      "[1284/1762] D loss: 0.8160, G loss: 22.6322\n",
      "[1364/1762] D loss: 0.0875, G loss: 16.9570\n",
      "[1444/1762] D loss: 0.0002, G loss: 19.8070\n",
      "[1524/1762] D loss: 0.0003, G loss: 23.7508\n",
      "[1604/1762] D loss: 0.0013, G loss: 15.4477\n",
      "[1684/1762] D loss: 0.0001, G loss: 16.3836\n",
      "[1762/1762] D loss: 0.0000, G loss: 16.5211\n",
      "train error: \n",
      " D loss: 0.003271, G loss: 21.937729, D accuracy: 100.0%, cell accuracy: 97.0%, board accuracy: 0.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.001510, G loss: 21.935203, D accuracy: 100.0%, cell accuracy: 96.9%, board accuracy: 1.1% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0002, G loss: 31.0712\n",
      "[84/1762] D loss: 0.0001, G loss: 13.6935\n",
      "[164/1762] D loss: 0.0009, G loss: 12.7500\n",
      "[244/1762] D loss: 0.0673, G loss: 18.1598\n",
      "[324/1762] D loss: 0.0000, G loss: 27.9540\n",
      "[404/1762] D loss: 0.0149, G loss: 13.7325\n",
      "[484/1762] D loss: 0.0012, G loss: 10.6707\n",
      "[564/1762] D loss: 0.0024, G loss: 6.7707\n",
      "[644/1762] D loss: 0.0093, G loss: 16.9286\n",
      "[724/1762] D loss: 0.0095, G loss: 10.8257\n",
      "[804/1762] D loss: 0.0004, G loss: 12.4389\n",
      "[884/1762] D loss: 0.0001, G loss: 20.7663\n",
      "[964/1762] D loss: 0.0268, G loss: 14.3150\n",
      "[1044/1762] D loss: 0.0018, G loss: 21.8592\n",
      "[1124/1762] D loss: 0.0014, G loss: 13.6456\n",
      "[1204/1762] D loss: 0.0032, G loss: 5.9816\n",
      "[1284/1762] D loss: 0.0006, G loss: 13.3881\n",
      "[1364/1762] D loss: 0.0004, G loss: 15.0231\n",
      "[1444/1762] D loss: 0.0004, G loss: 14.9846\n",
      "[1524/1762] D loss: 0.0010, G loss: 23.5335\n",
      "[1604/1762] D loss: 0.0009, G loss: 15.2260\n",
      "[1684/1762] D loss: 0.0001, G loss: 23.2762\n",
      "[1762/1762] D loss: 0.0003, G loss: 21.8022\n",
      "train error: \n",
      " D loss: 0.051408, G loss: 10.943383, D accuracy: 99.2%, cell accuracy: 97.0%, board accuracy: 0.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.026869, G loss: 10.941770, D accuracy: 99.5%, cell accuracy: 96.9%, board accuracy: 1.1% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0006, G loss: 12.1912\n",
      "[84/1762] D loss: 0.0224, G loss: 6.8325\n",
      "[164/1762] D loss: 0.0078, G loss: 23.9294\n",
      "[244/1762] D loss: 0.0010, G loss: 9.1244\n",
      "[324/1762] D loss: 0.0002, G loss: 11.2148\n",
      "[404/1762] D loss: 0.0045, G loss: 6.2675\n",
      "[484/1762] D loss: 0.0043, G loss: 34.7987\n",
      "[564/1762] D loss: 0.0022, G loss: 10.8526\n",
      "[644/1762] D loss: 0.0003, G loss: 19.2907\n",
      "[724/1762] D loss: 0.0002, G loss: 47.1146\n",
      "[804/1762] D loss: 0.0002, G loss: 16.4124\n",
      "[884/1762] D loss: 0.0000, G loss: 49.2963\n",
      "[964/1762] D loss: 0.0001, G loss: 17.6398\n",
      "[1044/1762] D loss: 0.0001, G loss: 13.0918\n",
      "[1124/1762] D loss: 0.0001, G loss: 33.9253\n",
      "[1204/1762] D loss: 0.0000, G loss: 21.5740\n",
      "[1284/1762] D loss: 0.0002, G loss: 20.8121\n",
      "[1364/1762] D loss: 0.0000, G loss: 20.3410\n",
      "[1444/1762] D loss: 0.0000, G loss: 21.7952\n",
      "[1524/1762] D loss: 0.0000, G loss: 35.5145\n",
      "[1604/1762] D loss: 0.0001, G loss: 25.5305\n",
      "[1684/1762] D loss: 0.0000, G loss: 20.9198\n",
      "[1762/1762] D loss: 0.0000, G loss: 15.6819\n",
      "train error: \n",
      " D loss: 0.021507, G loss: 19.842457, D accuracy: 99.7%, cell accuracy: 97.0%, board accuracy: 0.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.014495, G loss: 19.502539, D accuracy: 99.7%, cell accuracy: 97.0%, board accuracy: 0.7% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 18.8004\n",
      "[84/1762] D loss: 0.0654, G loss: 10.7334\n",
      "[164/1762] D loss: 0.0006, G loss: 15.9774\n",
      "[244/1762] D loss: 0.0184, G loss: 11.7939\n",
      "[324/1762] D loss: 0.0010, G loss: 10.8941\n",
      "[404/1762] D loss: 0.0000, G loss: 23.2889\n",
      "[484/1762] D loss: 0.0000, G loss: 42.9011\n",
      "[564/1762] D loss: 0.0000, G loss: 44.4233\n",
      "[644/1762] D loss: 0.0002, G loss: 21.0573\n",
      "[724/1762] D loss: 0.0261, G loss: 32.6782\n",
      "[804/1762] D loss: 0.0000, G loss: 32.5466\n",
      "[884/1762] D loss: 0.0000, G loss: 21.4416\n",
      "[964/1762] D loss: 0.0001, G loss: 29.4055\n",
      "[1044/1762] D loss: 0.0028, G loss: 20.9498\n",
      "[1124/1762] D loss: 0.0011, G loss: 18.7006\n",
      "[1204/1762] D loss: 0.0023, G loss: 10.2739\n",
      "[1284/1762] D loss: 0.0000, G loss: 37.2465\n",
      "[1364/1762] D loss: 0.0001, G loss: 19.8986\n",
      "[1444/1762] D loss: 0.0156, G loss: 20.4153\n",
      "[1524/1762] D loss: 0.0018, G loss: 15.0813\n",
      "[1604/1762] D loss: 0.0003, G loss: 10.7851\n",
      "[1684/1762] D loss: 0.0006, G loss: 25.3771\n",
      "[1762/1762] D loss: 0.0000, G loss: 15.0139\n",
      "train error: \n",
      " D loss: 0.012522, G loss: 20.924845, D accuracy: 99.8%, cell accuracy: 97.1%, board accuracy: 0.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.016895, G loss: 21.170075, D accuracy: 99.7%, cell accuracy: 97.0%, board accuracy: 0.9% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0011, G loss: 10.6487\n",
      "[84/1762] D loss: 0.0008, G loss: 12.2445\n",
      "[164/1762] D loss: 0.0001, G loss: 13.9335\n",
      "[244/1762] D loss: 0.0006, G loss: 13.5921\n",
      "[324/1762] D loss: 0.0002, G loss: 17.0615\n",
      "[404/1762] D loss: 0.0045, G loss: 22.2529\n",
      "[484/1762] D loss: 0.0013, G loss: 14.0756\n",
      "[564/1762] D loss: 0.0000, G loss: 25.6537\n",
      "[644/1762] D loss: 0.0011, G loss: 15.3804\n",
      "[724/1762] D loss: 0.0000, G loss: 22.1533\n",
      "[804/1762] D loss: 0.0000, G loss: 28.0140\n",
      "[884/1762] D loss: 0.0002, G loss: 9.0364\n",
      "[964/1762] D loss: 0.0002, G loss: 28.0964\n",
      "[1044/1762] D loss: 0.0009, G loss: 19.3920\n",
      "[1124/1762] D loss: 0.0000, G loss: 29.6145\n",
      "[1204/1762] D loss: 0.0041, G loss: 16.6612\n",
      "[1284/1762] D loss: 0.0007, G loss: 22.7873\n",
      "[1364/1762] D loss: 0.0001, G loss: 12.3996\n",
      "[1444/1762] D loss: 0.0009, G loss: 40.5548\n",
      "[1524/1762] D loss: 0.0002, G loss: 30.1574\n",
      "[1604/1762] D loss: 0.0379, G loss: 38.8248\n",
      "[1684/1762] D loss: 0.0002, G loss: 25.6200\n",
      "[1762/1762] D loss: 0.0001, G loss: 20.5110\n",
      "train error: \n",
      " D loss: 0.002606, G loss: 22.829972, D accuracy: 100.0%, cell accuracy: 97.0%, board accuracy: 0.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.006199, G loss: 22.682888, D accuracy: 99.9%, cell accuracy: 97.0%, board accuracy: 0.7% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0078, G loss: 37.0114\n",
      "[84/1762] D loss: 0.0007, G loss: 13.9662\n",
      "[164/1762] D loss: 0.0000, G loss: 24.0421\n",
      "[244/1762] D loss: 0.0000, G loss: 33.5143\n",
      "[324/1762] D loss: 0.0000, G loss: 27.1082\n",
      "[404/1762] D loss: 0.0000, G loss: 14.9679\n",
      "[484/1762] D loss: 0.0003, G loss: 27.9714\n",
      "[564/1762] D loss: 0.0002, G loss: 37.9836\n",
      "[644/1762] D loss: 0.0000, G loss: 25.5445\n",
      "[724/1762] D loss: 0.0006, G loss: 42.6696\n",
      "[804/1762] D loss: 0.0000, G loss: 72.5736\n",
      "[884/1762] D loss: 0.0000, G loss: 18.7451\n",
      "[964/1762] D loss: 0.0000, G loss: 47.8496\n",
      "[1044/1762] D loss: 0.0000, G loss: 29.7986\n",
      "[1124/1762] D loss: 0.0001, G loss: 29.8250\n",
      "[1204/1762] D loss: 0.0000, G loss: 20.7939\n",
      "[1284/1762] D loss: 0.0000, G loss: 38.5795\n",
      "[1364/1762] D loss: 0.0000, G loss: 18.2707\n",
      "[1444/1762] D loss: 0.0001, G loss: 11.6364\n",
      "[1524/1762] D loss: 0.0005, G loss: 11.8683\n",
      "[1604/1762] D loss: 0.0000, G loss: 42.3826\n",
      "[1684/1762] D loss: 0.0001, G loss: 32.3795\n",
      "[1762/1762] D loss: 0.0000, G loss: 33.5837\n",
      "train error: \n",
      " D loss: 0.000813, G loss: 30.003810, D accuracy: 100.0%, cell accuracy: 97.0%, board accuracy: 0.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000108, G loss: 30.383963, D accuracy: 100.0%, cell accuracy: 96.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 27.1899\n",
      "[84/1762] D loss: 0.0000, G loss: 32.0367\n",
      "[164/1762] D loss: 0.0078, G loss: 38.6041\n",
      "[244/1762] D loss: 0.0000, G loss: 45.7142\n",
      "[324/1762] D loss: 0.0000, G loss: 34.1864\n",
      "[404/1762] D loss: 0.0000, G loss: 60.7556\n",
      "[484/1762] D loss: 0.0000, G loss: 56.1380\n",
      "[564/1762] D loss: 0.0000, G loss: 52.4371\n",
      "[644/1762] D loss: 0.0000, G loss: 17.8413\n",
      "[724/1762] D loss: 0.0000, G loss: 30.8659\n",
      "[804/1762] D loss: 0.0000, G loss: 19.6992\n",
      "[884/1762] D loss: 0.0000, G loss: 43.9897\n",
      "[964/1762] D loss: 0.0000, G loss: 21.5798\n",
      "[1044/1762] D loss: 0.0261, G loss: 19.2562\n",
      "[1124/1762] D loss: 0.0000, G loss: 21.4535\n",
      "[1204/1762] D loss: 0.0001, G loss: 14.4253\n",
      "[1284/1762] D loss: 0.0090, G loss: 9.0325\n",
      "[1364/1762] D loss: 0.0008, G loss: 19.8232\n",
      "[1444/1762] D loss: 0.0001, G loss: 13.7079\n",
      "[1524/1762] D loss: 0.0007, G loss: 32.3831\n",
      "[1604/1762] D loss: 0.0000, G loss: 39.3605\n",
      "[1684/1762] D loss: 0.0003, G loss: 11.7690\n",
      "[1762/1762] D loss: 0.0003, G loss: 32.3038\n",
      "train error: \n",
      " D loss: 0.024212, G loss: 23.188031, D accuracy: 99.5%, cell accuracy: 96.9%, board accuracy: 0.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.033663, G loss: 23.205414, D accuracy: 99.5%, cell accuracy: 96.9%, board accuracy: 0.9% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0013, G loss: 27.2052\n",
      "[84/1762] D loss: 0.0001, G loss: 15.4134\n",
      "[164/1762] D loss: 0.0030, G loss: 9.8220\n",
      "[244/1762] D loss: 0.0013, G loss: 17.5148\n",
      "[324/1762] D loss: 0.0670, G loss: 16.4565\n",
      "[404/1762] D loss: 0.0041, G loss: 6.9512\n",
      "[484/1762] D loss: 0.0001, G loss: 23.5949\n",
      "[564/1762] D loss: 0.0000, G loss: 23.9588\n",
      "[644/1762] D loss: 0.0000, G loss: 18.3361\n",
      "[724/1762] D loss: 0.0001, G loss: 17.9006\n",
      "[804/1762] D loss: 0.0001, G loss: 33.0431\n",
      "[884/1762] D loss: 0.0001, G loss: 29.9981\n",
      "[964/1762] D loss: 0.0069, G loss: 17.7512\n",
      "[1044/1762] D loss: 0.0044, G loss: 11.9246\n",
      "[1124/1762] D loss: 0.0005, G loss: 23.5028\n",
      "[1204/1762] D loss: 0.0001, G loss: 32.8176\n",
      "[1284/1762] D loss: 0.0028, G loss: 8.5138\n",
      "[1364/1762] D loss: 0.0107, G loss: 13.3397\n",
      "[1444/1762] D loss: 0.0002, G loss: 13.8726\n",
      "[1524/1762] D loss: 0.0001, G loss: 14.6238\n",
      "[1604/1762] D loss: 0.0006, G loss: 45.1871\n",
      "[1684/1762] D loss: 0.0008, G loss: 22.5859\n",
      "[1762/1762] D loss: 0.0003, G loss: 27.1211\n",
      "train error: \n",
      " D loss: 0.002046, G loss: 22.874574, D accuracy: 100.0%, cell accuracy: 97.0%, board accuracy: 0.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.004506, G loss: 22.636628, D accuracy: 99.9%, cell accuracy: 97.0%, board accuracy: 1.4% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 30.6091\n",
      "[84/1762] D loss: 0.0003, G loss: 18.6144\n",
      "[164/1762] D loss: 0.0003, G loss: 17.2927\n",
      "[244/1762] D loss: 0.0000, G loss: 32.8604\n",
      "[324/1762] D loss: 0.0000, G loss: 50.1430\n",
      "[404/1762] D loss: 0.0003, G loss: 28.9002\n",
      "[484/1762] D loss: 0.0002, G loss: 11.3536\n",
      "[564/1762] D loss: 0.0001, G loss: 18.8381\n",
      "[644/1762] D loss: 0.0002, G loss: 45.0351\n",
      "[724/1762] D loss: 0.0003, G loss: 29.6482\n",
      "[804/1762] D loss: 0.0005, G loss: 16.9414\n",
      "[884/1762] D loss: 0.0000, G loss: 24.3152\n",
      "[964/1762] D loss: 0.0000, G loss: 27.1135\n",
      "[1044/1762] D loss: 0.0005, G loss: 28.7611\n",
      "[1124/1762] D loss: 0.0000, G loss: 11.9157\n",
      "[1204/1762] D loss: 0.0003, G loss: 24.6550\n",
      "[1284/1762] D loss: 0.0009, G loss: 9.0590\n",
      "[1364/1762] D loss: 0.0002, G loss: 9.9444\n",
      "[1444/1762] D loss: 0.0008, G loss: 12.4805\n",
      "[1524/1762] D loss: 0.0003, G loss: 23.0364\n",
      "[1604/1762] D loss: 0.0000, G loss: 28.5344\n",
      "[1684/1762] D loss: 0.0000, G loss: 37.0748\n",
      "[1762/1762] D loss: 0.0017, G loss: 10.7830\n",
      "train error: \n",
      " D loss: 0.041443, G loss: 27.184466, D accuracy: 99.3%, cell accuracy: 97.0%, board accuracy: 0.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.067188, G loss: 27.233140, D accuracy: 99.0%, cell accuracy: 97.0%, board accuracy: 0.7% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 16.1102\n",
      "[84/1762] D loss: 0.0004, G loss: 17.4511\n",
      "[164/1762] D loss: 0.0000, G loss: 20.7925\n",
      "[244/1762] D loss: 0.0052, G loss: 24.3113\n",
      "[324/1762] D loss: 0.0007, G loss: 11.2415\n",
      "[404/1762] D loss: 0.0001, G loss: 30.2046\n",
      "[484/1762] D loss: 0.0001, G loss: 11.9554\n",
      "[564/1762] D loss: 0.0000, G loss: 23.4240\n",
      "[644/1762] D loss: 0.0001, G loss: 30.3689\n",
      "[724/1762] D loss: 0.0004, G loss: 25.5979\n",
      "[804/1762] D loss: 0.0001, G loss: 32.2173\n",
      "[884/1762] D loss: 0.0001, G loss: 15.5508\n",
      "[964/1762] D loss: 0.0796, G loss: 11.8749\n",
      "[1044/1762] D loss: 0.0000, G loss: 50.8033\n",
      "[1124/1762] D loss: 0.0002, G loss: 18.4702\n",
      "[1204/1762] D loss: 0.0102, G loss: 10.6336\n",
      "[1284/1762] D loss: 0.5673, G loss: 28.3415\n",
      "[1364/1762] D loss: 0.0108, G loss: 19.1649\n",
      "[1444/1762] D loss: 0.0068, G loss: 10.0496\n",
      "[1524/1762] D loss: 0.0493, G loss: 5.4411\n",
      "[1604/1762] D loss: 0.0801, G loss: 9.4195\n",
      "[1684/1762] D loss: 0.0000, G loss: 23.8129\n",
      "[1762/1762] D loss: 0.0000, G loss: 45.7634\n",
      "train error: \n",
      " D loss: 0.003457, G loss: 21.163377, D accuracy: 100.0%, cell accuracy: 97.0%, board accuracy: 0.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.008451, G loss: 21.304605, D accuracy: 99.9%, cell accuracy: 96.9%, board accuracy: 0.5% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0033, G loss: 16.1797\n",
      "[84/1762] D loss: 0.0001, G loss: 20.9558\n",
      "[164/1762] D loss: 0.0022, G loss: 8.4413\n",
      "[244/1762] D loss: 0.0008, G loss: 13.3390\n",
      "[324/1762] D loss: 0.0000, G loss: 22.3404\n",
      "[404/1762] D loss: 0.0001, G loss: 21.0658\n",
      "[484/1762] D loss: 0.0002, G loss: 16.5883\n",
      "[564/1762] D loss: 0.0000, G loss: 29.8057\n",
      "[644/1762] D loss: 0.0003, G loss: 14.9058\n",
      "[724/1762] D loss: 0.0107, G loss: 17.2670\n",
      "[804/1762] D loss: 0.0000, G loss: 25.9534\n",
      "[884/1762] D loss: 0.0000, G loss: 30.0359\n",
      "[964/1762] D loss: 0.0003, G loss: 27.6531\n",
      "[1044/1762] D loss: 0.0000, G loss: 27.3930\n",
      "[1124/1762] D loss: 0.0011, G loss: 17.1333\n",
      "[1204/1762] D loss: 0.0005, G loss: 8.8530\n",
      "[1284/1762] D loss: 0.0000, G loss: 35.0241\n",
      "[1364/1762] D loss: 0.0003, G loss: 14.8832\n",
      "[1444/1762] D loss: 0.0007, G loss: 18.0366\n",
      "[1524/1762] D loss: 0.0007, G loss: 15.4567\n",
      "[1604/1762] D loss: 0.0010, G loss: 21.4920\n",
      "[1684/1762] D loss: 0.0001, G loss: 15.6879\n",
      "[1762/1762] D loss: 0.0004, G loss: 7.9507\n",
      "train error: \n",
      " D loss: 0.003727, G loss: 17.341001, D accuracy: 100.0%, cell accuracy: 97.0%, board accuracy: 0.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.006334, G loss: 17.330155, D accuracy: 99.9%, cell accuracy: 97.0%, board accuracy: 0.5% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0002, G loss: 17.1046\n",
      "[84/1762] D loss: 0.0007, G loss: 10.5361\n",
      "[164/1762] D loss: 0.0000, G loss: 20.7508\n",
      "[244/1762] D loss: 0.0002, G loss: 15.5547\n",
      "[324/1762] D loss: 0.0000, G loss: 18.1577\n",
      "[404/1762] D loss: 0.0000, G loss: 29.5894\n",
      "[484/1762] D loss: 0.0003, G loss: 13.5896\n",
      "[564/1762] D loss: 0.0000, G loss: 28.7235\n",
      "[644/1762] D loss: 0.0003, G loss: 15.7551\n",
      "[724/1762] D loss: 0.1183, G loss: 13.5292\n",
      "[804/1762] D loss: 0.0130, G loss: 9.1766\n",
      "[884/1762] D loss: 0.0000, G loss: 17.6924\n",
      "[964/1762] D loss: 0.0000, G loss: 21.2367\n",
      "[1044/1762] D loss: 0.0000, G loss: 20.5261\n",
      "[1124/1762] D loss: 0.0000, G loss: 13.3480\n",
      "[1204/1762] D loss: 0.0000, G loss: 19.6423\n",
      "[1284/1762] D loss: 0.0000, G loss: 26.2489\n",
      "[1364/1762] D loss: 0.0000, G loss: 26.9181\n",
      "[1444/1762] D loss: 0.0001, G loss: 16.4632\n",
      "[1524/1762] D loss: 0.0004, G loss: 17.9597\n",
      "[1604/1762] D loss: 0.0000, G loss: 20.4036\n",
      "[1684/1762] D loss: 0.0001, G loss: 16.0057\n",
      "[1762/1762] D loss: 0.0000, G loss: 14.7825\n",
      "train error: \n",
      " D loss: 0.002436, G loss: 17.916588, D accuracy: 99.9%, cell accuracy: 97.0%, board accuracy: 0.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000353, G loss: 17.767077, D accuracy: 100.0%, cell accuracy: 97.0%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 24.2903\n",
      "[84/1762] D loss: 0.0012, G loss: 7.6705\n",
      "[164/1762] D loss: 0.0027, G loss: 21.9860\n",
      "[244/1762] D loss: 0.0000, G loss: 36.5088\n",
      "[324/1762] D loss: 0.0000, G loss: 35.2432\n",
      "[404/1762] D loss: 0.0001, G loss: 17.8158\n",
      "[484/1762] D loss: 0.0000, G loss: 18.6391\n",
      "[564/1762] D loss: 0.0000, G loss: 18.1184\n",
      "[644/1762] D loss: 0.0002, G loss: 30.8481\n",
      "[724/1762] D loss: 0.0002, G loss: 22.4161\n",
      "[804/1762] D loss: 0.0000, G loss: 20.4148\n",
      "[884/1762] D loss: 0.0002, G loss: 20.3362\n",
      "[964/1762] D loss: 0.0000, G loss: 14.6995\n",
      "[1044/1762] D loss: 0.0000, G loss: 16.0308\n",
      "[1124/1762] D loss: 0.0000, G loss: 22.1152\n",
      "[1204/1762] D loss: 0.0000, G loss: 27.4432\n",
      "[1284/1762] D loss: 0.0003, G loss: 23.4031\n",
      "[1364/1762] D loss: 0.0001, G loss: 10.4288\n",
      "[1444/1762] D loss: 0.0000, G loss: 35.5366\n",
      "[1524/1762] D loss: 0.0000, G loss: 11.8754\n",
      "[1604/1762] D loss: 0.0011, G loss: 12.4244\n",
      "[1684/1762] D loss: 0.0000, G loss: 26.2273\n",
      "[1762/1762] D loss: 0.0004, G loss: 22.4027\n",
      "train error: \n",
      " D loss: 0.002532, G loss: 20.610479, D accuracy: 99.9%, cell accuracy: 97.1%, board accuracy: 0.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.002778, G loss: 20.791901, D accuracy: 99.9%, cell accuracy: 97.0%, board accuracy: 1.1% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 21.6213\n",
      "[84/1762] D loss: 0.0001, G loss: 23.4270\n",
      "[164/1762] D loss: 0.0000, G loss: 18.2810\n",
      "[244/1762] D loss: 0.0002, G loss: 12.9443\n",
      "[324/1762] D loss: 0.0020, G loss: 10.8717\n",
      "[404/1762] D loss: 0.0004, G loss: 34.3039\n",
      "[484/1762] D loss: 0.0014, G loss: 20.3735\n",
      "[564/1762] D loss: 0.0003, G loss: 19.1651\n",
      "[644/1762] D loss: 0.0023, G loss: 11.3389\n",
      "[724/1762] D loss: 0.0016, G loss: 20.6359\n",
      "[804/1762] D loss: 0.0000, G loss: 15.8053\n",
      "[884/1762] D loss: 0.0006, G loss: 14.2174\n",
      "[964/1762] D loss: 0.0032, G loss: 12.1240\n",
      "[1044/1762] D loss: 0.0000, G loss: 25.5215\n",
      "[1124/1762] D loss: 0.0000, G loss: 40.0181\n",
      "[1204/1762] D loss: 0.0000, G loss: 22.4917\n",
      "[1284/1762] D loss: 0.0000, G loss: 33.3568\n",
      "[1364/1762] D loss: 0.0001, G loss: 14.5877\n",
      "[1444/1762] D loss: 0.0003, G loss: 15.6519\n",
      "[1524/1762] D loss: 0.0015, G loss: 16.8137\n",
      "[1604/1762] D loss: 0.0002, G loss: 20.4875\n",
      "[1684/1762] D loss: 0.0001, G loss: 25.0630\n",
      "[1762/1762] D loss: 0.0000, G loss: 22.7026\n",
      "train error: \n",
      " D loss: 0.005454, G loss: 23.416308, D accuracy: 99.9%, cell accuracy: 97.0%, board accuracy: 0.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000426, G loss: 23.815077, D accuracy: 100.0%, cell accuracy: 97.0%, board accuracy: 0.5% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0003, G loss: 11.5689\n",
      "[84/1762] D loss: 0.0000, G loss: 21.1190\n",
      "[164/1762] D loss: 0.0011, G loss: 21.9281\n",
      "[244/1762] D loss: 0.0000, G loss: 36.0423\n",
      "[324/1762] D loss: 0.0000, G loss: 14.1457\n",
      "[404/1762] D loss: 0.0001, G loss: 20.9440\n",
      "[484/1762] D loss: 0.0000, G loss: 32.6650\n",
      "[564/1762] D loss: 0.0000, G loss: 17.4377\n",
      "[644/1762] D loss: 0.0000, G loss: 34.8514\n",
      "[724/1762] D loss: 0.0584, G loss: 21.7570\n",
      "[804/1762] D loss: 0.0002, G loss: 16.9527\n",
      "[884/1762] D loss: 0.0000, G loss: 24.5960\n",
      "[964/1762] D loss: 0.0003, G loss: 18.5522\n",
      "[1044/1762] D loss: 0.0001, G loss: 10.3192\n",
      "[1124/1762] D loss: 0.0001, G loss: 11.5300\n",
      "[1204/1762] D loss: 0.0001, G loss: 25.5629\n",
      "[1284/1762] D loss: 0.0000, G loss: 36.3938\n",
      "[1364/1762] D loss: 0.0000, G loss: 49.5564\n",
      "[1444/1762] D loss: 0.0001, G loss: 22.5478\n",
      "[1524/1762] D loss: 0.0005, G loss: 11.8593\n",
      "[1604/1762] D loss: 0.0001, G loss: 25.1550\n",
      "[1684/1762] D loss: 0.0000, G loss: 21.3672\n",
      "[1762/1762] D loss: 0.0001, G loss: 13.7961\n",
      "train error: \n",
      " D loss: 0.010481, G loss: 24.431400, D accuracy: 99.9%, cell accuracy: 97.0%, board accuracy: 0.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.012951, G loss: 24.464047, D accuracy: 99.8%, cell accuracy: 96.9%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0639, G loss: 21.6442\n",
      "[84/1762] D loss: 0.0141, G loss: 13.1313\n",
      "[164/1762] D loss: 0.0000, G loss: 29.5810\n",
      "[244/1762] D loss: 0.0000, G loss: 21.2381\n",
      "[324/1762] D loss: 0.0000, G loss: 46.3695\n",
      "[404/1762] D loss: 0.0000, G loss: 21.2735\n",
      "[484/1762] D loss: 0.0003, G loss: 18.0401\n",
      "[564/1762] D loss: 0.0002, G loss: 13.0558\n",
      "[644/1762] D loss: 0.0000, G loss: 27.2250\n",
      "[724/1762] D loss: 0.0001, G loss: 20.3982\n",
      "[804/1762] D loss: 0.0000, G loss: 26.7351\n",
      "[884/1762] D loss: 0.0001, G loss: 41.8741\n",
      "[964/1762] D loss: 0.0022, G loss: 9.2287\n",
      "[1044/1762] D loss: 0.0000, G loss: 29.0345\n",
      "[1124/1762] D loss: 0.0000, G loss: 40.9211\n",
      "[1204/1762] D loss: 0.0001, G loss: 21.2949\n",
      "[1284/1762] D loss: 0.0002, G loss: 15.0092\n",
      "[1364/1762] D loss: 0.0000, G loss: 39.8143\n",
      "[1444/1762] D loss: 0.0000, G loss: 33.1662\n",
      "[1524/1762] D loss: 0.0002, G loss: 14.5983\n",
      "[1604/1762] D loss: 0.0000, G loss: 18.7858\n",
      "[1684/1762] D loss: 0.0000, G loss: 27.7434\n",
      "[1762/1762] D loss: 0.0003, G loss: 45.3634\n",
      "train error: \n",
      " D loss: 0.000893, G loss: 26.578177, D accuracy: 100.0%, cell accuracy: 97.0%, board accuracy: 0.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000398, G loss: 26.829176, D accuracy: 100.0%, cell accuracy: 96.9%, board accuracy: 0.5% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001, G loss: 10.5270\n",
      "[84/1762] D loss: 0.0000, G loss: 16.0065\n",
      "[164/1762] D loss: 0.0000, G loss: 19.2160\n",
      "[244/1762] D loss: 0.0002, G loss: 15.3420\n",
      "[324/1762] D loss: 0.0000, G loss: 15.7507\n",
      "[404/1762] D loss: 0.0000, G loss: 31.1201\n",
      "[484/1762] D loss: 0.0000, G loss: 25.9721\n",
      "[564/1762] D loss: 0.0000, G loss: 25.1310\n",
      "[644/1762] D loss: 0.0000, G loss: 33.8984\n",
      "[724/1762] D loss: 0.0000, G loss: 24.6411\n",
      "[804/1762] D loss: 0.0000, G loss: 13.4222\n",
      "[884/1762] D loss: 0.0000, G loss: 27.9604\n",
      "[964/1762] D loss: 0.0000, G loss: 28.3341\n",
      "[1044/1762] D loss: 0.0000, G loss: 23.7073\n",
      "[1124/1762] D loss: 0.0000, G loss: 51.4298\n",
      "[1204/1762] D loss: 0.0000, G loss: 48.9197\n",
      "[1284/1762] D loss: 0.0000, G loss: 22.1330\n",
      "[1364/1762] D loss: 0.0000, G loss: 18.9343\n",
      "[1444/1762] D loss: 0.0045, G loss: 24.2586\n",
      "[1524/1762] D loss: 0.0001, G loss: 21.9439\n",
      "[1604/1762] D loss: 0.0000, G loss: 34.7149\n",
      "[1684/1762] D loss: 0.0000, G loss: 21.6411\n",
      "[1762/1762] D loss: 0.0000, G loss: 35.4219\n",
      "train error: \n",
      " D loss: 0.001051, G loss: 23.095963, D accuracy: 99.9%, cell accuracy: 97.0%, board accuracy: 0.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.001786, G loss: 23.178721, D accuracy: 99.9%, cell accuracy: 96.9%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 26.5520\n",
      "[84/1762] D loss: 0.0000, G loss: 14.4914\n",
      "[164/1762] D loss: 0.3043, G loss: 13.7574\n",
      "[244/1762] D loss: 0.0001, G loss: 25.0432\n",
      "[324/1762] D loss: 0.0000, G loss: 32.8091\n",
      "[404/1762] D loss: 0.0001, G loss: 12.9594\n",
      "[484/1762] D loss: 0.0000, G loss: 14.6365\n",
      "[564/1762] D loss: 0.0000, G loss: 20.9133\n",
      "[644/1762] D loss: 0.0000, G loss: 15.8963\n",
      "[724/1762] D loss: 0.0000, G loss: 29.2183\n",
      "[804/1762] D loss: 0.0001, G loss: 26.7762\n",
      "[884/1762] D loss: 0.0000, G loss: 40.1530\n",
      "[964/1762] D loss: 0.0000, G loss: 13.0409\n",
      "[1044/1762] D loss: 0.0000, G loss: 21.7128\n",
      "[1124/1762] D loss: 0.0000, G loss: 23.9449\n",
      "[1204/1762] D loss: 0.0014, G loss: 15.8452\n",
      "[1284/1762] D loss: 0.0021, G loss: 8.5169\n",
      "[1364/1762] D loss: 0.0002, G loss: 16.8351\n",
      "[1444/1762] D loss: 0.0001, G loss: 13.8756\n",
      "[1524/1762] D loss: 0.0000, G loss: 51.6888\n",
      "[1604/1762] D loss: 0.0000, G loss: 31.0921\n",
      "[1684/1762] D loss: 0.0086, G loss: 19.0676\n",
      "[1762/1762] D loss: 0.0001, G loss: 30.9688\n",
      "train error: \n",
      " D loss: 0.021380, G loss: 21.062531, D accuracy: 99.8%, cell accuracy: 97.0%, board accuracy: 0.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.008850, G loss: 21.043174, D accuracy: 99.9%, cell accuracy: 96.9%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 25.8051\n",
      "[84/1762] D loss: 0.0000, G loss: 21.9447\n",
      "[164/1762] D loss: 0.0000, G loss: 14.2627\n",
      "[244/1762] D loss: 0.0001, G loss: 34.0302\n",
      "[324/1762] D loss: 0.0000, G loss: 22.5988\n",
      "[404/1762] D loss: 0.0019, G loss: 6.3994\n",
      "[484/1762] D loss: 0.0148, G loss: 12.0812\n",
      "[564/1762] D loss: 0.0000, G loss: 20.1112\n",
      "[644/1762] D loss: 0.0003, G loss: 30.3670\n",
      "[724/1762] D loss: 0.0019, G loss: 9.1029\n",
      "[804/1762] D loss: 0.0006, G loss: 17.0759\n",
      "[884/1762] D loss: 0.0025, G loss: 12.3965\n",
      "[964/1762] D loss: 0.0001, G loss: 67.7599\n",
      "[1044/1762] D loss: 0.0001, G loss: 10.6096\n",
      "[1124/1762] D loss: 0.0000, G loss: 18.5323\n",
      "[1204/1762] D loss: 0.0000, G loss: 15.6052\n",
      "[1284/1762] D loss: 0.0000, G loss: 22.2602\n",
      "[1364/1762] D loss: 0.0001, G loss: 14.3768\n",
      "[1444/1762] D loss: 0.0000, G loss: 23.6407\n",
      "[1524/1762] D loss: 0.0001, G loss: 37.8815\n",
      "[1604/1762] D loss: 0.0000, G loss: 23.2427\n",
      "[1684/1762] D loss: 0.0003, G loss: 11.3851\n",
      "[1762/1762] D loss: 0.0001, G loss: 14.4060\n",
      "train error: \n",
      " D loss: 0.007696, G loss: 22.234030, D accuracy: 99.9%, cell accuracy: 97.0%, board accuracy: 0.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.008023, G loss: 22.110969, D accuracy: 100.0%, cell accuracy: 97.0%, board accuracy: 0.5% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0175, G loss: 31.7229\n",
      "[84/1762] D loss: 0.0005, G loss: 15.1900\n",
      "[164/1762] D loss: 0.0000, G loss: 15.5938\n",
      "[244/1762] D loss: 0.0000, G loss: 41.2972\n",
      "[324/1762] D loss: 0.0003, G loss: 13.3044\n",
      "[404/1762] D loss: 0.0005, G loss: 14.4079\n",
      "[484/1762] D loss: 0.0000, G loss: 32.2667\n",
      "[564/1762] D loss: 0.0000, G loss: 19.1827\n",
      "[644/1762] D loss: 0.0000, G loss: 27.3662\n",
      "[724/1762] D loss: 0.0000, G loss: 12.8387\n",
      "[804/1762] D loss: 0.0000, G loss: 34.1634\n",
      "[884/1762] D loss: 0.0008, G loss: 43.5749\n",
      "[964/1762] D loss: 0.0000, G loss: 24.6251\n",
      "[1044/1762] D loss: 0.0000, G loss: 23.2427\n",
      "[1124/1762] D loss: 0.0000, G loss: 53.4175\n",
      "[1204/1762] D loss: 0.0000, G loss: 15.8613\n",
      "[1284/1762] D loss: 0.0001, G loss: 17.8213\n",
      "[1364/1762] D loss: 0.0002, G loss: 36.3323\n",
      "[1444/1762] D loss: 0.0000, G loss: 24.8700\n",
      "[1524/1762] D loss: 0.0000, G loss: 33.1123\n",
      "[1604/1762] D loss: 0.0000, G loss: 33.6502\n",
      "[1684/1762] D loss: 0.0001, G loss: 31.6964\n",
      "[1762/1762] D loss: 0.0001, G loss: 16.4615\n",
      "train error: \n",
      " D loss: 0.000481, G loss: 29.096843, D accuracy: 100.0%, cell accuracy: 96.9%, board accuracy: 0.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000094, G loss: 29.118152, D accuracy: 100.0%, cell accuracy: 96.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0009, G loss: 21.7455\n",
      "[84/1762] D loss: 0.0001, G loss: 21.2531\n",
      "[164/1762] D loss: 0.0000, G loss: 18.7211\n",
      "[244/1762] D loss: 0.0000, G loss: 32.5541\n",
      "[324/1762] D loss: 0.0000, G loss: 60.8047\n",
      "[404/1762] D loss: 0.0000, G loss: 17.0502\n",
      "[484/1762] D loss: 0.0000, G loss: 59.6163\n",
      "[564/1762] D loss: 0.0000, G loss: 50.5067\n",
      "[644/1762] D loss: 0.0000, G loss: 12.7708\n",
      "[724/1762] D loss: 0.0000, G loss: 21.7464\n",
      "[804/1762] D loss: 0.0003, G loss: 68.9442\n",
      "[884/1762] D loss: 0.0000, G loss: 47.0124\n",
      "[964/1762] D loss: 0.0000, G loss: 11.3572\n",
      "[1044/1762] D loss: 0.0002, G loss: 39.5923\n",
      "[1124/1762] D loss: 0.0001, G loss: 23.1199\n",
      "[1204/1762] D loss: 0.0000, G loss: 40.2845\n",
      "[1284/1762] D loss: 0.0002, G loss: 25.8528\n",
      "[1364/1762] D loss: 0.0000, G loss: 45.6931\n",
      "[1444/1762] D loss: 0.0000, G loss: 52.3875\n",
      "[1524/1762] D loss: 0.0000, G loss: 44.1426\n",
      "[1604/1762] D loss: 0.0000, G loss: 43.1075\n",
      "[1684/1762] D loss: 0.0000, G loss: 22.7481\n",
      "[1762/1762] D loss: 0.0000, G loss: 29.6982\n",
      "train error: \n",
      " D loss: 0.000401, G loss: 36.573419, D accuracy: 100.0%, cell accuracy: 97.0%, board accuracy: 0.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000056, G loss: 37.142240, D accuracy: 100.0%, cell accuracy: 96.9%, board accuracy: 0.7% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0008, G loss: 11.3304\n",
      "[84/1762] D loss: 0.0001, G loss: 37.9038\n",
      "[164/1762] D loss: 0.0000, G loss: 50.4348\n",
      "[244/1762] D loss: 0.0000, G loss: 30.0315\n",
      "[324/1762] D loss: 0.0000, G loss: 34.0568\n",
      "[404/1762] D loss: 0.0003, G loss: 24.3184\n",
      "[484/1762] D loss: 0.0000, G loss: 57.7385\n",
      "[564/1762] D loss: 0.0000, G loss: 23.8095\n",
      "[644/1762] D loss: 0.0000, G loss: 43.2821\n",
      "[724/1762] D loss: 0.0000, G loss: 41.8274\n",
      "[804/1762] D loss: 0.0000, G loss: 31.2342\n",
      "[884/1762] D loss: 0.0000, G loss: 30.3794\n",
      "[964/1762] D loss: 0.0000, G loss: 35.1520\n",
      "[1044/1762] D loss: 0.0000, G loss: 23.1862\n",
      "[1124/1762] D loss: 0.0000, G loss: 23.9101\n",
      "[1204/1762] D loss: 0.0000, G loss: 20.7624\n",
      "[1284/1762] D loss: 0.0000, G loss: 17.7611\n",
      "[1364/1762] D loss: 0.0000, G loss: 39.6072\n",
      "[1444/1762] D loss: 0.0000, G loss: 40.7884\n",
      "[1524/1762] D loss: 0.0000, G loss: 30.9970\n",
      "[1604/1762] D loss: 0.0000, G loss: 27.0025\n",
      "[1684/1762] D loss: 0.0000, G loss: 55.1339\n",
      "[1762/1762] D loss: 0.0000, G loss: 10.6963\n",
      "train error: \n",
      " D loss: 0.001218, G loss: 33.531809, D accuracy: 99.9%, cell accuracy: 97.0%, board accuracy: 0.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.016835, G loss: 34.255709, D accuracy: 99.7%, cell accuracy: 96.9%, board accuracy: 0.7% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 21.7401\n",
      "[84/1762] D loss: 0.0000, G loss: 26.2838\n",
      "[164/1762] D loss: 0.0000, G loss: 60.3027\n",
      "[244/1762] D loss: 0.0000, G loss: 15.8691\n",
      "[324/1762] D loss: 0.0022, G loss: 14.6704\n",
      "[404/1762] D loss: 0.0005, G loss: 34.6734\n",
      "[484/1762] D loss: 0.0005, G loss: 11.3603\n",
      "[564/1762] D loss: 0.0031, G loss: 29.9041\n",
      "[644/1762] D loss: 0.0021, G loss: 9.6904\n",
      "[724/1762] D loss: 0.0000, G loss: 24.7091\n",
      "[804/1762] D loss: 0.0029, G loss: 6.2691\n",
      "[884/1762] D loss: 0.0009, G loss: 11.8019\n",
      "[964/1762] D loss: 0.0009, G loss: 16.0652\n",
      "[1044/1762] D loss: 0.0016, G loss: 37.1048\n",
      "[1124/1762] D loss: 0.0030, G loss: 7.3580\n",
      "[1204/1762] D loss: 0.0004, G loss: 23.8161\n",
      "[1284/1762] D loss: 0.0002, G loss: 16.1389\n",
      "[1364/1762] D loss: 0.0000, G loss: 20.4180\n",
      "[1444/1762] D loss: 0.0001, G loss: 40.4685\n",
      "[1524/1762] D loss: 0.0002, G loss: 33.3588\n",
      "[1604/1762] D loss: 0.0000, G loss: 64.2675\n",
      "[1684/1762] D loss: 0.0000, G loss: 25.8234\n",
      "[1762/1762] D loss: 0.0000, G loss: 27.5247\n",
      "train error: \n",
      " D loss: 0.008392, G loss: 28.257750, D accuracy: 99.9%, cell accuracy: 97.0%, board accuracy: 0.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000120, G loss: 28.589569, D accuracy: 100.0%, cell accuracy: 96.9%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001, G loss: 14.7551\n",
      "[84/1762] D loss: 0.0001, G loss: 25.1291\n",
      "[164/1762] D loss: 0.0000, G loss: 43.3736\n",
      "[244/1762] D loss: 0.0001, G loss: 46.2616\n",
      "[324/1762] D loss: 0.0000, G loss: 26.9804\n",
      "[404/1762] D loss: 0.0000, G loss: 43.9687\n",
      "[484/1762] D loss: 0.0000, G loss: 34.6895\n",
      "[564/1762] D loss: 0.0009, G loss: 34.2068\n",
      "[644/1762] D loss: 0.0001, G loss: 24.9456\n",
      "[724/1762] D loss: 0.0001, G loss: 14.2019\n",
      "[804/1762] D loss: 0.0000, G loss: 22.4523\n",
      "[884/1762] D loss: 0.0001, G loss: 17.8705\n",
      "[964/1762] D loss: 0.0000, G loss: 16.7347\n",
      "[1044/1762] D loss: 0.0000, G loss: 14.8969\n",
      "[1124/1762] D loss: 0.0021, G loss: 15.7124\n",
      "[1204/1762] D loss: 0.0000, G loss: 25.6580\n",
      "[1284/1762] D loss: 0.0000, G loss: 26.2616\n",
      "[1364/1762] D loss: 0.0000, G loss: 14.1096\n",
      "[1444/1762] D loss: 0.0002, G loss: 30.8638\n",
      "[1524/1762] D loss: 0.0000, G loss: 45.3928\n",
      "[1604/1762] D loss: 0.0002, G loss: 19.6772\n",
      "[1684/1762] D loss: 0.0002, G loss: 11.5073\n",
      "[1762/1762] D loss: 0.0041, G loss: 20.4393\n",
      "train error: \n",
      " D loss: 0.006175, G loss: 28.672302, D accuracy: 99.9%, cell accuracy: 97.0%, board accuracy: 0.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000048, G loss: 28.490553, D accuracy: 100.0%, cell accuracy: 97.0%, board accuracy: 0.5% \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    for cls in [DiscWithMoreConvBN, DiscWithMoreConv, DiscWithMoreConvBNPad, DiscWithMoreConvPad]:\n",
    "        run_name = \"fgrd_\" + cls.__name__\n",
    "        train_and_freeze_gen_and_replace_disc(run_name=run_name, disc_cls=cls)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results here are very clear - batch normalization in the discriminator hurts performance. This is supported by the paper _[A Large-Scale Study on Regularization and Normalization in GANs](https://arxiv.org/pdf/1807.04720.pdf)_, which suggests other normalization schemes that we could try instead. However, just removing the batch norm for now is easiest.\n",
    "\n",
    "Out of `DiscWithMoreConv` and `DiscWithMoreConvPad`, `DiscWithMoreConvPad` seems to perform better overall, but let's try both architectures in the main GAN training and see which leads to better overall performance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also noticed a problem with the \"combined accuracy\" which explain why it goes above 100%, and show that it might just be a useless metric. We assume that the input to the discriminator D is the thresholded output of the generator G, but in fact the input is the non-thresholded version. This means that the accuracy $ a_G $ used in the calculation is artificially high given the definition of $ a_D $."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply to main training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(run_name=\"\", disc_cls=TetrisDiscriminator, epochs=50):\n",
    "    learning_rate = 1e-3\n",
    "\n",
    "    gen = TetrisModel().to(device)\n",
    "    disc = disc_cls().to(device)\n",
    "\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer_gen = torch.optim.Adam(gen.parameters(), lr=learning_rate)\n",
    "    optimizer_disc = torch.optim.Adam(disc.parameters(), lr=learning_rate)\n",
    "\n",
    "    log_dir = os.path.join(\"runs\", \"experiment_019\")\n",
    "    log_subdir = os.path.join(log_dir, run_name + \"_\" + datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"))\n",
    "    tb_writer = SummaryWriter(log_subdir)\n",
    "\n",
    "    train_examples = find_interesting_examples(train_dataset)\n",
    "    test_examples = find_interesting_examples(test_dataset)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch}\\n-------------------------------\")\n",
    "        train_loop(train_dataloader, gen, disc, loss_fn, optimizer_gen, optimizer_disc)\n",
    "        test_loop(\"train\", train_dataloader, gen, disc, loss_fn, tb_writer, epoch, train_examples)\n",
    "        test_loop(\"test\", test_dataloader, gen, disc, loss_fn, tb_writer, epoch, test_examples)\n",
    "        for name, weight in gen.named_parameters():\n",
    "            tb_writer.add_histogram(f\"Generator weights/{name}\", weight, epoch)\n",
    "            tb_writer.add_histogram(f\"Generator gradients/{name}\", weight.grad, epoch)\n",
    "        for name, weight in disc.named_parameters():\n",
    "            tb_writer.add_histogram(f\"Discriminator weights/{name}\", weight, epoch)\n",
    "            tb_writer.add_histogram(f\"Discriminator gradients/{name}\", weight.grad, epoch)\n",
    "\n",
    "    tb_writer.close()\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3892, G loss: 0.6414\n",
      "[84/1762] D loss: 1.3302, G loss: 0.7201\n",
      "[164/1762] D loss: 0.7441, G loss: 1.4206\n",
      "[244/1762] D loss: 0.2290, G loss: 3.1195\n",
      "[324/1762] D loss: 0.0895, G loss: 3.2415\n",
      "[404/1762] D loss: 0.1292, G loss: 3.1448\n",
      "[484/1762] D loss: 0.4249, G loss: 1.3855\n",
      "[564/1762] D loss: 0.5185, G loss: 0.8465\n",
      "[644/1762] D loss: 0.5203, G loss: 2.4053\n",
      "[724/1762] D loss: 1.4124, G loss: 0.3857\n",
      "[804/1762] D loss: 0.9023, G loss: 1.1524\n",
      "[884/1762] D loss: 0.7865, G loss: 1.7076\n",
      "[964/1762] D loss: 0.8257, G loss: 1.6789\n",
      "[1044/1762] D loss: 0.5351, G loss: 1.1946\n",
      "[1124/1762] D loss: 0.2774, G loss: 1.2280\n",
      "[1204/1762] D loss: 1.9897, G loss: 0.5594\n",
      "[1284/1762] D loss: 1.5844, G loss: 1.7941\n",
      "[1364/1762] D loss: 1.2731, G loss: 1.6554\n",
      "[1444/1762] D loss: 1.0932, G loss: 0.9276\n",
      "[1524/1762] D loss: 1.0267, G loss: 0.9000\n",
      "[1604/1762] D loss: 0.9021, G loss: 1.0433\n",
      "[1684/1762] D loss: 1.1549, G loss: 1.7695\n",
      "[1762/1762] D loss: 0.8986, G loss: 1.8093\n",
      "train error: \n",
      " D loss: 1.075855, G loss: 1.617294, D accuracy: 74.5%, cell accuracy: 98.0%, board accuracy: 0.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.125492, G loss: 1.625474, D accuracy: 71.8%, cell accuracy: 97.9%, board accuracy: 0.5% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1984, G loss: 1.1306\n",
      "[84/1762] D loss: 0.6793, G loss: 1.5207\n",
      "[164/1762] D loss: 1.0501, G loss: 1.1425\n",
      "[244/1762] D loss: 1.4711, G loss: 0.4032\n",
      "[324/1762] D loss: 1.1400, G loss: 1.1099\n",
      "[404/1762] D loss: 0.6806, G loss: 1.8156\n",
      "[484/1762] D loss: 0.5251, G loss: 1.9103\n",
      "[564/1762] D loss: 0.8575, G loss: 2.0966\n",
      "[644/1762] D loss: 0.5462, G loss: 2.0860\n",
      "[724/1762] D loss: 1.1504, G loss: 0.7078\n",
      "[804/1762] D loss: 1.2221, G loss: 0.6006\n",
      "[884/1762] D loss: 1.1530, G loss: 0.6863\n",
      "[964/1762] D loss: 1.0755, G loss: 1.6739\n",
      "[1044/1762] D loss: 1.2743, G loss: 1.2860\n",
      "[1124/1762] D loss: 0.7455, G loss: 1.0621\n",
      "[1204/1762] D loss: 0.9190, G loss: 2.1927\n",
      "[1284/1762] D loss: 0.6725, G loss: 1.0908\n",
      "[1364/1762] D loss: 2.2258, G loss: 0.7633\n",
      "[1444/1762] D loss: 2.5425, G loss: 3.4440\n",
      "[1524/1762] D loss: 1.2702, G loss: 0.8813\n",
      "[1604/1762] D loss: 1.3281, G loss: 1.0480\n",
      "[1684/1762] D loss: 1.1153, G loss: 0.6811\n",
      "[1762/1762] D loss: 1.0216, G loss: 0.9792\n",
      "train error: \n",
      " D loss: 1.200749, G loss: 0.747809, D accuracy: 66.7%, cell accuracy: 98.7%, board accuracy: 15.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.188783, G loss: 0.749617, D accuracy: 67.7%, cell accuracy: 98.6%, board accuracy: 13.4% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9737, G loss: 0.9543\n",
      "[84/1762] D loss: 1.1827, G loss: 1.0041\n",
      "[164/1762] D loss: 1.0162, G loss: 0.7748\n",
      "[244/1762] D loss: 1.3026, G loss: 0.9672\n",
      "[324/1762] D loss: 1.2470, G loss: 1.0777\n",
      "[404/1762] D loss: 1.4161, G loss: 0.5251\n",
      "[484/1762] D loss: 1.5623, G loss: 0.5442\n",
      "[564/1762] D loss: 1.3282, G loss: 0.8317\n",
      "[644/1762] D loss: 1.3015, G loss: 0.6329\n",
      "[724/1762] D loss: 1.0788, G loss: 0.9978\n",
      "[804/1762] D loss: 1.1068, G loss: 0.7679\n",
      "[884/1762] D loss: 1.1425, G loss: 0.7725\n",
      "[964/1762] D loss: 1.2104, G loss: 0.9284\n",
      "[1044/1762] D loss: 1.4559, G loss: 0.4154\n",
      "[1124/1762] D loss: 1.3837, G loss: 0.7275\n",
      "[1204/1762] D loss: 1.3783, G loss: 1.0131\n",
      "[1284/1762] D loss: 1.2742, G loss: 0.7061\n",
      "[1364/1762] D loss: 1.3400, G loss: 0.7352\n",
      "[1444/1762] D loss: 1.1314, G loss: 0.9234\n",
      "[1524/1762] D loss: 1.3503, G loss: 0.7203\n",
      "[1604/1762] D loss: 1.1510, G loss: 0.8698\n",
      "[1684/1762] D loss: 1.3599, G loss: 0.9135\n",
      "[1762/1762] D loss: 1.2721, G loss: 0.8972\n",
      "train error: \n",
      " D loss: 1.338178, G loss: 0.743658, D accuracy: 58.8%, cell accuracy: 99.6%, board accuracy: 65.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.333835, G loss: 0.744135, D accuracy: 58.6%, cell accuracy: 99.5%, board accuracy: 59.5% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3515, G loss: 0.7861\n",
      "[84/1762] D loss: 1.2052, G loss: 0.9572\n",
      "[164/1762] D loss: 1.3465, G loss: 0.6311\n",
      "[244/1762] D loss: 1.3986, G loss: 0.8763\n",
      "[324/1762] D loss: 1.4083, G loss: 0.7946\n",
      "[404/1762] D loss: 1.4280, G loss: 0.5490\n",
      "[484/1762] D loss: 1.2870, G loss: 0.6149\n",
      "[564/1762] D loss: 1.3109, G loss: 0.7083\n",
      "[644/1762] D loss: 1.5654, G loss: 1.0098\n",
      "[724/1762] D loss: 1.4091, G loss: 0.7211\n",
      "[804/1762] D loss: 1.4423, G loss: 0.5761\n",
      "[884/1762] D loss: 1.3481, G loss: 0.8204\n",
      "[964/1762] D loss: 1.2709, G loss: 0.6897\n",
      "[1044/1762] D loss: 1.3374, G loss: 0.6707\n",
      "[1124/1762] D loss: 1.3727, G loss: 0.6433\n",
      "[1204/1762] D loss: 1.3591, G loss: 0.8053\n",
      "[1284/1762] D loss: 1.3079, G loss: 0.6630\n",
      "[1364/1762] D loss: 1.2686, G loss: 0.8344\n",
      "[1444/1762] D loss: 1.3412, G loss: 0.6355\n",
      "[1524/1762] D loss: 1.3068, G loss: 0.9554\n",
      "[1604/1762] D loss: 1.2376, G loss: 0.9199\n",
      "[1684/1762] D loss: 1.3594, G loss: 0.7347\n",
      "[1762/1762] D loss: 1.3797, G loss: 0.7368\n",
      "train error: \n",
      " D loss: 1.355003, G loss: 0.755032, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 84.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.350791, G loss: 0.756202, D accuracy: 55.6%, cell accuracy: 99.7%, board accuracy: 82.0% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3902, G loss: 0.7375\n",
      "[84/1762] D loss: 1.3835, G loss: 0.5716\n",
      "[164/1762] D loss: 1.3386, G loss: 0.8463\n",
      "[244/1762] D loss: 1.2674, G loss: 0.8465\n",
      "[324/1762] D loss: 1.3935, G loss: 0.6215\n",
      "[404/1762] D loss: 1.3429, G loss: 0.7975\n",
      "[484/1762] D loss: 1.3925, G loss: 0.7954\n",
      "[564/1762] D loss: 1.2672, G loss: 0.8449\n",
      "[644/1762] D loss: 1.3689, G loss: 0.7063\n",
      "[724/1762] D loss: 1.4080, G loss: 0.5556\n",
      "[804/1762] D loss: 1.4585, G loss: 0.7038\n",
      "[884/1762] D loss: 1.3896, G loss: 0.6575\n",
      "[964/1762] D loss: 1.3937, G loss: 0.6228\n",
      "[1044/1762] D loss: 1.4761, G loss: 0.4890\n",
      "[1124/1762] D loss: 1.3522, G loss: 0.8167\n",
      "[1204/1762] D loss: 1.3300, G loss: 0.8405\n",
      "[1284/1762] D loss: 1.4009, G loss: 0.6117\n",
      "[1364/1762] D loss: 1.3237, G loss: 0.6902\n",
      "[1444/1762] D loss: 1.2949, G loss: 0.8066\n",
      "[1524/1762] D loss: 1.3146, G loss: 0.6757\n",
      "[1604/1762] D loss: 1.3816, G loss: 0.6399\n",
      "[1684/1762] D loss: 1.1343, G loss: 0.7206\n",
      "[1762/1762] D loss: 1.2583, G loss: 0.7222\n",
      "train error: \n",
      " D loss: 1.342098, G loss: 0.709861, D accuracy: 55.8%, cell accuracy: 99.8%, board accuracy: 86.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.336249, G loss: 0.707085, D accuracy: 57.0%, cell accuracy: 99.7%, board accuracy: 83.9% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2711, G loss: 0.7478\n",
      "[84/1762] D loss: 1.4162, G loss: 0.9493\n",
      "[164/1762] D loss: 1.3465, G loss: 0.5676\n",
      "[244/1762] D loss: 1.4139, G loss: 0.8676\n",
      "[324/1762] D loss: 1.2879, G loss: 0.5934\n",
      "[404/1762] D loss: 1.2993, G loss: 0.8589\n",
      "[484/1762] D loss: 1.3905, G loss: 0.7961\n",
      "[564/1762] D loss: 1.2414, G loss: 0.8102\n",
      "[644/1762] D loss: 1.3862, G loss: 0.7191\n",
      "[724/1762] D loss: 1.2891, G loss: 0.8548\n",
      "[804/1762] D loss: 1.3955, G loss: 0.6148\n",
      "[884/1762] D loss: 1.2443, G loss: 0.9696\n",
      "[964/1762] D loss: 1.3838, G loss: 0.7136\n",
      "[1044/1762] D loss: 1.3874, G loss: 0.5513\n",
      "[1124/1762] D loss: 1.2273, G loss: 0.9079\n",
      "[1204/1762] D loss: 1.4191, G loss: 0.7511\n",
      "[1284/1762] D loss: 1.4401, G loss: 0.9010\n",
      "[1364/1762] D loss: 1.2319, G loss: 0.6992\n",
      "[1444/1762] D loss: 1.4169, G loss: 0.5775\n",
      "[1524/1762] D loss: 1.3990, G loss: 0.6883\n",
      "[1604/1762] D loss: 1.2944, G loss: 0.8345\n",
      "[1684/1762] D loss: 1.5004, G loss: 0.5323\n",
      "[1762/1762] D loss: 1.4762, G loss: 0.9048\n",
      "train error: \n",
      " D loss: 1.505436, G loss: 1.051452, D accuracy: 49.8%, cell accuracy: 97.9%, board accuracy: 13.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.504213, G loss: 1.054339, D accuracy: 49.3%, cell accuracy: 97.9%, board accuracy: 13.6% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5462, G loss: 1.0076\n",
      "[84/1762] D loss: 1.5451, G loss: 0.7175\n",
      "[164/1762] D loss: 1.3529, G loss: 0.7532\n",
      "[244/1762] D loss: 1.4292, G loss: 0.7648\n",
      "[324/1762] D loss: 1.3751, G loss: 0.6905\n",
      "[404/1762] D loss: 1.3895, G loss: 0.6608\n",
      "[484/1762] D loss: 1.3883, G loss: 0.6237\n",
      "[564/1762] D loss: 1.3803, G loss: 0.6848\n",
      "[644/1762] D loss: 1.3722, G loss: 0.7043\n",
      "[724/1762] D loss: 1.3862, G loss: 0.6956\n",
      "[804/1762] D loss: 1.3238, G loss: 0.7264\n",
      "[884/1762] D loss: 1.3194, G loss: 0.7043\n",
      "[964/1762] D loss: 1.3428, G loss: 0.7371\n",
      "[1044/1762] D loss: 1.3869, G loss: 0.7473\n",
      "[1124/1762] D loss: 1.3944, G loss: 0.7893\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.7230\n",
      "[1284/1762] D loss: 1.3888, G loss: 0.6353\n",
      "[1364/1762] D loss: 1.4112, G loss: 0.6905\n",
      "[1444/1762] D loss: 1.3889, G loss: 0.7185\n",
      "[1524/1762] D loss: 1.3880, G loss: 0.6844\n",
      "[1604/1762] D loss: 1.3891, G loss: 0.6712\n",
      "[1684/1762] D loss: 1.3078, G loss: 0.7858\n",
      "[1762/1762] D loss: 1.3753, G loss: 0.6583\n",
      "train error: \n",
      " D loss: 1.365427, G loss: 0.647641, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 90.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.360760, G loss: 0.646223, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2880, G loss: 0.7439\n",
      "[84/1762] D loss: 1.3720, G loss: 0.6555\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6834\n",
      "[244/1762] D loss: 1.3851, G loss: 0.7011\n",
      "[324/1762] D loss: 1.3856, G loss: 0.7178\n",
      "[404/1762] D loss: 1.3854, G loss: 0.7218\n",
      "[484/1762] D loss: 1.3875, G loss: 0.6398\n",
      "[564/1762] D loss: 1.7647, G loss: 0.5826\n",
      "[644/1762] D loss: 1.2940, G loss: 0.6527\n",
      "[724/1762] D loss: 1.3798, G loss: 0.7181\n",
      "[804/1762] D loss: 1.4161, G loss: 0.8037\n",
      "[884/1762] D loss: 1.3858, G loss: 0.6381\n",
      "[964/1762] D loss: 1.3939, G loss: 0.7842\n",
      "[1044/1762] D loss: 1.3898, G loss: 0.6362\n",
      "[1124/1762] D loss: 1.3954, G loss: 0.6099\n",
      "[1204/1762] D loss: 1.3916, G loss: 0.6676\n",
      "[1284/1762] D loss: 1.3644, G loss: 0.6959\n",
      "[1364/1762] D loss: 1.3849, G loss: 0.7247\n",
      "[1444/1762] D loss: 1.3871, G loss: 0.6745\n",
      "[1524/1762] D loss: 1.3870, G loss: 0.6238\n",
      "[1604/1762] D loss: 1.3858, G loss: 0.7162\n",
      "[1684/1762] D loss: 1.3889, G loss: 0.7295\n",
      "[1762/1762] D loss: 1.3862, G loss: 0.7207\n",
      "train error: \n",
      " D loss: 1.368821, G loss: 0.654158, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 88.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.366356, G loss: 0.651296, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 84.8% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3869, G loss: 0.6496\n",
      "[84/1762] D loss: 1.3835, G loss: 0.7152\n",
      "[164/1762] D loss: 1.3962, G loss: 0.6275\n",
      "[244/1762] D loss: 1.3885, G loss: 0.6646\n",
      "[324/1762] D loss: 1.3887, G loss: 0.6514\n",
      "[404/1762] D loss: 1.3863, G loss: 0.7382\n",
      "[484/1762] D loss: 1.3617, G loss: 0.6953\n",
      "[564/1762] D loss: 1.3879, G loss: 0.6406\n",
      "[644/1762] D loss: 1.2520, G loss: 0.8410\n",
      "[724/1762] D loss: 1.3917, G loss: 0.6453\n",
      "[804/1762] D loss: 1.3956, G loss: 0.6187\n",
      "[884/1762] D loss: 1.3902, G loss: 0.7487\n",
      "[964/1762] D loss: 1.3777, G loss: 0.7518\n",
      "[1044/1762] D loss: 1.3916, G loss: 0.6847\n",
      "[1124/1762] D loss: 1.3166, G loss: 0.7815\n",
      "[1204/1762] D loss: 1.4435, G loss: 0.7646\n",
      "[1284/1762] D loss: 1.3880, G loss: 0.7343\n",
      "[1364/1762] D loss: 1.3442, G loss: 0.7452\n",
      "[1444/1762] D loss: 1.3910, G loss: 0.7536\n",
      "[1524/1762] D loss: 1.3900, G loss: 0.7305\n",
      "[1604/1762] D loss: 1.4030, G loss: 0.6946\n",
      "[1684/1762] D loss: 1.3849, G loss: 0.7025\n",
      "[1762/1762] D loss: 1.1784, G loss: 0.8637\n",
      "train error: \n",
      " D loss: 1.367375, G loss: 0.768985, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.364216, G loss: 0.767484, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3968, G loss: 0.7469\n",
      "[84/1762] D loss: 1.3882, G loss: 0.7185\n",
      "[164/1762] D loss: 1.2950, G loss: 0.7889\n",
      "[244/1762] D loss: 1.2298, G loss: 0.8194\n",
      "[324/1762] D loss: 1.3878, G loss: 0.6978\n",
      "[404/1762] D loss: 1.3878, G loss: 0.6710\n",
      "[484/1762] D loss: 1.2240, G loss: 0.7409\n",
      "[564/1762] D loss: 1.3915, G loss: 0.6293\n",
      "[644/1762] D loss: 1.3899, G loss: 0.7203\n",
      "[724/1762] D loss: 1.3607, G loss: 0.8150\n",
      "[804/1762] D loss: 1.3933, G loss: 0.6558\n",
      "[884/1762] D loss: 1.2381, G loss: 0.9643\n",
      "[964/1762] D loss: 1.0465, G loss: 0.7703\n",
      "[1044/1762] D loss: 1.3913, G loss: 0.6880\n",
      "[1124/1762] D loss: 1.4393, G loss: 0.5435\n",
      "[1204/1762] D loss: 1.4024, G loss: 0.7118\n",
      "[1284/1762] D loss: 1.4197, G loss: 0.5342\n",
      "[1364/1762] D loss: 1.3948, G loss: 0.7021\n",
      "[1444/1762] D loss: 1.3920, G loss: 0.6756\n",
      "[1524/1762] D loss: 1.4026, G loss: 0.7952\n",
      "[1604/1762] D loss: 1.4013, G loss: 0.6372\n",
      "[1684/1762] D loss: 1.3904, G loss: 0.7568\n",
      "[1762/1762] D loss: 1.4904, G loss: 0.6438\n",
      "train error: \n",
      " D loss: 1.339708, G loss: 0.844369, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 89.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.325727, G loss: 0.850429, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 85.2% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4052, G loss: 0.9593\n",
      "[84/1762] D loss: 1.4069, G loss: 0.6757\n",
      "[164/1762] D loss: 1.1828, G loss: 0.8139\n",
      "[244/1762] D loss: 1.5903, G loss: 0.5766\n",
      "[324/1762] D loss: 1.2701, G loss: 0.7808\n",
      "[404/1762] D loss: 1.4035, G loss: 0.7261\n",
      "[484/1762] D loss: 1.4680, G loss: 0.6681\n",
      "[564/1762] D loss: 1.3903, G loss: 0.7949\n",
      "[644/1762] D loss: 1.3892, G loss: 0.6863\n",
      "[724/1762] D loss: 1.3794, G loss: 0.7306\n",
      "[804/1762] D loss: 1.3899, G loss: 0.7479\n",
      "[884/1762] D loss: 1.3840, G loss: 0.6809\n",
      "[964/1762] D loss: 1.3866, G loss: 0.6898\n",
      "[1044/1762] D loss: 1.3862, G loss: 0.6817\n",
      "[1124/1762] D loss: 1.3849, G loss: 0.7060\n",
      "[1204/1762] D loss: 1.3882, G loss: 0.7311\n",
      "[1284/1762] D loss: 1.3859, G loss: 0.6988\n",
      "[1364/1762] D loss: 1.3855, G loss: 0.7034\n",
      "[1444/1762] D loss: 1.3868, G loss: 0.7010\n",
      "[1524/1762] D loss: 1.3941, G loss: 0.6773\n",
      "[1604/1762] D loss: 1.3878, G loss: 0.6964\n",
      "[1684/1762] D loss: 1.2814, G loss: 0.7478\n",
      "[1762/1762] D loss: 1.3672, G loss: 0.7453\n",
      "train error: \n",
      " D loss: 1.358394, G loss: 0.711769, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 85.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.353151, G loss: 0.711594, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 81.6% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3840, G loss: 0.7093\n",
      "[84/1762] D loss: 1.2709, G loss: 0.7294\n",
      "[164/1762] D loss: 1.3929, G loss: 0.6558\n",
      "[244/1762] D loss: 1.3880, G loss: 0.7336\n",
      "[324/1762] D loss: 1.3817, G loss: 0.6852\n",
      "[404/1762] D loss: 1.1013, G loss: 0.8594\n",
      "[484/1762] D loss: 1.3886, G loss: 0.7034\n",
      "[564/1762] D loss: 1.3948, G loss: 0.6767\n",
      "[644/1762] D loss: 1.6502, G loss: 0.8350\n",
      "[724/1762] D loss: 1.3748, G loss: 0.7641\n",
      "[804/1762] D loss: 1.3799, G loss: 0.6476\n",
      "[884/1762] D loss: 1.3870, G loss: 0.6811\n",
      "[964/1762] D loss: 1.3863, G loss: 0.6747\n",
      "[1044/1762] D loss: 1.3498, G loss: 0.7479\n",
      "[1124/1762] D loss: 1.3898, G loss: 0.7073\n",
      "[1204/1762] D loss: 1.4015, G loss: 0.6465\n",
      "[1284/1762] D loss: 1.3954, G loss: 0.6781\n",
      "[1364/1762] D loss: 1.2251, G loss: 0.6973\n",
      "[1444/1762] D loss: 1.2483, G loss: 0.6842\n",
      "[1524/1762] D loss: 1.3908, G loss: 0.7481\n",
      "[1604/1762] D loss: 1.3954, G loss: 0.7373\n",
      "[1684/1762] D loss: 1.4272, G loss: 0.6487\n",
      "[1762/1762] D loss: 1.3878, G loss: 0.7250\n",
      "train error: \n",
      " D loss: 1.347287, G loss: 0.820090, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 88.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.335955, G loss: 0.820682, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2313, G loss: 0.8567\n",
      "[84/1762] D loss: 1.3927, G loss: 0.7606\n",
      "[164/1762] D loss: 1.3844, G loss: 0.7658\n",
      "[244/1762] D loss: 1.3870, G loss: 0.6500\n",
      "[324/1762] D loss: 1.3922, G loss: 0.7269\n",
      "[404/1762] D loss: 1.1707, G loss: 0.8656\n",
      "[484/1762] D loss: 1.3892, G loss: 0.8122\n",
      "[564/1762] D loss: 1.2637, G loss: 0.7310\n",
      "[644/1762] D loss: 1.6904, G loss: 0.8654\n",
      "[724/1762] D loss: 1.4389, G loss: 0.6437\n",
      "[804/1762] D loss: 1.4269, G loss: 0.8082\n",
      "[884/1762] D loss: 1.3873, G loss: 0.7655\n",
      "[964/1762] D loss: 1.1062, G loss: 0.8813\n",
      "[1044/1762] D loss: 1.5022, G loss: 0.5732\n",
      "[1124/1762] D loss: 1.4896, G loss: 1.0488\n",
      "[1204/1762] D loss: 0.9901, G loss: 1.1612\n",
      "[1284/1762] D loss: 0.6288, G loss: 2.4988\n",
      "[1364/1762] D loss: 1.4057, G loss: 0.8293\n",
      "[1444/1762] D loss: 1.4116, G loss: 0.7887\n",
      "[1524/1762] D loss: 1.4110, G loss: 0.6749\n",
      "[1604/1762] D loss: 1.4033, G loss: 0.8965\n",
      "[1684/1762] D loss: 1.3316, G loss: 0.8079\n",
      "[1762/1762] D loss: 1.3244, G loss: 0.7310\n",
      "train error: \n",
      " D loss: 1.349073, G loss: 0.720781, D accuracy: 61.9%, cell accuracy: 97.9%, board accuracy: 8.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.348857, G loss: 0.718048, D accuracy: 62.5%, cell accuracy: 97.9%, board accuracy: 7.7% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3831, G loss: 0.7097\n",
      "[84/1762] D loss: 1.3290, G loss: 0.6816\n",
      "[164/1762] D loss: 1.3710, G loss: 0.8218\n",
      "[244/1762] D loss: 1.3228, G loss: 0.9227\n",
      "[324/1762] D loss: 1.4093, G loss: 0.8434\n",
      "[404/1762] D loss: 1.4062, G loss: 0.7365\n",
      "[484/1762] D loss: 1.3142, G loss: 0.7312\n",
      "[564/1762] D loss: 1.2765, G loss: 0.6442\n",
      "[644/1762] D loss: 1.3651, G loss: 0.6870\n",
      "[724/1762] D loss: 1.3310, G loss: 0.8075\n",
      "[804/1762] D loss: 1.3928, G loss: 0.7339\n",
      "[884/1762] D loss: 1.4039, G loss: 0.5949\n",
      "[964/1762] D loss: 1.3931, G loss: 0.7928\n",
      "[1044/1762] D loss: 1.3995, G loss: 0.8539\n",
      "[1124/1762] D loss: 1.3948, G loss: 0.6334\n",
      "[1204/1762] D loss: 1.3860, G loss: 0.7202\n",
      "[1284/1762] D loss: 1.3906, G loss: 0.7165\n",
      "[1364/1762] D loss: 1.1704, G loss: 0.9878\n",
      "[1444/1762] D loss: 1.4218, G loss: 0.8530\n",
      "[1524/1762] D loss: 1.4096, G loss: 0.8668\n",
      "[1604/1762] D loss: 1.3928, G loss: 0.6646\n",
      "[1684/1762] D loss: 1.2065, G loss: 0.7979\n",
      "[1762/1762] D loss: 1.3851, G loss: 0.5989\n",
      "train error: \n",
      " D loss: 1.325508, G loss: 0.709523, D accuracy: 55.4%, cell accuracy: 99.7%, board accuracy: 68.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.308738, G loss: 0.715278, D accuracy: 56.5%, cell accuracy: 99.6%, board accuracy: 64.5% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1864, G loss: 0.7863\n",
      "[84/1762] D loss: 1.4317, G loss: 0.9495\n",
      "[164/1762] D loss: 1.1760, G loss: 0.8648\n",
      "[244/1762] D loss: 1.3976, G loss: 0.7846\n",
      "[324/1762] D loss: 1.3988, G loss: 0.6476\n",
      "[404/1762] D loss: 1.3988, G loss: 0.8418\n",
      "[484/1762] D loss: 1.1463, G loss: 0.8883\n",
      "[564/1762] D loss: 1.3897, G loss: 0.6829\n",
      "[644/1762] D loss: 0.8944, G loss: 1.0723\n",
      "[724/1762] D loss: 1.1307, G loss: 1.1813\n",
      "[804/1762] D loss: 1.4129, G loss: 0.8537\n",
      "[884/1762] D loss: 1.4154, G loss: 0.8270\n",
      "[964/1762] D loss: 1.4080, G loss: 0.8730\n",
      "[1044/1762] D loss: 2.0914, G loss: 1.6819\n",
      "[1124/1762] D loss: 1.0404, G loss: 0.9314\n",
      "[1204/1762] D loss: 0.9721, G loss: 1.2168\n",
      "[1284/1762] D loss: 1.4703, G loss: 0.4895\n",
      "[1364/1762] D loss: 1.3933, G loss: 0.7567\n",
      "[1444/1762] D loss: 1.3868, G loss: 0.7024\n",
      "[1524/1762] D loss: 1.3866, G loss: 0.7207\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6879\n",
      "[1684/1762] D loss: 1.4561, G loss: 0.6697\n",
      "[1762/1762] D loss: 1.3756, G loss: 0.6338\n",
      "train error: \n",
      " D loss: 1.399340, G loss: 0.661636, D accuracy: 50.3%, cell accuracy: 99.6%, board accuracy: 54.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.406225, G loss: 0.658511, D accuracy: 48.6%, cell accuracy: 99.5%, board accuracy: 53.4% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3874, G loss: 0.6619\n",
      "[84/1762] D loss: 1.4450, G loss: 0.6635\n",
      "[164/1762] D loss: 1.4246, G loss: 0.6805\n",
      "[244/1762] D loss: 1.3794, G loss: 0.7236\n",
      "[324/1762] D loss: 1.3842, G loss: 0.6732\n",
      "[404/1762] D loss: 1.3883, G loss: 0.6873\n",
      "[484/1762] D loss: 1.3872, G loss: 0.7067\n",
      "[564/1762] D loss: 1.3809, G loss: 0.6958\n",
      "[644/1762] D loss: 1.3861, G loss: 0.6896\n",
      "[724/1762] D loss: 1.3875, G loss: 0.6728\n",
      "[804/1762] D loss: 1.3848, G loss: 0.6897\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6924\n",
      "[964/1762] D loss: 1.3866, G loss: 0.6797\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.6943\n",
      "[1124/1762] D loss: 1.3816, G loss: 0.6858\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6911\n",
      "[1284/1762] D loss: 1.3855, G loss: 0.6710\n",
      "[1364/1762] D loss: 1.3868, G loss: 0.6722\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.6970\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.6919\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6883\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6889\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.6744\n",
      "train error: \n",
      " D loss: 1.387567, G loss: 0.686525, D accuracy: 48.2%, cell accuracy: 99.8%, board accuracy: 89.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.387952, G loss: 0.686033, D accuracy: 48.2%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3866, G loss: 0.6785\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6878\n",
      "[164/1762] D loss: 1.3833, G loss: 0.6816\n",
      "[244/1762] D loss: 1.3864, G loss: 0.6936\n",
      "[324/1762] D loss: 1.3865, G loss: 0.6909\n",
      "[404/1762] D loss: 1.3860, G loss: 0.6858\n",
      "[484/1762] D loss: 1.3866, G loss: 0.6804\n",
      "[564/1762] D loss: 1.3724, G loss: 0.6985\n",
      "[644/1762] D loss: 1.3872, G loss: 0.6889\n",
      "[724/1762] D loss: 1.3888, G loss: 0.6914\n",
      "[804/1762] D loss: 1.2908, G loss: 0.6868\n",
      "[884/1762] D loss: 1.3888, G loss: 0.6685\n",
      "[964/1762] D loss: 1.3872, G loss: 0.6674\n",
      "[1044/1762] D loss: 1.3876, G loss: 0.6665\n",
      "[1124/1762] D loss: 1.3942, G loss: 0.7055\n",
      "[1204/1762] D loss: 1.4808, G loss: 0.7003\n",
      "[1284/1762] D loss: 1.4025, G loss: 0.9682\n",
      "[1364/1762] D loss: 1.2628, G loss: 0.6194\n",
      "[1444/1762] D loss: 0.5377, G loss: 1.3300\n",
      "[1524/1762] D loss: 0.0380, G loss: 4.1564\n",
      "[1604/1762] D loss: 0.0047, G loss: 5.9457\n",
      "[1684/1762] D loss: 0.0045, G loss: 5.9526\n",
      "[1762/1762] D loss: 0.0013, G loss: 7.0511\n",
      "train error: \n",
      " D loss: 0.010304, G loss: 6.647999, D accuracy: 99.9%, cell accuracy: 94.4%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.013270, G loss: 6.666973, D accuracy: 99.9%, cell accuracy: 94.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0020, G loss: 6.5938\n",
      "[84/1762] D loss: 0.0025, G loss: 6.1060\n",
      "[164/1762] D loss: 1.0794, G loss: 0.9254\n",
      "[244/1762] D loss: 1.2310, G loss: 0.9701\n",
      "[324/1762] D loss: 0.9301, G loss: 1.2312\n",
      "[404/1762] D loss: 1.4233, G loss: 1.9104\n",
      "[484/1762] D loss: 1.3614, G loss: 0.7287\n",
      "[564/1762] D loss: 1.1119, G loss: 1.1919\n",
      "[644/1762] D loss: 0.9439, G loss: 1.1614\n",
      "[724/1762] D loss: 1.3744, G loss: 0.6752\n",
      "[804/1762] D loss: 1.6509, G loss: 1.1968\n",
      "[884/1762] D loss: 1.4307, G loss: 0.5568\n",
      "[964/1762] D loss: 1.3898, G loss: 0.6302\n",
      "[1044/1762] D loss: 1.3879, G loss: 0.7043\n",
      "[1124/1762] D loss: 1.3935, G loss: 0.7599\n",
      "[1204/1762] D loss: 1.3912, G loss: 0.6776\n",
      "[1284/1762] D loss: 1.1796, G loss: 0.7855\n",
      "[1364/1762] D loss: 1.3765, G loss: 0.6960\n",
      "[1444/1762] D loss: 1.3989, G loss: 0.7398\n",
      "[1524/1762] D loss: 1.3874, G loss: 0.6798\n",
      "[1604/1762] D loss: 1.1402, G loss: 0.8598\n",
      "[1684/1762] D loss: 1.3870, G loss: 0.6530\n",
      "[1762/1762] D loss: 1.4121, G loss: 0.8500\n",
      "train error: \n",
      " D loss: 1.329534, G loss: 0.830771, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.310045, G loss: 0.837529, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 85.9% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4104, G loss: 0.8799\n",
      "[84/1762] D loss: 1.4085, G loss: 0.7327\n",
      "[164/1762] D loss: 1.3901, G loss: 0.7726\n",
      "[244/1762] D loss: 1.3931, G loss: 0.7818\n",
      "[324/1762] D loss: 1.4185, G loss: 0.6836\n",
      "[404/1762] D loss: 1.4021, G loss: 0.6267\n",
      "[484/1762] D loss: 1.3888, G loss: 0.7331\n",
      "[564/1762] D loss: 1.1735, G loss: 0.7106\n",
      "[644/1762] D loss: 1.3881, G loss: 0.6693\n",
      "[724/1762] D loss: 1.3898, G loss: 0.6903\n",
      "[804/1762] D loss: 1.2918, G loss: 0.9150\n",
      "[884/1762] D loss: 1.3707, G loss: 0.7212\n",
      "[964/1762] D loss: 1.4089, G loss: 0.8518\n",
      "[1044/1762] D loss: 1.2772, G loss: 0.8949\n",
      "[1124/1762] D loss: 1.0509, G loss: 1.4238\n",
      "[1204/1762] D loss: 1.4373, G loss: 0.8505\n",
      "[1284/1762] D loss: 1.3727, G loss: 0.7243\n",
      "[1364/1762] D loss: 1.3980, G loss: 0.6801\n",
      "[1444/1762] D loss: 1.3848, G loss: 0.6877\n",
      "[1524/1762] D loss: 1.4115, G loss: 0.6721\n",
      "[1604/1762] D loss: 1.3099, G loss: 0.8165\n",
      "[1684/1762] D loss: 1.3602, G loss: 0.6606\n",
      "[1762/1762] D loss: 1.3847, G loss: 0.7335\n",
      "train error: \n",
      " D loss: 1.335114, G loss: 0.774636, D accuracy: 53.9%, cell accuracy: 99.7%, board accuracy: 72.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.327311, G loss: 0.777244, D accuracy: 55.0%, cell accuracy: 99.7%, board accuracy: 70.0% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3783, G loss: 0.7100\n",
      "[84/1762] D loss: 1.3956, G loss: 0.6479\n",
      "[164/1762] D loss: 1.1830, G loss: 0.7178\n",
      "[244/1762] D loss: 1.3916, G loss: 0.7534\n",
      "[324/1762] D loss: 1.3957, G loss: 0.6043\n",
      "[404/1762] D loss: 1.4072, G loss: 0.8179\n",
      "[484/1762] D loss: 1.3489, G loss: 0.7240\n",
      "[564/1762] D loss: 1.4009, G loss: 0.5870\n",
      "[644/1762] D loss: 1.1472, G loss: 0.8990\n",
      "[724/1762] D loss: 1.3901, G loss: 0.6350\n",
      "[804/1762] D loss: 1.1814, G loss: 0.7112\n",
      "[884/1762] D loss: 1.4023, G loss: 0.7196\n",
      "[964/1762] D loss: 1.3977, G loss: 0.7821\n",
      "[1044/1762] D loss: 1.1457, G loss: 0.8032\n",
      "[1124/1762] D loss: 1.3868, G loss: 0.6750\n",
      "[1204/1762] D loss: 1.4016, G loss: 0.6088\n",
      "[1284/1762] D loss: 1.1175, G loss: 1.0739\n",
      "[1364/1762] D loss: 1.3934, G loss: 0.6165\n",
      "[1444/1762] D loss: 1.4056, G loss: 0.8009\n",
      "[1524/1762] D loss: 1.4047, G loss: 0.7444\n",
      "[1604/1762] D loss: 1.3914, G loss: 0.6738\n",
      "[1684/1762] D loss: 1.3893, G loss: 0.7299\n",
      "[1762/1762] D loss: 1.3972, G loss: 0.6584\n",
      "train error: \n",
      " D loss: 1.323980, G loss: 0.672730, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 90.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.304727, G loss: 0.684426, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3952, G loss: 0.5702\n",
      "[84/1762] D loss: 1.3879, G loss: 0.7488\n",
      "[164/1762] D loss: 1.3413, G loss: 0.7645\n",
      "[244/1762] D loss: 1.3686, G loss: 0.7878\n",
      "[324/1762] D loss: 1.3922, G loss: 0.7714\n",
      "[404/1762] D loss: 1.3893, G loss: 0.6640\n",
      "[484/1762] D loss: 1.3988, G loss: 0.8055\n",
      "[564/1762] D loss: 1.3870, G loss: 0.6574\n",
      "[644/1762] D loss: 1.3975, G loss: 0.7642\n",
      "[724/1762] D loss: 1.3805, G loss: 0.6873\n",
      "[804/1762] D loss: 1.3680, G loss: 0.8106\n",
      "[884/1762] D loss: 1.3874, G loss: 0.7212\n",
      "[964/1762] D loss: 1.1312, G loss: 0.9000\n",
      "[1044/1762] D loss: 1.3905, G loss: 0.6485\n",
      "[1124/1762] D loss: 1.3916, G loss: 0.7082\n",
      "[1204/1762] D loss: 1.3888, G loss: 0.6966\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.7430\n",
      "[1364/1762] D loss: 1.3705, G loss: 0.6652\n",
      "[1444/1762] D loss: 1.1019, G loss: 0.8746\n",
      "[1524/1762] D loss: 1.1133, G loss: 0.9221\n",
      "[1604/1762] D loss: 1.1290, G loss: 0.7851\n",
      "[1684/1762] D loss: 1.3952, G loss: 0.5606\n",
      "[1762/1762] D loss: 1.3958, G loss: 0.6982\n",
      "train error: \n",
      " D loss: 1.305443, G loss: 0.817304, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 84.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.281512, G loss: 0.845213, D accuracy: 55.0%, cell accuracy: 99.7%, board accuracy: 81.6% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1004, G loss: 0.9516\n",
      "[84/1762] D loss: 1.3404, G loss: 0.7384\n",
      "[164/1762] D loss: 1.3852, G loss: 0.7010\n",
      "[244/1762] D loss: 1.0012, G loss: 1.2432\n",
      "[324/1762] D loss: 1.4123, G loss: 0.6411\n",
      "[404/1762] D loss: 1.2477, G loss: 1.1138\n",
      "[484/1762] D loss: 1.3880, G loss: 0.6745\n",
      "[564/1762] D loss: 1.4135, G loss: 0.5442\n",
      "[644/1762] D loss: 1.3932, G loss: 0.6856\n",
      "[724/1762] D loss: 1.0749, G loss: 0.9711\n",
      "[804/1762] D loss: 1.0148, G loss: 1.0839\n",
      "[884/1762] D loss: 1.4962, G loss: 0.7281\n",
      "[964/1762] D loss: 1.0996, G loss: 0.8618\n",
      "[1044/1762] D loss: 1.2616, G loss: 0.5651\n",
      "[1124/1762] D loss: 1.3488, G loss: 0.7814\n",
      "[1204/1762] D loss: 1.4608, G loss: 0.9273\n",
      "[1284/1762] D loss: 1.4152, G loss: 0.9009\n",
      "[1364/1762] D loss: 1.3928, G loss: 0.6456\n",
      "[1444/1762] D loss: 1.4061, G loss: 0.6002\n",
      "[1524/1762] D loss: 1.3953, G loss: 0.6526\n",
      "[1604/1762] D loss: 1.4154, G loss: 0.8269\n",
      "[1684/1762] D loss: 1.3887, G loss: 0.7123\n",
      "[1762/1762] D loss: 1.3076, G loss: 0.7903\n",
      "train error: \n",
      " D loss: 1.310033, G loss: 0.803828, D accuracy: 53.7%, cell accuracy: 99.7%, board accuracy: 80.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.289384, G loss: 0.819562, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 76.6% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3872, G loss: 0.7239\n",
      "[84/1762] D loss: 1.1045, G loss: 0.9763\n",
      "[164/1762] D loss: 1.3670, G loss: 0.6159\n",
      "[244/1762] D loss: 1.3906, G loss: 0.7066\n",
      "[324/1762] D loss: 1.3945, G loss: 0.6297\n",
      "[404/1762] D loss: 1.3627, G loss: 0.7333\n",
      "[484/1762] D loss: 1.3956, G loss: 0.6032\n",
      "[564/1762] D loss: 1.3876, G loss: 0.6909\n",
      "[644/1762] D loss: 1.3947, G loss: 0.7246\n",
      "[724/1762] D loss: 1.1072, G loss: 1.0329\n",
      "[804/1762] D loss: 1.0995, G loss: 0.9157\n",
      "[884/1762] D loss: 1.3880, G loss: 0.7338\n",
      "[964/1762] D loss: 1.3944, G loss: 0.7092\n",
      "[1044/1762] D loss: 1.4003, G loss: 0.6948\n",
      "[1124/1762] D loss: 1.4729, G loss: 0.5903\n",
      "[1204/1762] D loss: 1.3921, G loss: 0.6239\n",
      "[1284/1762] D loss: 0.8441, G loss: 1.3235\n",
      "[1364/1762] D loss: 1.1925, G loss: 0.8392\n",
      "[1444/1762] D loss: 1.3727, G loss: 0.7804\n",
      "[1524/1762] D loss: 0.5996, G loss: 1.8770\n",
      "[1604/1762] D loss: 1.2402, G loss: 1.1294\n",
      "[1684/1762] D loss: 1.4958, G loss: 0.9757\n",
      "[1762/1762] D loss: 1.3205, G loss: 0.6587\n",
      "train error: \n",
      " D loss: 1.310639, G loss: 0.722632, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 85.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.289196, G loss: 0.747204, D accuracy: 55.7%, cell accuracy: 99.7%, board accuracy: 80.5% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3996, G loss: 0.7056\n",
      "[84/1762] D loss: 1.3776, G loss: 0.6706\n",
      "[164/1762] D loss: 1.4103, G loss: 0.8399\n",
      "[244/1762] D loss: 1.0741, G loss: 1.4156\n",
      "[324/1762] D loss: 1.3552, G loss: 0.6342\n",
      "[404/1762] D loss: 1.3901, G loss: 0.6915\n",
      "[484/1762] D loss: 1.1068, G loss: 0.9999\n",
      "[564/1762] D loss: 1.3889, G loss: 0.7221\n",
      "[644/1762] D loss: 1.3871, G loss: 0.6710\n",
      "[724/1762] D loss: 1.1018, G loss: 0.9421\n",
      "[804/1762] D loss: 1.4158, G loss: 0.7651\n",
      "[884/1762] D loss: 1.4026, G loss: 0.7930\n",
      "[964/1762] D loss: 1.3893, G loss: 0.6907\n",
      "[1044/1762] D loss: 1.0778, G loss: 1.0389\n",
      "[1124/1762] D loss: 1.0874, G loss: 0.9973\n",
      "[1204/1762] D loss: 1.4037, G loss: 0.6651\n",
      "[1284/1762] D loss: 1.4093, G loss: 0.7541\n",
      "[1364/1762] D loss: 1.3877, G loss: 0.7057\n",
      "[1444/1762] D loss: 1.0649, G loss: 1.1900\n",
      "[1524/1762] D loss: 1.3878, G loss: 0.6513\n",
      "[1604/1762] D loss: 1.3978, G loss: 0.8070\n",
      "[1684/1762] D loss: 1.3710, G loss: 0.7375\n",
      "[1762/1762] D loss: 1.3893, G loss: 0.6795\n",
      "train error: \n",
      " D loss: 1.295406, G loss: 0.814396, D accuracy: 55.7%, cell accuracy: 99.7%, board accuracy: 81.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.279636, G loss: 0.848571, D accuracy: 56.0%, cell accuracy: 99.7%, board accuracy: 80.0% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0827, G loss: 1.0411\n",
      "[84/1762] D loss: 1.3130, G loss: 0.8660\n",
      "[164/1762] D loss: 1.3943, G loss: 0.7301\n",
      "[244/1762] D loss: 1.0975, G loss: 0.9462\n",
      "[324/1762] D loss: 1.3617, G loss: 0.6805\n",
      "[404/1762] D loss: 1.3951, G loss: 0.7698\n",
      "[484/1762] D loss: 0.9787, G loss: 1.4043\n",
      "[564/1762] D loss: 1.3938, G loss: 0.7018\n",
      "[644/1762] D loss: 1.0890, G loss: 0.9839\n",
      "[724/1762] D loss: 1.3960, G loss: 0.7581\n",
      "[804/1762] D loss: 1.3913, G loss: 0.7125\n",
      "[884/1762] D loss: 1.3566, G loss: 0.8001\n",
      "[964/1762] D loss: 1.0566, G loss: 1.0454\n",
      "[1044/1762] D loss: 1.2904, G loss: 0.8686\n",
      "[1124/1762] D loss: 1.3939, G loss: 0.7218\n",
      "[1204/1762] D loss: 1.4060, G loss: 0.6252\n",
      "[1284/1762] D loss: 1.3745, G loss: 0.5800\n",
      "[1364/1762] D loss: 1.3116, G loss: 1.0529\n",
      "[1444/1762] D loss: 1.2930, G loss: 0.7354\n",
      "[1524/1762] D loss: 1.2437, G loss: 0.7458\n",
      "[1604/1762] D loss: 1.4035, G loss: 0.7983\n",
      "[1684/1762] D loss: 1.3657, G loss: 0.7786\n",
      "[1762/1762] D loss: 1.4155, G loss: 0.6170\n",
      "train error: \n",
      " D loss: 1.304367, G loss: 0.799458, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 86.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.278064, G loss: 0.829040, D accuracy: 55.7%, cell accuracy: 99.8%, board accuracy: 82.3% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3939, G loss: 0.7950\n",
      "[84/1762] D loss: 1.3876, G loss: 0.6950\n",
      "[164/1762] D loss: 1.1028, G loss: 0.9090\n",
      "[244/1762] D loss: 1.3894, G loss: 0.6840\n",
      "[324/1762] D loss: 1.3953, G loss: 0.6456\n",
      "[404/1762] D loss: 1.3878, G loss: 0.7097\n",
      "[484/1762] D loss: 1.3873, G loss: 0.7084\n",
      "[564/1762] D loss: 1.0763, G loss: 1.0830\n",
      "[644/1762] D loss: 1.3900, G loss: 0.6786\n",
      "[724/1762] D loss: 1.0545, G loss: 1.1478\n",
      "[804/1762] D loss: 1.3880, G loss: 0.6893\n",
      "[884/1762] D loss: 1.3904, G loss: 0.7145\n",
      "[964/1762] D loss: 1.3106, G loss: 0.7859\n",
      "[1044/1762] D loss: 1.3732, G loss: 0.7143\n",
      "[1124/1762] D loss: 1.3915, G loss: 0.6465\n",
      "[1204/1762] D loss: 1.0846, G loss: 1.0589\n",
      "[1284/1762] D loss: 0.7553, G loss: 1.4670\n",
      "[1364/1762] D loss: 1.3888, G loss: 0.6798\n",
      "[1444/1762] D loss: 1.0589, G loss: 1.2501\n",
      "[1524/1762] D loss: 0.7643, G loss: 1.4279\n",
      "[1604/1762] D loss: 1.0824, G loss: 1.0561\n",
      "[1684/1762] D loss: 1.3988, G loss: 0.5686\n",
      "[1762/1762] D loss: 1.3875, G loss: 0.7158\n",
      "train error: \n",
      " D loss: 1.294070, G loss: 0.854085, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 90.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.269369, G loss: 0.882832, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3876, G loss: 0.7140\n",
      "[84/1762] D loss: 1.3867, G loss: 0.6499\n",
      "[164/1762] D loss: 1.3934, G loss: 0.6967\n",
      "[244/1762] D loss: 1.3894, G loss: 0.6451\n",
      "[324/1762] D loss: 1.3947, G loss: 0.7178\n",
      "[404/1762] D loss: 1.0158, G loss: 0.9597\n",
      "[484/1762] D loss: 1.6018, G loss: 1.1008\n",
      "[564/1762] D loss: 1.4563, G loss: 0.7682\n",
      "[644/1762] D loss: 1.3932, G loss: 0.9149\n",
      "[724/1762] D loss: 1.1791, G loss: 0.8698\n",
      "[804/1762] D loss: 1.3911, G loss: 0.7343\n",
      "[884/1762] D loss: 1.3873, G loss: 0.7229\n",
      "[964/1762] D loss: 1.1262, G loss: 0.8375\n",
      "[1044/1762] D loss: 1.3536, G loss: 0.7491\n",
      "[1124/1762] D loss: 1.3913, G loss: 0.7414\n",
      "[1204/1762] D loss: 1.1087, G loss: 0.8769\n",
      "[1284/1762] D loss: 1.3926, G loss: 0.7504\n",
      "[1364/1762] D loss: 1.1685, G loss: 0.9400\n",
      "[1444/1762] D loss: 1.1240, G loss: 0.9395\n",
      "[1524/1762] D loss: 1.3916, G loss: 0.7640\n",
      "[1604/1762] D loss: 1.3860, G loss: 0.8473\n",
      "[1684/1762] D loss: 1.0905, G loss: 0.9929\n",
      "[1762/1762] D loss: 1.3943, G loss: 0.6418\n",
      "train error: \n",
      " D loss: 1.303037, G loss: 0.787719, D accuracy: 54.2%, cell accuracy: 99.9%, board accuracy: 90.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.280799, G loss: 0.802904, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3901, G loss: 0.7219\n",
      "[84/1762] D loss: 1.3038, G loss: 0.7595\n",
      "[164/1762] D loss: 1.0834, G loss: 1.0016\n",
      "[244/1762] D loss: 1.4049, G loss: 0.7520\n",
      "[324/1762] D loss: 1.3955, G loss: 0.7859\n",
      "[404/1762] D loss: 1.3898, G loss: 0.6547\n",
      "[484/1762] D loss: 1.3915, G loss: 0.7592\n",
      "[564/1762] D loss: 1.3881, G loss: 0.7135\n",
      "[644/1762] D loss: 1.3899, G loss: 0.6837\n",
      "[724/1762] D loss: 1.3745, G loss: 0.6968\n",
      "[804/1762] D loss: 1.0617, G loss: 0.9994\n",
      "[884/1762] D loss: 1.3958, G loss: 0.5953\n",
      "[964/1762] D loss: 1.0809, G loss: 1.0262\n",
      "[1044/1762] D loss: 1.3916, G loss: 0.7180\n",
      "[1124/1762] D loss: 1.3944, G loss: 0.7367\n",
      "[1204/1762] D loss: 1.3920, G loss: 0.7228\n",
      "[1284/1762] D loss: 1.3884, G loss: 0.6844\n",
      "[1364/1762] D loss: 1.0595, G loss: 1.1507\n",
      "[1444/1762] D loss: 1.0794, G loss: 1.0043\n",
      "[1524/1762] D loss: 1.3957, G loss: 0.6468\n",
      "[1604/1762] D loss: 1.4004, G loss: 0.7784\n",
      "[1684/1762] D loss: 1.3984, G loss: 0.6663\n",
      "[1762/1762] D loss: 1.3834, G loss: 0.6956\n",
      "train error: \n",
      " D loss: 1.285360, G loss: 0.807443, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.261083, G loss: 0.842954, D accuracy: 55.6%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3937, G loss: 0.6684\n",
      "[84/1762] D loss: 1.3899, G loss: 0.7179\n",
      "[164/1762] D loss: 1.0628, G loss: 1.1884\n",
      "[244/1762] D loss: 1.3871, G loss: 0.7009\n",
      "[324/1762] D loss: 1.3879, G loss: 0.7003\n",
      "[404/1762] D loss: 1.3909, G loss: 0.6018\n",
      "[484/1762] D loss: 1.3910, G loss: 0.7236\n",
      "[564/1762] D loss: 1.0479, G loss: 1.3164\n",
      "[644/1762] D loss: 1.0719, G loss: 1.0858\n",
      "[724/1762] D loss: 1.3869, G loss: 0.6539\n",
      "[804/1762] D loss: 1.1396, G loss: 0.6923\n",
      "[884/1762] D loss: 1.3875, G loss: 0.7548\n",
      "[964/1762] D loss: 1.3865, G loss: 0.6826\n",
      "[1044/1762] D loss: 1.3928, G loss: 0.6892\n",
      "[1124/1762] D loss: 1.2449, G loss: 0.7908\n",
      "[1204/1762] D loss: 1.3970, G loss: 0.7775\n",
      "[1284/1762] D loss: 1.3964, G loss: 0.5871\n",
      "[1364/1762] D loss: 1.4034, G loss: 0.8203\n",
      "[1444/1762] D loss: 1.3945, G loss: 0.6134\n",
      "[1524/1762] D loss: 1.0658, G loss: 1.1238\n",
      "[1604/1762] D loss: 1.3606, G loss: 0.7152\n",
      "[1684/1762] D loss: 1.0769, G loss: 1.0324\n",
      "[1762/1762] D loss: 1.3958, G loss: 0.7533\n",
      "train error: \n",
      " D loss: 1.295777, G loss: 0.859293, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 90.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.268017, G loss: 0.898404, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3911, G loss: 0.7240\n",
      "[84/1762] D loss: 1.3881, G loss: 0.6576\n",
      "[164/1762] D loss: 1.3000, G loss: 0.8665\n",
      "[244/1762] D loss: 1.3031, G loss: 0.5375\n",
      "[324/1762] D loss: 1.3669, G loss: 0.8129\n",
      "[404/1762] D loss: 1.1194, G loss: 1.1042\n",
      "[484/1762] D loss: 1.1131, G loss: 0.7707\n",
      "[564/1762] D loss: 1.3992, G loss: 0.7620\n",
      "[644/1762] D loss: 1.1026, G loss: 0.9767\n",
      "[724/1762] D loss: 1.3870, G loss: 0.6811\n",
      "[804/1762] D loss: 1.3960, G loss: 0.7867\n",
      "[884/1762] D loss: 1.0680, G loss: 1.1140\n",
      "[964/1762] D loss: 1.0534, G loss: 1.1062\n",
      "[1044/1762] D loss: 1.0753, G loss: 1.0235\n",
      "[1124/1762] D loss: 1.3908, G loss: 0.7087\n",
      "[1204/1762] D loss: 1.3786, G loss: 0.7076\n",
      "[1284/1762] D loss: 1.3904, G loss: 0.7068\n",
      "[1364/1762] D loss: 1.3877, G loss: 0.7166\n",
      "[1444/1762] D loss: 1.3944, G loss: 0.7681\n",
      "[1524/1762] D loss: 1.3973, G loss: 0.6438\n",
      "[1604/1762] D loss: 1.3965, G loss: 0.7590\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.6836\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6925\n",
      "train error: \n",
      " D loss: 1.292702, G loss: 0.814707, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 90.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.268697, G loss: 0.851083, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3866, G loss: 0.6814\n",
      "[84/1762] D loss: 1.3867, G loss: 0.6925\n",
      "[164/1762] D loss: 1.3878, G loss: 0.7179\n",
      "[244/1762] D loss: 1.3902, G loss: 0.6538\n",
      "[324/1762] D loss: 1.3882, G loss: 0.6655\n",
      "[404/1762] D loss: 0.9025, G loss: 1.5392\n",
      "[484/1762] D loss: 1.0795, G loss: 1.0163\n",
      "[564/1762] D loss: 1.4083, G loss: 0.8046\n",
      "[644/1762] D loss: 1.3987, G loss: 0.7557\n",
      "[724/1762] D loss: 1.3926, G loss: 0.6434\n",
      "[804/1762] D loss: 1.0647, G loss: 1.1697\n",
      "[884/1762] D loss: 1.3920, G loss: 0.7548\n",
      "[964/1762] D loss: 1.3948, G loss: 0.6489\n",
      "[1044/1762] D loss: 1.3909, G loss: 0.6591\n",
      "[1124/1762] D loss: 1.3782, G loss: 0.7237\n",
      "[1204/1762] D loss: 1.0692, G loss: 1.0243\n",
      "[1284/1762] D loss: 1.2406, G loss: 0.8756\n",
      "[1364/1762] D loss: 1.0571, G loss: 1.2022\n",
      "[1444/1762] D loss: 0.6010, G loss: 1.7756\n",
      "[1524/1762] D loss: 1.0497, G loss: 1.3505\n",
      "[1604/1762] D loss: 1.3900, G loss: 0.6506\n",
      "[1684/1762] D loss: 1.2801, G loss: 0.8275\n",
      "[1762/1762] D loss: 0.7077, G loss: 2.2202\n",
      "train error: \n",
      " D loss: 1.289849, G loss: 0.896511, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 89.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.261906, G loss: 0.941020, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0406, G loss: 1.4402\n",
      "[84/1762] D loss: 1.3957, G loss: 0.6529\n",
      "[164/1762] D loss: 1.0637, G loss: 1.1510\n",
      "[244/1762] D loss: 1.3978, G loss: 0.7868\n",
      "[324/1762] D loss: 1.2540, G loss: 0.8769\n",
      "[404/1762] D loss: 1.5291, G loss: 0.4566\n",
      "[484/1762] D loss: 1.4509, G loss: 0.4820\n",
      "[564/1762] D loss: 1.3852, G loss: 0.6957\n",
      "[644/1762] D loss: 1.3549, G loss: 0.7758\n",
      "[724/1762] D loss: 1.3911, G loss: 0.6820\n",
      "[804/1762] D loss: 1.2268, G loss: 1.1263\n",
      "[884/1762] D loss: 1.2929, G loss: 0.7301\n",
      "[964/1762] D loss: 1.3967, G loss: 0.6133\n",
      "[1044/1762] D loss: 1.3910, G loss: 0.6793\n",
      "[1124/1762] D loss: 1.0620, G loss: 1.1270\n",
      "[1204/1762] D loss: 1.3898, G loss: 0.7125\n",
      "[1284/1762] D loss: 1.0516, G loss: 1.3876\n",
      "[1364/1762] D loss: 1.2893, G loss: 0.8213\n",
      "[1444/1762] D loss: 1.4016, G loss: 0.6009\n",
      "[1524/1762] D loss: 1.3888, G loss: 0.7230\n",
      "[1604/1762] D loss: 1.3877, G loss: 0.7059\n",
      "[1684/1762] D loss: 1.3889, G loss: 0.6957\n",
      "[1762/1762] D loss: 1.3853, G loss: 0.6883\n",
      "train error: \n",
      " D loss: 1.288610, G loss: 0.898313, D accuracy: 54.2%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.258846, G loss: 0.954177, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3874, G loss: 0.7203\n",
      "[84/1762] D loss: 1.0645, G loss: 1.2075\n",
      "[164/1762] D loss: 1.3869, G loss: 0.7132\n",
      "[244/1762] D loss: 1.3900, G loss: 0.6569\n",
      "[324/1762] D loss: 1.4073, G loss: 0.8486\n",
      "[404/1762] D loss: 1.3915, G loss: 0.6859\n",
      "[484/1762] D loss: 1.3643, G loss: 0.6625\n",
      "[564/1762] D loss: 1.0544, G loss: 1.3990\n",
      "[644/1762] D loss: 1.3888, G loss: 0.6774\n",
      "[724/1762] D loss: 1.3897, G loss: 0.6781\n",
      "[804/1762] D loss: 1.3875, G loss: 0.6984\n",
      "[884/1762] D loss: 1.3885, G loss: 0.6620\n",
      "[964/1762] D loss: 1.3637, G loss: 0.7643\n",
      "[1044/1762] D loss: 1.1663, G loss: 1.3838\n",
      "[1124/1762] D loss: 1.3561, G loss: 0.6224\n",
      "[1204/1762] D loss: 1.3952, G loss: 0.6989\n",
      "[1284/1762] D loss: 1.0789, G loss: 1.0373\n",
      "[1364/1762] D loss: 1.0721, G loss: 1.0463\n",
      "[1444/1762] D loss: 1.3980, G loss: 0.6120\n",
      "[1524/1762] D loss: 0.7447, G loss: 1.5900\n",
      "[1604/1762] D loss: 1.3714, G loss: 0.6619\n",
      "[1684/1762] D loss: 1.3923, G loss: 0.6907\n",
      "[1762/1762] D loss: 1.3871, G loss: 0.6894\n",
      "train error: \n",
      " D loss: 1.285982, G loss: 0.858747, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 90.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.256994, G loss: 0.910871, D accuracy: 55.7%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3973, G loss: 0.6538\n",
      "[84/1762] D loss: 1.2354, G loss: 0.8544\n",
      "[164/1762] D loss: 1.3871, G loss: 0.6964\n",
      "[244/1762] D loss: 1.3929, G loss: 0.6546\n",
      "[324/1762] D loss: 1.0684, G loss: 1.1120\n",
      "[404/1762] D loss: 0.7156, G loss: 2.0559\n",
      "[484/1762] D loss: 1.3945, G loss: 0.7773\n",
      "[564/1762] D loss: 1.3877, G loss: 0.6983\n",
      "[644/1762] D loss: 1.3913, G loss: 0.7218\n",
      "[724/1762] D loss: 1.3917, G loss: 0.6380\n",
      "[804/1762] D loss: 1.3899, G loss: 0.7416\n",
      "[884/1762] D loss: 0.7145, G loss: 1.9341\n",
      "[964/1762] D loss: 1.3898, G loss: 0.6768\n",
      "[1044/1762] D loss: 1.3879, G loss: 0.6577\n",
      "[1124/1762] D loss: 1.3867, G loss: 0.6904\n",
      "[1204/1762] D loss: 1.3868, G loss: 0.6973\n",
      "[1284/1762] D loss: 1.3871, G loss: 0.6815\n",
      "[1364/1762] D loss: 1.0173, G loss: 1.3090\n",
      "[1444/1762] D loss: 1.3878, G loss: 0.6967\n",
      "[1524/1762] D loss: 1.3916, G loss: 0.6884\n",
      "[1604/1762] D loss: 1.3930, G loss: 0.6134\n",
      "[1684/1762] D loss: 1.3869, G loss: 0.6862\n",
      "[1762/1762] D loss: 1.0163, G loss: 1.5654\n",
      "train error: \n",
      " D loss: 1.287932, G loss: 0.889782, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.260276, G loss: 0.948325, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3887, G loss: 0.6404\n",
      "[84/1762] D loss: 1.3862, G loss: 0.6633\n",
      "[164/1762] D loss: 1.3942, G loss: 0.7884\n",
      "[244/1762] D loss: 1.3304, G loss: 0.7513\n",
      "[324/1762] D loss: 1.3984, G loss: 0.7682\n",
      "[404/1762] D loss: 1.3872, G loss: 0.6826\n",
      "[484/1762] D loss: 1.3865, G loss: 0.6988\n",
      "[564/1762] D loss: 1.3906, G loss: 0.7335\n",
      "[644/1762] D loss: 1.0469, G loss: 1.7414\n",
      "[724/1762] D loss: 1.3868, G loss: 0.6989\n",
      "[804/1762] D loss: 1.3948, G loss: 0.6576\n",
      "[884/1762] D loss: 1.6892, G loss: 0.7284\n",
      "[964/1762] D loss: 1.4755, G loss: 1.1335\n",
      "[1044/1762] D loss: 0.9020, G loss: 0.9992\n",
      "[1124/1762] D loss: 1.1634, G loss: 0.7396\n",
      "[1204/1762] D loss: 1.3915, G loss: 0.7276\n",
      "[1284/1762] D loss: 1.4214, G loss: 0.7908\n",
      "[1364/1762] D loss: 1.1126, G loss: 0.9569\n",
      "[1444/1762] D loss: 1.3869, G loss: 0.7043\n",
      "[1524/1762] D loss: 1.1118, G loss: 0.8640\n",
      "[1604/1762] D loss: 1.3877, G loss: 0.6866\n",
      "[1684/1762] D loss: 1.3872, G loss: 0.6568\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.6966\n",
      "train error: \n",
      " D loss: 1.298093, G loss: 0.837349, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 90.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.272703, G loss: 0.870857, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0797, G loss: 1.0233\n",
      "[84/1762] D loss: 1.0730, G loss: 1.0256\n",
      "[164/1762] D loss: 1.0667, G loss: 1.0227\n",
      "[244/1762] D loss: 1.3880, G loss: 0.7205\n",
      "[324/1762] D loss: 1.3885, G loss: 0.7315\n",
      "[404/1762] D loss: 1.3854, G loss: 0.7226\n",
      "[484/1762] D loss: 1.0593, G loss: 1.1993\n",
      "[564/1762] D loss: 1.3737, G loss: 0.6738\n",
      "[644/1762] D loss: 1.3886, G loss: 0.6643\n",
      "[724/1762] D loss: 1.3776, G loss: 0.7447\n",
      "[804/1762] D loss: 1.3987, G loss: 0.6512\n",
      "[884/1762] D loss: 1.0598, G loss: 1.1976\n",
      "[964/1762] D loss: 1.3719, G loss: 0.6988\n",
      "[1044/1762] D loss: 1.2230, G loss: 1.3105\n",
      "[1124/1762] D loss: 0.7207, G loss: 1.8766\n",
      "[1204/1762] D loss: 1.3940, G loss: 0.5683\n",
      "[1284/1762] D loss: 1.3658, G loss: 0.7952\n",
      "[1364/1762] D loss: 1.3946, G loss: 0.7649\n",
      "[1444/1762] D loss: 1.3899, G loss: 0.6547\n",
      "[1524/1762] D loss: 1.3952, G loss: 0.6334\n",
      "[1604/1762] D loss: 0.7125, G loss: 2.0305\n",
      "[1684/1762] D loss: 1.0592, G loss: 1.3487\n",
      "[1762/1762] D loss: 1.4236, G loss: 0.7716\n",
      "train error: \n",
      " D loss: 1.226382, G loss: 1.054704, D accuracy: 59.2%, cell accuracy: 99.4%, board accuracy: 66.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.202337, G loss: 1.154581, D accuracy: 62.0%, cell accuracy: 99.3%, board accuracy: 61.8% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0552, G loss: 1.3163\n",
      "[84/1762] D loss: 1.4091, G loss: 0.7684\n",
      "[164/1762] D loss: 1.3878, G loss: 0.6987\n",
      "[244/1762] D loss: 1.2853, G loss: 1.0701\n",
      "[324/1762] D loss: 1.4020, G loss: 0.7201\n",
      "[404/1762] D loss: 1.3923, G loss: 0.6556\n",
      "[484/1762] D loss: 1.3887, G loss: 0.6949\n",
      "[564/1762] D loss: 1.2258, G loss: 0.9810\n",
      "[644/1762] D loss: 1.2385, G loss: 1.0540\n",
      "[724/1762] D loss: 1.4222, G loss: 0.6709\n",
      "[804/1762] D loss: 1.3175, G loss: 0.7999\n",
      "[884/1762] D loss: 1.0643, G loss: 1.1053\n",
      "[964/1762] D loss: 1.0288, G loss: 1.2464\n",
      "[1044/1762] D loss: 1.3891, G loss: 0.7802\n",
      "[1124/1762] D loss: 1.3901, G loss: 0.6333\n",
      "[1204/1762] D loss: 0.7004, G loss: 2.7312\n",
      "[1284/1762] D loss: 1.2441, G loss: 0.8930\n",
      "[1364/1762] D loss: 0.8949, G loss: 1.7742\n",
      "[1444/1762] D loss: 1.0677, G loss: 1.0449\n",
      "[1524/1762] D loss: 1.3920, G loss: 0.6402\n",
      "[1604/1762] D loss: 1.0629, G loss: 1.1470\n",
      "[1684/1762] D loss: 1.0754, G loss: 1.0580\n",
      "[1762/1762] D loss: 1.3904, G loss: 0.7289\n",
      "train error: \n",
      " D loss: 1.288210, G loss: 0.925663, D accuracy: 54.1%, cell accuracy: 99.9%, board accuracy: 91.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.256616, G loss: 0.986079, D accuracy: 55.7%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0605, G loss: 1.1926\n",
      "[84/1762] D loss: 1.0467, G loss: 1.4956\n",
      "[164/1762] D loss: 1.0467, G loss: 1.5869\n",
      "[244/1762] D loss: 1.3873, G loss: 0.6982\n",
      "[324/1762] D loss: 1.3885, G loss: 0.6754\n",
      "[404/1762] D loss: 1.0491, G loss: 1.4823\n",
      "[484/1762] D loss: 1.3881, G loss: 0.6880\n",
      "[564/1762] D loss: 1.3901, G loss: 0.6794\n",
      "[644/1762] D loss: 1.4041, G loss: 0.6335\n",
      "[724/1762] D loss: 1.3875, G loss: 0.7197\n",
      "[804/1762] D loss: 1.0518, G loss: 1.2716\n",
      "[884/1762] D loss: 1.3896, G loss: 0.7257\n",
      "[964/1762] D loss: 1.3929, G loss: 0.7231\n",
      "[1044/1762] D loss: 1.3969, G loss: 0.6461\n",
      "[1124/1762] D loss: 1.3872, G loss: 0.6660\n",
      "[1204/1762] D loss: 0.7202, G loss: 1.8240\n",
      "[1284/1762] D loss: 1.3882, G loss: 0.6638\n",
      "[1364/1762] D loss: 1.3913, G loss: 0.6364\n",
      "[1444/1762] D loss: 1.3877, G loss: 0.6609\n",
      "[1524/1762] D loss: 1.0444, G loss: 1.6038\n",
      "[1604/1762] D loss: 1.0645, G loss: 1.0924\n",
      "[1684/1762] D loss: 1.0581, G loss: 1.1918\n",
      "[1762/1762] D loss: 1.4068, G loss: 0.5855\n",
      "train error: \n",
      " D loss: 1.257588, G loss: 0.940334, D accuracy: 56.6%, cell accuracy: 99.8%, board accuracy: 84.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.229492, G loss: 1.008869, D accuracy: 57.8%, cell accuracy: 99.7%, board accuracy: 80.7% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0524, G loss: 1.4100\n",
      "[84/1762] D loss: 1.3960, G loss: 0.7902\n",
      "[164/1762] D loss: 1.3869, G loss: 0.6936\n",
      "[244/1762] D loss: 1.3031, G loss: 0.7429\n",
      "[324/1762] D loss: 1.5434, G loss: 0.3922\n",
      "[404/1762] D loss: 1.3903, G loss: 0.6882\n",
      "[484/1762] D loss: 1.3905, G loss: 0.7200\n",
      "[564/1762] D loss: 1.3891, G loss: 0.6977\n",
      "[644/1762] D loss: 1.0598, G loss: 1.1555\n",
      "[724/1762] D loss: 1.0615, G loss: 1.1421\n",
      "[804/1762] D loss: 1.3876, G loss: 0.6981\n",
      "[884/1762] D loss: 1.3743, G loss: 0.7001\n",
      "[964/1762] D loss: 1.2923, G loss: 0.7529\n",
      "[1044/1762] D loss: 1.3953, G loss: 0.7726\n",
      "[1124/1762] D loss: 1.3858, G loss: 0.7086\n",
      "[1204/1762] D loss: 0.9891, G loss: 1.2952\n",
      "[1284/1762] D loss: 1.0741, G loss: 1.0245\n",
      "[1364/1762] D loss: 1.0569, G loss: 1.1640\n",
      "[1444/1762] D loss: 1.3816, G loss: 0.7389\n",
      "[1524/1762] D loss: 1.3875, G loss: 0.6741\n",
      "[1604/1762] D loss: 1.2083, G loss: 1.1967\n",
      "[1684/1762] D loss: 1.3907, G loss: 0.6546\n",
      "[1762/1762] D loss: 1.3884, G loss: 0.6757\n",
      "train error: \n",
      " D loss: 1.283695, G loss: 0.910858, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 91.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.259218, G loss: 0.964943, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3869, G loss: 0.7061\n",
      "[84/1762] D loss: 1.0528, G loss: 1.2650\n",
      "[164/1762] D loss: 1.0493, G loss: 1.3538\n",
      "[244/1762] D loss: 1.0518, G loss: 1.3089\n",
      "[324/1762] D loss: 1.0488, G loss: 1.3749\n",
      "[404/1762] D loss: 1.3874, G loss: 0.7140\n",
      "[484/1762] D loss: 1.3865, G loss: 0.6812\n",
      "[564/1762] D loss: 1.3882, G loss: 0.7121\n",
      "[644/1762] D loss: 1.3877, G loss: 0.7271\n",
      "[724/1762] D loss: 1.3907, G loss: 0.7264\n",
      "[804/1762] D loss: 1.3872, G loss: 0.6959\n",
      "[884/1762] D loss: 1.3874, G loss: 0.6776\n",
      "[964/1762] D loss: 1.3874, G loss: 0.7102\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.7070\n",
      "[1124/1762] D loss: 1.3875, G loss: 0.7128\n",
      "[1204/1762] D loss: 1.3885, G loss: 0.6931\n",
      "[1284/1762] D loss: 1.3888, G loss: 0.6579\n",
      "[1364/1762] D loss: 1.3895, G loss: 0.6645\n",
      "[1444/1762] D loss: 0.7043, G loss: 2.4456\n",
      "[1524/1762] D loss: 1.3872, G loss: 0.6920\n",
      "[1604/1762] D loss: 1.0469, G loss: 1.4601\n",
      "[1684/1762] D loss: 1.3899, G loss: 0.6651\n",
      "[1762/1762] D loss: 1.3876, G loss: 0.7411\n",
      "train error: \n",
      " D loss: 1.287312, G loss: 0.964110, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.258908, G loss: 1.035350, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0469, G loss: 1.5177\n",
      "[84/1762] D loss: 1.3884, G loss: 0.6950\n",
      "[164/1762] D loss: 1.3873, G loss: 0.6842\n",
      "[244/1762] D loss: 1.3874, G loss: 0.6709\n",
      "[324/1762] D loss: 1.3878, G loss: 0.7037\n",
      "[404/1762] D loss: 1.3868, G loss: 0.6719\n",
      "[484/1762] D loss: 1.3870, G loss: 0.6824\n",
      "[564/1762] D loss: 1.3873, G loss: 0.6620\n",
      "[644/1762] D loss: 1.3896, G loss: 0.7310\n",
      "[724/1762] D loss: 1.0465, G loss: 1.5179\n",
      "[804/1762] D loss: 1.3892, G loss: 0.7420\n",
      "[884/1762] D loss: 1.0577, G loss: 1.3635\n",
      "[964/1762] D loss: 1.3875, G loss: 0.6973\n",
      "[1044/1762] D loss: 1.3897, G loss: 0.6582\n",
      "[1124/1762] D loss: 1.3883, G loss: 0.7387\n",
      "[1204/1762] D loss: 1.3868, G loss: 0.6705\n",
      "[1284/1762] D loss: 1.0464, G loss: 1.4553\n",
      "[1364/1762] D loss: 1.0452, G loss: 1.4966\n",
      "[1444/1762] D loss: 1.3870, G loss: 0.6934\n",
      "[1524/1762] D loss: 1.0448, G loss: 1.5300\n",
      "[1604/1762] D loss: 1.3883, G loss: 0.7258\n",
      "[1684/1762] D loss: 1.0448, G loss: 1.5091\n",
      "[1762/1762] D loss: 0.7005, G loss: 2.4764\n",
      "train error: \n",
      " D loss: 1.286365, G loss: 0.986936, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.258349, G loss: 1.069828, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0450, G loss: 1.5118\n",
      "[84/1762] D loss: 1.3869, G loss: 0.6940\n",
      "[164/1762] D loss: 1.3865, G loss: 0.6934\n",
      "[244/1762] D loss: 1.3867, G loss: 0.6808\n",
      "[324/1762] D loss: 1.3879, G loss: 0.6638\n",
      "[404/1762] D loss: 1.3889, G loss: 0.7150\n",
      "[484/1762] D loss: 1.3867, G loss: 0.7063\n",
      "[564/1762] D loss: 0.6978, G loss: 2.7001\n",
      "[644/1762] D loss: 1.3865, G loss: 0.6817\n",
      "[724/1762] D loss: 1.0436, G loss: 1.5724\n",
      "[804/1762] D loss: 1.0455, G loss: 1.5419\n",
      "[884/1762] D loss: 1.3898, G loss: 0.7420\n",
      "[964/1762] D loss: 1.0578, G loss: 1.5178\n",
      "[1044/1762] D loss: 1.3865, G loss: 0.7043\n",
      "[1124/1762] D loss: 1.3899, G loss: 0.6309\n",
      "[1204/1762] D loss: 1.0483, G loss: 1.5492\n",
      "[1284/1762] D loss: 1.0468, G loss: 1.5945\n",
      "[1364/1762] D loss: 1.0456, G loss: 1.6176\n",
      "[1444/1762] D loss: 0.6998, G loss: 2.4678\n",
      "[1524/1762] D loss: 1.1403, G loss: 1.4770\n",
      "[1604/1762] D loss: 1.2793, G loss: 0.9227\n",
      "[1684/1762] D loss: 1.3898, G loss: 0.7217\n",
      "[1762/1762] D loss: 1.3860, G loss: 0.6906\n",
      "train error: \n",
      " D loss: 1.279800, G loss: 0.946773, D accuracy: 55.1%, cell accuracy: 99.9%, board accuracy: 90.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.250520, G loss: 1.015125, D accuracy: 55.9%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3889, G loss: 0.6761\n",
      "[84/1762] D loss: 1.3837, G loss: 0.7049\n",
      "[164/1762] D loss: 1.1484, G loss: 1.3744\n",
      "[244/1762] D loss: 1.3930, G loss: 0.7697\n",
      "[324/1762] D loss: 1.3931, G loss: 0.7174\n",
      "[404/1762] D loss: 1.3875, G loss: 0.7220\n",
      "[484/1762] D loss: 1.3889, G loss: 0.7211\n",
      "[564/1762] D loss: 1.0536, G loss: 1.5932\n",
      "[644/1762] D loss: 1.3896, G loss: 0.7001\n",
      "[724/1762] D loss: 1.3878, G loss: 0.7176\n",
      "[804/1762] D loss: 1.0481, G loss: 1.5215\n",
      "[884/1762] D loss: 1.3866, G loss: 0.6759\n",
      "[964/1762] D loss: 1.3866, G loss: 0.6983\n",
      "[1044/1762] D loss: 1.0438, G loss: 1.5595\n",
      "[1124/1762] D loss: 1.3894, G loss: 0.7015\n",
      "[1204/1762] D loss: 1.3937, G loss: 0.7049\n",
      "[1284/1762] D loss: 1.3887, G loss: 0.7189\n",
      "[1364/1762] D loss: 1.3867, G loss: 0.6791\n",
      "[1444/1762] D loss: 1.3872, G loss: 0.7334\n",
      "[1524/1762] D loss: 1.3871, G loss: 0.7081\n",
      "[1604/1762] D loss: 1.3885, G loss: 0.7121\n",
      "[1684/1762] D loss: 1.3870, G loss: 0.6979\n",
      "[1762/1762] D loss: 0.6962, G loss: 2.9165\n",
      "train error: \n",
      " D loss: 1.285275, G loss: 0.970258, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.256501, G loss: 1.062974, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0419, G loss: 1.7196\n",
      "[84/1762] D loss: 1.3872, G loss: 0.7179\n",
      "[164/1762] D loss: 1.0418, G loss: 1.7378\n",
      "[244/1762] D loss: 1.3912, G loss: 0.7233\n",
      "[324/1762] D loss: 1.3865, G loss: 0.6750\n",
      "[404/1762] D loss: 1.0407, G loss: 1.8530\n",
      "[484/1762] D loss: 1.3884, G loss: 0.7192\n",
      "[564/1762] D loss: 1.3866, G loss: 0.6902\n",
      "[644/1762] D loss: 1.3900, G loss: 0.7478\n",
      "[724/1762] D loss: 1.3872, G loss: 0.6756\n",
      "[804/1762] D loss: 1.3898, G loss: 0.7377\n",
      "[884/1762] D loss: 1.0442, G loss: 1.5743\n",
      "[964/1762] D loss: 1.3864, G loss: 0.6793\n",
      "[1044/1762] D loss: 1.3874, G loss: 0.6995\n",
      "[1124/1762] D loss: 1.3902, G loss: 0.7315\n",
      "[1204/1762] D loss: 1.3936, G loss: 0.7584\n",
      "[1284/1762] D loss: 1.3876, G loss: 0.6685\n",
      "[1364/1762] D loss: 0.6997, G loss: 2.5422\n",
      "[1444/1762] D loss: 1.3877, G loss: 0.7284\n",
      "[1524/1762] D loss: 1.3945, G loss: 0.7466\n",
      "[1604/1762] D loss: 1.3866, G loss: 0.6670\n",
      "[1684/1762] D loss: 1.0439, G loss: 1.5736\n",
      "[1762/1762] D loss: 0.7021, G loss: 2.5376\n",
      "train error: \n",
      " D loss: 1.286263, G loss: 0.984238, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.256851, G loss: 1.076471, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3879, G loss: 0.7012\n",
      "[84/1762] D loss: 1.3868, G loss: 0.6970\n",
      "[164/1762] D loss: 1.3875, G loss: 0.6677\n",
      "[244/1762] D loss: 1.0425, G loss: 1.6571\n",
      "[324/1762] D loss: 1.3878, G loss: 0.6771\n",
      "[404/1762] D loss: 1.3871, G loss: 0.7161\n",
      "[484/1762] D loss: 1.3869, G loss: 0.7163\n",
      "[564/1762] D loss: 1.3863, G loss: 0.6810\n",
      "[644/1762] D loss: 1.3887, G loss: 0.6721\n",
      "[724/1762] D loss: 1.3881, G loss: 0.7229\n",
      "[804/1762] D loss: 1.3865, G loss: 0.6944\n",
      "[884/1762] D loss: 1.3872, G loss: 0.6747\n",
      "[964/1762] D loss: 1.3870, G loss: 0.6981\n",
      "[1044/1762] D loss: 1.3883, G loss: 0.6724\n",
      "[1124/1762] D loss: 1.3961, G loss: 0.7684\n",
      "[1204/1762] D loss: 1.3917, G loss: 0.6709\n",
      "[1284/1762] D loss: 1.3901, G loss: 0.6718\n",
      "[1364/1762] D loss: 1.3873, G loss: 0.7180\n",
      "[1444/1762] D loss: 1.3882, G loss: 0.7258\n",
      "[1524/1762] D loss: 1.3865, G loss: 0.7081\n",
      "[1604/1762] D loss: 1.3873, G loss: 0.6998\n",
      "[1684/1762] D loss: 1.3903, G loss: 0.7322\n",
      "[1762/1762] D loss: 1.3939, G loss: 0.6381\n",
      "train error: \n",
      " D loss: 1.284760, G loss: 0.967081, D accuracy: 54.0%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.255892, G loss: 1.054062, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3872, G loss: 0.7084\n",
      "[84/1762] D loss: 1.3870, G loss: 0.6755\n",
      "[164/1762] D loss: 1.3822, G loss: 0.6906\n",
      "[244/1762] D loss: 1.0442, G loss: 1.5454\n",
      "[324/1762] D loss: 1.3862, G loss: 0.6860\n",
      "[404/1762] D loss: 1.3949, G loss: 0.6328\n",
      "[484/1762] D loss: 1.3873, G loss: 0.7158\n",
      "[564/1762] D loss: 1.3890, G loss: 0.7053\n",
      "[644/1762] D loss: 1.3845, G loss: 0.7000\n",
      "[724/1762] D loss: 1.4100, G loss: 0.5839\n",
      "[804/1762] D loss: 1.3915, G loss: 0.7814\n",
      "[884/1762] D loss: 1.0452, G loss: 1.7355\n",
      "[964/1762] D loss: 1.0458, G loss: 1.5259\n",
      "[1044/1762] D loss: 1.0471, G loss: 1.4542\n",
      "[1124/1762] D loss: 1.0427, G loss: 1.7591\n",
      "[1204/1762] D loss: 1.3331, G loss: 0.8438\n",
      "[1284/1762] D loss: 1.3963, G loss: 0.6260\n",
      "[1364/1762] D loss: 1.0427, G loss: 1.7388\n",
      "[1444/1762] D loss: 1.3855, G loss: 0.7191\n",
      "[1524/1762] D loss: 1.3854, G loss: 0.6949\n",
      "[1604/1762] D loss: 1.3886, G loss: 0.6605\n",
      "[1684/1762] D loss: 1.3882, G loss: 0.6546\n",
      "[1762/1762] D loss: 1.3860, G loss: 0.6856\n",
      "train error: \n",
      " D loss: 1.286208, G loss: 0.944763, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.255897, G loss: 1.032645, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0443, G loss: 1.5160\n",
      "[84/1762] D loss: 1.3897, G loss: 0.7535\n",
      "[164/1762] D loss: 1.3834, G loss: 0.7381\n",
      "[244/1762] D loss: 1.3876, G loss: 0.6417\n",
      "[324/1762] D loss: 1.0449, G loss: 1.5375\n",
      "[404/1762] D loss: 1.3884, G loss: 0.6924\n",
      "[484/1762] D loss: 1.3869, G loss: 0.7075\n",
      "[564/1762] D loss: 1.0443, G loss: 1.5962\n",
      "[644/1762] D loss: 1.0431, G loss: 1.6714\n",
      "[724/1762] D loss: 1.0458, G loss: 1.5744\n",
      "[804/1762] D loss: 1.3867, G loss: 0.6975\n",
      "[884/1762] D loss: 1.0423, G loss: 1.8210\n",
      "[964/1762] D loss: 1.3864, G loss: 0.7023\n",
      "[1044/1762] D loss: 1.0426, G loss: 1.6712\n",
      "[1124/1762] D loss: 1.0434, G loss: 1.6325\n",
      "[1204/1762] D loss: 1.3865, G loss: 0.6989\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6918\n",
      "[1364/1762] D loss: 1.3889, G loss: 0.7294\n",
      "[1444/1762] D loss: 1.3870, G loss: 0.6860\n",
      "[1524/1762] D loss: 1.2328, G loss: 1.0894\n",
      "[1604/1762] D loss: 1.3884, G loss: 0.6593\n",
      "[1684/1762] D loss: 1.3880, G loss: 0.7090\n",
      "[1762/1762] D loss: 1.3866, G loss: 0.7043\n",
      "train error: \n",
      " D loss: 1.285348, G loss: 0.971963, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.255991, G loss: 1.060057, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3870, G loss: 0.6752\n",
      "[84/1762] D loss: 1.3866, G loss: 0.7030\n",
      "[164/1762] D loss: 1.3870, G loss: 0.6746\n",
      "[244/1762] D loss: 1.0434, G loss: 1.6534\n",
      "[324/1762] D loss: 0.6987, G loss: 2.6090\n",
      "[404/1762] D loss: 1.3883, G loss: 0.7127\n",
      "[484/1762] D loss: 1.3869, G loss: 0.6902\n",
      "[564/1762] D loss: 1.3894, G loss: 0.7363\n",
      "[644/1762] D loss: 1.3866, G loss: 0.6907\n",
      "[724/1762] D loss: 1.3867, G loss: 0.6920\n",
      "[804/1762] D loss: 1.0413, G loss: 1.9424\n",
      "[884/1762] D loss: 1.3872, G loss: 0.6784\n",
      "[964/1762] D loss: 1.0423, G loss: 1.6958\n",
      "[1044/1762] D loss: 1.0485, G loss: 1.6626\n",
      "[1124/1762] D loss: 1.0426, G loss: 1.7030\n",
      "[1204/1762] D loss: 1.3873, G loss: 0.6997\n",
      "[1284/1762] D loss: 1.3869, G loss: 0.6703\n",
      "[1364/1762] D loss: 1.0944, G loss: 1.6960\n",
      "[1444/1762] D loss: 1.3869, G loss: 0.6978\n",
      "[1524/1762] D loss: 1.0421, G loss: 1.9091\n",
      "[1604/1762] D loss: 1.3872, G loss: 0.7064\n",
      "[1684/1762] D loss: 1.3884, G loss: 0.7117\n",
      "[1762/1762] D loss: 1.3869, G loss: 0.6678\n",
      "train error: \n",
      " D loss: 1.285044, G loss: 0.994570, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.255737, G loss: 1.091553, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3872, G loss: 0.6625\n",
      "[84/1762] D loss: 1.0417, G loss: 1.7286\n",
      "[164/1762] D loss: 1.0442, G loss: 1.7108\n",
      "[244/1762] D loss: 1.3895, G loss: 0.6478\n",
      "[324/1762] D loss: 1.3881, G loss: 0.7046\n",
      "[404/1762] D loss: 1.3883, G loss: 0.6997\n",
      "[484/1762] D loss: 1.3867, G loss: 0.6977\n",
      "[564/1762] D loss: 1.3877, G loss: 0.6865\n",
      "[644/1762] D loss: 1.3902, G loss: 0.6740\n",
      "[724/1762] D loss: 1.0419, G loss: 1.7300\n",
      "[804/1762] D loss: 1.0424, G loss: 1.8833\n",
      "[884/1762] D loss: 1.0420, G loss: 1.7170\n",
      "[964/1762] D loss: 1.3878, G loss: 0.6764\n",
      "[1044/1762] D loss: 1.0423, G loss: 1.7298\n",
      "[1124/1762] D loss: 1.3866, G loss: 0.6885\n",
      "[1204/1762] D loss: 1.0435, G loss: 1.7515\n",
      "[1284/1762] D loss: 1.3870, G loss: 0.7262\n",
      "[1364/1762] D loss: 1.3869, G loss: 0.7086\n",
      "[1444/1762] D loss: 1.3935, G loss: 0.7127\n",
      "[1524/1762] D loss: 1.1454, G loss: 1.6873\n",
      "[1604/1762] D loss: 1.1052, G loss: 1.6949\n",
      "[1684/1762] D loss: 1.3962, G loss: 0.6811\n",
      "[1762/1762] D loss: 1.3869, G loss: 0.7164\n",
      "train error: \n",
      " D loss: 1.288739, G loss: 1.066412, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.259159, G loss: 1.160248, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0431, G loss: 1.7662\n",
      "[84/1762] D loss: 1.3876, G loss: 0.7182\n",
      "[164/1762] D loss: 1.3881, G loss: 0.6553\n",
      "[244/1762] D loss: 1.3873, G loss: 0.7197\n",
      "[324/1762] D loss: 1.0442, G loss: 1.9298\n",
      "[404/1762] D loss: 1.3880, G loss: 0.6818\n",
      "[484/1762] D loss: 1.3913, G loss: 0.7428\n",
      "[564/1762] D loss: 1.0434, G loss: 1.7210\n",
      "[644/1762] D loss: 1.3904, G loss: 0.6606\n",
      "[724/1762] D loss: 1.3999, G loss: 0.6485\n",
      "[804/1762] D loss: 1.3914, G loss: 0.7399\n",
      "[884/1762] D loss: 1.0432, G loss: 1.6981\n",
      "[964/1762] D loss: 1.3865, G loss: 0.6943\n",
      "[1044/1762] D loss: 1.3877, G loss: 0.7170\n",
      "[1124/1762] D loss: 1.3867, G loss: 0.6803\n",
      "[1204/1762] D loss: 1.3869, G loss: 0.7188\n",
      "[1284/1762] D loss: 1.3866, G loss: 0.7057\n",
      "[1364/1762] D loss: 1.3877, G loss: 0.7172\n",
      "[1444/1762] D loss: 1.0421, G loss: 1.6956\n",
      "[1524/1762] D loss: 1.3866, G loss: 0.7111\n",
      "[1604/1762] D loss: 1.3882, G loss: 0.6744\n",
      "[1684/1762] D loss: 1.3890, G loss: 0.7287\n",
      "[1762/1762] D loss: 1.3875, G loss: 0.7097\n",
      "train error: \n",
      " D loss: 1.285356, G loss: 0.986263, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.256255, G loss: 1.077094, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4034, G loss: 0.5727\n",
      "[84/1762] D loss: 1.3190, G loss: 0.6321\n",
      "[164/1762] D loss: 0.2209, G loss: 3.1349\n",
      "[244/1762] D loss: 0.0580, G loss: 5.8434\n",
      "[324/1762] D loss: 0.2285, G loss: 6.5687\n",
      "[404/1762] D loss: 0.0945, G loss: 6.8827\n",
      "[484/1762] D loss: 0.1922, G loss: 5.1960\n",
      "[564/1762] D loss: 1.2637, G loss: 5.8041\n",
      "[644/1762] D loss: 0.0510, G loss: 3.5269\n",
      "[724/1762] D loss: 0.3531, G loss: 3.2201\n",
      "[804/1762] D loss: 1.8178, G loss: 2.0716\n",
      "[884/1762] D loss: 0.9580, G loss: 1.9567\n",
      "[964/1762] D loss: 1.2755, G loss: 2.1100\n",
      "[1044/1762] D loss: 0.6598, G loss: 3.3053\n",
      "[1124/1762] D loss: 0.6509, G loss: 2.6733\n",
      "[1204/1762] D loss: 0.6184, G loss: 0.3496\n",
      "[1284/1762] D loss: 1.6954, G loss: 2.3653\n",
      "[1364/1762] D loss: 0.8431, G loss: 1.7333\n",
      "[1444/1762] D loss: 0.5751, G loss: 2.0038\n",
      "[1524/1762] D loss: 1.1308, G loss: 2.2122\n",
      "[1604/1762] D loss: 1.6061, G loss: 1.0212\n",
      "[1684/1762] D loss: 1.2637, G loss: 0.6835\n",
      "[1762/1762] D loss: 1.6153, G loss: 0.5045\n",
      "train error: \n",
      " D loss: 1.276520, G loss: 0.644704, D accuracy: 63.7%, cell accuracy: 96.2%, board accuracy: 13.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.284050, G loss: 0.648143, D accuracy: 63.2%, cell accuracy: 96.0%, board accuracy: 13.4% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2572, G loss: 0.8659\n",
      "[84/1762] D loss: 0.9543, G loss: 0.9077\n",
      "[164/1762] D loss: 1.2244, G loss: 0.9081\n",
      "[244/1762] D loss: 1.1490, G loss: 0.8821\n",
      "[324/1762] D loss: 1.0326, G loss: 1.0084\n",
      "[404/1762] D loss: 0.7852, G loss: 1.8270\n",
      "[484/1762] D loss: 0.8582, G loss: 1.5455\n",
      "[564/1762] D loss: 0.6124, G loss: 1.0564\n",
      "[644/1762] D loss: 0.9202, G loss: 1.1458\n",
      "[724/1762] D loss: 1.1711, G loss: 1.4090\n",
      "[804/1762] D loss: 1.2182, G loss: 1.2100\n",
      "[884/1762] D loss: 1.3703, G loss: 0.3916\n",
      "[964/1762] D loss: 1.4788, G loss: 0.5590\n",
      "[1044/1762] D loss: 1.2671, G loss: 0.7252\n",
      "[1124/1762] D loss: 1.3189, G loss: 0.6737\n",
      "[1204/1762] D loss: 1.4187, G loss: 0.4750\n",
      "[1284/1762] D loss: 1.3669, G loss: 0.6955\n",
      "[1364/1762] D loss: 1.3795, G loss: 0.6663\n",
      "[1444/1762] D loss: 1.2576, G loss: 0.9264\n",
      "[1524/1762] D loss: 1.3772, G loss: 0.6105\n",
      "[1604/1762] D loss: 1.6007, G loss: 0.9728\n",
      "[1684/1762] D loss: 1.3182, G loss: 0.7641\n",
      "[1762/1762] D loss: 1.1516, G loss: 0.8839\n",
      "train error: \n",
      " D loss: 1.318717, G loss: 0.772997, D accuracy: 62.5%, cell accuracy: 99.4%, board accuracy: 43.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.326342, G loss: 0.768143, D accuracy: 61.8%, cell accuracy: 99.3%, board accuracy: 42.0% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2968, G loss: 0.9574\n",
      "[84/1762] D loss: 1.2614, G loss: 0.8320\n",
      "[164/1762] D loss: 1.2389, G loss: 0.6814\n",
      "[244/1762] D loss: 1.3264, G loss: 0.8363\n",
      "[324/1762] D loss: 1.2580, G loss: 0.8612\n",
      "[404/1762] D loss: 1.2139, G loss: 0.7179\n",
      "[484/1762] D loss: 1.3248, G loss: 0.7860\n",
      "[564/1762] D loss: 1.3441, G loss: 0.9250\n",
      "[644/1762] D loss: 1.2530, G loss: 0.8069\n",
      "[724/1762] D loss: 1.2633, G loss: 0.6179\n",
      "[804/1762] D loss: 1.3889, G loss: 0.5984\n",
      "[884/1762] D loss: 1.4645, G loss: 0.4466\n",
      "[964/1762] D loss: 1.3525, G loss: 1.0330\n",
      "[1044/1762] D loss: 1.2739, G loss: 0.8031\n",
      "[1124/1762] D loss: 1.3981, G loss: 0.7575\n",
      "[1204/1762] D loss: 1.3653, G loss: 0.9162\n",
      "[1284/1762] D loss: 1.3745, G loss: 0.6891\n",
      "[1364/1762] D loss: 1.3456, G loss: 0.8118\n",
      "[1444/1762] D loss: 1.2443, G loss: 0.7416\n",
      "[1524/1762] D loss: 1.3668, G loss: 0.8288\n",
      "[1604/1762] D loss: 1.3323, G loss: 0.7344\n",
      "[1684/1762] D loss: 1.3787, G loss: 0.7618\n",
      "[1762/1762] D loss: 1.3048, G loss: 0.8273\n",
      "train error: \n",
      " D loss: 1.364096, G loss: 0.707613, D accuracy: 55.8%, cell accuracy: 99.7%, board accuracy: 76.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.358960, G loss: 0.713509, D accuracy: 55.9%, cell accuracy: 99.7%, board accuracy: 74.8% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3814, G loss: 0.6957\n",
      "[84/1762] D loss: 1.3248, G loss: 0.7783\n",
      "[164/1762] D loss: 1.3452, G loss: 0.6787\n",
      "[244/1762] D loss: 1.2278, G loss: 0.7417\n",
      "[324/1762] D loss: 1.4091, G loss: 0.6483\n",
      "[404/1762] D loss: 1.3934, G loss: 0.7628\n",
      "[484/1762] D loss: 1.3935, G loss: 0.8255\n",
      "[564/1762] D loss: 1.1616, G loss: 0.8127\n",
      "[644/1762] D loss: 1.4207, G loss: 0.6186\n",
      "[724/1762] D loss: 1.3866, G loss: 0.8234\n",
      "[804/1762] D loss: 1.3752, G loss: 0.6958\n",
      "[884/1762] D loss: 1.3614, G loss: 0.6257\n",
      "[964/1762] D loss: 1.4070, G loss: 0.7473\n",
      "[1044/1762] D loss: 1.3811, G loss: 0.7094\n",
      "[1124/1762] D loss: 1.3414, G loss: 0.8727\n",
      "[1204/1762] D loss: 1.2429, G loss: 0.7107\n",
      "[1284/1762] D loss: 1.2723, G loss: 0.8470\n",
      "[1364/1762] D loss: 1.4253, G loss: 0.6320\n",
      "[1444/1762] D loss: 1.5230, G loss: 1.1854\n",
      "[1524/1762] D loss: 1.3072, G loss: 0.6415\n",
      "[1604/1762] D loss: 1.3887, G loss: 0.9574\n",
      "[1684/1762] D loss: 1.3768, G loss: 0.6537\n",
      "[1762/1762] D loss: 1.3737, G loss: 0.6521\n",
      "train error: \n",
      " D loss: 1.354564, G loss: 0.664756, D accuracy: 55.2%, cell accuracy: 99.7%, board accuracy: 77.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.348141, G loss: 0.669343, D accuracy: 55.9%, cell accuracy: 99.7%, board accuracy: 73.6% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3984, G loss: 0.6537\n",
      "[84/1762] D loss: 1.3844, G loss: 0.8043\n",
      "[164/1762] D loss: 1.3461, G loss: 0.8723\n",
      "[244/1762] D loss: 1.2097, G loss: 0.8979\n",
      "[324/1762] D loss: 1.4261, G loss: 0.8085\n",
      "[404/1762] D loss: 1.3845, G loss: 0.7466\n",
      "[484/1762] D loss: 1.3787, G loss: 0.7240\n",
      "[564/1762] D loss: 1.3779, G loss: 0.6902\n",
      "[644/1762] D loss: 1.3820, G loss: 0.7090\n",
      "[724/1762] D loss: 1.4260, G loss: 0.7648\n",
      "[804/1762] D loss: 1.3521, G loss: 0.6353\n",
      "[884/1762] D loss: 1.4161, G loss: 0.7882\n",
      "[964/1762] D loss: 1.4069, G loss: 0.6672\n",
      "[1044/1762] D loss: 1.3014, G loss: 0.7697\n",
      "[1124/1762] D loss: 1.2079, G loss: 0.9027\n",
      "[1204/1762] D loss: 1.3636, G loss: 0.7133\n",
      "[1284/1762] D loss: 1.3838, G loss: 0.7651\n",
      "[1364/1762] D loss: 1.3876, G loss: 0.8932\n",
      "[1444/1762] D loss: 1.4521, G loss: 0.7680\n",
      "[1524/1762] D loss: 1.3826, G loss: 0.5486\n",
      "[1604/1762] D loss: 0.7297, G loss: 1.1849\n",
      "[1684/1762] D loss: 1.3982, G loss: 0.7658\n",
      "[1762/1762] D loss: 1.3801, G loss: 0.6717\n",
      "train error: \n",
      " D loss: 1.320995, G loss: 0.789649, D accuracy: 55.5%, cell accuracy: 99.7%, board accuracy: 81.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.308933, G loss: 0.794456, D accuracy: 56.8%, cell accuracy: 99.7%, board accuracy: 79.3% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3649, G loss: 0.6690\n",
      "[84/1762] D loss: 1.2304, G loss: 0.9679\n",
      "[164/1762] D loss: 1.3849, G loss: 0.7048\n",
      "[244/1762] D loss: 1.4458, G loss: 0.8211\n",
      "[324/1762] D loss: 1.3829, G loss: 0.7527\n",
      "[404/1762] D loss: 1.3925, G loss: 0.6271\n",
      "[484/1762] D loss: 1.3815, G loss: 0.7704\n",
      "[564/1762] D loss: 0.9089, G loss: 1.1500\n",
      "[644/1762] D loss: 1.3825, G loss: 0.8576\n",
      "[724/1762] D loss: 1.4469, G loss: 0.7306\n",
      "[804/1762] D loss: 1.3874, G loss: 0.7611\n",
      "[884/1762] D loss: 1.3752, G loss: 0.6781\n",
      "[964/1762] D loss: 1.4096, G loss: 0.5629\n",
      "[1044/1762] D loss: 1.3808, G loss: 0.7508\n",
      "[1124/1762] D loss: 1.3733, G loss: 0.6329\n",
      "[1204/1762] D loss: 1.3779, G loss: 0.6614\n",
      "[1284/1762] D loss: 1.4897, G loss: 0.6928\n",
      "[1364/1762] D loss: 1.1932, G loss: 0.9970\n",
      "[1444/1762] D loss: 1.1488, G loss: 0.8392\n",
      "[1524/1762] D loss: 1.4007, G loss: 0.6889\n",
      "[1604/1762] D loss: 1.4195, G loss: 0.5816\n",
      "[1684/1762] D loss: 1.4291, G loss: 0.5802\n",
      "[1762/1762] D loss: 1.3825, G loss: 0.5966\n",
      "train error: \n",
      " D loss: 1.360442, G loss: 0.579949, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 86.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.344858, G loss: 0.585038, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 83.0% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4072, G loss: 0.5575\n",
      "[84/1762] D loss: 1.4018, G loss: 0.7981\n",
      "[164/1762] D loss: 1.2879, G loss: 0.8118\n",
      "[244/1762] D loss: 1.4147, G loss: 0.6971\n",
      "[324/1762] D loss: 1.3837, G loss: 0.7411\n",
      "[404/1762] D loss: 1.4290, G loss: 0.6085\n",
      "[484/1762] D loss: 1.4289, G loss: 0.5936\n",
      "[564/1762] D loss: 1.3339, G loss: 0.6939\n",
      "[644/1762] D loss: 1.2116, G loss: 0.6930\n",
      "[724/1762] D loss: 1.3862, G loss: 0.6017\n",
      "[804/1762] D loss: 1.3861, G loss: 0.6072\n",
      "[884/1762] D loss: 1.3873, G loss: 0.7334\n",
      "[964/1762] D loss: 1.3715, G loss: 0.6975\n",
      "[1044/1762] D loss: 1.3925, G loss: 0.6048\n",
      "[1124/1762] D loss: 1.4395, G loss: 0.5632\n",
      "[1204/1762] D loss: 1.3853, G loss: 0.6961\n",
      "[1284/1762] D loss: 1.3816, G loss: 0.7302\n",
      "[1364/1762] D loss: 1.3415, G loss: 0.7648\n",
      "[1444/1762] D loss: 1.1537, G loss: 0.8152\n",
      "[1524/1762] D loss: 1.4098, G loss: 0.8232\n",
      "[1604/1762] D loss: 1.3333, G loss: 0.8365\n",
      "[1684/1762] D loss: 1.3948, G loss: 0.6337\n",
      "[1762/1762] D loss: 0.9301, G loss: 0.9941\n",
      "train error: \n",
      " D loss: 1.325222, G loss: 0.804163, D accuracy: 57.1%, cell accuracy: 99.4%, board accuracy: 49.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.309951, G loss: 0.812185, D accuracy: 58.9%, cell accuracy: 99.3%, board accuracy: 48.6% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4090, G loss: 0.7851\n",
      "[84/1762] D loss: 1.4045, G loss: 0.6463\n",
      "[164/1762] D loss: 0.9456, G loss: 0.8630\n",
      "[244/1762] D loss: 0.1892, G loss: 2.6413\n",
      "[324/1762] D loss: 1.2386, G loss: 0.6209\n",
      "[404/1762] D loss: 1.1570, G loss: 0.9424\n",
      "[484/1762] D loss: 1.3283, G loss: 0.9233\n",
      "[564/1762] D loss: 1.1816, G loss: 0.7312\n",
      "[644/1762] D loss: 1.2496, G loss: 0.7330\n",
      "[724/1762] D loss: 1.2740, G loss: 0.6650\n",
      "[804/1762] D loss: 1.4018, G loss: 0.6245\n",
      "[884/1762] D loss: 1.3151, G loss: 0.9065\n",
      "[964/1762] D loss: 1.4178, G loss: 0.6417\n",
      "[1044/1762] D loss: 1.3842, G loss: 0.6806\n",
      "[1124/1762] D loss: 1.3735, G loss: 0.6635\n",
      "[1204/1762] D loss: 1.2547, G loss: 0.7671\n",
      "[1284/1762] D loss: 1.3807, G loss: 0.5967\n",
      "[1364/1762] D loss: 1.4261, G loss: 0.5643\n",
      "[1444/1762] D loss: 1.3909, G loss: 0.6656\n",
      "[1524/1762] D loss: 1.4249, G loss: 0.5165\n",
      "[1604/1762] D loss: 1.4407, G loss: 0.5284\n",
      "[1684/1762] D loss: 1.3893, G loss: 0.6924\n",
      "[1762/1762] D loss: 1.5676, G loss: 0.8857\n",
      "train error: \n",
      " D loss: 1.492008, G loss: 0.932784, D accuracy: 45.9%, cell accuracy: 98.8%, board accuracy: 17.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.492954, G loss: 0.924514, D accuracy: 45.5%, cell accuracy: 98.7%, board accuracy: 18.9% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5290, G loss: 1.1718\n",
      "[84/1762] D loss: 1.1841, G loss: 0.9972\n",
      "[164/1762] D loss: 1.5391, G loss: 0.7330\n",
      "[244/1762] D loss: 1.3673, G loss: 0.6502\n",
      "[324/1762] D loss: 1.4007, G loss: 0.7041\n",
      "[404/1762] D loss: 1.3653, G loss: 0.7112\n",
      "[484/1762] D loss: 1.3747, G loss: 0.6319\n",
      "[564/1762] D loss: 1.3923, G loss: 0.7543\n",
      "[644/1762] D loss: 1.3804, G loss: 0.7093\n",
      "[724/1762] D loss: 1.3862, G loss: 0.7158\n",
      "[804/1762] D loss: 1.3883, G loss: 0.6547\n",
      "[884/1762] D loss: 1.3921, G loss: 0.6730\n",
      "[964/1762] D loss: 1.3800, G loss: 0.7067\n",
      "[1044/1762] D loss: 1.3625, G loss: 0.7070\n",
      "[1124/1762] D loss: 1.3520, G loss: 0.6617\n",
      "[1204/1762] D loss: 1.3861, G loss: 0.6937\n",
      "[1284/1762] D loss: 1.3860, G loss: 0.7415\n",
      "[1364/1762] D loss: 1.3933, G loss: 0.6549\n",
      "[1444/1762] D loss: 1.3883, G loss: 0.6852\n",
      "[1524/1762] D loss: 1.3885, G loss: 0.7029\n",
      "[1604/1762] D loss: 1.3896, G loss: 0.7361\n",
      "[1684/1762] D loss: 1.3061, G loss: 0.7580\n",
      "[1762/1762] D loss: 1.1847, G loss: 0.7197\n",
      "train error: \n",
      " D loss: 1.361997, G loss: 0.725419, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.356397, G loss: 0.726325, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 84.1% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3980, G loss: 0.7067\n",
      "[84/1762] D loss: 1.3942, G loss: 0.6745\n",
      "[164/1762] D loss: 1.2781, G loss: 0.6469\n",
      "[244/1762] D loss: 1.2502, G loss: 0.7606\n",
      "[324/1762] D loss: 1.2322, G loss: 0.7761\n",
      "[404/1762] D loss: 1.3853, G loss: 0.7241\n",
      "[484/1762] D loss: 1.3913, G loss: 0.7826\n",
      "[564/1762] D loss: 1.3811, G loss: 0.7500\n",
      "[644/1762] D loss: 1.0980, G loss: 0.9111\n",
      "[724/1762] D loss: 1.3884, G loss: 0.6226\n",
      "[804/1762] D loss: 1.4072, G loss: 0.7893\n",
      "[884/1762] D loss: 1.1859, G loss: 0.8104\n",
      "[964/1762] D loss: 1.2777, G loss: 0.6366\n",
      "[1044/1762] D loss: 1.3912, G loss: 0.7813\n",
      "[1124/1762] D loss: 1.3862, G loss: 0.6918\n",
      "[1204/1762] D loss: 1.3866, G loss: 0.6839\n",
      "[1284/1762] D loss: 1.3853, G loss: 0.7248\n",
      "[1364/1762] D loss: 1.3860, G loss: 0.6769\n",
      "[1444/1762] D loss: 1.3467, G loss: 0.7653\n",
      "[1524/1762] D loss: 1.3893, G loss: 0.7383\n",
      "[1604/1762] D loss: 1.5726, G loss: 0.6846\n",
      "[1684/1762] D loss: 1.2268, G loss: 0.8651\n",
      "[1762/1762] D loss: 1.3855, G loss: 0.6427\n",
      "train error: \n",
      " D loss: 1.347071, G loss: 0.657352, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 80.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.340833, G loss: 0.656234, D accuracy: 55.8%, cell accuracy: 99.7%, board accuracy: 76.8% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3581, G loss: 0.5908\n",
      "[84/1762] D loss: 1.2002, G loss: 0.7872\n",
      "[164/1762] D loss: 1.2193, G loss: 0.8295\n",
      "[244/1762] D loss: 1.3922, G loss: 0.7334\n",
      "[324/1762] D loss: 1.4264, G loss: 0.8475\n",
      "[404/1762] D loss: 1.3745, G loss: 0.6592\n",
      "[484/1762] D loss: 1.3509, G loss: 0.6942\n",
      "[564/1762] D loss: 1.4096, G loss: 0.7263\n",
      "[644/1762] D loss: 0.9951, G loss: 0.9071\n",
      "[724/1762] D loss: 1.4179, G loss: 0.7694\n",
      "[804/1762] D loss: 1.2162, G loss: 0.7909\n",
      "[884/1762] D loss: 1.4140, G loss: 0.6874\n",
      "[964/1762] D loss: 1.3915, G loss: 0.7118\n",
      "[1044/1762] D loss: 1.4022, G loss: 0.7848\n",
      "[1124/1762] D loss: 1.3955, G loss: 0.6918\n",
      "[1204/1762] D loss: 1.3895, G loss: 0.8247\n",
      "[1284/1762] D loss: 1.3873, G loss: 0.6048\n",
      "[1364/1762] D loss: 1.2202, G loss: 0.7956\n",
      "[1444/1762] D loss: 1.2770, G loss: 0.9758\n",
      "[1524/1762] D loss: 1.4978, G loss: 0.7795\n",
      "[1604/1762] D loss: 1.3833, G loss: 0.7228\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.5907\n",
      "[1762/1762] D loss: 1.3879, G loss: 0.7696\n",
      "train error: \n",
      " D loss: 1.330764, G loss: 0.837270, D accuracy: 54.9%, cell accuracy: 99.5%, board accuracy: 66.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.316477, G loss: 0.842127, D accuracy: 55.2%, cell accuracy: 99.4%, board accuracy: 62.3% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2042, G loss: 0.9440\n",
      "[84/1762] D loss: 1.3914, G loss: 0.6365\n",
      "[164/1762] D loss: 1.3815, G loss: 0.7389\n",
      "[244/1762] D loss: 1.1991, G loss: 0.8157\n",
      "[324/1762] D loss: 1.3659, G loss: 0.7223\n",
      "[404/1762] D loss: 1.3905, G loss: 0.7251\n",
      "[484/1762] D loss: 1.1591, G loss: 0.9410\n",
      "[564/1762] D loss: 1.3876, G loss: 0.7009\n",
      "[644/1762] D loss: 1.3899, G loss: 0.6885\n",
      "[724/1762] D loss: 1.3885, G loss: 0.6861\n",
      "[804/1762] D loss: 1.3899, G loss: 0.7004\n",
      "[884/1762] D loss: 1.3721, G loss: 0.7984\n",
      "[964/1762] D loss: 1.3510, G loss: 0.7818\n",
      "[1044/1762] D loss: 1.3930, G loss: 0.7395\n",
      "[1124/1762] D loss: 1.4050, G loss: 0.7286\n",
      "[1204/1762] D loss: 1.3916, G loss: 0.6601\n",
      "[1284/1762] D loss: 1.3836, G loss: 0.7058\n",
      "[1364/1762] D loss: 1.1251, G loss: 0.8645\n",
      "[1444/1762] D loss: 1.1124, G loss: 0.8223\n",
      "[1524/1762] D loss: 1.3919, G loss: 0.7463\n",
      "[1604/1762] D loss: 1.3789, G loss: 0.8413\n",
      "[1684/1762] D loss: 0.9218, G loss: 0.8691\n",
      "[1762/1762] D loss: 1.4200, G loss: 0.9669\n",
      "train error: \n",
      " D loss: 1.353935, G loss: 0.962660, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 85.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.329438, G loss: 0.966240, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 83.0% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4353, G loss: 0.9151\n",
      "[84/1762] D loss: 1.1508, G loss: 0.7429\n",
      "[164/1762] D loss: 1.3851, G loss: 0.7183\n",
      "[244/1762] D loss: 1.3899, G loss: 0.7393\n",
      "[324/1762] D loss: 1.1657, G loss: 0.8198\n",
      "[404/1762] D loss: 1.3865, G loss: 0.7084\n",
      "[484/1762] D loss: 1.1720, G loss: 0.7953\n",
      "[564/1762] D loss: 1.3753, G loss: 0.7216\n",
      "[644/1762] D loss: 1.4094, G loss: 0.8654\n",
      "[724/1762] D loss: 1.4074, G loss: 0.7919\n",
      "[804/1762] D loss: 1.4129, G loss: 0.6858\n",
      "[884/1762] D loss: 1.0202, G loss: 0.8882\n",
      "[964/1762] D loss: 1.4393, G loss: 0.7692\n",
      "[1044/1762] D loss: 1.4040, G loss: 0.5617\n",
      "[1124/1762] D loss: 1.3950, G loss: 0.7083\n",
      "[1204/1762] D loss: 1.1383, G loss: 0.7639\n",
      "[1284/1762] D loss: 1.1813, G loss: 0.7362\n",
      "[1364/1762] D loss: 1.3956, G loss: 0.7025\n",
      "[1444/1762] D loss: 1.4060, G loss: 0.6133\n",
      "[1524/1762] D loss: 1.1462, G loss: 0.7643\n",
      "[1604/1762] D loss: 1.1471, G loss: 0.8056\n",
      "[1684/1762] D loss: 1.1403, G loss: 0.9914\n",
      "[1762/1762] D loss: 1.3656, G loss: 0.8559\n",
      "train error: \n",
      " D loss: 1.314879, G loss: 0.872542, D accuracy: 54.3%, cell accuracy: 99.6%, board accuracy: 70.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.292407, G loss: 0.883816, D accuracy: 55.1%, cell accuracy: 99.5%, board accuracy: 66.8% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4009, G loss: 0.7833\n",
      "[84/1762] D loss: 1.3534, G loss: 0.6857\n",
      "[164/1762] D loss: 1.1246, G loss: 1.0420\n",
      "[244/1762] D loss: 1.3964, G loss: 0.6989\n",
      "[324/1762] D loss: 1.4135, G loss: 0.5842\n",
      "[404/1762] D loss: 1.3814, G loss: 0.6806\n",
      "[484/1762] D loss: 1.3892, G loss: 0.6696\n",
      "[564/1762] D loss: 1.3869, G loss: 0.7128\n",
      "[644/1762] D loss: 1.3847, G loss: 0.6842\n",
      "[724/1762] D loss: 1.3865, G loss: 0.7050\n",
      "[804/1762] D loss: 1.3873, G loss: 0.7274\n",
      "[884/1762] D loss: 1.3177, G loss: 0.7199\n",
      "[964/1762] D loss: 1.3231, G loss: 0.7256\n",
      "[1044/1762] D loss: 1.3868, G loss: 0.7182\n",
      "[1124/1762] D loss: 1.2724, G loss: 0.7659\n",
      "[1204/1762] D loss: 1.3860, G loss: 0.7733\n",
      "[1284/1762] D loss: 1.3869, G loss: 0.6930\n",
      "[1364/1762] D loss: 1.3980, G loss: 0.6002\n",
      "[1444/1762] D loss: 1.3884, G loss: 0.6722\n",
      "[1524/1762] D loss: 1.3894, G loss: 0.7141\n",
      "[1604/1762] D loss: 1.3833, G loss: 0.6723\n",
      "[1684/1762] D loss: 1.3907, G loss: 0.7298\n",
      "[1762/1762] D loss: 1.3775, G loss: 0.7600\n",
      "train error: \n",
      " D loss: 1.345276, G loss: 0.746799, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 85.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.331780, G loss: 0.743511, D accuracy: 55.0%, cell accuracy: 99.7%, board accuracy: 84.1% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3867, G loss: 0.7097\n",
      "[84/1762] D loss: 1.2398, G loss: 0.7896\n",
      "[164/1762] D loss: 1.3902, G loss: 0.7318\n",
      "[244/1762] D loss: 1.2425, G loss: 0.6556\n",
      "[324/1762] D loss: 1.3867, G loss: 0.5926\n",
      "[404/1762] D loss: 1.4969, G loss: 0.5183\n",
      "[484/1762] D loss: 1.4184, G loss: 0.8195\n",
      "[564/1762] D loss: 1.3737, G loss: 0.7674\n",
      "[644/1762] D loss: 1.3884, G loss: 0.7314\n",
      "[724/1762] D loss: 1.3861, G loss: 0.7269\n",
      "[804/1762] D loss: 1.3880, G loss: 0.7375\n",
      "[884/1762] D loss: 1.3875, G loss: 0.7285\n",
      "[964/1762] D loss: 1.3874, G loss: 0.7216\n",
      "[1044/1762] D loss: 1.3892, G loss: 0.7489\n",
      "[1124/1762] D loss: 1.3873, G loss: 0.6750\n",
      "[1204/1762] D loss: 1.3869, G loss: 0.7574\n",
      "[1284/1762] D loss: 1.3947, G loss: 0.7652\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.7291\n",
      "[1444/1762] D loss: 1.3976, G loss: 0.8243\n",
      "[1524/1762] D loss: 1.2342, G loss: 0.7000\n",
      "[1604/1762] D loss: 1.3874, G loss: 0.7250\n",
      "[1684/1762] D loss: 1.3911, G loss: 0.8134\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6930\n",
      "train error: \n",
      " D loss: 1.340657, G loss: 0.698274, D accuracy: 52.2%, cell accuracy: 99.7%, board accuracy: 84.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.329497, G loss: 0.697143, D accuracy: 53.1%, cell accuracy: 99.7%, board accuracy: 83.0% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2250, G loss: 0.7152\n",
      "[84/1762] D loss: 1.3884, G loss: 0.7099\n",
      "[164/1762] D loss: 1.3867, G loss: 0.6870\n",
      "[244/1762] D loss: 1.3875, G loss: 0.6918\n",
      "[324/1762] D loss: 1.3865, G loss: 0.7396\n",
      "[404/1762] D loss: 1.3880, G loss: 0.7164\n",
      "[484/1762] D loss: 1.2017, G loss: 0.7408\n",
      "[564/1762] D loss: 1.3877, G loss: 0.7516\n",
      "[644/1762] D loss: 1.3882, G loss: 0.7767\n",
      "[724/1762] D loss: 1.3913, G loss: 0.7513\n",
      "[804/1762] D loss: 1.1907, G loss: 0.7378\n",
      "[884/1762] D loss: 1.1804, G loss: 0.7488\n",
      "[964/1762] D loss: 1.1747, G loss: 0.7206\n",
      "[1044/1762] D loss: 1.3937, G loss: 0.7739\n",
      "[1124/1762] D loss: 1.1598, G loss: 0.7148\n",
      "[1204/1762] D loss: 1.3808, G loss: 0.6997\n",
      "[1284/1762] D loss: 1.4040, G loss: 0.7270\n",
      "[1364/1762] D loss: 1.2274, G loss: 0.7264\n",
      "[1444/1762] D loss: 1.2113, G loss: 0.7612\n",
      "[1524/1762] D loss: 1.3998, G loss: 0.7709\n",
      "[1604/1762] D loss: 1.4262, G loss: 0.8503\n",
      "[1684/1762] D loss: 1.3895, G loss: 0.6535\n",
      "[1762/1762] D loss: 1.3675, G loss: 0.6869\n",
      "train error: \n",
      " D loss: 1.331474, G loss: 0.677144, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 86.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.308391, G loss: 0.688561, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 84.5% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3871, G loss: 0.6728\n",
      "[84/1762] D loss: 1.4018, G loss: 0.7959\n",
      "[164/1762] D loss: 1.3893, G loss: 0.6494\n",
      "[244/1762] D loss: 1.3873, G loss: 0.7066\n",
      "[324/1762] D loss: 1.3928, G loss: 0.7322\n",
      "[404/1762] D loss: 1.1549, G loss: 0.8070\n",
      "[484/1762] D loss: 1.3960, G loss: 0.7432\n",
      "[564/1762] D loss: 1.3878, G loss: 0.6288\n",
      "[644/1762] D loss: 1.4160, G loss: 0.7112\n",
      "[724/1762] D loss: 1.4257, G loss: 0.6480\n",
      "[804/1762] D loss: 1.3372, G loss: 0.8059\n",
      "[884/1762] D loss: 1.3865, G loss: 0.6449\n",
      "[964/1762] D loss: 1.3874, G loss: 0.7752\n",
      "[1044/1762] D loss: 0.9407, G loss: 0.9914\n",
      "[1124/1762] D loss: 1.2701, G loss: 0.7867\n",
      "[1204/1762] D loss: 1.7822, G loss: 0.9031\n",
      "[1284/1762] D loss: 1.3878, G loss: 0.7714\n",
      "[1364/1762] D loss: 1.3785, G loss: 0.7135\n",
      "[1444/1762] D loss: 1.1660, G loss: 0.7255\n",
      "[1524/1762] D loss: 1.2252, G loss: 0.7123\n",
      "[1604/1762] D loss: 1.1855, G loss: 0.8029\n",
      "[1684/1762] D loss: 1.3973, G loss: 0.7562\n",
      "[1762/1762] D loss: 1.3836, G loss: 0.7537\n",
      "train error: \n",
      " D loss: 1.325310, G loss: 0.731287, D accuracy: 53.9%, cell accuracy: 99.7%, board accuracy: 69.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.305720, G loss: 0.732600, D accuracy: 54.9%, cell accuracy: 99.6%, board accuracy: 67.0% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4114, G loss: 0.7271\n",
      "[84/1762] D loss: 1.4012, G loss: 0.6748\n",
      "[164/1762] D loss: 1.1874, G loss: 0.7030\n",
      "[244/1762] D loss: 1.3884, G loss: 0.7927\n",
      "[324/1762] D loss: 1.3859, G loss: 0.6505\n",
      "[404/1762] D loss: 1.3909, G loss: 0.6905\n",
      "[484/1762] D loss: 1.3909, G loss: 0.8149\n",
      "[564/1762] D loss: 1.3897, G loss: 0.6580\n",
      "[644/1762] D loss: 1.3925, G loss: 0.6668\n",
      "[724/1762] D loss: 1.4246, G loss: 0.8631\n",
      "[804/1762] D loss: 1.3438, G loss: 0.6904\n",
      "[884/1762] D loss: 1.3778, G loss: 0.7284\n",
      "[964/1762] D loss: 1.1236, G loss: 0.8171\n",
      "[1044/1762] D loss: 1.1005, G loss: 0.9379\n",
      "[1124/1762] D loss: 1.1008, G loss: 0.9998\n",
      "[1204/1762] D loss: 1.4647, G loss: 0.8289\n",
      "[1284/1762] D loss: 1.3869, G loss: 0.6914\n",
      "[1364/1762] D loss: 1.1168, G loss: 0.8639\n",
      "[1444/1762] D loss: 1.4338, G loss: 0.6595\n",
      "[1524/1762] D loss: 1.2528, G loss: 0.5575\n",
      "[1604/1762] D loss: 1.3018, G loss: 0.6159\n",
      "[1684/1762] D loss: 1.3820, G loss: 0.6330\n",
      "[1762/1762] D loss: 1.3768, G loss: 0.6930\n",
      "train error: \n",
      " D loss: 1.397227, G loss: 0.684388, D accuracy: 52.9%, cell accuracy: 99.4%, board accuracy: 53.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.401925, G loss: 0.684749, D accuracy: 52.8%, cell accuracy: 99.4%, board accuracy: 50.5% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3792, G loss: 0.6665\n",
      "[84/1762] D loss: 1.3803, G loss: 0.6864\n",
      "[164/1762] D loss: 1.3881, G loss: 0.7251\n",
      "[244/1762] D loss: 1.3882, G loss: 0.6835\n",
      "[324/1762] D loss: 1.3663, G loss: 0.7214\n",
      "[404/1762] D loss: 1.3890, G loss: 0.6823\n",
      "[484/1762] D loss: 1.3866, G loss: 0.6481\n",
      "[564/1762] D loss: 1.3678, G loss: 0.6741\n",
      "[644/1762] D loss: 1.3859, G loss: 0.7221\n",
      "[724/1762] D loss: 1.3710, G loss: 0.7420\n",
      "[804/1762] D loss: 1.3872, G loss: 0.7064\n",
      "[884/1762] D loss: 1.3874, G loss: 0.6828\n",
      "[964/1762] D loss: 1.3877, G loss: 0.6686\n",
      "[1044/1762] D loss: 1.2711, G loss: 0.7187\n",
      "[1124/1762] D loss: 1.2149, G loss: 0.7499\n",
      "[1204/1762] D loss: 1.2307, G loss: 0.7510\n",
      "[1284/1762] D loss: 1.3340, G loss: 0.7299\n",
      "[1364/1762] D loss: 1.3922, G loss: 0.7145\n",
      "[1444/1762] D loss: 1.3738, G loss: 0.6353\n",
      "[1524/1762] D loss: 1.3926, G loss: 0.7115\n",
      "[1604/1762] D loss: 1.1422, G loss: 0.8652\n",
      "[1684/1762] D loss: 1.4098, G loss: 0.7637\n",
      "[1762/1762] D loss: 0.8192, G loss: 1.2462\n",
      "train error: \n",
      " D loss: 1.335732, G loss: 0.893307, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 89.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.310785, G loss: 0.909881, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 84.5% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1247, G loss: 1.0976\n",
      "[84/1762] D loss: 1.0779, G loss: 0.9383\n",
      "[164/1762] D loss: 1.3951, G loss: 0.6216\n",
      "[244/1762] D loss: 1.3877, G loss: 0.6513\n",
      "[324/1762] D loss: 1.1265, G loss: 0.8880\n",
      "[404/1762] D loss: 1.1293, G loss: 0.8759\n",
      "[484/1762] D loss: 1.3885, G loss: 0.7283\n",
      "[564/1762] D loss: 1.3739, G loss: 0.6244\n",
      "[644/1762] D loss: 1.1067, G loss: 1.0343\n",
      "[724/1762] D loss: 1.3977, G loss: 0.7068\n",
      "[804/1762] D loss: 1.4138, G loss: 0.5478\n",
      "[884/1762] D loss: 1.3956, G loss: 0.7563\n",
      "[964/1762] D loss: 1.4061, G loss: 0.7606\n",
      "[1044/1762] D loss: 1.3930, G loss: 0.7852\n",
      "[1124/1762] D loss: 1.3908, G loss: 0.6447\n",
      "[1204/1762] D loss: 1.3950, G loss: 0.7298\n",
      "[1284/1762] D loss: 1.0590, G loss: 0.9489\n",
      "[1364/1762] D loss: 1.3168, G loss: 0.8088\n",
      "[1444/1762] D loss: 1.3731, G loss: 0.6958\n",
      "[1524/1762] D loss: 1.4357, G loss: 1.1027\n",
      "[1604/1762] D loss: 1.4013, G loss: 0.7733\n",
      "[1684/1762] D loss: 0.9133, G loss: 0.9281\n",
      "[1762/1762] D loss: 0.8880, G loss: 0.8204\n",
      "train error: \n",
      " D loss: 1.288197, G loss: 0.751842, D accuracy: 61.2%, cell accuracy: 98.7%, board accuracy: 41.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.261642, G loss: 0.766048, D accuracy: 61.9%, cell accuracy: 98.5%, board accuracy: 36.6% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3845, G loss: 0.6954\n",
      "[84/1762] D loss: 1.3226, G loss: 0.8656\n",
      "[164/1762] D loss: 1.1997, G loss: 0.8107\n",
      "[244/1762] D loss: 1.0894, G loss: 1.1627\n",
      "[324/1762] D loss: 1.4029, G loss: 0.7608\n",
      "[404/1762] D loss: 0.7505, G loss: 1.3193\n",
      "[484/1762] D loss: 1.3934, G loss: 0.7594\n",
      "[564/1762] D loss: 1.0737, G loss: 0.9842\n",
      "[644/1762] D loss: 1.3759, G loss: 0.6631\n",
      "[724/1762] D loss: 1.3878, G loss: 0.6858\n",
      "[804/1762] D loss: 1.3899, G loss: 0.6502\n",
      "[884/1762] D loss: 1.0556, G loss: 1.1647\n",
      "[964/1762] D loss: 1.0578, G loss: 1.0640\n",
      "[1044/1762] D loss: 1.0935, G loss: 0.9233\n",
      "[1124/1762] D loss: 1.0857, G loss: 0.9640\n",
      "[1204/1762] D loss: 1.3875, G loss: 0.6982\n",
      "[1284/1762] D loss: 1.4067, G loss: 0.8377\n",
      "[1364/1762] D loss: 1.3831, G loss: 0.6496\n",
      "[1444/1762] D loss: 1.3830, G loss: 0.8173\n",
      "[1524/1762] D loss: 1.3899, G loss: 0.7200\n",
      "[1604/1762] D loss: 1.0772, G loss: 1.0221\n",
      "[1684/1762] D loss: 1.3861, G loss: 0.6670\n",
      "[1762/1762] D loss: 1.3834, G loss: 0.6970\n",
      "train error: \n",
      " D loss: 1.299442, G loss: 0.892741, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 90.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.265381, G loss: 0.951563, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3866, G loss: 0.6910\n",
      "[84/1762] D loss: 1.3750, G loss: 0.6983\n",
      "[164/1762] D loss: 1.3598, G loss: 0.6830\n",
      "[244/1762] D loss: 1.2812, G loss: 0.7399\n",
      "[324/1762] D loss: 1.1121, G loss: 1.0092\n",
      "[404/1762] D loss: 1.4199, G loss: 0.5847\n",
      "[484/1762] D loss: 1.3882, G loss: 0.6662\n",
      "[564/1762] D loss: 1.3892, G loss: 0.7350\n",
      "[644/1762] D loss: 1.3983, G loss: 0.5842\n",
      "[724/1762] D loss: 1.3905, G loss: 0.6867\n",
      "[804/1762] D loss: 1.0575, G loss: 1.1910\n",
      "[884/1762] D loss: 1.0778, G loss: 1.2261\n",
      "[964/1762] D loss: 1.0549, G loss: 1.3188\n",
      "[1044/1762] D loss: 1.3914, G loss: 0.6563\n",
      "[1124/1762] D loss: 1.2377, G loss: 1.1694\n",
      "[1204/1762] D loss: 1.3900, G loss: 0.6709\n",
      "[1284/1762] D loss: 1.0537, G loss: 1.2767\n",
      "[1364/1762] D loss: 1.3917, G loss: 0.7395\n",
      "[1444/1762] D loss: 1.3912, G loss: 0.6551\n",
      "[1524/1762] D loss: 1.3861, G loss: 0.6723\n",
      "[1604/1762] D loss: 1.0621, G loss: 1.4289\n",
      "[1684/1762] D loss: 1.4211, G loss: 0.6387\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.7312\n",
      "train error: \n",
      " D loss: 1.289451, G loss: 0.852390, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 80.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.260846, G loss: 0.887909, D accuracy: 55.5%, cell accuracy: 99.7%, board accuracy: 77.3% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3967, G loss: 0.7687\n",
      "[84/1762] D loss: 1.2682, G loss: 1.1321\n",
      "[164/1762] D loss: 1.0814, G loss: 1.1245\n",
      "[244/1762] D loss: 1.3565, G loss: 0.7757\n",
      "[324/1762] D loss: 1.0618, G loss: 1.1876\n",
      "[404/1762] D loss: 1.3862, G loss: 0.7029\n",
      "[484/1762] D loss: 1.3870, G loss: 0.6553\n",
      "[564/1762] D loss: 0.9947, G loss: 1.2207\n",
      "[644/1762] D loss: 1.3920, G loss: 0.6676\n",
      "[724/1762] D loss: 1.3879, G loss: 0.7320\n",
      "[804/1762] D loss: 1.3876, G loss: 0.7222\n",
      "[884/1762] D loss: 1.0564, G loss: 1.2549\n",
      "[964/1762] D loss: 1.3872, G loss: 0.7070\n",
      "[1044/1762] D loss: 1.3824, G loss: 0.7133\n",
      "[1124/1762] D loss: 1.3862, G loss: 0.7006\n",
      "[1204/1762] D loss: 1.3868, G loss: 0.6772\n",
      "[1284/1762] D loss: 1.3879, G loss: 0.7290\n",
      "[1364/1762] D loss: 1.0511, G loss: 1.4355\n",
      "[1444/1762] D loss: 1.0726, G loss: 1.1989\n",
      "[1524/1762] D loss: 1.3910, G loss: 0.7689\n",
      "[1604/1762] D loss: 0.9797, G loss: 1.4920\n",
      "[1684/1762] D loss: 1.3673, G loss: 0.6798\n",
      "[1762/1762] D loss: 1.0309, G loss: 1.2908\n",
      "train error: \n",
      " D loss: 1.281829, G loss: 0.763089, D accuracy: 58.0%, cell accuracy: 99.7%, board accuracy: 68.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.247630, G loss: 0.811178, D accuracy: 60.1%, cell accuracy: 99.6%, board accuracy: 61.8% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3370, G loss: 0.7083\n",
      "[84/1762] D loss: 0.9077, G loss: 1.9251\n",
      "[164/1762] D loss: 1.0665, G loss: 1.0504\n",
      "[244/1762] D loss: 1.2341, G loss: 0.9291\n",
      "[324/1762] D loss: 1.0465, G loss: 1.6267\n",
      "[404/1762] D loss: 1.3897, G loss: 0.6826\n",
      "[484/1762] D loss: 1.3833, G loss: 0.6538\n",
      "[564/1762] D loss: 1.3879, G loss: 0.6535\n",
      "[644/1762] D loss: 1.4439, G loss: 0.4687\n",
      "[724/1762] D loss: 1.3828, G loss: 0.6120\n",
      "[804/1762] D loss: 1.3868, G loss: 0.7011\n",
      "[884/1762] D loss: 1.3867, G loss: 0.6813\n",
      "[964/1762] D loss: 1.3919, G loss: 0.7573\n",
      "[1044/1762] D loss: 1.3877, G loss: 0.7053\n",
      "[1124/1762] D loss: 1.2115, G loss: 1.2785\n",
      "[1204/1762] D loss: 1.3873, G loss: 0.7064\n",
      "[1284/1762] D loss: 1.0492, G loss: 1.3448\n",
      "[1364/1762] D loss: 1.3923, G loss: 0.6518\n",
      "[1444/1762] D loss: 1.3877, G loss: 0.6837\n",
      "[1524/1762] D loss: 1.3323, G loss: 0.8348\n",
      "[1604/1762] D loss: 1.3901, G loss: 0.6930\n",
      "[1684/1762] D loss: 1.3919, G loss: 0.7256\n",
      "[1762/1762] D loss: 1.3916, G loss: 0.7335\n",
      "train error: \n",
      " D loss: 1.285462, G loss: 0.922126, D accuracy: 54.1%, cell accuracy: 99.9%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.256224, G loss: 0.977016, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3691, G loss: 0.7058\n",
      "[84/1762] D loss: 1.3948, G loss: 0.6444\n",
      "[164/1762] D loss: 1.3850, G loss: 0.6842\n",
      "[244/1762] D loss: 1.3839, G loss: 0.7077\n",
      "[324/1762] D loss: 1.3869, G loss: 0.6957\n",
      "[404/1762] D loss: 1.3869, G loss: 0.6982\n",
      "[484/1762] D loss: 1.4095, G loss: 0.7408\n",
      "[564/1762] D loss: 0.7188, G loss: 1.9848\n",
      "[644/1762] D loss: 0.7103, G loss: 2.0970\n",
      "[724/1762] D loss: 1.3904, G loss: 0.6390\n",
      "[804/1762] D loss: 1.3872, G loss: 0.7105\n",
      "[884/1762] D loss: 1.3937, G loss: 0.6803\n",
      "[964/1762] D loss: 0.8924, G loss: 2.1653\n",
      "[1044/1762] D loss: 1.3900, G loss: 0.7025\n",
      "[1124/1762] D loss: 1.3866, G loss: 0.6772\n",
      "[1204/1762] D loss: 0.8796, G loss: 2.5479\n",
      "[1284/1762] D loss: 1.3847, G loss: 0.6637\n",
      "[1364/1762] D loss: 1.3895, G loss: 0.7350\n",
      "[1444/1762] D loss: 1.3993, G loss: 0.8049\n",
      "[1524/1762] D loss: 1.4015, G loss: 0.6026\n",
      "[1604/1762] D loss: 1.3896, G loss: 0.6730\n",
      "[1684/1762] D loss: 1.0522, G loss: 1.3899\n",
      "[1762/1762] D loss: 1.4342, G loss: 0.7618\n",
      "train error: \n",
      " D loss: 1.301187, G loss: 0.913885, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 91.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.270680, G loss: 0.981162, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4007, G loss: 0.8001\n",
      "[84/1762] D loss: 1.3934, G loss: 0.7648\n",
      "[164/1762] D loss: 1.0487, G loss: 1.3981\n",
      "[244/1762] D loss: 1.3884, G loss: 0.7195\n",
      "[324/1762] D loss: 1.3870, G loss: 0.7039\n",
      "[404/1762] D loss: 1.3959, G loss: 0.6640\n",
      "[484/1762] D loss: 1.0525, G loss: 1.3617\n",
      "[564/1762] D loss: 1.3846, G loss: 0.7015\n",
      "[644/1762] D loss: 1.3866, G loss: 0.7237\n",
      "[724/1762] D loss: 1.3944, G loss: 0.7420\n",
      "[804/1762] D loss: 1.3855, G loss: 0.6917\n",
      "[884/1762] D loss: 1.3871, G loss: 0.6791\n",
      "[964/1762] D loss: 0.3591, G loss: 3.3151\n",
      "[1044/1762] D loss: 1.0457, G loss: 1.5686\n",
      "[1124/1762] D loss: 1.0463, G loss: 1.4388\n",
      "[1204/1762] D loss: 1.0460, G loss: 1.5108\n",
      "[1284/1762] D loss: 1.3909, G loss: 0.7494\n",
      "[1364/1762] D loss: 1.3879, G loss: 0.6642\n",
      "[1444/1762] D loss: 1.4204, G loss: 0.5625\n",
      "[1524/1762] D loss: 1.0509, G loss: 1.3941\n",
      "[1604/1762] D loss: 1.0448, G loss: 1.5301\n",
      "[1684/1762] D loss: 1.3879, G loss: 0.6729\n",
      "[1762/1762] D loss: 1.3870, G loss: 0.7113\n",
      "train error: \n",
      " D loss: 1.291156, G loss: 0.928354, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.259559, G loss: 1.018535, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6863\n",
      "[84/1762] D loss: 1.0443, G loss: 1.5203\n",
      "[164/1762] D loss: 1.3866, G loss: 0.6868\n",
      "[244/1762] D loss: 1.3870, G loss: 0.6813\n",
      "[324/1762] D loss: 1.3876, G loss: 0.6697\n",
      "[404/1762] D loss: 1.3876, G loss: 0.6914\n",
      "[484/1762] D loss: 1.3883, G loss: 0.6955\n",
      "[564/1762] D loss: 1.3871, G loss: 0.6854\n",
      "[644/1762] D loss: 1.0441, G loss: 1.7992\n",
      "[724/1762] D loss: 1.3893, G loss: 0.6745\n",
      "[804/1762] D loss: 1.3866, G loss: 0.6731\n",
      "[884/1762] D loss: 1.3920, G loss: 0.6755\n",
      "[964/1762] D loss: 1.0475, G loss: 1.3781\n",
      "[1044/1762] D loss: 0.7880, G loss: 1.7752\n",
      "[1124/1762] D loss: 1.3986, G loss: 0.7953\n",
      "[1204/1762] D loss: 1.3882, G loss: 0.7125\n",
      "[1284/1762] D loss: 1.3904, G loss: 0.6313\n",
      "[1364/1762] D loss: 1.3513, G loss: 0.7521\n",
      "[1444/1762] D loss: 1.3875, G loss: 0.7063\n",
      "[1524/1762] D loss: 1.2046, G loss: 1.5285\n",
      "[1604/1762] D loss: 1.3861, G loss: 0.6391\n",
      "[1684/1762] D loss: 1.3919, G loss: 0.7509\n",
      "[1762/1762] D loss: 1.3869, G loss: 0.6746\n",
      "train error: \n",
      " D loss: 1.295599, G loss: 0.938237, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.262180, G loss: 1.011448, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2359, G loss: 1.5370\n",
      "[84/1762] D loss: 1.2386, G loss: 0.7140\n",
      "[164/1762] D loss: 0.9524, G loss: 1.8154\n",
      "[244/1762] D loss: 1.3964, G loss: 0.6617\n",
      "[324/1762] D loss: 1.3897, G loss: 0.7787\n",
      "[404/1762] D loss: 1.3857, G loss: 0.6814\n",
      "[484/1762] D loss: 1.3855, G loss: 0.7046\n",
      "[564/1762] D loss: 1.4936, G loss: 1.9518\n",
      "[644/1762] D loss: 1.0591, G loss: 1.0783\n",
      "[724/1762] D loss: 1.2830, G loss: 0.7130\n",
      "[804/1762] D loss: 1.3394, G loss: 0.7159\n",
      "[884/1762] D loss: 1.4570, G loss: 0.6593\n",
      "[964/1762] D loss: 1.3959, G loss: 0.6765\n",
      "[1044/1762] D loss: 1.0622, G loss: 1.3145\n",
      "[1124/1762] D loss: 1.3904, G loss: 0.6907\n",
      "[1204/1762] D loss: 1.0548, G loss: 1.3309\n",
      "[1284/1762] D loss: 1.0435, G loss: 1.3023\n",
      "[1364/1762] D loss: 1.3897, G loss: 0.7295\n",
      "[1444/1762] D loss: 1.0564, G loss: 1.4248\n",
      "[1524/1762] D loss: 1.0508, G loss: 1.4573\n",
      "[1604/1762] D loss: 1.0722, G loss: 1.2273\n",
      "[1684/1762] D loss: 1.3886, G loss: 0.6891\n",
      "[1762/1762] D loss: 1.3878, G loss: 0.7230\n",
      "train error: \n",
      " D loss: 1.286725, G loss: 0.900287, D accuracy: 54.1%, cell accuracy: 99.9%, board accuracy: 91.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.259137, G loss: 0.967117, D accuracy: 55.6%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0514, G loss: 1.3853\n",
      "[84/1762] D loss: 1.3872, G loss: 0.6947\n",
      "[164/1762] D loss: 1.3875, G loss: 0.7063\n",
      "[244/1762] D loss: 1.0477, G loss: 1.5332\n",
      "[324/1762] D loss: 1.0525, G loss: 1.5191\n",
      "[404/1762] D loss: 1.0460, G loss: 1.5047\n",
      "[484/1762] D loss: 1.3900, G loss: 0.6430\n",
      "[564/1762] D loss: 1.3883, G loss: 0.6753\n",
      "[644/1762] D loss: 0.7019, G loss: 2.4405\n",
      "[724/1762] D loss: 1.3903, G loss: 0.6469\n",
      "[804/1762] D loss: 1.3910, G loss: 0.6399\n",
      "[884/1762] D loss: 1.3868, G loss: 0.6925\n",
      "[964/1762] D loss: 1.3878, G loss: 0.6736\n",
      "[1044/1762] D loss: 1.3877, G loss: 0.7367\n",
      "[1124/1762] D loss: 2.0741, G loss: 1.5673\n",
      "[1204/1762] D loss: 1.4146, G loss: 0.7723\n",
      "[1284/1762] D loss: 1.3878, G loss: 0.6724\n",
      "[1364/1762] D loss: 1.0559, G loss: 1.2213\n",
      "[1444/1762] D loss: 1.3877, G loss: 0.7078\n",
      "[1524/1762] D loss: 1.0488, G loss: 1.3932\n",
      "[1604/1762] D loss: 1.3861, G loss: 0.6932\n",
      "[1684/1762] D loss: 1.3876, G loss: 0.7251\n",
      "[1762/1762] D loss: 1.3874, G loss: 0.6967\n",
      "train error: \n",
      " D loss: 1.289260, G loss: 0.915697, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.263679, G loss: 0.984851, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3869, G loss: 0.7035\n",
      "[84/1762] D loss: 1.3868, G loss: 0.6929\n",
      "[164/1762] D loss: 1.3866, G loss: 0.6737\n",
      "[244/1762] D loss: 1.3871, G loss: 0.7179\n",
      "[324/1762] D loss: 1.0444, G loss: 1.5182\n",
      "[404/1762] D loss: 1.0454, G loss: 1.5005\n",
      "[484/1762] D loss: 1.3861, G loss: 0.7083\n",
      "[564/1762] D loss: 1.3885, G loss: 0.6980\n",
      "[644/1762] D loss: 1.3865, G loss: 0.7067\n",
      "[724/1762] D loss: 0.7015, G loss: 2.4541\n",
      "[804/1762] D loss: 1.3871, G loss: 0.7009\n",
      "[884/1762] D loss: 1.3968, G loss: 0.6384\n",
      "[964/1762] D loss: 1.3889, G loss: 0.6672\n",
      "[1044/1762] D loss: 0.7057, G loss: 2.1473\n",
      "[1124/1762] D loss: 1.2160, G loss: 1.4418\n",
      "[1204/1762] D loss: 1.0485, G loss: 1.4452\n",
      "[1284/1762] D loss: 1.3364, G loss: 0.7449\n",
      "[1364/1762] D loss: 1.3871, G loss: 0.7109\n",
      "[1444/1762] D loss: 1.0451, G loss: 1.6563\n",
      "[1524/1762] D loss: 1.0421, G loss: 1.7276\n",
      "[1604/1762] D loss: 0.7047, G loss: 2.4567\n",
      "[1684/1762] D loss: 1.3867, G loss: 0.6932\n",
      "[1762/1762] D loss: 0.1647, G loss: 3.7426\n",
      "train error: \n",
      " D loss: 1.326500, G loss: 0.889410, D accuracy: 53.1%, cell accuracy: 99.9%, board accuracy: 90.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.316728, G loss: 0.958456, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3868, G loss: 0.6723\n",
      "[84/1762] D loss: 1.4118, G loss: 0.6497\n",
      "[164/1762] D loss: 1.0464, G loss: 1.4893\n",
      "[244/1762] D loss: 1.0585, G loss: 1.3292\n",
      "[324/1762] D loss: 1.0263, G loss: 1.4504\n",
      "[404/1762] D loss: 1.3869, G loss: 0.7249\n",
      "[484/1762] D loss: 0.7030, G loss: 2.4834\n",
      "[564/1762] D loss: 1.3893, G loss: 0.7007\n",
      "[644/1762] D loss: 1.3860, G loss: 0.7027\n",
      "[724/1762] D loss: 1.3898, G loss: 0.6807\n",
      "[804/1762] D loss: 1.3887, G loss: 0.7183\n",
      "[884/1762] D loss: 1.3874, G loss: 0.6666\n",
      "[964/1762] D loss: 1.3863, G loss: 0.7162\n",
      "[1044/1762] D loss: 1.2187, G loss: 0.7718\n",
      "[1124/1762] D loss: 1.3304, G loss: 1.2737\n",
      "[1204/1762] D loss: 1.3872, G loss: 0.7053\n",
      "[1284/1762] D loss: 1.3876, G loss: 0.7064\n",
      "[1364/1762] D loss: 1.3919, G loss: 0.6607\n",
      "[1444/1762] D loss: 1.2868, G loss: 0.7585\n",
      "[1524/1762] D loss: 1.3906, G loss: 0.7220\n",
      "[1604/1762] D loss: 1.2120, G loss: 0.7225\n",
      "[1684/1762] D loss: 1.3996, G loss: 0.6880\n",
      "[1762/1762] D loss: 1.3943, G loss: 0.7230\n",
      "train error: \n",
      " D loss: 1.305383, G loss: 0.824135, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.281821, G loss: 0.847293, D accuracy: 55.9%, cell accuracy: 99.8%, board accuracy: 83.6% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1785, G loss: 0.9873\n",
      "[84/1762] D loss: 1.3872, G loss: 0.6801\n",
      "[164/1762] D loss: 1.3927, G loss: 0.7459\n",
      "[244/1762] D loss: 1.3887, G loss: 0.6978\n",
      "[324/1762] D loss: 1.3885, G loss: 0.7229\n",
      "[404/1762] D loss: 1.0566, G loss: 1.2434\n",
      "[484/1762] D loss: 1.0813, G loss: 1.2807\n",
      "[564/1762] D loss: 1.3891, G loss: 0.7295\n",
      "[644/1762] D loss: 1.3890, G loss: 0.6916\n",
      "[724/1762] D loss: 1.0509, G loss: 1.3367\n",
      "[804/1762] D loss: 1.3910, G loss: 0.6470\n",
      "[884/1762] D loss: 1.0462, G loss: 1.4946\n",
      "[964/1762] D loss: 1.0473, G loss: 1.4290\n",
      "[1044/1762] D loss: 1.3876, G loss: 0.6744\n",
      "[1124/1762] D loss: 1.3871, G loss: 0.6787\n",
      "[1204/1762] D loss: 1.3894, G loss: 0.7200\n",
      "[1284/1762] D loss: 0.7943, G loss: 2.3930\n",
      "[1364/1762] D loss: 1.3869, G loss: 0.6965\n",
      "[1444/1762] D loss: 1.3871, G loss: 0.6651\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.6829\n",
      "[1604/1762] D loss: 1.3866, G loss: 0.7028\n",
      "[1684/1762] D loss: 1.3870, G loss: 0.6850\n",
      "[1762/1762] D loss: 1.3893, G loss: 0.6477\n",
      "train error: \n",
      " D loss: 1.286531, G loss: 0.987561, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 90.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.257720, G loss: 1.070564, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3960, G loss: 0.6758\n",
      "[84/1762] D loss: 1.0279, G loss: 1.7636\n",
      "[164/1762] D loss: 1.4191, G loss: 0.7660\n",
      "[244/1762] D loss: 1.4378, G loss: 0.9346\n",
      "[324/1762] D loss: 1.3956, G loss: 0.7346\n",
      "[404/1762] D loss: 1.4272, G loss: 0.6716\n",
      "[484/1762] D loss: 1.3875, G loss: 0.6946\n",
      "[564/1762] D loss: 1.3890, G loss: 0.7212\n",
      "[644/1762] D loss: 1.0593, G loss: 1.2792\n",
      "[724/1762] D loss: 1.3926, G loss: 0.6277\n",
      "[804/1762] D loss: 1.3656, G loss: 0.7300\n",
      "[884/1762] D loss: 1.0700, G loss: 1.1422\n",
      "[964/1762] D loss: 1.0460, G loss: 1.7672\n",
      "[1044/1762] D loss: 1.0561, G loss: 1.3376\n",
      "[1124/1762] D loss: 1.3389, G loss: 1.0281\n",
      "[1204/1762] D loss: 1.2921, G loss: 0.7213\n",
      "[1284/1762] D loss: 1.3318, G loss: 1.0283\n",
      "[1364/1762] D loss: 1.0501, G loss: 1.4899\n",
      "[1444/1762] D loss: 1.3899, G loss: 0.7364\n",
      "[1524/1762] D loss: 1.3877, G loss: 0.6985\n",
      "[1604/1762] D loss: 1.3870, G loss: 0.6949\n",
      "[1684/1762] D loss: 1.0446, G loss: 1.5873\n",
      "[1762/1762] D loss: 1.3881, G loss: 0.6876\n",
      "train error: \n",
      " D loss: 1.303897, G loss: 1.094822, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 89.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.269459, G loss: 1.203187, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4000, G loss: 0.7955\n",
      "[84/1762] D loss: 1.3965, G loss: 0.8436\n",
      "[164/1762] D loss: 1.3884, G loss: 0.7234\n",
      "[244/1762] D loss: 1.3868, G loss: 0.6855\n",
      "[324/1762] D loss: 1.0588, G loss: 1.3473\n",
      "[404/1762] D loss: 1.3884, G loss: 0.6664\n",
      "[484/1762] D loss: 1.3859, G loss: 0.7001\n",
      "[564/1762] D loss: 1.3917, G loss: 0.6506\n",
      "[644/1762] D loss: 1.4033, G loss: 0.7133\n",
      "[724/1762] D loss: 1.3896, G loss: 0.7499\n",
      "[804/1762] D loss: 1.3868, G loss: 0.6775\n",
      "[884/1762] D loss: 1.0433, G loss: 1.6201\n",
      "[964/1762] D loss: 1.3875, G loss: 0.7013\n",
      "[1044/1762] D loss: 1.4395, G loss: 0.6531\n",
      "[1124/1762] D loss: 1.3874, G loss: 0.6759\n",
      "[1204/1762] D loss: 1.3919, G loss: 0.6373\n",
      "[1284/1762] D loss: 1.0481, G loss: 1.5482\n",
      "[1364/1762] D loss: 1.0468, G loss: 1.5497\n",
      "[1444/1762] D loss: 1.3891, G loss: 0.7355\n",
      "[1524/1762] D loss: 1.3861, G loss: 0.6898\n",
      "[1604/1762] D loss: 1.3871, G loss: 0.6734\n",
      "[1684/1762] D loss: 1.0436, G loss: 1.7274\n",
      "[1762/1762] D loss: 1.3869, G loss: 0.6879\n",
      "train error: \n",
      " D loss: 1.296160, G loss: 0.972552, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.264870, G loss: 1.077707, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3866, G loss: 0.6976\n",
      "[84/1762] D loss: 1.3877, G loss: 0.6637\n",
      "[164/1762] D loss: 1.3874, G loss: 0.7309\n",
      "[244/1762] D loss: 1.3866, G loss: 0.6853\n",
      "[324/1762] D loss: 1.3866, G loss: 0.6901\n",
      "[404/1762] D loss: 1.3870, G loss: 0.6801\n",
      "[484/1762] D loss: 1.3960, G loss: 0.7037\n",
      "[564/1762] D loss: 1.2009, G loss: 0.8185\n",
      "[644/1762] D loss: 0.9624, G loss: 1.3332\n",
      "[724/1762] D loss: 1.2777, G loss: 0.8232\n",
      "[804/1762] D loss: 1.3913, G loss: 0.7408\n",
      "[884/1762] D loss: 1.4043, G loss: 0.6764\n",
      "[964/1762] D loss: 1.4057, G loss: 0.7940\n",
      "[1044/1762] D loss: 0.7988, G loss: 1.2145\n",
      "[1124/1762] D loss: 1.4017, G loss: 0.5928\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6959\n",
      "[1284/1762] D loss: 1.4090, G loss: 0.8287\n",
      "[1364/1762] D loss: 1.3932, G loss: 0.7666\n",
      "[1444/1762] D loss: 1.3851, G loss: 0.6777\n",
      "[1524/1762] D loss: 1.3895, G loss: 0.6903\n",
      "[1604/1762] D loss: 1.3946, G loss: 0.6280\n",
      "[1684/1762] D loss: 1.3904, G loss: 0.6729\n",
      "[1762/1762] D loss: 1.3861, G loss: 0.7027\n",
      "train error: \n",
      " D loss: 1.310412, G loss: 0.892936, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 89.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.284676, G loss: 0.960376, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3877, G loss: 0.6924\n",
      "[84/1762] D loss: 1.0471, G loss: 1.4329\n",
      "[164/1762] D loss: 1.3835, G loss: 0.7037\n",
      "[244/1762] D loss: 1.3866, G loss: 0.6900\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6971\n",
      "[404/1762] D loss: 1.3912, G loss: 0.7511\n",
      "[484/1762] D loss: 1.3840, G loss: 0.6952\n",
      "[564/1762] D loss: 1.3865, G loss: 0.6870\n",
      "[644/1762] D loss: 1.3875, G loss: 0.6931\n",
      "[724/1762] D loss: 1.3895, G loss: 0.6427\n",
      "[804/1762] D loss: 1.3922, G loss: 0.7678\n",
      "[884/1762] D loss: 1.3904, G loss: 0.7394\n",
      "[964/1762] D loss: 1.3915, G loss: 0.6413\n",
      "[1044/1762] D loss: 1.0511, G loss: 1.5093\n",
      "[1124/1762] D loss: 1.0452, G loss: 1.5368\n",
      "[1204/1762] D loss: 1.3872, G loss: 0.7379\n",
      "[1284/1762] D loss: 1.1089, G loss: 1.0444\n",
      "[1364/1762] D loss: 1.1814, G loss: 0.9252\n",
      "[1444/1762] D loss: 1.3818, G loss: 0.6883\n",
      "[1524/1762] D loss: 1.0060, G loss: 1.4478\n",
      "[1604/1762] D loss: 1.0516, G loss: 1.8012\n",
      "[1684/1762] D loss: 1.3867, G loss: 0.6741\n",
      "[1762/1762] D loss: 1.3897, G loss: 0.6936\n",
      "train error: \n",
      " D loss: 1.292726, G loss: 0.880639, D accuracy: 55.9%, cell accuracy: 99.8%, board accuracy: 82.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.267660, G loss: 0.939567, D accuracy: 56.5%, cell accuracy: 99.8%, board accuracy: 83.0% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0658, G loss: 1.3008\n",
      "[84/1762] D loss: 1.0510, G loss: 1.6025\n",
      "[164/1762] D loss: 1.3885, G loss: 0.7095\n",
      "[244/1762] D loss: 1.3795, G loss: 0.7801\n",
      "[324/1762] D loss: 1.3851, G loss: 0.6505\n",
      "[404/1762] D loss: 1.2287, G loss: 0.8962\n",
      "[484/1762] D loss: 1.4302, G loss: 0.6289\n",
      "[564/1762] D loss: 1.4045, G loss: 0.7572\n",
      "[644/1762] D loss: 1.3913, G loss: 0.7443\n",
      "[724/1762] D loss: 1.3895, G loss: 0.7137\n",
      "[804/1762] D loss: 1.3887, G loss: 0.6734\n",
      "[884/1762] D loss: 1.0872, G loss: 1.6413\n",
      "[964/1762] D loss: 1.3874, G loss: 0.7129\n",
      "[1044/1762] D loss: 1.3883, G loss: 0.6593\n",
      "[1124/1762] D loss: 1.3877, G loss: 0.6751\n",
      "[1204/1762] D loss: 1.3879, G loss: 0.7318\n",
      "[1284/1762] D loss: 1.4217, G loss: 0.5441\n",
      "[1364/1762] D loss: 1.0553, G loss: 1.8991\n",
      "[1444/1762] D loss: 1.2729, G loss: 0.8592\n",
      "[1524/1762] D loss: 1.3853, G loss: 0.6655\n",
      "[1604/1762] D loss: 1.3882, G loss: 0.6732\n",
      "[1684/1762] D loss: 1.3914, G loss: 0.7656\n",
      "[1762/1762] D loss: 1.3952, G loss: 0.7673\n",
      "train error: \n",
      " D loss: 1.292044, G loss: 1.099975, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.280904, G loss: 1.185215, D accuracy: 54.4%, cell accuracy: 99.7%, board accuracy: 85.9% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1386, G loss: 2.0516\n",
      "[84/1762] D loss: 1.3955, G loss: 0.6075\n",
      "[164/1762] D loss: 1.3950, G loss: 0.6218\n",
      "[244/1762] D loss: 1.3850, G loss: 0.7624\n",
      "[324/1762] D loss: 1.0621, G loss: 1.8437\n",
      "[404/1762] D loss: 1.3882, G loss: 0.7368\n",
      "[484/1762] D loss: 1.3909, G loss: 0.7088\n",
      "[564/1762] D loss: 1.0502, G loss: 1.8809\n",
      "[644/1762] D loss: 1.3880, G loss: 0.6703\n",
      "[724/1762] D loss: 1.3869, G loss: 0.6755\n",
      "[804/1762] D loss: 1.3864, G loss: 0.7052\n",
      "[884/1762] D loss: 1.0414, G loss: 1.8604\n",
      "[964/1762] D loss: 1.3569, G loss: 0.6767\n",
      "[1044/1762] D loss: 1.3905, G loss: 0.7252\n",
      "[1124/1762] D loss: 1.3880, G loss: 0.7019\n",
      "[1204/1762] D loss: 1.2559, G loss: 1.1920\n",
      "[1284/1762] D loss: 1.3913, G loss: 0.6443\n",
      "[1364/1762] D loss: 1.3984, G loss: 0.6177\n",
      "[1444/1762] D loss: 1.0791, G loss: 1.6743\n",
      "[1524/1762] D loss: 1.3367, G loss: 0.7426\n",
      "[1604/1762] D loss: 0.6576, G loss: 2.3466\n",
      "[1684/1762] D loss: 1.3973, G loss: 0.7698\n",
      "[1762/1762] D loss: 1.2554, G loss: 0.8309\n",
      "train error: \n",
      " D loss: 1.313224, G loss: 0.916596, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 90.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.293431, G loss: 0.974229, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3867, G loss: 0.7081\n",
      "[84/1762] D loss: 1.3904, G loss: 0.7084\n",
      "[164/1762] D loss: 1.3443, G loss: 1.6054\n",
      "[244/1762] D loss: 1.3887, G loss: 0.7302\n",
      "[324/1762] D loss: 0.9128, G loss: 1.6880\n",
      "[404/1762] D loss: 1.3865, G loss: 0.6956\n",
      "[484/1762] D loss: 1.0456, G loss: 1.6792\n",
      "[564/1762] D loss: 1.3926, G loss: 0.6225\n",
      "[644/1762] D loss: 1.0977, G loss: 1.1582\n",
      "[724/1762] D loss: 1.3887, G loss: 0.6480\n",
      "[804/1762] D loss: 1.3876, G loss: 0.6678\n",
      "[884/1762] D loss: 1.3895, G loss: 0.6512\n",
      "[964/1762] D loss: 1.3872, G loss: 0.7083\n",
      "[1044/1762] D loss: 1.3865, G loss: 0.6997\n",
      "[1124/1762] D loss: 1.5174, G loss: 0.4462\n",
      "[1204/1762] D loss: 1.3902, G loss: 0.7179\n",
      "[1284/1762] D loss: 1.3987, G loss: 0.6074\n",
      "[1364/1762] D loss: 1.1983, G loss: 1.5496\n",
      "[1444/1762] D loss: 1.3836, G loss: 0.6792\n",
      "[1524/1762] D loss: 1.3895, G loss: 0.7052\n",
      "[1604/1762] D loss: 1.3873, G loss: 0.7214\n",
      "[1684/1762] D loss: 1.0517, G loss: 1.8517\n",
      "[1762/1762] D loss: 1.3913, G loss: 0.6663\n",
      "train error: \n",
      " D loss: 1.294979, G loss: 0.931986, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.271409, G loss: 0.987786, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3873, G loss: 0.6931\n",
      "[84/1762] D loss: 1.0437, G loss: 1.7019\n",
      "[164/1762] D loss: 1.3874, G loss: 0.6629\n",
      "[244/1762] D loss: 1.3869, G loss: 0.6839\n",
      "[324/1762] D loss: 1.3870, G loss: 0.6780\n",
      "[404/1762] D loss: 1.2702, G loss: 0.7678\n",
      "[484/1762] D loss: 1.3956, G loss: 0.7166\n",
      "[564/1762] D loss: 1.3899, G loss: 0.6457\n",
      "[644/1762] D loss: 1.3963, G loss: 0.6965\n",
      "[724/1762] D loss: 1.3865, G loss: 0.6965\n",
      "[804/1762] D loss: 1.0428, G loss: 1.7035\n",
      "[884/1762] D loss: 1.0505, G loss: 1.7171\n",
      "[964/1762] D loss: 1.3870, G loss: 0.6682\n",
      "[1044/1762] D loss: 1.3875, G loss: 0.6776\n",
      "[1124/1762] D loss: 1.0420, G loss: 1.8465\n",
      "[1204/1762] D loss: 0.6965, G loss: 2.9162\n",
      "[1284/1762] D loss: 1.3871, G loss: 0.6766\n",
      "[1364/1762] D loss: 1.3872, G loss: 0.6784\n",
      "[1444/1762] D loss: 1.3898, G loss: 0.6474\n",
      "[1524/1762] D loss: 1.3893, G loss: 0.7221\n",
      "[1604/1762] D loss: 1.3898, G loss: 0.6293\n",
      "[1684/1762] D loss: 1.3872, G loss: 0.6945\n",
      "[1762/1762] D loss: 1.3871, G loss: 0.7235\n",
      "train error: \n",
      " D loss: 1.291896, G loss: 1.049585, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.267425, G loss: 1.145888, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3869, G loss: 0.7093\n",
      "[84/1762] D loss: 1.3867, G loss: 0.6802\n",
      "[164/1762] D loss: 1.3927, G loss: 0.6390\n",
      "[244/1762] D loss: 1.3866, G loss: 0.6779\n",
      "[324/1762] D loss: 1.0473, G loss: 1.6810\n",
      "[404/1762] D loss: 1.3891, G loss: 0.6706\n",
      "[484/1762] D loss: 1.4985, G loss: 1.8500\n",
      "[564/1762] D loss: 1.4049, G loss: 0.7109\n",
      "[644/1762] D loss: 1.3926, G loss: 0.6363\n",
      "[724/1762] D loss: 1.3880, G loss: 0.6982\n",
      "[804/1762] D loss: 1.9576, G loss: 0.5882\n",
      "[884/1762] D loss: 1.2199, G loss: 0.9277\n",
      "[964/1762] D loss: 1.3844, G loss: 0.8202\n",
      "[1044/1762] D loss: 1.0827, G loss: 1.3941\n",
      "[1124/1762] D loss: 1.3168, G loss: 0.6955\n",
      "[1204/1762] D loss: 1.3887, G loss: 0.6932\n",
      "[1284/1762] D loss: 1.0486, G loss: 1.6144\n",
      "[1364/1762] D loss: 1.1429, G loss: 0.8928\n",
      "[1444/1762] D loss: 1.2498, G loss: 1.2134\n",
      "[1524/1762] D loss: 1.3806, G loss: 0.6307\n",
      "[1604/1762] D loss: 0.7713, G loss: 2.4474\n",
      "[1684/1762] D loss: 1.0644, G loss: 1.7345\n",
      "[1762/1762] D loss: 1.3902, G loss: 0.6159\n",
      "train error: \n",
      " D loss: 1.301896, G loss: 0.990291, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 91.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.278921, G loss: 1.058210, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0958, G loss: 0.9935\n",
      "[84/1762] D loss: 1.3867, G loss: 0.6697\n",
      "[164/1762] D loss: 1.3873, G loss: 0.7080\n",
      "[244/1762] D loss: 1.0483, G loss: 1.8043\n",
      "[324/1762] D loss: 1.3950, G loss: 0.6586\n",
      "[404/1762] D loss: 0.7987, G loss: 1.8691\n",
      "[484/1762] D loss: 1.0481, G loss: 1.7219\n",
      "[564/1762] D loss: 1.0482, G loss: 1.6643\n",
      "[644/1762] D loss: 1.3874, G loss: 0.6920\n",
      "[724/1762] D loss: 1.3868, G loss: 0.7095\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6892\n",
      "[884/1762] D loss: 1.0442, G loss: 1.7290\n",
      "[964/1762] D loss: 1.3896, G loss: 0.7075\n",
      "[1044/1762] D loss: 1.3867, G loss: 0.6763\n",
      "[1124/1762] D loss: 1.3870, G loss: 0.6864\n",
      "[1204/1762] D loss: 1.0422, G loss: 1.7616\n",
      "[1284/1762] D loss: 1.3877, G loss: 0.7051\n",
      "[1364/1762] D loss: 1.3868, G loss: 0.7194\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6979\n",
      "[1524/1762] D loss: 1.3873, G loss: 0.7194\n",
      "[1604/1762] D loss: 1.3881, G loss: 0.6751\n",
      "[1684/1762] D loss: 1.0592, G loss: 1.8053\n",
      "[1762/1762] D loss: 1.0126, G loss: 1.2461\n",
      "train error: \n",
      " D loss: 1.249338, G loss: 1.008633, D accuracy: 58.8%, cell accuracy: 99.3%, board accuracy: 72.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.237389, G loss: 1.081952, D accuracy: 59.4%, cell accuracy: 99.3%, board accuracy: 70.7% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2115, G loss: 0.9043\n",
      "[84/1762] D loss: 1.2065, G loss: 1.3942\n",
      "[164/1762] D loss: 1.3998, G loss: 0.6679\n",
      "[244/1762] D loss: 1.3898, G loss: 0.6593\n",
      "[324/1762] D loss: 1.2330, G loss: 1.0731\n",
      "[404/1762] D loss: 1.3872, G loss: 0.6812\n",
      "[484/1762] D loss: 1.3866, G loss: 0.6897\n",
      "[564/1762] D loss: 1.3906, G loss: 0.6623\n",
      "[644/1762] D loss: 1.3898, G loss: 0.7510\n",
      "[724/1762] D loss: 1.3870, G loss: 0.7120\n",
      "[804/1762] D loss: 1.3871, G loss: 0.6787\n",
      "[884/1762] D loss: 1.3963, G loss: 0.6869\n",
      "[964/1762] D loss: 1.3870, G loss: 0.6714\n",
      "[1044/1762] D loss: 1.0452, G loss: 1.7616\n",
      "[1124/1762] D loss: 1.3887, G loss: 0.6701\n",
      "[1204/1762] D loss: 1.0438, G loss: 1.7170\n",
      "[1284/1762] D loss: 1.3871, G loss: 0.7192\n",
      "[1364/1762] D loss: 1.3866, G loss: 0.6990\n",
      "[1444/1762] D loss: 0.7210, G loss: 2.1982\n",
      "[1524/1762] D loss: 1.3881, G loss: 0.6685\n",
      "[1604/1762] D loss: 1.3952, G loss: 0.6438\n",
      "[1684/1762] D loss: 1.3941, G loss: 0.6209\n",
      "[1762/1762] D loss: 1.3725, G loss: 0.6527\n",
      "train error: \n",
      " D loss: 1.292952, G loss: 0.991327, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 85.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.267268, G loss: 1.077985, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 84.1% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0458, G loss: 1.7840\n",
      "[84/1762] D loss: 1.3838, G loss: 0.6786\n",
      "[164/1762] D loss: 1.3872, G loss: 0.6849\n",
      "[244/1762] D loss: 0.6946, G loss: 3.3628\n",
      "[324/1762] D loss: 1.3134, G loss: 0.6640\n",
      "[404/1762] D loss: 1.3971, G loss: 0.6102\n",
      "[484/1762] D loss: 1.0130, G loss: 1.6793\n",
      "[564/1762] D loss: 1.2434, G loss: 1.2878\n",
      "[644/1762] D loss: 1.3872, G loss: 0.6731\n",
      "[724/1762] D loss: 1.3090, G loss: 1.0416\n",
      "[804/1762] D loss: 1.3968, G loss: 0.7492\n",
      "[884/1762] D loss: 1.3822, G loss: 0.6980\n",
      "[964/1762] D loss: 1.0456, G loss: 1.5086\n",
      "[1044/1762] D loss: 1.3890, G loss: 0.6563\n",
      "[1124/1762] D loss: 1.3876, G loss: 0.6999\n",
      "[1204/1762] D loss: 1.3621, G loss: 0.7031\n",
      "[1284/1762] D loss: 1.3874, G loss: 0.6923\n",
      "[1364/1762] D loss: 1.1907, G loss: 2.4890\n",
      "[1444/1762] D loss: 1.3877, G loss: 0.6712\n",
      "[1524/1762] D loss: 1.3828, G loss: 0.6730\n",
      "[1604/1762] D loss: 1.2975, G loss: 0.8285\n",
      "[1684/1762] D loss: 1.3426, G loss: 0.7650\n",
      "[1762/1762] D loss: 1.3887, G loss: 0.6625\n",
      "train error: \n",
      " D loss: 1.290979, G loss: 1.018183, D accuracy: 54.2%, cell accuracy: 99.9%, board accuracy: 89.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.271829, G loss: 1.123619, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3822, G loss: 0.6726\n",
      "[84/1762] D loss: 0.9421, G loss: 1.7967\n",
      "[164/1762] D loss: 1.3908, G loss: 0.6463\n",
      "[244/1762] D loss: 1.0426, G loss: 2.0553\n",
      "[324/1762] D loss: 1.4235, G loss: 0.7776\n",
      "[404/1762] D loss: 1.3945, G loss: 0.6043\n",
      "[484/1762] D loss: 1.3896, G loss: 0.6447\n",
      "[564/1762] D loss: 1.3985, G loss: 0.7820\n",
      "[644/1762] D loss: 1.3868, G loss: 0.6923\n",
      "[724/1762] D loss: 1.3879, G loss: 0.7238\n",
      "[804/1762] D loss: 1.3868, G loss: 0.6647\n",
      "[884/1762] D loss: 1.3854, G loss: 0.7056\n",
      "[964/1762] D loss: 1.0445, G loss: 1.9404\n",
      "[1044/1762] D loss: 1.3877, G loss: 0.7036\n",
      "[1124/1762] D loss: 1.3878, G loss: 0.6598\n",
      "[1204/1762] D loss: 1.0413, G loss: 1.9620\n",
      "[1284/1762] D loss: 1.3865, G loss: 0.6850\n",
      "[1364/1762] D loss: 1.3877, G loss: 0.6957\n",
      "[1444/1762] D loss: 1.3882, G loss: 0.7156\n",
      "[1524/1762] D loss: 1.0408, G loss: 1.9687\n",
      "[1604/1762] D loss: 1.0414, G loss: 1.8776\n",
      "[1684/1762] D loss: 1.0444, G loss: 1.9894\n",
      "[1762/1762] D loss: 1.3869, G loss: 0.7124\n",
      "train error: \n",
      " D loss: 1.299478, G loss: 1.053701, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.264878, G loss: 1.160833, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3868, G loss: 0.6980\n",
      "[84/1762] D loss: 1.0448, G loss: 1.7126\n",
      "[164/1762] D loss: 1.3864, G loss: 0.7017\n",
      "[244/1762] D loss: 1.2149, G loss: 1.7778\n",
      "[324/1762] D loss: 1.3870, G loss: 0.7162\n",
      "[404/1762] D loss: 1.3868, G loss: 0.7060\n",
      "[484/1762] D loss: 1.0439, G loss: 1.8433\n",
      "[564/1762] D loss: 1.3863, G loss: 0.6895\n",
      "[644/1762] D loss: 1.3872, G loss: 0.7049\n",
      "[724/1762] D loss: 1.3606, G loss: 0.7332\n",
      "[804/1762] D loss: 0.6953, G loss: 3.1042\n",
      "[884/1762] D loss: 1.0428, G loss: 1.9306\n",
      "[964/1762] D loss: 0.7122, G loss: 2.7559\n",
      "[1044/1762] D loss: 1.3702, G loss: 0.7144\n",
      "[1124/1762] D loss: 1.3867, G loss: 0.6704\n",
      "[1204/1762] D loss: 1.3869, G loss: 0.7140\n",
      "[1284/1762] D loss: 1.3862, G loss: 0.6881\n",
      "[1364/1762] D loss: 1.0470, G loss: 1.4656\n",
      "[1444/1762] D loss: 1.3886, G loss: 0.7269\n",
      "[1524/1762] D loss: 1.3835, G loss: 0.7023\n",
      "[1604/1762] D loss: 1.3895, G loss: 0.6425\n",
      "[1684/1762] D loss: 0.7211, G loss: 2.4493\n",
      "[1762/1762] D loss: 1.3877, G loss: 0.6962\n",
      "train error: \n",
      " D loss: 1.292060, G loss: 0.978404, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.267411, G loss: 1.058092, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3866, G loss: 0.6818\n",
      "[84/1762] D loss: 1.3866, G loss: 0.6964\n",
      "[164/1762] D loss: 1.3846, G loss: 0.6842\n",
      "[244/1762] D loss: 1.2842, G loss: 0.8125\n",
      "[324/1762] D loss: 1.3879, G loss: 0.6564\n",
      "[404/1762] D loss: 1.2981, G loss: 0.7941\n",
      "[484/1762] D loss: 1.3887, G loss: 0.7262\n",
      "[564/1762] D loss: 1.3908, G loss: 0.6412\n",
      "[644/1762] D loss: 1.3777, G loss: 0.6432\n",
      "[724/1762] D loss: 1.2309, G loss: 1.2693\n",
      "[804/1762] D loss: 1.3876, G loss: 0.6708\n",
      "[884/1762] D loss: 1.0563, G loss: 1.5479\n",
      "[964/1762] D loss: 1.3899, G loss: 0.6790\n",
      "[1044/1762] D loss: 1.3874, G loss: 0.7171\n",
      "[1124/1762] D loss: 1.2238, G loss: 1.0716\n",
      "[1204/1762] D loss: 0.7254, G loss: 3.2376\n",
      "[1284/1762] D loss: 1.3648, G loss: 0.6418\n",
      "[1364/1762] D loss: 1.0449, G loss: 1.5214\n",
      "[1444/1762] D loss: 1.3935, G loss: 0.6482\n",
      "[1524/1762] D loss: 1.0420, G loss: 1.8403\n",
      "[1604/1762] D loss: 1.3885, G loss: 0.6823\n",
      "[1684/1762] D loss: 1.3009, G loss: 0.8230\n",
      "[1762/1762] D loss: 1.6787, G loss: 0.3387\n",
      "train error: \n",
      " D loss: 1.309545, G loss: 0.914270, D accuracy: 56.1%, cell accuracy: 99.6%, board accuracy: 62.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.264815, G loss: 1.021581, D accuracy: 58.0%, cell accuracy: 99.6%, board accuracy: 58.6% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5116, G loss: 0.4623\n",
      "[84/1762] D loss: 1.3945, G loss: 0.6200\n",
      "[164/1762] D loss: 1.4013, G loss: 0.8073\n",
      "[244/1762] D loss: 1.4049, G loss: 0.6983\n",
      "[324/1762] D loss: 1.3888, G loss: 0.7609\n",
      "[404/1762] D loss: 1.3876, G loss: 0.6746\n",
      "[484/1762] D loss: 1.3902, G loss: 0.6657\n",
      "[564/1762] D loss: 1.3877, G loss: 0.7132\n",
      "[644/1762] D loss: 1.3864, G loss: 0.7002\n",
      "[724/1762] D loss: 1.0480, G loss: 1.4305\n",
      "[804/1762] D loss: 1.3387, G loss: 0.7803\n",
      "[884/1762] D loss: 1.0646, G loss: 1.1444\n",
      "[964/1762] D loss: 1.4114, G loss: 0.5771\n",
      "[1044/1762] D loss: 1.3914, G loss: 0.6178\n",
      "[1124/1762] D loss: 1.3871, G loss: 0.7107\n",
      "[1204/1762] D loss: 1.2648, G loss: 0.6955\n",
      "[1284/1762] D loss: 1.3879, G loss: 0.7060\n",
      "[1364/1762] D loss: 1.3899, G loss: 0.6478\n",
      "[1444/1762] D loss: 1.2739, G loss: 0.7475\n",
      "[1524/1762] D loss: 1.3883, G loss: 0.6407\n",
      "[1604/1762] D loss: 1.3260, G loss: 0.7775\n",
      "[1684/1762] D loss: 1.3870, G loss: 0.6821\n",
      "[1762/1762] D loss: 1.3300, G loss: 0.6844\n",
      "train error: \n",
      " D loss: 1.280810, G loss: 1.026794, D accuracy: 56.5%, cell accuracy: 99.7%, board accuracy: 82.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.263206, G loss: 1.174388, D accuracy: 58.0%, cell accuracy: 99.6%, board accuracy: 79.5% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4002, G loss: 0.5763\n",
      "[84/1762] D loss: 1.3874, G loss: 0.6898\n",
      "[164/1762] D loss: 1.3870, G loss: 0.7106\n",
      "[244/1762] D loss: 1.4322, G loss: 0.9119\n",
      "[324/1762] D loss: 1.0349, G loss: 1.7366\n",
      "[404/1762] D loss: 1.0913, G loss: 1.0277\n",
      "[484/1762] D loss: 1.3299, G loss: 0.7812\n",
      "[564/1762] D loss: 1.0600, G loss: 1.2283\n",
      "[644/1762] D loss: 1.3869, G loss: 0.7212\n",
      "[724/1762] D loss: 1.0620, G loss: 1.1519\n",
      "[804/1762] D loss: 1.3866, G loss: 0.7040\n",
      "[884/1762] D loss: 1.3878, G loss: 0.6766\n",
      "[964/1762] D loss: 1.3869, G loss: 0.7093\n",
      "[1044/1762] D loss: 1.2781, G loss: 0.9210\n",
      "[1124/1762] D loss: 1.0533, G loss: 1.3334\n",
      "[1204/1762] D loss: 1.3870, G loss: 0.6847\n",
      "[1284/1762] D loss: 1.3870, G loss: 0.7100\n",
      "[1364/1762] D loss: 1.3921, G loss: 0.6567\n",
      "[1444/1762] D loss: 1.0556, G loss: 1.3110\n",
      "[1524/1762] D loss: 1.0574, G loss: 1.2188\n",
      "[1604/1762] D loss: 1.0537, G loss: 1.2999\n",
      "[1684/1762] D loss: 1.3867, G loss: 0.6922\n",
      "[1762/1762] D loss: 1.3902, G loss: 0.6349\n",
      "train error: \n",
      " D loss: 1.305035, G loss: 0.793845, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.289305, G loss: 0.838124, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3879, G loss: 0.6574\n",
      "[84/1762] D loss: 1.3869, G loss: 0.6785\n",
      "[164/1762] D loss: 1.3875, G loss: 0.7017\n",
      "[244/1762] D loss: 1.0801, G loss: 0.9974\n",
      "[324/1762] D loss: 1.0462, G loss: 1.3995\n",
      "[404/1762] D loss: 1.3876, G loss: 0.6738\n",
      "[484/1762] D loss: 1.3876, G loss: 0.7105\n",
      "[564/1762] D loss: 1.3861, G loss: 0.6561\n",
      "[644/1762] D loss: 1.3864, G loss: 0.7006\n",
      "[724/1762] D loss: 0.3714, G loss: 3.0179\n",
      "[804/1762] D loss: 1.3872, G loss: 0.6860\n",
      "[884/1762] D loss: 1.0664, G loss: 1.1476\n",
      "[964/1762] D loss: 1.3907, G loss: 0.7486\n",
      "[1044/1762] D loss: 1.3870, G loss: 0.6850\n",
      "[1124/1762] D loss: 1.3910, G loss: 0.6732\n",
      "[1204/1762] D loss: 1.0408, G loss: 2.0661\n",
      "[1284/1762] D loss: 1.3868, G loss: 0.6543\n",
      "[1364/1762] D loss: 1.3883, G loss: 0.6863\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.6773\n",
      "[1524/1762] D loss: 1.3914, G loss: 0.6403\n",
      "[1604/1762] D loss: 1.3910, G loss: 0.7381\n",
      "[1684/1762] D loss: 1.3865, G loss: 0.6882\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.6983\n",
      "train error: \n",
      " D loss: 1.306002, G loss: 0.920379, D accuracy: 53.4%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.294354, G loss: 0.999892, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.7310\n",
      "[84/1762] D loss: 1.2114, G loss: 0.7924\n",
      "[164/1762] D loss: 0.5643, G loss: 1.5385\n",
      "[244/1762] D loss: 0.4648, G loss: 3.4138\n",
      "[324/1762] D loss: 0.4579, G loss: 4.7303\n",
      "[404/1762] D loss: 0.4111, G loss: 3.6939\n",
      "[484/1762] D loss: 0.3342, G loss: 2.8887\n",
      "[564/1762] D loss: 0.8006, G loss: 2.3475\n",
      "[644/1762] D loss: 0.7118, G loss: 2.0098\n",
      "[724/1762] D loss: 0.8978, G loss: 1.0018\n",
      "[804/1762] D loss: 1.5431, G loss: 2.2102\n",
      "[884/1762] D loss: 0.8391, G loss: 1.0098\n",
      "[964/1762] D loss: 1.0557, G loss: 1.2880\n",
      "[1044/1762] D loss: 1.1487, G loss: 1.0130\n",
      "[1124/1762] D loss: 1.3811, G loss: 0.8192\n",
      "[1204/1762] D loss: 1.5141, G loss: 2.1171\n",
      "[1284/1762] D loss: 0.9923, G loss: 0.4976\n",
      "[1364/1762] D loss: 0.9661, G loss: 1.2034\n",
      "[1444/1762] D loss: 1.2343, G loss: 0.8229\n",
      "[1524/1762] D loss: 1.5951, G loss: 1.7320\n",
      "[1604/1762] D loss: 1.3117, G loss: 1.2776\n",
      "[1684/1762] D loss: 1.3882, G loss: 0.9054\n",
      "[1762/1762] D loss: 0.7061, G loss: 1.2655\n",
      "train error: \n",
      " D loss: 1.012727, G loss: 0.963957, D accuracy: 82.5%, cell accuracy: 97.8%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.025347, G loss: 0.975298, D accuracy: 83.3%, cell accuracy: 97.8%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8812, G loss: 1.2442\n",
      "[84/1762] D loss: 1.9310, G loss: 1.0646\n",
      "[164/1762] D loss: 1.2255, G loss: 0.9620\n",
      "[244/1762] D loss: 1.0694, G loss: 1.2589\n",
      "[324/1762] D loss: 1.3052, G loss: 0.6989\n",
      "[404/1762] D loss: 1.2226, G loss: 0.5264\n",
      "[484/1762] D loss: 1.1541, G loss: 1.3796\n",
      "[564/1762] D loss: 1.2134, G loss: 0.5703\n",
      "[644/1762] D loss: 1.1945, G loss: 0.7091\n",
      "[724/1762] D loss: 1.1817, G loss: 1.0133\n",
      "[804/1762] D loss: 1.3688, G loss: 0.6346\n",
      "[884/1762] D loss: 1.3006, G loss: 0.7952\n",
      "[964/1762] D loss: 1.2316, G loss: 1.1523\n",
      "[1044/1762] D loss: 1.3585, G loss: 0.9703\n",
      "[1124/1762] D loss: 1.3349, G loss: 0.7901\n",
      "[1204/1762] D loss: 1.3765, G loss: 1.4229\n",
      "[1284/1762] D loss: 1.3540, G loss: 0.9635\n",
      "[1364/1762] D loss: 1.3975, G loss: 0.7240\n",
      "[1444/1762] D loss: 1.3893, G loss: 0.5134\n",
      "[1524/1762] D loss: 1.3704, G loss: 0.4950\n",
      "[1604/1762] D loss: 1.2981, G loss: 0.7780\n",
      "[1684/1762] D loss: 1.3640, G loss: 0.7634\n",
      "[1762/1762] D loss: 1.3180, G loss: 0.6728\n",
      "train error: \n",
      " D loss: 1.355548, G loss: 0.653436, D accuracy: 57.9%, cell accuracy: 99.6%, board accuracy: 71.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.358590, G loss: 0.652154, D accuracy: 57.6%, cell accuracy: 99.5%, board accuracy: 71.4% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3841, G loss: 0.4999\n",
      "[84/1762] D loss: 1.4206, G loss: 0.4760\n",
      "[164/1762] D loss: 1.3636, G loss: 0.8409\n",
      "[244/1762] D loss: 1.3513, G loss: 0.7543\n",
      "[324/1762] D loss: 1.3178, G loss: 0.7444\n",
      "[404/1762] D loss: 1.3215, G loss: 0.6771\n",
      "[484/1762] D loss: 1.4690, G loss: 0.7734\n",
      "[564/1762] D loss: 1.2934, G loss: 0.6558\n",
      "[644/1762] D loss: 1.3635, G loss: 0.7877\n",
      "[724/1762] D loss: 1.3366, G loss: 0.6525\n",
      "[804/1762] D loss: 1.3367, G loss: 0.7339\n",
      "[884/1762] D loss: 1.3168, G loss: 0.6764\n",
      "[964/1762] D loss: 1.4285, G loss: 0.5404\n",
      "[1044/1762] D loss: 1.3346, G loss: 0.7724\n",
      "[1124/1762] D loss: 1.4612, G loss: 0.9178\n",
      "[1204/1762] D loss: 1.3713, G loss: 0.9319\n",
      "[1284/1762] D loss: 1.3739, G loss: 0.8545\n",
      "[1364/1762] D loss: 1.4754, G loss: 0.5154\n",
      "[1444/1762] D loss: 1.3536, G loss: 0.7759\n",
      "[1524/1762] D loss: 1.1978, G loss: 0.6688\n",
      "[1604/1762] D loss: 1.2845, G loss: 0.7073\n",
      "[1684/1762] D loss: 1.2209, G loss: 1.0865\n",
      "[1762/1762] D loss: 1.4469, G loss: 0.8611\n",
      "train error: \n",
      " D loss: 1.340515, G loss: 0.849881, D accuracy: 56.9%, cell accuracy: 99.6%, board accuracy: 73.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.338716, G loss: 0.841828, D accuracy: 58.5%, cell accuracy: 99.6%, board accuracy: 72.3% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3667, G loss: 0.7028\n",
      "[84/1762] D loss: 1.2851, G loss: 0.7194\n",
      "[164/1762] D loss: 1.3339, G loss: 0.6922\n",
      "[244/1762] D loss: 1.3115, G loss: 0.4410\n",
      "[324/1762] D loss: 1.3249, G loss: 0.4522\n",
      "[404/1762] D loss: 1.3993, G loss: 0.4799\n",
      "[484/1762] D loss: 1.3445, G loss: 0.6790\n",
      "[564/1762] D loss: 1.3933, G loss: 0.7697\n",
      "[644/1762] D loss: 1.3447, G loss: 0.8097\n",
      "[724/1762] D loss: 1.4154, G loss: 0.8287\n",
      "[804/1762] D loss: 1.2758, G loss: 0.7076\n",
      "[884/1762] D loss: 1.3961, G loss: 0.7584\n",
      "[964/1762] D loss: 1.3899, G loss: 0.6998\n",
      "[1044/1762] D loss: 1.2002, G loss: 0.6727\n",
      "[1124/1762] D loss: 1.4122, G loss: 0.7039\n",
      "[1204/1762] D loss: 1.4271, G loss: 0.6269\n",
      "[1284/1762] D loss: 1.3966, G loss: 0.5075\n",
      "[1364/1762] D loss: 1.3885, G loss: 0.6585\n",
      "[1444/1762] D loss: 1.2926, G loss: 0.7634\n",
      "[1524/1762] D loss: 1.0333, G loss: 1.0829\n",
      "[1604/1762] D loss: 1.7383, G loss: 1.0282\n",
      "[1684/1762] D loss: 1.4876, G loss: 0.6210\n",
      "[1762/1762] D loss: 1.5140, G loss: 0.8071\n",
      "train error: \n",
      " D loss: 1.388554, G loss: 0.663306, D accuracy: 52.3%, cell accuracy: 99.6%, board accuracy: 67.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.389200, G loss: 0.661761, D accuracy: 52.2%, cell accuracy: 99.6%, board accuracy: 68.9% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4529, G loss: 0.6485\n",
      "[84/1762] D loss: 1.3954, G loss: 0.6659\n",
      "[164/1762] D loss: 1.3667, G loss: 0.7699\n",
      "[244/1762] D loss: 1.3414, G loss: 0.7176\n",
      "[324/1762] D loss: 1.3194, G loss: 0.7503\n",
      "[404/1762] D loss: 1.2642, G loss: 0.8311\n",
      "[484/1762] D loss: 1.2840, G loss: 0.6564\n",
      "[564/1762] D loss: 1.3947, G loss: 0.6632\n",
      "[644/1762] D loss: 1.3797, G loss: 0.6054\n",
      "[724/1762] D loss: 1.4081, G loss: 0.6093\n",
      "[804/1762] D loss: 1.3358, G loss: 0.9279\n",
      "[884/1762] D loss: 1.3816, G loss: 0.5747\n",
      "[964/1762] D loss: 1.3510, G loss: 0.8541\n",
      "[1044/1762] D loss: 1.3843, G loss: 0.6761\n",
      "[1124/1762] D loss: 1.3912, G loss: 0.5843\n",
      "[1204/1762] D loss: 1.3873, G loss: 0.6444\n",
      "[1284/1762] D loss: 1.3174, G loss: 0.7892\n",
      "[1364/1762] D loss: 1.4205, G loss: 0.6525\n",
      "[1444/1762] D loss: 1.3436, G loss: 0.7719\n",
      "[1524/1762] D loss: 1.4135, G loss: 0.6504\n",
      "[1604/1762] D loss: 1.2559, G loss: 0.8901\n",
      "[1684/1762] D loss: 1.3852, G loss: 0.6444\n",
      "[1762/1762] D loss: 1.3931, G loss: 0.6855\n",
      "train error: \n",
      " D loss: 1.346992, G loss: 0.727689, D accuracy: 54.1%, cell accuracy: 99.7%, board accuracy: 75.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.337436, G loss: 0.727866, D accuracy: 55.1%, cell accuracy: 99.6%, board accuracy: 71.1% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3476, G loss: 0.7270\n",
      "[84/1762] D loss: 1.3937, G loss: 0.7327\n",
      "[164/1762] D loss: 1.3318, G loss: 0.7245\n",
      "[244/1762] D loss: 1.3943, G loss: 0.7882\n",
      "[324/1762] D loss: 1.4234, G loss: 0.5797\n",
      "[404/1762] D loss: 1.3283, G loss: 0.6981\n",
      "[484/1762] D loss: 1.3770, G loss: 0.8353\n",
      "[564/1762] D loss: 1.4216, G loss: 0.7149\n",
      "[644/1762] D loss: 1.3818, G loss: 0.6534\n",
      "[724/1762] D loss: 1.2077, G loss: 0.8338\n",
      "[804/1762] D loss: 1.4028, G loss: 0.8054\n",
      "[884/1762] D loss: 1.0244, G loss: 0.9834\n",
      "[964/1762] D loss: 1.1831, G loss: 0.8636\n",
      "[1044/1762] D loss: 1.3851, G loss: 0.7889\n",
      "[1124/1762] D loss: 1.2769, G loss: 0.6255\n",
      "[1204/1762] D loss: 1.0616, G loss: 0.9435\n",
      "[1284/1762] D loss: 1.6146, G loss: 0.9886\n",
      "[1364/1762] D loss: 1.3877, G loss: 0.9203\n",
      "[1444/1762] D loss: 1.2791, G loss: 0.6587\n",
      "[1524/1762] D loss: 1.3292, G loss: 0.7761\n",
      "[1604/1762] D loss: 1.1964, G loss: 0.8934\n",
      "[1684/1762] D loss: 1.3587, G loss: 0.9367\n",
      "[1762/1762] D loss: 1.3933, G loss: 0.6908\n",
      "train error: \n",
      " D loss: 1.332896, G loss: 0.691255, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 85.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.322698, G loss: 0.694422, D accuracy: 56.6%, cell accuracy: 99.7%, board accuracy: 82.0% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1530, G loss: 0.7982\n",
      "[84/1762] D loss: 1.1379, G loss: 0.9569\n",
      "[164/1762] D loss: 1.4016, G loss: 0.5461\n",
      "[244/1762] D loss: 1.4131, G loss: 0.8472\n",
      "[324/1762] D loss: 1.1991, G loss: 0.7533\n",
      "[404/1762] D loss: 1.4096, G loss: 0.6025\n",
      "[484/1762] D loss: 1.2216, G loss: 0.7136\n",
      "[564/1762] D loss: 1.3904, G loss: 0.6317\n",
      "[644/1762] D loss: 1.3947, G loss: 0.8425\n",
      "[724/1762] D loss: 1.4191, G loss: 0.8334\n",
      "[804/1762] D loss: 1.3775, G loss: 0.7915\n",
      "[884/1762] D loss: 1.3872, G loss: 0.6451\n",
      "[964/1762] D loss: 1.4536, G loss: 0.4540\n",
      "[1044/1762] D loss: 1.1812, G loss: 0.8821\n",
      "[1124/1762] D loss: 1.3972, G loss: 0.6359\n",
      "[1204/1762] D loss: 1.4320, G loss: 0.6003\n",
      "[1284/1762] D loss: 1.3880, G loss: 0.7233\n",
      "[1364/1762] D loss: 1.2062, G loss: 0.8160\n",
      "[1444/1762] D loss: 1.3850, G loss: 0.7484\n",
      "[1524/1762] D loss: 1.4037, G loss: 0.7519\n",
      "[1604/1762] D loss: 1.4085, G loss: 0.6186\n",
      "[1684/1762] D loss: 1.3521, G loss: 0.8257\n",
      "[1762/1762] D loss: 1.4054, G loss: 0.8177\n",
      "train error: \n",
      " D loss: 1.325782, G loss: 0.767110, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 81.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.309751, G loss: 0.773437, D accuracy: 56.5%, cell accuracy: 99.7%, board accuracy: 78.0% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3962, G loss: 0.6438\n",
      "[84/1762] D loss: 1.4051, G loss: 0.7678\n",
      "[164/1762] D loss: 1.3896, G loss: 0.6471\n",
      "[244/1762] D loss: 1.3897, G loss: 0.7393\n",
      "[324/1762] D loss: 1.3928, G loss: 0.5560\n",
      "[404/1762] D loss: 1.3990, G loss: 0.5517\n",
      "[484/1762] D loss: 1.4083, G loss: 0.5795\n",
      "[564/1762] D loss: 1.3981, G loss: 0.7557\n",
      "[644/1762] D loss: 1.4135, G loss: 0.7847\n",
      "[724/1762] D loss: 1.3815, G loss: 0.6864\n",
      "[804/1762] D loss: 0.9136, G loss: 0.9913\n",
      "[884/1762] D loss: 1.3955, G loss: 0.7064\n",
      "[964/1762] D loss: 1.4033, G loss: 0.5360\n",
      "[1044/1762] D loss: 1.3570, G loss: 0.7400\n",
      "[1124/1762] D loss: 1.3907, G loss: 0.7200\n",
      "[1204/1762] D loss: 1.3872, G loss: 0.7766\n",
      "[1284/1762] D loss: 1.3926, G loss: 0.6874\n",
      "[1364/1762] D loss: 1.3983, G loss: 0.6562\n",
      "[1444/1762] D loss: 1.1453, G loss: 1.0489\n",
      "[1524/1762] D loss: 1.5380, G loss: 1.0879\n",
      "[1604/1762] D loss: 1.3873, G loss: 0.6649\n",
      "[1684/1762] D loss: 1.3883, G loss: 0.7730\n",
      "[1762/1762] D loss: 0.8919, G loss: 0.9642\n",
      "train error: \n",
      " D loss: 1.324074, G loss: 0.790204, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 82.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.307569, G loss: 0.799574, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 77.3% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3873, G loss: 0.6778\n",
      "[84/1762] D loss: 1.4255, G loss: 0.5454\n",
      "[164/1762] D loss: 1.4039, G loss: 0.7710\n",
      "[244/1762] D loss: 1.3304, G loss: 0.7566\n",
      "[324/1762] D loss: 1.3463, G loss: 0.7530\n",
      "[404/1762] D loss: 1.4049, G loss: 0.7958\n",
      "[484/1762] D loss: 1.1135, G loss: 0.7284\n",
      "[564/1762] D loss: 1.1849, G loss: 0.7051\n",
      "[644/1762] D loss: 1.1429, G loss: 0.7967\n",
      "[724/1762] D loss: 1.1700, G loss: 0.7714\n",
      "[804/1762] D loss: 1.3689, G loss: 0.6332\n",
      "[884/1762] D loss: 1.3953, G loss: 0.6992\n",
      "[964/1762] D loss: 1.4436, G loss: 0.6000\n",
      "[1044/1762] D loss: 1.3847, G loss: 0.7220\n",
      "[1124/1762] D loss: 1.3726, G loss: 1.0423\n",
      "[1204/1762] D loss: 1.3788, G loss: 0.7436\n",
      "[1284/1762] D loss: 1.3301, G loss: 0.7216\n",
      "[1364/1762] D loss: 1.3784, G loss: 0.7226\n",
      "[1444/1762] D loss: 1.3117, G loss: 0.6563\n",
      "[1524/1762] D loss: 1.3883, G loss: 0.7294\n",
      "[1604/1762] D loss: 1.3887, G loss: 0.7354\n",
      "[1684/1762] D loss: 1.3868, G loss: 0.7511\n",
      "[1762/1762] D loss: 1.3882, G loss: 0.6853\n",
      "train error: \n",
      " D loss: 1.338645, G loss: 0.721561, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 81.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.329416, G loss: 0.725258, D accuracy: 56.5%, cell accuracy: 99.7%, board accuracy: 79.8% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3585, G loss: 0.7149\n",
      "[84/1762] D loss: 1.3889, G loss: 0.7404\n",
      "[164/1762] D loss: 1.3887, G loss: 0.6532\n",
      "[244/1762] D loss: 1.3900, G loss: 0.6528\n",
      "[324/1762] D loss: 1.3992, G loss: 0.6778\n",
      "[404/1762] D loss: 1.4209, G loss: 0.5713\n",
      "[484/1762] D loss: 1.1745, G loss: 0.8711\n",
      "[564/1762] D loss: 1.3889, G loss: 0.6320\n",
      "[644/1762] D loss: 1.3838, G loss: 0.7524\n",
      "[724/1762] D loss: 1.4115, G loss: 0.8298\n",
      "[804/1762] D loss: 1.3857, G loss: 0.6553\n",
      "[884/1762] D loss: 1.3908, G loss: 0.6818\n",
      "[964/1762] D loss: 1.3908, G loss: 0.6482\n",
      "[1044/1762] D loss: 1.3809, G loss: 0.6682\n",
      "[1124/1762] D loss: 1.1785, G loss: 0.7337\n",
      "[1204/1762] D loss: 1.4000, G loss: 0.8003\n",
      "[1284/1762] D loss: 1.1873, G loss: 0.7940\n",
      "[1364/1762] D loss: 1.3956, G loss: 0.7499\n",
      "[1444/1762] D loss: 1.3993, G loss: 0.7873\n",
      "[1524/1762] D loss: 1.4704, G loss: 0.9151\n",
      "[1604/1762] D loss: 1.4114, G loss: 0.8056\n",
      "[1684/1762] D loss: 1.1419, G loss: 0.9396\n",
      "[1762/1762] D loss: 1.3778, G loss: 0.7756\n",
      "train error: \n",
      " D loss: 1.327350, G loss: 0.850932, D accuracy: 53.8%, cell accuracy: 99.7%, board accuracy: 79.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.309332, G loss: 0.861572, D accuracy: 55.2%, cell accuracy: 99.7%, board accuracy: 76.6% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4102, G loss: 0.9123\n",
      "[84/1762] D loss: 1.4179, G loss: 0.6500\n",
      "[164/1762] D loss: 1.3910, G loss: 0.7457\n",
      "[244/1762] D loss: 1.3977, G loss: 0.6806\n",
      "[324/1762] D loss: 1.1515, G loss: 0.8139\n",
      "[404/1762] D loss: 1.3862, G loss: 0.7541\n",
      "[484/1762] D loss: 1.1828, G loss: 0.7687\n",
      "[564/1762] D loss: 1.0986, G loss: 0.8136\n",
      "[644/1762] D loss: 1.3985, G loss: 0.6532\n",
      "[724/1762] D loss: 1.3915, G loss: 0.6795\n",
      "[804/1762] D loss: 1.3781, G loss: 0.7733\n",
      "[884/1762] D loss: 1.3881, G loss: 0.5832\n",
      "[964/1762] D loss: 1.4070, G loss: 0.5877\n",
      "[1044/1762] D loss: 1.4826, G loss: 0.6617\n",
      "[1124/1762] D loss: 1.6380, G loss: 0.7216\n",
      "[1204/1762] D loss: 1.0555, G loss: 0.8760\n",
      "[1284/1762] D loss: 1.4264, G loss: 0.7342\n",
      "[1364/1762] D loss: 1.4204, G loss: 0.9046\n",
      "[1444/1762] D loss: 1.3867, G loss: 0.8406\n",
      "[1524/1762] D loss: 1.4009, G loss: 0.8095\n",
      "[1604/1762] D loss: 1.3908, G loss: 0.6471\n",
      "[1684/1762] D loss: 1.3884, G loss: 0.7140\n",
      "[1762/1762] D loss: 1.3875, G loss: 0.6759\n",
      "train error: \n",
      " D loss: 1.373796, G loss: 0.694352, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 83.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.372191, G loss: 0.695409, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 80.9% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3839, G loss: 0.7107\n",
      "[84/1762] D loss: 1.3226, G loss: 0.6746\n",
      "[164/1762] D loss: 1.3908, G loss: 0.7283\n",
      "[244/1762] D loss: 1.4020, G loss: 0.7713\n",
      "[324/1762] D loss: 1.2415, G loss: 0.7293\n",
      "[404/1762] D loss: 1.2435, G loss: 0.7296\n",
      "[484/1762] D loss: 1.3646, G loss: 0.7170\n",
      "[564/1762] D loss: 1.3843, G loss: 0.6649\n",
      "[644/1762] D loss: 1.3985, G loss: 0.6887\n",
      "[724/1762] D loss: 1.3904, G loss: 0.6553\n",
      "[804/1762] D loss: 1.3950, G loss: 0.6009\n",
      "[884/1762] D loss: 1.3948, G loss: 0.7101\n",
      "[964/1762] D loss: 1.3965, G loss: 0.7874\n",
      "[1044/1762] D loss: 1.7568, G loss: 0.6691\n",
      "[1124/1762] D loss: 1.3057, G loss: 0.7612\n",
      "[1204/1762] D loss: 1.1041, G loss: 1.1007\n",
      "[1284/1762] D loss: 1.3702, G loss: 0.7123\n",
      "[1364/1762] D loss: 1.3950, G loss: 0.7893\n",
      "[1444/1762] D loss: 1.3885, G loss: 0.6691\n",
      "[1524/1762] D loss: 1.3867, G loss: 0.7453\n",
      "[1604/1762] D loss: 1.3874, G loss: 0.7010\n",
      "[1684/1762] D loss: 1.3909, G loss: 0.7509\n",
      "[1762/1762] D loss: 1.2063, G loss: 0.7737\n",
      "train error: \n",
      " D loss: 1.363886, G loss: 0.711798, D accuracy: 54.6%, cell accuracy: 99.6%, board accuracy: 65.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.362175, G loss: 0.715650, D accuracy: 54.8%, cell accuracy: 99.5%, board accuracy: 60.9% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3871, G loss: 0.6651\n",
      "[84/1762] D loss: 1.4061, G loss: 0.7502\n",
      "[164/1762] D loss: 1.2326, G loss: 0.7524\n",
      "[244/1762] D loss: 1.3862, G loss: 0.6649\n",
      "[324/1762] D loss: 1.3814, G loss: 0.7430\n",
      "[404/1762] D loss: 1.3140, G loss: 0.8777\n",
      "[484/1762] D loss: 1.2016, G loss: 0.8314\n",
      "[564/1762] D loss: 1.3950, G loss: 0.6839\n",
      "[644/1762] D loss: 1.3944, G loss: 0.7011\n",
      "[724/1762] D loss: 1.3898, G loss: 0.7456\n",
      "[804/1762] D loss: 1.3411, G loss: 0.6378\n",
      "[884/1762] D loss: 1.3916, G loss: 0.6847\n",
      "[964/1762] D loss: 1.3543, G loss: 0.7109\n",
      "[1044/1762] D loss: 1.1791, G loss: 0.9364\n",
      "[1124/1762] D loss: 1.4220, G loss: 0.7643\n",
      "[1204/1762] D loss: 1.4510, G loss: 0.5438\n",
      "[1284/1762] D loss: 1.1934, G loss: 0.8241\n",
      "[1364/1762] D loss: 1.2268, G loss: 0.6270\n",
      "[1444/1762] D loss: 1.4102, G loss: 0.6912\n",
      "[1524/1762] D loss: 1.1574, G loss: 0.8792\n",
      "[1604/1762] D loss: 1.3680, G loss: 0.7189\n",
      "[1684/1762] D loss: 1.2898, G loss: 0.6787\n",
      "[1762/1762] D loss: 1.4223, G loss: 0.7849\n",
      "train error: \n",
      " D loss: 1.350821, G loss: 0.622960, D accuracy: 55.9%, cell accuracy: 99.3%, board accuracy: 52.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.344301, G loss: 0.631121, D accuracy: 55.2%, cell accuracy: 99.3%, board accuracy: 46.8% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3954, G loss: 0.6558\n",
      "[84/1762] D loss: 1.4567, G loss: 0.5427\n",
      "[164/1762] D loss: 1.4959, G loss: 0.8765\n",
      "[244/1762] D loss: 1.3969, G loss: 0.7254\n",
      "[324/1762] D loss: 1.4069, G loss: 0.6408\n",
      "[404/1762] D loss: 1.3870, G loss: 0.6780\n",
      "[484/1762] D loss: 1.4114, G loss: 0.6652\n",
      "[564/1762] D loss: 1.4166, G loss: 0.5234\n",
      "[644/1762] D loss: 1.0780, G loss: 1.0148\n",
      "[724/1762] D loss: 1.1084, G loss: 0.9736\n",
      "[804/1762] D loss: 1.5072, G loss: 1.0430\n",
      "[884/1762] D loss: 1.2120, G loss: 0.7542\n",
      "[964/1762] D loss: 1.3490, G loss: 0.8450\n",
      "[1044/1762] D loss: 1.3938, G loss: 0.6027\n",
      "[1124/1762] D loss: 1.3921, G loss: 0.6516\n",
      "[1204/1762] D loss: 1.3896, G loss: 0.7021\n",
      "[1284/1762] D loss: 1.3875, G loss: 0.6408\n",
      "[1364/1762] D loss: 0.8667, G loss: 1.0431\n",
      "[1444/1762] D loss: 1.3866, G loss: 0.8305\n",
      "[1524/1762] D loss: 1.1448, G loss: 0.7760\n",
      "[1604/1762] D loss: 1.4828, G loss: 0.4799\n",
      "[1684/1762] D loss: 1.4128, G loss: 0.7977\n",
      "[1762/1762] D loss: 1.3895, G loss: 0.7582\n",
      "train error: \n",
      " D loss: 1.316405, G loss: 0.889480, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 85.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.296957, G loss: 0.901259, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 81.8% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3953, G loss: 0.7910\n",
      "[84/1762] D loss: 1.3687, G loss: 0.6856\n",
      "[164/1762] D loss: 1.1331, G loss: 0.9737\n",
      "[244/1762] D loss: 1.3910, G loss: 0.7375\n",
      "[324/1762] D loss: 1.3888, G loss: 0.7079\n",
      "[404/1762] D loss: 1.2848, G loss: 0.7253\n",
      "[484/1762] D loss: 1.1251, G loss: 0.9659\n",
      "[564/1762] D loss: 1.3868, G loss: 0.6839\n",
      "[644/1762] D loss: 1.3758, G loss: 0.7065\n",
      "[724/1762] D loss: 1.4394, G loss: 0.5628\n",
      "[804/1762] D loss: 1.3338, G loss: 0.7360\n",
      "[884/1762] D loss: 1.4056, G loss: 0.8131\n",
      "[964/1762] D loss: 1.0991, G loss: 0.9768\n",
      "[1044/1762] D loss: 1.3907, G loss: 0.6754\n",
      "[1124/1762] D loss: 1.0912, G loss: 1.0410\n",
      "[1204/1762] D loss: 1.4862, G loss: 0.6773\n",
      "[1284/1762] D loss: 1.3080, G loss: 0.9164\n",
      "[1364/1762] D loss: 1.0947, G loss: 1.0632\n",
      "[1444/1762] D loss: 1.4044, G loss: 0.6871\n",
      "[1524/1762] D loss: 1.4301, G loss: 0.9904\n",
      "[1604/1762] D loss: 1.4078, G loss: 0.6470\n",
      "[1684/1762] D loss: 1.3868, G loss: 0.7578\n",
      "[1762/1762] D loss: 1.4382, G loss: 0.8257\n",
      "train error: \n",
      " D loss: 1.315483, G loss: 0.808471, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 86.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.298239, G loss: 0.814381, D accuracy: 56.4%, cell accuracy: 99.7%, board accuracy: 82.5% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1517, G loss: 0.8514\n",
      "[84/1762] D loss: 1.3909, G loss: 0.8084\n",
      "[164/1762] D loss: 1.3864, G loss: 0.6850\n",
      "[244/1762] D loss: 1.3568, G loss: 0.7652\n",
      "[324/1762] D loss: 1.3951, G loss: 0.7197\n",
      "[404/1762] D loss: 1.1649, G loss: 0.7642\n",
      "[484/1762] D loss: 1.0785, G loss: 1.0871\n",
      "[564/1762] D loss: 1.1160, G loss: 0.9213\n",
      "[644/1762] D loss: 1.5328, G loss: 0.8942\n",
      "[724/1762] D loss: 1.4190, G loss: 0.6019\n",
      "[804/1762] D loss: 1.3831, G loss: 0.7962\n",
      "[884/1762] D loss: 1.3946, G loss: 0.7079\n",
      "[964/1762] D loss: 1.4219, G loss: 0.5974\n",
      "[1044/1762] D loss: 1.3954, G loss: 0.9339\n",
      "[1124/1762] D loss: 1.3922, G loss: 0.6025\n",
      "[1204/1762] D loss: 1.3793, G loss: 0.6940\n",
      "[1284/1762] D loss: 0.7657, G loss: 1.0821\n",
      "[1364/1762] D loss: 1.1301, G loss: 0.8451\n",
      "[1444/1762] D loss: 1.4010, G loss: 0.8329\n",
      "[1524/1762] D loss: 0.9967, G loss: 1.1283\n",
      "[1604/1762] D loss: 1.3882, G loss: 0.6857\n",
      "[1684/1762] D loss: 0.7639, G loss: 1.4382\n",
      "[1762/1762] D loss: 1.3926, G loss: 0.6731\n",
      "train error: \n",
      " D loss: 1.299607, G loss: 0.783462, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 87.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.274462, G loss: 0.817097, D accuracy: 55.8%, cell accuracy: 99.7%, board accuracy: 83.4% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0808, G loss: 0.9884\n",
      "[84/1762] D loss: 1.3892, G loss: 0.7642\n",
      "[164/1762] D loss: 1.0439, G loss: 1.0232\n",
      "[244/1762] D loss: 1.4076, G loss: 0.5605\n",
      "[324/1762] D loss: 1.2004, G loss: 0.8122\n",
      "[404/1762] D loss: 1.6337, G loss: 0.4886\n",
      "[484/1762] D loss: 1.3881, G loss: 0.9929\n",
      "[564/1762] D loss: 1.1154, G loss: 0.9078\n",
      "[644/1762] D loss: 1.3792, G loss: 0.7422\n",
      "[724/1762] D loss: 1.4138, G loss: 0.5669\n",
      "[804/1762] D loss: 1.2316, G loss: 0.9959\n",
      "[884/1762] D loss: 1.5011, G loss: 1.3395\n",
      "[964/1762] D loss: 0.7319, G loss: 1.3725\n",
      "[1044/1762] D loss: 0.9347, G loss: 1.2661\n",
      "[1124/1762] D loss: 1.3943, G loss: 0.6841\n",
      "[1204/1762] D loss: 1.3677, G loss: 0.7641\n",
      "[1284/1762] D loss: 1.3961, G loss: 0.6905\n",
      "[1364/1762] D loss: 1.3976, G loss: 0.6980\n",
      "[1444/1762] D loss: 1.3960, G loss: 0.7299\n",
      "[1524/1762] D loss: 1.0684, G loss: 1.1621\n",
      "[1604/1762] D loss: 1.3877, G loss: 0.7254\n",
      "[1684/1762] D loss: 1.2866, G loss: 0.9149\n",
      "[1762/1762] D loss: 1.3858, G loss: 0.6472\n",
      "train error: \n",
      " D loss: 1.284837, G loss: 0.798216, D accuracy: 55.6%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.251878, G loss: 0.855774, D accuracy: 56.5%, cell accuracy: 99.7%, board accuracy: 84.5% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3936, G loss: 0.6043\n",
      "[84/1762] D loss: 1.0788, G loss: 1.0005\n",
      "[164/1762] D loss: 1.3904, G loss: 0.6410\n",
      "[244/1762] D loss: 1.3995, G loss: 0.7960\n",
      "[324/1762] D loss: 1.3872, G loss: 0.7111\n",
      "[404/1762] D loss: 1.3929, G loss: 0.6975\n",
      "[484/1762] D loss: 1.0707, G loss: 1.0698\n",
      "[564/1762] D loss: 1.3902, G loss: 0.6620\n",
      "[644/1762] D loss: 1.3902, G loss: 0.7842\n",
      "[724/1762] D loss: 1.0789, G loss: 1.0793\n",
      "[804/1762] D loss: 1.4035, G loss: 0.6452\n",
      "[884/1762] D loss: 1.4131, G loss: 0.5994\n",
      "[964/1762] D loss: 1.2954, G loss: 1.2241\n",
      "[1044/1762] D loss: 1.3854, G loss: 0.7249\n",
      "[1124/1762] D loss: 1.3983, G loss: 0.8205\n",
      "[1204/1762] D loss: 1.1333, G loss: 0.9158\n",
      "[1284/1762] D loss: 1.4035, G loss: 0.6035\n",
      "[1364/1762] D loss: 1.1522, G loss: 0.9771\n",
      "[1444/1762] D loss: 1.3978, G loss: 0.6069\n",
      "[1524/1762] D loss: 1.1696, G loss: 1.0820\n",
      "[1604/1762] D loss: 1.3958, G loss: 0.7153\n",
      "[1684/1762] D loss: 1.3906, G loss: 0.7226\n",
      "[1762/1762] D loss: 1.3972, G loss: 0.7912\n",
      "train error: \n",
      " D loss: 1.280333, G loss: 0.978348, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.248836, G loss: 1.025673, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 84.8% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4095, G loss: 0.8103\n",
      "[84/1762] D loss: 1.3027, G loss: 0.8049\n",
      "[164/1762] D loss: 1.3935, G loss: 0.6481\n",
      "[244/1762] D loss: 1.3231, G loss: 0.8288\n",
      "[324/1762] D loss: 1.3937, G loss: 0.6551\n",
      "[404/1762] D loss: 1.3891, G loss: 0.7403\n",
      "[484/1762] D loss: 1.0573, G loss: 1.2089\n",
      "[564/1762] D loss: 1.1802, G loss: 1.0153\n",
      "[644/1762] D loss: 1.3961, G loss: 0.6423\n",
      "[724/1762] D loss: 0.7256, G loss: 1.7416\n",
      "[804/1762] D loss: 1.0604, G loss: 1.1760\n",
      "[884/1762] D loss: 1.3952, G loss: 0.7383\n",
      "[964/1762] D loss: 1.3932, G loss: 0.6220\n",
      "[1044/1762] D loss: 1.0732, G loss: 1.2521\n",
      "[1124/1762] D loss: 1.4033, G loss: 0.6308\n",
      "[1204/1762] D loss: 1.0585, G loss: 1.1487\n",
      "[1284/1762] D loss: 1.3927, G loss: 0.7052\n",
      "[1364/1762] D loss: 1.3964, G loss: 0.6384\n",
      "[1444/1762] D loss: 1.3978, G loss: 0.6276\n",
      "[1524/1762] D loss: 1.0628, G loss: 1.4307\n",
      "[1604/1762] D loss: 1.4071, G loss: 0.5764\n",
      "[1684/1762] D loss: 1.3924, G loss: 0.8329\n",
      "[1762/1762] D loss: 1.3843, G loss: 0.6687\n",
      "train error: \n",
      " D loss: 1.290019, G loss: 0.794643, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.268066, G loss: 0.822913, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0710, G loss: 1.0193\n",
      "[84/1762] D loss: 0.7193, G loss: 1.9617\n",
      "[164/1762] D loss: 1.3833, G loss: 0.7571\n",
      "[244/1762] D loss: 1.1396, G loss: 1.1874\n",
      "[324/1762] D loss: 1.1702, G loss: 1.1752\n",
      "[404/1762] D loss: 1.0581, G loss: 1.3395\n",
      "[484/1762] D loss: 1.3903, G loss: 0.7027\n",
      "[564/1762] D loss: 1.3866, G loss: 0.6919\n",
      "[644/1762] D loss: 1.3984, G loss: 0.6124\n",
      "[724/1762] D loss: 1.2964, G loss: 0.8155\n",
      "[804/1762] D loss: 1.0597, G loss: 1.2025\n",
      "[884/1762] D loss: 1.0523, G loss: 1.3014\n",
      "[964/1762] D loss: 1.0459, G loss: 1.3705\n",
      "[1044/1762] D loss: 1.0665, G loss: 1.3161\n",
      "[1124/1762] D loss: 1.3928, G loss: 0.7202\n",
      "[1204/1762] D loss: 0.9118, G loss: 1.9477\n",
      "[1284/1762] D loss: 1.3938, G loss: 0.6667\n",
      "[1364/1762] D loss: 1.0650, G loss: 1.2522\n",
      "[1444/1762] D loss: 1.3975, G loss: 0.5882\n",
      "[1524/1762] D loss: 0.7426, G loss: 1.6332\n",
      "[1604/1762] D loss: 1.3878, G loss: 0.7061\n",
      "[1684/1762] D loss: 1.3163, G loss: 0.7511\n",
      "[1762/1762] D loss: 1.4006, G loss: 0.5512\n",
      "train error: \n",
      " D loss: 1.296748, G loss: 0.754818, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.275244, G loss: 0.781744, D accuracy: 55.9%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4005, G loss: 0.5794\n",
      "[84/1762] D loss: 0.8801, G loss: 1.5719\n",
      "[164/1762] D loss: 1.4034, G loss: 0.5136\n",
      "[244/1762] D loss: 1.3875, G loss: 0.7141\n",
      "[324/1762] D loss: 1.3888, G loss: 0.6739\n",
      "[404/1762] D loss: 1.2142, G loss: 1.2691\n",
      "[484/1762] D loss: 1.4015, G loss: 0.6417\n",
      "[564/1762] D loss: 1.3908, G loss: 0.7366\n",
      "[644/1762] D loss: 1.0576, G loss: 1.2245\n",
      "[724/1762] D loss: 1.0588, G loss: 1.3528\n",
      "[804/1762] D loss: 1.4391, G loss: 0.6263\n",
      "[884/1762] D loss: 1.3899, G loss: 0.7710\n",
      "[964/1762] D loss: 1.4473, G loss: 0.5370\n",
      "[1044/1762] D loss: 1.3889, G loss: 0.7177\n",
      "[1124/1762] D loss: 1.3891, G loss: 0.6717\n",
      "[1204/1762] D loss: 1.3906, G loss: 0.7242\n",
      "[1284/1762] D loss: 1.0534, G loss: 1.3296\n",
      "[1364/1762] D loss: 1.4180, G loss: 0.6123\n",
      "[1444/1762] D loss: 1.4016, G loss: 0.8165\n",
      "[1524/1762] D loss: 1.0525, G loss: 1.3716\n",
      "[1604/1762] D loss: 1.0463, G loss: 1.4581\n",
      "[1684/1762] D loss: 1.0468, G loss: 1.4982\n",
      "[1762/1762] D loss: 0.3829, G loss: 2.7533\n",
      "train error: \n",
      " D loss: 1.288010, G loss: 0.864789, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.259385, G loss: 0.936956, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3983, G loss: 0.6353\n",
      "[84/1762] D loss: 1.3897, G loss: 0.6442\n",
      "[164/1762] D loss: 1.3747, G loss: 0.6594\n",
      "[244/1762] D loss: 1.0518, G loss: 1.3664\n",
      "[324/1762] D loss: 1.3978, G loss: 0.7013\n",
      "[404/1762] D loss: 1.3792, G loss: 0.6379\n",
      "[484/1762] D loss: 1.3887, G loss: 0.7281\n",
      "[564/1762] D loss: 1.0504, G loss: 1.3573\n",
      "[644/1762] D loss: 1.3878, G loss: 0.6731\n",
      "[724/1762] D loss: 1.4063, G loss: 0.7349\n",
      "[804/1762] D loss: 1.3910, G loss: 0.6916\n",
      "[884/1762] D loss: 1.1601, G loss: 1.3698\n",
      "[964/1762] D loss: 1.3891, G loss: 0.7037\n",
      "[1044/1762] D loss: 1.0473, G loss: 1.4438\n",
      "[1124/1762] D loss: 1.3904, G loss: 0.6512\n",
      "[1204/1762] D loss: 1.3866, G loss: 0.7106\n",
      "[1284/1762] D loss: 1.3892, G loss: 0.6761\n",
      "[1364/1762] D loss: 1.3869, G loss: 0.6904\n",
      "[1444/1762] D loss: 1.3960, G loss: 0.6398\n",
      "[1524/1762] D loss: 1.3892, G loss: 0.6843\n",
      "[1604/1762] D loss: 1.3917, G loss: 0.7005\n",
      "[1684/1762] D loss: 1.3848, G loss: 0.6832\n",
      "[1762/1762] D loss: 1.3955, G loss: 0.7253\n",
      "train error: \n",
      " D loss: 1.285850, G loss: 0.959749, D accuracy: 54.0%, cell accuracy: 99.9%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.256757, G loss: 1.039085, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3873, G loss: 0.6827\n",
      "[84/1762] D loss: 1.3930, G loss: 0.6416\n",
      "[164/1762] D loss: 0.7014, G loss: 2.4687\n",
      "[244/1762] D loss: 1.0452, G loss: 1.4957\n",
      "[324/1762] D loss: 1.3890, G loss: 0.6583\n",
      "[404/1762] D loss: 0.7013, G loss: 2.4039\n",
      "[484/1762] D loss: 1.3870, G loss: 0.6867\n",
      "[564/1762] D loss: 1.3811, G loss: 0.6919\n",
      "[644/1762] D loss: 1.3929, G loss: 0.6893\n",
      "[724/1762] D loss: 1.3894, G loss: 0.7242\n",
      "[804/1762] D loss: 1.3955, G loss: 0.6313\n",
      "[884/1762] D loss: 1.3897, G loss: 0.7464\n",
      "[964/1762] D loss: 0.3561, G loss: 3.5189\n",
      "[1044/1762] D loss: 1.3875, G loss: 0.7434\n",
      "[1124/1762] D loss: 1.0464, G loss: 1.5182\n",
      "[1204/1762] D loss: 0.7032, G loss: 2.4891\n",
      "[1284/1762] D loss: 1.3899, G loss: 0.7303\n",
      "[1364/1762] D loss: 1.3956, G loss: 0.6282\n",
      "[1444/1762] D loss: 1.3916, G loss: 0.6946\n",
      "[1524/1762] D loss: 1.3876, G loss: 0.6948\n",
      "[1604/1762] D loss: 0.7014, G loss: 2.5296\n",
      "[1684/1762] D loss: 1.0425, G loss: 1.6496\n",
      "[1762/1762] D loss: 1.3869, G loss: 0.6907\n",
      "train error: \n",
      " D loss: 1.286103, G loss: 0.965690, D accuracy: 54.1%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.257946, G loss: 1.040874, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6934\n",
      "[84/1762] D loss: 1.3880, G loss: 0.7500\n",
      "[164/1762] D loss: 1.3866, G loss: 0.7120\n",
      "[244/1762] D loss: 1.3877, G loss: 0.6673\n",
      "[324/1762] D loss: 1.3905, G loss: 0.7304\n",
      "[404/1762] D loss: 1.3856, G loss: 0.6517\n",
      "[484/1762] D loss: 0.6945, G loss: 2.7183\n",
      "[564/1762] D loss: 1.5813, G loss: 0.4466\n",
      "[644/1762] D loss: 1.4950, G loss: 0.5248\n",
      "[724/1762] D loss: 1.1127, G loss: 0.9535\n",
      "[804/1762] D loss: 1.3533, G loss: 0.8385\n",
      "[884/1762] D loss: 1.4048, G loss: 0.7000\n",
      "[964/1762] D loss: 1.0744, G loss: 1.0539\n",
      "[1044/1762] D loss: 1.3924, G loss: 0.6610\n",
      "[1124/1762] D loss: 1.0687, G loss: 1.1427\n",
      "[1204/1762] D loss: 1.0527, G loss: 1.3353\n",
      "[1284/1762] D loss: 1.0531, G loss: 1.2486\n",
      "[1364/1762] D loss: 1.0539, G loss: 1.3217\n",
      "[1444/1762] D loss: 1.3868, G loss: 0.6872\n",
      "[1524/1762] D loss: 1.0480, G loss: 1.4017\n",
      "[1604/1762] D loss: 1.2841, G loss: 0.7923\n",
      "[1684/1762] D loss: 1.5729, G loss: 0.5589\n",
      "[1762/1762] D loss: 1.4248, G loss: 0.7555\n",
      "train error: \n",
      " D loss: 1.304138, G loss: 0.933928, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.270376, G loss: 0.982959, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 85.0% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0269, G loss: 1.2346\n",
      "[84/1762] D loss: 1.0575, G loss: 1.2155\n",
      "[164/1762] D loss: 1.3887, G loss: 0.7279\n",
      "[244/1762] D loss: 1.0484, G loss: 1.4373\n",
      "[324/1762] D loss: 1.0479, G loss: 1.3746\n",
      "[404/1762] D loss: 1.1960, G loss: 1.4076\n",
      "[484/1762] D loss: 1.4136, G loss: 0.8432\n",
      "[564/1762] D loss: 1.4227, G loss: 0.8518\n",
      "[644/1762] D loss: 1.0794, G loss: 1.1343\n",
      "[724/1762] D loss: 1.3901, G loss: 0.6555\n",
      "[804/1762] D loss: 1.3877, G loss: 0.6750\n",
      "[884/1762] D loss: 1.3879, G loss: 0.7136\n",
      "[964/1762] D loss: 1.3875, G loss: 0.7175\n",
      "[1044/1762] D loss: 1.3871, G loss: 0.7197\n",
      "[1124/1762] D loss: 1.3895, G loss: 0.7268\n",
      "[1204/1762] D loss: 1.3896, G loss: 0.7368\n",
      "[1284/1762] D loss: 1.3896, G loss: 0.7333\n",
      "[1364/1762] D loss: 1.2457, G loss: 1.3045\n",
      "[1444/1762] D loss: 1.3833, G loss: 0.6898\n",
      "[1524/1762] D loss: 1.3820, G loss: 0.6579\n",
      "[1604/1762] D loss: 1.4066, G loss: 0.5886\n",
      "[1684/1762] D loss: 1.3911, G loss: 0.6674\n",
      "[1762/1762] D loss: 1.4060, G loss: 0.7511\n",
      "train error: \n",
      " D loss: 1.289959, G loss: 0.905284, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.261263, G loss: 0.975761, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3884, G loss: 0.7057\n",
      "[84/1762] D loss: 1.0495, G loss: 1.4207\n",
      "[164/1762] D loss: 1.0491, G loss: 1.3841\n",
      "[244/1762] D loss: 1.3871, G loss: 0.7028\n",
      "[324/1762] D loss: 1.3955, G loss: 0.6211\n",
      "[404/1762] D loss: 1.3775, G loss: 0.7609\n",
      "[484/1762] D loss: 1.2834, G loss: 1.0091\n",
      "[564/1762] D loss: 1.0516, G loss: 1.3601\n",
      "[644/1762] D loss: 1.0464, G loss: 1.4725\n",
      "[724/1762] D loss: 1.4005, G loss: 0.6277\n",
      "[804/1762] D loss: 1.3954, G loss: 0.7188\n",
      "[884/1762] D loss: 1.3874, G loss: 0.7114\n",
      "[964/1762] D loss: 1.0531, G loss: 1.3462\n",
      "[1044/1762] D loss: 1.3904, G loss: 0.7169\n",
      "[1124/1762] D loss: 1.4380, G loss: 0.7557\n",
      "[1204/1762] D loss: 0.8939, G loss: 1.8130\n",
      "[1284/1762] D loss: 1.2891, G loss: 0.9639\n",
      "[1364/1762] D loss: 1.4196, G loss: 0.4988\n",
      "[1444/1762] D loss: 0.7276, G loss: 1.7476\n",
      "[1524/1762] D loss: 1.3877, G loss: 0.6721\n",
      "[1604/1762] D loss: 1.3894, G loss: 0.6805\n",
      "[1684/1762] D loss: 1.3881, G loss: 0.6969\n",
      "[1762/1762] D loss: 1.3835, G loss: 0.7055\n",
      "train error: \n",
      " D loss: 1.286345, G loss: 0.927565, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 91.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.260365, G loss: 0.987574, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3875, G loss: 0.6655\n",
      "[84/1762] D loss: 1.3872, G loss: 0.6852\n",
      "[164/1762] D loss: 1.3905, G loss: 0.6489\n",
      "[244/1762] D loss: 1.3932, G loss: 0.7010\n",
      "[324/1762] D loss: 1.4078, G loss: 0.5998\n",
      "[404/1762] D loss: 1.3871, G loss: 0.6947\n",
      "[484/1762] D loss: 1.3176, G loss: 0.7143\n",
      "[564/1762] D loss: 1.3891, G loss: 0.6715\n",
      "[644/1762] D loss: 1.3911, G loss: 0.6799\n",
      "[724/1762] D loss: 1.0498, G loss: 1.4423\n",
      "[804/1762] D loss: 1.3895, G loss: 0.7516\n",
      "[884/1762] D loss: 1.0373, G loss: 1.4477\n",
      "[964/1762] D loss: 1.3882, G loss: 0.6914\n",
      "[1044/1762] D loss: 1.4069, G loss: 0.7919\n",
      "[1124/1762] D loss: 1.0449, G loss: 1.5561\n",
      "[1204/1762] D loss: 1.3871, G loss: 0.7097\n",
      "[1284/1762] D loss: 1.0452, G loss: 1.7010\n",
      "[1364/1762] D loss: 1.0287, G loss: 1.6203\n",
      "[1444/1762] D loss: 1.3916, G loss: 0.7198\n",
      "[1524/1762] D loss: 1.0449, G loss: 1.5736\n",
      "[1604/1762] D loss: 1.3911, G loss: 0.6337\n",
      "[1684/1762] D loss: 1.3865, G loss: 0.6814\n",
      "[1762/1762] D loss: 1.3880, G loss: 0.6961\n",
      "train error: \n",
      " D loss: 1.286420, G loss: 0.982110, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.257813, G loss: 1.066909, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3894, G loss: 0.7136\n",
      "[84/1762] D loss: 1.3874, G loss: 0.6694\n",
      "[164/1762] D loss: 1.3872, G loss: 0.6794\n",
      "[244/1762] D loss: 1.0439, G loss: 1.7334\n",
      "[324/1762] D loss: 1.3889, G loss: 0.6767\n",
      "[404/1762] D loss: 1.3869, G loss: 0.6943\n",
      "[484/1762] D loss: 1.3868, G loss: 0.7110\n",
      "[564/1762] D loss: 1.3879, G loss: 0.7286\n",
      "[644/1762] D loss: 1.3901, G loss: 0.7433\n",
      "[724/1762] D loss: 1.0421, G loss: 1.7608\n",
      "[804/1762] D loss: 1.3921, G loss: 0.6363\n",
      "[884/1762] D loss: 1.3874, G loss: 0.7064\n",
      "[964/1762] D loss: 1.2523, G loss: 1.0583\n",
      "[1044/1762] D loss: 1.4390, G loss: 0.4731\n",
      "[1124/1762] D loss: 1.4389, G loss: 0.8909\n",
      "[1204/1762] D loss: 1.4020, G loss: 0.8114\n",
      "[1284/1762] D loss: 1.3677, G loss: 0.6675\n",
      "[1364/1762] D loss: 1.3972, G loss: 0.6954\n",
      "[1444/1762] D loss: 1.3870, G loss: 0.6838\n",
      "[1524/1762] D loss: 1.3899, G loss: 0.6644\n",
      "[1604/1762] D loss: 1.3929, G loss: 0.7786\n",
      "[1684/1762] D loss: 1.0485, G loss: 1.7734\n",
      "[1762/1762] D loss: 1.3903, G loss: 0.7269\n",
      "train error: \n",
      " D loss: 1.283039, G loss: 0.941306, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.252002, G loss: 1.000912, D accuracy: 55.7%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0440, G loss: 1.4748\n",
      "[84/1762] D loss: 1.3740, G loss: 0.6829\n",
      "[164/1762] D loss: 1.3858, G loss: 0.7349\n",
      "[244/1762] D loss: 1.3899, G loss: 0.7246\n",
      "[324/1762] D loss: 1.3907, G loss: 0.6220\n",
      "[404/1762] D loss: 1.3867, G loss: 0.7126\n",
      "[484/1762] D loss: 1.4275, G loss: 0.4966\n",
      "[564/1762] D loss: 1.3867, G loss: 0.6643\n",
      "[644/1762] D loss: 1.3883, G loss: 0.6830\n",
      "[724/1762] D loss: 1.3872, G loss: 0.6707\n",
      "[804/1762] D loss: 1.0579, G loss: 1.4513\n",
      "[884/1762] D loss: 1.3885, G loss: 0.7223\n",
      "[964/1762] D loss: 1.3867, G loss: 0.7091\n",
      "[1044/1762] D loss: 1.0460, G loss: 1.5113\n",
      "[1124/1762] D loss: 1.3866, G loss: 0.7007\n",
      "[1204/1762] D loss: 1.0453, G loss: 1.5863\n",
      "[1284/1762] D loss: 1.3919, G loss: 0.6394\n",
      "[1364/1762] D loss: 1.0477, G loss: 1.5154\n",
      "[1444/1762] D loss: 1.3873, G loss: 0.6973\n",
      "[1524/1762] D loss: 0.6912, G loss: 2.6498\n",
      "[1604/1762] D loss: 1.2256, G loss: 1.3974\n",
      "[1684/1762] D loss: 1.0398, G loss: 1.8136\n",
      "[1762/1762] D loss: 1.3304, G loss: 0.7812\n",
      "train error: \n",
      " D loss: 1.265863, G loss: 1.076570, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 87.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.237178, G loss: 1.131886, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 83.4% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0446, G loss: 1.6469\n",
      "[84/1762] D loss: 1.2836, G loss: 1.0525\n",
      "[164/1762] D loss: 1.2186, G loss: 1.7718\n",
      "[244/1762] D loss: 1.3893, G loss: 0.7527\n",
      "[324/1762] D loss: 1.0474, G loss: 1.6551\n",
      "[404/1762] D loss: 1.4973, G loss: 0.5761\n",
      "[484/1762] D loss: 1.3894, G loss: 0.6562\n",
      "[564/1762] D loss: 1.3871, G loss: 0.7113\n",
      "[644/1762] D loss: 1.0420, G loss: 1.4686\n",
      "[724/1762] D loss: 1.0506, G loss: 1.4533\n",
      "[804/1762] D loss: 1.3733, G loss: 0.7247\n",
      "[884/1762] D loss: 1.3965, G loss: 0.7736\n",
      "[964/1762] D loss: 1.3904, G loss: 0.7349\n",
      "[1044/1762] D loss: 1.3875, G loss: 0.7028\n",
      "[1124/1762] D loss: 1.3873, G loss: 0.6879\n",
      "[1204/1762] D loss: 1.3921, G loss: 0.6168\n",
      "[1284/1762] D loss: 1.3891, G loss: 0.6642\n",
      "[1364/1762] D loss: 1.3912, G loss: 0.6520\n",
      "[1444/1762] D loss: 1.3888, G loss: 0.7456\n",
      "[1524/1762] D loss: 1.3866, G loss: 0.6615\n",
      "[1604/1762] D loss: 1.3886, G loss: 0.6730\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.6996\n",
      "[1762/1762] D loss: 1.3894, G loss: 0.7456\n",
      "train error: \n",
      " D loss: 1.283240, G loss: 0.979326, D accuracy: 54.0%, cell accuracy: 99.9%, board accuracy: 91.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.259686, G loss: 1.024444, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3866, G loss: 0.6864\n",
      "[84/1762] D loss: 1.0438, G loss: 1.6063\n",
      "[164/1762] D loss: 1.3873, G loss: 0.6729\n",
      "[244/1762] D loss: 1.3873, G loss: 0.6534\n",
      "[324/1762] D loss: 1.3026, G loss: 2.4142\n",
      "[404/1762] D loss: 0.7410, G loss: 2.2383\n",
      "[484/1762] D loss: 1.3916, G loss: 0.7239\n",
      "[564/1762] D loss: 1.3872, G loss: 0.7247\n",
      "[644/1762] D loss: 1.0565, G loss: 1.3091\n",
      "[724/1762] D loss: 1.3888, G loss: 0.6913\n",
      "[804/1762] D loss: 1.3869, G loss: 0.7099\n",
      "[884/1762] D loss: 1.3875, G loss: 0.6714\n",
      "[964/1762] D loss: 1.3873, G loss: 0.6533\n",
      "[1044/1762] D loss: 1.3865, G loss: 0.7027\n",
      "[1124/1762] D loss: 1.2285, G loss: 1.3629\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6587\n",
      "[1284/1762] D loss: 1.3908, G loss: 0.7114\n",
      "[1364/1762] D loss: 1.3869, G loss: 0.7099\n",
      "[1444/1762] D loss: 1.3871, G loss: 0.6628\n",
      "[1524/1762] D loss: 1.0435, G loss: 1.6060\n",
      "[1604/1762] D loss: 1.0446, G loss: 1.5280\n",
      "[1684/1762] D loss: 1.0473, G loss: 1.6080\n",
      "[1762/1762] D loss: 0.6999, G loss: 2.5514\n",
      "train error: \n",
      " D loss: 1.284296, G loss: 0.991923, D accuracy: 54.2%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.258133, G loss: 1.066231, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0435, G loss: 1.5744\n",
      "[84/1762] D loss: 1.0433, G loss: 1.6841\n",
      "[164/1762] D loss: 1.3857, G loss: 0.7215\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6875\n",
      "[324/1762] D loss: 1.3889, G loss: 0.7094\n",
      "[404/1762] D loss: 1.3855, G loss: 0.7019\n",
      "[484/1762] D loss: 1.3864, G loss: 0.6878\n",
      "[564/1762] D loss: 1.0433, G loss: 1.6556\n",
      "[644/1762] D loss: 1.3874, G loss: 0.6596\n",
      "[724/1762] D loss: 1.3884, G loss: 0.6604\n",
      "[804/1762] D loss: 1.3877, G loss: 0.6692\n",
      "[884/1762] D loss: 1.3890, G loss: 0.6529\n",
      "[964/1762] D loss: 0.6978, G loss: 2.8273\n",
      "[1044/1762] D loss: 1.0526, G loss: 1.7370\n",
      "[1124/1762] D loss: 1.3883, G loss: 0.6603\n",
      "[1204/1762] D loss: 1.4589, G loss: 0.4867\n",
      "[1284/1762] D loss: 1.3954, G loss: 0.6627\n",
      "[1364/1762] D loss: 1.3873, G loss: 0.6841\n",
      "[1444/1762] D loss: 1.3941, G loss: 0.6813\n",
      "[1524/1762] D loss: 1.0468, G loss: 1.4359\n",
      "[1604/1762] D loss: 1.0459, G loss: 1.4719\n",
      "[1684/1762] D loss: 1.3883, G loss: 0.6786\n",
      "[1762/1762] D loss: 1.3904, G loss: 0.6801\n",
      "train error: \n",
      " D loss: 1.287289, G loss: 0.996212, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.258780, G loss: 1.080132, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3868, G loss: 0.7088\n",
      "[84/1762] D loss: 1.0526, G loss: 1.7206\n",
      "[164/1762] D loss: 1.3895, G loss: 0.7308\n",
      "[244/1762] D loss: 1.3875, G loss: 0.7243\n",
      "[324/1762] D loss: 1.0435, G loss: 1.6270\n",
      "[404/1762] D loss: 1.3872, G loss: 0.7109\n",
      "[484/1762] D loss: 1.3884, G loss: 0.6690\n",
      "[564/1762] D loss: 1.3865, G loss: 0.7048\n",
      "[644/1762] D loss: 1.3854, G loss: 0.6983\n",
      "[724/1762] D loss: 1.0356, G loss: 1.7765\n",
      "[804/1762] D loss: 1.3994, G loss: 0.6213\n",
      "[884/1762] D loss: 1.3900, G loss: 0.6440\n",
      "[964/1762] D loss: 1.3876, G loss: 0.6656\n",
      "[1044/1762] D loss: 1.3875, G loss: 0.6708\n",
      "[1124/1762] D loss: 1.3868, G loss: 0.7012\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6867\n",
      "[1284/1762] D loss: 1.0425, G loss: 1.8224\n",
      "[1364/1762] D loss: 1.3884, G loss: 0.7159\n",
      "[1444/1762] D loss: 1.3847, G loss: 0.6826\n",
      "[1524/1762] D loss: 1.3892, G loss: 0.6510\n",
      "[1604/1762] D loss: 1.3875, G loss: 0.6610\n",
      "[1684/1762] D loss: 1.2365, G loss: 0.7890\n",
      "[1762/1762] D loss: 1.4618, G loss: 0.5010\n",
      "train error: \n",
      " D loss: 1.333885, G loss: 0.716139, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 81.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.301763, G loss: 0.773406, D accuracy: 56.5%, cell accuracy: 99.8%, board accuracy: 78.4% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4666, G loss: 0.5030\n",
      "[84/1762] D loss: 1.1750, G loss: 2.1111\n",
      "[164/1762] D loss: 1.3888, G loss: 0.7220\n",
      "[244/1762] D loss: 1.3898, G loss: 0.6733\n",
      "[324/1762] D loss: 1.4081, G loss: 0.7754\n",
      "[404/1762] D loss: 1.4048, G loss: 0.6548\n",
      "[484/1762] D loss: 1.0495, G loss: 1.4348\n",
      "[564/1762] D loss: 1.3879, G loss: 0.6639\n",
      "[644/1762] D loss: 1.3878, G loss: 0.6808\n",
      "[724/1762] D loss: 1.3893, G loss: 0.7081\n",
      "[804/1762] D loss: 0.8901, G loss: 2.7660\n",
      "[884/1762] D loss: 1.3878, G loss: 0.6872\n",
      "[964/1762] D loss: 1.0445, G loss: 1.6133\n",
      "[1044/1762] D loss: 1.3874, G loss: 0.6637\n",
      "[1124/1762] D loss: 1.3874, G loss: 0.6788\n",
      "[1204/1762] D loss: 1.0442, G loss: 1.6896\n",
      "[1284/1762] D loss: 1.3865, G loss: 0.7123\n",
      "[1364/1762] D loss: 1.3870, G loss: 0.6767\n",
      "[1444/1762] D loss: 1.3866, G loss: 0.6965\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.6999\n",
      "[1604/1762] D loss: 1.3865, G loss: 0.6916\n",
      "[1684/1762] D loss: 1.3881, G loss: 0.6975\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.7147\n",
      "train error: \n",
      " D loss: 1.285825, G loss: 1.015336, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.257870, G loss: 1.113636, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3870, G loss: 0.7162\n",
      "[84/1762] D loss: 1.0433, G loss: 1.6746\n",
      "[164/1762] D loss: 1.3864, G loss: 0.6921\n",
      "[244/1762] D loss: 1.3864, G loss: 0.6979\n",
      "[324/1762] D loss: 1.0420, G loss: 1.7243\n",
      "[404/1762] D loss: 1.0418, G loss: 1.7968\n",
      "[484/1762] D loss: 1.3871, G loss: 0.6571\n",
      "[564/1762] D loss: 1.3870, G loss: 0.7064\n",
      "[644/1762] D loss: 1.3883, G loss: 0.7224\n",
      "[724/1762] D loss: 1.3866, G loss: 0.6844\n",
      "[804/1762] D loss: 1.3887, G loss: 0.6434\n",
      "[884/1762] D loss: 1.3894, G loss: 0.6452\n",
      "[964/1762] D loss: 1.4027, G loss: 0.8201\n",
      "[1044/1762] D loss: 1.3971, G loss: 0.6233\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.6998\n",
      "[1204/1762] D loss: 1.3871, G loss: 0.6840\n",
      "[1284/1762] D loss: 1.3873, G loss: 0.6923\n",
      "[1364/1762] D loss: 0.6997, G loss: 2.6835\n",
      "[1444/1762] D loss: 1.3869, G loss: 0.6867\n",
      "[1524/1762] D loss: 1.3884, G loss: 0.6552\n",
      "[1604/1762] D loss: 1.0439, G loss: 1.7225\n",
      "[1684/1762] D loss: 1.3871, G loss: 0.6758\n",
      "[1762/1762] D loss: 1.3874, G loss: 0.7090\n",
      "train error: \n",
      " D loss: 1.283038, G loss: 1.039791, D accuracy: 54.1%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.255063, G loss: 1.129956, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3867, G loss: 0.7006\n",
      "[84/1762] D loss: 1.3866, G loss: 0.6750\n",
      "[164/1762] D loss: 1.0430, G loss: 1.7481\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6928\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6967\n",
      "[404/1762] D loss: 1.0415, G loss: 1.7763\n",
      "[484/1762] D loss: 1.3857, G loss: 0.7111\n",
      "[564/1762] D loss: 0.8862, G loss: 2.2278\n",
      "[644/1762] D loss: 1.4137, G loss: 0.5781\n",
      "[724/1762] D loss: 1.2010, G loss: 6.0938\n",
      "[804/1762] D loss: 1.3873, G loss: 0.6682\n",
      "[884/1762] D loss: 1.0435, G loss: 1.7299\n",
      "[964/1762] D loss: 1.3975, G loss: 0.7108\n",
      "[1044/1762] D loss: 1.3903, G loss: 0.7444\n",
      "[1124/1762] D loss: 1.0421, G loss: 1.8270\n",
      "[1204/1762] D loss: 1.3923, G loss: 0.7577\n",
      "[1284/1762] D loss: 1.3873, G loss: 0.7239\n",
      "[1364/1762] D loss: 1.3889, G loss: 0.6642\n",
      "[1444/1762] D loss: 1.3900, G loss: 0.6601\n",
      "[1524/1762] D loss: 1.3868, G loss: 0.6808\n",
      "[1604/1762] D loss: 1.0401, G loss: 2.5193\n",
      "[1684/1762] D loss: 1.3866, G loss: 0.7014\n",
      "[1762/1762] D loss: 1.3921, G loss: 0.6187\n",
      "train error: \n",
      " D loss: 1.278039, G loss: 1.080641, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 89.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.248302, G loss: 1.193426, D accuracy: 56.5%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0433, G loss: 1.8131\n",
      "[84/1762] D loss: 1.3812, G loss: 0.8304\n",
      "[164/1762] D loss: 1.3893, G loss: 0.7182\n",
      "[244/1762] D loss: 1.3873, G loss: 0.7387\n",
      "[324/1762] D loss: 1.0444, G loss: 1.7863\n",
      "[404/1762] D loss: 1.3965, G loss: 0.6055\n",
      "[484/1762] D loss: 1.0474, G loss: 1.5075\n",
      "[564/1762] D loss: 1.3874, G loss: 0.6771\n",
      "[644/1762] D loss: 1.3890, G loss: 0.6514\n",
      "[724/1762] D loss: 1.3105, G loss: 0.8316\n",
      "[804/1762] D loss: 1.3938, G loss: 0.6180\n",
      "[884/1762] D loss: 1.3845, G loss: 0.6917\n",
      "[964/1762] D loss: 1.3903, G loss: 0.6398\n",
      "[1044/1762] D loss: 1.3859, G loss: 0.6898\n",
      "[1124/1762] D loss: 1.3857, G loss: 0.7032\n",
      "[1204/1762] D loss: 1.3866, G loss: 0.6996\n",
      "[1284/1762] D loss: 1.0427, G loss: 1.6312\n",
      "[1364/1762] D loss: 1.3876, G loss: 0.6733\n",
      "[1444/1762] D loss: 1.3868, G loss: 0.7067\n",
      "[1524/1762] D loss: 1.3923, G loss: 0.6382\n",
      "[1604/1762] D loss: 1.0447, G loss: 3.1108\n",
      "[1684/1762] D loss: 1.3878, G loss: 0.6479\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.7041\n",
      "train error: \n",
      " D loss: 1.287831, G loss: 0.985454, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 86.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.260701, G loss: 1.066150, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 83.2% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0401, G loss: 1.7768\n",
      "[84/1762] D loss: 1.3921, G loss: 0.6370\n",
      "[164/1762] D loss: 1.3874, G loss: 0.7139\n",
      "[244/1762] D loss: 1.3874, G loss: 0.6832\n",
      "[324/1762] D loss: 1.3863, G loss: 0.7157\n",
      "[404/1762] D loss: 1.3870, G loss: 0.7118\n",
      "[484/1762] D loss: 1.3913, G loss: 0.6465\n",
      "[564/1762] D loss: 1.3887, G loss: 0.7335\n",
      "[644/1762] D loss: 1.3867, G loss: 0.7153\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6833\n",
      "[804/1762] D loss: 1.3894, G loss: 0.7140\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6938\n",
      "[964/1762] D loss: 1.3860, G loss: 0.6902\n",
      "[1044/1762] D loss: 1.3868, G loss: 0.6953\n",
      "[1124/1762] D loss: 1.0430, G loss: 1.6233\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6829\n",
      "[1284/1762] D loss: 1.3908, G loss: 0.6482\n",
      "[1364/1762] D loss: 1.3873, G loss: 0.7159\n",
      "[1444/1762] D loss: 1.3872, G loss: 0.7123\n",
      "[1524/1762] D loss: 1.3884, G loss: 0.7256\n",
      "[1604/1762] D loss: 1.0425, G loss: 1.6877\n",
      "[1684/1762] D loss: 1.0419, G loss: 1.7423\n",
      "[1762/1762] D loss: 1.3873, G loss: 0.7215\n",
      "train error: \n",
      " D loss: 1.283880, G loss: 1.068730, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 91.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.258810, G loss: 1.167769, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6994\n",
      "[84/1762] D loss: 1.3887, G loss: 0.6620\n",
      "[164/1762] D loss: 1.0413, G loss: 1.8131\n",
      "[244/1762] D loss: 1.3866, G loss: 0.6822\n",
      "[324/1762] D loss: 1.3866, G loss: 0.6916\n",
      "[404/1762] D loss: 1.3868, G loss: 0.6942\n",
      "[484/1762] D loss: 1.0411, G loss: 1.8690\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6929\n",
      "[644/1762] D loss: 1.0409, G loss: 1.9110\n",
      "[724/1762] D loss: 0.6953, G loss: 4.0848\n",
      "[804/1762] D loss: 1.3886, G loss: 0.6538\n",
      "[884/1762] D loss: 1.0436, G loss: 1.7811\n",
      "[964/1762] D loss: 0.7671, G loss: 3.2045\n",
      "[1044/1762] D loss: 1.3971, G loss: 0.6208\n",
      "[1124/1762] D loss: 1.3868, G loss: 0.6728\n",
      "[1204/1762] D loss: 1.3870, G loss: 0.6617\n",
      "[1284/1762] D loss: 1.0435, G loss: 1.9577\n",
      "[1364/1762] D loss: 1.0413, G loss: 2.0037\n",
      "[1444/1762] D loss: 1.2171, G loss: 3.4201\n",
      "[1524/1762] D loss: 1.3871, G loss: 0.7134\n",
      "[1604/1762] D loss: 1.3805, G loss: 0.7116\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6831\n",
      "[1762/1762] D loss: 1.3897, G loss: 0.6956\n",
      "train error: \n",
      " D loss: 1.251274, G loss: 1.294311, D accuracy: 57.0%, cell accuracy: 99.7%, board accuracy: 82.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.226084, G loss: 1.453960, D accuracy: 57.4%, cell accuracy: 99.7%, board accuracy: 80.9% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3852, G loss: 0.6798\n",
      "[84/1762] D loss: 1.4053, G loss: 0.5712\n",
      "[164/1762] D loss: 1.3926, G loss: 0.6197\n",
      "[244/1762] D loss: 1.4103, G loss: 0.8137\n",
      "[324/1762] D loss: 1.3898, G loss: 0.6428\n",
      "[404/1762] D loss: 1.3877, G loss: 0.7125\n",
      "[484/1762] D loss: 1.3872, G loss: 0.6930\n",
      "[564/1762] D loss: 1.3871, G loss: 0.6954\n",
      "[644/1762] D loss: 1.0428, G loss: 1.5861\n",
      "[724/1762] D loss: 1.3872, G loss: 0.6886\n",
      "[804/1762] D loss: 1.3868, G loss: 0.6991\n",
      "[884/1762] D loss: 1.0421, G loss: 1.7163\n",
      "[964/1762] D loss: 1.3865, G loss: 0.7021\n",
      "[1044/1762] D loss: 1.3865, G loss: 0.6912\n",
      "[1124/1762] D loss: 1.0419, G loss: 1.7488\n",
      "[1204/1762] D loss: 1.0416, G loss: 1.7665\n",
      "[1284/1762] D loss: 1.3681, G loss: 0.7533\n",
      "[1364/1762] D loss: 1.3869, G loss: 0.6828\n",
      "[1444/1762] D loss: 1.0411, G loss: 1.9691\n",
      "[1524/1762] D loss: 1.3865, G loss: 0.6949\n",
      "[1604/1762] D loss: 1.3870, G loss: 0.7047\n",
      "[1684/1762] D loss: 1.3867, G loss: 0.7118\n",
      "[1762/1762] D loss: 0.6949, G loss: 3.2736\n",
      "train error: \n",
      " D loss: 1.276672, G loss: 1.134275, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.243324, G loss: 1.260285, D accuracy: 56.0%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3889, G loss: 0.6443\n",
      "[84/1762] D loss: 1.3876, G loss: 0.7024\n",
      "[164/1762] D loss: 1.3866, G loss: 0.6989\n",
      "[244/1762] D loss: 1.0411, G loss: 2.0426\n",
      "[324/1762] D loss: 1.0422, G loss: 1.9376\n",
      "[404/1762] D loss: 1.3865, G loss: 0.6801\n",
      "[484/1762] D loss: 0.6952, G loss: 3.2932\n",
      "[564/1762] D loss: 1.3870, G loss: 0.7021\n",
      "[644/1762] D loss: 1.0402, G loss: 3.4492\n",
      "[724/1762] D loss: 1.3876, G loss: 0.6709\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6917\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6977\n",
      "[964/1762] D loss: 1.3877, G loss: 0.6923\n",
      "[1044/1762] D loss: 1.3867, G loss: 0.6966\n",
      "[1124/1762] D loss: 1.0439, G loss: 1.6184\n",
      "[1204/1762] D loss: 1.0434, G loss: 1.6198\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6944\n",
      "[1364/1762] D loss: 1.3866, G loss: 0.6834\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6947\n",
      "[1524/1762] D loss: 1.0415, G loss: 1.7860\n",
      "[1604/1762] D loss: 1.3866, G loss: 0.6979\n",
      "[1684/1762] D loss: 1.3865, G loss: 0.7067\n",
      "[1762/1762] D loss: 1.3875, G loss: 0.6615\n",
      "train error: \n",
      " D loss: 1.267946, G loss: 1.213698, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 89.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.240480, G loss: 1.355552, D accuracy: 56.2%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6814\n",
      "[84/1762] D loss: 1.1798, G loss: 3.7456\n",
      "[164/1762] D loss: 1.4017, G loss: 0.5606\n",
      "[244/1762] D loss: 1.3900, G loss: 0.7098\n",
      "[324/1762] D loss: 1.0424, G loss: 1.6988\n",
      "[404/1762] D loss: 1.3873, G loss: 0.6630\n",
      "[484/1762] D loss: 1.3867, G loss: 0.6811\n",
      "[564/1762] D loss: 1.3872, G loss: 0.6759\n",
      "[644/1762] D loss: 1.3868, G loss: 0.6979\n",
      "[724/1762] D loss: 1.3832, G loss: 0.7041\n",
      "[804/1762] D loss: 1.2230, G loss: 1.9408\n",
      "[884/1762] D loss: 1.0405, G loss: 2.0458\n",
      "[964/1762] D loss: 1.3875, G loss: 0.6488\n",
      "[1044/1762] D loss: 1.4449, G loss: 0.6602\n",
      "[1124/1762] D loss: 1.0472, G loss: 1.8916\n",
      "[1204/1762] D loss: 1.3865, G loss: 0.6824\n",
      "[1284/1762] D loss: 1.3872, G loss: 0.7253\n",
      "[1364/1762] D loss: 1.3858, G loss: 0.6918\n",
      "[1444/1762] D loss: 1.3846, G loss: 0.7169\n",
      "[1524/1762] D loss: 1.3871, G loss: 0.6848\n",
      "[1604/1762] D loss: 1.3850, G loss: 0.6793\n",
      "[1684/1762] D loss: 1.0407, G loss: 1.9236\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.7047\n",
      "train error: \n",
      " D loss: 1.282102, G loss: 1.085056, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.252673, G loss: 1.203778, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3877, G loss: 0.6771\n",
      "[84/1762] D loss: 1.3862, G loss: 0.6984\n",
      "[164/1762] D loss: 1.3867, G loss: 0.6777\n",
      "[244/1762] D loss: 1.0426, G loss: 2.1750\n",
      "[324/1762] D loss: 1.3866, G loss: 0.6798\n",
      "[404/1762] D loss: 1.3866, G loss: 0.6833\n",
      "[484/1762] D loss: 1.3861, G loss: 0.6835\n",
      "[564/1762] D loss: 1.3845, G loss: 0.6997\n",
      "[644/1762] D loss: 1.3862, G loss: 0.6906\n",
      "[724/1762] D loss: 1.3868, G loss: 0.6893\n",
      "[804/1762] D loss: 1.3915, G loss: 0.6375\n",
      "[884/1762] D loss: 1.3867, G loss: 0.6730\n",
      "[964/1762] D loss: 1.3876, G loss: 0.6647\n",
      "[1044/1762] D loss: 1.3867, G loss: 0.7024\n",
      "[1124/1762] D loss: 1.3862, G loss: 0.7152\n",
      "[1204/1762] D loss: 1.3899, G loss: 0.6616\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6880\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6938\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6912\n",
      "[1524/1762] D loss: 1.3860, G loss: 0.7047\n",
      "[1604/1762] D loss: 1.3854, G loss: 0.7051\n",
      "[1684/1762] D loss: 1.3867, G loss: 0.6926\n",
      "[1762/1762] D loss: 1.3749, G loss: 0.7014\n",
      "train error: \n",
      " D loss: 1.281297, G loss: 1.143595, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.251426, G loss: 1.282204, D accuracy: 57.0%, cell accuracy: 99.8%, board accuracy: 84.3% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3858, G loss: 0.7028\n",
      "[84/1762] D loss: 1.3865, G loss: 0.6920\n",
      "[164/1762] D loss: 1.3865, G loss: 0.6912\n",
      "[244/1762] D loss: 1.3427, G loss: 0.7451\n",
      "[324/1762] D loss: 1.3845, G loss: 0.6579\n",
      "[404/1762] D loss: 1.4114, G loss: 0.5705\n",
      "[484/1762] D loss: 1.3479, G loss: 0.7183\n",
      "[564/1762] D loss: 1.3878, G loss: 0.7171\n",
      "[644/1762] D loss: 1.0410, G loss: 2.4730\n",
      "[724/1762] D loss: 1.0422, G loss: 2.0983\n",
      "[804/1762] D loss: 1.3866, G loss: 0.6824\n",
      "[884/1762] D loss: 1.3866, G loss: 0.6906\n",
      "[964/1762] D loss: 1.3869, G loss: 0.7076\n",
      "[1044/1762] D loss: 1.3866, G loss: 0.6897\n",
      "[1124/1762] D loss: 1.3858, G loss: 0.6909\n",
      "[1204/1762] D loss: 1.3874, G loss: 0.6897\n",
      "[1284/1762] D loss: 1.0445, G loss: 1.9482\n",
      "[1364/1762] D loss: 1.3346, G loss: 0.7751\n",
      "[1444/1762] D loss: 1.4470, G loss: 0.5380\n",
      "[1524/1762] D loss: 1.0535, G loss: 1.8539\n",
      "[1604/1762] D loss: 1.0431, G loss: 1.7584\n",
      "[1684/1762] D loss: 1.0397, G loss: 2.0822\n",
      "[1762/1762] D loss: 1.3870, G loss: 0.7015\n",
      "train error: \n",
      " D loss: 1.283054, G loss: 1.061803, D accuracy: 54.5%, cell accuracy: 99.9%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.253041, G loss: 1.191772, D accuracy: 56.0%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0409, G loss: 1.9888\n",
      "[84/1762] D loss: 1.3855, G loss: 0.6901\n",
      "[164/1762] D loss: 1.3963, G loss: 0.6652\n",
      "[244/1762] D loss: 1.3886, G loss: 0.7251\n",
      "[324/1762] D loss: 1.3879, G loss: 0.7418\n",
      "[404/1762] D loss: 1.0408, G loss: 2.0297\n",
      "[484/1762] D loss: 1.3928, G loss: 0.7051\n",
      "[564/1762] D loss: 1.0415, G loss: 1.7718\n",
      "[644/1762] D loss: 1.3884, G loss: 0.7243\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6944\n",
      "[804/1762] D loss: 1.3866, G loss: 0.6841\n",
      "[884/1762] D loss: 1.0415, G loss: 1.8194\n",
      "[964/1762] D loss: 1.3863, G loss: 0.6861\n",
      "[1044/1762] D loss: 1.3867, G loss: 0.7067\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.6942\n",
      "[1204/1762] D loss: 0.6947, G loss: 3.2756\n",
      "[1284/1762] D loss: 1.0408, G loss: 1.9560\n",
      "[1364/1762] D loss: 1.3867, G loss: 0.6876\n",
      "[1444/1762] D loss: 1.2002, G loss: 2.0203\n",
      "[1524/1762] D loss: 1.0027, G loss: 2.2304\n",
      "[1604/1762] D loss: 1.3871, G loss: 0.6781\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.6843\n",
      "[1762/1762] D loss: 0.6965, G loss: 3.6642\n",
      "train error: \n",
      " D loss: 1.284337, G loss: 1.098822, D accuracy: 54.0%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.254454, G loss: 1.270791, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3869, G loss: 0.6787\n",
      "[84/1762] D loss: 1.3865, G loss: 0.6892\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6980\n",
      "[244/1762] D loss: 1.3867, G loss: 0.7073\n",
      "[324/1762] D loss: 1.3858, G loss: 0.6784\n",
      "[404/1762] D loss: 1.3859, G loss: 0.6911\n",
      "[484/1762] D loss: 1.3551, G loss: 0.7466\n",
      "[564/1762] D loss: 1.0404, G loss: 2.2159\n",
      "[644/1762] D loss: 1.0389, G loss: 2.1225\n",
      "[724/1762] D loss: 1.3855, G loss: 0.7062\n",
      "[804/1762] D loss: 1.3863, G loss: 0.6963\n",
      "[884/1762] D loss: 1.3869, G loss: 0.6845\n",
      "[964/1762] D loss: 1.3866, G loss: 0.6976\n",
      "[1044/1762] D loss: 1.3868, G loss: 0.7076\n",
      "[1124/1762] D loss: 1.3893, G loss: 0.7136\n",
      "[1204/1762] D loss: 1.0399, G loss: 2.2631\n",
      "[1284/1762] D loss: 1.3866, G loss: 0.6983\n",
      "[1364/1762] D loss: 1.3859, G loss: 0.6877\n",
      "[1444/1762] D loss: 1.3874, G loss: 0.6796\n",
      "[1524/1762] D loss: 1.3868, G loss: 0.6921\n",
      "[1604/1762] D loss: 1.3868, G loss: 0.7092\n",
      "[1684/1762] D loss: 1.3861, G loss: 0.6977\n",
      "[1762/1762] D loss: 1.3857, G loss: 0.6975\n",
      "train error: \n",
      " D loss: 1.283189, G loss: 1.148660, D accuracy: 54.0%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.254533, G loss: 1.283848, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3870, G loss: 0.6782\n",
      "[84/1762] D loss: 1.3865, G loss: 0.6886\n",
      "[164/1762] D loss: 1.3868, G loss: 0.6949\n",
      "[244/1762] D loss: 1.3873, G loss: 0.6891\n",
      "[324/1762] D loss: 1.3865, G loss: 0.6849\n",
      "[404/1762] D loss: 1.3868, G loss: 0.7212\n",
      "[484/1762] D loss: 1.0403, G loss: 2.2167\n",
      "[564/1762] D loss: 1.3870, G loss: 0.6816\n",
      "[644/1762] D loss: 1.0399, G loss: 2.3705\n",
      "[724/1762] D loss: 1.3872, G loss: 0.6739\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6979\n",
      "[884/1762] D loss: 1.0395, G loss: 2.1834\n",
      "[964/1762] D loss: 1.0400, G loss: 2.2614\n",
      "[1044/1762] D loss: 1.0401, G loss: 2.2610\n",
      "[1124/1762] D loss: 1.0399, G loss: 2.2177\n",
      "[1204/1762] D loss: 1.2121, G loss: 1.8039\n",
      "[1284/1762] D loss: 0.8672, G loss: 7.2770\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.7004\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6819\n",
      "[1524/1762] D loss: 1.3867, G loss: 0.7006\n",
      "[1604/1762] D loss: 1.3871, G loss: 0.6925\n",
      "[1684/1762] D loss: 1.3861, G loss: 0.6906\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6918\n",
      "train error: \n",
      " D loss: 1.284790, G loss: 1.090879, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.255862, G loss: 1.209054, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3857, G loss: 0.6887\n",
      "[84/1762] D loss: 1.3866, G loss: 0.7055\n",
      "[164/1762] D loss: 1.3860, G loss: 0.6989\n",
      "[244/1762] D loss: 1.3865, G loss: 0.6875\n",
      "[324/1762] D loss: 1.0410, G loss: 2.0219\n",
      "[404/1762] D loss: 1.3867, G loss: 0.6843\n",
      "[484/1762] D loss: 1.3872, G loss: 0.6811\n",
      "[564/1762] D loss: 1.3863, G loss: 0.6924\n",
      "[644/1762] D loss: 1.0401, G loss: 2.2001\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6970\n",
      "[804/1762] D loss: 1.3857, G loss: 0.6813\n",
      "[884/1762] D loss: 1.3865, G loss: 0.6985\n",
      "[964/1762] D loss: 1.0401, G loss: 2.2024\n",
      "[1044/1762] D loss: 1.0403, G loss: 2.1858\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.6917\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6857\n",
      "[1284/1762] D loss: 1.0399, G loss: 2.1429\n",
      "[1364/1762] D loss: 1.3874, G loss: 0.6889\n",
      "[1444/1762] D loss: 1.3877, G loss: 0.6783\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.6931\n",
      "[1604/1762] D loss: 1.3847, G loss: 0.6897\n",
      "[1684/1762] D loss: 1.0436, G loss: 2.1162\n",
      "[1762/1762] D loss: 1.3900, G loss: 0.7218\n",
      "train error: \n",
      " D loss: 1.270177, G loss: 1.344083, D accuracy: 55.4%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.231629, G loss: 1.565635, D accuracy: 56.6%, cell accuracy: 99.8%, board accuracy: 83.9% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3908, G loss: 0.7408\n",
      "[84/1762] D loss: 1.0436, G loss: 2.4228\n",
      "[164/1762] D loss: 1.3871, G loss: 0.6975\n",
      "[244/1762] D loss: 1.3869, G loss: 0.6773\n",
      "[324/1762] D loss: 1.3880, G loss: 0.7463\n",
      "[404/1762] D loss: 1.0440, G loss: 1.6345\n",
      "[484/1762] D loss: 1.3877, G loss: 0.6586\n",
      "[564/1762] D loss: 1.0412, G loss: 1.8707\n",
      "[644/1762] D loss: 1.3867, G loss: 0.7021\n",
      "[724/1762] D loss: 1.0410, G loss: 1.8643\n",
      "[804/1762] D loss: 1.0407, G loss: 1.9575\n",
      "[884/1762] D loss: 1.3871, G loss: 0.6936\n",
      "[964/1762] D loss: 1.3865, G loss: 0.6887\n",
      "[1044/1762] D loss: 1.0410, G loss: 1.9525\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.7015\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6956\n",
      "[1284/1762] D loss: 1.3877, G loss: 0.6695\n",
      "[1364/1762] D loss: 1.3875, G loss: 0.6978\n",
      "[1444/1762] D loss: 1.4135, G loss: 0.5791\n",
      "[1524/1762] D loss: 1.3916, G loss: 0.7539\n",
      "[1604/1762] D loss: 1.3877, G loss: 0.6624\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.6894\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.6970\n",
      "train error: \n",
      " D loss: 1.288293, G loss: 0.986691, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 85.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.260315, G loss: 1.073475, D accuracy: 55.2%, cell accuracy: 99.7%, board accuracy: 80.9% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6948\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6926\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6912\n",
      "[244/1762] D loss: 1.3867, G loss: 0.6979\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6952\n",
      "[404/1762] D loss: 1.0459, G loss: 1.8416\n",
      "[484/1762] D loss: 1.3477, G loss: 0.7440\n",
      "[564/1762] D loss: 1.3852, G loss: 0.6878\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6915\n",
      "[724/1762] D loss: 1.3867, G loss: 0.6995\n",
      "[804/1762] D loss: 1.3855, G loss: 0.6897\n",
      "[884/1762] D loss: 1.0406, G loss: 1.9346\n",
      "[964/1762] D loss: 1.3911, G loss: 0.6856\n",
      "[1044/1762] D loss: 1.3866, G loss: 0.6912\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.6869\n",
      "[1204/1762] D loss: 1.3850, G loss: 0.6763\n",
      "[1284/1762] D loss: 1.2457, G loss: 1.1250\n",
      "[1364/1762] D loss: 1.4010, G loss: 0.5830\n",
      "[1444/1762] D loss: 1.3871, G loss: 0.6969\n",
      "[1524/1762] D loss: 1.0442, G loss: 1.5793\n",
      "[1604/1762] D loss: 1.3870, G loss: 0.6667\n",
      "[1684/1762] D loss: 1.3867, G loss: 0.6776\n",
      "[1762/1762] D loss: 1.3871, G loss: 0.6645\n",
      "train error: \n",
      " D loss: 1.287724, G loss: 0.942363, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.257669, G loss: 1.038135, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3975, G loss: 0.8010\n",
      "[84/1762] D loss: 1.2547, G loss: 0.6931\n",
      "[164/1762] D loss: 0.5384, G loss: 1.8534\n",
      "[244/1762] D loss: 0.4563, G loss: 3.8973\n",
      "[324/1762] D loss: 0.2584, G loss: 4.3466\n",
      "[404/1762] D loss: 0.5918, G loss: 6.3983\n",
      "[484/1762] D loss: 0.2503, G loss: 5.0005\n",
      "[564/1762] D loss: 0.7435, G loss: 5.5475\n",
      "[644/1762] D loss: 1.0613, G loss: 4.9141\n",
      "[724/1762] D loss: 0.4779, G loss: 2.3723\n",
      "[804/1762] D loss: 0.7978, G loss: 5.0310\n",
      "[884/1762] D loss: 0.7257, G loss: 4.2084\n",
      "[964/1762] D loss: 0.9200, G loss: 2.0084\n",
      "[1044/1762] D loss: 0.2924, G loss: 3.2555\n",
      "[1124/1762] D loss: 2.3591, G loss: 1.8990\n",
      "[1204/1762] D loss: 2.1741, G loss: 1.5429\n",
      "[1284/1762] D loss: 1.0737, G loss: 1.3272\n",
      "[1364/1762] D loss: 0.7044, G loss: 0.5672\n",
      "[1444/1762] D loss: 0.7866, G loss: 1.8214\n",
      "[1524/1762] D loss: 0.5835, G loss: 1.0786\n",
      "[1604/1762] D loss: 0.9643, G loss: 2.0739\n",
      "[1684/1762] D loss: 1.4988, G loss: 0.9130\n",
      "[1762/1762] D loss: 1.0434, G loss: 1.1976\n",
      "train error: \n",
      " D loss: 1.164151, G loss: 1.347837, D accuracy: 67.8%, cell accuracy: 97.2%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.165717, G loss: 1.345189, D accuracy: 68.1%, cell accuracy: 97.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9395, G loss: 0.8669\n",
      "[84/1762] D loss: 1.4881, G loss: 0.7261\n",
      "[164/1762] D loss: 1.3364, G loss: 0.5789\n",
      "[244/1762] D loss: 0.8497, G loss: 1.0556\n",
      "[324/1762] D loss: 0.6372, G loss: 1.7005\n",
      "[404/1762] D loss: 0.8814, G loss: 1.3006\n",
      "[484/1762] D loss: 0.6881, G loss: 1.9378\n",
      "[564/1762] D loss: 1.1126, G loss: 0.3313\n",
      "[644/1762] D loss: 0.9892, G loss: 1.0086\n",
      "[724/1762] D loss: 1.1555, G loss: 2.0365\n",
      "[804/1762] D loss: 1.1816, G loss: 0.6667\n",
      "[884/1762] D loss: 1.3149, G loss: 1.1858\n",
      "[964/1762] D loss: 0.9790, G loss: 0.8684\n",
      "[1044/1762] D loss: 1.2937, G loss: 1.0068\n",
      "[1124/1762] D loss: 1.4732, G loss: 0.5967\n",
      "[1204/1762] D loss: 1.4606, G loss: 0.9126\n",
      "[1284/1762] D loss: 1.6109, G loss: 0.3376\n",
      "[1364/1762] D loss: 1.2949, G loss: 0.7040\n",
      "[1444/1762] D loss: 1.1231, G loss: 0.8553\n",
      "[1524/1762] D loss: 1.4305, G loss: 0.6787\n",
      "[1604/1762] D loss: 1.3279, G loss: 0.7464\n",
      "[1684/1762] D loss: 1.4147, G loss: 0.6506\n",
      "[1762/1762] D loss: 1.2640, G loss: 0.8745\n",
      "train error: \n",
      " D loss: 1.356939, G loss: 0.844530, D accuracy: 54.8%, cell accuracy: 99.4%, board accuracy: 46.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.359845, G loss: 0.838176, D accuracy: 54.8%, cell accuracy: 99.3%, board accuracy: 44.3% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3328, G loss: 0.8881\n",
      "[84/1762] D loss: 1.3550, G loss: 0.8469\n",
      "[164/1762] D loss: 1.2407, G loss: 0.8122\n",
      "[244/1762] D loss: 1.3316, G loss: 0.7123\n",
      "[324/1762] D loss: 1.4524, G loss: 0.9321\n",
      "[404/1762] D loss: 1.3528, G loss: 0.7527\n",
      "[484/1762] D loss: 1.2333, G loss: 0.8349\n",
      "[564/1762] D loss: 1.3960, G loss: 0.7749\n",
      "[644/1762] D loss: 1.3671, G loss: 0.7370\n",
      "[724/1762] D loss: 1.3594, G loss: 0.7671\n",
      "[804/1762] D loss: 1.2638, G loss: 0.9075\n",
      "[884/1762] D loss: 1.3892, G loss: 0.6661\n",
      "[964/1762] D loss: 1.3151, G loss: 0.8040\n",
      "[1044/1762] D loss: 1.3511, G loss: 0.7065\n",
      "[1124/1762] D loss: 1.3042, G loss: 0.7037\n",
      "[1204/1762] D loss: 1.2944, G loss: 0.7907\n",
      "[1284/1762] D loss: 1.3709, G loss: 0.6133\n",
      "[1364/1762] D loss: 1.1705, G loss: 1.0442\n",
      "[1444/1762] D loss: 1.3558, G loss: 0.8173\n",
      "[1524/1762] D loss: 1.3383, G loss: 0.9084\n",
      "[1604/1762] D loss: 1.3983, G loss: 0.6756\n",
      "[1684/1762] D loss: 1.3752, G loss: 0.6503\n",
      "[1762/1762] D loss: 1.3789, G loss: 0.7055\n",
      "train error: \n",
      " D loss: 1.368896, G loss: 0.878815, D accuracy: 52.3%, cell accuracy: 99.7%, board accuracy: 76.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.368279, G loss: 0.882827, D accuracy: 52.5%, cell accuracy: 99.6%, board accuracy: 75.5% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3388, G loss: 1.1160\n",
      "[84/1762] D loss: 1.4404, G loss: 0.8351\n",
      "[164/1762] D loss: 1.4130, G loss: 0.7761\n",
      "[244/1762] D loss: 1.3696, G loss: 0.8474\n",
      "[324/1762] D loss: 1.3107, G loss: 0.7574\n",
      "[404/1762] D loss: 1.3399, G loss: 0.8291\n",
      "[484/1762] D loss: 1.3871, G loss: 0.7881\n",
      "[564/1762] D loss: 1.3672, G loss: 0.6803\n",
      "[644/1762] D loss: 1.3796, G loss: 0.6255\n",
      "[724/1762] D loss: 1.3809, G loss: 0.7934\n",
      "[804/1762] D loss: 1.3831, G loss: 0.6020\n",
      "[884/1762] D loss: 1.2905, G loss: 0.5326\n",
      "[964/1762] D loss: 1.4202, G loss: 0.7478\n",
      "[1044/1762] D loss: 1.4124, G loss: 0.5814\n",
      "[1124/1762] D loss: 1.3538, G loss: 0.7490\n",
      "[1204/1762] D loss: 1.4029, G loss: 0.5947\n",
      "[1284/1762] D loss: 1.3973, G loss: 0.6712\n",
      "[1364/1762] D loss: 1.3777, G loss: 0.6857\n",
      "[1444/1762] D loss: 1.4355, G loss: 0.5872\n",
      "[1524/1762] D loss: 1.3758, G loss: 0.7206\n",
      "[1604/1762] D loss: 1.3991, G loss: 0.5507\n",
      "[1684/1762] D loss: 1.3848, G loss: 0.6779\n",
      "[1762/1762] D loss: 1.2675, G loss: 0.6810\n",
      "train error: \n",
      " D loss: 1.343409, G loss: 0.619021, D accuracy: 59.4%, cell accuracy: 99.5%, board accuracy: 44.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.327609, G loss: 0.633416, D accuracy: 60.5%, cell accuracy: 99.4%, board accuracy: 43.2% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2971, G loss: 0.7658\n",
      "[84/1762] D loss: 1.3731, G loss: 0.7808\n",
      "[164/1762] D loss: 1.3625, G loss: 0.6462\n",
      "[244/1762] D loss: 1.3902, G loss: 0.6102\n",
      "[324/1762] D loss: 1.3765, G loss: 0.7733\n",
      "[404/1762] D loss: 1.3811, G loss: 0.6984\n",
      "[484/1762] D loss: 1.3799, G loss: 0.9310\n",
      "[564/1762] D loss: 1.3339, G loss: 0.8762\n",
      "[644/1762] D loss: 1.3883, G loss: 0.5920\n",
      "[724/1762] D loss: 1.3237, G loss: 0.7545\n",
      "[804/1762] D loss: 1.2538, G loss: 0.7283\n",
      "[884/1762] D loss: 1.3505, G loss: 1.0021\n",
      "[964/1762] D loss: 1.2480, G loss: 0.7617\n",
      "[1044/1762] D loss: 1.2122, G loss: 0.9373\n",
      "[1124/1762] D loss: 1.3939, G loss: 0.5682\n",
      "[1204/1762] D loss: 1.1733, G loss: 1.3472\n",
      "[1284/1762] D loss: 1.2760, G loss: 0.8549\n",
      "[1364/1762] D loss: 1.4192, G loss: 0.8429\n",
      "[1444/1762] D loss: 1.3814, G loss: 0.5444\n",
      "[1524/1762] D loss: 1.2023, G loss: 0.9827\n",
      "[1604/1762] D loss: 1.4318, G loss: 0.6963\n",
      "[1684/1762] D loss: 1.4585, G loss: 0.9703\n",
      "[1762/1762] D loss: 1.3835, G loss: 0.6973\n",
      "train error: \n",
      " D loss: 1.366096, G loss: 0.696710, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 72.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.360621, G loss: 0.698542, D accuracy: 55.7%, cell accuracy: 99.6%, board accuracy: 69.1% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4054, G loss: 0.6251\n",
      "[84/1762] D loss: 1.4000, G loss: 0.7937\n",
      "[164/1762] D loss: 1.4144, G loss: 0.8643\n",
      "[244/1762] D loss: 1.2999, G loss: 0.9742\n",
      "[324/1762] D loss: 1.3856, G loss: 0.7174\n",
      "[404/1762] D loss: 1.2064, G loss: 0.8656\n",
      "[484/1762] D loss: 1.3969, G loss: 0.6535\n",
      "[564/1762] D loss: 1.2994, G loss: 0.7393\n",
      "[644/1762] D loss: 1.2521, G loss: 0.8771\n",
      "[724/1762] D loss: 1.4135, G loss: 0.6656\n",
      "[804/1762] D loss: 1.3023, G loss: 0.8622\n",
      "[884/1762] D loss: 1.3507, G loss: 0.7976\n",
      "[964/1762] D loss: 1.3920, G loss: 0.7571\n",
      "[1044/1762] D loss: 1.4058, G loss: 0.7751\n",
      "[1124/1762] D loss: 1.4269, G loss: 0.8422\n",
      "[1204/1762] D loss: 1.6365, G loss: 0.5294\n",
      "[1284/1762] D loss: 1.3826, G loss: 0.6841\n",
      "[1364/1762] D loss: 1.3662, G loss: 0.7072\n",
      "[1444/1762] D loss: 1.3303, G loss: 0.7170\n",
      "[1524/1762] D loss: 1.2502, G loss: 0.8352\n",
      "[1604/1762] D loss: 0.9127, G loss: 0.9027\n",
      "[1684/1762] D loss: 0.1972, G loss: 2.3262\n",
      "[1762/1762] D loss: 0.0075, G loss: 5.6691\n",
      "train error: \n",
      " D loss: 0.018384, G loss: 4.877939, D accuracy: 100.0%, cell accuracy: 93.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.021835, G loss: 4.849442, D accuracy: 99.9%, cell accuracy: 93.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0079, G loss: 5.6393\n",
      "[84/1762] D loss: 0.5860, G loss: 1.3437\n",
      "[164/1762] D loss: 1.3582, G loss: 0.8350\n",
      "[244/1762] D loss: 1.3885, G loss: 0.7586\n",
      "[324/1762] D loss: 1.3795, G loss: 0.7133\n",
      "[404/1762] D loss: 1.3596, G loss: 0.7374\n",
      "[484/1762] D loss: 1.4177, G loss: 0.6183\n",
      "[564/1762] D loss: 1.3641, G loss: 0.6684\n",
      "[644/1762] D loss: 1.2976, G loss: 0.6916\n",
      "[724/1762] D loss: 1.3573, G loss: 0.7063\n",
      "[804/1762] D loss: 1.3757, G loss: 0.6873\n",
      "[884/1762] D loss: 1.3871, G loss: 0.6607\n",
      "[964/1762] D loss: 1.3792, G loss: 0.7486\n",
      "[1044/1762] D loss: 1.3876, G loss: 0.7251\n",
      "[1124/1762] D loss: 1.3787, G loss: 0.7228\n",
      "[1204/1762] D loss: 1.3707, G loss: 0.6301\n",
      "[1284/1762] D loss: 1.3854, G loss: 0.7346\n",
      "[1364/1762] D loss: 1.3888, G loss: 0.7598\n",
      "[1444/1762] D loss: 1.3874, G loss: 0.7518\n",
      "[1524/1762] D loss: 1.2843, G loss: 0.6609\n",
      "[1604/1762] D loss: 1.3909, G loss: 0.7464\n",
      "[1684/1762] D loss: 1.1975, G loss: 0.7377\n",
      "[1762/1762] D loss: 1.3645, G loss: 0.7512\n",
      "train error: \n",
      " D loss: 1.340266, G loss: 0.710783, D accuracy: 56.3%, cell accuracy: 99.4%, board accuracy: 36.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.323984, G loss: 0.721528, D accuracy: 58.1%, cell accuracy: 99.3%, board accuracy: 33.9% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3746, G loss: 0.7360\n",
      "[84/1762] D loss: 1.1915, G loss: 0.8503\n",
      "[164/1762] D loss: 1.2966, G loss: 0.7325\n",
      "[244/1762] D loss: 1.1308, G loss: 0.8154\n",
      "[324/1762] D loss: 1.2223, G loss: 0.5605\n",
      "[404/1762] D loss: 1.2065, G loss: 0.7118\n",
      "[484/1762] D loss: 1.1625, G loss: 0.9028\n",
      "[564/1762] D loss: 1.0009, G loss: 1.0040\n",
      "[644/1762] D loss: 1.2853, G loss: 0.5605\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6827\n",
      "[804/1762] D loss: 1.4027, G loss: 0.7271\n",
      "[884/1762] D loss: 1.4536, G loss: 0.4633\n",
      "[964/1762] D loss: 1.4098, G loss: 0.6811\n",
      "[1044/1762] D loss: 1.3221, G loss: 0.7599\n",
      "[1124/1762] D loss: 1.3889, G loss: 0.6314\n",
      "[1204/1762] D loss: 1.3990, G loss: 0.6458\n",
      "[1284/1762] D loss: 1.3891, G loss: 0.9921\n",
      "[1364/1762] D loss: 1.3052, G loss: 0.8736\n",
      "[1444/1762] D loss: 1.4059, G loss: 0.7899\n",
      "[1524/1762] D loss: 1.3806, G loss: 0.5941\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.9157\n",
      "[1684/1762] D loss: 1.1111, G loss: 1.0363\n",
      "[1762/1762] D loss: 1.3858, G loss: 0.6666\n",
      "train error: \n",
      " D loss: 1.339416, G loss: 0.628116, D accuracy: 54.6%, cell accuracy: 99.7%, board accuracy: 74.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.324391, G loss: 0.632248, D accuracy: 55.7%, cell accuracy: 99.7%, board accuracy: 70.7% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3926, G loss: 0.6109\n",
      "[84/1762] D loss: 1.3860, G loss: 0.6849\n",
      "[164/1762] D loss: 1.3861, G loss: 0.7449\n",
      "[244/1762] D loss: 1.3503, G loss: 0.8887\n",
      "[324/1762] D loss: 1.1446, G loss: 1.0247\n",
      "[404/1762] D loss: 1.3856, G loss: 0.7281\n",
      "[484/1762] D loss: 1.3915, G loss: 0.6012\n",
      "[564/1762] D loss: 1.3823, G loss: 0.6253\n",
      "[644/1762] D loss: 1.3871, G loss: 0.7043\n",
      "[724/1762] D loss: 1.3895, G loss: 0.6485\n",
      "[804/1762] D loss: 1.1157, G loss: 0.7582\n",
      "[884/1762] D loss: 1.4140, G loss: 0.7498\n",
      "[964/1762] D loss: 1.3904, G loss: 0.6558\n",
      "[1044/1762] D loss: 1.4048, G loss: 0.7956\n",
      "[1124/1762] D loss: 1.3565, G loss: 0.7731\n",
      "[1204/1762] D loss: 1.3616, G loss: 0.7587\n",
      "[1284/1762] D loss: 1.1373, G loss: 0.8234\n",
      "[1364/1762] D loss: 1.2152, G loss: 0.8081\n",
      "[1444/1762] D loss: 1.3782, G loss: 0.7081\n",
      "[1524/1762] D loss: 1.4020, G loss: 0.5902\n",
      "[1604/1762] D loss: 1.3825, G loss: 0.6047\n",
      "[1684/1762] D loss: 1.4028, G loss: 0.7457\n",
      "[1762/1762] D loss: 1.2466, G loss: 1.2253\n",
      "train error: \n",
      " D loss: 1.357886, G loss: 1.052325, D accuracy: 54.2%, cell accuracy: 99.6%, board accuracy: 73.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.333332, G loss: 1.067672, D accuracy: 55.2%, cell accuracy: 99.5%, board accuracy: 70.0% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3734, G loss: 0.9187\n",
      "[84/1762] D loss: 1.1007, G loss: 0.9660\n",
      "[164/1762] D loss: 1.2639, G loss: 0.9139\n",
      "[244/1762] D loss: 1.4091, G loss: 0.5649\n",
      "[324/1762] D loss: 1.3793, G loss: 0.6404\n",
      "[404/1762] D loss: 1.1115, G loss: 0.9630\n",
      "[484/1762] D loss: 1.0993, G loss: 0.7468\n",
      "[564/1762] D loss: 1.3871, G loss: 0.7451\n",
      "[644/1762] D loss: 1.3788, G loss: 0.6682\n",
      "[724/1762] D loss: 1.3876, G loss: 0.6401\n",
      "[804/1762] D loss: 1.0987, G loss: 0.9698\n",
      "[884/1762] D loss: 1.3871, G loss: 0.7269\n",
      "[964/1762] D loss: 1.4110, G loss: 0.6990\n",
      "[1044/1762] D loss: 1.3873, G loss: 0.6113\n",
      "[1124/1762] D loss: 1.2690, G loss: 0.9854\n",
      "[1204/1762] D loss: 1.2862, G loss: 0.8023\n",
      "[1284/1762] D loss: 1.3913, G loss: 0.6853\n",
      "[1364/1762] D loss: 1.3940, G loss: 0.7302\n",
      "[1444/1762] D loss: 1.3614, G loss: 0.6840\n",
      "[1524/1762] D loss: 1.3876, G loss: 0.7122\n",
      "[1604/1762] D loss: 1.4142, G loss: 0.7576\n",
      "[1684/1762] D loss: 1.2735, G loss: 0.7592\n",
      "[1762/1762] D loss: 1.3894, G loss: 0.6449\n",
      "train error: \n",
      " D loss: 1.367732, G loss: 0.662530, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 85.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.363055, G loss: 0.666262, D accuracy: 55.3%, cell accuracy: 99.7%, board accuracy: 83.2% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4041, G loss: 0.5667\n",
      "[84/1762] D loss: 1.3248, G loss: 0.8935\n",
      "[164/1762] D loss: 1.4251, G loss: 0.5287\n",
      "[244/1762] D loss: 1.3864, G loss: 0.7529\n",
      "[324/1762] D loss: 1.3877, G loss: 0.6622\n",
      "[404/1762] D loss: 1.2743, G loss: 0.7838\n",
      "[484/1762] D loss: 1.3944, G loss: 0.6200\n",
      "[564/1762] D loss: 1.3994, G loss: 0.6688\n",
      "[644/1762] D loss: 1.1175, G loss: 0.9343\n",
      "[724/1762] D loss: 1.3892, G loss: 0.7331\n",
      "[804/1762] D loss: 1.3875, G loss: 0.6924\n",
      "[884/1762] D loss: 1.2856, G loss: 1.0153\n",
      "[964/1762] D loss: 1.3754, G loss: 0.7517\n",
      "[1044/1762] D loss: 1.0440, G loss: 1.6658\n",
      "[1124/1762] D loss: 1.5749, G loss: 1.8702\n",
      "[1204/1762] D loss: 1.3621, G loss: 0.6931\n",
      "[1284/1762] D loss: 1.3500, G loss: 0.7136\n",
      "[1364/1762] D loss: 1.3619, G loss: 0.6951\n",
      "[1444/1762] D loss: 0.7824, G loss: 1.3267\n",
      "[1524/1762] D loss: 1.3916, G loss: 0.6752\n",
      "[1604/1762] D loss: 1.3544, G loss: 0.7414\n",
      "[1684/1762] D loss: 1.3532, G loss: 0.7096\n",
      "[1762/1762] D loss: 0.7988, G loss: 1.2078\n",
      "train error: \n",
      " D loss: 1.306116, G loss: 0.792907, D accuracy: 55.1%, cell accuracy: 99.7%, board accuracy: 77.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.277773, G loss: 0.835372, D accuracy: 55.8%, cell accuracy: 99.7%, board accuracy: 74.1% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0973, G loss: 1.1842\n",
      "[84/1762] D loss: 1.3900, G loss: 0.7191\n",
      "[164/1762] D loss: 1.3728, G loss: 0.7092\n",
      "[244/1762] D loss: 1.1078, G loss: 0.8687\n",
      "[324/1762] D loss: 1.4096, G loss: 0.8324\n",
      "[404/1762] D loss: 1.4213, G loss: 0.6439\n",
      "[484/1762] D loss: 1.3999, G loss: 0.6227\n",
      "[564/1762] D loss: 1.3708, G loss: 0.6945\n",
      "[644/1762] D loss: 1.3945, G loss: 0.7806\n",
      "[724/1762] D loss: 1.4038, G loss: 0.5890\n",
      "[804/1762] D loss: 1.4811, G loss: 0.7451\n",
      "[884/1762] D loss: 1.3183, G loss: 1.6909\n",
      "[964/1762] D loss: 1.3683, G loss: 0.6952\n",
      "[1044/1762] D loss: 1.0631, G loss: 1.1559\n",
      "[1124/1762] D loss: 1.3440, G loss: 0.7331\n",
      "[1204/1762] D loss: 1.3707, G loss: 0.6509\n",
      "[1284/1762] D loss: 1.0449, G loss: 0.9320\n",
      "[1364/1762] D loss: 1.2145, G loss: 0.7152\n",
      "[1444/1762] D loss: 0.9779, G loss: 0.8390\n",
      "[1524/1762] D loss: 1.4716, G loss: 0.6934\n",
      "[1604/1762] D loss: 1.3218, G loss: 0.7430\n",
      "[1684/1762] D loss: 1.3964, G loss: 0.7966\n",
      "[1762/1762] D loss: 1.3921, G loss: 0.7149\n",
      "train error: \n",
      " D loss: 1.324545, G loss: 0.763654, D accuracy: 55.4%, cell accuracy: 99.7%, board accuracy: 77.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.308070, G loss: 0.769825, D accuracy: 57.2%, cell accuracy: 99.6%, board accuracy: 74.8% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3903, G loss: 0.7495\n",
      "[84/1762] D loss: 0.9823, G loss: 0.7358\n",
      "[164/1762] D loss: 1.3597, G loss: 0.7233\n",
      "[244/1762] D loss: 1.3913, G loss: 0.6699\n",
      "[324/1762] D loss: 1.3972, G loss: 0.7104\n",
      "[404/1762] D loss: 1.3677, G loss: 0.7679\n",
      "[484/1762] D loss: 1.3999, G loss: 0.8077\n",
      "[564/1762] D loss: 1.3155, G loss: 0.8280\n",
      "[644/1762] D loss: 1.3921, G loss: 0.7230\n",
      "[724/1762] D loss: 1.3871, G loss: 0.7053\n",
      "[804/1762] D loss: 1.3776, G loss: 0.6418\n",
      "[884/1762] D loss: 0.9471, G loss: 1.2886\n",
      "[964/1762] D loss: 1.4335, G loss: 0.5432\n",
      "[1044/1762] D loss: 1.3879, G loss: 0.6939\n",
      "[1124/1762] D loss: 1.3523, G loss: 0.6695\n",
      "[1204/1762] D loss: 1.4132, G loss: 0.7703\n",
      "[1284/1762] D loss: 1.4241, G loss: 0.8272\n",
      "[1364/1762] D loss: 1.3122, G loss: 1.2408\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.7079\n",
      "[1524/1762] D loss: 1.0598, G loss: 1.3400\n",
      "[1604/1762] D loss: 1.0345, G loss: 1.6438\n",
      "[1684/1762] D loss: 1.2816, G loss: 1.2963\n",
      "[1762/1762] D loss: 0.9739, G loss: 1.8736\n",
      "train error: \n",
      " D loss: 1.439174, G loss: 1.334857, D accuracy: 54.1%, cell accuracy: 99.7%, board accuracy: 79.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.402317, G loss: 1.370740, D accuracy: 55.1%, cell accuracy: 99.6%, board accuracy: 75.0% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1605, G loss: 1.7349\n",
      "[84/1762] D loss: 1.4459, G loss: 0.9300\n",
      "[164/1762] D loss: 1.3779, G loss: 0.7582\n",
      "[244/1762] D loss: 1.0778, G loss: 1.1749\n",
      "[324/1762] D loss: 1.3882, G loss: 0.6890\n",
      "[404/1762] D loss: 1.2987, G loss: 1.0437\n",
      "[484/1762] D loss: 1.2014, G loss: 1.3825\n",
      "[564/1762] D loss: 1.0607, G loss: 1.3418\n",
      "[644/1762] D loss: 1.1792, G loss: 0.7919\n",
      "[724/1762] D loss: 1.4110, G loss: 0.6814\n",
      "[804/1762] D loss: 0.9851, G loss: 1.7015\n",
      "[884/1762] D loss: 1.3893, G loss: 0.6875\n",
      "[964/1762] D loss: 1.0514, G loss: 1.3193\n",
      "[1044/1762] D loss: 1.3867, G loss: 0.6830\n",
      "[1124/1762] D loss: 1.4049, G loss: 0.6587\n",
      "[1204/1762] D loss: 1.3828, G loss: 0.8203\n",
      "[1284/1762] D loss: 1.3889, G loss: 0.6710\n",
      "[1364/1762] D loss: 1.3975, G loss: 0.6250\n",
      "[1444/1762] D loss: 1.1971, G loss: 1.1604\n",
      "[1524/1762] D loss: 1.3912, G loss: 0.6338\n",
      "[1604/1762] D loss: 1.3086, G loss: 0.8666\n",
      "[1684/1762] D loss: 1.3857, G loss: 0.6566\n",
      "[1762/1762] D loss: 0.9737, G loss: 0.8817\n",
      "train error: \n",
      " D loss: 1.308919, G loss: 0.708160, D accuracy: 54.3%, cell accuracy: 99.7%, board accuracy: 79.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.280059, G loss: 0.753973, D accuracy: 55.2%, cell accuracy: 99.7%, board accuracy: 77.3% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0765, G loss: 1.0898\n",
      "[84/1762] D loss: 1.3893, G loss: 0.7182\n",
      "[164/1762] D loss: 1.0602, G loss: 1.4140\n",
      "[244/1762] D loss: 1.3688, G loss: 0.6782\n",
      "[324/1762] D loss: 1.2983, G loss: 0.6240\n",
      "[404/1762] D loss: 1.4021, G loss: 0.5477\n",
      "[484/1762] D loss: 1.3977, G loss: 0.7124\n",
      "[564/1762] D loss: 1.3870, G loss: 0.7043\n",
      "[644/1762] D loss: 1.0456, G loss: 1.8784\n",
      "[724/1762] D loss: 1.3955, G loss: 0.6361\n",
      "[804/1762] D loss: 1.3912, G loss: 0.6693\n",
      "[884/1762] D loss: 1.2933, G loss: 1.2108\n",
      "[964/1762] D loss: 0.7727, G loss: 1.5585\n",
      "[1044/1762] D loss: 1.0742, G loss: 1.4418\n",
      "[1124/1762] D loss: 1.0643, G loss: 1.0571\n",
      "[1204/1762] D loss: 1.4106, G loss: 0.8562\n",
      "[1284/1762] D loss: 1.3886, G loss: 0.6489\n",
      "[1364/1762] D loss: 1.3810, G loss: 0.6172\n",
      "[1444/1762] D loss: 1.3242, G loss: 0.7301\n",
      "[1524/1762] D loss: 1.3413, G loss: 0.7693\n",
      "[1604/1762] D loss: 1.0303, G loss: 1.1762\n",
      "[1684/1762] D loss: 1.3996, G loss: 0.7086\n",
      "[1762/1762] D loss: 1.4552, G loss: 0.6912\n",
      "train error: \n",
      " D loss: 1.220556, G loss: 0.971633, D accuracy: 60.5%, cell accuracy: 99.4%, board accuracy: 75.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.203514, G loss: 1.058594, D accuracy: 61.0%, cell accuracy: 99.4%, board accuracy: 71.1% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3925, G loss: 0.6608\n",
      "[84/1762] D loss: 1.0607, G loss: 1.8946\n",
      "[164/1762] D loss: 1.0889, G loss: 1.6286\n",
      "[244/1762] D loss: 1.3960, G loss: 0.7865\n",
      "[324/1762] D loss: 1.2667, G loss: 1.4263\n",
      "[404/1762] D loss: 1.3911, G loss: 0.6584\n",
      "[484/1762] D loss: 1.2962, G loss: 0.8290\n",
      "[564/1762] D loss: 1.3881, G loss: 0.6901\n",
      "[644/1762] D loss: 1.4135, G loss: 0.5369\n",
      "[724/1762] D loss: 1.0683, G loss: 2.0289\n",
      "[804/1762] D loss: 1.3914, G loss: 0.6435\n",
      "[884/1762] D loss: 1.3498, G loss: 0.7478\n",
      "[964/1762] D loss: 1.3755, G loss: 0.6981\n",
      "[1044/1762] D loss: 1.3883, G loss: 0.6676\n",
      "[1124/1762] D loss: 1.3886, G loss: 0.6508\n",
      "[1204/1762] D loss: 1.3950, G loss: 0.6389\n",
      "[1284/1762] D loss: 1.0491, G loss: 1.3948\n",
      "[1364/1762] D loss: 1.4133, G loss: 0.8187\n",
      "[1444/1762] D loss: 1.3942, G loss: 0.6519\n",
      "[1524/1762] D loss: 1.3885, G loss: 0.7312\n",
      "[1604/1762] D loss: 1.2132, G loss: 0.6911\n",
      "[1684/1762] D loss: 1.3924, G loss: 0.6441\n",
      "[1762/1762] D loss: 1.3943, G loss: 0.6189\n",
      "train error: \n",
      " D loss: 1.276309, G loss: 1.030079, D accuracy: 55.8%, cell accuracy: 99.8%, board accuracy: 84.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.246088, G loss: 1.124855, D accuracy: 57.7%, cell accuracy: 99.7%, board accuracy: 82.5% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3896, G loss: 0.6763\n",
      "[84/1762] D loss: 1.3337, G loss: 0.7968\n",
      "[164/1762] D loss: 1.0756, G loss: 1.4532\n",
      "[244/1762] D loss: 1.3814, G loss: 0.6256\n",
      "[324/1762] D loss: 1.3859, G loss: 0.6950\n",
      "[404/1762] D loss: 1.3889, G loss: 0.7045\n",
      "[484/1762] D loss: 1.1488, G loss: 1.7267\n",
      "[564/1762] D loss: 0.8575, G loss: 2.1162\n",
      "[644/1762] D loss: 1.4128, G loss: 0.7720\n",
      "[724/1762] D loss: 1.0378, G loss: 1.5530\n",
      "[804/1762] D loss: 1.2789, G loss: 0.9365\n",
      "[884/1762] D loss: 1.1281, G loss: 1.5345\n",
      "[964/1762] D loss: 1.2945, G loss: 0.7473\n",
      "[1044/1762] D loss: 1.4021, G loss: 0.7657\n",
      "[1124/1762] D loss: 1.3826, G loss: 0.7395\n",
      "[1204/1762] D loss: 1.3947, G loss: 0.8667\n",
      "[1284/1762] D loss: 0.6552, G loss: 4.2291\n",
      "[1364/1762] D loss: 1.0436, G loss: 1.9391\n",
      "[1444/1762] D loss: 1.3883, G loss: 0.7002\n",
      "[1524/1762] D loss: 1.0540, G loss: 1.5190\n",
      "[1604/1762] D loss: 1.0422, G loss: 2.1587\n",
      "[1684/1762] D loss: 1.3885, G loss: 0.7169\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6850\n",
      "train error: \n",
      " D loss: 1.266828, G loss: 1.071232, D accuracy: 57.2%, cell accuracy: 99.7%, board accuracy: 72.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.238787, G loss: 1.200170, D accuracy: 58.1%, cell accuracy: 99.6%, board accuracy: 68.2% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3369, G loss: 0.8308\n",
      "[84/1762] D loss: 1.0551, G loss: 1.2935\n",
      "[164/1762] D loss: 1.3453, G loss: 0.7004\n",
      "[244/1762] D loss: 1.3895, G loss: 0.7138\n",
      "[324/1762] D loss: 1.0591, G loss: 1.2368\n",
      "[404/1762] D loss: 0.7136, G loss: 2.0868\n",
      "[484/1762] D loss: 1.0656, G loss: 1.7677\n",
      "[564/1762] D loss: 1.0505, G loss: 1.6390\n",
      "[644/1762] D loss: 1.0551, G loss: 1.2959\n",
      "[724/1762] D loss: 1.0455, G loss: 1.5692\n",
      "[804/1762] D loss: 1.3901, G loss: 0.6635\n",
      "[884/1762] D loss: 1.3890, G loss: 0.6893\n",
      "[964/1762] D loss: 1.0436, G loss: 1.7646\n",
      "[1044/1762] D loss: 0.8799, G loss: 2.6225\n",
      "[1124/1762] D loss: 1.3953, G loss: 0.6346\n",
      "[1204/1762] D loss: 1.3145, G loss: 0.8273\n",
      "[1284/1762] D loss: 1.3891, G loss: 0.6719\n",
      "[1364/1762] D loss: 1.3875, G loss: 0.6703\n",
      "[1444/1762] D loss: 1.3875, G loss: 0.7395\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.6929\n",
      "[1604/1762] D loss: 1.4902, G loss: 0.6930\n",
      "[1684/1762] D loss: 1.3550, G loss: 1.0358\n",
      "[1762/1762] D loss: 1.3970, G loss: 0.5971\n",
      "train error: \n",
      " D loss: 1.274896, G loss: 0.921210, D accuracy: 57.5%, cell accuracy: 99.6%, board accuracy: 75.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.258074, G loss: 0.970236, D accuracy: 57.7%, cell accuracy: 99.6%, board accuracy: 74.3% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4129, G loss: 0.5451\n",
      "[84/1762] D loss: 1.3207, G loss: 0.8496\n",
      "[164/1762] D loss: 0.9800, G loss: 1.1714\n",
      "[244/1762] D loss: 1.1855, G loss: 1.3531\n",
      "[324/1762] D loss: 1.1866, G loss: 2.1391\n",
      "[404/1762] D loss: 1.2812, G loss: 0.9297\n",
      "[484/1762] D loss: 1.0319, G loss: 1.3542\n",
      "[564/1762] D loss: 1.0496, G loss: 1.3898\n",
      "[644/1762] D loss: 1.3699, G loss: 0.8351\n",
      "[724/1762] D loss: 1.3138, G loss: 1.1484\n",
      "[804/1762] D loss: 1.3586, G loss: 0.7112\n",
      "[884/1762] D loss: 1.3872, G loss: 0.6731\n",
      "[964/1762] D loss: 1.4008, G loss: 0.5785\n",
      "[1044/1762] D loss: 1.3884, G loss: 0.7007\n",
      "[1124/1762] D loss: 1.0426, G loss: 1.6456\n",
      "[1204/1762] D loss: 0.9113, G loss: 3.8691\n",
      "[1284/1762] D loss: 1.3881, G loss: 0.6638\n",
      "[1364/1762] D loss: 1.3875, G loss: 0.7209\n",
      "[1444/1762] D loss: 1.3881, G loss: 0.7274\n",
      "[1524/1762] D loss: 1.0429, G loss: 1.7930\n",
      "[1604/1762] D loss: 1.3867, G loss: 0.6884\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.6988\n",
      "[1762/1762] D loss: 1.3881, G loss: 0.7207\n",
      "train error: \n",
      " D loss: 1.285696, G loss: 1.062667, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.259169, G loss: 1.144386, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0401, G loss: 1.9730\n",
      "[84/1762] D loss: 1.0405, G loss: 2.0168\n",
      "[164/1762] D loss: 1.0412, G loss: 2.1810\n",
      "[244/1762] D loss: 1.3871, G loss: 0.7008\n",
      "[324/1762] D loss: 1.2062, G loss: 1.9689\n",
      "[404/1762] D loss: 1.3871, G loss: 0.7006\n",
      "[484/1762] D loss: 1.3871, G loss: 0.6807\n",
      "[564/1762] D loss: 1.0380, G loss: 2.1809\n",
      "[644/1762] D loss: 1.3861, G loss: 0.7080\n",
      "[724/1762] D loss: 1.0417, G loss: 1.8545\n",
      "[804/1762] D loss: 1.3866, G loss: 0.6833\n",
      "[884/1762] D loss: 1.3871, G loss: 0.7151\n",
      "[964/1762] D loss: 1.3865, G loss: 0.6871\n",
      "[1044/1762] D loss: 1.3866, G loss: 0.6795\n",
      "[1124/1762] D loss: 1.3875, G loss: 0.6845\n",
      "[1204/1762] D loss: 1.3523, G loss: 0.7341\n",
      "[1284/1762] D loss: 1.3952, G loss: 0.6949\n",
      "[1364/1762] D loss: 1.0403, G loss: 2.0934\n",
      "[1444/1762] D loss: 1.2877, G loss: 1.0311\n",
      "[1524/1762] D loss: 1.3957, G loss: 0.6366\n",
      "[1604/1762] D loss: 1.3870, G loss: 0.6882\n",
      "[1684/1762] D loss: 1.3870, G loss: 0.7177\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.6908\n",
      "train error: \n",
      " D loss: 1.284924, G loss: 1.061580, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 90.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.253686, G loss: 1.188253, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6883\n",
      "[84/1762] D loss: 1.0416, G loss: 2.0949\n",
      "[164/1762] D loss: 1.0382, G loss: 1.9710\n",
      "[244/1762] D loss: 1.0408, G loss: 2.1606\n",
      "[324/1762] D loss: 1.3867, G loss: 0.6979\n",
      "[404/1762] D loss: 1.3875, G loss: 0.6669\n",
      "[484/1762] D loss: 1.2306, G loss: 0.9634\n",
      "[564/1762] D loss: 1.0902, G loss: 1.6674\n",
      "[644/1762] D loss: 1.3877, G loss: 0.7291\n",
      "[724/1762] D loss: 1.3873, G loss: 0.6887\n",
      "[804/1762] D loss: 1.3866, G loss: 0.7018\n",
      "[884/1762] D loss: 1.3867, G loss: 0.6867\n",
      "[964/1762] D loss: 1.0413, G loss: 2.0161\n",
      "[1044/1762] D loss: 1.2193, G loss: 1.3245\n",
      "[1124/1762] D loss: 1.3860, G loss: 0.6864\n",
      "[1204/1762] D loss: 1.3883, G loss: 0.6569\n",
      "[1284/1762] D loss: 1.3882, G loss: 0.6515\n",
      "[1364/1762] D loss: 1.3868, G loss: 0.7107\n",
      "[1444/1762] D loss: 1.3844, G loss: 0.6340\n",
      "[1524/1762] D loss: 1.3907, G loss: 0.6514\n",
      "[1604/1762] D loss: 1.4126, G loss: 0.5483\n",
      "[1684/1762] D loss: 1.1212, G loss: 0.9189\n",
      "[1762/1762] D loss: 1.3869, G loss: 0.6669\n",
      "train error: \n",
      " D loss: 1.298492, G loss: 0.720017, D accuracy: 56.6%, cell accuracy: 99.5%, board accuracy: 61.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.279616, G loss: 0.732546, D accuracy: 57.2%, cell accuracy: 99.5%, board accuracy: 57.7% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2251, G loss: 0.6894\n",
      "[84/1762] D loss: 1.0831, G loss: 0.9804\n",
      "[164/1762] D loss: 1.3850, G loss: 0.7051\n",
      "[244/1762] D loss: 1.4297, G loss: 0.5307\n",
      "[324/1762] D loss: 1.3933, G loss: 0.7051\n",
      "[404/1762] D loss: 1.1900, G loss: 0.7181\n",
      "[484/1762] D loss: 1.3624, G loss: 0.9248\n",
      "[564/1762] D loss: 1.0534, G loss: 1.5896\n",
      "[644/1762] D loss: 1.3235, G loss: 0.7143\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6716\n",
      "[804/1762] D loss: 1.2563, G loss: 1.0004\n",
      "[884/1762] D loss: 1.3720, G loss: 0.7072\n",
      "[964/1762] D loss: 1.3671, G loss: 0.6500\n",
      "[1044/1762] D loss: 1.3912, G loss: 0.6704\n",
      "[1124/1762] D loss: 1.3859, G loss: 0.7409\n",
      "[1204/1762] D loss: 1.0411, G loss: 2.1411\n",
      "[1284/1762] D loss: 1.3769, G loss: 0.6914\n",
      "[1364/1762] D loss: 1.3909, G loss: 0.7280\n",
      "[1444/1762] D loss: 1.2438, G loss: 0.6223\n",
      "[1524/1762] D loss: 1.3979, G loss: 0.7507\n",
      "[1604/1762] D loss: 1.2696, G loss: 0.8672\n",
      "[1684/1762] D loss: 1.3874, G loss: 0.6908\n",
      "[1762/1762] D loss: 1.4364, G loss: 0.5042\n",
      "train error: \n",
      " D loss: 1.300031, G loss: 0.782130, D accuracy: 56.8%, cell accuracy: 99.6%, board accuracy: 70.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.271054, G loss: 0.857533, D accuracy: 58.1%, cell accuracy: 99.5%, board accuracy: 70.2% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0735, G loss: 1.4308\n",
      "[84/1762] D loss: 1.2784, G loss: 1.1834\n",
      "[164/1762] D loss: 1.4299, G loss: 0.7654\n",
      "[244/1762] D loss: 1.1826, G loss: 0.7837\n",
      "[324/1762] D loss: 1.3904, G loss: 0.6573\n",
      "[404/1762] D loss: 1.0480, G loss: 1.5828\n",
      "[484/1762] D loss: 1.3896, G loss: 0.7087\n",
      "[564/1762] D loss: 1.3870, G loss: 0.7018\n",
      "[644/1762] D loss: 1.3874, G loss: 0.7169\n",
      "[724/1762] D loss: 1.3889, G loss: 0.7278\n",
      "[804/1762] D loss: 1.1795, G loss: 1.5898\n",
      "[884/1762] D loss: 1.0759, G loss: 0.8478\n",
      "[964/1762] D loss: 1.3868, G loss: 0.7129\n",
      "[1044/1762] D loss: 1.3932, G loss: 0.7699\n",
      "[1124/1762] D loss: 0.9500, G loss: 3.3430\n",
      "[1204/1762] D loss: 1.3977, G loss: 0.6296\n",
      "[1284/1762] D loss: 1.3905, G loss: 0.7453\n",
      "[1364/1762] D loss: 1.2764, G loss: 0.8508\n",
      "[1444/1762] D loss: 1.3936, G loss: 0.6315\n",
      "[1524/1762] D loss: 1.3915, G loss: 0.6842\n",
      "[1604/1762] D loss: 1.3772, G loss: 0.6437\n",
      "[1684/1762] D loss: 1.0934, G loss: 2.0039\n",
      "[1762/1762] D loss: 1.3989, G loss: 0.6068\n",
      "train error: \n",
      " D loss: 1.297213, G loss: 0.755522, D accuracy: 55.6%, cell accuracy: 99.5%, board accuracy: 73.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.276416, G loss: 0.815801, D accuracy: 56.0%, cell accuracy: 99.5%, board accuracy: 73.4% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0754, G loss: 0.9922\n",
      "[84/1762] D loss: 1.3897, G loss: 0.7480\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6893\n",
      "[244/1762] D loss: 1.4015, G loss: 0.6816\n",
      "[324/1762] D loss: 1.0725, G loss: 1.1732\n",
      "[404/1762] D loss: 1.3765, G loss: 0.7170\n",
      "[484/1762] D loss: 1.3876, G loss: 0.6821\n",
      "[564/1762] D loss: 0.6911, G loss: 2.5393\n",
      "[644/1762] D loss: 1.0979, G loss: 0.9438\n",
      "[724/1762] D loss: 1.3798, G loss: 0.6981\n",
      "[804/1762] D loss: 1.3906, G loss: 0.6984\n",
      "[884/1762] D loss: 1.3430, G loss: 0.7387\n",
      "[964/1762] D loss: 1.3841, G loss: 0.6605\n",
      "[1044/1762] D loss: 1.3944, G loss: 0.7260\n",
      "[1124/1762] D loss: 1.3908, G loss: 0.6384\n",
      "[1204/1762] D loss: 1.3831, G loss: 0.7084\n",
      "[1284/1762] D loss: 1.3850, G loss: 0.6684\n",
      "[1364/1762] D loss: 1.4039, G loss: 0.5846\n",
      "[1444/1762] D loss: 1.1243, G loss: 0.8316\n",
      "[1524/1762] D loss: 1.4016, G loss: 0.6633\n",
      "[1604/1762] D loss: 1.3891, G loss: 0.6470\n",
      "[1684/1762] D loss: 1.0366, G loss: 2.0441\n",
      "[1762/1762] D loss: 1.3835, G loss: 0.7254\n",
      "train error: \n",
      " D loss: 1.287426, G loss: 1.176024, D accuracy: 53.7%, cell accuracy: 99.6%, board accuracy: 83.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.267978, G loss: 1.286200, D accuracy: 54.7%, cell accuracy: 99.5%, board accuracy: 80.7% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0410, G loss: 2.3418\n",
      "[84/1762] D loss: 1.3626, G loss: 0.6482\n",
      "[164/1762] D loss: 1.0440, G loss: 2.7105\n",
      "[244/1762] D loss: 1.3869, G loss: 0.6790\n",
      "[324/1762] D loss: 1.3899, G loss: 0.7251\n",
      "[404/1762] D loss: 1.0452, G loss: 1.4994\n",
      "[484/1762] D loss: 1.3926, G loss: 0.6753\n",
      "[564/1762] D loss: 1.3902, G loss: 0.7313\n",
      "[644/1762] D loss: 1.3894, G loss: 0.6629\n",
      "[724/1762] D loss: 1.4071, G loss: 0.7395\n",
      "[804/1762] D loss: 1.3804, G loss: 0.7179\n",
      "[884/1762] D loss: 1.0577, G loss: 1.2231\n",
      "[964/1762] D loss: 1.3879, G loss: 0.6759\n",
      "[1044/1762] D loss: 1.3887, G loss: 0.6234\n",
      "[1124/1762] D loss: 1.3868, G loss: 0.6889\n",
      "[1204/1762] D loss: 1.3592, G loss: 0.7802\n",
      "[1284/1762] D loss: 1.0615, G loss: 1.0925\n",
      "[1364/1762] D loss: 1.3873, G loss: 0.6823\n",
      "[1444/1762] D loss: 1.3886, G loss: 0.6579\n",
      "[1524/1762] D loss: 1.3978, G loss: 0.6111\n",
      "[1604/1762] D loss: 1.3814, G loss: 0.7080\n",
      "[1684/1762] D loss: 1.3890, G loss: 0.6450\n",
      "[1762/1762] D loss: 1.6070, G loss: 0.6919\n",
      "train error: \n",
      " D loss: 1.291613, G loss: 0.911088, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 84.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.260653, G loss: 0.972629, D accuracy: 56.1%, cell accuracy: 99.7%, board accuracy: 82.7% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0528, G loss: 1.2186\n",
      "[84/1762] D loss: 1.3825, G loss: 0.6499\n",
      "[164/1762] D loss: 1.3474, G loss: 0.7759\n",
      "[244/1762] D loss: 1.4021, G loss: 0.7922\n",
      "[324/1762] D loss: 1.3945, G loss: 0.6419\n",
      "[404/1762] D loss: 1.3890, G loss: 0.7184\n",
      "[484/1762] D loss: 1.3884, G loss: 0.6500\n",
      "[564/1762] D loss: 1.3393, G loss: 0.7538\n",
      "[644/1762] D loss: 1.0393, G loss: 1.8863\n",
      "[724/1762] D loss: 1.0437, G loss: 1.7921\n",
      "[804/1762] D loss: 1.3883, G loss: 0.6523\n",
      "[884/1762] D loss: 1.0406, G loss: 2.1344\n",
      "[964/1762] D loss: 1.3930, G loss: 0.6882\n",
      "[1044/1762] D loss: 1.3870, G loss: 0.6734\n",
      "[1124/1762] D loss: 1.2705, G loss: 0.8405\n",
      "[1204/1762] D loss: 1.3899, G loss: 0.6408\n",
      "[1284/1762] D loss: 1.3865, G loss: 0.6892\n",
      "[1364/1762] D loss: 1.3874, G loss: 0.6857\n",
      "[1444/1762] D loss: 1.1106, G loss: 0.8595\n",
      "[1524/1762] D loss: 1.3293, G loss: 0.8443\n",
      "[1604/1762] D loss: 1.3879, G loss: 0.6658\n",
      "[1684/1762] D loss: 1.0403, G loss: 2.6249\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.7013\n",
      "train error: \n",
      " D loss: 1.287496, G loss: 1.108897, D accuracy: 54.4%, cell accuracy: 99.7%, board accuracy: 87.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.261060, G loss: 1.280137, D accuracy: 55.1%, cell accuracy: 99.6%, board accuracy: 83.9% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3894, G loss: 0.6638\n",
      "[84/1762] D loss: 1.3881, G loss: 0.6579\n",
      "[164/1762] D loss: 1.3875, G loss: 0.6822\n",
      "[244/1762] D loss: 1.3837, G loss: 0.7471\n",
      "[324/1762] D loss: 1.0673, G loss: 1.0869\n",
      "[404/1762] D loss: 1.3867, G loss: 0.6876\n",
      "[484/1762] D loss: 1.3873, G loss: 0.7120\n",
      "[564/1762] D loss: 1.0413, G loss: 1.9868\n",
      "[644/1762] D loss: 1.3881, G loss: 0.6926\n",
      "[724/1762] D loss: 1.0747, G loss: 1.1310\n",
      "[804/1762] D loss: 1.3753, G loss: 0.7311\n",
      "[884/1762] D loss: 1.3928, G loss: 0.6402\n",
      "[964/1762] D loss: 1.0448, G loss: 1.9992\n",
      "[1044/1762] D loss: 1.3872, G loss: 0.7314\n",
      "[1124/1762] D loss: 1.3873, G loss: 0.7678\n",
      "[1204/1762] D loss: 1.3893, G loss: 0.6573\n",
      "[1284/1762] D loss: 1.0599, G loss: 1.3053\n",
      "[1364/1762] D loss: 1.3885, G loss: 0.7199\n",
      "[1444/1762] D loss: 1.3884, G loss: 0.6868\n",
      "[1524/1762] D loss: 1.3833, G loss: 0.6785\n",
      "[1604/1762] D loss: 1.3872, G loss: 0.7161\n",
      "[1684/1762] D loss: 1.3881, G loss: 0.6983\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6761\n",
      "train error: \n",
      " D loss: 1.294749, G loss: 1.180766, D accuracy: 54.3%, cell accuracy: 99.7%, board accuracy: 89.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.280554, G loss: 1.359240, D accuracy: 55.1%, cell accuracy: 99.6%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3869, G loss: 0.6885\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6989\n",
      "[164/1762] D loss: 1.3879, G loss: 0.6898\n",
      "[244/1762] D loss: 1.0399, G loss: 2.3813\n",
      "[324/1762] D loss: 1.3870, G loss: 0.6900\n",
      "[404/1762] D loss: 1.0404, G loss: 2.2646\n",
      "[484/1762] D loss: 1.3861, G loss: 0.7119\n",
      "[564/1762] D loss: 1.3729, G loss: 0.6614\n",
      "[644/1762] D loss: 1.3830, G loss: 0.7099\n",
      "[724/1762] D loss: 1.3884, G loss: 0.7102\n",
      "[804/1762] D loss: 1.0424, G loss: 1.6761\n",
      "[884/1762] D loss: 1.1806, G loss: 0.7048\n",
      "[964/1762] D loss: 1.0411, G loss: 1.8540\n",
      "[1044/1762] D loss: 1.3873, G loss: 0.7214\n",
      "[1124/1762] D loss: 1.3855, G loss: 0.6694\n",
      "[1204/1762] D loss: 1.0568, G loss: 1.8745\n",
      "[1284/1762] D loss: 1.1826, G loss: 1.3075\n",
      "[1364/1762] D loss: 1.3876, G loss: 0.7177\n",
      "[1444/1762] D loss: 1.0424, G loss: 2.3836\n",
      "[1524/1762] D loss: 1.3866, G loss: 0.7078\n",
      "[1604/1762] D loss: 1.3872, G loss: 0.7227\n",
      "[1684/1762] D loss: 1.3881, G loss: 0.7226\n",
      "[1762/1762] D loss: 1.3868, G loss: 0.6681\n",
      "train error: \n",
      " D loss: 1.286902, G loss: 1.159658, D accuracy: 53.9%, cell accuracy: 99.7%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.270409, G loss: 1.288903, D accuracy: 54.7%, cell accuracy: 99.6%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3868, G loss: 0.7067\n",
      "[84/1762] D loss: 1.4004, G loss: 0.5779\n",
      "[164/1762] D loss: 1.3881, G loss: 0.7088\n",
      "[244/1762] D loss: 1.3875, G loss: 0.6927\n",
      "[324/1762] D loss: 1.2380, G loss: 1.2977\n",
      "[404/1762] D loss: 1.0407, G loss: 2.0642\n",
      "[484/1762] D loss: 1.3870, G loss: 0.7179\n",
      "[564/1762] D loss: 1.3882, G loss: 0.6714\n",
      "[644/1762] D loss: 1.3878, G loss: 0.7268\n",
      "[724/1762] D loss: 1.0440, G loss: 2.4781\n",
      "[804/1762] D loss: 1.3869, G loss: 0.6738\n",
      "[884/1762] D loss: 1.3866, G loss: 0.6882\n",
      "[964/1762] D loss: 1.3868, G loss: 0.6864\n",
      "[1044/1762] D loss: 1.3885, G loss: 0.7343\n",
      "[1124/1762] D loss: 1.2460, G loss: 1.0553\n",
      "[1204/1762] D loss: 1.3300, G loss: 0.9856\n",
      "[1284/1762] D loss: 1.3917, G loss: 0.6582\n",
      "[1364/1762] D loss: 1.3881, G loss: 0.6821\n",
      "[1444/1762] D loss: 1.3859, G loss: 0.7023\n",
      "[1524/1762] D loss: 0.9891, G loss: 2.0238\n",
      "[1604/1762] D loss: 1.3868, G loss: 0.6801\n",
      "[1684/1762] D loss: 0.9773, G loss: 2.4861\n",
      "[1762/1762] D loss: 1.3477, G loss: 1.3889\n",
      "train error: \n",
      " D loss: 1.245828, G loss: 1.144851, D accuracy: 62.2%, cell accuracy: 99.6%, board accuracy: 54.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.222282, G loss: 1.294109, D accuracy: 62.2%, cell accuracy: 99.5%, board accuracy: 56.8% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2596, G loss: 1.3625\n",
      "[84/1762] D loss: 1.3869, G loss: 0.6492\n",
      "[164/1762] D loss: 1.3820, G loss: 0.7008\n",
      "[244/1762] D loss: 1.3874, G loss: 0.7179\n",
      "[324/1762] D loss: 1.3873, G loss: 0.6594\n",
      "[404/1762] D loss: 1.3871, G loss: 0.7092\n",
      "[484/1762] D loss: 1.3865, G loss: 0.7371\n",
      "[564/1762] D loss: 1.3905, G loss: 0.6381\n",
      "[644/1762] D loss: 1.3892, G loss: 0.6643\n",
      "[724/1762] D loss: 1.3871, G loss: 0.7122\n",
      "[804/1762] D loss: 1.3867, G loss: 0.6938\n",
      "[884/1762] D loss: 1.3866, G loss: 0.7034\n",
      "[964/1762] D loss: 1.3869, G loss: 0.6906\n",
      "[1044/1762] D loss: 1.3873, G loss: 0.6715\n",
      "[1124/1762] D loss: 1.3869, G loss: 0.7157\n",
      "[1204/1762] D loss: 1.2109, G loss: 2.4140\n",
      "[1284/1762] D loss: 1.3851, G loss: 0.7136\n",
      "[1364/1762] D loss: 1.0425, G loss: 2.2161\n",
      "[1444/1762] D loss: 1.0398, G loss: 2.7057\n",
      "[1524/1762] D loss: 1.0424, G loss: 2.0638\n",
      "[1604/1762] D loss: 1.0409, G loss: 2.1466\n",
      "[1684/1762] D loss: 1.3868, G loss: 0.6808\n",
      "[1762/1762] D loss: 1.3858, G loss: 0.6969\n",
      "train error: \n",
      " D loss: 1.289784, G loss: 1.103487, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.259840, G loss: 1.215873, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0401, G loss: 2.1868\n",
      "[84/1762] D loss: 1.0427, G loss: 1.6504\n",
      "[164/1762] D loss: 0.6940, G loss: 3.6924\n",
      "[244/1762] D loss: 1.3866, G loss: 0.6906\n",
      "[324/1762] D loss: 1.3882, G loss: 0.6528\n",
      "[404/1762] D loss: 1.3873, G loss: 0.7035\n",
      "[484/1762] D loss: 0.6861, G loss: 3.2732\n",
      "[564/1762] D loss: 1.3872, G loss: 0.6743\n",
      "[644/1762] D loss: 1.3606, G loss: 0.7071\n",
      "[724/1762] D loss: 1.3879, G loss: 0.6642\n",
      "[804/1762] D loss: 1.0412, G loss: 2.0263\n",
      "[884/1762] D loss: 1.0418, G loss: 2.2158\n",
      "[964/1762] D loss: 1.3769, G loss: 0.6427\n",
      "[1044/1762] D loss: 1.0400, G loss: 2.6629\n",
      "[1124/1762] D loss: 1.0408, G loss: 1.8273\n",
      "[1204/1762] D loss: 1.0402, G loss: 2.8089\n",
      "[1284/1762] D loss: 1.3880, G loss: 0.6578\n",
      "[1364/1762] D loss: 1.1820, G loss: 0.8312\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6458\n",
      "[1524/1762] D loss: 1.0425, G loss: 1.6818\n",
      "[1604/1762] D loss: 1.3716, G loss: 0.7117\n",
      "[1684/1762] D loss: 1.3870, G loss: 0.6720\n",
      "[1762/1762] D loss: 0.6963, G loss: 3.3578\n",
      "train error: \n",
      " D loss: 1.310827, G loss: 1.180713, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.290881, G loss: 1.323837, D accuracy: 55.7%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3502, G loss: 0.7185\n",
      "[84/1762] D loss: 1.3908, G loss: 0.6448\n",
      "[164/1762] D loss: 1.3885, G loss: 0.6796\n",
      "[244/1762] D loss: 1.3814, G loss: 0.6857\n",
      "[324/1762] D loss: 1.0426, G loss: 1.6730\n",
      "[404/1762] D loss: 1.2798, G loss: 1.2566\n",
      "[484/1762] D loss: 1.0415, G loss: 2.5166\n",
      "[564/1762] D loss: 1.3915, G loss: 0.6664\n",
      "[644/1762] D loss: 1.3881, G loss: 0.6585\n",
      "[724/1762] D loss: 1.3741, G loss: 0.7182\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6983\n",
      "[884/1762] D loss: 1.0426, G loss: 1.6809\n",
      "[964/1762] D loss: 1.3875, G loss: 0.7067\n",
      "[1044/1762] D loss: 0.9682, G loss: 2.2368\n",
      "[1124/1762] D loss: 1.3876, G loss: 0.6988\n",
      "[1204/1762] D loss: 1.3872, G loss: 0.6845\n",
      "[1284/1762] D loss: 1.3879, G loss: 0.7269\n",
      "[1364/1762] D loss: 1.3750, G loss: 0.7172\n",
      "[1444/1762] D loss: 1.3517, G loss: 0.6623\n",
      "[1524/1762] D loss: 1.3195, G loss: 0.8611\n",
      "[1604/1762] D loss: 1.3555, G loss: 0.8961\n",
      "[1684/1762] D loss: 0.6953, G loss: 3.7228\n",
      "[1762/1762] D loss: 1.3883, G loss: 0.7308\n",
      "train error: \n",
      " D loss: 1.285920, G loss: 1.179084, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.260181, G loss: 1.315414, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3872, G loss: 0.7127\n",
      "[84/1762] D loss: 1.3768, G loss: 0.6699\n",
      "[164/1762] D loss: 1.3742, G loss: 0.6001\n",
      "[244/1762] D loss: 1.3351, G loss: 0.8941\n",
      "[324/1762] D loss: 1.3913, G loss: 0.6608\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6867\n",
      "[484/1762] D loss: 1.3870, G loss: 0.6758\n",
      "[564/1762] D loss: 1.2857, G loss: 1.0276\n",
      "[644/1762] D loss: 0.6943, G loss: 4.1471\n",
      "[724/1762] D loss: 1.3876, G loss: 0.7221\n",
      "[804/1762] D loss: 0.6941, G loss: 3.9708\n",
      "[884/1762] D loss: 1.2686, G loss: 1.2157\n",
      "[964/1762] D loss: 1.0436, G loss: 2.1134\n",
      "[1044/1762] D loss: 1.3881, G loss: 0.7300\n",
      "[1124/1762] D loss: 1.3866, G loss: 0.6978\n",
      "[1204/1762] D loss: 1.2988, G loss: 1.2024\n",
      "[1284/1762] D loss: 0.7008, G loss: 3.7359\n",
      "[1364/1762] D loss: 1.3872, G loss: 0.7178\n",
      "[1444/1762] D loss: 1.3778, G loss: 0.6786\n",
      "[1524/1762] D loss: 1.0401, G loss: 2.3774\n",
      "[1604/1762] D loss: 1.3742, G loss: 0.6618\n",
      "[1684/1762] D loss: 1.3926, G loss: 0.7313\n",
      "[1762/1762] D loss: 0.6971, G loss: 2.7892\n",
      "train error: \n",
      " D loss: 1.289015, G loss: 0.981088, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 90.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.258547, G loss: 1.074337, D accuracy: 56.1%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3869, G loss: 0.6718\n",
      "[84/1762] D loss: 1.3887, G loss: 0.6569\n",
      "[164/1762] D loss: 1.3828, G loss: 0.7410\n",
      "[244/1762] D loss: 0.6967, G loss: 2.9600\n",
      "[324/1762] D loss: 1.3886, G loss: 0.6495\n",
      "[404/1762] D loss: 1.3868, G loss: 0.6958\n",
      "[484/1762] D loss: 1.0298, G loss: 2.2691\n",
      "[564/1762] D loss: 1.0476, G loss: 2.3849\n",
      "[644/1762] D loss: 1.3878, G loss: 0.6628\n",
      "[724/1762] D loss: 1.0407, G loss: 2.0252\n",
      "[804/1762] D loss: 1.3864, G loss: 0.7018\n",
      "[884/1762] D loss: 1.3877, G loss: 0.6996\n",
      "[964/1762] D loss: 1.3866, G loss: 0.7048\n",
      "[1044/1762] D loss: 1.3868, G loss: 0.7048\n",
      "[1124/1762] D loss: 1.3878, G loss: 0.6651\n",
      "[1204/1762] D loss: 1.2197, G loss: 2.0476\n",
      "[1284/1762] D loss: 1.0443, G loss: 1.9555\n",
      "[1364/1762] D loss: 1.0403, G loss: 2.0727\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.6998\n",
      "[1524/1762] D loss: 1.3868, G loss: 0.6830\n",
      "[1604/1762] D loss: 1.0406, G loss: 2.0113\n",
      "[1684/1762] D loss: 1.3861, G loss: 0.6906\n",
      "[1762/1762] D loss: 1.3862, G loss: 0.6968\n",
      "train error: \n",
      " D loss: 1.285094, G loss: 1.131317, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.256076, G loss: 1.275983, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3867, G loss: 0.6844\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6874\n",
      "[164/1762] D loss: 1.3899, G loss: 0.7585\n",
      "[244/1762] D loss: 1.0465, G loss: 2.1473\n",
      "[324/1762] D loss: 1.1293, G loss: 1.0097\n",
      "[404/1762] D loss: 0.6943, G loss: 4.4598\n",
      "[484/1762] D loss: 1.0417, G loss: 2.1611\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6929\n",
      "[644/1762] D loss: 1.3853, G loss: 0.6647\n",
      "[724/1762] D loss: 1.3890, G loss: 0.7391\n",
      "[804/1762] D loss: 1.3877, G loss: 0.6924\n",
      "[884/1762] D loss: 1.3868, G loss: 0.6963\n",
      "[964/1762] D loss: 1.4048, G loss: 0.5741\n",
      "[1044/1762] D loss: 1.3888, G loss: 0.7352\n",
      "[1124/1762] D loss: 1.3873, G loss: 0.6905\n",
      "[1204/1762] D loss: 1.0440, G loss: 1.5748\n",
      "[1284/1762] D loss: 1.3212, G loss: 0.7834\n",
      "[1364/1762] D loss: 1.0410, G loss: 2.9419\n",
      "[1444/1762] D loss: 1.0479, G loss: 1.4323\n",
      "[1524/1762] D loss: 1.0405, G loss: 2.1908\n",
      "[1604/1762] D loss: 1.3886, G loss: 0.6574\n",
      "[1684/1762] D loss: 1.3893, G loss: 0.6478\n",
      "[1762/1762] D loss: 1.3931, G loss: 0.7246\n",
      "train error: \n",
      " D loss: 1.285562, G loss: 1.292677, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 90.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.259018, G loss: 1.509678, D accuracy: 55.1%, cell accuracy: 99.7%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0429, G loss: 2.5754\n",
      "[84/1762] D loss: 1.2707, G loss: 1.3022\n",
      "[164/1762] D loss: 1.2312, G loss: 1.3359\n",
      "[244/1762] D loss: 1.0409, G loss: 2.3375\n",
      "[324/1762] D loss: 1.3837, G loss: 0.7126\n",
      "[404/1762] D loss: 1.3871, G loss: 0.7122\n",
      "[484/1762] D loss: 1.3877, G loss: 0.6564\n",
      "[564/1762] D loss: 1.3867, G loss: 0.6834\n",
      "[644/1762] D loss: 1.0768, G loss: 1.1096\n",
      "[724/1762] D loss: 1.3905, G loss: 0.7324\n",
      "[804/1762] D loss: 1.3906, G loss: 0.6375\n",
      "[884/1762] D loss: 1.0401, G loss: 2.0618\n",
      "[964/1762] D loss: 1.3865, G loss: 0.7044\n",
      "[1044/1762] D loss: 1.2820, G loss: 0.8549\n",
      "[1124/1762] D loss: 1.0402, G loss: 2.7931\n",
      "[1204/1762] D loss: 1.3949, G loss: 0.6505\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6815\n",
      "[1364/1762] D loss: 1.0400, G loss: 2.7054\n",
      "[1444/1762] D loss: 1.3879, G loss: 0.7044\n",
      "[1524/1762] D loss: 1.3868, G loss: 0.6840\n",
      "[1604/1762] D loss: 1.3868, G loss: 0.6956\n",
      "[1684/1762] D loss: 1.0396, G loss: 3.1763\n",
      "[1762/1762] D loss: 0.6928, G loss: 5.0780\n",
      "train error: \n",
      " D loss: 1.266628, G loss: 1.402224, D accuracy: 55.4%, cell accuracy: 99.7%, board accuracy: 78.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.247379, G loss: 1.574564, D accuracy: 57.5%, cell accuracy: 99.6%, board accuracy: 75.0% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0390, G loss: 2.7051\n",
      "[84/1762] D loss: 1.3899, G loss: 0.6528\n",
      "[164/1762] D loss: 1.0467, G loss: 2.7568\n",
      "[244/1762] D loss: 0.8147, G loss: 2.7705\n",
      "[324/1762] D loss: 1.3873, G loss: 0.6962\n",
      "[404/1762] D loss: 1.0413, G loss: 2.2666\n",
      "[484/1762] D loss: 1.3868, G loss: 0.6985\n",
      "[564/1762] D loss: 1.3864, G loss: 0.7064\n",
      "[644/1762] D loss: 1.4011, G loss: 0.5908\n",
      "[724/1762] D loss: 1.3881, G loss: 0.7159\n",
      "[804/1762] D loss: 1.0409, G loss: 1.9437\n",
      "[884/1762] D loss: 1.3865, G loss: 0.6912\n",
      "[964/1762] D loss: 1.3863, G loss: 0.6984\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.7115\n",
      "[1124/1762] D loss: 1.0399, G loss: 2.5902\n",
      "[1204/1762] D loss: 1.0404, G loss: 2.4128\n",
      "[1284/1762] D loss: 1.3873, G loss: 0.6726\n",
      "[1364/1762] D loss: 1.0432, G loss: 1.8763\n",
      "[1444/1762] D loss: 1.3857, G loss: 0.6999\n",
      "[1524/1762] D loss: 1.3861, G loss: 0.6908\n",
      "[1604/1762] D loss: 1.0958, G loss: 1.7170\n",
      "[1684/1762] D loss: 1.3901, G loss: 0.6298\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6818\n",
      "train error: \n",
      " D loss: 1.290957, G loss: 1.009540, D accuracy: 53.8%, cell accuracy: 99.7%, board accuracy: 91.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.265919, G loss: 1.119153, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3873, G loss: 0.7175\n",
      "[84/1762] D loss: 0.6997, G loss: 2.7126\n",
      "[164/1762] D loss: 0.6955, G loss: 3.1755\n",
      "[244/1762] D loss: 1.3966, G loss: 0.5993\n",
      "[324/1762] D loss: 1.3875, G loss: 0.7052\n",
      "[404/1762] D loss: 1.3867, G loss: 0.7112\n",
      "[484/1762] D loss: 1.3881, G loss: 0.7242\n",
      "[564/1762] D loss: 1.1871, G loss: 1.3409\n",
      "[644/1762] D loss: 1.0398, G loss: 3.1756\n",
      "[724/1762] D loss: 1.3476, G loss: 0.7320\n",
      "[804/1762] D loss: 1.3872, G loss: 0.6979\n",
      "[884/1762] D loss: 1.3883, G loss: 0.7166\n",
      "[964/1762] D loss: 1.3424, G loss: 0.7484\n",
      "[1044/1762] D loss: 1.3901, G loss: 0.6539\n",
      "[1124/1762] D loss: 1.3772, G loss: 0.6966\n",
      "[1204/1762] D loss: 1.3789, G loss: 0.6717\n",
      "[1284/1762] D loss: 1.3836, G loss: 0.6965\n",
      "[1364/1762] D loss: 1.3877, G loss: 0.6748\n",
      "[1444/1762] D loss: 1.3902, G loss: 0.7442\n",
      "[1524/1762] D loss: 1.3952, G loss: 0.6176\n",
      "[1604/1762] D loss: 1.0407, G loss: 1.9626\n",
      "[1684/1762] D loss: 1.2574, G loss: 1.1648\n",
      "[1762/1762] D loss: 1.3897, G loss: 0.6417\n",
      "train error: \n",
      " D loss: 1.291248, G loss: 1.005422, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 91.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.264058, G loss: 1.072874, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3912, G loss: 0.6496\n",
      "[84/1762] D loss: 1.3872, G loss: 0.7128\n",
      "[164/1762] D loss: 1.0425, G loss: 1.6719\n",
      "[244/1762] D loss: 1.3866, G loss: 0.7061\n",
      "[324/1762] D loss: 1.3869, G loss: 0.7076\n",
      "[404/1762] D loss: 1.3871, G loss: 0.7023\n",
      "[484/1762] D loss: 1.3884, G loss: 0.7255\n",
      "[564/1762] D loss: 1.3905, G loss: 0.6404\n",
      "[644/1762] D loss: 1.3743, G loss: 0.6882\n",
      "[724/1762] D loss: 1.0432, G loss: 1.8126\n",
      "[804/1762] D loss: 1.2346, G loss: 3.3120\n",
      "[884/1762] D loss: 1.3261, G loss: 0.7717\n",
      "[964/1762] D loss: 1.0457, G loss: 1.7419\n",
      "[1044/1762] D loss: 1.3874, G loss: 0.6829\n",
      "[1124/1762] D loss: 1.3866, G loss: 0.6755\n",
      "[1204/1762] D loss: 1.0411, G loss: 2.6727\n",
      "[1284/1762] D loss: 1.0405, G loss: 2.0857\n",
      "[1364/1762] D loss: 1.3865, G loss: 0.6934\n",
      "[1444/1762] D loss: 1.0403, G loss: 2.1319\n",
      "[1524/1762] D loss: 1.3869, G loss: 0.6885\n",
      "[1604/1762] D loss: 1.3715, G loss: 0.6780\n",
      "[1684/1762] D loss: 1.3804, G loss: 0.6916\n",
      "[1762/1762] D loss: 0.6943, G loss: 3.5200\n",
      "train error: \n",
      " D loss: 1.286131, G loss: 1.107851, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.256111, G loss: 1.240793, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3859, G loss: 0.6828\n",
      "[84/1762] D loss: 1.3876, G loss: 0.6715\n",
      "[164/1762] D loss: 1.0407, G loss: 2.1643\n",
      "[244/1762] D loss: 1.3873, G loss: 0.6857\n",
      "[324/1762] D loss: 1.3851, G loss: 0.6854\n",
      "[404/1762] D loss: 1.3865, G loss: 0.6974\n",
      "[484/1762] D loss: 1.3884, G loss: 0.7282\n",
      "[564/1762] D loss: 1.3870, G loss: 0.7091\n",
      "[644/1762] D loss: 1.3818, G loss: 0.6894\n",
      "[724/1762] D loss: 1.3853, G loss: 0.6817\n",
      "[804/1762] D loss: 1.3866, G loss: 0.6582\n",
      "[884/1762] D loss: 1.3903, G loss: 0.6516\n",
      "[964/1762] D loss: 1.3867, G loss: 0.6961\n",
      "[1044/1762] D loss: 1.0430, G loss: 2.4971\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.6962\n",
      "[1204/1762] D loss: 1.3869, G loss: 0.7195\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6706\n",
      "[1364/1762] D loss: 1.3925, G loss: 0.6673\n",
      "[1444/1762] D loss: 1.3874, G loss: 0.6881\n",
      "[1524/1762] D loss: 1.3879, G loss: 0.6664\n",
      "[1604/1762] D loss: 0.6937, G loss: 4.0052\n",
      "[1684/1762] D loss: 1.0399, G loss: 2.5128\n",
      "[1762/1762] D loss: 0.6937, G loss: 3.7903\n",
      "train error: \n",
      " D loss: 1.286237, G loss: 1.193854, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.256792, G loss: 1.362489, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3873, G loss: 0.7039\n",
      "[84/1762] D loss: 1.3866, G loss: 0.6913\n",
      "[164/1762] D loss: 1.3877, G loss: 0.9211\n",
      "[244/1762] D loss: 1.3244, G loss: 0.8433\n",
      "[324/1762] D loss: 1.3860, G loss: 0.7056\n",
      "[404/1762] D loss: 1.0401, G loss: 2.3557\n",
      "[484/1762] D loss: 1.0407, G loss: 2.4773\n",
      "[564/1762] D loss: 1.3871, G loss: 0.6991\n",
      "[644/1762] D loss: 1.3870, G loss: 0.7002\n",
      "[724/1762] D loss: 1.3852, G loss: 0.6932\n",
      "[804/1762] D loss: 1.0403, G loss: 2.2794\n",
      "[884/1762] D loss: 1.0426, G loss: 2.3359\n",
      "[964/1762] D loss: 1.3871, G loss: 0.7051\n",
      "[1044/1762] D loss: 1.2388, G loss: 1.1409\n",
      "[1124/1762] D loss: 1.3881, G loss: 0.7206\n",
      "[1204/1762] D loss: 1.0493, G loss: 1.5837\n",
      "[1284/1762] D loss: 1.3870, G loss: 0.7298\n",
      "[1364/1762] D loss: 1.0248, G loss: 1.8881\n",
      "[1444/1762] D loss: 1.0633, G loss: 1.2678\n",
      "[1524/1762] D loss: 1.3700, G loss: 0.7185\n",
      "[1604/1762] D loss: 1.0404, G loss: 3.1043\n",
      "[1684/1762] D loss: 1.0405, G loss: 3.1143\n",
      "[1762/1762] D loss: 1.3896, G loss: 0.6515\n",
      "train error: \n",
      " D loss: 1.257531, G loss: 1.384538, D accuracy: 60.5%, cell accuracy: 99.5%, board accuracy: 71.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.222616, G loss: 1.683315, D accuracy: 62.0%, cell accuracy: 99.3%, board accuracy: 68.6% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3548, G loss: 0.7098\n",
      "[84/1762] D loss: 1.0609, G loss: 1.4459\n",
      "[164/1762] D loss: 1.4260, G loss: 0.5200\n",
      "[244/1762] D loss: 1.0574, G loss: 1.4114\n",
      "[324/1762] D loss: 1.0681, G loss: 1.6307\n",
      "[404/1762] D loss: 1.3903, G loss: 0.7049\n",
      "[484/1762] D loss: 1.0420, G loss: 2.4258\n",
      "[564/1762] D loss: 1.3936, G loss: 0.6252\n",
      "[644/1762] D loss: 1.3881, G loss: 0.7115\n",
      "[724/1762] D loss: 1.0406, G loss: 2.0988\n",
      "[804/1762] D loss: 1.3875, G loss: 0.6890\n",
      "[884/1762] D loss: 1.0404, G loss: 2.1487\n",
      "[964/1762] D loss: 1.0402, G loss: 2.1398\n",
      "[1044/1762] D loss: 1.3926, G loss: 0.7458\n",
      "[1124/1762] D loss: 1.3867, G loss: 0.6894\n",
      "[1204/1762] D loss: 1.0406, G loss: 2.2480\n",
      "[1284/1762] D loss: 1.3861, G loss: 0.7030\n",
      "[1364/1762] D loss: 1.3867, G loss: 0.7005\n",
      "[1444/1762] D loss: 1.3868, G loss: 0.6735\n",
      "[1524/1762] D loss: 1.3856, G loss: 0.7008\n",
      "[1604/1762] D loss: 1.3860, G loss: 0.6941\n",
      "[1684/1762] D loss: 1.2049, G loss: 2.1774\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.6811\n",
      "train error: \n",
      " D loss: 1.286196, G loss: 1.223112, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.258434, G loss: 1.392162, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3861, G loss: 0.6929\n",
      "[84/1762] D loss: 1.3874, G loss: 0.7064\n",
      "[164/1762] D loss: 1.3865, G loss: 0.6848\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6832\n",
      "[324/1762] D loss: 1.3846, G loss: 0.6813\n",
      "[404/1762] D loss: 1.0421, G loss: 2.3600\n",
      "[484/1762] D loss: 1.3866, G loss: 0.6840\n",
      "[564/1762] D loss: 1.2163, G loss: 1.4198\n",
      "[644/1762] D loss: 1.3865, G loss: 0.6851\n",
      "[724/1762] D loss: 1.0393, G loss: 2.2235\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6683\n",
      "[884/1762] D loss: 1.3867, G loss: 0.6993\n",
      "[964/1762] D loss: 1.0418, G loss: 3.6230\n",
      "[1044/1762] D loss: 1.3872, G loss: 0.6654\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.6857\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6977\n",
      "[1284/1762] D loss: 1.3866, G loss: 0.6955\n",
      "[1364/1762] D loss: 1.3865, G loss: 0.7053\n",
      "[1444/1762] D loss: 1.3873, G loss: 0.7058\n",
      "[1524/1762] D loss: 1.3867, G loss: 0.6786\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6897\n",
      "[1684/1762] D loss: 1.3858, G loss: 0.6926\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.6914\n",
      "train error: \n",
      " D loss: 1.287397, G loss: 1.254899, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.261992, G loss: 1.464138, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0397, G loss: 2.8620\n",
      "[84/1762] D loss: 1.3867, G loss: 0.6787\n",
      "[164/1762] D loss: 1.3868, G loss: 0.6495\n",
      "[244/1762] D loss: 1.3873, G loss: 0.6788\n",
      "[324/1762] D loss: 1.2170, G loss: 1.0989\n",
      "[404/1762] D loss: 1.3873, G loss: 0.7228\n",
      "[484/1762] D loss: 1.3872, G loss: 0.7061\n",
      "[564/1762] D loss: 1.3850, G loss: 0.6724\n",
      "[644/1762] D loss: 1.4217, G loss: 0.5367\n",
      "[724/1762] D loss: 1.3579, G loss: 0.7340\n",
      "[804/1762] D loss: 1.3233, G loss: 0.6499\n",
      "[884/1762] D loss: 1.3668, G loss: 0.5606\n",
      "[964/1762] D loss: 1.3488, G loss: 0.7179\n",
      "[1044/1762] D loss: 1.3894, G loss: 0.6248\n",
      "[1124/1762] D loss: 1.3889, G loss: 0.7200\n",
      "[1204/1762] D loss: 1.3873, G loss: 0.6793\n",
      "[1284/1762] D loss: 1.3931, G loss: 0.7556\n",
      "[1364/1762] D loss: 1.3889, G loss: 0.7384\n",
      "[1444/1762] D loss: 1.3862, G loss: 0.7090\n",
      "[1524/1762] D loss: 1.3871, G loss: 0.7171\n",
      "[1604/1762] D loss: 1.3884, G loss: 0.7196\n",
      "[1684/1762] D loss: 1.0423, G loss: 1.8357\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.7116\n",
      "train error: \n",
      " D loss: 1.289881, G loss: 1.087555, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.260737, G loss: 1.225510, D accuracy: 54.9%, cell accuracy: 99.7%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3865, G loss: 0.7102\n",
      "[84/1762] D loss: 1.3866, G loss: 0.6893\n",
      "[164/1762] D loss: 1.3852, G loss: 0.6964\n",
      "[244/1762] D loss: 1.3866, G loss: 0.6835\n",
      "[324/1762] D loss: 1.3870, G loss: 0.6815\n",
      "[404/1762] D loss: 1.3745, G loss: 0.7076\n",
      "[484/1762] D loss: 1.0566, G loss: 1.9832\n",
      "[564/1762] D loss: 1.0437, G loss: 1.6990\n",
      "[644/1762] D loss: 1.3873, G loss: 0.7071\n",
      "[724/1762] D loss: 1.3663, G loss: 0.7180\n",
      "[804/1762] D loss: 1.0419, G loss: 1.8654\n",
      "[884/1762] D loss: 1.0412, G loss: 1.8091\n",
      "[964/1762] D loss: 1.3871, G loss: 0.6749\n",
      "[1044/1762] D loss: 1.0407, G loss: 1.8492\n",
      "[1124/1762] D loss: 1.3874, G loss: 0.7124\n",
      "[1204/1762] D loss: 1.3866, G loss: 0.7026\n",
      "[1284/1762] D loss: 1.4081, G loss: 0.5653\n",
      "[1364/1762] D loss: 1.0405, G loss: 2.1913\n",
      "[1444/1762] D loss: 1.3897, G loss: 0.7070\n",
      "[1524/1762] D loss: 1.3882, G loss: 0.6700\n",
      "[1604/1762] D loss: 1.3867, G loss: 0.6938\n",
      "[1684/1762] D loss: 1.3888, G loss: 0.6617\n",
      "[1762/1762] D loss: 1.3872, G loss: 0.7168\n",
      "train error: \n",
      " D loss: 1.288148, G loss: 1.112486, D accuracy: 54.1%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.260730, G loss: 1.227306, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3869, G loss: 0.7002\n",
      "[84/1762] D loss: 1.0434, G loss: 2.1626\n",
      "[164/1762] D loss: 1.0406, G loss: 2.1613\n",
      "[244/1762] D loss: 1.0406, G loss: 2.0484\n",
      "[324/1762] D loss: 1.0345, G loss: 2.1745\n",
      "[404/1762] D loss: 1.3729, G loss: 0.6906\n",
      "[484/1762] D loss: 1.3859, G loss: 0.6826\n",
      "[564/1762] D loss: 1.3868, G loss: 0.6820\n",
      "[644/1762] D loss: 1.3869, G loss: 0.6659\n",
      "[724/1762] D loss: 1.0393, G loss: 2.4500\n",
      "[804/1762] D loss: 1.3871, G loss: 0.6919\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6860\n",
      "[964/1762] D loss: 1.3874, G loss: 0.6907\n",
      "[1044/1762] D loss: 1.0406, G loss: 2.3196\n",
      "[1124/1762] D loss: 1.3867, G loss: 0.7000\n",
      "[1204/1762] D loss: 1.3862, G loss: 0.6851\n",
      "[1284/1762] D loss: 1.3855, G loss: 0.6991\n",
      "[1364/1762] D loss: 1.0394, G loss: 2.4572\n",
      "[1444/1762] D loss: 1.3810, G loss: 0.6986\n",
      "[1524/1762] D loss: 1.3840, G loss: 0.7098\n",
      "[1604/1762] D loss: 1.3847, G loss: 0.6809\n",
      "[1684/1762] D loss: 1.0338, G loss: 2.5989\n",
      "[1762/1762] D loss: 1.3892, G loss: 0.6475\n",
      "train error: \n",
      " D loss: 1.278660, G loss: 1.300226, D accuracy: 55.4%, cell accuracy: 99.8%, board accuracy: 89.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.247486, G loss: 1.488429, D accuracy: 56.1%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3865, G loss: 0.6748\n",
      "[84/1762] D loss: 1.0403, G loss: 2.6797\n",
      "[164/1762] D loss: 1.3845, G loss: 0.6976\n",
      "[244/1762] D loss: 1.3919, G loss: 0.6432\n",
      "[324/1762] D loss: 1.3873, G loss: 0.7187\n",
      "[404/1762] D loss: 1.3890, G loss: 0.6871\n",
      "[484/1762] D loss: 0.8216, G loss: 2.0041\n",
      "[564/1762] D loss: 1.0431, G loss: 2.3883\n",
      "[644/1762] D loss: 1.2594, G loss: 1.5580\n",
      "[724/1762] D loss: 1.3878, G loss: 0.6692\n",
      "[804/1762] D loss: 1.3880, G loss: 0.7212\n",
      "[884/1762] D loss: 1.0399, G loss: 2.5497\n",
      "[964/1762] D loss: 1.3845, G loss: 0.6846\n",
      "[1044/1762] D loss: 1.3872, G loss: 0.6588\n",
      "[1124/1762] D loss: 1.4071, G loss: 0.5068\n",
      "[1204/1762] D loss: 1.3940, G loss: 0.7893\n",
      "[1284/1762] D loss: 1.3836, G loss: 0.7341\n",
      "[1364/1762] D loss: 1.3825, G loss: 0.6743\n",
      "[1444/1762] D loss: 1.3855, G loss: 0.6603\n",
      "[1524/1762] D loss: 0.8263, G loss: 2.0532\n",
      "[1604/1762] D loss: 1.0403, G loss: 2.5576\n",
      "[1684/1762] D loss: 1.0362, G loss: 2.2990\n",
      "[1762/1762] D loss: 1.3882, G loss: 0.6970\n",
      "train error: \n",
      " D loss: 1.274584, G loss: 1.248429, D accuracy: 58.8%, cell accuracy: 99.5%, board accuracy: 71.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.251776, G loss: 1.397614, D accuracy: 58.5%, cell accuracy: 99.4%, board accuracy: 71.6% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0420, G loss: 2.0374\n",
      "[84/1762] D loss: 1.3846, G loss: 0.7083\n",
      "[164/1762] D loss: 1.3862, G loss: 0.6418\n",
      "[244/1762] D loss: 1.0167, G loss: 2.6038\n",
      "[324/1762] D loss: 1.3858, G loss: 0.6906\n",
      "[404/1762] D loss: 1.3855, G loss: 0.7076\n",
      "[484/1762] D loss: 1.0376, G loss: 2.3832\n",
      "[564/1762] D loss: 1.3862, G loss: 0.6886\n",
      "[644/1762] D loss: 1.3762, G loss: 0.7063\n",
      "[724/1762] D loss: 1.2097, G loss: 1.9251\n",
      "[804/1762] D loss: 1.0104, G loss: 3.2516\n",
      "[884/1762] D loss: 1.3077, G loss: 1.0254\n",
      "[964/1762] D loss: 1.3825, G loss: 0.5172\n",
      "[1044/1762] D loss: 1.3272, G loss: 0.7829\n",
      "[1124/1762] D loss: 1.3861, G loss: 0.6785\n",
      "[1204/1762] D loss: 1.3661, G loss: 0.6827\n",
      "[1284/1762] D loss: 0.9848, G loss: 1.3931\n",
      "[1364/1762] D loss: 1.3163, G loss: 0.7894\n",
      "[1444/1762] D loss: 1.3888, G loss: 0.7564\n",
      "[1524/1762] D loss: 1.3939, G loss: 0.6605\n",
      "[1604/1762] D loss: 1.3861, G loss: 0.7063\n",
      "[1684/1762] D loss: 1.3860, G loss: 0.7090\n",
      "[1762/1762] D loss: 1.3833, G loss: 0.7157\n",
      "train error: \n",
      " D loss: 1.267474, G loss: 1.412067, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 87.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.241535, G loss: 1.692461, D accuracy: 55.9%, cell accuracy: 99.7%, board accuracy: 85.9% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3860, G loss: 0.7091\n",
      "[84/1762] D loss: 1.0400, G loss: 2.0876\n",
      "[164/1762] D loss: 1.3875, G loss: 0.7261\n",
      "[244/1762] D loss: 1.0440, G loss: 2.4519\n",
      "[324/1762] D loss: 1.0397, G loss: 2.7692\n",
      "[404/1762] D loss: 1.3872, G loss: 0.6968\n",
      "[484/1762] D loss: 1.0429, G loss: 2.5885\n",
      "[564/1762] D loss: 1.3859, G loss: 0.7110\n",
      "[644/1762] D loss: 1.3858, G loss: 0.6688\n",
      "[724/1762] D loss: 1.3922, G loss: 0.7653\n",
      "[804/1762] D loss: 1.3825, G loss: 0.6655\n",
      "[884/1762] D loss: 1.3834, G loss: 0.6981\n",
      "[964/1762] D loss: 1.0398, G loss: 2.3841\n",
      "[1044/1762] D loss: 1.0401, G loss: 2.4547\n",
      "[1124/1762] D loss: 1.3846, G loss: 0.7071\n",
      "[1204/1762] D loss: 1.3858, G loss: 0.6991\n",
      "[1284/1762] D loss: 1.3795, G loss: 0.6642\n",
      "[1364/1762] D loss: 1.3881, G loss: 0.7270\n",
      "[1444/1762] D loss: 1.3867, G loss: 0.7101\n",
      "[1524/1762] D loss: 1.3880, G loss: 0.7145\n",
      "[1604/1762] D loss: 1.3882, G loss: 0.7287\n",
      "[1684/1762] D loss: 1.3910, G loss: 0.6311\n",
      "[1762/1762] D loss: 0.6938, G loss: 4.3722\n",
      "train error: \n",
      " D loss: 1.281668, G loss: 1.308844, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 90.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.252679, G loss: 1.481434, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3868, G loss: 0.7059\n",
      "[84/1762] D loss: 1.0397, G loss: 2.5125\n",
      "[164/1762] D loss: 1.3861, G loss: 0.7052\n",
      "[244/1762] D loss: 1.0404, G loss: 3.0464\n",
      "[324/1762] D loss: 1.3846, G loss: 0.6923\n",
      "[404/1762] D loss: 1.3855, G loss: 0.7015\n",
      "[484/1762] D loss: 1.3856, G loss: 0.6965\n",
      "[564/1762] D loss: 1.3862, G loss: 0.6978\n",
      "[644/1762] D loss: 1.3853, G loss: 0.7097\n",
      "[724/1762] D loss: 1.3868, G loss: 0.6802\n",
      "[804/1762] D loss: 1.3868, G loss: 0.6702\n",
      "[884/1762] D loss: 1.3886, G loss: 0.7269\n",
      "[964/1762] D loss: 1.3811, G loss: 0.7260\n",
      "[1044/1762] D loss: 1.3887, G loss: 0.7218\n",
      "[1124/1762] D loss: 1.4229, G loss: 0.7357\n",
      "[1204/1762] D loss: 1.3871, G loss: 0.6727\n",
      "[1284/1762] D loss: 1.0380, G loss: 3.7165\n",
      "[1364/1762] D loss: 1.3854, G loss: 0.6844\n",
      "[1444/1762] D loss: 1.3869, G loss: 0.6813\n",
      "[1524/1762] D loss: 1.2522, G loss: 1.2276\n",
      "[1604/1762] D loss: 1.3894, G loss: 0.6499\n",
      "[1684/1762] D loss: 1.3879, G loss: 0.7116\n",
      "[1762/1762] D loss: 1.3893, G loss: 0.6461\n",
      "train error: \n",
      " D loss: 1.289468, G loss: 1.176644, D accuracy: 54.2%, cell accuracy: 99.9%, board accuracy: 91.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.259359, G loss: 1.331753, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    for cls in [DiscWithMoreConv, DiscWithMoreConvPad]:\n",
    "        train(run_name=cls.__name__, disc_cls=cls)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of discriminator loss, we see a clear improvement in stability with both these architectures. The generator loss also remains stable, as it was before. The generator's board accuracy develops some instability though, which is more pronounced with `DiscWithMoreConvPad`. In terms of spawn recall, most runs stay at 0% for most of the 50 epochs. For one run of `DiscWithMoreConv` and `DiscWithMoreConvPad`, the spawn recall jumps up to about 100% at epoch 5 and subsequently shoots straight back down to around 0%, staying there for the rest of the training run. For one run of `DiscWithMoreConvPad`, the spawn recall unstably climbs up to 100% near the end of the training run and stays there for 3 epochs until the end of the run.\n",
    "\n",
    "Let's rerun these setups for more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3851, G loss: 0.7879\n",
      "[84/1762] D loss: 0.9136, G loss: 1.0055\n",
      "[164/1762] D loss: 0.4617, G loss: 1.7729\n",
      "[244/1762] D loss: 0.2613, G loss: 2.3178\n",
      "[324/1762] D loss: 0.0654, G loss: 3.6756\n",
      "[404/1762] D loss: 0.0686, G loss: 3.7125\n",
      "[484/1762] D loss: 0.0520, G loss: 4.7508\n",
      "[564/1762] D loss: 0.3333, G loss: 4.4908\n",
      "[644/1762] D loss: 0.4289, G loss: 2.5978\n",
      "[724/1762] D loss: 0.1807, G loss: 2.1890\n",
      "[804/1762] D loss: 0.9813, G loss: 1.1784\n",
      "[884/1762] D loss: 0.2758, G loss: 3.6516\n",
      "[964/1762] D loss: 0.3733, G loss: 4.9151\n",
      "[1044/1762] D loss: 0.8165, G loss: 1.1965\n",
      "[1124/1762] D loss: 0.8963, G loss: 0.9477\n",
      "[1204/1762] D loss: 1.3434, G loss: 1.1568\n",
      "[1284/1762] D loss: 1.2089, G loss: 0.9935\n",
      "[1364/1762] D loss: 1.1547, G loss: 1.0692\n",
      "[1444/1762] D loss: 1.1294, G loss: 1.0402\n",
      "[1524/1762] D loss: 1.7733, G loss: 0.3653\n",
      "[1604/1762] D loss: 1.1462, G loss: 1.7192\n",
      "[1684/1762] D loss: 1.2643, G loss: 0.8560\n",
      "[1762/1762] D loss: 0.9819, G loss: 1.1106\n",
      "train error: \n",
      " D loss: 1.322214, G loss: 0.908740, D accuracy: 63.6%, cell accuracy: 99.6%, board accuracy: 60.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.334480, G loss: 0.898788, D accuracy: 61.1%, cell accuracy: 99.6%, board accuracy: 58.2% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2985, G loss: 1.0462\n",
      "[84/1762] D loss: 1.2602, G loss: 1.0575\n",
      "[164/1762] D loss: 1.2172, G loss: 0.8296\n",
      "[244/1762] D loss: 1.4244, G loss: 0.4490\n",
      "[324/1762] D loss: 1.2734, G loss: 1.7026\n",
      "[404/1762] D loss: 1.1461, G loss: 0.7916\n",
      "[484/1762] D loss: 1.8159, G loss: 1.8268\n",
      "[564/1762] D loss: 1.1049, G loss: 1.0807\n",
      "[644/1762] D loss: 1.3968, G loss: 0.5497\n",
      "[724/1762] D loss: 1.4923, G loss: 0.7599\n",
      "[804/1762] D loss: 1.2992, G loss: 0.6760\n",
      "[884/1762] D loss: 1.1778, G loss: 0.9567\n",
      "[964/1762] D loss: 1.7341, G loss: 0.4082\n",
      "[1044/1762] D loss: 1.1573, G loss: 1.1948\n",
      "[1124/1762] D loss: 1.3619, G loss: 0.6421\n",
      "[1204/1762] D loss: 1.3274, G loss: 1.0744\n",
      "[1284/1762] D loss: 1.3794, G loss: 1.1496\n",
      "[1364/1762] D loss: 1.3658, G loss: 0.8038\n",
      "[1444/1762] D loss: 1.3356, G loss: 0.5716\n",
      "[1524/1762] D loss: 1.5097, G loss: 0.3837\n",
      "[1604/1762] D loss: 1.1724, G loss: 0.7089\n",
      "[1684/1762] D loss: 1.4995, G loss: 0.5506\n",
      "[1762/1762] D loss: 1.9897, G loss: 0.3873\n",
      "train error: \n",
      " D loss: 1.316099, G loss: 1.033178, D accuracy: 53.6%, cell accuracy: 99.3%, board accuracy: 59.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.291238, G loss: 1.054291, D accuracy: 55.0%, cell accuracy: 99.3%, board accuracy: 56.1% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.6696, G loss: 0.7243\n",
      "[84/1762] D loss: 1.3505, G loss: 0.6452\n",
      "[164/1762] D loss: 1.3663, G loss: 0.8095\n",
      "[244/1762] D loss: 1.5037, G loss: 0.3827\n",
      "[324/1762] D loss: 0.9521, G loss: 1.3240\n",
      "[404/1762] D loss: 1.3872, G loss: 0.9875\n",
      "[484/1762] D loss: 1.2877, G loss: 0.7624\n",
      "[564/1762] D loss: 1.4121, G loss: 0.6533\n",
      "[644/1762] D loss: 1.7607, G loss: 0.4646\n",
      "[724/1762] D loss: 1.3518, G loss: 0.6979\n",
      "[804/1762] D loss: 0.8660, G loss: 1.0113\n",
      "[884/1762] D loss: 1.3915, G loss: 0.8936\n",
      "[964/1762] D loss: 1.3635, G loss: 0.8475\n",
      "[1044/1762] D loss: 1.3905, G loss: 0.6815\n",
      "[1124/1762] D loss: 1.3744, G loss: 0.8195\n",
      "[1204/1762] D loss: 1.3829, G loss: 0.8185\n",
      "[1284/1762] D loss: 1.3030, G loss: 0.8613\n",
      "[1364/1762] D loss: 1.4379, G loss: 0.6590\n",
      "[1444/1762] D loss: 1.5239, G loss: 0.9805\n",
      "[1524/1762] D loss: 1.4033, G loss: 0.8748\n",
      "[1604/1762] D loss: 1.6585, G loss: 1.2705\n",
      "[1684/1762] D loss: 0.7415, G loss: 1.4008\n",
      "[1762/1762] D loss: 1.8015, G loss: 0.3000\n",
      "train error: \n",
      " D loss: 1.454109, G loss: 0.423942, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 82.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.425662, G loss: 0.443083, D accuracy: 54.4%, cell accuracy: 99.7%, board accuracy: 79.1% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.7056, G loss: 0.4264\n",
      "[84/1762] D loss: 1.3742, G loss: 0.6501\n",
      "[164/1762] D loss: 1.3955, G loss: 1.0056\n",
      "[244/1762] D loss: 1.4189, G loss: 0.6980\n",
      "[324/1762] D loss: 1.4005, G loss: 0.7353\n",
      "[404/1762] D loss: 0.4318, G loss: 1.5241\n",
      "[484/1762] D loss: 1.5359, G loss: 1.3688\n",
      "[564/1762] D loss: 1.3818, G loss: 1.0290\n",
      "[644/1762] D loss: 1.4098, G loss: 0.8265\n",
      "[724/1762] D loss: 1.2650, G loss: 0.6778\n",
      "[804/1762] D loss: 1.3752, G loss: 0.8999\n",
      "[884/1762] D loss: 1.4710, G loss: 0.5971\n",
      "[964/1762] D loss: 1.4040, G loss: 0.6939\n",
      "[1044/1762] D loss: 1.4053, G loss: 0.6725\n",
      "[1124/1762] D loss: 1.3917, G loss: 0.7395\n",
      "[1204/1762] D loss: 1.4066, G loss: 0.9197\n",
      "[1284/1762] D loss: 1.4021, G loss: 0.6080\n",
      "[1364/1762] D loss: 0.8491, G loss: 1.0281\n",
      "[1444/1762] D loss: 1.3655, G loss: 0.4974\n",
      "[1524/1762] D loss: 1.9030, G loss: 0.9161\n",
      "[1604/1762] D loss: 1.3505, G loss: 0.9262\n",
      "[1684/1762] D loss: 1.3855, G loss: 0.8484\n",
      "[1762/1762] D loss: 1.3617, G loss: 0.7665\n",
      "train error: \n",
      " D loss: 1.442413, G loss: 0.772464, D accuracy: 50.9%, cell accuracy: 99.7%, board accuracy: 77.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.463348, G loss: 0.784112, D accuracy: 50.1%, cell accuracy: 99.7%, board accuracy: 76.8% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4288, G loss: 0.8896\n",
      "[84/1762] D loss: 1.3218, G loss: 0.7856\n",
      "[164/1762] D loss: 1.4554, G loss: 0.5707\n",
      "[244/1762] D loss: 1.4403, G loss: 0.7368\n",
      "[324/1762] D loss: 1.3852, G loss: 0.5969\n",
      "[404/1762] D loss: 0.8531, G loss: 0.9574\n",
      "[484/1762] D loss: 0.7077, G loss: 1.7043\n",
      "[564/1762] D loss: 0.8492, G loss: 1.0902\n",
      "[644/1762] D loss: 1.4068, G loss: 0.8857\n",
      "[724/1762] D loss: 0.8591, G loss: 1.2643\n",
      "[804/1762] D loss: 1.3141, G loss: 0.8842\n",
      "[884/1762] D loss: 0.9401, G loss: 0.7698\n",
      "[964/1762] D loss: 1.3900, G loss: 0.7789\n",
      "[1044/1762] D loss: 0.6883, G loss: 1.3279\n",
      "[1124/1762] D loss: 1.4269, G loss: 0.5526\n",
      "[1204/1762] D loss: 0.9550, G loss: 0.7218\n",
      "[1284/1762] D loss: 1.4042, G loss: 0.7652\n",
      "[1364/1762] D loss: 1.5515, G loss: 0.6774\n",
      "[1444/1762] D loss: 1.8038, G loss: 0.4963\n",
      "[1524/1762] D loss: 1.3136, G loss: 1.1163\n",
      "[1604/1762] D loss: 1.3371, G loss: 0.6457\n",
      "[1684/1762] D loss: 1.2652, G loss: 0.8099\n",
      "[1762/1762] D loss: 1.5076, G loss: 1.1343\n",
      "train error: \n",
      " D loss: 1.454853, G loss: 1.168779, D accuracy: 52.5%, cell accuracy: 99.8%, board accuracy: 81.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.448476, G loss: 1.174114, D accuracy: 53.4%, cell accuracy: 99.7%, board accuracy: 78.4% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0143, G loss: 1.0618\n",
      "[84/1762] D loss: 1.4715, G loss: 1.0022\n",
      "[164/1762] D loss: 1.3986, G loss: 0.6429\n",
      "[244/1762] D loss: 1.4130, G loss: 0.7740\n",
      "[324/1762] D loss: 0.8497, G loss: 1.0678\n",
      "[404/1762] D loss: 0.8174, G loss: 1.2026\n",
      "[484/1762] D loss: 0.7150, G loss: 1.2534\n",
      "[564/1762] D loss: 0.7310, G loss: 1.4415\n",
      "[644/1762] D loss: 0.5928, G loss: 1.2362\n",
      "[724/1762] D loss: 0.5304, G loss: 1.2021\n",
      "[804/1762] D loss: 0.5975, G loss: 1.1978\n",
      "[884/1762] D loss: 1.4143, G loss: 0.6187\n",
      "[964/1762] D loss: 1.2943, G loss: 0.7008\n",
      "[1044/1762] D loss: 0.6610, G loss: 0.7949\n",
      "[1124/1762] D loss: 1.4230, G loss: 0.8331\n",
      "[1204/1762] D loss: 1.5081, G loss: 0.8217\n",
      "[1284/1762] D loss: 1.4188, G loss: 0.9438\n",
      "[1364/1762] D loss: 2.7798, G loss: 0.1715\n",
      "[1444/1762] D loss: 1.6848, G loss: 1.3964\n",
      "[1524/1762] D loss: 1.6922, G loss: 1.0244\n",
      "[1604/1762] D loss: 1.4297, G loss: 0.7821\n",
      "[1684/1762] D loss: 1.4128, G loss: 0.7632\n",
      "[1762/1762] D loss: 1.2592, G loss: 0.8436\n",
      "train error: \n",
      " D loss: 1.401215, G loss: 0.732131, D accuracy: 50.0%, cell accuracy: 99.7%, board accuracy: 70.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.403412, G loss: 0.730296, D accuracy: 50.9%, cell accuracy: 99.7%, board accuracy: 71.6% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4322, G loss: 0.6321\n",
      "[84/1762] D loss: 1.1860, G loss: 0.7888\n",
      "[164/1762] D loss: 1.3225, G loss: 0.7605\n",
      "[244/1762] D loss: 1.3538, G loss: 0.7823\n",
      "[324/1762] D loss: 1.3971, G loss: 0.6481\n",
      "[404/1762] D loss: 1.3937, G loss: 0.7574\n",
      "[484/1762] D loss: 1.3900, G loss: 0.7235\n",
      "[564/1762] D loss: 1.4056, G loss: 0.8187\n",
      "[644/1762] D loss: 0.9840, G loss: 0.9529\n",
      "[724/1762] D loss: 1.4143, G loss: 0.8226\n",
      "[804/1762] D loss: 1.3981, G loss: 0.6350\n",
      "[884/1762] D loss: 1.4131, G loss: 0.8493\n",
      "[964/1762] D loss: 1.3380, G loss: 0.7429\n",
      "[1044/1762] D loss: 1.3940, G loss: 0.7513\n",
      "[1124/1762] D loss: 1.4007, G loss: 0.7127\n",
      "[1204/1762] D loss: 0.7209, G loss: 1.1289\n",
      "[1284/1762] D loss: 0.7604, G loss: 1.0657\n",
      "[1364/1762] D loss: 0.7119, G loss: 1.0638\n",
      "[1444/1762] D loss: 1.2189, G loss: 1.3577\n",
      "[1524/1762] D loss: 2.5276, G loss: 0.8298\n",
      "[1604/1762] D loss: 1.4402, G loss: 0.5225\n",
      "[1684/1762] D loss: 1.0640, G loss: 0.8843\n",
      "[1762/1762] D loss: 1.3978, G loss: 0.7799\n",
      "train error: \n",
      " D loss: 1.355308, G loss: 0.662657, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 89.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.347278, G loss: 0.663603, D accuracy: 55.7%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2792, G loss: 0.7669\n",
      "[84/1762] D loss: 1.3945, G loss: 0.6302\n",
      "[164/1762] D loss: 0.8875, G loss: 0.9969\n",
      "[244/1762] D loss: 0.6023, G loss: 1.0558\n",
      "[324/1762] D loss: 1.3600, G loss: 0.6666\n",
      "[404/1762] D loss: 1.3572, G loss: 0.7088\n",
      "[484/1762] D loss: 1.4046, G loss: 0.8592\n",
      "[564/1762] D loss: 1.3968, G loss: 0.5665\n",
      "[644/1762] D loss: 1.4220, G loss: 0.8008\n",
      "[724/1762] D loss: 1.3827, G loss: 0.6563\n",
      "[804/1762] D loss: 0.5771, G loss: 1.0604\n",
      "[884/1762] D loss: 1.4372, G loss: 0.5798\n",
      "[964/1762] D loss: 1.3942, G loss: 0.9686\n",
      "[1044/1762] D loss: 1.4240, G loss: 0.7642\n",
      "[1124/1762] D loss: 1.4534, G loss: 0.5452\n",
      "[1204/1762] D loss: 1.5436, G loss: 1.1694\n",
      "[1284/1762] D loss: 1.4426, G loss: 0.6137\n",
      "[1364/1762] D loss: 1.4106, G loss: 0.7370\n",
      "[1444/1762] D loss: 1.6389, G loss: 1.0975\n",
      "[1524/1762] D loss: 1.7271, G loss: 0.8700\n",
      "[1604/1762] D loss: 1.5361, G loss: 0.6635\n",
      "[1684/1762] D loss: 1.3160, G loss: 0.8510\n",
      "[1762/1762] D loss: 1.3069, G loss: 1.5619\n",
      "train error: \n",
      " D loss: 1.457097, G loss: 1.183179, D accuracy: 52.6%, cell accuracy: 99.3%, board accuracy: 41.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.455296, G loss: 1.220133, D accuracy: 51.7%, cell accuracy: 99.2%, board accuracy: 37.7% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1517, G loss: 1.1499\n",
      "[84/1762] D loss: 1.2818, G loss: 0.7268\n",
      "[164/1762] D loss: 1.4659, G loss: 0.9243\n",
      "[244/1762] D loss: 1.2633, G loss: 0.8329\n",
      "[324/1762] D loss: 1.6651, G loss: 1.2393\n",
      "[404/1762] D loss: 1.3861, G loss: 0.6872\n",
      "[484/1762] D loss: 0.6383, G loss: 1.5702\n",
      "[564/1762] D loss: 1.4513, G loss: 0.4485\n",
      "[644/1762] D loss: 1.3930, G loss: 0.9009\n",
      "[724/1762] D loss: 1.3892, G loss: 0.6504\n",
      "[804/1762] D loss: 1.4042, G loss: 0.5683\n",
      "[884/1762] D loss: 1.4065, G loss: 0.6482\n",
      "[964/1762] D loss: 1.4134, G loss: 0.8989\n",
      "[1044/1762] D loss: 1.3933, G loss: 0.6340\n",
      "[1124/1762] D loss: 1.3543, G loss: 0.6743\n",
      "[1204/1762] D loss: 0.4361, G loss: 1.4995\n",
      "[1284/1762] D loss: 0.5348, G loss: 1.6509\n",
      "[1364/1762] D loss: 1.6700, G loss: 0.5564\n",
      "[1444/1762] D loss: 1.5398, G loss: 1.0010\n",
      "[1524/1762] D loss: 1.4273, G loss: 0.8306\n",
      "[1604/1762] D loss: 1.3905, G loss: 0.8982\n",
      "[1684/1762] D loss: 0.4827, G loss: 1.5772\n",
      "[1762/1762] D loss: 1.3948, G loss: 0.5771\n",
      "train error: \n",
      " D loss: 1.322901, G loss: 0.706614, D accuracy: 57.3%, cell accuracy: 99.4%, board accuracy: 42.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.311498, G loss: 0.721865, D accuracy: 58.4%, cell accuracy: 99.4%, board accuracy: 38.6% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4341, G loss: 0.8774\n",
      "[84/1762] D loss: 0.7509, G loss: 1.1494\n",
      "[164/1762] D loss: 0.6794, G loss: 1.0256\n",
      "[244/1762] D loss: 0.5573, G loss: 1.5604\n",
      "[324/1762] D loss: 1.4906, G loss: 0.9587\n",
      "[404/1762] D loss: 1.5173, G loss: 1.0397\n",
      "[484/1762] D loss: 1.3933, G loss: 0.6311\n",
      "[564/1762] D loss: 1.3726, G loss: 0.9876\n",
      "[644/1762] D loss: 1.4057, G loss: 0.7350\n",
      "[724/1762] D loss: 1.4327, G loss: 0.4294\n",
      "[804/1762] D loss: 1.4432, G loss: 0.9663\n",
      "[884/1762] D loss: 1.4106, G loss: 0.7982\n",
      "[964/1762] D loss: 1.3595, G loss: 0.6488\n",
      "[1044/1762] D loss: 1.4304, G loss: 0.7995\n",
      "[1124/1762] D loss: 0.3922, G loss: 1.4531\n",
      "[1204/1762] D loss: 1.3926, G loss: 0.7142\n",
      "[1284/1762] D loss: 1.4204, G loss: 0.8058\n",
      "[1364/1762] D loss: 1.4565, G loss: 0.5559\n",
      "[1444/1762] D loss: 1.4128, G loss: 0.7574\n",
      "[1524/1762] D loss: 1.4834, G loss: 1.0213\n",
      "[1604/1762] D loss: 1.4173, G loss: 0.7601\n",
      "[1684/1762] D loss: 0.2402, G loss: 1.8952\n",
      "[1762/1762] D loss: 1.4143, G loss: 0.7647\n",
      "train error: \n",
      " D loss: 1.055335, G loss: 1.049288, D accuracy: 77.6%, cell accuracy: 99.7%, board accuracy: 46.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.052429, G loss: 1.060403, D accuracy: 76.5%, cell accuracy: 99.6%, board accuracy: 46.8% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4806, G loss: 0.9170\n",
      "[84/1762] D loss: 1.4196, G loss: 0.7014\n",
      "[164/1762] D loss: 1.4755, G loss: 1.0846\n",
      "[244/1762] D loss: 0.5455, G loss: 1.0812\n",
      "[324/1762] D loss: 1.4431, G loss: 0.8842\n",
      "[404/1762] D loss: 1.4007, G loss: 0.8230\n",
      "[484/1762] D loss: 1.4077, G loss: 0.9854\n",
      "[564/1762] D loss: 1.4245, G loss: 0.8637\n",
      "[644/1762] D loss: 1.4258, G loss: 0.5026\n",
      "[724/1762] D loss: 0.4016, G loss: 1.2815\n",
      "[804/1762] D loss: 0.3797, G loss: 1.4303\n",
      "[884/1762] D loss: 0.2516, G loss: 1.7272\n",
      "[964/1762] D loss: 1.2853, G loss: 0.8587\n",
      "[1044/1762] D loss: 1.5666, G loss: 0.3642\n",
      "[1124/1762] D loss: 1.5573, G loss: 0.9728\n",
      "[1204/1762] D loss: 1.4074, G loss: 0.7872\n",
      "[1284/1762] D loss: 1.3456, G loss: 1.2463\n",
      "[1364/1762] D loss: 1.4203, G loss: 0.7103\n",
      "[1444/1762] D loss: 0.3910, G loss: 1.4095\n",
      "[1524/1762] D loss: 1.4885, G loss: 0.8897\n",
      "[1604/1762] D loss: 0.2572, G loss: 1.4880\n",
      "[1684/1762] D loss: 1.4164, G loss: 0.5642\n",
      "[1762/1762] D loss: 1.4325, G loss: 0.5818\n",
      "train error: \n",
      " D loss: 1.791923, G loss: 0.245603, D accuracy: 50.4%, cell accuracy: 99.8%, board accuracy: 90.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.784639, G loss: 0.249641, D accuracy: 50.0%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3860, G loss: 1.4350\n",
      "[84/1762] D loss: 1.1922, G loss: 1.1438\n",
      "[164/1762] D loss: 0.4191, G loss: 1.2691\n",
      "[244/1762] D loss: 1.4424, G loss: 1.1131\n",
      "[324/1762] D loss: 1.6115, G loss: 1.1771\n",
      "[404/1762] D loss: 1.5200, G loss: 0.3934\n",
      "[484/1762] D loss: 0.3791, G loss: 1.3401\n",
      "[564/1762] D loss: 1.4211, G loss: 0.5076\n",
      "[644/1762] D loss: 1.3959, G loss: 0.8749\n",
      "[724/1762] D loss: 1.4927, G loss: 0.9209\n",
      "[804/1762] D loss: 0.4920, G loss: 1.1401\n",
      "[884/1762] D loss: 1.5480, G loss: 0.4802\n",
      "[964/1762] D loss: 1.5201, G loss: 1.2239\n",
      "[1044/1762] D loss: 1.3916, G loss: 0.7193\n",
      "[1124/1762] D loss: 1.4314, G loss: 0.9285\n",
      "[1204/1762] D loss: 0.3225, G loss: 1.4626\n",
      "[1284/1762] D loss: 1.4365, G loss: 0.8941\n",
      "[1364/1762] D loss: 1.4085, G loss: 0.6104\n",
      "[1444/1762] D loss: 1.4483, G loss: 0.9047\n",
      "[1524/1762] D loss: 1.4066, G loss: 0.7295\n",
      "[1604/1762] D loss: 1.3952, G loss: 0.6243\n",
      "[1684/1762] D loss: 0.2189, G loss: 1.6226\n",
      "[1762/1762] D loss: 1.3973, G loss: 0.7127\n",
      "train error: \n",
      " D loss: 1.357917, G loss: 0.667700, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 88.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.334744, G loss: 0.682355, D accuracy: 56.4%, cell accuracy: 99.8%, board accuracy: 85.2% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4026, G loss: 0.8063\n",
      "[84/1762] D loss: 1.4602, G loss: 1.1648\n",
      "[164/1762] D loss: 0.4430, G loss: 1.2873\n",
      "[244/1762] D loss: 1.3562, G loss: 0.7658\n",
      "[324/1762] D loss: 1.5128, G loss: 0.9796\n",
      "[404/1762] D loss: 1.4938, G loss: 1.1261\n",
      "[484/1762] D loss: 1.4865, G loss: 0.9721\n",
      "[564/1762] D loss: 1.6178, G loss: 1.1291\n",
      "[644/1762] D loss: 1.6183, G loss: 1.0391\n",
      "[724/1762] D loss: 0.2933, G loss: 1.3094\n",
      "[804/1762] D loss: 1.4312, G loss: 0.5207\n",
      "[884/1762] D loss: 1.4583, G loss: 0.9130\n",
      "[964/1762] D loss: 0.2653, G loss: 1.5786\n",
      "[1044/1762] D loss: 1.4248, G loss: 0.7059\n",
      "[1124/1762] D loss: 0.1551, G loss: 1.8215\n",
      "[1204/1762] D loss: 1.4660, G loss: 0.9279\n",
      "[1284/1762] D loss: 1.4107, G loss: 0.8232\n",
      "[1364/1762] D loss: 1.4062, G loss: 0.6366\n",
      "[1444/1762] D loss: 0.2948, G loss: 1.4656\n",
      "[1524/1762] D loss: 0.2910, G loss: 1.6282\n",
      "[1604/1762] D loss: 0.1823, G loss: 2.2297\n",
      "[1684/1762] D loss: 0.2176, G loss: 1.9798\n",
      "[1762/1762] D loss: 1.4114, G loss: 0.8585\n",
      "train error: \n",
      " D loss: 1.346625, G loss: 0.869675, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 89.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.330491, G loss: 0.871016, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5026, G loss: 1.0534\n",
      "[84/1762] D loss: 0.2425, G loss: 1.6908\n",
      "[164/1762] D loss: 1.3918, G loss: 0.6092\n",
      "[244/1762] D loss: 1.4112, G loss: 0.5582\n",
      "[324/1762] D loss: 0.2792, G loss: 1.9323\n",
      "[404/1762] D loss: 1.4703, G loss: 0.8800\n",
      "[484/1762] D loss: 1.3967, G loss: 0.7848\n",
      "[564/1762] D loss: 1.2600, G loss: 0.7758\n",
      "[644/1762] D loss: 1.2981, G loss: 0.8137\n",
      "[724/1762] D loss: 1.4348, G loss: 0.6075\n",
      "[804/1762] D loss: 1.2570, G loss: 0.9572\n",
      "[884/1762] D loss: 1.4518, G loss: 0.9250\n",
      "[964/1762] D loss: 1.3855, G loss: 0.8798\n",
      "[1044/1762] D loss: 1.0905, G loss: 1.0212\n",
      "[1124/1762] D loss: 1.1364, G loss: 0.9309\n",
      "[1204/1762] D loss: 1.1508, G loss: 0.8074\n",
      "[1284/1762] D loss: 1.3212, G loss: 0.6515\n",
      "[1364/1762] D loss: 1.5039, G loss: 0.7670\n",
      "[1444/1762] D loss: 0.1651, G loss: 2.1633\n",
      "[1524/1762] D loss: 0.4340, G loss: 1.1778\n",
      "[1604/1762] D loss: 0.2656, G loss: 2.2149\n",
      "[1684/1762] D loss: 0.1715, G loss: 2.3382\n",
      "[1762/1762] D loss: 1.2715, G loss: 1.5237\n",
      "train error: \n",
      " D loss: 1.355541, G loss: 0.814295, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.344123, G loss: 0.822317, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 85.0% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1856, G loss: 2.0006\n",
      "[84/1762] D loss: 1.4610, G loss: 0.8464\n",
      "[164/1762] D loss: 1.4317, G loss: 0.4366\n",
      "[244/1762] D loss: 1.4022, G loss: 0.6960\n",
      "[324/1762] D loss: 0.1152, G loss: 2.2530\n",
      "[404/1762] D loss: 1.4298, G loss: 0.6266\n",
      "[484/1762] D loss: 0.1914, G loss: 1.9084\n",
      "[564/1762] D loss: 0.3027, G loss: 1.4427\n",
      "[644/1762] D loss: 1.5413, G loss: 1.0232\n",
      "[724/1762] D loss: 1.4229, G loss: 0.6054\n",
      "[804/1762] D loss: 1.4844, G loss: 1.1558\n",
      "[884/1762] D loss: 0.2774, G loss: 1.5108\n",
      "[964/1762] D loss: 1.4293, G loss: 0.5174\n",
      "[1044/1762] D loss: 0.7642, G loss: 0.7812\n",
      "[1124/1762] D loss: 0.3351, G loss: 1.4144\n",
      "[1204/1762] D loss: 0.2782, G loss: 1.4719\n",
      "[1284/1762] D loss: 1.2025, G loss: 1.0028\n",
      "[1364/1762] D loss: 1.3269, G loss: 0.8508\n",
      "[1444/1762] D loss: 1.5501, G loss: 0.9264\n",
      "[1524/1762] D loss: 1.4859, G loss: 1.0075\n",
      "[1604/1762] D loss: 0.4006, G loss: 1.1404\n",
      "[1684/1762] D loss: 0.1667, G loss: 1.9473\n",
      "[1762/1762] D loss: 1.5494, G loss: 1.0018\n",
      "train error: \n",
      " D loss: 1.390712, G loss: 0.565983, D accuracy: 52.3%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.383287, G loss: 0.569835, D accuracy: 51.7%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2067, G loss: 1.7897\n",
      "[84/1762] D loss: 1.4378, G loss: 0.7809\n",
      "[164/1762] D loss: 1.4028, G loss: 0.6124\n",
      "[244/1762] D loss: 1.5903, G loss: 0.3499\n",
      "[324/1762] D loss: 0.4657, G loss: 1.1971\n",
      "[404/1762] D loss: 1.4908, G loss: 1.0139\n",
      "[484/1762] D loss: 1.5187, G loss: 1.3323\n",
      "[564/1762] D loss: 0.2719, G loss: 1.7789\n",
      "[644/1762] D loss: 0.3487, G loss: 1.4615\n",
      "[724/1762] D loss: 1.4222, G loss: 0.6568\n",
      "[804/1762] D loss: 1.4262, G loss: 0.5626\n",
      "[884/1762] D loss: 1.4097, G loss: 0.7883\n",
      "[964/1762] D loss: 0.3549, G loss: 1.3631\n",
      "[1044/1762] D loss: 1.5035, G loss: 1.2405\n",
      "[1124/1762] D loss: 0.3787, G loss: 1.2353\n",
      "[1204/1762] D loss: 1.4781, G loss: 0.9772\n",
      "[1284/1762] D loss: 1.4849, G loss: 0.8125\n",
      "[1364/1762] D loss: 1.4229, G loss: 0.5824\n",
      "[1444/1762] D loss: 0.3233, G loss: 1.5799\n",
      "[1524/1762] D loss: 1.4388, G loss: 0.8632\n",
      "[1604/1762] D loss: 1.3600, G loss: 0.7437\n",
      "[1684/1762] D loss: 0.3873, G loss: 1.1659\n",
      "[1762/1762] D loss: 1.4054, G loss: 0.7919\n",
      "train error: \n",
      " D loss: 1.670414, G loss: 0.292505, D accuracy: 50.2%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.662599, G loss: 0.295938, D accuracy: 50.1%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2687, G loss: 1.5487\n",
      "[84/1762] D loss: 1.4537, G loss: 0.6796\n",
      "[164/1762] D loss: 1.4241, G loss: 0.5658\n",
      "[244/1762] D loss: 0.3669, G loss: 1.3405\n",
      "[324/1762] D loss: 1.5458, G loss: 1.1208\n",
      "[404/1762] D loss: 1.3980, G loss: 0.6997\n",
      "[484/1762] D loss: 0.2050, G loss: 1.8303\n",
      "[564/1762] D loss: 1.3035, G loss: 0.9005\n",
      "[644/1762] D loss: 0.3866, G loss: 1.2610\n",
      "[724/1762] D loss: 0.2447, G loss: 2.2288\n",
      "[804/1762] D loss: 2.2052, G loss: 0.3539\n",
      "[884/1762] D loss: 0.9784, G loss: 2.1244\n",
      "[964/1762] D loss: 1.3167, G loss: 0.6659\n",
      "[1044/1762] D loss: 1.5359, G loss: 1.0636\n",
      "[1124/1762] D loss: 1.4079, G loss: 0.6810\n",
      "[1204/1762] D loss: 1.4422, G loss: 0.6843\n",
      "[1284/1762] D loss: 1.4134, G loss: 0.7833\n",
      "[1364/1762] D loss: 1.4184, G loss: 0.6979\n",
      "[1444/1762] D loss: 1.3079, G loss: 0.9167\n",
      "[1524/1762] D loss: 1.4152, G loss: 0.6672\n",
      "[1604/1762] D loss: 1.3214, G loss: 0.8557\n",
      "[1684/1762] D loss: 1.4464, G loss: 0.8898\n",
      "[1762/1762] D loss: 1.3849, G loss: 0.6960\n",
      "train error: \n",
      " D loss: 1.351784, G loss: 0.804241, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 87.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.337385, G loss: 0.823061, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 83.6% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4005, G loss: 0.7086\n",
      "[84/1762] D loss: 1.3848, G loss: 0.7294\n",
      "[164/1762] D loss: 1.4770, G loss: 0.9533\n",
      "[244/1762] D loss: 1.4591, G loss: 0.8463\n",
      "[324/1762] D loss: 0.9838, G loss: 0.9806\n",
      "[404/1762] D loss: 1.4505, G loss: 0.6958\n",
      "[484/1762] D loss: 1.4252, G loss: 0.7641\n",
      "[564/1762] D loss: 0.4601, G loss: 1.1952\n",
      "[644/1762] D loss: 0.5351, G loss: 1.0230\n",
      "[724/1762] D loss: 0.3362, G loss: 1.4320\n",
      "[804/1762] D loss: 1.6085, G loss: 0.4006\n",
      "[884/1762] D loss: 1.4454, G loss: 0.9712\n",
      "[964/1762] D loss: 1.4426, G loss: 0.9237\n",
      "[1044/1762] D loss: 1.4004, G loss: 0.8539\n",
      "[1124/1762] D loss: 1.4032, G loss: 0.7255\n",
      "[1204/1762] D loss: 1.3842, G loss: 0.6392\n",
      "[1284/1762] D loss: 1.3925, G loss: 0.7951\n",
      "[1364/1762] D loss: 1.3919, G loss: 0.7256\n",
      "[1444/1762] D loss: 1.4188, G loss: 0.5267\n",
      "[1524/1762] D loss: 1.4047, G loss: 0.7815\n",
      "[1604/1762] D loss: 1.4229, G loss: 0.8547\n",
      "[1684/1762] D loss: 1.4402, G loss: 0.6265\n",
      "[1762/1762] D loss: 1.3976, G loss: 0.6028\n",
      "train error: \n",
      " D loss: 1.325313, G loss: 0.705920, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.306501, G loss: 0.720327, D accuracy: 56.7%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3236, G loss: 1.7571\n",
      "[84/1762] D loss: 0.9079, G loss: 1.1153\n",
      "[164/1762] D loss: 1.3920, G loss: 0.7437\n",
      "[244/1762] D loss: 0.3498, G loss: 1.4002\n",
      "[324/1762] D loss: 1.4049, G loss: 0.7730\n",
      "[404/1762] D loss: 0.1489, G loss: 2.1168\n",
      "[484/1762] D loss: 1.7428, G loss: 1.2779\n",
      "[564/1762] D loss: 1.5100, G loss: 0.4551\n",
      "[644/1762] D loss: 1.3877, G loss: 0.7662\n",
      "[724/1762] D loss: 1.3523, G loss: 0.7297\n",
      "[804/1762] D loss: 1.4775, G loss: 1.1001\n",
      "[884/1762] D loss: 1.3885, G loss: 0.6548\n",
      "[964/1762] D loss: 1.4140, G loss: 0.8506\n",
      "[1044/1762] D loss: 1.4186, G loss: 0.6031\n",
      "[1124/1762] D loss: 1.4828, G loss: 0.5790\n",
      "[1204/1762] D loss: 1.4576, G loss: 1.0417\n",
      "[1284/1762] D loss: 1.5276, G loss: 0.9680\n",
      "[1364/1762] D loss: 1.4247, G loss: 0.5200\n",
      "[1444/1762] D loss: 0.0992, G loss: 2.6834\n",
      "[1524/1762] D loss: 1.4307, G loss: 0.7446\n",
      "[1604/1762] D loss: 0.3399, G loss: 1.5507\n",
      "[1684/1762] D loss: 0.1893, G loss: 1.9078\n",
      "[1762/1762] D loss: 1.6352, G loss: 1.2805\n",
      "train error: \n",
      " D loss: 1.377522, G loss: 0.551980, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.362403, G loss: 0.556384, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.8506, G loss: 1.3872\n",
      "[84/1762] D loss: 1.4270, G loss: 0.8518\n",
      "[164/1762] D loss: 1.3931, G loss: 0.6917\n",
      "[244/1762] D loss: 0.1917, G loss: 1.8420\n",
      "[324/1762] D loss: 1.4171, G loss: 0.6125\n",
      "[404/1762] D loss: 0.1437, G loss: 2.1759\n",
      "[484/1762] D loss: 1.3899, G loss: 1.0526\n",
      "[564/1762] D loss: 0.0799, G loss: 2.7450\n",
      "[644/1762] D loss: 0.2679, G loss: 3.1976\n",
      "[724/1762] D loss: 1.8836, G loss: 1.1968\n",
      "[804/1762] D loss: 1.1021, G loss: 0.7991\n",
      "[884/1762] D loss: 1.4283, G loss: 0.7808\n",
      "[964/1762] D loss: 1.4151, G loss: 0.8745\n",
      "[1044/1762] D loss: 1.3933, G loss: 0.6359\n",
      "[1124/1762] D loss: 1.4373, G loss: 0.8327\n",
      "[1204/1762] D loss: 1.5219, G loss: 0.9345\n",
      "[1284/1762] D loss: 0.6345, G loss: 1.1995\n",
      "[1364/1762] D loss: 1.2877, G loss: 0.6511\n",
      "[1444/1762] D loss: 1.4021, G loss: 0.7022\n",
      "[1524/1762] D loss: 1.3861, G loss: 0.6401\n",
      "[1604/1762] D loss: 0.5293, G loss: 1.5027\n",
      "[1684/1762] D loss: 1.3909, G loss: 0.6061\n",
      "[1762/1762] D loss: 1.0523, G loss: 1.0531\n",
      "train error: \n",
      " D loss: 1.342297, G loss: 0.625915, D accuracy: 57.7%, cell accuracy: 99.6%, board accuracy: 74.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.341585, G loss: 0.620387, D accuracy: 56.4%, cell accuracy: 99.5%, board accuracy: 72.0% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4130, G loss: 0.5816\n",
      "[84/1762] D loss: 1.3430, G loss: 0.8263\n",
      "[164/1762] D loss: 1.3412, G loss: 0.7325\n",
      "[244/1762] D loss: 0.3689, G loss: 1.5245\n",
      "[324/1762] D loss: 1.4236, G loss: 0.7530\n",
      "[404/1762] D loss: 1.5849, G loss: 1.0746\n",
      "[484/1762] D loss: 1.3848, G loss: 0.8556\n",
      "[564/1762] D loss: 1.4242, G loss: 0.8797\n",
      "[644/1762] D loss: 1.3974, G loss: 0.8040\n",
      "[724/1762] D loss: 0.2345, G loss: 1.8018\n",
      "[804/1762] D loss: 0.2667, G loss: 1.8665\n",
      "[884/1762] D loss: 1.5112, G loss: 1.0265\n",
      "[964/1762] D loss: 0.2804, G loss: 1.5917\n",
      "[1044/1762] D loss: 0.2474, G loss: 1.7030\n",
      "[1124/1762] D loss: 1.4137, G loss: 0.5991\n",
      "[1204/1762] D loss: 0.2305, G loss: 1.7610\n",
      "[1284/1762] D loss: 0.2148, G loss: 1.7673\n",
      "[1364/1762] D loss: 1.3391, G loss: 0.6931\n",
      "[1444/1762] D loss: 1.4209, G loss: 0.8001\n",
      "[1524/1762] D loss: 1.3828, G loss: 0.7440\n",
      "[1604/1762] D loss: 0.2608, G loss: 1.6464\n",
      "[1684/1762] D loss: 1.4128, G loss: 0.5690\n",
      "[1762/1762] D loss: 1.4276, G loss: 0.6310\n",
      "train error: \n",
      " D loss: 1.353185, G loss: 0.606094, D accuracy: 53.8%, cell accuracy: 99.7%, board accuracy: 85.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.333362, G loss: 0.616967, D accuracy: 55.1%, cell accuracy: 99.6%, board accuracy: 82.5% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3460, G loss: 0.7595\n",
      "[84/1762] D loss: 0.0554, G loss: 3.3495\n",
      "[164/1762] D loss: 1.4445, G loss: 0.7831\n",
      "[244/1762] D loss: 0.2976, G loss: 1.5590\n",
      "[324/1762] D loss: 0.1072, G loss: 2.7590\n",
      "[404/1762] D loss: 0.0279, G loss: 4.1733\n",
      "[484/1762] D loss: 0.0422, G loss: 3.4962\n",
      "[564/1762] D loss: 0.3112, G loss: 1.5634\n",
      "[644/1762] D loss: 1.2214, G loss: 0.8970\n",
      "[724/1762] D loss: 1.5165, G loss: 0.7070\n",
      "[804/1762] D loss: 1.4121, G loss: 0.8788\n",
      "[884/1762] D loss: 1.3950, G loss: 0.6964\n",
      "[964/1762] D loss: 1.4338, G loss: 0.5392\n",
      "[1044/1762] D loss: 2.7755, G loss: 0.1488\n",
      "[1124/1762] D loss: 2.1172, G loss: 0.2863\n",
      "[1204/1762] D loss: 1.3646, G loss: 0.6497\n",
      "[1284/1762] D loss: 1.1912, G loss: 2.1145\n",
      "[1364/1762] D loss: 1.4156, G loss: 0.5556\n",
      "[1444/1762] D loss: 0.7820, G loss: 1.2809\n",
      "[1524/1762] D loss: 1.5104, G loss: 0.6614\n",
      "[1604/1762] D loss: 1.0747, G loss: 0.8208\n",
      "[1684/1762] D loss: 1.3924, G loss: 0.7015\n",
      "[1762/1762] D loss: 1.5109, G loss: 0.6970\n",
      "train error: \n",
      " D loss: 1.374656, G loss: 0.798678, D accuracy: 53.0%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.366975, G loss: 0.794834, D accuracy: 53.1%, cell accuracy: 99.7%, board accuracy: 85.0% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4019, G loss: 0.7382\n",
      "[84/1762] D loss: 0.8128, G loss: 1.3858\n",
      "[164/1762] D loss: 1.4120, G loss: 0.5891\n",
      "[244/1762] D loss: 1.3432, G loss: 0.9582\n",
      "[324/1762] D loss: 1.3729, G loss: 0.8732\n",
      "[404/1762] D loss: 1.3135, G loss: 1.1297\n",
      "[484/1762] D loss: 1.4242, G loss: 0.8455\n",
      "[564/1762] D loss: 1.3912, G loss: 0.6866\n",
      "[644/1762] D loss: 1.3895, G loss: 0.6892\n",
      "[724/1762] D loss: 1.4062, G loss: 0.8437\n",
      "[804/1762] D loss: 1.3599, G loss: 0.7371\n",
      "[884/1762] D loss: 0.7047, G loss: 1.1179\n",
      "[964/1762] D loss: 1.4005, G loss: 0.7873\n",
      "[1044/1762] D loss: 0.5374, G loss: 1.8011\n",
      "[1124/1762] D loss: 1.4238, G loss: 0.9253\n",
      "[1204/1762] D loss: 0.6516, G loss: 1.0808\n",
      "[1284/1762] D loss: 1.4230, G loss: 0.5625\n",
      "[1364/1762] D loss: 0.6978, G loss: 1.3638\n",
      "[1444/1762] D loss: 1.4317, G loss: 0.6032\n",
      "[1524/1762] D loss: 1.4285, G loss: 0.8523\n",
      "[1604/1762] D loss: 0.3317, G loss: 1.4361\n",
      "[1684/1762] D loss: 1.4473, G loss: 0.8781\n",
      "[1762/1762] D loss: 0.5047, G loss: 1.9025\n",
      "train error: \n",
      " D loss: 1.046627, G loss: 1.037540, D accuracy: 78.5%, cell accuracy: 99.3%, board accuracy: 34.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.093161, G loss: 0.945574, D accuracy: 74.8%, cell accuracy: 99.4%, board accuracy: 42.3% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0621, G loss: 1.1481\n",
      "[84/1762] D loss: 1.4939, G loss: 1.0318\n",
      "[164/1762] D loss: 0.3185, G loss: 1.6798\n",
      "[244/1762] D loss: 1.4420, G loss: 0.8777\n",
      "[324/1762] D loss: 0.3386, G loss: 1.6157\n",
      "[404/1762] D loss: 1.4310, G loss: 0.6933\n",
      "[484/1762] D loss: 1.6195, G loss: 1.2478\n",
      "[564/1762] D loss: 1.3973, G loss: 0.7019\n",
      "[644/1762] D loss: 0.3862, G loss: 1.3480\n",
      "[724/1762] D loss: 1.5347, G loss: 1.0771\n",
      "[804/1762] D loss: 0.8600, G loss: 0.9249\n",
      "[884/1762] D loss: 1.2047, G loss: 0.7973\n",
      "[964/1762] D loss: 1.4505, G loss: 0.5445\n",
      "[1044/1762] D loss: 1.3928, G loss: 0.7332\n",
      "[1124/1762] D loss: 0.7628, G loss: 0.9873\n",
      "[1204/1762] D loss: 1.4013, G loss: 0.6077\n",
      "[1284/1762] D loss: 1.3865, G loss: 0.7143\n",
      "[1364/1762] D loss: 1.3988, G loss: 0.7976\n",
      "[1444/1762] D loss: 0.2805, G loss: 1.6852\n",
      "[1524/1762] D loss: 1.3948, G loss: 0.6618\n",
      "[1604/1762] D loss: 1.3680, G loss: 0.6847\n",
      "[1684/1762] D loss: 1.3343, G loss: 1.3209\n",
      "[1762/1762] D loss: 0.7512, G loss: 1.4908\n",
      "train error: \n",
      " D loss: 1.443548, G loss: 1.186247, D accuracy: 52.8%, cell accuracy: 99.7%, board accuracy: 80.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.442329, G loss: 1.171090, D accuracy: 53.3%, cell accuracy: 99.7%, board accuracy: 80.0% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3259, G loss: 0.6862\n",
      "[84/1762] D loss: 1.0761, G loss: 1.2083\n",
      "[164/1762] D loss: 0.8932, G loss: 1.0957\n",
      "[244/1762] D loss: 1.4643, G loss: 0.5042\n",
      "[324/1762] D loss: 1.4004, G loss: 0.6393\n",
      "[404/1762] D loss: 1.3035, G loss: 0.9141\n",
      "[484/1762] D loss: 1.4190, G loss: 0.5959\n",
      "[564/1762] D loss: 1.4349, G loss: 0.6428\n",
      "[644/1762] D loss: 1.3955, G loss: 0.6542\n",
      "[724/1762] D loss: 0.6390, G loss: 1.4596\n",
      "[804/1762] D loss: 1.3968, G loss: 0.9052\n",
      "[884/1762] D loss: 0.8495, G loss: 1.2267\n",
      "[964/1762] D loss: 1.3970, G loss: 0.6786\n",
      "[1044/1762] D loss: 1.3892, G loss: 0.7402\n",
      "[1124/1762] D loss: 1.3972, G loss: 0.6321\n",
      "[1204/1762] D loss: 1.4050, G loss: 0.7612\n",
      "[1284/1762] D loss: 1.3874, G loss: 0.7479\n",
      "[1364/1762] D loss: 1.3977, G loss: 0.7641\n",
      "[1444/1762] D loss: 1.3901, G loss: 0.7642\n",
      "[1524/1762] D loss: 1.3922, G loss: 0.8132\n",
      "[1604/1762] D loss: 1.4435, G loss: 1.1298\n",
      "[1684/1762] D loss: 0.4445, G loss: 1.2743\n",
      "[1762/1762] D loss: 1.3355, G loss: 0.9865\n",
      "train error: \n",
      " D loss: 1.326360, G loss: 1.030027, D accuracy: 54.7%, cell accuracy: 99.6%, board accuracy: 76.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.296235, G loss: 1.063973, D accuracy: 55.3%, cell accuracy: 99.5%, board accuracy: 71.8% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5896, G loss: 1.0204\n",
      "[84/1762] D loss: 0.3227, G loss: 1.4383\n",
      "[164/1762] D loss: 1.4215, G loss: 0.7641\n",
      "[244/1762] D loss: 1.3985, G loss: 0.8739\n",
      "[324/1762] D loss: 0.6820, G loss: 2.3789\n",
      "[404/1762] D loss: 1.3872, G loss: 0.6983\n",
      "[484/1762] D loss: 1.4502, G loss: 1.1152\n",
      "[564/1762] D loss: 1.3677, G loss: 0.6444\n",
      "[644/1762] D loss: 1.4058, G loss: 0.7742\n",
      "[724/1762] D loss: 1.4105, G loss: 0.6903\n",
      "[804/1762] D loss: 1.1123, G loss: 0.8195\n",
      "[884/1762] D loss: 1.5292, G loss: 0.4092\n",
      "[964/1762] D loss: 1.4161, G loss: 0.5851\n",
      "[1044/1762] D loss: 1.3869, G loss: 0.6850\n",
      "[1124/1762] D loss: 1.0869, G loss: 1.5036\n",
      "[1204/1762] D loss: 1.4149, G loss: 0.8671\n",
      "[1284/1762] D loss: 1.4208, G loss: 0.5397\n",
      "[1364/1762] D loss: 1.3730, G loss: 0.6497\n",
      "[1444/1762] D loss: 1.3671, G loss: 1.0025\n",
      "[1524/1762] D loss: 1.4933, G loss: 0.9465\n",
      "[1604/1762] D loss: 1.4059, G loss: 0.5744\n",
      "[1684/1762] D loss: 1.4076, G loss: 0.7441\n",
      "[1762/1762] D loss: 1.4191, G loss: 0.9023\n",
      "train error: \n",
      " D loss: 1.378460, G loss: 0.845673, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 90.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.364235, G loss: 0.848081, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3913, G loss: 0.7041\n",
      "[84/1762] D loss: 1.3891, G loss: 0.6370\n",
      "[164/1762] D loss: 1.4015, G loss: 0.7821\n",
      "[244/1762] D loss: 1.1398, G loss: 1.1422\n",
      "[324/1762] D loss: 0.3519, G loss: 1.7023\n",
      "[404/1762] D loss: 1.4513, G loss: 0.8825\n",
      "[484/1762] D loss: 1.4063, G loss: 0.7465\n",
      "[564/1762] D loss: 1.4445, G loss: 0.8507\n",
      "[644/1762] D loss: 0.3296, G loss: 1.5989\n",
      "[724/1762] D loss: 1.4423, G loss: 0.9228\n",
      "[804/1762] D loss: 1.7525, G loss: 1.3792\n",
      "[884/1762] D loss: 1.4929, G loss: 0.6979\n",
      "[964/1762] D loss: 1.3325, G loss: 0.6618\n",
      "[1044/1762] D loss: 1.3890, G loss: 0.7942\n",
      "[1124/1762] D loss: 1.3157, G loss: 0.9734\n",
      "[1204/1762] D loss: 1.3991, G loss: 0.7078\n",
      "[1284/1762] D loss: 1.3912, G loss: 0.6927\n",
      "[1364/1762] D loss: 0.6006, G loss: 1.2471\n",
      "[1444/1762] D loss: 1.4853, G loss: 0.9030\n",
      "[1524/1762] D loss: 1.3929, G loss: 0.7084\n",
      "[1604/1762] D loss: 1.0081, G loss: 0.8295\n",
      "[1684/1762] D loss: 1.6329, G loss: 0.6865\n",
      "[1762/1762] D loss: 1.4286, G loss: 0.6017\n",
      "train error: \n",
      " D loss: 1.335652, G loss: 0.724380, D accuracy: 55.9%, cell accuracy: 99.8%, board accuracy: 74.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.320250, G loss: 0.729141, D accuracy: 55.9%, cell accuracy: 99.8%, board accuracy: 76.4% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4243, G loss: 0.7954\n",
      "[84/1762] D loss: 1.3911, G loss: 0.7697\n",
      "[164/1762] D loss: 1.4245, G loss: 0.7644\n",
      "[244/1762] D loss: 1.5597, G loss: 1.1047\n",
      "[324/1762] D loss: 1.4565, G loss: 0.4862\n",
      "[404/1762] D loss: 1.4408, G loss: 0.4872\n",
      "[484/1762] D loss: 1.4466, G loss: 0.7605\n",
      "[564/1762] D loss: 1.4798, G loss: 0.8151\n",
      "[644/1762] D loss: 1.4147, G loss: 0.8542\n",
      "[724/1762] D loss: 1.3853, G loss: 0.6728\n",
      "[804/1762] D loss: 1.4828, G loss: 0.5322\n",
      "[884/1762] D loss: 1.2993, G loss: 0.9503\n",
      "[964/1762] D loss: 1.0365, G loss: 1.3718\n",
      "[1044/1762] D loss: 1.4040, G loss: 0.6076\n",
      "[1124/1762] D loss: 1.4111, G loss: 0.9842\n",
      "[1204/1762] D loss: 1.0155, G loss: 1.0317\n",
      "[1284/1762] D loss: 1.3879, G loss: 0.6885\n",
      "[1364/1762] D loss: 1.2248, G loss: 0.7365\n",
      "[1444/1762] D loss: 1.2271, G loss: 0.7441\n",
      "[1524/1762] D loss: 1.4027, G loss: 0.7097\n",
      "[1604/1762] D loss: 1.4092, G loss: 0.7107\n",
      "[1684/1762] D loss: 1.4004, G loss: 0.6832\n",
      "[1762/1762] D loss: 1.4220, G loss: 0.5975\n",
      "train error: \n",
      " D loss: 1.320851, G loss: 0.755226, D accuracy: 54.8%, cell accuracy: 99.9%, board accuracy: 89.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.305960, G loss: 0.788902, D accuracy: 55.9%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4065, G loss: 0.6356\n",
      "[84/1762] D loss: 1.2705, G loss: 1.0378\n",
      "[164/1762] D loss: 1.4012, G loss: 0.6092\n",
      "[244/1762] D loss: 1.1089, G loss: 1.0781\n",
      "[324/1762] D loss: 1.3998, G loss: 0.7477\n",
      "[404/1762] D loss: 1.3926, G loss: 0.7514\n",
      "[484/1762] D loss: 1.3989, G loss: 0.5941\n",
      "[564/1762] D loss: 1.3934, G loss: 0.7117\n",
      "[644/1762] D loss: 1.2647, G loss: 1.5489\n",
      "[724/1762] D loss: 0.9797, G loss: 1.6785\n",
      "[804/1762] D loss: 1.4104, G loss: 0.5740\n",
      "[884/1762] D loss: 1.3915, G loss: 0.7519\n",
      "[964/1762] D loss: 1.3879, G loss: 0.6785\n",
      "[1044/1762] D loss: 1.4009, G loss: 0.5876\n",
      "[1124/1762] D loss: 1.4078, G loss: 0.5933\n",
      "[1204/1762] D loss: 0.8912, G loss: 1.4165\n",
      "[1284/1762] D loss: 1.3876, G loss: 0.6505\n",
      "[1364/1762] D loss: 1.1029, G loss: 0.7988\n",
      "[1444/1762] D loss: 1.4515, G loss: 0.8710\n",
      "[1524/1762] D loss: 1.3876, G loss: 0.6948\n",
      "[1604/1762] D loss: 1.4048, G loss: 0.7750\n",
      "[1684/1762] D loss: 1.5919, G loss: 0.6854\n",
      "[1762/1762] D loss: 1.3942, G loss: 0.7907\n",
      "train error: \n",
      " D loss: 1.356709, G loss: 0.853628, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 91.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.341211, G loss: 0.857813, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4037, G loss: 0.8136\n",
      "[84/1762] D loss: 0.8553, G loss: 0.9869\n",
      "[164/1762] D loss: 1.4443, G loss: 0.9504\n",
      "[244/1762] D loss: 1.3763, G loss: 0.7350\n",
      "[324/1762] D loss: 1.3902, G loss: 0.6711\n",
      "[404/1762] D loss: 1.3799, G loss: 0.8006\n",
      "[484/1762] D loss: 1.4316, G loss: 0.5994\n",
      "[564/1762] D loss: 1.3973, G loss: 0.6416\n",
      "[644/1762] D loss: 0.3411, G loss: 2.2942\n",
      "[724/1762] D loss: 1.5313, G loss: 0.3926\n",
      "[804/1762] D loss: 0.6116, G loss: 1.2815\n",
      "[884/1762] D loss: 1.4029, G loss: 0.7991\n",
      "[964/1762] D loss: 1.3431, G loss: 0.6823\n",
      "[1044/1762] D loss: 1.2428, G loss: 0.6006\n",
      "[1124/1762] D loss: 1.3305, G loss: 0.6821\n",
      "[1204/1762] D loss: 1.4326, G loss: 0.9609\n",
      "[1284/1762] D loss: 1.3904, G loss: 0.6851\n",
      "[1364/1762] D loss: 1.1201, G loss: 1.2511\n",
      "[1444/1762] D loss: 1.2962, G loss: 0.5139\n",
      "[1524/1762] D loss: 1.5528, G loss: 0.4004\n",
      "[1604/1762] D loss: 1.5996, G loss: 0.3603\n",
      "[1684/1762] D loss: 1.9618, G loss: 0.6058\n",
      "[1762/1762] D loss: 1.7409, G loss: 0.3360\n",
      "train error: \n",
      " D loss: 1.395871, G loss: 0.627206, D accuracy: 52.9%, cell accuracy: 99.9%, board accuracy: 90.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.374724, G loss: 0.659811, D accuracy: 54.5%, cell accuracy: 99.9%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4255, G loss: 0.7095\n",
      "[84/1762] D loss: 1.2130, G loss: 0.7754\n",
      "[164/1762] D loss: 1.4330, G loss: 0.4932\n",
      "[244/1762] D loss: 1.4036, G loss: 0.6148\n",
      "[324/1762] D loss: 1.3980, G loss: 0.6688\n",
      "[404/1762] D loss: 1.1244, G loss: 0.9415\n",
      "[484/1762] D loss: 1.3934, G loss: 0.8116\n",
      "[564/1762] D loss: 1.4551, G loss: 0.9249\n",
      "[644/1762] D loss: 1.3931, G loss: 0.8203\n",
      "[724/1762] D loss: 1.3921, G loss: 0.6840\n",
      "[804/1762] D loss: 1.4926, G loss: 0.8371\n",
      "[884/1762] D loss: 1.5179, G loss: 1.0991\n",
      "[964/1762] D loss: 1.0480, G loss: 0.8994\n",
      "[1044/1762] D loss: 1.0973, G loss: 0.7229\n",
      "[1124/1762] D loss: 1.4891, G loss: 0.9556\n",
      "[1204/1762] D loss: 1.4235, G loss: 0.8570\n",
      "[1284/1762] D loss: 0.7855, G loss: 1.2077\n",
      "[1364/1762] D loss: 1.4044, G loss: 0.8298\n",
      "[1444/1762] D loss: 1.4163, G loss: 0.7137\n",
      "[1524/1762] D loss: 0.9441, G loss: 1.1911\n",
      "[1604/1762] D loss: 1.3908, G loss: 0.7286\n",
      "[1684/1762] D loss: 1.3991, G loss: 0.6820\n",
      "[1762/1762] D loss: 1.4251, G loss: 0.6316\n",
      "train error: \n",
      " D loss: 1.359159, G loss: 0.840539, D accuracy: 52.7%, cell accuracy: 99.9%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.349270, G loss: 0.842469, D accuracy: 52.8%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4130, G loss: 0.5689\n",
      "[84/1762] D loss: 1.3918, G loss: 0.7306\n",
      "[164/1762] D loss: 1.2263, G loss: 1.1184\n",
      "[244/1762] D loss: 0.8525, G loss: 1.3625\n",
      "[324/1762] D loss: 1.3994, G loss: 0.6218\n",
      "[404/1762] D loss: 1.4058, G loss: 0.7916\n",
      "[484/1762] D loss: 1.3926, G loss: 0.6549\n",
      "[564/1762] D loss: 1.3582, G loss: 0.6392\n",
      "[644/1762] D loss: 1.1530, G loss: 0.9651\n",
      "[724/1762] D loss: 1.3884, G loss: 0.7043\n",
      "[804/1762] D loss: 1.3959, G loss: 0.7875\n",
      "[884/1762] D loss: 1.3920, G loss: 0.7240\n",
      "[964/1762] D loss: 1.3935, G loss: 0.7393\n",
      "[1044/1762] D loss: 1.2827, G loss: 1.2729\n",
      "[1124/1762] D loss: 1.4138, G loss: 0.5689\n",
      "[1204/1762] D loss: 1.3876, G loss: 0.5938\n",
      "[1284/1762] D loss: 0.7741, G loss: 1.1698\n",
      "[1364/1762] D loss: 1.3168, G loss: 0.7671\n",
      "[1444/1762] D loss: 1.3506, G loss: 0.7737\n",
      "[1524/1762] D loss: 0.8802, G loss: 1.3070\n",
      "[1604/1762] D loss: 1.4101, G loss: 0.6360\n",
      "[1684/1762] D loss: 1.3890, G loss: 0.5978\n",
      "[1762/1762] D loss: 1.5812, G loss: 0.3804\n",
      "train error: \n",
      " D loss: 1.397875, G loss: 0.869421, D accuracy: 51.5%, cell accuracy: 99.7%, board accuracy: 87.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.385491, G loss: 0.875446, D accuracy: 52.3%, cell accuracy: 99.7%, board accuracy: 84.8% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5698, G loss: 0.4092\n",
      "[84/1762] D loss: 1.2616, G loss: 0.8474\n",
      "[164/1762] D loss: 1.1750, G loss: 0.6708\n",
      "[244/1762] D loss: 1.3917, G loss: 0.8376\n",
      "[324/1762] D loss: 1.4021, G loss: 0.7365\n",
      "[404/1762] D loss: 1.3913, G loss: 0.7323\n",
      "[484/1762] D loss: 1.3949, G loss: 0.7513\n",
      "[564/1762] D loss: 1.3958, G loss: 0.7411\n",
      "[644/1762] D loss: 1.4212, G loss: 0.8636\n",
      "[724/1762] D loss: 1.3885, G loss: 0.7354\n",
      "[804/1762] D loss: 1.4112, G loss: 0.6914\n",
      "[884/1762] D loss: 1.4160, G loss: 0.7783\n",
      "[964/1762] D loss: 1.4034, G loss: 0.8646\n",
      "[1044/1762] D loss: 0.7820, G loss: 1.0209\n",
      "[1124/1762] D loss: 1.3945, G loss: 0.7041\n",
      "[1204/1762] D loss: 1.3242, G loss: 0.9878\n",
      "[1284/1762] D loss: 1.3983, G loss: 0.5784\n",
      "[1364/1762] D loss: 1.3968, G loss: 0.7638\n",
      "[1444/1762] D loss: 1.3915, G loss: 0.7787\n",
      "[1524/1762] D loss: 1.3760, G loss: 0.6798\n",
      "[1604/1762] D loss: 1.5435, G loss: 0.8977\n",
      "[1684/1762] D loss: 0.9399, G loss: 1.4944\n",
      "[1762/1762] D loss: 2.1574, G loss: 1.2389\n",
      "train error: \n",
      " D loss: 1.431229, G loss: 1.118828, D accuracy: 51.9%, cell accuracy: 99.8%, board accuracy: 89.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.425212, G loss: 1.107715, D accuracy: 52.7%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9636, G loss: 0.7855\n",
      "[84/1762] D loss: 0.7920, G loss: 1.0531\n",
      "[164/1762] D loss: 1.4222, G loss: 0.6140\n",
      "[244/1762] D loss: 0.7595, G loss: 1.4569\n",
      "[324/1762] D loss: 1.4111, G loss: 0.8419\n",
      "[404/1762] D loss: 1.4007, G loss: 0.6536\n",
      "[484/1762] D loss: 1.3953, G loss: 0.6609\n",
      "[564/1762] D loss: 1.4110, G loss: 0.7286\n",
      "[644/1762] D loss: 1.3938, G loss: 0.5949\n",
      "[724/1762] D loss: 0.7602, G loss: 1.1186\n",
      "[804/1762] D loss: 1.0876, G loss: 0.7686\n",
      "[884/1762] D loss: 1.3932, G loss: 0.7121\n",
      "[964/1762] D loss: 1.4380, G loss: 0.5138\n",
      "[1044/1762] D loss: 1.4114, G loss: 0.7518\n",
      "[1124/1762] D loss: 1.3394, G loss: 0.7615\n",
      "[1204/1762] D loss: 1.4241, G loss: 0.5509\n",
      "[1284/1762] D loss: 1.4116, G loss: 0.6102\n",
      "[1364/1762] D loss: 1.3989, G loss: 0.6922\n",
      "[1444/1762] D loss: 1.4103, G loss: 0.6280\n",
      "[1524/1762] D loss: 1.4631, G loss: 0.5097\n",
      "[1604/1762] D loss: 1.3965, G loss: 0.6347\n",
      "[1684/1762] D loss: 0.4770, G loss: 1.2836\n",
      "[1762/1762] D loss: 1.4554, G loss: 0.8930\n",
      "train error: \n",
      " D loss: 1.368170, G loss: 0.991662, D accuracy: 52.6%, cell accuracy: 99.9%, board accuracy: 90.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.347603, G loss: 1.046677, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4112, G loss: 0.7681\n",
      "[84/1762] D loss: 0.6911, G loss: 1.0329\n",
      "[164/1762] D loss: 1.3886, G loss: 0.7569\n",
      "[244/1762] D loss: 1.4494, G loss: 0.5958\n",
      "[324/1762] D loss: 1.5205, G loss: 0.5879\n",
      "[404/1762] D loss: 1.4581, G loss: 0.8544\n",
      "[484/1762] D loss: 1.4029, G loss: 0.6947\n",
      "[564/1762] D loss: 1.3985, G loss: 0.6500\n",
      "[644/1762] D loss: 1.4144, G loss: 0.7242\n",
      "[724/1762] D loss: 1.3896, G loss: 0.6601\n",
      "[804/1762] D loss: 1.4026, G loss: 0.6062\n",
      "[884/1762] D loss: 1.4011, G loss: 0.6290\n",
      "[964/1762] D loss: 1.3915, G loss: 0.7372\n",
      "[1044/1762] D loss: 1.4209, G loss: 0.8613\n",
      "[1124/1762] D loss: 1.1779, G loss: 0.7156\n",
      "[1204/1762] D loss: 0.9007, G loss: 1.1191\n",
      "[1284/1762] D loss: 1.3873, G loss: 0.7073\n",
      "[1364/1762] D loss: 1.3529, G loss: 0.6402\n",
      "[1444/1762] D loss: 0.8085, G loss: 1.0764\n",
      "[1524/1762] D loss: 1.4144, G loss: 0.6941\n",
      "[1604/1762] D loss: 1.0865, G loss: 1.4264\n",
      "[1684/1762] D loss: 1.3873, G loss: 0.6386\n",
      "[1762/1762] D loss: 1.4323, G loss: 0.5654\n",
      "train error: \n",
      " D loss: 1.355457, G loss: 0.780650, D accuracy: 52.7%, cell accuracy: 99.9%, board accuracy: 91.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.343773, G loss: 0.798059, D accuracy: 53.1%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3966, G loss: 0.6566\n",
      "[84/1762] D loss: 1.3998, G loss: 0.7080\n",
      "[164/1762] D loss: 1.4038, G loss: 0.7437\n",
      "[244/1762] D loss: 1.4158, G loss: 0.7159\n",
      "[324/1762] D loss: 1.3952, G loss: 0.6354\n",
      "[404/1762] D loss: 1.3524, G loss: 0.8598\n",
      "[484/1762] D loss: 1.4160, G loss: 0.5991\n",
      "[564/1762] D loss: 1.4389, G loss: 0.8545\n",
      "[644/1762] D loss: 1.4442, G loss: 0.7497\n",
      "[724/1762] D loss: 1.3962, G loss: 0.7326\n",
      "[804/1762] D loss: 1.4025, G loss: 0.6214\n",
      "[884/1762] D loss: 1.3801, G loss: 0.6951\n",
      "[964/1762] D loss: 1.4308, G loss: 0.7882\n",
      "[1044/1762] D loss: 1.5277, G loss: 0.7443\n",
      "[1124/1762] D loss: 0.5338, G loss: 1.5289\n",
      "[1204/1762] D loss: 1.4044, G loss: 0.6764\n",
      "[1284/1762] D loss: 1.4403, G loss: 0.5357\n",
      "[1364/1762] D loss: 1.2970, G loss: 1.0134\n",
      "[1444/1762] D loss: 1.3636, G loss: 0.9095\n",
      "[1524/1762] D loss: 0.8043, G loss: 1.4102\n",
      "[1604/1762] D loss: 1.3949, G loss: 0.7166\n",
      "[1684/1762] D loss: 1.3996, G loss: 0.6964\n",
      "[1762/1762] D loss: 1.4255, G loss: 0.8767\n",
      "train error: \n",
      " D loss: 1.350872, G loss: 0.855787, D accuracy: 52.9%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.328991, G loss: 0.901921, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3931, G loss: 0.8129\n",
      "[84/1762] D loss: 0.5188, G loss: 2.3248\n",
      "[164/1762] D loss: 1.4423, G loss: 0.5173\n",
      "[244/1762] D loss: 1.4030, G loss: 0.6747\n",
      "[324/1762] D loss: 1.4022, G loss: 0.7327\n",
      "[404/1762] D loss: 1.6494, G loss: 1.0866\n",
      "[484/1762] D loss: 1.3998, G loss: 0.6323\n",
      "[564/1762] D loss: 1.5013, G loss: 1.0279\n",
      "[644/1762] D loss: 1.6047, G loss: 1.0935\n",
      "[724/1762] D loss: 1.4041, G loss: 0.6470\n",
      "[804/1762] D loss: 1.3975, G loss: 0.8378\n",
      "[884/1762] D loss: 1.4986, G loss: 0.6379\n",
      "[964/1762] D loss: 1.4267, G loss: 0.4959\n",
      "[1044/1762] D loss: 0.3602, G loss: 1.4807\n",
      "[1124/1762] D loss: 0.5664, G loss: 1.8032\n",
      "[1204/1762] D loss: 1.4574, G loss: 0.9922\n",
      "[1284/1762] D loss: 0.4646, G loss: 1.1942\n",
      "[1364/1762] D loss: 1.4072, G loss: 0.6060\n",
      "[1444/1762] D loss: 1.3965, G loss: 0.8707\n",
      "[1524/1762] D loss: 1.4021, G loss: 0.8650\n",
      "[1604/1762] D loss: 1.3884, G loss: 0.7779\n",
      "[1684/1762] D loss: 1.0743, G loss: 2.7601\n",
      "[1762/1762] D loss: 1.4986, G loss: 0.9627\n",
      "train error: \n",
      " D loss: 1.350737, G loss: 0.643184, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 91.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.333545, G loss: 0.654040, D accuracy: 54.3%, cell accuracy: 99.9%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4042, G loss: 0.6810\n",
      "[84/1762] D loss: 0.3879, G loss: 1.9781\n",
      "[164/1762] D loss: 0.5669, G loss: 1.5456\n",
      "[244/1762] D loss: 0.8373, G loss: 1.6503\n",
      "[324/1762] D loss: 1.4245, G loss: 0.7850\n",
      "[404/1762] D loss: 1.3571, G loss: 1.1023\n",
      "[484/1762] D loss: 1.4145, G loss: 0.5372\n",
      "[564/1762] D loss: 1.4002, G loss: 0.6328\n",
      "[644/1762] D loss: 1.3978, G loss: 0.7520\n",
      "[724/1762] D loss: 1.3975, G loss: 0.7678\n",
      "[804/1762] D loss: 0.1716, G loss: 2.3558\n",
      "[884/1762] D loss: 0.3699, G loss: 1.4456\n",
      "[964/1762] D loss: 1.4129, G loss: 0.7642\n",
      "[1044/1762] D loss: 1.4478, G loss: 0.9234\n",
      "[1124/1762] D loss: 1.3512, G loss: 0.5359\n",
      "[1204/1762] D loss: 1.3949, G loss: 0.6922\n",
      "[1284/1762] D loss: 1.4379, G loss: 0.9513\n",
      "[1364/1762] D loss: 1.4136, G loss: 0.7892\n",
      "[1444/1762] D loss: 0.2694, G loss: 1.6202\n",
      "[1524/1762] D loss: 1.4277, G loss: 0.7645\n",
      "[1604/1762] D loss: 1.3878, G loss: 0.7316\n",
      "[1684/1762] D loss: 1.4056, G loss: 0.8059\n",
      "[1762/1762] D loss: 1.3105, G loss: 1.0297\n",
      "train error: \n",
      " D loss: 1.311884, G loss: 0.777510, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.287491, G loss: 0.805804, D accuracy: 56.2%, cell accuracy: 99.8%, board accuracy: 85.5% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3704, G loss: 0.6973\n",
      "[84/1762] D loss: 1.5115, G loss: 0.4074\n",
      "[164/1762] D loss: 1.3976, G loss: 0.8059\n",
      "[244/1762] D loss: 1.6804, G loss: 1.3161\n",
      "[324/1762] D loss: 0.5001, G loss: 1.5653\n",
      "[404/1762] D loss: 1.5279, G loss: 1.0860\n",
      "[484/1762] D loss: 1.4139, G loss: 0.6377\n",
      "[564/1762] D loss: 1.4055, G loss: 0.6512\n",
      "[644/1762] D loss: 1.4185, G loss: 0.8192\n",
      "[724/1762] D loss: 1.4055, G loss: 0.7330\n",
      "[804/1762] D loss: 1.4046, G loss: 0.7663\n",
      "[884/1762] D loss: 1.4046, G loss: 0.7689\n",
      "[964/1762] D loss: 1.3977, G loss: 0.6125\n",
      "[1044/1762] D loss: 1.4201, G loss: 0.7218\n",
      "[1124/1762] D loss: 1.3307, G loss: 0.6148\n",
      "[1204/1762] D loss: 1.3957, G loss: 0.7608\n",
      "[1284/1762] D loss: 1.4430, G loss: 0.5417\n",
      "[1364/1762] D loss: 0.8409, G loss: 1.3484\n",
      "[1444/1762] D loss: 0.4433, G loss: 1.4965\n",
      "[1524/1762] D loss: 1.4143, G loss: 0.8030\n",
      "[1604/1762] D loss: 1.3890, G loss: 0.6732\n",
      "[1684/1762] D loss: 1.4430, G loss: 0.4918\n",
      "[1762/1762] D loss: 1.3969, G loss: 0.7999\n",
      "train error: \n",
      " D loss: 1.401780, G loss: 0.567368, D accuracy: 52.5%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.385159, G loss: 0.571872, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4063, G loss: 0.6061\n",
      "[84/1762] D loss: 0.2478, G loss: 1.9401\n",
      "[164/1762] D loss: 1.4940, G loss: 0.4541\n",
      "[244/1762] D loss: 1.2695, G loss: 0.9335\n",
      "[324/1762] D loss: 1.4083, G loss: 0.6056\n",
      "[404/1762] D loss: 1.5261, G loss: 1.2337\n",
      "[484/1762] D loss: 0.3593, G loss: 1.3319\n",
      "[564/1762] D loss: 1.4207, G loss: 0.8668\n",
      "[644/1762] D loss: 0.2530, G loss: 1.8072\n",
      "[724/1762] D loss: 1.4527, G loss: 0.9104\n",
      "[804/1762] D loss: 1.3611, G loss: 1.0933\n",
      "[884/1762] D loss: 1.4070, G loss: 0.7768\n",
      "[964/1762] D loss: 1.3988, G loss: 0.6402\n",
      "[1044/1762] D loss: 1.4012, G loss: 0.8312\n",
      "[1124/1762] D loss: 1.5820, G loss: 1.1074\n",
      "[1204/1762] D loss: 1.3956, G loss: 0.7735\n",
      "[1284/1762] D loss: 1.3896, G loss: 0.6305\n",
      "[1364/1762] D loss: 1.4006, G loss: 0.8066\n",
      "[1444/1762] D loss: 1.4189, G loss: 0.7676\n",
      "[1524/1762] D loss: 1.4993, G loss: 1.0656\n",
      "[1604/1762] D loss: 1.3941, G loss: 0.6724\n",
      "[1684/1762] D loss: 0.0400, G loss: 3.5998\n",
      "[1762/1762] D loss: 1.3606, G loss: 0.8419\n",
      "train error: \n",
      " D loss: 1.351468, G loss: 0.766408, D accuracy: 52.8%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.329323, G loss: 0.774012, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2041, G loss: 1.7437\n",
      "[84/1762] D loss: 1.3996, G loss: 0.6363\n",
      "[164/1762] D loss: 0.3130, G loss: 1.4747\n",
      "[244/1762] D loss: 0.1790, G loss: 2.0417\n",
      "[324/1762] D loss: 1.4015, G loss: 0.8155\n",
      "[404/1762] D loss: 1.3905, G loss: 0.7269\n",
      "[484/1762] D loss: 0.0475, G loss: 3.2906\n",
      "[564/1762] D loss: 1.4083, G loss: 0.6712\n",
      "[644/1762] D loss: 1.5549, G loss: 0.6196\n",
      "[724/1762] D loss: 0.2254, G loss: 1.8974\n",
      "[804/1762] D loss: 1.5715, G loss: 0.9891\n",
      "[884/1762] D loss: 1.3877, G loss: 0.7074\n",
      "[964/1762] D loss: 1.4398, G loss: 0.6450\n",
      "[1044/1762] D loss: 0.0355, G loss: 3.5573\n",
      "[1124/1762] D loss: 0.1845, G loss: 1.9876\n",
      "[1204/1762] D loss: 1.3684, G loss: 0.8077\n",
      "[1284/1762] D loss: 1.4510, G loss: 0.6491\n",
      "[1364/1762] D loss: 0.2835, G loss: 1.5344\n",
      "[1444/1762] D loss: 1.3044, G loss: 0.8108\n",
      "[1524/1762] D loss: 1.4713, G loss: 0.9149\n",
      "[1604/1762] D loss: 1.4001, G loss: 0.6081\n",
      "[1684/1762] D loss: 0.3310, G loss: 1.7450\n",
      "[1762/1762] D loss: 1.3994, G loss: 0.7669\n",
      "train error: \n",
      " D loss: 1.512949, G loss: 0.398710, D accuracy: 52.7%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.491133, G loss: 0.405604, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2812, G loss: 1.8613\n",
      "[84/1762] D loss: 1.4270, G loss: 0.5570\n",
      "[164/1762] D loss: 0.2857, G loss: 1.9124\n",
      "[244/1762] D loss: 1.5074, G loss: 0.8350\n",
      "[324/1762] D loss: 1.4085, G loss: 0.6885\n",
      "[404/1762] D loss: 1.4207, G loss: 0.6643\n",
      "[484/1762] D loss: 1.4491, G loss: 1.0151\n",
      "[564/1762] D loss: 1.4186, G loss: 0.8011\n",
      "[644/1762] D loss: 1.4848, G loss: 0.4209\n",
      "[724/1762] D loss: 1.4381, G loss: 0.8721\n",
      "[804/1762] D loss: 1.4221, G loss: 0.6042\n",
      "[884/1762] D loss: 0.1484, G loss: 2.1708\n",
      "[964/1762] D loss: 1.5621, G loss: 1.2462\n",
      "[1044/1762] D loss: 1.0469, G loss: 1.3219\n",
      "[1124/1762] D loss: 0.2418, G loss: 1.5719\n",
      "[1204/1762] D loss: 0.1547, G loss: 2.5153\n",
      "[1284/1762] D loss: 3.8670, G loss: 0.0705\n",
      "[1364/1762] D loss: 0.7886, G loss: 2.0231\n",
      "[1444/1762] D loss: 1.4741, G loss: 0.7806\n",
      "[1524/1762] D loss: 1.6339, G loss: 0.3705\n",
      "[1604/1762] D loss: 1.4202, G loss: 0.6388\n",
      "[1684/1762] D loss: 1.4159, G loss: 0.8593\n",
      "[1762/1762] D loss: 1.3880, G loss: 0.6764\n",
      "train error: \n",
      " D loss: 1.338937, G loss: 0.787884, D accuracy: 52.9%, cell accuracy: 99.9%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.313998, G loss: 0.822221, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4157, G loss: 0.5814\n",
      "[84/1762] D loss: 1.4480, G loss: 0.8760\n",
      "[164/1762] D loss: 1.3842, G loss: 0.7096\n",
      "[244/1762] D loss: 1.3895, G loss: 0.7062\n",
      "[324/1762] D loss: 1.4188, G loss: 0.5938\n",
      "[404/1762] D loss: 1.3997, G loss: 0.6130\n",
      "[484/1762] D loss: 1.3959, G loss: 0.7770\n",
      "[564/1762] D loss: 1.3969, G loss: 0.7225\n",
      "[644/1762] D loss: 1.2981, G loss: 1.0976\n",
      "[724/1762] D loss: 1.4601, G loss: 0.9654\n",
      "[804/1762] D loss: 0.4085, G loss: 1.4644\n",
      "[884/1762] D loss: 1.3879, G loss: 0.6779\n",
      "[964/1762] D loss: 1.3886, G loss: 0.6498\n",
      "[1044/1762] D loss: 1.8544, G loss: 0.2895\n",
      "[1124/1762] D loss: 0.9171, G loss: 1.2444\n",
      "[1204/1762] D loss: 0.7575, G loss: 1.1709\n",
      "[1284/1762] D loss: 1.3733, G loss: 0.6707\n",
      "[1364/1762] D loss: 1.3990, G loss: 0.6000\n",
      "[1444/1762] D loss: 1.3927, G loss: 0.6454\n",
      "[1524/1762] D loss: 1.5942, G loss: 0.4296\n",
      "[1604/1762] D loss: 1.4150, G loss: 0.7810\n",
      "[1684/1762] D loss: 1.4097, G loss: 0.6842\n",
      "[1762/1762] D loss: 0.2281, G loss: 1.7550\n",
      "train error: \n",
      " D loss: 1.437343, G loss: 0.478352, D accuracy: 51.4%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.427358, G loss: 0.481196, D accuracy: 51.2%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4133, G loss: 0.5809\n",
      "[84/1762] D loss: 1.3908, G loss: 0.6829\n",
      "[164/1762] D loss: 1.4028, G loss: 0.7679\n",
      "[244/1762] D loss: 1.4774, G loss: 0.9247\n",
      "[324/1762] D loss: 0.0856, G loss: 2.5302\n",
      "[404/1762] D loss: 1.5028, G loss: 0.4144\n",
      "[484/1762] D loss: 1.3955, G loss: 0.6541\n",
      "[564/1762] D loss: 1.4250, G loss: 0.6388\n",
      "[644/1762] D loss: 1.4159, G loss: 0.7768\n",
      "[724/1762] D loss: 1.3994, G loss: 0.6095\n",
      "[804/1762] D loss: 1.4122, G loss: 0.6062\n",
      "[884/1762] D loss: 1.3944, G loss: 0.7821\n",
      "[964/1762] D loss: 1.4251, G loss: 0.5052\n",
      "[1044/1762] D loss: 0.3249, G loss: 1.5333\n",
      "[1124/1762] D loss: 1.4155, G loss: 0.6031\n",
      "[1204/1762] D loss: 1.3920, G loss: 0.6778\n",
      "[1284/1762] D loss: 1.4014, G loss: 0.7174\n",
      "[1364/1762] D loss: 1.4657, G loss: 0.4994\n",
      "[1444/1762] D loss: 1.3999, G loss: 0.6290\n",
      "[1524/1762] D loss: 0.1911, G loss: 2.0171\n",
      "[1604/1762] D loss: 1.4040, G loss: 0.7341\n",
      "[1684/1762] D loss: 1.4006, G loss: 0.7312\n",
      "[1762/1762] D loss: 1.4533, G loss: 0.8900\n",
      "train error: \n",
      " D loss: 1.368501, G loss: 0.572930, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.349856, G loss: 0.584987, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2427, G loss: 1.5779\n",
      "[84/1762] D loss: 1.3940, G loss: 0.6576\n",
      "[164/1762] D loss: 1.3910, G loss: 0.6495\n",
      "[244/1762] D loss: 1.3969, G loss: 0.7016\n",
      "[324/1762] D loss: 1.3962, G loss: 0.6078\n",
      "[404/1762] D loss: 0.3100, G loss: 1.4325\n",
      "[484/1762] D loss: 1.4360, G loss: 0.5876\n",
      "[564/1762] D loss: 1.4133, G loss: 0.6841\n",
      "[644/1762] D loss: 1.3989, G loss: 0.8753\n",
      "[724/1762] D loss: 1.5008, G loss: 0.9934\n",
      "[804/1762] D loss: 1.4266, G loss: 0.8039\n",
      "[884/1762] D loss: 1.4149, G loss: 0.8314\n",
      "[964/1762] D loss: 1.3944, G loss: 0.7104\n",
      "[1044/1762] D loss: 1.3955, G loss: 0.7204\n",
      "[1124/1762] D loss: 1.3922, G loss: 0.7099\n",
      "[1204/1762] D loss: 0.7381, G loss: 1.5868\n",
      "[1284/1762] D loss: 1.4176, G loss: 0.6163\n",
      "[1364/1762] D loss: 1.4060, G loss: 1.2177\n",
      "[1444/1762] D loss: 1.4103, G loss: 0.7299\n",
      "[1524/1762] D loss: 0.1572, G loss: 2.1275\n",
      "[1604/1762] D loss: 1.5010, G loss: 1.0252\n",
      "[1684/1762] D loss: 1.4780, G loss: 0.9202\n",
      "[1762/1762] D loss: 1.3894, G loss: 0.6105\n",
      "train error: \n",
      " D loss: 1.373791, G loss: 0.540552, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 88.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.336007, G loss: 0.570773, D accuracy: 58.2%, cell accuracy: 99.7%, board accuracy: 82.3% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4166, G loss: 0.7009\n",
      "[84/1762] D loss: 1.2430, G loss: 0.8907\n",
      "[164/1762] D loss: 1.4030, G loss: 0.6693\n",
      "[244/1762] D loss: 1.4173, G loss: 0.6852\n",
      "[324/1762] D loss: 1.4035, G loss: 0.6392\n",
      "[404/1762] D loss: 1.5390, G loss: 0.3280\n",
      "[484/1762] D loss: 1.4069, G loss: 0.7206\n",
      "[564/1762] D loss: 1.3965, G loss: 0.8470\n",
      "[644/1762] D loss: 1.3887, G loss: 0.7749\n",
      "[724/1762] D loss: 1.4341, G loss: 0.8755\n",
      "[804/1762] D loss: 1.2099, G loss: 1.5102\n",
      "[884/1762] D loss: 1.4066, G loss: 0.7657\n",
      "[964/1762] D loss: 1.4315, G loss: 0.5636\n",
      "[1044/1762] D loss: 1.4138, G loss: 0.8399\n",
      "[1124/1762] D loss: 1.3540, G loss: 0.8466\n",
      "[1204/1762] D loss: 1.3867, G loss: 0.7238\n",
      "[1284/1762] D loss: 1.3917, G loss: 0.6194\n",
      "[1364/1762] D loss: 1.3944, G loss: 0.6959\n",
      "[1444/1762] D loss: 0.9005, G loss: 1.2659\n",
      "[1524/1762] D loss: 0.2637, G loss: 1.6539\n",
      "[1604/1762] D loss: 1.3977, G loss: 0.7365\n",
      "[1684/1762] D loss: 1.4362, G loss: 0.8427\n",
      "[1762/1762] D loss: 0.0204, G loss: 3.9529\n",
      "train error: \n",
      " D loss: 3.003387, G loss: 0.065161, D accuracy: 50.1%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "test error: \n",
      " D loss: 2.957908, G loss: 0.067800, D accuracy: 50.0%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1501, G loss: 2.0698\n",
      "[84/1762] D loss: 0.1910, G loss: 1.7629\n",
      "[164/1762] D loss: 1.3887, G loss: 0.5870\n",
      "[244/1762] D loss: 1.4003, G loss: 0.7787\n",
      "[324/1762] D loss: 1.0505, G loss: 2.1705\n",
      "[404/1762] D loss: 0.3236, G loss: 1.4524\n",
      "[484/1762] D loss: 0.1738, G loss: 2.1610\n",
      "[564/1762] D loss: 1.4017, G loss: 0.6608\n",
      "[644/1762] D loss: 1.4054, G loss: 0.7348\n",
      "[724/1762] D loss: 1.4286, G loss: 0.6731\n",
      "[804/1762] D loss: 0.1364, G loss: 2.2552\n",
      "[884/1762] D loss: 1.3185, G loss: 0.8406\n",
      "[964/1762] D loss: 1.2669, G loss: 0.8853\n",
      "[1044/1762] D loss: 1.6274, G loss: 1.1617\n",
      "[1124/1762] D loss: 0.2394, G loss: 2.9147\n",
      "[1204/1762] D loss: 1.3351, G loss: 0.6670\n",
      "[1284/1762] D loss: 1.6139, G loss: 0.3915\n",
      "[1364/1762] D loss: 1.4048, G loss: 0.6319\n",
      "[1444/1762] D loss: 1.3962, G loss: 0.6399\n",
      "[1524/1762] D loss: 1.2908, G loss: 0.8493\n",
      "[1604/1762] D loss: 1.4699, G loss: 0.5809\n",
      "[1684/1762] D loss: 0.2935, G loss: 1.9551\n",
      "[1762/1762] D loss: 1.4283, G loss: 0.8339\n",
      "train error: \n",
      " D loss: 1.378379, G loss: 0.872676, D accuracy: 52.2%, cell accuracy: 99.9%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.358107, G loss: 0.899822, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4787, G loss: 0.8211\n",
      "[84/1762] D loss: 1.4626, G loss: 0.4976\n",
      "[164/1762] D loss: 1.4059, G loss: 0.7937\n",
      "[244/1762] D loss: 1.4396, G loss: 0.8517\n",
      "[324/1762] D loss: 1.3972, G loss: 0.7156\n",
      "[404/1762] D loss: 1.3978, G loss: 0.6293\n",
      "[484/1762] D loss: 1.4400, G loss: 0.5360\n",
      "[564/1762] D loss: 1.4008, G loss: 0.6964\n",
      "[644/1762] D loss: 1.3975, G loss: 0.8073\n",
      "[724/1762] D loss: 1.4587, G loss: 0.5102\n",
      "[804/1762] D loss: 1.4265, G loss: 0.8186\n",
      "[884/1762] D loss: 1.4025, G loss: 0.7749\n",
      "[964/1762] D loss: 1.2723, G loss: 1.1712\n",
      "[1044/1762] D loss: 1.3919, G loss: 0.6858\n",
      "[1124/1762] D loss: 1.3999, G loss: 0.6535\n",
      "[1204/1762] D loss: 1.3931, G loss: 0.7558\n",
      "[1284/1762] D loss: 0.3515, G loss: 1.3102\n",
      "[1364/1762] D loss: 1.4008, G loss: 0.7519\n",
      "[1444/1762] D loss: 1.4203, G loss: 0.8355\n",
      "[1524/1762] D loss: 1.4504, G loss: 0.5238\n",
      "[1604/1762] D loss: 1.4531, G loss: 0.9439\n",
      "[1684/1762] D loss: 1.3905, G loss: 0.6868\n",
      "[1762/1762] D loss: 1.4352, G loss: 0.8836\n",
      "train error: \n",
      " D loss: 1.365245, G loss: 0.604888, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.342648, G loss: 0.616724, D accuracy: 55.6%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1892, G loss: 2.2607\n",
      "[84/1762] D loss: 1.3889, G loss: 0.7617\n",
      "[164/1762] D loss: 1.4095, G loss: 0.7688\n",
      "[244/1762] D loss: 1.5066, G loss: 0.5385\n",
      "[324/1762] D loss: 1.4166, G loss: 0.7978\n",
      "[404/1762] D loss: 0.1314, G loss: 2.2463\n",
      "[484/1762] D loss: 0.0731, G loss: 2.7647\n",
      "[564/1762] D loss: 0.1240, G loss: 2.0705\n",
      "[644/1762] D loss: 0.1217, G loss: 2.1767\n",
      "[724/1762] D loss: 0.1723, G loss: 2.2469\n",
      "[804/1762] D loss: 1.4046, G loss: 0.7774\n",
      "[884/1762] D loss: 1.4064, G loss: 0.7346\n",
      "[964/1762] D loss: 0.1975, G loss: 1.6956\n",
      "[1044/1762] D loss: 1.4399, G loss: 0.5037\n",
      "[1124/1762] D loss: 1.4085, G loss: 0.7948\n",
      "[1204/1762] D loss: 0.1149, G loss: 2.3489\n",
      "[1284/1762] D loss: 0.1753, G loss: 2.0827\n",
      "[1364/1762] D loss: 1.3926, G loss: 0.7510\n",
      "[1444/1762] D loss: 1.3890, G loss: 0.7023\n",
      "[1524/1762] D loss: 1.4299, G loss: 0.7559\n",
      "[1604/1762] D loss: 1.4275, G loss: 0.6590\n",
      "[1684/1762] D loss: 1.4260, G loss: 0.6022\n",
      "[1762/1762] D loss: 1.3872, G loss: 0.6927\n",
      "train error: \n",
      " D loss: 1.377594, G loss: 0.556175, D accuracy: 54.1%, cell accuracy: 99.9%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.340816, G loss: 0.600011, D accuracy: 55.7%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3881, G loss: 0.6393\n",
      "[84/1762] D loss: 1.4114, G loss: 0.6292\n",
      "[164/1762] D loss: 1.4039, G loss: 0.6220\n",
      "[244/1762] D loss: 1.3391, G loss: 0.7793\n",
      "[324/1762] D loss: 1.5134, G loss: 0.9316\n",
      "[404/1762] D loss: 1.3961, G loss: 0.6299\n",
      "[484/1762] D loss: 1.3966, G loss: 0.6884\n",
      "[564/1762] D loss: 1.4510, G loss: 0.8844\n",
      "[644/1762] D loss: 0.1452, G loss: 2.1624\n",
      "[724/1762] D loss: 1.4109, G loss: 0.5275\n",
      "[804/1762] D loss: 1.4215, G loss: 0.8015\n",
      "[884/1762] D loss: 0.1076, G loss: 2.4142\n",
      "[964/1762] D loss: 1.3878, G loss: 0.6955\n",
      "[1044/1762] D loss: 1.5724, G loss: 1.0763\n",
      "[1124/1762] D loss: 1.4025, G loss: 0.5838\n",
      "[1204/1762] D loss: 1.3970, G loss: 0.7166\n",
      "[1284/1762] D loss: 1.4300, G loss: 0.8442\n",
      "[1364/1762] D loss: 0.1564, G loss: 2.0389\n",
      "[1444/1762] D loss: 1.3941, G loss: 0.7056\n",
      "[1524/1762] D loss: 1.4028, G loss: 0.8069\n",
      "[1604/1762] D loss: 1.4100, G loss: 0.6035\n",
      "[1684/1762] D loss: 1.4137, G loss: 0.6370\n",
      "[1762/1762] D loss: 1.3919, G loss: 0.6616\n",
      "train error: \n",
      " D loss: 1.367116, G loss: 0.584600, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.333256, G loss: 0.642056, D accuracy: 55.6%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4117, G loss: 0.6956\n",
      "[84/1762] D loss: 1.3905, G loss: 0.8194\n",
      "[164/1762] D loss: 1.4261, G loss: 0.7730\n",
      "[244/1762] D loss: 1.3941, G loss: 0.6356\n",
      "[324/1762] D loss: 1.5388, G loss: 0.5314\n",
      "[404/1762] D loss: 1.4053, G loss: 0.8396\n",
      "[484/1762] D loss: 1.3945, G loss: 0.7458\n",
      "[564/1762] D loss: 1.4615, G loss: 0.9286\n",
      "[644/1762] D loss: 1.1973, G loss: 0.9424\n",
      "[724/1762] D loss: 1.4491, G loss: 0.8299\n",
      "[804/1762] D loss: 1.4279, G loss: 0.6537\n",
      "[884/1762] D loss: 1.4351, G loss: 0.5489\n",
      "[964/1762] D loss: 0.0727, G loss: 2.7029\n",
      "[1044/1762] D loss: 1.4295, G loss: 0.6600\n",
      "[1124/1762] D loss: 1.2124, G loss: 0.9193\n",
      "[1204/1762] D loss: 1.3955, G loss: 0.6295\n",
      "[1284/1762] D loss: 1.3321, G loss: 0.9290\n",
      "[1364/1762] D loss: 1.3759, G loss: 0.6783\n",
      "[1444/1762] D loss: 1.4363, G loss: 0.4905\n",
      "[1524/1762] D loss: 1.4104, G loss: 0.7285\n",
      "[1604/1762] D loss: 1.3952, G loss: 0.7166\n",
      "[1684/1762] D loss: 0.0927, G loss: 2.4866\n",
      "[1762/1762] D loss: 1.3881, G loss: 0.6684\n",
      "train error: \n",
      " D loss: 1.350283, G loss: 0.799669, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.332426, G loss: 0.809012, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4014, G loss: 0.7086\n",
      "[84/1762] D loss: 1.4286, G loss: 0.6003\n",
      "[164/1762] D loss: 1.3986, G loss: 0.6839\n",
      "[244/1762] D loss: 1.4310, G loss: 0.6074\n",
      "[324/1762] D loss: 1.3989, G loss: 0.8578\n",
      "[404/1762] D loss: 1.3974, G loss: 0.7230\n",
      "[484/1762] D loss: 0.0685, G loss: 2.6308\n",
      "[564/1762] D loss: 1.3277, G loss: 0.9005\n",
      "[644/1762] D loss: 1.3886, G loss: 0.6858\n",
      "[724/1762] D loss: 1.4255, G loss: 0.8173\n",
      "[804/1762] D loss: 1.4002, G loss: 0.7909\n",
      "[884/1762] D loss: 1.3985, G loss: 0.8240\n",
      "[964/1762] D loss: 1.4671, G loss: 0.4432\n",
      "[1044/1762] D loss: 0.0835, G loss: 2.8800\n",
      "[1124/1762] D loss: 1.4582, G loss: 0.9413\n",
      "[1204/1762] D loss: 1.5710, G loss: 0.4977\n",
      "[1284/1762] D loss: 0.0894, G loss: 2.5693\n",
      "[1364/1762] D loss: 1.4136, G loss: 0.8755\n",
      "[1444/1762] D loss: 0.1280, G loss: 2.2936\n",
      "[1524/1762] D loss: 1.4198, G loss: 0.9041\n",
      "[1604/1762] D loss: 1.4388, G loss: 0.8819\n",
      "[1684/1762] D loss: 0.0691, G loss: 2.8175\n",
      "[1762/1762] D loss: 1.3995, G loss: 0.7550\n",
      "train error: \n",
      " D loss: 1.450485, G loss: 0.447982, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.429349, G loss: 0.465228, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3958, G loss: 0.6864\n",
      "[84/1762] D loss: 1.3933, G loss: 0.6788\n",
      "[164/1762] D loss: 1.3954, G loss: 0.7489\n",
      "[244/1762] D loss: 1.3942, G loss: 0.8090\n",
      "[324/1762] D loss: 1.4167, G loss: 0.7713\n",
      "[404/1762] D loss: 1.3887, G loss: 0.6443\n",
      "[484/1762] D loss: 1.4692, G loss: 0.9066\n",
      "[564/1762] D loss: 1.3940, G loss: 0.7510\n",
      "[644/1762] D loss: 1.4447, G loss: 0.9080\n",
      "[724/1762] D loss: 1.4126, G loss: 0.8120\n",
      "[804/1762] D loss: 1.4045, G loss: 0.7584\n",
      "[884/1762] D loss: 0.0816, G loss: 2.6622\n",
      "[964/1762] D loss: 1.4057, G loss: 0.6458\n",
      "[1044/1762] D loss: 1.4058, G loss: 0.7392\n",
      "[1124/1762] D loss: 1.3938, G loss: 0.7348\n",
      "[1204/1762] D loss: 1.3952, G loss: 0.7226\n",
      "[1284/1762] D loss: 1.4161, G loss: 0.6741\n",
      "[1364/1762] D loss: 1.4835, G loss: 0.5318\n",
      "[1444/1762] D loss: 1.3975, G loss: 0.5758\n",
      "[1524/1762] D loss: 1.3950, G loss: 0.7387\n",
      "[1604/1762] D loss: 1.4008, G loss: 0.7109\n",
      "[1684/1762] D loss: 1.5387, G loss: 0.4798\n",
      "[1762/1762] D loss: 1.4930, G loss: 1.1098\n",
      "train error: \n",
      " D loss: 1.339273, G loss: 0.692326, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.320632, G loss: 0.696787, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4857, G loss: 0.9772\n",
      "[84/1762] D loss: 1.2115, G loss: 1.3547\n",
      "[164/1762] D loss: 1.7845, G loss: 2.0643\n",
      "[244/1762] D loss: 0.1112, G loss: 2.6333\n",
      "[324/1762] D loss: 1.4897, G loss: 0.3800\n",
      "[404/1762] D loss: 0.0944, G loss: 2.4626\n",
      "[484/1762] D loss: 1.4596, G loss: 0.8425\n",
      "[564/1762] D loss: 1.3030, G loss: 1.0456\n",
      "[644/1762] D loss: 1.4263, G loss: 0.5075\n",
      "[724/1762] D loss: 1.3629, G loss: 0.5818\n",
      "[804/1762] D loss: 0.0966, G loss: 2.6826\n",
      "[884/1762] D loss: 0.0726, G loss: 2.9190\n",
      "[964/1762] D loss: 1.4751, G loss: 0.9722\n",
      "[1044/1762] D loss: 1.4242, G loss: 0.7339\n",
      "[1124/1762] D loss: 1.3944, G loss: 0.6599\n",
      "[1204/1762] D loss: 1.3921, G loss: 0.6659\n",
      "[1284/1762] D loss: 1.4167, G loss: 0.8465\n",
      "[1364/1762] D loss: 0.0408, G loss: 3.2702\n",
      "[1444/1762] D loss: 1.3965, G loss: 0.6404\n",
      "[1524/1762] D loss: 1.4095, G loss: 0.6050\n",
      "[1604/1762] D loss: 0.0655, G loss: 2.9340\n",
      "[1684/1762] D loss: 1.3981, G loss: 0.6951\n",
      "[1762/1762] D loss: 1.3904, G loss: 0.6708\n",
      "train error: \n",
      " D loss: 1.481203, G loss: 0.413089, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.460314, G loss: 0.424744, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4029, G loss: 0.7256\n",
      "[84/1762] D loss: 1.4698, G loss: 0.4876\n",
      "[164/1762] D loss: 0.0464, G loss: 3.4050\n",
      "[244/1762] D loss: 1.4548, G loss: 0.8804\n",
      "[324/1762] D loss: 1.4586, G loss: 0.8616\n",
      "[404/1762] D loss: 1.3991, G loss: 0.6854\n",
      "[484/1762] D loss: 1.4015, G loss: 0.6466\n",
      "[564/1762] D loss: 1.4008, G loss: 0.6201\n",
      "[644/1762] D loss: 0.1119, G loss: 2.4691\n",
      "[724/1762] D loss: 1.4285, G loss: 0.5514\n",
      "[804/1762] D loss: 1.3999, G loss: 0.8806\n",
      "[884/1762] D loss: 1.4267, G loss: 0.5934\n",
      "[964/1762] D loss: 1.4029, G loss: 0.7976\n",
      "[1044/1762] D loss: 1.4147, G loss: 0.7366\n",
      "[1124/1762] D loss: 1.4183, G loss: 0.8406\n",
      "[1204/1762] D loss: 1.4590, G loss: 0.8988\n",
      "[1284/1762] D loss: 1.3953, G loss: 0.6298\n",
      "[1364/1762] D loss: 1.3957, G loss: 0.6737\n",
      "[1444/1762] D loss: 1.4051, G loss: 0.7093\n",
      "[1524/1762] D loss: 1.4341, G loss: 0.5107\n",
      "[1604/1762] D loss: 0.0065, G loss: 5.0973\n",
      "[1684/1762] D loss: 1.4105, G loss: 0.5552\n",
      "[1762/1762] D loss: 1.5001, G loss: 0.9931\n",
      "train error: \n",
      " D loss: 2.813073, G loss: 0.071767, D accuracy: 50.1%, cell accuracy: 99.9%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 2.808042, G loss: 0.073052, D accuracy: 50.1%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4836, G loss: 0.6966\n",
      "[84/1762] D loss: 0.1069, G loss: 2.5192\n",
      "[164/1762] D loss: 1.3941, G loss: 0.8105\n",
      "[244/1762] D loss: 1.4007, G loss: 0.6706\n",
      "[324/1762] D loss: 1.3869, G loss: 0.8022\n",
      "[404/1762] D loss: 1.3999, G loss: 0.6403\n",
      "[484/1762] D loss: 1.6054, G loss: 0.9954\n",
      "[564/1762] D loss: 1.3919, G loss: 1.7071\n",
      "[644/1762] D loss: 1.3962, G loss: 0.6780\n",
      "[724/1762] D loss: 0.1307, G loss: 2.2660\n",
      "[804/1762] D loss: 1.3888, G loss: 0.6865\n",
      "[884/1762] D loss: 1.3944, G loss: 0.7671\n",
      "[964/1762] D loss: 1.3914, G loss: 0.6622\n",
      "[1044/1762] D loss: 1.4037, G loss: 0.5898\n",
      "[1124/1762] D loss: 0.0722, G loss: 2.9846\n",
      "[1204/1762] D loss: 1.4078, G loss: 0.6690\n",
      "[1284/1762] D loss: 1.3927, G loss: 0.5871\n",
      "[1364/1762] D loss: 0.0068, G loss: 5.1375\n",
      "[1444/1762] D loss: 1.3962, G loss: 0.7537\n",
      "[1524/1762] D loss: 1.4055, G loss: 0.5178\n",
      "[1604/1762] D loss: 0.1536, G loss: 2.3845\n",
      "[1684/1762] D loss: 1.3893, G loss: 0.6447\n",
      "[1762/1762] D loss: 1.4807, G loss: 0.5101\n",
      "train error: \n",
      " D loss: 1.524900, G loss: 0.380912, D accuracy: 50.9%, cell accuracy: 99.9%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.505311, G loss: 0.393320, D accuracy: 51.1%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0999, G loss: 2.5787\n",
      "[84/1762] D loss: 0.1172, G loss: 2.4178\n",
      "[164/1762] D loss: 1.4861, G loss: 0.4830\n",
      "[244/1762] D loss: 1.3945, G loss: 0.8352\n",
      "[324/1762] D loss: 1.4904, G loss: 0.9721\n",
      "[404/1762] D loss: 0.0886, G loss: 2.5348\n",
      "[484/1762] D loss: 1.4022, G loss: 0.6197\n",
      "[564/1762] D loss: 1.4032, G loss: 0.6860\n",
      "[644/1762] D loss: 1.4052, G loss: 0.6912\n",
      "[724/1762] D loss: 0.2395, G loss: 2.0834\n",
      "[804/1762] D loss: 1.3902, G loss: 0.7011\n",
      "[884/1762] D loss: 1.7513, G loss: 0.6762\n",
      "[964/1762] D loss: 0.0838, G loss: 2.8577\n",
      "[1044/1762] D loss: 1.3841, G loss: 0.6413\n",
      "[1124/1762] D loss: 1.4264, G loss: 0.7558\n",
      "[1204/1762] D loss: 1.3970, G loss: 0.5854\n",
      "[1284/1762] D loss: 0.0773, G loss: 2.7552\n",
      "[1364/1762] D loss: 1.4142, G loss: 0.5988\n",
      "[1444/1762] D loss: 0.2464, G loss: 1.7652\n",
      "[1524/1762] D loss: 1.4317, G loss: 0.7591\n",
      "[1604/1762] D loss: 0.0076, G loss: 5.1979\n",
      "[1684/1762] D loss: 0.1047, G loss: 2.6403\n",
      "[1762/1762] D loss: 0.0083, G loss: 5.1416\n",
      "train error: \n",
      " D loss: 2.558675, G loss: 0.116829, D accuracy: 50.2%, cell accuracy: 99.8%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 2.502753, G loss: 0.137904, D accuracy: 50.6%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5953, G loss: 0.9514\n",
      "[84/1762] D loss: 1.4072, G loss: 0.6096\n",
      "[164/1762] D loss: 0.0505, G loss: 3.4013\n",
      "[244/1762] D loss: 1.3940, G loss: 0.6500\n",
      "[324/1762] D loss: 1.4135, G loss: 0.5130\n",
      "[404/1762] D loss: 0.0060, G loss: 5.1559\n",
      "[484/1762] D loss: 1.3935, G loss: 0.7217\n",
      "[564/1762] D loss: 1.4098, G loss: 0.7556\n",
      "[644/1762] D loss: 1.3858, G loss: 0.6827\n",
      "[724/1762] D loss: 1.3990, G loss: 0.7665\n",
      "[804/1762] D loss: 1.3882, G loss: 0.6948\n",
      "[884/1762] D loss: 1.3890, G loss: 0.7443\n",
      "[964/1762] D loss: 1.4229, G loss: 0.8140\n",
      "[1044/1762] D loss: 0.0474, G loss: 3.1109\n",
      "[1124/1762] D loss: 1.3981, G loss: 0.8054\n",
      "[1204/1762] D loss: 0.0029, G loss: 6.0082\n",
      "[1284/1762] D loss: 1.4287, G loss: 0.7782\n",
      "[1364/1762] D loss: 1.3903, G loss: 0.6372\n",
      "[1444/1762] D loss: 1.4009, G loss: 0.7631\n",
      "[1524/1762] D loss: 1.3944, G loss: 0.7243\n",
      "[1604/1762] D loss: 0.0429, G loss: 3.2036\n",
      "[1684/1762] D loss: 0.1995, G loss: 1.8590\n",
      "[1762/1762] D loss: 1.4500, G loss: 0.9603\n",
      "train error: \n",
      " D loss: 1.889748, G loss: 0.222095, D accuracy: 50.9%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.855448, G loss: 0.242882, D accuracy: 51.2%, cell accuracy: 99.7%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4215, G loss: 0.8161\n",
      "[84/1762] D loss: 0.0492, G loss: 3.1605\n",
      "[164/1762] D loss: 1.3976, G loss: 0.5962\n",
      "[244/1762] D loss: 1.4201, G loss: 0.9327\n",
      "[324/1762] D loss: 1.3907, G loss: 0.6015\n",
      "[404/1762] D loss: 0.0736, G loss: 2.7163\n",
      "[484/1762] D loss: 0.0350, G loss: 3.5290\n",
      "[564/1762] D loss: 0.0774, G loss: 2.6727\n",
      "[644/1762] D loss: 0.0834, G loss: 2.6905\n",
      "[724/1762] D loss: 1.3911, G loss: 0.6495\n",
      "[804/1762] D loss: 1.3979, G loss: 0.7903\n",
      "[884/1762] D loss: 0.0760, G loss: 2.5697\n",
      "[964/1762] D loss: 1.3918, G loss: 0.7276\n",
      "[1044/1762] D loss: 0.0501, G loss: 3.2594\n",
      "[1124/1762] D loss: 1.3980, G loss: 0.7397\n",
      "[1204/1762] D loss: 1.3922, G loss: 0.7750\n",
      "[1284/1762] D loss: 1.3895, G loss: 0.6972\n",
      "[1364/1762] D loss: 0.0033, G loss: 5.9514\n",
      "[1444/1762] D loss: 1.3960, G loss: 0.7550\n",
      "[1524/1762] D loss: 0.0500, G loss: 2.9788\n",
      "[1604/1762] D loss: 1.3945, G loss: 0.6193\n",
      "[1684/1762] D loss: 1.4061, G loss: 0.6823\n",
      "[1762/1762] D loss: 1.4042, G loss: 0.6080\n",
      "train error: \n",
      " D loss: 1.704791, G loss: 0.271103, D accuracy: 50.1%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.688994, G loss: 0.274532, D accuracy: 50.0%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4498, G loss: 0.5821\n",
      "[84/1762] D loss: 1.5026, G loss: 0.5330\n",
      "[164/1762] D loss: 1.4137, G loss: 0.6731\n",
      "[244/1762] D loss: 0.0779, G loss: 2.7600\n",
      "[324/1762] D loss: 1.4136, G loss: 0.8518\n",
      "[404/1762] D loss: 1.4009, G loss: 0.6427\n",
      "[484/1762] D loss: 1.4496, G loss: 0.8597\n",
      "[564/1762] D loss: 1.4434, G loss: 0.5389\n",
      "[644/1762] D loss: 1.4510, G loss: 0.5113\n",
      "[724/1762] D loss: 0.0188, G loss: 4.9057\n",
      "[804/1762] D loss: 1.4064, G loss: 0.6680\n",
      "[884/1762] D loss: 1.4335, G loss: 0.5756\n",
      "[964/1762] D loss: 1.5097, G loss: 0.9831\n",
      "[1044/1762] D loss: 1.5792, G loss: 0.3162\n",
      "[1124/1762] D loss: 0.0065, G loss: 5.3369\n",
      "[1204/1762] D loss: 1.4158, G loss: 0.7428\n",
      "[1284/1762] D loss: 1.3935, G loss: 0.6302\n",
      "[1364/1762] D loss: 1.4618, G loss: 0.9184\n",
      "[1444/1762] D loss: 0.0925, G loss: 2.6948\n",
      "[1524/1762] D loss: 1.4111, G loss: 0.7786\n",
      "[1604/1762] D loss: 1.4011, G loss: 0.6051\n",
      "[1684/1762] D loss: 0.0814, G loss: 2.6541\n",
      "[1762/1762] D loss: 1.5484, G loss: 1.0208\n",
      "train error: \n",
      " D loss: 1.491642, G loss: 0.449419, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 90.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.464327, G loss: 0.468299, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.6580, G loss: 0.9651\n",
      "[84/1762] D loss: 1.4035, G loss: 0.7654\n",
      "[164/1762] D loss: 0.0346, G loss: 3.7241\n",
      "[244/1762] D loss: 1.3990, G loss: 0.6972\n",
      "[324/1762] D loss: 0.0769, G loss: 2.8380\n",
      "[404/1762] D loss: 1.4330, G loss: 0.5104\n",
      "[484/1762] D loss: 1.4362, G loss: 0.7203\n",
      "[564/1762] D loss: 1.3870, G loss: 0.8731\n",
      "[644/1762] D loss: 1.4875, G loss: 1.0409\n",
      "[724/1762] D loss: 0.1180, G loss: 3.6913\n",
      "[804/1762] D loss: 1.4007, G loss: 0.8071\n",
      "[884/1762] D loss: 1.4561, G loss: 0.5055\n",
      "[964/1762] D loss: 1.3962, G loss: 0.6557\n",
      "[1044/1762] D loss: 1.3839, G loss: 0.8908\n",
      "[1124/1762] D loss: 1.3959, G loss: 0.7582\n",
      "[1204/1762] D loss: 1.3936, G loss: 0.6289\n",
      "[1284/1762] D loss: 1.4447, G loss: 0.7865\n",
      "[1364/1762] D loss: 0.0835, G loss: 2.5641\n",
      "[1444/1762] D loss: 1.4065, G loss: 0.7440\n",
      "[1524/1762] D loss: 1.4377, G loss: 0.5193\n",
      "[1604/1762] D loss: 1.4258, G loss: 0.9174\n",
      "[1684/1762] D loss: 1.1057, G loss: 1.8316\n",
      "[1762/1762] D loss: 1.4601, G loss: 0.5260\n",
      "train error: \n",
      " D loss: 1.431520, G loss: 0.498807, D accuracy: 51.7%, cell accuracy: 99.8%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.419238, G loss: 0.511031, D accuracy: 51.4%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1824, G loss: 2.2827\n",
      "[84/1762] D loss: 1.4021, G loss: 0.6091\n",
      "[164/1762] D loss: 1.4133, G loss: 0.7553\n",
      "[244/1762] D loss: 1.3900, G loss: 0.7104\n",
      "[324/1762] D loss: 1.3960, G loss: 0.7481\n",
      "[404/1762] D loss: 0.2461, G loss: 1.8568\n",
      "[484/1762] D loss: 1.4098, G loss: 0.7791\n",
      "[564/1762] D loss: 1.3942, G loss: 0.6428\n",
      "[644/1762] D loss: 1.4142, G loss: 0.8849\n",
      "[724/1762] D loss: 1.4041, G loss: 0.5926\n",
      "[804/1762] D loss: 1.5192, G loss: 0.8077\n",
      "[884/1762] D loss: 1.4599, G loss: 0.5376\n",
      "[964/1762] D loss: 1.4360, G loss: 0.6706\n",
      "[1044/1762] D loss: 1.4569, G loss: 0.8881\n",
      "[1124/1762] D loss: 1.3981, G loss: 0.7533\n",
      "[1204/1762] D loss: 1.3905, G loss: 0.6382\n",
      "[1284/1762] D loss: 0.0426, G loss: 4.0468\n",
      "[1364/1762] D loss: 0.0793, G loss: 2.7342\n",
      "[1444/1762] D loss: 1.3891, G loss: 0.7066\n",
      "[1524/1762] D loss: 1.4297, G loss: 0.6419\n",
      "[1604/1762] D loss: 1.4047, G loss: 0.6939\n",
      "[1684/1762] D loss: 1.5130, G loss: 0.9619\n",
      "[1762/1762] D loss: 1.8232, G loss: 1.0250\n",
      "train error: \n",
      " D loss: 1.367963, G loss: 0.641815, D accuracy: 52.4%, cell accuracy: 99.8%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.354957, G loss: 0.655040, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3996, G loss: 0.5052\n",
      "[84/1762] D loss: 1.4143, G loss: 0.8045\n",
      "[164/1762] D loss: 1.3899, G loss: 0.6908\n",
      "[244/1762] D loss: 0.1181, G loss: 2.5081\n",
      "[324/1762] D loss: 1.4138, G loss: 0.5493\n",
      "[404/1762] D loss: 0.0729, G loss: 3.0567\n",
      "[484/1762] D loss: 0.1028, G loss: 2.5691\n",
      "[564/1762] D loss: 1.6364, G loss: 0.8964\n",
      "[644/1762] D loss: 1.6848, G loss: 1.0663\n",
      "[724/1762] D loss: 1.4554, G loss: 0.8825\n",
      "[804/1762] D loss: 0.1579, G loss: 2.1107\n",
      "[884/1762] D loss: 1.4101, G loss: 0.8336\n",
      "[964/1762] D loss: 1.3870, G loss: 0.6984\n",
      "[1044/1762] D loss: 1.3940, G loss: 0.6514\n",
      "[1124/1762] D loss: 1.3884, G loss: 0.7577\n",
      "[1204/1762] D loss: 1.4117, G loss: 0.5692\n",
      "[1284/1762] D loss: 1.2821, G loss: 1.0687\n",
      "[1364/1762] D loss: 0.0813, G loss: 2.7457\n",
      "[1444/1762] D loss: 1.4065, G loss: 0.8636\n",
      "[1524/1762] D loss: 1.4000, G loss: 0.7845\n",
      "[1604/1762] D loss: 0.0417, G loss: 3.3520\n",
      "[1684/1762] D loss: 1.3913, G loss: 0.6865\n",
      "[1762/1762] D loss: 1.3901, G loss: 0.7085\n",
      "train error: \n",
      " D loss: 1.399225, G loss: 0.528677, D accuracy: 53.4%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.381881, G loss: 0.538467, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3937, G loss: 0.7176\n",
      "[84/1762] D loss: 1.3979, G loss: 0.6988\n",
      "[164/1762] D loss: 1.4186, G loss: 0.7817\n",
      "[244/1762] D loss: 1.4073, G loss: 0.5793\n",
      "[324/1762] D loss: 1.4363, G loss: 0.8774\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6888\n",
      "[484/1762] D loss: 1.4120, G loss: 0.6383\n",
      "[564/1762] D loss: 1.4448, G loss: 0.5422\n",
      "[644/1762] D loss: 1.4053, G loss: 0.6654\n",
      "[724/1762] D loss: 1.3900, G loss: 0.6928\n",
      "[804/1762] D loss: 1.4011, G loss: 0.7327\n",
      "[884/1762] D loss: 1.4714, G loss: 0.5160\n",
      "[964/1762] D loss: 1.3919, G loss: 0.7191\n",
      "[1044/1762] D loss: 1.4621, G loss: 0.9210\n",
      "[1124/1762] D loss: 1.2057, G loss: 0.8864\n",
      "[1204/1762] D loss: 1.3997, G loss: 0.7389\n",
      "[1284/1762] D loss: 0.0311, G loss: 3.7351\n",
      "[1364/1762] D loss: 1.4002, G loss: 0.7273\n",
      "[1444/1762] D loss: 1.3981, G loss: 0.6998\n",
      "[1524/1762] D loss: 1.3906, G loss: 0.7103\n",
      "[1604/1762] D loss: 1.3962, G loss: 0.7083\n",
      "[1684/1762] D loss: 1.4014, G loss: 0.6280\n",
      "[1762/1762] D loss: 1.5408, G loss: 0.5803\n",
      "train error: \n",
      " D loss: 3.346905, G loss: 3.744439, D accuracy: 52.7%, cell accuracy: 99.7%, board accuracy: 84.7% \n",
      "\n",
      "test error: \n",
      " D loss: 3.315824, G loss: 3.824801, D accuracy: 53.3%, cell accuracy: 99.6%, board accuracy: 80.7% \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4320, G loss: 0.9801\n",
      "[84/1762] D loss: 0.1962, G loss: 2.1840\n",
      "[164/1762] D loss: 0.2672, G loss: 1.5972\n",
      "[244/1762] D loss: 1.6576, G loss: 1.0365\n",
      "[324/1762] D loss: 1.4500, G loss: 1.0941\n",
      "[404/1762] D loss: 1.5070, G loss: 0.9678\n",
      "[484/1762] D loss: 1.3991, G loss: 0.6256\n",
      "[564/1762] D loss: 0.2346, G loss: 1.5729\n",
      "[644/1762] D loss: 0.1159, G loss: 2.1819\n",
      "[724/1762] D loss: 1.4026, G loss: 0.8077\n",
      "[804/1762] D loss: 0.0400, G loss: 3.4839\n",
      "[884/1762] D loss: 0.0782, G loss: 2.8871\n",
      "[964/1762] D loss: 0.3459, G loss: 1.3256\n",
      "[1044/1762] D loss: 1.3955, G loss: 0.7653\n",
      "[1124/1762] D loss: 1.3936, G loss: 0.7129\n",
      "[1204/1762] D loss: 0.0399, G loss: 3.5288\n",
      "[1284/1762] D loss: 1.4784, G loss: 0.8732\n",
      "[1364/1762] D loss: 1.4170, G loss: 0.5069\n",
      "[1444/1762] D loss: 1.4200, G loss: 0.5157\n",
      "[1524/1762] D loss: 1.4000, G loss: 0.6192\n",
      "[1604/1762] D loss: 1.4298, G loss: 0.8840\n",
      "[1684/1762] D loss: 1.4097, G loss: 0.5652\n",
      "[1762/1762] D loss: 1.3866, G loss: 0.7201\n",
      "train error: \n",
      " D loss: 1.518117, G loss: 0.387047, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.506844, G loss: 0.387393, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0474, G loss: 3.4032\n",
      "[84/1762] D loss: 1.3875, G loss: 0.6902\n",
      "[164/1762] D loss: 1.4023, G loss: 0.8317\n",
      "[244/1762] D loss: 1.3956, G loss: 0.7123\n",
      "[324/1762] D loss: 0.0471, G loss: 3.1560\n",
      "[404/1762] D loss: 1.3954, G loss: 0.6812\n",
      "[484/1762] D loss: 1.3971, G loss: 0.7340\n",
      "[564/1762] D loss: 1.4019, G loss: 0.5852\n",
      "[644/1762] D loss: 0.0684, G loss: 3.1380\n",
      "[724/1762] D loss: 1.3940, G loss: 0.7760\n",
      "[804/1762] D loss: 1.3948, G loss: 0.7002\n",
      "[884/1762] D loss: 1.3927, G loss: 0.6749\n",
      "[964/1762] D loss: 1.3962, G loss: 0.6245\n",
      "[1044/1762] D loss: 1.3897, G loss: 0.7278\n",
      "[1124/1762] D loss: 0.0658, G loss: 3.1932\n",
      "[1204/1762] D loss: 1.3919, G loss: 0.6939\n",
      "[1284/1762] D loss: 1.5662, G loss: 0.9694\n",
      "[1364/1762] D loss: 1.4013, G loss: 0.6452\n",
      "[1444/1762] D loss: 1.3987, G loss: 0.6513\n",
      "[1524/1762] D loss: 1.5598, G loss: 1.0136\n",
      "[1604/1762] D loss: 1.3936, G loss: 0.6349\n",
      "[1684/1762] D loss: 0.0053, G loss: 5.9113\n",
      "[1762/1762] D loss: 0.0007, G loss: 7.5192\n",
      "train error: \n",
      " D loss: 2.790143, G loss: 0.090050, D accuracy: 50.6%, cell accuracy: 99.8%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.746433, G loss: 0.105627, D accuracy: 50.9%, cell accuracy: 99.7%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6867\n",
      "[84/1762] D loss: 0.1493, G loss: 2.7719\n",
      "[164/1762] D loss: 1.4136, G loss: 0.7904\n",
      "[244/1762] D loss: 1.4101, G loss: 0.5855\n",
      "[324/1762] D loss: 1.3953, G loss: 0.7384\n",
      "[404/1762] D loss: 1.3973, G loss: 0.7748\n",
      "[484/1762] D loss: 1.4431, G loss: 0.8772\n",
      "[564/1762] D loss: 0.1392, G loss: 2.5548\n",
      "[644/1762] D loss: 0.0564, G loss: 3.8552\n",
      "[724/1762] D loss: 0.0523, G loss: 3.1257\n",
      "[804/1762] D loss: 0.0343, G loss: 3.6494\n",
      "[884/1762] D loss: 1.4215, G loss: 0.5207\n",
      "[964/1762] D loss: 1.3943, G loss: 0.6719\n",
      "[1044/1762] D loss: 1.3906, G loss: 0.7972\n",
      "[1124/1762] D loss: 1.4004, G loss: 0.6092\n",
      "[1204/1762] D loss: 1.4154, G loss: 0.5276\n",
      "[1284/1762] D loss: 1.4259, G loss: 0.8082\n",
      "[1364/1762] D loss: 0.0529, G loss: 3.2189\n",
      "[1444/1762] D loss: 0.0291, G loss: 3.9092\n",
      "[1524/1762] D loss: 1.4153, G loss: 0.7564\n",
      "[1604/1762] D loss: 1.4025, G loss: 0.5621\n",
      "[1684/1762] D loss: 1.4290, G loss: 0.5857\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6674\n",
      "train error: \n",
      " D loss: 1.730924, G loss: 0.303278, D accuracy: 48.7%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.724784, G loss: 0.300376, D accuracy: 48.9%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0644, G loss: 3.0504\n",
      "[84/1762] D loss: 1.3948, G loss: 0.6737\n",
      "[164/1762] D loss: 1.3868, G loss: 0.6814\n",
      "[244/1762] D loss: 0.0215, G loss: 4.2947\n",
      "[324/1762] D loss: 1.3885, G loss: 0.6878\n",
      "[404/1762] D loss: 1.5501, G loss: 0.4259\n",
      "[484/1762] D loss: 0.0356, G loss: 3.8459\n",
      "[564/1762] D loss: 1.3975, G loss: 0.5805\n",
      "[644/1762] D loss: 1.4117, G loss: 0.6057\n",
      "[724/1762] D loss: 1.3880, G loss: 0.6942\n",
      "[804/1762] D loss: 0.0443, G loss: 3.2375\n",
      "[884/1762] D loss: 1.3912, G loss: 0.7634\n",
      "[964/1762] D loss: 1.4154, G loss: 0.8267\n",
      "[1044/1762] D loss: 1.3932, G loss: 0.6221\n",
      "[1124/1762] D loss: 0.0200, G loss: 4.0952\n",
      "[1204/1762] D loss: 0.0291, G loss: 3.9176\n",
      "[1284/1762] D loss: 0.0238, G loss: 4.0728\n",
      "[1364/1762] D loss: 1.4215, G loss: 0.5293\n",
      "[1444/1762] D loss: 1.3914, G loss: 0.7493\n",
      "[1524/1762] D loss: 1.3973, G loss: 0.7684\n",
      "[1604/1762] D loss: 1.4055, G loss: 0.5634\n",
      "[1684/1762] D loss: 1.4024, G loss: 0.7856\n",
      "[1762/1762] D loss: 1.3074, G loss: 0.8981\n",
      "train error: \n",
      " D loss: 1.494575, G loss: 0.561885, D accuracy: 51.5%, cell accuracy: 99.8%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.499440, G loss: 0.571951, D accuracy: 51.9%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3881, G loss: 0.6860\n",
      "[84/1762] D loss: 1.4092, G loss: 0.5841\n",
      "[164/1762] D loss: 0.0623, G loss: 2.9391\n",
      "[244/1762] D loss: 1.4231, G loss: 0.8489\n",
      "[324/1762] D loss: 1.4164, G loss: 0.6079\n",
      "[404/1762] D loss: 0.0176, G loss: 4.3058\n",
      "[484/1762] D loss: 1.3917, G loss: 0.7386\n",
      "[564/1762] D loss: 1.4138, G loss: 0.8192\n",
      "[644/1762] D loss: 1.4287, G loss: 0.5480\n",
      "[724/1762] D loss: 1.3958, G loss: 0.7177\n",
      "[804/1762] D loss: 1.4076, G loss: 0.5573\n",
      "[884/1762] D loss: 1.3957, G loss: 0.6913\n",
      "[964/1762] D loss: 1.0308, G loss: 1.2875\n",
      "[1044/1762] D loss: 1.4161, G loss: 0.7855\n",
      "[1124/1762] D loss: 0.0768, G loss: 2.9137\n",
      "[1204/1762] D loss: 0.0424, G loss: 3.5081\n",
      "[1284/1762] D loss: 1.4059, G loss: 0.7458\n",
      "[1364/1762] D loss: 0.0220, G loss: 4.0802\n",
      "[1444/1762] D loss: 1.4268, G loss: 0.8028\n",
      "[1524/1762] D loss: 1.3918, G loss: 0.6372\n",
      "[1604/1762] D loss: 1.3964, G loss: 0.7049\n",
      "[1684/1762] D loss: 1.4120, G loss: 0.7073\n",
      "[1762/1762] D loss: 1.3917, G loss: 0.6377\n",
      "train error: \n",
      " D loss: 1.801822, G loss: 0.279624, D accuracy: 49.1%, cell accuracy: 99.8%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.801638, G loss: 0.282151, D accuracy: 49.3%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4517, G loss: 0.5174\n",
      "[84/1762] D loss: 0.0652, G loss: 4.6092\n",
      "[164/1762] D loss: 1.5082, G loss: 1.1256\n",
      "[244/1762] D loss: 0.0924, G loss: 2.7550\n",
      "[324/1762] D loss: 1.4809, G loss: 0.4801\n",
      "[404/1762] D loss: 1.4719, G loss: 0.4884\n",
      "[484/1762] D loss: 1.4138, G loss: 0.5755\n",
      "[564/1762] D loss: 0.0005, G loss: 8.2610\n",
      "[644/1762] D loss: 0.2256, G loss: 1.7827\n",
      "[724/1762] D loss: 0.0207, G loss: 4.1433\n",
      "[804/1762] D loss: 1.3949, G loss: 0.6959\n",
      "[884/1762] D loss: 1.6268, G loss: 0.9577\n",
      "[964/1762] D loss: 1.4964, G loss: 0.8338\n",
      "[1044/1762] D loss: 1.3904, G loss: 0.7074\n",
      "[1124/1762] D loss: 1.4089, G loss: 0.8525\n",
      "[1204/1762] D loss: 1.3946, G loss: 0.7426\n",
      "[1284/1762] D loss: 1.4104, G loss: 0.7935\n",
      "[1364/1762] D loss: 1.4172, G loss: 0.5905\n",
      "[1444/1762] D loss: 1.3884, G loss: 0.7086\n",
      "[1524/1762] D loss: 1.4096, G loss: 0.8389\n",
      "[1604/1762] D loss: 0.0764, G loss: 3.1674\n",
      "[1684/1762] D loss: 1.3930, G loss: 0.8003\n",
      "[1762/1762] D loss: 1.3866, G loss: 0.6641\n",
      "train error: \n",
      " D loss: 1.711173, G loss: 0.316139, D accuracy: 48.7%, cell accuracy: 99.8%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.732233, G loss: 0.310655, D accuracy: 48.6%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3919, G loss: 0.7343\n",
      "[84/1762] D loss: 0.0838, G loss: 3.1627\n",
      "[164/1762] D loss: 1.4022, G loss: 0.7996\n",
      "[244/1762] D loss: 1.3593, G loss: 0.7187\n",
      "[324/1762] D loss: 1.6547, G loss: 0.7839\n",
      "[404/1762] D loss: 1.3955, G loss: 0.6555\n",
      "[484/1762] D loss: 1.4031, G loss: 0.6847\n",
      "[564/1762] D loss: 0.0006, G loss: 9.4562\n",
      "[644/1762] D loss: 1.4283, G loss: 0.5174\n",
      "[724/1762] D loss: 1.3866, G loss: 0.6547\n",
      "[804/1762] D loss: 1.4076, G loss: 0.8365\n",
      "[884/1762] D loss: 0.0309, G loss: 3.8140\n",
      "[964/1762] D loss: 1.3973, G loss: 0.7623\n",
      "[1044/1762] D loss: 1.4646, G loss: 0.8141\n",
      "[1124/1762] D loss: 1.3917, G loss: 0.6184\n",
      "[1204/1762] D loss: 1.3888, G loss: 0.6682\n",
      "[1284/1762] D loss: 1.4022, G loss: 0.8283\n",
      "[1364/1762] D loss: 1.3966, G loss: 0.6518\n",
      "[1444/1762] D loss: 1.4326, G loss: 0.8706\n",
      "[1524/1762] D loss: 1.4117, G loss: 0.5620\n",
      "[1604/1762] D loss: 1.4528, G loss: 0.8098\n",
      "[1684/1762] D loss: 1.4016, G loss: 0.6588\n",
      "[1762/1762] D loss: 1.3910, G loss: 0.7055\n",
      "train error: \n",
      " D loss: 1.837046, G loss: 0.340387, D accuracy: 48.7%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.882225, G loss: 0.357001, D accuracy: 48.1%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4246, G loss: 0.6051\n",
      "[84/1762] D loss: 0.0289, G loss: 3.9200\n",
      "[164/1762] D loss: 1.4088, G loss: 0.5630\n",
      "[244/1762] D loss: 1.3885, G loss: 0.7286\n",
      "[324/1762] D loss: 1.4068, G loss: 0.6183\n",
      "[404/1762] D loss: 1.4322, G loss: 0.5210\n",
      "[484/1762] D loss: 1.4038, G loss: 0.6944\n",
      "[564/1762] D loss: 0.0304, G loss: 3.6122\n",
      "[644/1762] D loss: 1.3926, G loss: 0.7364\n",
      "[724/1762] D loss: 0.0246, G loss: 3.7865\n",
      "[804/1762] D loss: 1.3918, G loss: 0.7706\n",
      "[884/1762] D loss: 1.3975, G loss: 0.6180\n",
      "[964/1762] D loss: 1.4021, G loss: 0.6093\n",
      "[1044/1762] D loss: 1.3921, G loss: 0.7033\n",
      "[1124/1762] D loss: 1.4255, G loss: 0.8743\n",
      "[1204/1762] D loss: 1.4063, G loss: 0.7201\n",
      "[1284/1762] D loss: 1.4409, G loss: 0.6716\n",
      "[1364/1762] D loss: 1.4163, G loss: 0.8767\n",
      "[1444/1762] D loss: 1.3991, G loss: 0.7152\n",
      "[1524/1762] D loss: 1.4290, G loss: 0.5593\n",
      "[1604/1762] D loss: 1.3913, G loss: 0.6913\n",
      "[1684/1762] D loss: 1.3950, G loss: 0.6650\n",
      "[1762/1762] D loss: 1.3858, G loss: 0.6422\n",
      "train error: \n",
      " D loss: 1.857099, G loss: 0.390514, D accuracy: 47.2%, cell accuracy: 99.8%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.942160, G loss: 0.395901, D accuracy: 46.2%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0011, G loss: 8.7791\n",
      "[84/1762] D loss: 1.3880, G loss: 0.6705\n",
      "[164/1762] D loss: 0.0246, G loss: 3.8520\n",
      "[244/1762] D loss: 0.0004, G loss: 13.4517\n",
      "[324/1762] D loss: 0.0139, G loss: 4.5133\n",
      "[404/1762] D loss: 1.4072, G loss: 0.7205\n",
      "[484/1762] D loss: 1.3910, G loss: 0.6245\n",
      "[564/1762] D loss: 0.0008, G loss: 9.9975\n",
      "[644/1762] D loss: 0.0136, G loss: 4.5029\n",
      "[724/1762] D loss: 1.4075, G loss: 0.7428\n",
      "[804/1762] D loss: 1.5185, G loss: 0.4392\n",
      "[884/1762] D loss: 1.3962, G loss: 0.7087\n",
      "[964/1762] D loss: 1.3958, G loss: 0.6459\n",
      "[1044/1762] D loss: 1.3920, G loss: 0.7066\n",
      "[1124/1762] D loss: 1.3216, G loss: 0.8578\n",
      "[1204/1762] D loss: 0.9576, G loss: 1.1191\n",
      "[1284/1762] D loss: 1.4311, G loss: 0.6754\n",
      "[1364/1762] D loss: 1.3954, G loss: 0.8566\n",
      "[1444/1762] D loss: 1.5756, G loss: 1.0660\n",
      "[1524/1762] D loss: 1.3909, G loss: 0.6477\n",
      "[1604/1762] D loss: 0.3326, G loss: 2.3537\n",
      "[1684/1762] D loss: 0.1520, G loss: 2.2690\n",
      "[1762/1762] D loss: 0.5614, G loss: 7.8887\n",
      "train error: \n",
      " D loss: 1.643095, G loss: 0.418783, D accuracy: 49.7%, cell accuracy: 99.8%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.642282, G loss: 0.435554, D accuracy: 50.5%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4111, G loss: 0.5413\n",
      "[84/1762] D loss: 0.0007, G loss: 8.9344\n",
      "[164/1762] D loss: 0.0434, G loss: 3.9256\n",
      "[244/1762] D loss: 1.3970, G loss: 0.7745\n",
      "[324/1762] D loss: 1.3933, G loss: 0.7435\n",
      "[404/1762] D loss: 1.3930, G loss: 0.6646\n",
      "[484/1762] D loss: 1.4194, G loss: 0.5661\n",
      "[564/1762] D loss: 1.4018, G loss: 0.6372\n",
      "[644/1762] D loss: 0.0393, G loss: 3.5110\n",
      "[724/1762] D loss: 1.3892, G loss: 0.6829\n",
      "[804/1762] D loss: 1.4361, G loss: 0.8587\n",
      "[884/1762] D loss: 1.4114, G loss: 0.7595\n",
      "[964/1762] D loss: 1.3944, G loss: 0.6101\n",
      "[1044/1762] D loss: 1.3910, G loss: 0.7169\n",
      "[1124/1762] D loss: 1.3981, G loss: 0.6468\n",
      "[1204/1762] D loss: 1.3899, G loss: 0.7457\n",
      "[1284/1762] D loss: 1.4066, G loss: 0.7204\n",
      "[1364/1762] D loss: 1.3957, G loss: 0.6617\n",
      "[1444/1762] D loss: 1.4012, G loss: 0.7903\n",
      "[1524/1762] D loss: 0.0198, G loss: 4.4559\n",
      "[1604/1762] D loss: 1.4067, G loss: 0.7517\n",
      "[1684/1762] D loss: 0.0131, G loss: 4.5692\n",
      "[1762/1762] D loss: 0.9229, G loss: 2.7317\n",
      "train error: \n",
      " D loss: 2.630144, G loss: 0.147639, D accuracy: 49.7%, cell accuracy: 99.6%, board accuracy: 88.8% \n",
      "\n",
      "test error: \n",
      " D loss: 2.591570, G loss: 0.216895, D accuracy: 50.5%, cell accuracy: 99.4%, board accuracy: 85.9% \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5019, G loss: 0.3559\n",
      "[84/1762] D loss: 1.4581, G loss: 0.9182\n",
      "[164/1762] D loss: 1.3948, G loss: 0.7239\n",
      "[244/1762] D loss: 1.3913, G loss: 0.6719\n",
      "[324/1762] D loss: 1.3920, G loss: 0.6023\n",
      "[404/1762] D loss: 0.0177, G loss: 4.3442\n",
      "[484/1762] D loss: 1.3948, G loss: 0.7709\n",
      "[564/1762] D loss: 1.4057, G loss: 0.7129\n",
      "[644/1762] D loss: 1.0857, G loss: 1.7943\n",
      "[724/1762] D loss: 0.0540, G loss: 2.5985\n",
      "[804/1762] D loss: 1.5377, G loss: 1.0408\n",
      "[884/1762] D loss: 1.9706, G loss: 1.2165\n",
      "[964/1762] D loss: 1.4288, G loss: 0.4983\n",
      "[1044/1762] D loss: 1.4061, G loss: 0.6467\n",
      "[1124/1762] D loss: 1.3952, G loss: 0.7847\n",
      "[1204/1762] D loss: 1.4057, G loss: 0.6240\n",
      "[1284/1762] D loss: 1.3921, G loss: 0.7536\n",
      "[1364/1762] D loss: 1.4101, G loss: 0.6033\n",
      "[1444/1762] D loss: 1.3978, G loss: 0.7503\n",
      "[1524/1762] D loss: 1.4248, G loss: 0.7828\n",
      "[1604/1762] D loss: 1.3956, G loss: 0.6966\n",
      "[1684/1762] D loss: 1.4252, G loss: 0.6393\n",
      "[1762/1762] D loss: 1.3896, G loss: 0.6734\n",
      "train error: \n",
      " D loss: 2.031472, G loss: 0.223379, D accuracy: 48.1%, cell accuracy: 99.8%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 2.052492, G loss: 0.225974, D accuracy: 47.5%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3890, G loss: 0.6466\n",
      "[84/1762] D loss: 1.6096, G loss: 1.0258\n",
      "[164/1762] D loss: 1.3944, G loss: 0.6601\n",
      "[244/1762] D loss: 1.4105, G loss: 0.6109\n",
      "[324/1762] D loss: 1.3875, G loss: 0.7487\n",
      "[404/1762] D loss: 1.4257, G loss: 0.7900\n",
      "[484/1762] D loss: 1.3934, G loss: 0.6195\n",
      "[564/1762] D loss: 1.3887, G loss: 0.6605\n",
      "[644/1762] D loss: 0.0428, G loss: 4.1504\n",
      "[724/1762] D loss: 1.4120, G loss: 0.8937\n",
      "[804/1762] D loss: 1.4045, G loss: 0.7771\n",
      "[884/1762] D loss: 1.4007, G loss: 0.6886\n",
      "[964/1762] D loss: 1.3907, G loss: 0.7209\n",
      "[1044/1762] D loss: 0.0009, G loss: 9.6160\n",
      "[1124/1762] D loss: 1.4014, G loss: 0.7352\n",
      "[1204/1762] D loss: 1.3880, G loss: 0.7648\n",
      "[1284/1762] D loss: 1.3917, G loss: 0.7065\n",
      "[1364/1762] D loss: 0.0194, G loss: 4.4899\n",
      "[1444/1762] D loss: 1.4684, G loss: 0.4869\n",
      "[1524/1762] D loss: 1.4077, G loss: 0.5788\n",
      "[1604/1762] D loss: 0.0472, G loss: 3.3094\n",
      "[1684/1762] D loss: 1.4021, G loss: 0.5932\n",
      "[1762/1762] D loss: 1.3946, G loss: 0.6103\n",
      "train error: \n",
      " D loss: 2.782407, G loss: 0.081529, D accuracy: 48.8%, cell accuracy: 99.8%, board accuracy: 92.8% \n",
      "\n",
      "test error: \n",
      " D loss: 2.775230, G loss: 0.090123, D accuracy: 48.8%, cell accuracy: 99.7%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3934, G loss: 0.6817\n",
      "[84/1762] D loss: 1.3929, G loss: 0.7718\n",
      "[164/1762] D loss: 1.3846, G loss: 0.6433\n",
      "[244/1762] D loss: 0.0066, G loss: 6.1130\n",
      "[324/1762] D loss: 1.3970, G loss: 0.7781\n",
      "[404/1762] D loss: 1.3904, G loss: 0.7121\n",
      "[484/1762] D loss: 0.0013, G loss: 11.8206\n",
      "[564/1762] D loss: 1.3980, G loss: 0.6577\n",
      "[644/1762] D loss: 1.4557, G loss: 0.4555\n",
      "[724/1762] D loss: 0.0500, G loss: 4.2945\n",
      "[804/1762] D loss: 1.4081, G loss: 0.7832\n",
      "[884/1762] D loss: 1.4039, G loss: 0.8162\n",
      "[964/1762] D loss: 0.0283, G loss: 4.3317\n",
      "[1044/1762] D loss: 0.0226, G loss: 4.5530\n",
      "[1124/1762] D loss: 1.4084, G loss: 0.7567\n",
      "[1204/1762] D loss: 0.0008, G loss: 10.5536\n",
      "[1284/1762] D loss: 0.9847, G loss: 1.3736\n",
      "[1364/1762] D loss: 1.4089, G loss: 0.7391\n",
      "[1444/1762] D loss: 0.0833, G loss: 2.7797\n",
      "[1524/1762] D loss: 0.0110, G loss: 5.7421\n",
      "[1604/1762] D loss: 1.3917, G loss: 0.6929\n",
      "[1684/1762] D loss: 1.3989, G loss: 0.5641\n",
      "[1762/1762] D loss: 1.4789, G loss: 0.4758\n",
      "train error: \n",
      " D loss: 2.029192, G loss: 0.339142, D accuracy: 47.6%, cell accuracy: 99.8%, board accuracy: 92.8% \n",
      "\n",
      "test error: \n",
      " D loss: 2.138332, G loss: 0.337625, D accuracy: 46.5%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5170, G loss: 0.5653\n",
      "[84/1762] D loss: 1.5809, G loss: 1.1594\n",
      "[164/1762] D loss: 1.3895, G loss: 0.7501\n",
      "[244/1762] D loss: 1.4024, G loss: 0.6040\n",
      "[324/1762] D loss: 1.4128, G loss: 0.8035\n",
      "[404/1762] D loss: 0.0138, G loss: 5.4179\n",
      "[484/1762] D loss: 1.3894, G loss: 0.6988\n",
      "[564/1762] D loss: 1.3987, G loss: 0.7401\n",
      "[644/1762] D loss: 1.3874, G loss: 0.6819\n",
      "[724/1762] D loss: 1.3312, G loss: 0.6934\n",
      "[804/1762] D loss: 1.4191, G loss: 0.5894\n",
      "[884/1762] D loss: 1.3915, G loss: 0.7171\n",
      "[964/1762] D loss: 1.2032, G loss: 1.0656\n",
      "[1044/1762] D loss: 1.5345, G loss: 1.1776\n",
      "[1124/1762] D loss: 1.4055, G loss: 0.6767\n",
      "[1204/1762] D loss: 1.4468, G loss: 0.9810\n",
      "[1284/1762] D loss: 0.0868, G loss: 2.4750\n",
      "[1364/1762] D loss: 1.4163, G loss: 0.5308\n",
      "[1444/1762] D loss: 1.4237, G loss: 0.5470\n",
      "[1524/1762] D loss: 1.3907, G loss: 0.6415\n",
      "[1604/1762] D loss: 0.0569, G loss: 3.2577\n",
      "[1684/1762] D loss: 1.3961, G loss: 0.6311\n",
      "[1762/1762] D loss: 1.4078, G loss: 0.6160\n",
      "train error: \n",
      " D loss: 2.055887, G loss: 0.762111, D accuracy: 48.2%, cell accuracy: 99.8%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 2.232825, G loss: 0.773445, D accuracy: 47.6%, cell accuracy: 99.7%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4074, G loss: 0.6551\n",
      "[84/1762] D loss: 1.3933, G loss: 0.6705\n",
      "[164/1762] D loss: 0.0347, G loss: 3.7428\n",
      "[244/1762] D loss: 1.3966, G loss: 0.8006\n",
      "[324/1762] D loss: 0.0574, G loss: 3.8398\n",
      "[404/1762] D loss: 1.4000, G loss: 0.7064\n",
      "[484/1762] D loss: 1.3930, G loss: 0.6467\n",
      "[564/1762] D loss: 1.4019, G loss: 0.8147\n",
      "[644/1762] D loss: 1.3885, G loss: 0.6088\n",
      "[724/1762] D loss: 1.2993, G loss: 0.7053\n",
      "[804/1762] D loss: 1.4017, G loss: 0.6653\n",
      "[884/1762] D loss: 1.3876, G loss: 0.6641\n",
      "[964/1762] D loss: 1.3964, G loss: 0.6750\n",
      "[1044/1762] D loss: 1.3918, G loss: 0.6724\n",
      "[1124/1762] D loss: 1.4496, G loss: 0.7820\n",
      "[1204/1762] D loss: 1.4058, G loss: 0.7619\n",
      "[1284/1762] D loss: 1.3987, G loss: 0.6890\n",
      "[1364/1762] D loss: 1.3989, G loss: 0.5952\n",
      "[1444/1762] D loss: 1.3988, G loss: 0.7852\n",
      "[1524/1762] D loss: 1.3890, G loss: 0.7248\n",
      "[1604/1762] D loss: 1.3952, G loss: 0.6346\n",
      "[1684/1762] D loss: 0.0151, G loss: 6.7318\n",
      "[1762/1762] D loss: 1.0229, G loss: 2.7486\n",
      "train error: \n",
      " D loss: 1.795300, G loss: 0.356326, D accuracy: 48.0%, cell accuracy: 99.8%, board accuracy: 91.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.843473, G loss: 0.352376, D accuracy: 47.4%, cell accuracy: 99.7%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4033, G loss: 0.6962\n",
      "[84/1762] D loss: 1.3962, G loss: 0.6415\n",
      "[164/1762] D loss: 1.4012, G loss: 0.8046\n",
      "[244/1762] D loss: 1.4166, G loss: 0.8306\n",
      "[324/1762] D loss: 1.4043, G loss: 0.5783\n",
      "[404/1762] D loss: 0.2225, G loss: 2.4969\n",
      "[484/1762] D loss: 0.9527, G loss: 2.5885\n",
      "[564/1762] D loss: 1.4074, G loss: 0.5691\n",
      "[644/1762] D loss: 0.0007, G loss: 10.2221\n",
      "[724/1762] D loss: 1.3950, G loss: 0.6778\n",
      "[804/1762] D loss: 1.3918, G loss: 0.6651\n",
      "[884/1762] D loss: 1.3867, G loss: 0.7335\n",
      "[964/1762] D loss: 1.3875, G loss: 0.6675\n",
      "[1044/1762] D loss: 1.3878, G loss: 0.6763\n",
      "[1124/1762] D loss: 1.3881, G loss: 0.6924\n",
      "[1204/1762] D loss: 1.3898, G loss: 0.6691\n",
      "[1284/1762] D loss: 1.3925, G loss: 0.6438\n",
      "[1364/1762] D loss: 0.0258, G loss: 3.9340\n",
      "[1444/1762] D loss: 1.3923, G loss: 0.7621\n",
      "[1524/1762] D loss: 0.0721, G loss: 3.2977\n",
      "[1604/1762] D loss: 1.4503, G loss: 0.4281\n",
      "[1684/1762] D loss: 0.0046, G loss: 6.6948\n",
      "[1762/1762] D loss: 1.3909, G loss: 0.6199\n",
      "train error: \n",
      " D loss: 2.439793, G loss: 0.329731, D accuracy: 46.5%, cell accuracy: 99.8%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 2.642261, G loss: 0.327733, D accuracy: 45.7%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0418, G loss: 3.3489\n",
      "[84/1762] D loss: 1.3933, G loss: 0.6138\n",
      "[164/1762] D loss: 1.3882, G loss: 0.7118\n",
      "[244/1762] D loss: 1.3943, G loss: 0.6488\n",
      "[324/1762] D loss: 0.0540, G loss: 3.2749\n",
      "[404/1762] D loss: 1.4059, G loss: 0.6800\n",
      "[484/1762] D loss: 1.4015, G loss: 0.5757\n",
      "[564/1762] D loss: 1.3876, G loss: 0.6721\n",
      "[644/1762] D loss: 1.3966, G loss: 0.6055\n",
      "[724/1762] D loss: 0.0108, G loss: 5.2782\n",
      "[804/1762] D loss: 1.3993, G loss: 0.7082\n",
      "[884/1762] D loss: 1.3898, G loss: 0.6458\n",
      "[964/1762] D loss: 1.3886, G loss: 0.7076\n",
      "[1044/1762] D loss: 1.3888, G loss: 0.6857\n",
      "[1124/1762] D loss: 0.0123, G loss: 4.4270\n",
      "[1204/1762] D loss: 0.0009, G loss: 12.5764\n",
      "[1284/1762] D loss: 1.3951, G loss: 0.6375\n",
      "[1364/1762] D loss: 1.3886, G loss: 0.6567\n",
      "[1444/1762] D loss: 0.0075, G loss: 5.0371\n",
      "[1524/1762] D loss: 0.0103, G loss: 5.1366\n",
      "[1604/1762] D loss: 0.0048, G loss: 5.9857\n",
      "[1684/1762] D loss: 0.0131, G loss: 4.7312\n",
      "[1762/1762] D loss: 1.3875, G loss: 0.7418\n",
      "train error: \n",
      " D loss: 2.798558, G loss: 0.162968, D accuracy: 46.4%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 2.994549, G loss: 0.163895, D accuracy: 45.6%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0172, G loss: 4.4410\n",
      "[84/1762] D loss: 1.3864, G loss: 0.7186\n",
      "[164/1762] D loss: 0.0069, G loss: 6.9317\n",
      "[244/1762] D loss: 0.7006, G loss: 4.7475\n",
      "[324/1762] D loss: 0.0145, G loss: 4.4167\n",
      "[404/1762] D loss: 1.3890, G loss: 0.6866\n",
      "[484/1762] D loss: 0.0499, G loss: 3.1653\n",
      "[564/1762] D loss: 1.4154, G loss: 0.8620\n",
      "[644/1762] D loss: 1.3543, G loss: 0.7256\n",
      "[724/1762] D loss: 1.3781, G loss: 0.6870\n",
      "[804/1762] D loss: 1.3923, G loss: 0.7291\n",
      "[884/1762] D loss: 1.3907, G loss: 0.6355\n",
      "[964/1762] D loss: 1.3886, G loss: 0.6349\n",
      "[1044/1762] D loss: 1.3918, G loss: 0.7445\n",
      "[1124/1762] D loss: 1.3880, G loss: 0.6642\n",
      "[1204/1762] D loss: 0.0297, G loss: 3.7768\n",
      "[1284/1762] D loss: 1.3872, G loss: 0.6821\n",
      "[1364/1762] D loss: 1.4015, G loss: 0.5758\n",
      "[1444/1762] D loss: 1.3881, G loss: 0.6660\n",
      "[1524/1762] D loss: 1.4010, G loss: 0.6222\n",
      "[1604/1762] D loss: 1.3875, G loss: 0.6997\n",
      "[1684/1762] D loss: 1.3934, G loss: 0.7910\n",
      "[1762/1762] D loss: 1.3890, G loss: 0.6913\n",
      "train error: \n",
      " D loss: 3.918789, G loss: 0.033283, D accuracy: 47.0%, cell accuracy: 99.8%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 4.011282, G loss: 0.034004, D accuracy: 46.0%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0079, G loss: 5.3560\n",
      "[84/1762] D loss: 1.3868, G loss: 0.7117\n",
      "[164/1762] D loss: 1.3897, G loss: 0.6210\n",
      "[244/1762] D loss: 1.3875, G loss: 0.6619\n",
      "[324/1762] D loss: 1.3975, G loss: 0.7694\n",
      "[404/1762] D loss: 1.3944, G loss: 0.6748\n",
      "[484/1762] D loss: 1.4022, G loss: 0.6071\n",
      "[564/1762] D loss: 1.3893, G loss: 0.6356\n",
      "[644/1762] D loss: 0.0047, G loss: 5.7599\n",
      "[724/1762] D loss: 1.3900, G loss: 0.6559\n",
      "[804/1762] D loss: 0.0000, G loss: 13.3248\n",
      "[884/1762] D loss: 1.4019, G loss: 0.7603\n",
      "[964/1762] D loss: 0.0066, G loss: 5.3973\n",
      "[1044/1762] D loss: 1.4138, G loss: 0.5690\n",
      "[1124/1762] D loss: 1.4015, G loss: 0.6001\n",
      "[1204/1762] D loss: 1.3868, G loss: 0.6922\n",
      "[1284/1762] D loss: 1.3872, G loss: 0.6848\n",
      "[1364/1762] D loss: 1.3901, G loss: 0.6385\n",
      "[1444/1762] D loss: 1.3917, G loss: 0.6233\n",
      "[1524/1762] D loss: 1.3915, G loss: 0.6472\n",
      "[1604/1762] D loss: 0.0300, G loss: 4.0992\n",
      "[1684/1762] D loss: 0.0135, G loss: 4.5138\n",
      "[1762/1762] D loss: 0.0000, G loss: 13.8989\n",
      "train error: \n",
      " D loss: 3.858525, G loss: 0.054726, D accuracy: 46.5%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 4.019074, G loss: 0.055849, D accuracy: 45.5%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3865, G loss: 0.6900\n",
      "[84/1762] D loss: 1.3919, G loss: 0.7636\n",
      "[164/1762] D loss: 1.3875, G loss: 0.7344\n",
      "[244/1762] D loss: 1.4064, G loss: 0.5981\n",
      "[324/1762] D loss: 1.3878, G loss: 0.6781\n",
      "[404/1762] D loss: 1.3961, G loss: 0.6234\n",
      "[484/1762] D loss: 1.1717, G loss: 1.2326\n",
      "[564/1762] D loss: 1.3908, G loss: 0.7639\n",
      "[644/1762] D loss: 1.3886, G loss: 0.7842\n",
      "[724/1762] D loss: 1.3984, G loss: 0.7972\n",
      "[804/1762] D loss: 1.4397, G loss: 0.6243\n",
      "[884/1762] D loss: 1.4453, G loss: 0.8991\n",
      "[964/1762] D loss: 1.4132, G loss: 0.5751\n",
      "[1044/1762] D loss: 1.3852, G loss: 0.6655\n",
      "[1124/1762] D loss: 1.3868, G loss: 0.7038\n",
      "[1204/1762] D loss: 1.4030, G loss: 0.7592\n",
      "[1284/1762] D loss: 0.0326, G loss: 4.2533\n",
      "[1364/1762] D loss: 1.3978, G loss: 0.6425\n",
      "[1444/1762] D loss: 1.3975, G loss: 0.6092\n",
      "[1524/1762] D loss: 1.3911, G loss: 0.6816\n",
      "[1604/1762] D loss: 1.3899, G loss: 0.6534\n",
      "[1684/1762] D loss: 0.0343, G loss: 3.3755\n",
      "[1762/1762] D loss: 1.4198, G loss: 0.5369\n",
      "train error: \n",
      " D loss: 2.761685, G loss: 0.332265, D accuracy: 46.6%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 3.040379, G loss: 0.344750, D accuracy: 45.7%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 11.8411\n",
      "[84/1762] D loss: 1.3925, G loss: 0.6586\n",
      "[164/1762] D loss: 0.0001, G loss: 11.7734\n",
      "[244/1762] D loss: 1.2031, G loss: 1.7277\n",
      "[324/1762] D loss: 1.3033, G loss: 2.0408\n",
      "[404/1762] D loss: 1.4692, G loss: 0.9343\n",
      "[484/1762] D loss: 1.4023, G loss: 0.5817\n",
      "[564/1762] D loss: 0.0041, G loss: 6.2199\n",
      "[644/1762] D loss: 1.4691, G loss: 0.5506\n",
      "[724/1762] D loss: 1.3938, G loss: 0.7403\n",
      "[804/1762] D loss: 1.3891, G loss: 0.7341\n",
      "[884/1762] D loss: 0.0017, G loss: 6.8939\n",
      "[964/1762] D loss: 1.4013, G loss: 0.8584\n",
      "[1044/1762] D loss: 1.3790, G loss: 0.8138\n",
      "[1124/1762] D loss: 1.3917, G loss: 0.6378\n",
      "[1204/1762] D loss: 1.4052, G loss: 0.5814\n",
      "[1284/1762] D loss: 0.0283, G loss: 3.2505\n",
      "[1364/1762] D loss: 0.2349, G loss: 1.9350\n",
      "[1444/1762] D loss: 0.8923, G loss: 3.5159\n",
      "[1524/1762] D loss: 1.3888, G loss: 0.6948\n",
      "[1604/1762] D loss: 1.3104, G loss: 0.8888\n",
      "[1684/1762] D loss: 1.3913, G loss: 0.8352\n",
      "[1762/1762] D loss: 1.4271, G loss: 0.9232\n",
      "train error: \n",
      " D loss: 2.709608, G loss: 0.366833, D accuracy: 48.8%, cell accuracy: 99.7%, board accuracy: 85.9% \n",
      "\n",
      "test error: \n",
      " D loss: 3.003269, G loss: 0.356978, D accuracy: 47.5%, cell accuracy: 99.7%, board accuracy: 83.6% \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3947, G loss: 0.7825\n",
      "[84/1762] D loss: 0.0208, G loss: 5.3147\n",
      "[164/1762] D loss: 1.3904, G loss: 0.7890\n",
      "[244/1762] D loss: 1.3951, G loss: 0.7374\n",
      "[324/1762] D loss: 1.3911, G loss: 0.6574\n",
      "[404/1762] D loss: 0.0002, G loss: 18.1388\n",
      "[484/1762] D loss: 0.2885, G loss: 1.8198\n",
      "[564/1762] D loss: 1.4134, G loss: 0.5958\n",
      "[644/1762] D loss: 1.4113, G loss: 0.5764\n",
      "[724/1762] D loss: 1.4029, G loss: 0.6977\n",
      "[804/1762] D loss: 0.0107, G loss: 4.9246\n",
      "[884/1762] D loss: 1.3908, G loss: 0.6623\n",
      "[964/1762] D loss: 1.4077, G loss: 0.8590\n",
      "[1044/1762] D loss: 1.3883, G loss: 0.7102\n",
      "[1124/1762] D loss: 0.0465, G loss: 3.3643\n",
      "[1204/1762] D loss: 0.0133, G loss: 4.6281\n",
      "[1284/1762] D loss: 1.3899, G loss: 0.6478\n",
      "[1364/1762] D loss: 1.3868, G loss: 0.7085\n",
      "[1444/1762] D loss: 0.0061, G loss: 5.2441\n",
      "[1524/1762] D loss: 1.3893, G loss: 0.6947\n",
      "[1604/1762] D loss: 1.2217, G loss: 0.8583\n",
      "[1684/1762] D loss: 0.1005, G loss: 2.9120\n",
      "[1762/1762] D loss: 1.3880, G loss: 0.6670\n",
      "train error: \n",
      " D loss: 3.137917, G loss: 0.355504, D accuracy: 47.0%, cell accuracy: 99.8%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 3.548037, G loss: 0.350034, D accuracy: 45.9%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0212, G loss: 3.6455\n",
      "[84/1762] D loss: 1.3959, G loss: 0.5687\n",
      "[164/1762] D loss: 1.3953, G loss: 0.7444\n",
      "[244/1762] D loss: 1.3934, G loss: 0.6565\n",
      "[324/1762] D loss: 1.4178, G loss: 0.8771\n",
      "[404/1762] D loss: 1.3957, G loss: 0.6385\n",
      "[484/1762] D loss: 1.3875, G loss: 0.7095\n",
      "[564/1762] D loss: 1.3917, G loss: 0.7199\n",
      "[644/1762] D loss: 1.3866, G loss: 0.7211\n",
      "[724/1762] D loss: 1.3820, G loss: 0.7840\n",
      "[804/1762] D loss: 1.3942, G loss: 0.7850\n",
      "[884/1762] D loss: 1.3964, G loss: 0.6218\n",
      "[964/1762] D loss: 0.0078, G loss: 5.4332\n",
      "[1044/1762] D loss: 1.3889, G loss: 0.6606\n",
      "[1124/1762] D loss: 1.3889, G loss: 0.6638\n",
      "[1204/1762] D loss: 1.3870, G loss: 0.7020\n",
      "[1284/1762] D loss: 1.3867, G loss: 0.6830\n",
      "[1364/1762] D loss: 0.0178, G loss: 4.0605\n",
      "[1444/1762] D loss: 1.3869, G loss: 0.6823\n",
      "[1524/1762] D loss: 1.3870, G loss: 0.6882\n",
      "[1604/1762] D loss: 1.3956, G loss: 0.7659\n",
      "[1684/1762] D loss: 0.0026, G loss: 6.1775\n",
      "[1762/1762] D loss: 1.3965, G loss: 0.6917\n",
      "train error: \n",
      " D loss: 2.952853, G loss: 0.196250, D accuracy: 46.5%, cell accuracy: 99.8%, board accuracy: 92.8% \n",
      "\n",
      "test error: \n",
      " D loss: 3.221068, G loss: 0.196210, D accuracy: 45.6%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4160, G loss: 0.6759\n",
      "[84/1762] D loss: 1.3893, G loss: 0.7043\n",
      "[164/1762] D loss: 0.0096, G loss: 5.1377\n",
      "[244/1762] D loss: 0.0130, G loss: 4.5319\n",
      "[324/1762] D loss: 1.3870, G loss: 0.6734\n",
      "[404/1762] D loss: 0.2157, G loss: 3.0722\n",
      "[484/1762] D loss: 1.3908, G loss: 0.7398\n",
      "[564/1762] D loss: 1.4051, G loss: 0.5908\n",
      "[644/1762] D loss: 0.0206, G loss: 4.4541\n",
      "[724/1762] D loss: 1.4022, G loss: 0.5583\n",
      "[804/1762] D loss: 1.3910, G loss: 0.6677\n",
      "[884/1762] D loss: 1.3880, G loss: 0.6714\n",
      "[964/1762] D loss: 1.3891, G loss: 0.6953\n",
      "[1044/1762] D loss: 1.3868, G loss: 0.6855\n",
      "[1124/1762] D loss: 0.0079, G loss: 5.0878\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6815\n",
      "[1284/1762] D loss: 0.0081, G loss: 5.9653\n",
      "[1364/1762] D loss: 1.3907, G loss: 0.6716\n",
      "[1444/1762] D loss: 1.3869, G loss: 0.6816\n",
      "[1524/1762] D loss: 1.3866, G loss: 0.6678\n",
      "[1604/1762] D loss: 1.3865, G loss: 0.6663\n",
      "[1684/1762] D loss: 1.3823, G loss: 0.8283\n",
      "[1762/1762] D loss: 1.3887, G loss: 0.6967\n",
      "train error: \n",
      " D loss: 3.016296, G loss: 0.695208, D accuracy: 46.9%, cell accuracy: 99.9%, board accuracy: 92.8% \n",
      "\n",
      "test error: \n",
      " D loss: 3.379177, G loss: 0.695720, D accuracy: 46.0%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3882, G loss: 0.7343\n",
      "[84/1762] D loss: 1.3908, G loss: 0.7950\n",
      "[164/1762] D loss: 1.3928, G loss: 0.6464\n",
      "[244/1762] D loss: 1.3856, G loss: 0.7099\n",
      "[324/1762] D loss: 0.0244, G loss: 5.2828\n",
      "[404/1762] D loss: 0.0010, G loss: 7.5528\n",
      "[484/1762] D loss: 1.4001, G loss: 0.7238\n",
      "[564/1762] D loss: 1.4101, G loss: 0.5155\n",
      "[644/1762] D loss: 1.3951, G loss: 0.6512\n",
      "[724/1762] D loss: 1.3891, G loss: 0.6372\n",
      "[804/1762] D loss: 1.4501, G loss: 0.9391\n",
      "[884/1762] D loss: 1.3897, G loss: 0.6935\n",
      "[964/1762] D loss: 0.0066, G loss: 5.6528\n",
      "[1044/1762] D loss: 1.3879, G loss: 0.6747\n",
      "[1124/1762] D loss: 1.3922, G loss: 0.8013\n",
      "[1204/1762] D loss: 1.3901, G loss: 0.6419\n",
      "[1284/1762] D loss: 1.3968, G loss: 0.7938\n",
      "[1364/1762] D loss: 1.3920, G loss: 0.6590\n",
      "[1444/1762] D loss: 1.3861, G loss: 0.7192\n",
      "[1524/1762] D loss: 0.0003, G loss: 9.4226\n",
      "[1604/1762] D loss: 1.4111, G loss: 0.7310\n",
      "[1684/1762] D loss: 1.4127, G loss: 0.8938\n",
      "[1762/1762] D loss: 1.4091, G loss: 0.5727\n",
      "train error: \n",
      " D loss: 2.562190, G loss: 0.207979, D accuracy: 46.4%, cell accuracy: 99.8%, board accuracy: 92.8% \n",
      "\n",
      "test error: \n",
      " D loss: 2.665838, G loss: 0.207591, D accuracy: 45.5%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4045, G loss: 1.4907\n",
      "[84/1762] D loss: 1.3892, G loss: 0.6525\n",
      "[164/1762] D loss: 1.3911, G loss: 0.7495\n",
      "[244/1762] D loss: 0.0115, G loss: 4.7612\n",
      "[324/1762] D loss: 1.3873, G loss: 0.6864\n",
      "[404/1762] D loss: 1.3874, G loss: 0.6605\n",
      "[484/1762] D loss: 1.3910, G loss: 0.7583\n",
      "[564/1762] D loss: 1.3874, G loss: 0.6692\n",
      "[644/1762] D loss: 1.3873, G loss: 0.6706\n",
      "[724/1762] D loss: 1.4231, G loss: 0.5497\n",
      "[804/1762] D loss: 0.2184, G loss: 2.9835\n",
      "[884/1762] D loss: 0.2438, G loss: 2.2398\n",
      "[964/1762] D loss: 1.3927, G loss: 0.7269\n",
      "[1044/1762] D loss: 1.5822, G loss: 0.7004\n",
      "[1124/1762] D loss: 1.3866, G loss: 0.6816\n",
      "[1204/1762] D loss: 0.0232, G loss: 4.0201\n",
      "[1284/1762] D loss: 0.0093, G loss: 5.1119\n",
      "[1364/1762] D loss: 1.3919, G loss: 0.6266\n",
      "[1444/1762] D loss: 1.3904, G loss: 0.6649\n",
      "[1524/1762] D loss: 0.0098, G loss: 4.8144\n",
      "[1604/1762] D loss: 1.3820, G loss: 0.6584\n",
      "[1684/1762] D loss: 1.4110, G loss: 0.8093\n",
      "[1762/1762] D loss: 0.0000, G loss: 14.4193\n",
      "train error: \n",
      " D loss: 5.312120, G loss: 0.008778, D accuracy: 49.3%, cell accuracy: 99.8%, board accuracy: 92.8% \n",
      "\n",
      "test error: \n",
      " D loss: 5.238567, G loss: 0.009593, D accuracy: 49.3%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4223, G loss: 0.9107\n",
      "[84/1762] D loss: 1.3921, G loss: 0.6280\n",
      "[164/1762] D loss: 1.3994, G loss: 0.7789\n",
      "[244/1762] D loss: 1.3870, G loss: 0.7260\n",
      "[324/1762] D loss: 1.3893, G loss: 0.6544\n",
      "[404/1762] D loss: 1.3866, G loss: 0.7076\n",
      "[484/1762] D loss: 1.3941, G loss: 0.6067\n",
      "[564/1762] D loss: 1.3924, G loss: 0.7628\n",
      "[644/1762] D loss: 1.3922, G loss: 0.6365\n",
      "[724/1762] D loss: 1.3891, G loss: 0.7389\n",
      "[804/1762] D loss: 1.3904, G loss: 0.6454\n",
      "[884/1762] D loss: 1.3866, G loss: 0.6891\n",
      "[964/1762] D loss: 1.3873, G loss: 0.6635\n",
      "[1044/1762] D loss: 1.3902, G loss: 0.7586\n",
      "[1124/1762] D loss: 0.0534, G loss: 3.5091\n",
      "[1204/1762] D loss: 1.3902, G loss: 0.6535\n",
      "[1284/1762] D loss: 1.3891, G loss: 0.7143\n",
      "[1364/1762] D loss: 1.3882, G loss: 0.6760\n",
      "[1444/1762] D loss: 0.0265, G loss: 4.3263\n",
      "[1524/1762] D loss: 1.3883, G loss: 0.6564\n",
      "[1604/1762] D loss: 0.0128, G loss: 4.7315\n",
      "[1684/1762] D loss: 1.3877, G loss: 0.6661\n",
      "[1762/1762] D loss: 1.3869, G loss: 0.7110\n",
      "train error: \n",
      " D loss: 4.071306, G loss: 0.663713, D accuracy: 46.7%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 4.781625, G loss: 0.660691, D accuracy: 45.6%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 11.6545\n",
      "[84/1762] D loss: 1.3873, G loss: 0.7164\n",
      "[164/1762] D loss: 1.3846, G loss: 0.6618\n",
      "[244/1762] D loss: 1.3864, G loss: 0.7038\n",
      "[324/1762] D loss: 0.0193, G loss: 5.0711\n",
      "[404/1762] D loss: 1.3871, G loss: 0.6716\n",
      "[484/1762] D loss: 1.3866, G loss: 0.6873\n",
      "[564/1762] D loss: 1.3382, G loss: 0.8256\n",
      "[644/1762] D loss: 1.4086, G loss: 0.6036\n",
      "[724/1762] D loss: 1.3900, G loss: 0.6717\n",
      "[804/1762] D loss: 1.2263, G loss: 1.0169\n",
      "[884/1762] D loss: 1.3941, G loss: 0.6017\n",
      "[964/1762] D loss: 1.3867, G loss: 0.6985\n",
      "[1044/1762] D loss: 1.3884, G loss: 0.7464\n",
      "[1124/1762] D loss: 1.5504, G loss: 0.8197\n",
      "[1204/1762] D loss: 1.3941, G loss: 0.7300\n",
      "[1284/1762] D loss: 1.3903, G loss: 0.7331\n",
      "[1364/1762] D loss: 1.4003, G loss: 0.5835\n",
      "[1444/1762] D loss: 1.3871, G loss: 0.7161\n",
      "[1524/1762] D loss: 1.3869, G loss: 0.7180\n",
      "[1604/1762] D loss: 1.3865, G loss: 0.6775\n",
      "[1684/1762] D loss: 0.0954, G loss: 3.1737\n",
      "[1762/1762] D loss: 1.3887, G loss: 0.6482\n",
      "train error: \n",
      " D loss: 3.124682, G loss: 0.376326, D accuracy: 46.5%, cell accuracy: 99.8%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 3.527609, G loss: 0.375046, D accuracy: 45.5%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3938, G loss: 0.6155\n",
      "[84/1762] D loss: 1.3977, G loss: 0.7961\n",
      "[164/1762] D loss: 1.3878, G loss: 0.6598\n",
      "[244/1762] D loss: 1.3821, G loss: 0.6878\n",
      "[324/1762] D loss: 1.3882, G loss: 0.7074\n",
      "[404/1762] D loss: 0.0002, G loss: 10.3889\n",
      "[484/1762] D loss: 1.3877, G loss: 0.6575\n",
      "[564/1762] D loss: 0.0179, G loss: 4.9394\n",
      "[644/1762] D loss: 1.3883, G loss: 0.6679\n",
      "[724/1762] D loss: 0.0158, G loss: 4.7044\n",
      "[804/1762] D loss: 1.4160, G loss: 0.7752\n",
      "[884/1762] D loss: 1.3699, G loss: 0.7296\n",
      "[964/1762] D loss: 1.3873, G loss: 0.6879\n",
      "[1044/1762] D loss: 1.3865, G loss: 0.7100\n",
      "[1124/1762] D loss: 1.3912, G loss: 0.7454\n",
      "[1204/1762] D loss: 1.3879, G loss: 0.7251\n",
      "[1284/1762] D loss: 0.5992, G loss: 0.9549\n",
      "[1364/1762] D loss: 0.1493, G loss: 2.9391\n",
      "[1444/1762] D loss: 1.3922, G loss: 0.6286\n",
      "[1524/1762] D loss: 1.3872, G loss: 0.7006\n",
      "[1604/1762] D loss: 1.3938, G loss: 0.7638\n",
      "[1684/1762] D loss: 1.3876, G loss: 0.7433\n",
      "[1762/1762] D loss: 1.3868, G loss: 0.6879\n",
      "train error: \n",
      " D loss: 2.641299, G loss: 0.361574, D accuracy: 46.5%, cell accuracy: 99.8%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 2.930549, G loss: 0.363559, D accuracy: 45.6%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1140, G loss: 3.8624\n",
      "[84/1762] D loss: 1.3943, G loss: 0.6088\n",
      "[164/1762] D loss: 1.3993, G loss: 0.8144\n",
      "[244/1762] D loss: 0.0066, G loss: 5.9160\n",
      "[324/1762] D loss: 1.4149, G loss: 0.7707\n",
      "[404/1762] D loss: 1.3868, G loss: 0.6797\n",
      "[484/1762] D loss: 1.3893, G loss: 0.7251\n",
      "[564/1762] D loss: 1.3901, G loss: 0.6526\n",
      "[644/1762] D loss: 1.3897, G loss: 0.6919\n",
      "[724/1762] D loss: 1.4058, G loss: 0.8306\n",
      "[804/1762] D loss: 1.3948, G loss: 0.6164\n",
      "[884/1762] D loss: 0.0672, G loss: 3.4080\n",
      "[964/1762] D loss: 1.3981, G loss: 0.6216\n",
      "[1044/1762] D loss: 0.4076, G loss: 1.9167\n",
      "[1124/1762] D loss: 0.4139, G loss: 1.4477\n",
      "[1204/1762] D loss: 1.3895, G loss: 0.7436\n",
      "[1284/1762] D loss: 1.2152, G loss: 1.4559\n",
      "[1364/1762] D loss: 1.3892, G loss: 0.7436\n",
      "[1444/1762] D loss: 1.3895, G loss: 0.6435\n",
      "[1524/1762] D loss: 1.3893, G loss: 0.6467\n",
      "[1604/1762] D loss: 1.3876, G loss: 0.7163\n",
      "[1684/1762] D loss: 1.3871, G loss: 0.7189\n",
      "[1762/1762] D loss: 1.3874, G loss: 0.6711\n",
      "train error: \n",
      " D loss: 2.448252, G loss: 0.426990, D accuracy: 46.5%, cell accuracy: 99.8%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 2.663565, G loss: 0.427061, D accuracy: 45.5%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3868, G loss: 0.6846\n",
      "[84/1762] D loss: 1.3875, G loss: 0.7307\n",
      "[164/1762] D loss: 0.0002, G loss: 9.1813\n",
      "[244/1762] D loss: 0.1888, G loss: 3.0047\n",
      "[324/1762] D loss: 0.0135, G loss: 4.8182\n",
      "[404/1762] D loss: 1.3865, G loss: 0.7113\n",
      "[484/1762] D loss: 1.3881, G loss: 0.6669\n",
      "[564/1762] D loss: 0.0177, G loss: 5.5799\n",
      "[644/1762] D loss: 0.1055, G loss: 4.2292\n",
      "[724/1762] D loss: 1.3984, G loss: 0.6654\n",
      "[804/1762] D loss: 1.4413, G loss: 0.9334\n",
      "[884/1762] D loss: 1.3870, G loss: 0.6994\n",
      "[964/1762] D loss: 1.3839, G loss: 0.6637\n",
      "[1044/1762] D loss: 0.0063, G loss: 6.6008\n",
      "[1124/1762] D loss: 1.3929, G loss: 0.7701\n",
      "[1204/1762] D loss: 1.3921, G loss: 0.7202\n",
      "[1284/1762] D loss: 0.3588, G loss: 2.1795\n",
      "[1364/1762] D loss: 0.0475, G loss: 4.3783\n",
      "[1444/1762] D loss: 1.3919, G loss: 0.7557\n",
      "[1524/1762] D loss: 1.3898, G loss: 0.7299\n",
      "[1604/1762] D loss: 1.3876, G loss: 0.7220\n",
      "[1684/1762] D loss: 1.3891, G loss: 0.6408\n",
      "[1762/1762] D loss: 1.3984, G loss: 0.5850\n",
      "train error: \n",
      " D loss: 2.649283, G loss: 0.525438, D accuracy: 46.7%, cell accuracy: 99.8%, board accuracy: 92.8% \n",
      "\n",
      "test error: \n",
      " D loss: 2.920155, G loss: 0.527666, D accuracy: 46.0%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3974, G loss: 0.5906\n",
      "[84/1762] D loss: 1.4183, G loss: 0.8898\n",
      "[164/1762] D loss: 1.4110, G loss: 0.8368\n",
      "[244/1762] D loss: 1.3874, G loss: 0.6859\n",
      "[324/1762] D loss: 1.3869, G loss: 0.6944\n",
      "[404/1762] D loss: 0.0021, G loss: 6.6429\n",
      "[484/1762] D loss: 1.3887, G loss: 0.7426\n",
      "[564/1762] D loss: 0.0133, G loss: 4.6863\n",
      "[644/1762] D loss: 1.3906, G loss: 0.7588\n",
      "[724/1762] D loss: 2.3567, G loss: 0.7121\n",
      "[804/1762] D loss: 1.2784, G loss: 2.4314\n",
      "[884/1762] D loss: 0.0074, G loss: 5.5918\n",
      "[964/1762] D loss: 0.4786, G loss: 1.8574\n",
      "[1044/1762] D loss: 1.3919, G loss: 0.7442\n",
      "[1124/1762] D loss: 0.0073, G loss: 5.9656\n",
      "[1204/1762] D loss: 1.3875, G loss: 0.7030\n",
      "[1284/1762] D loss: 0.4053, G loss: 2.9542\n",
      "[1364/1762] D loss: 1.3405, G loss: 0.7477\n",
      "[1444/1762] D loss: 1.3910, G loss: 0.7271\n",
      "[1524/1762] D loss: 0.3774, G loss: 1.2810\n",
      "[1604/1762] D loss: 0.0141, G loss: 5.7017\n",
      "[1684/1762] D loss: 1.3869, G loss: 0.6702\n",
      "[1762/1762] D loss: 1.4085, G loss: 0.7725\n",
      "train error: \n",
      " D loss: 4.585620, G loss: 0.774374, D accuracy: 50.4%, cell accuracy: 99.8%, board accuracy: 91.2% \n",
      "\n",
      "test error: \n",
      " D loss: 5.433598, G loss: 0.801482, D accuracy: 50.5%, cell accuracy: 99.7%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3828, G loss: 0.7967\n",
      "[84/1762] D loss: 1.3899, G loss: 0.6796\n",
      "[164/1762] D loss: 1.3869, G loss: 0.7205\n",
      "[244/1762] D loss: 1.3895, G loss: 0.6623\n",
      "[324/1762] D loss: 1.4542, G loss: 0.7893\n",
      "[404/1762] D loss: 1.3828, G loss: 0.6893\n",
      "[484/1762] D loss: 1.4032, G loss: 0.5663\n",
      "[564/1762] D loss: 0.4836, G loss: 0.9862\n",
      "[644/1762] D loss: 1.4002, G loss: 0.7979\n",
      "[724/1762] D loss: 1.4003, G loss: 0.7836\n",
      "[804/1762] D loss: 1.1292, G loss: 1.7498\n",
      "[884/1762] D loss: 0.3254, G loss: 3.9458\n",
      "[964/1762] D loss: 0.1087, G loss: 3.6650\n",
      "[1044/1762] D loss: 1.3909, G loss: 0.6428\n",
      "[1124/1762] D loss: 0.0363, G loss: 3.7662\n",
      "[1204/1762] D loss: 0.0038, G loss: 7.1120\n",
      "[1284/1762] D loss: 1.3869, G loss: 0.6117\n",
      "[1364/1762] D loss: 1.3913, G loss: 0.6710\n",
      "[1444/1762] D loss: 1.3976, G loss: 0.6588\n",
      "[1524/1762] D loss: 1.3921, G loss: 0.7456\n",
      "[1604/1762] D loss: 0.0835, G loss: 2.8563\n",
      "[1684/1762] D loss: 1.3338, G loss: 0.7102\n",
      "[1762/1762] D loss: 1.3920, G loss: 0.6371\n",
      "train error: \n",
      " D loss: 3.582708, G loss: 0.506468, D accuracy: 50.3%, cell accuracy: 99.7%, board accuracy: 88.0% \n",
      "\n",
      "test error: \n",
      " D loss: 4.098356, G loss: 0.552610, D accuracy: 50.5%, cell accuracy: 99.6%, board accuracy: 85.7% \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2980, G loss: 0.7890\n",
      "[84/1762] D loss: 1.3918, G loss: 0.6238\n",
      "[164/1762] D loss: 0.0101, G loss: 7.9079\n",
      "[244/1762] D loss: 1.1699, G loss: 1.1981\n",
      "[324/1762] D loss: 1.4326, G loss: 0.8498\n",
      "[404/1762] D loss: 1.3856, G loss: 0.6244\n",
      "[484/1762] D loss: 1.4710, G loss: 0.7990\n",
      "[564/1762] D loss: 1.3344, G loss: 0.6610\n",
      "[644/1762] D loss: 0.0051, G loss: 8.4281\n",
      "[724/1762] D loss: 1.3941, G loss: 0.6496\n",
      "[804/1762] D loss: 0.9501, G loss: 3.2013\n",
      "[884/1762] D loss: 1.3913, G loss: 0.6380\n",
      "[964/1762] D loss: 1.1953, G loss: 1.4650\n",
      "[1044/1762] D loss: 0.5465, G loss: 1.1616\n",
      "[1124/1762] D loss: 1.3980, G loss: 0.6336\n",
      "[1204/1762] D loss: 1.3922, G loss: 0.6068\n",
      "[1284/1762] D loss: 0.0749, G loss: 3.5141\n",
      "[1364/1762] D loss: 1.4007, G loss: 0.5903\n",
      "[1444/1762] D loss: 1.3886, G loss: 0.8870\n",
      "[1524/1762] D loss: 1.3953, G loss: 0.7711\n",
      "[1604/1762] D loss: 0.0035, G loss: 6.5966\n",
      "[1684/1762] D loss: 1.4141, G loss: 0.7807\n",
      "[1762/1762] D loss: 1.3944, G loss: 0.7810\n",
      "train error: \n",
      " D loss: 2.823032, G loss: 0.459807, D accuracy: 49.9%, cell accuracy: 99.8%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 3.064406, G loss: 0.479537, D accuracy: 50.0%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0036, G loss: 5.9591\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6696\n",
      "[164/1762] D loss: 1.5596, G loss: 0.8025\n",
      "[244/1762] D loss: 0.0000, G loss: 16.1749\n",
      "[324/1762] D loss: 0.0336, G loss: 4.2667\n",
      "[404/1762] D loss: 1.3902, G loss: 0.7378\n",
      "[484/1762] D loss: 1.3884, G loss: 0.6618\n",
      "[564/1762] D loss: 1.3877, G loss: 0.6636\n",
      "[644/1762] D loss: 1.3890, G loss: 0.7211\n",
      "[724/1762] D loss: 0.0115, G loss: 4.6378\n",
      "[804/1762] D loss: 1.3865, G loss: 0.6876\n",
      "[884/1762] D loss: 1.2386, G loss: 1.2482\n",
      "[964/1762] D loss: 1.3883, G loss: 0.7274\n",
      "[1044/1762] D loss: 1.3868, G loss: 0.6834\n",
      "[1124/1762] D loss: 1.3878, G loss: 0.7248\n",
      "[1204/1762] D loss: 1.3983, G loss: 0.7605\n",
      "[1284/1762] D loss: 1.3879, G loss: 0.6673\n",
      "[1364/1762] D loss: 1.3860, G loss: 0.7264\n",
      "[1444/1762] D loss: 0.0020, G loss: 6.7280\n",
      "[1524/1762] D loss: 1.3885, G loss: 0.6617\n",
      "[1604/1762] D loss: 1.3898, G loss: 0.6945\n",
      "[1684/1762] D loss: 0.0035, G loss: 6.1787\n",
      "[1762/1762] D loss: 1.3888, G loss: 0.6525\n",
      "train error: \n",
      " D loss: 3.682076, G loss: 0.664633, D accuracy: 50.0%, cell accuracy: 99.8%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 4.211097, G loss: 0.691247, D accuracy: 50.0%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3882, G loss: 0.6539\n",
      "[84/1762] D loss: 0.1181, G loss: 6.8318\n",
      "[164/1762] D loss: 0.0125, G loss: 5.4589\n",
      "[244/1762] D loss: 1.3877, G loss: 0.6677\n",
      "[324/1762] D loss: 1.3969, G loss: 0.5962\n",
      "[404/1762] D loss: 1.3895, G loss: 0.7538\n",
      "[484/1762] D loss: 1.3450, G loss: 0.7423\n",
      "[564/1762] D loss: 0.0049, G loss: 4.9127\n",
      "[644/1762] D loss: 1.4330, G loss: 0.8582\n",
      "[724/1762] D loss: 1.3899, G loss: 0.6703\n",
      "[804/1762] D loss: 1.3918, G loss: 0.7706\n",
      "[884/1762] D loss: 1.4189, G loss: 0.7197\n",
      "[964/1762] D loss: 0.0105, G loss: 5.2696\n",
      "[1044/1762] D loss: 1.1805, G loss: 1.2160\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6992\n",
      "[1204/1762] D loss: 1.3895, G loss: 0.6402\n",
      "[1284/1762] D loss: 1.3871, G loss: 0.7025\n",
      "[1364/1762] D loss: 1.3976, G loss: 0.6132\n",
      "[1444/1762] D loss: 1.3872, G loss: 0.7247\n",
      "[1524/1762] D loss: 1.3861, G loss: 0.7110\n",
      "[1604/1762] D loss: 0.0003, G loss: 9.5382\n",
      "[1684/1762] D loss: 1.6387, G loss: 0.6500\n",
      "[1762/1762] D loss: 1.3929, G loss: 0.7809\n",
      "train error: \n",
      " D loss: 3.427241, G loss: 0.685819, D accuracy: 50.2%, cell accuracy: 99.8%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 3.841479, G loss: 0.706675, D accuracy: 50.1%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3875, G loss: 0.7296\n",
      "[84/1762] D loss: 0.0000, G loss: 27.2363\n",
      "[164/1762] D loss: 1.3912, G loss: 0.6304\n",
      "[244/1762] D loss: 1.3880, G loss: 0.6491\n",
      "[324/1762] D loss: 1.3901, G loss: 0.7525\n",
      "[404/1762] D loss: 0.0055, G loss: 5.9655\n",
      "[484/1762] D loss: 1.3909, G loss: 0.6328\n",
      "[564/1762] D loss: 1.3874, G loss: 0.7232\n",
      "[644/1762] D loss: 1.3869, G loss: 0.6878\n",
      "[724/1762] D loss: 1.3887, G loss: 0.6487\n",
      "[804/1762] D loss: 0.0048, G loss: 5.3750\n",
      "[884/1762] D loss: 0.0062, G loss: 6.1449\n",
      "[964/1762] D loss: 1.3860, G loss: 0.6583\n",
      "[1044/1762] D loss: 1.3914, G loss: 0.7792\n",
      "[1124/1762] D loss: 1.3902, G loss: 0.7219\n",
      "[1204/1762] D loss: 1.3845, G loss: 0.7053\n",
      "[1284/1762] D loss: 1.3865, G loss: 0.6962\n",
      "[1364/1762] D loss: 1.3192, G loss: 0.8000\n",
      "[1444/1762] D loss: 1.3873, G loss: 0.7177\n",
      "[1524/1762] D loss: 0.0036, G loss: 6.8809\n",
      "[1604/1762] D loss: 1.3944, G loss: 0.6154\n",
      "[1684/1762] D loss: 0.0026, G loss: 6.2316\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.7032\n",
      "train error: \n",
      " D loss: 3.420449, G loss: 0.524640, D accuracy: 50.1%, cell accuracy: 99.9%, board accuracy: 92.8% \n",
      "\n",
      "test error: \n",
      " D loss: 3.857054, G loss: 0.557829, D accuracy: 50.3%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3901, G loss: 0.6713\n",
      "[84/1762] D loss: 0.0086, G loss: 4.8516\n",
      "[164/1762] D loss: 1.3916, G loss: 0.7783\n",
      "[244/1762] D loss: 0.0542, G loss: 4.5071\n",
      "[324/1762] D loss: 1.3878, G loss: 0.6726\n",
      "[404/1762] D loss: 1.3867, G loss: 0.6908\n",
      "[484/1762] D loss: 0.0000, G loss: 15.8711\n",
      "[564/1762] D loss: 1.3866, G loss: 0.7006\n",
      "[644/1762] D loss: 1.3866, G loss: 0.7067\n",
      "[724/1762] D loss: 1.3885, G loss: 0.6537\n",
      "[804/1762] D loss: 1.3865, G loss: 0.6998\n",
      "[884/1762] D loss: 1.3865, G loss: 0.6959\n",
      "[964/1762] D loss: 0.0019, G loss: 7.1120\n",
      "[1044/1762] D loss: 0.0007, G loss: 7.8133\n",
      "[1124/1762] D loss: 1.3874, G loss: 0.7220\n",
      "[1204/1762] D loss: 0.0008, G loss: 7.4895\n",
      "[1284/1762] D loss: 1.3868, G loss: 0.6893\n",
      "[1364/1762] D loss: 0.0007, G loss: 7.8644\n",
      "[1444/1762] D loss: 1.3866, G loss: 0.6956\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.7090\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6983\n",
      "[1684/1762] D loss: 1.3877, G loss: 0.6579\n",
      "[1762/1762] D loss: 1.3868, G loss: 0.7153\n",
      "train error: \n",
      " D loss: 3.697716, G loss: 0.729158, D accuracy: 50.0%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 4.210973, G loss: 0.769070, D accuracy: 50.2%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3866, G loss: 0.7074\n",
      "[84/1762] D loss: 1.3868, G loss: 0.6846\n",
      "[164/1762] D loss: 1.4573, G loss: 0.7339\n",
      "[244/1762] D loss: 1.3871, G loss: 0.6780\n",
      "[324/1762] D loss: 0.0367, G loss: 3.5547\n",
      "[404/1762] D loss: 0.0000, G loss: 18.2934\n",
      "[484/1762] D loss: 1.3684, G loss: 0.6863\n",
      "[564/1762] D loss: 1.3871, G loss: 0.6859\n",
      "[644/1762] D loss: 0.0000, G loss: 18.4788\n",
      "[724/1762] D loss: 1.3868, G loss: 0.6898\n",
      "[804/1762] D loss: 1.3879, G loss: 0.6700\n",
      "[884/1762] D loss: 0.0007, G loss: 7.6650\n",
      "[964/1762] D loss: 1.3866, G loss: 0.6698\n",
      "[1044/1762] D loss: 1.3865, G loss: 0.7104\n",
      "[1124/1762] D loss: 1.3867, G loss: 0.6902\n",
      "[1204/1762] D loss: 0.0018, G loss: 6.8697\n",
      "[1284/1762] D loss: 1.3874, G loss: 0.6819\n",
      "[1364/1762] D loss: 0.0044, G loss: 7.8851\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6961\n",
      "[1524/1762] D loss: 1.3912, G loss: 0.6420\n",
      "[1604/1762] D loss: 1.3869, G loss: 0.7073\n",
      "[1684/1762] D loss: 1.3869, G loss: 0.6886\n",
      "[1762/1762] D loss: 1.3855, G loss: 0.6957\n",
      "train error: \n",
      " D loss: 3.623771, G loss: 0.693035, D accuracy: 50.0%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 4.134066, G loss: 0.726858, D accuracy: 50.0%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3870, G loss: 0.6796\n",
      "[84/1762] D loss: 1.3858, G loss: 0.6922\n",
      "[164/1762] D loss: 1.3867, G loss: 0.6782\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6908\n",
      "[324/1762] D loss: 1.3866, G loss: 0.6912\n",
      "[404/1762] D loss: 1.3869, G loss: 0.6701\n",
      "[484/1762] D loss: 1.3869, G loss: 0.7088\n",
      "[564/1762] D loss: 1.3865, G loss: 0.6992\n",
      "[644/1762] D loss: 0.0013, G loss: 7.1161\n",
      "[724/1762] D loss: 1.3866, G loss: 0.6784\n",
      "[804/1762] D loss: 0.0083, G loss: 5.0300\n",
      "[884/1762] D loss: 0.0031, G loss: 6.1108\n",
      "[964/1762] D loss: 1.3864, G loss: 0.6788\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.7026\n",
      "[1124/1762] D loss: 1.3888, G loss: 0.6889\n",
      "[1204/1762] D loss: 1.5422, G loss: 0.7103\n",
      "[1284/1762] D loss: 1.3873, G loss: 0.7302\n",
      "[1364/1762] D loss: 1.3883, G loss: 0.6468\n",
      "[1444/1762] D loss: 0.0000, G loss: 18.8396\n",
      "[1524/1762] D loss: 1.3869, G loss: 0.6707\n",
      "[1604/1762] D loss: 1.5221, G loss: 0.7084\n",
      "[1684/1762] D loss: 1.3875, G loss: 0.7250\n",
      "[1762/1762] D loss: 0.0000, G loss: 12.9371\n",
      "train error: \n",
      " D loss: 3.061392, G loss: 0.436965, D accuracy: 49.7%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 3.237397, G loss: 0.480975, D accuracy: 49.8%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3900, G loss: 0.6396\n",
      "[84/1762] D loss: 0.0249, G loss: 4.3227\n",
      "[164/1762] D loss: 1.3875, G loss: 0.7242\n",
      "[244/1762] D loss: 1.3869, G loss: 0.6838\n",
      "[324/1762] D loss: 1.3938, G loss: 0.6198\n",
      "[404/1762] D loss: 1.3869, G loss: 0.7059\n",
      "[484/1762] D loss: 1.3865, G loss: 0.6944\n",
      "[564/1762] D loss: 1.3872, G loss: 0.7221\n",
      "[644/1762] D loss: 1.3869, G loss: 0.6828\n",
      "[724/1762] D loss: 1.4151, G loss: 0.7644\n",
      "[804/1762] D loss: 1.3879, G loss: 0.7277\n",
      "[884/1762] D loss: 1.3915, G loss: 0.7517\n",
      "[964/1762] D loss: 0.0000, G loss: 16.5006\n",
      "[1044/1762] D loss: 1.3871, G loss: 0.6613\n",
      "[1124/1762] D loss: 1.3965, G loss: 0.8134\n",
      "[1204/1762] D loss: 1.3867, G loss: 0.7110\n",
      "[1284/1762] D loss: 1.3881, G loss: 0.7195\n",
      "[1364/1762] D loss: 0.0079, G loss: 7.1539\n",
      "[1444/1762] D loss: 1.3869, G loss: 0.6785\n",
      "[1524/1762] D loss: 1.3862, G loss: 0.6914\n",
      "[1604/1762] D loss: 1.3923, G loss: 0.7813\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6907\n",
      "[1762/1762] D loss: 1.3716, G loss: 0.6863\n",
      "train error: \n",
      " D loss: 4.032745, G loss: 0.284304, D accuracy: 49.9%, cell accuracy: 99.9%, board accuracy: 92.8% \n",
      "\n",
      "test error: \n",
      " D loss: 4.131360, G loss: 0.339327, D accuracy: 49.9%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3883, G loss: 0.6901\n",
      "[84/1762] D loss: 0.0028, G loss: 7.2182\n",
      "[164/1762] D loss: 1.3865, G loss: 0.6894\n",
      "[244/1762] D loss: 1.3864, G loss: 0.6939\n",
      "[324/1762] D loss: 1.3933, G loss: 0.6154\n",
      "[404/1762] D loss: 1.3903, G loss: 0.7567\n",
      "[484/1762] D loss: 1.3869, G loss: 0.6727\n",
      "[564/1762] D loss: 1.3867, G loss: 0.6849\n",
      "[644/1762] D loss: 1.0582, G loss: 2.3284\n",
      "[724/1762] D loss: 1.1703, G loss: 2.0653\n",
      "[804/1762] D loss: 1.4222, G loss: 0.7438\n",
      "[884/1762] D loss: 0.0090, G loss: 6.0305\n",
      "[964/1762] D loss: 1.4561, G loss: 0.4765\n",
      "[1044/1762] D loss: 0.1045, G loss: 5.1658\n",
      "[1124/1762] D loss: 1.3907, G loss: 0.7119\n",
      "[1204/1762] D loss: 0.3279, G loss: 1.3254\n",
      "[1284/1762] D loss: 1.4216, G loss: 0.8789\n",
      "[1364/1762] D loss: 1.3874, G loss: 0.6803\n",
      "[1444/1762] D loss: 0.0075, G loss: 5.7889\n",
      "[1524/1762] D loss: 0.0123, G loss: 6.8157\n",
      "[1604/1762] D loss: 0.0018, G loss: 6.9208\n",
      "[1684/1762] D loss: 1.3907, G loss: 0.6313\n",
      "[1762/1762] D loss: 1.3928, G loss: 0.6239\n",
      "train error: \n",
      " D loss: 3.951272, G loss: 0.457329, D accuracy: 49.4%, cell accuracy: 99.8%, board accuracy: 91.0% \n",
      "\n",
      "test error: \n",
      " D loss: 4.220817, G loss: 0.539200, D accuracy: 49.4%, cell accuracy: 99.7%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3885, G loss: 0.6791\n",
      "[84/1762] D loss: 0.0059, G loss: 5.5488\n",
      "[164/1762] D loss: 1.3873, G loss: 0.7098\n",
      "[244/1762] D loss: 1.3961, G loss: 0.7419\n",
      "[324/1762] D loss: 1.4272, G loss: 0.5241\n",
      "[404/1762] D loss: 1.4223, G loss: 0.8757\n",
      "[484/1762] D loss: 0.3826, G loss: 1.9870\n",
      "[564/1762] D loss: 1.3972, G loss: 0.7923\n",
      "[644/1762] D loss: 1.4006, G loss: 0.6936\n",
      "[724/1762] D loss: 1.3766, G loss: 0.7159\n",
      "[804/1762] D loss: 1.3891, G loss: 0.7337\n",
      "[884/1762] D loss: 1.4121, G loss: 0.5688\n",
      "[964/1762] D loss: 1.3956, G loss: 0.7229\n",
      "[1044/1762] D loss: 1.4042, G loss: 0.7995\n",
      "[1124/1762] D loss: 1.4524, G loss: 0.9390\n",
      "[1204/1762] D loss: 1.3880, G loss: 0.7401\n",
      "[1284/1762] D loss: 1.3903, G loss: 0.6957\n",
      "[1364/1762] D loss: 1.4121, G loss: 0.7954\n",
      "[1444/1762] D loss: 1.3868, G loss: 0.6548\n",
      "[1524/1762] D loss: 1.4002, G loss: 0.7833\n",
      "[1604/1762] D loss: 1.0946, G loss: 1.3908\n",
      "[1684/1762] D loss: 1.3912, G loss: 0.7348\n",
      "[1762/1762] D loss: 1.4114, G loss: 0.7864\n",
      "train error: \n",
      " D loss: 4.319837, G loss: 0.882379, D accuracy: 50.0%, cell accuracy: 99.8%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 4.946692, G loss: 1.003336, D accuracy: 50.0%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4201, G loss: 0.7747\n",
      "[84/1762] D loss: 1.3902, G loss: 0.6885\n",
      "[164/1762] D loss: 1.3948, G loss: 0.7368\n",
      "[244/1762] D loss: 1.3971, G loss: 0.6592\n",
      "[324/1762] D loss: 0.1106, G loss: 3.1010\n",
      "[404/1762] D loss: 0.1209, G loss: 2.8685\n",
      "[484/1762] D loss: 1.3980, G loss: 0.8040\n",
      "[564/1762] D loss: 0.1356, G loss: 2.9328\n",
      "[644/1762] D loss: 1.3882, G loss: 0.6675\n",
      "[724/1762] D loss: 1.4099, G loss: 0.7240\n",
      "[804/1762] D loss: 1.3894, G loss: 0.7268\n",
      "[884/1762] D loss: 1.3879, G loss: 0.6950\n",
      "[964/1762] D loss: 1.3895, G loss: 0.6498\n",
      "[1044/1762] D loss: 1.3869, G loss: 0.7029\n",
      "[1124/1762] D loss: 1.3884, G loss: 0.6707\n",
      "[1204/1762] D loss: 1.4430, G loss: 0.8271\n",
      "[1284/1762] D loss: 1.3938, G loss: 0.7352\n",
      "[1364/1762] D loss: 1.3871, G loss: 0.6969\n",
      "[1444/1762] D loss: 1.4032, G loss: 0.8118\n",
      "[1524/1762] D loss: 1.3895, G loss: 0.6957\n",
      "[1604/1762] D loss: 0.1374, G loss: 2.3186\n",
      "[1684/1762] D loss: 1.3885, G loss: 0.6883\n",
      "[1762/1762] D loss: 1.3844, G loss: 0.7077\n",
      "train error: \n",
      " D loss: 4.677479, G loss: 0.756076, D accuracy: 50.0%, cell accuracy: 99.8%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 5.363503, G loss: 0.879666, D accuracy: 49.9%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0010, G loss: 13.5735\n",
      "[84/1762] D loss: 1.3959, G loss: 0.7192\n",
      "[164/1762] D loss: 0.0529, G loss: 3.8033\n",
      "[244/1762] D loss: 1.3893, G loss: 0.6786\n",
      "[324/1762] D loss: 0.0247, G loss: 4.2568\n",
      "[404/1762] D loss: 0.0567, G loss: 3.9317\n",
      "[484/1762] D loss: 1.3891, G loss: 0.6767\n",
      "[564/1762] D loss: 1.3871, G loss: 0.7211\n",
      "[644/1762] D loss: 1.3858, G loss: 0.6985\n",
      "[724/1762] D loss: 1.3881, G loss: 0.6875\n",
      "[804/1762] D loss: 1.3927, G loss: 0.6446\n",
      "[884/1762] D loss: 0.0073, G loss: 5.9071\n",
      "[964/1762] D loss: 1.3879, G loss: 0.6593\n",
      "[1044/1762] D loss: 1.3902, G loss: 0.6536\n",
      "[1124/1762] D loss: 0.0004, G loss: 17.1485\n",
      "[1204/1762] D loss: 1.3951, G loss: 0.6225\n",
      "[1284/1762] D loss: 0.0000, G loss: 20.0652\n",
      "[1364/1762] D loss: 1.3872, G loss: 0.6875\n",
      "[1444/1762] D loss: 1.3861, G loss: 0.6898\n",
      "[1524/1762] D loss: 1.3856, G loss: 0.7015\n",
      "[1604/1762] D loss: 0.0013, G loss: 8.1804\n",
      "[1684/1762] D loss: 0.0224, G loss: 6.4897\n",
      "[1762/1762] D loss: 1.4001, G loss: 0.8274\n",
      "train error: \n",
      " D loss: 3.760233, G loss: 0.642506, D accuracy: 49.9%, cell accuracy: 99.8%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 4.073283, G loss: 0.755020, D accuracy: 50.0%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3962, G loss: 0.7191\n",
      "[84/1762] D loss: 1.3905, G loss: 0.6210\n",
      "[164/1762] D loss: 0.0190, G loss: 4.5255\n",
      "[244/1762] D loss: 1.3905, G loss: 0.7495\n",
      "[324/1762] D loss: 1.3957, G loss: 0.6289\n",
      "[404/1762] D loss: 1.3888, G loss: 0.7480\n",
      "[484/1762] D loss: 1.3881, G loss: 0.6817\n",
      "[564/1762] D loss: 1.3834, G loss: 0.7103\n",
      "[644/1762] D loss: 1.4751, G loss: 0.8518\n",
      "[724/1762] D loss: 0.0328, G loss: 6.2894\n",
      "[804/1762] D loss: 0.0029, G loss: 6.3905\n",
      "[884/1762] D loss: 1.3884, G loss: 0.7391\n",
      "[964/1762] D loss: 1.3870, G loss: 0.6785\n",
      "[1044/1762] D loss: 1.3904, G loss: 0.6638\n",
      "[1124/1762] D loss: 1.3875, G loss: 0.7065\n",
      "[1204/1762] D loss: 1.3879, G loss: 0.6950\n",
      "[1284/1762] D loss: 1.3973, G loss: 0.7492\n",
      "[1364/1762] D loss: 0.0018, G loss: 6.4781\n",
      "[1444/1762] D loss: 1.3918, G loss: 0.7492\n",
      "[1524/1762] D loss: 1.3866, G loss: 0.6770\n",
      "[1604/1762] D loss: 1.3856, G loss: 0.6826\n",
      "[1684/1762] D loss: 1.3950, G loss: 0.7890\n",
      "[1762/1762] D loss: 1.4073, G loss: 0.8158\n",
      "train error: \n",
      " D loss: 4.989974, G loss: 1.094802, D accuracy: 50.1%, cell accuracy: 99.8%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 5.788786, G loss: 1.205381, D accuracy: 49.8%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4527, G loss: 0.8690\n",
      "[84/1762] D loss: 0.0000, G loss: 17.5890\n",
      "[164/1762] D loss: 1.3901, G loss: 0.7238\n",
      "[244/1762] D loss: 1.3870, G loss: 0.6935\n",
      "[324/1762] D loss: 0.0046, G loss: 6.9045\n",
      "[404/1762] D loss: 1.3871, G loss: 0.6545\n",
      "[484/1762] D loss: 1.2993, G loss: 0.8484\n",
      "[564/1762] D loss: 1.4145, G loss: 0.7373\n",
      "[644/1762] D loss: 0.0493, G loss: 6.0022\n",
      "[724/1762] D loss: 1.3906, G loss: 0.7521\n",
      "[804/1762] D loss: 0.0014, G loss: 8.2202\n",
      "[884/1762] D loss: 1.3889, G loss: 0.6443\n",
      "[964/1762] D loss: 1.3869, G loss: 0.6812\n",
      "[1044/1762] D loss: 1.3402, G loss: 0.7881\n",
      "[1124/1762] D loss: 1.3870, G loss: 0.6890\n",
      "[1204/1762] D loss: 1.3872, G loss: 0.7112\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6838\n",
      "[1364/1762] D loss: 0.0009, G loss: 11.3922\n",
      "[1444/1762] D loss: 1.3855, G loss: 0.6996\n",
      "[1524/1762] D loss: 1.3874, G loss: 0.6531\n",
      "[1604/1762] D loss: 1.4035, G loss: 0.8499\n",
      "[1684/1762] D loss: 0.0728, G loss: 4.7855\n",
      "[1762/1762] D loss: 1.1287, G loss: 1.8235\n",
      "train error: \n",
      " D loss: 4.327172, G loss: 0.957609, D accuracy: 51.6%, cell accuracy: 99.7%, board accuracy: 85.3% \n",
      "\n",
      "test error: \n",
      " D loss: 4.994331, G loss: 1.107781, D accuracy: 52.0%, cell accuracy: 99.6%, board accuracy: 81.4% \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3871, G loss: 0.6309\n",
      "[84/1762] D loss: 1.3727, G loss: 0.6614\n",
      "[164/1762] D loss: 1.4891, G loss: 0.7955\n",
      "[244/1762] D loss: 0.0909, G loss: 4.5769\n",
      "[324/1762] D loss: 1.3872, G loss: 0.7138\n",
      "[404/1762] D loss: 1.3867, G loss: 0.6872\n",
      "[484/1762] D loss: 1.3866, G loss: 0.7128\n",
      "[564/1762] D loss: 1.3877, G loss: 0.7323\n",
      "[644/1762] D loss: 1.2762, G loss: 1.3905\n",
      "[724/1762] D loss: 0.0027, G loss: 7.0415\n",
      "[804/1762] D loss: 1.3903, G loss: 0.7368\n",
      "[884/1762] D loss: 1.6054, G loss: 0.7501\n",
      "[964/1762] D loss: 1.3900, G loss: 0.6699\n",
      "[1044/1762] D loss: 1.4178, G loss: 0.7088\n",
      "[1124/1762] D loss: 1.4251, G loss: 0.7313\n",
      "[1204/1762] D loss: 1.3939, G loss: 0.7460\n",
      "[1284/1762] D loss: 1.4647, G loss: 0.9236\n",
      "[1364/1762] D loss: 0.1558, G loss: 4.1743\n",
      "[1444/1762] D loss: 1.3869, G loss: 0.7176\n",
      "[1524/1762] D loss: 1.3870, G loss: 0.6611\n",
      "[1604/1762] D loss: 0.3174, G loss: 1.8605\n",
      "[1684/1762] D loss: 0.1350, G loss: 3.3536\n",
      "[1762/1762] D loss: 1.3942, G loss: 0.7679\n",
      "train error: \n",
      " D loss: 3.286295, G loss: 1.144042, D accuracy: 50.5%, cell accuracy: 99.8%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 3.671118, G loss: 1.279820, D accuracy: 50.3%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2041, G loss: 2.0516\n",
      "[84/1762] D loss: 1.3865, G loss: 0.7021\n",
      "[164/1762] D loss: 1.3888, G loss: 0.6439\n",
      "[244/1762] D loss: 0.0057, G loss: 6.4748\n",
      "[324/1762] D loss: 0.0019, G loss: 6.5859\n",
      "[404/1762] D loss: 1.3875, G loss: 0.6764\n",
      "[484/1762] D loss: 1.4141, G loss: 0.7888\n",
      "[564/1762] D loss: 0.0023, G loss: 7.1199\n",
      "[644/1762] D loss: 0.0088, G loss: 8.2694\n",
      "[724/1762] D loss: 0.0752, G loss: 3.5370\n",
      "[804/1762] D loss: 1.3868, G loss: 0.6761\n",
      "[884/1762] D loss: 1.3852, G loss: 0.6856\n",
      "[964/1762] D loss: 0.0044, G loss: 7.4168\n",
      "[1044/1762] D loss: 1.3868, G loss: 0.6831\n",
      "[1124/1762] D loss: 1.3781, G loss: 0.7001\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6754\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6852\n",
      "[1364/1762] D loss: 0.1630, G loss: 4.2326\n",
      "[1444/1762] D loss: 1.3868, G loss: 0.6797\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.6816\n",
      "[1604/1762] D loss: 1.3865, G loss: 0.6824\n",
      "[1684/1762] D loss: 1.2851, G loss: 0.9857\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6914\n",
      "train error: \n",
      " D loss: 5.729413, G loss: 1.146771, D accuracy: 50.1%, cell accuracy: 99.8%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 6.765950, G loss: 1.295748, D accuracy: 49.9%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3873, G loss: 0.6898\n",
      "[84/1762] D loss: 1.3869, G loss: 0.6685\n",
      "[164/1762] D loss: 1.6892, G loss: 0.7188\n",
      "[244/1762] D loss: 1.3863, G loss: 0.7017\n",
      "[324/1762] D loss: 1.3867, G loss: 0.6714\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6927\n",
      "[484/1762] D loss: 0.0434, G loss: 5.2644\n",
      "[564/1762] D loss: 0.0053, G loss: 6.6000\n",
      "[644/1762] D loss: 1.3888, G loss: 0.7173\n",
      "[724/1762] D loss: 0.0010, G loss: 7.5569\n",
      "[804/1762] D loss: 0.0020, G loss: 6.9882\n",
      "[884/1762] D loss: 0.0003, G loss: 8.6117\n",
      "[964/1762] D loss: 1.3869, G loss: 0.6787\n",
      "[1044/1762] D loss: 1.3879, G loss: 0.6943\n",
      "[1124/1762] D loss: 1.3840, G loss: 0.6812\n",
      "[1204/1762] D loss: 0.0004, G loss: 8.5129\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6898\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6913\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6802\n",
      "[1524/1762] D loss: 1.3866, G loss: 0.6963\n",
      "[1604/1762] D loss: 1.4063, G loss: 0.7574\n",
      "[1684/1762] D loss: 1.3867, G loss: 0.6786\n",
      "[1762/1762] D loss: 1.3860, G loss: 0.6912\n",
      "train error: \n",
      " D loss: 3.152860, G loss: 1.123077, D accuracy: 50.0%, cell accuracy: 99.8%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 3.467803, G loss: 1.302864, D accuracy: 50.0%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3865, G loss: 0.6925\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6985\n",
      "[164/1762] D loss: 1.3883, G loss: 0.6967\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6859\n",
      "[324/1762] D loss: 1.3865, G loss: 0.6886\n",
      "[404/1762] D loss: 0.0047, G loss: 6.3000\n",
      "[484/1762] D loss: 0.0032, G loss: 7.0131\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6891\n",
      "[644/1762] D loss: 1.4147, G loss: 0.7662\n",
      "[724/1762] D loss: 1.3871, G loss: 0.6780\n",
      "[804/1762] D loss: 0.0011, G loss: 7.3580\n",
      "[884/1762] D loss: 1.3862, G loss: 0.6751\n",
      "[964/1762] D loss: 0.0001, G loss: 10.3149\n",
      "[1044/1762] D loss: 0.0025, G loss: 6.6593\n",
      "[1124/1762] D loss: 0.0013, G loss: 11.4396\n",
      "[1204/1762] D loss: 0.0041, G loss: 7.6679\n",
      "[1284/1762] D loss: 1.3908, G loss: 0.7183\n",
      "[1364/1762] D loss: 1.3868, G loss: 0.6736\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.7140\n",
      "[1524/1762] D loss: 1.3862, G loss: 0.6948\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6961\n",
      "[1684/1762] D loss: 1.3871, G loss: 0.7161\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.7010\n",
      "train error: \n",
      " D loss: 3.285613, G loss: 1.108971, D accuracy: 50.4%, cell accuracy: 99.8%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 3.668657, G loss: 1.267709, D accuracy: 50.2%, cell accuracy: 99.7%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0016, G loss: 8.9258\n",
      "[84/1762] D loss: 1.3866, G loss: 0.6663\n",
      "[164/1762] D loss: 1.3902, G loss: 0.6577\n",
      "[244/1762] D loss: 1.4213, G loss: 0.7912\n",
      "[324/1762] D loss: 1.3897, G loss: 0.6414\n",
      "[404/1762] D loss: 1.3867, G loss: 0.6895\n",
      "[484/1762] D loss: 1.3864, G loss: 0.6965\n",
      "[564/1762] D loss: 1.3867, G loss: 0.7016\n",
      "[644/1762] D loss: 1.3881, G loss: 0.6965\n",
      "[724/1762] D loss: 1.3866, G loss: 0.6992\n",
      "[804/1762] D loss: 1.3866, G loss: 0.6836\n",
      "[884/1762] D loss: 1.3916, G loss: 0.6633\n",
      "[964/1762] D loss: 1.3607, G loss: 1.3787\n",
      "[1044/1762] D loss: 0.0001, G loss: 12.1345\n",
      "[1124/1762] D loss: 1.3880, G loss: 0.6675\n",
      "[1204/1762] D loss: 1.3874, G loss: 0.6661\n",
      "[1284/1762] D loss: 1.3867, G loss: 0.7046\n",
      "[1364/1762] D loss: 1.3867, G loss: 0.6841\n",
      "[1444/1762] D loss: 1.4688, G loss: 0.8888\n",
      "[1524/1762] D loss: 1.3866, G loss: 0.6761\n",
      "[1604/1762] D loss: 1.3865, G loss: 0.6961\n",
      "[1684/1762] D loss: 1.3866, G loss: 0.6858\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.7115\n",
      "train error: \n",
      " D loss: 2.757381, G loss: 1.101262, D accuracy: 49.9%, cell accuracy: 99.7%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 3.070276, G loss: 1.229286, D accuracy: 49.8%, cell accuracy: 99.6%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3845, G loss: 0.6881\n",
      "[84/1762] D loss: 0.0694, G loss: 10.1585\n",
      "[164/1762] D loss: 1.3809, G loss: 0.7057\n",
      "[244/1762] D loss: 0.0016, G loss: 9.9084\n",
      "[324/1762] D loss: 1.3866, G loss: 0.6874\n",
      "[404/1762] D loss: 0.4153, G loss: 1.8571\n",
      "[484/1762] D loss: 0.0817, G loss: 5.7127\n",
      "[564/1762] D loss: 1.3935, G loss: 0.7380\n",
      "[644/1762] D loss: 1.3866, G loss: 0.7149\n",
      "[724/1762] D loss: 1.3891, G loss: 0.7437\n",
      "[804/1762] D loss: 0.0390, G loss: 6.8105\n",
      "[884/1762] D loss: 1.3868, G loss: 0.7106\n",
      "[964/1762] D loss: 1.3872, G loss: 0.7109\n",
      "[1044/1762] D loss: 0.1076, G loss: 4.1316\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6900\n",
      "[1204/1762] D loss: 0.2326, G loss: 4.4785\n",
      "[1284/1762] D loss: 0.0327, G loss: 6.8858\n",
      "[1364/1762] D loss: 0.0014, G loss: 9.7510\n",
      "[1444/1762] D loss: 1.3866, G loss: 0.6797\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.6967\n",
      "[1604/1762] D loss: 1.3865, G loss: 0.6804\n",
      "[1684/1762] D loss: 1.3870, G loss: 0.7204\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6883\n",
      "train error: \n",
      " D loss: 2.976594, G loss: 1.116761, D accuracy: 50.1%, cell accuracy: 99.8%, board accuracy: 92.8% \n",
      "\n",
      "test error: \n",
      " D loss: 3.308733, G loss: 1.253413, D accuracy: 50.2%, cell accuracy: 99.7%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.7047\n",
      "[84/1762] D loss: 1.3877, G loss: 0.7347\n",
      "[164/1762] D loss: 1.3870, G loss: 0.7347\n",
      "[244/1762] D loss: 1.3867, G loss: 0.6893\n",
      "[324/1762] D loss: 0.0014, G loss: 8.1964\n",
      "[404/1762] D loss: 1.3863, G loss: 0.6910\n",
      "[484/1762] D loss: 1.3877, G loss: 0.6968\n",
      "[564/1762] D loss: 1.3874, G loss: 0.6663\n",
      "[644/1762] D loss: 0.0001, G loss: 17.0779\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6945\n",
      "[804/1762] D loss: 1.3867, G loss: 0.6990\n",
      "[884/1762] D loss: 1.3867, G loss: 0.6792\n",
      "[964/1762] D loss: 1.3864, G loss: 0.6827\n",
      "[1044/1762] D loss: 0.0037, G loss: 7.4862\n",
      "[1124/1762] D loss: 0.0051, G loss: 6.8044\n",
      "[1204/1762] D loss: 0.0066, G loss: 7.8869\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6990\n",
      "[1364/1762] D loss: 0.0001, G loss: 10.3552\n",
      "[1444/1762] D loss: 1.3444, G loss: 0.7408\n",
      "[1524/1762] D loss: 1.3877, G loss: 0.6548\n",
      "[1604/1762] D loss: 0.0002, G loss: 10.0307\n",
      "[1684/1762] D loss: 1.3966, G loss: 0.7335\n",
      "[1762/1762] D loss: 1.3771, G loss: 0.6833\n",
      "train error: \n",
      " D loss: 3.713999, G loss: 1.110891, D accuracy: 50.1%, cell accuracy: 99.7%, board accuracy: 90.9% \n",
      "\n",
      "test error: \n",
      " D loss: 4.284763, G loss: 1.266433, D accuracy: 50.6%, cell accuracy: 99.6%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3897, G loss: 0.7226\n",
      "[84/1762] D loss: 0.0001, G loss: 10.0629\n",
      "[164/1762] D loss: 1.3875, G loss: 0.6667\n",
      "[244/1762] D loss: 1.3864, G loss: 0.6901\n",
      "[324/1762] D loss: 1.3917, G loss: 0.7310\n",
      "[404/1762] D loss: 1.3872, G loss: 0.6753\n",
      "[484/1762] D loss: 0.0005, G loss: 8.0935\n",
      "[564/1762] D loss: 0.0005, G loss: 8.2035\n",
      "[644/1762] D loss: 1.3859, G loss: 0.6888\n",
      "[724/1762] D loss: 0.0005, G loss: 8.4415\n",
      "[804/1762] D loss: 1.3868, G loss: 0.6657\n",
      "[884/1762] D loss: 1.3875, G loss: 0.6908\n",
      "[964/1762] D loss: 0.0006, G loss: 8.1778\n",
      "[1044/1762] D loss: 1.3872, G loss: 0.7158\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6950\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6951\n",
      "[1284/1762] D loss: 1.3873, G loss: 0.7128\n",
      "[1364/1762] D loss: 0.0000, G loss: 20.8503\n",
      "[1444/1762] D loss: 0.0024, G loss: 7.6186\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.6903\n",
      "[1604/1762] D loss: 1.3866, G loss: 0.6875\n",
      "[1684/1762] D loss: 0.0002, G loss: 10.8942\n",
      "[1762/1762] D loss: 1.3870, G loss: 0.7102\n",
      "train error: \n",
      " D loss: 3.453046, G loss: 1.226422, D accuracy: 50.1%, cell accuracy: 99.8%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 3.959225, G loss: 1.448460, D accuracy: 50.1%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6933\n",
      "[84/1762] D loss: 0.8479, G loss: 6.6556\n",
      "[164/1762] D loss: 1.3866, G loss: 0.6795\n",
      "[244/1762] D loss: 1.3893, G loss: 0.7427\n",
      "[324/1762] D loss: 1.3864, G loss: 0.7012\n",
      "[404/1762] D loss: 0.0030, G loss: 6.0148\n",
      "[484/1762] D loss: 0.0744, G loss: 5.8802\n",
      "[564/1762] D loss: 1.3864, G loss: 0.7009\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6899\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6862\n",
      "[804/1762] D loss: 1.3861, G loss: 0.6953\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6869\n",
      "[964/1762] D loss: 1.3863, G loss: 0.6861\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.6876\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.7002\n",
      "[1204/1762] D loss: 1.3928, G loss: 0.7259\n",
      "[1284/1762] D loss: 0.0001, G loss: 10.5342\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6888\n",
      "[1444/1762] D loss: 1.3862, G loss: 0.6977\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.6839\n",
      "[1604/1762] D loss: 0.0200, G loss: 6.1293\n",
      "[1684/1762] D loss: 1.3868, G loss: 0.7134\n",
      "[1762/1762] D loss: 1.3861, G loss: 0.6856\n",
      "train error: \n",
      " D loss: 3.573175, G loss: 1.204157, D accuracy: 50.0%, cell accuracy: 99.8%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 4.099335, G loss: 1.403484, D accuracy: 50.0%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001, G loss: 9.3347\n",
      "[84/1762] D loss: 0.0016, G loss: 7.6708\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6989\n",
      "[244/1762] D loss: 0.0014, G loss: 6.9112\n",
      "[324/1762] D loss: 1.3864, G loss: 0.6993\n",
      "[404/1762] D loss: 1.3981, G loss: 0.7629\n",
      "[484/1762] D loss: 1.3868, G loss: 0.6701\n",
      "[564/1762] D loss: 0.0019, G loss: 8.2774\n",
      "[644/1762] D loss: 1.3843, G loss: 0.6817\n",
      "[724/1762] D loss: 0.0002, G loss: 17.2417\n",
      "[804/1762] D loss: 0.0000, G loss: 10.6376\n",
      "[884/1762] D loss: 0.0138, G loss: 5.4840\n",
      "[964/1762] D loss: 1.3874, G loss: 0.6835\n",
      "[1044/1762] D loss: 0.4083, G loss: 1.4852\n",
      "[1124/1762] D loss: 0.0009, G loss: 7.8353\n",
      "[1204/1762] D loss: 1.3862, G loss: 0.6896\n",
      "[1284/1762] D loss: 0.0017, G loss: 7.4535\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.7004\n",
      "[1444/1762] D loss: 1.3858, G loss: 0.6740\n",
      "[1524/1762] D loss: 0.0007, G loss: 8.0471\n",
      "[1604/1762] D loss: 1.3866, G loss: 0.6999\n",
      "[1684/1762] D loss: 1.3868, G loss: 0.6724\n",
      "[1762/1762] D loss: 1.4048, G loss: 0.7359\n",
      "train error: \n",
      " D loss: 4.298700, G loss: 1.372292, D accuracy: 50.5%, cell accuracy: 99.8%, board accuracy: 90.8% \n",
      "\n",
      "test error: \n",
      " D loss: 5.021768, G loss: 1.577034, D accuracy: 50.8%, cell accuracy: 99.7%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4065, G loss: 0.7640\n",
      "[84/1762] D loss: 0.1144, G loss: 4.4938\n",
      "[164/1762] D loss: 0.0000, G loss: 17.2311\n",
      "[244/1762] D loss: 0.0001, G loss: 9.2047\n",
      "[324/1762] D loss: 0.2786, G loss: 4.2772\n",
      "[404/1762] D loss: 1.3866, G loss: 0.6960\n",
      "[484/1762] D loss: 1.3867, G loss: 0.6770\n",
      "[564/1762] D loss: 1.3669, G loss: 0.6555\n",
      "[644/1762] D loss: 1.3867, G loss: 0.7113\n",
      "[724/1762] D loss: 1.3851, G loss: 0.7058\n",
      "[804/1762] D loss: 1.3855, G loss: 0.6917\n",
      "[884/1762] D loss: 1.3851, G loss: 0.6833\n",
      "[964/1762] D loss: 1.4150, G loss: 0.8454\n",
      "[1044/1762] D loss: 1.3876, G loss: 0.7181\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.6824\n",
      "[1204/1762] D loss: 1.3866, G loss: 0.6906\n",
      "[1284/1762] D loss: 1.3866, G loss: 0.7068\n",
      "[1364/1762] D loss: 1.3865, G loss: 0.6926\n",
      "[1444/1762] D loss: 1.3845, G loss: 0.7005\n",
      "[1524/1762] D loss: 0.0001, G loss: 9.7244\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6932\n",
      "[1684/1762] D loss: 1.3903, G loss: 0.7574\n",
      "[1762/1762] D loss: 1.3887, G loss: 0.7387\n",
      "train error: \n",
      " D loss: 3.842103, G loss: 1.293756, D accuracy: 50.0%, cell accuracy: 99.7%, board accuracy: 86.7% \n",
      "\n",
      "test error: \n",
      " D loss: 4.436888, G loss: 1.448378, D accuracy: 50.0%, cell accuracy: 99.7%, board accuracy: 85.0% \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3892, G loss: 0.7479\n",
      "[84/1762] D loss: 1.3868, G loss: 0.7167\n",
      "[164/1762] D loss: 1.3871, G loss: 0.7159\n",
      "[244/1762] D loss: 1.2327, G loss: 0.9284\n",
      "[324/1762] D loss: 1.3862, G loss: 0.6898\n",
      "[404/1762] D loss: 0.0007, G loss: 8.3949\n",
      "[484/1762] D loss: 1.3866, G loss: 0.6917\n",
      "[564/1762] D loss: 0.0170, G loss: 4.3191\n",
      "[644/1762] D loss: 1.3868, G loss: 0.7006\n",
      "[724/1762] D loss: 0.0016, G loss: 7.7046\n",
      "[804/1762] D loss: 0.0167, G loss: 4.7633\n",
      "[884/1762] D loss: 0.0131, G loss: 7.1765\n",
      "[964/1762] D loss: 0.0170, G loss: 7.5500\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6581\n",
      "[1124/1762] D loss: 0.0001, G loss: 21.1050\n",
      "[1204/1762] D loss: 1.3846, G loss: 0.6991\n",
      "[1284/1762] D loss: 0.0074, G loss: 5.5119\n",
      "[1364/1762] D loss: 0.2798, G loss: 4.3737\n",
      "[1444/1762] D loss: 0.3893, G loss: 2.0059\n",
      "[1524/1762] D loss: 1.3775, G loss: 0.7078\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6874\n",
      "[1684/1762] D loss: 1.3829, G loss: 0.7656\n",
      "[1762/1762] D loss: 1.3870, G loss: 0.7107\n",
      "train error: \n",
      " D loss: 2.933279, G loss: 1.230420, D accuracy: 50.6%, cell accuracy: 99.8%, board accuracy: 92.8% \n",
      "\n",
      "test error: \n",
      " D loss: 3.297333, G loss: 1.442191, D accuracy: 50.9%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3850, G loss: 0.6769\n",
      "[84/1762] D loss: 0.0007, G loss: 8.6394\n",
      "[164/1762] D loss: 0.0022, G loss: 7.4391\n",
      "[244/1762] D loss: 1.3687, G loss: 0.7437\n",
      "[324/1762] D loss: 1.4003, G loss: 0.6626\n",
      "[404/1762] D loss: 0.0002, G loss: 8.8252\n",
      "[484/1762] D loss: 0.0010, G loss: 8.1591\n",
      "[564/1762] D loss: 1.3910, G loss: 0.7458\n",
      "[644/1762] D loss: 1.3560, G loss: 0.6492\n",
      "[724/1762] D loss: 1.3942, G loss: 0.6065\n",
      "[804/1762] D loss: 0.1767, G loss: 2.5290\n",
      "[884/1762] D loss: 1.3737, G loss: 0.7184\n",
      "[964/1762] D loss: 1.3950, G loss: 0.6785\n",
      "[1044/1762] D loss: 1.4004, G loss: 0.7924\n",
      "[1124/1762] D loss: 1.3795, G loss: 0.6997\n",
      "[1204/1762] D loss: 1.3743, G loss: 0.7182\n",
      "[1284/1762] D loss: 1.3855, G loss: 0.6532\n",
      "[1364/1762] D loss: 1.3815, G loss: 0.7037\n",
      "[1444/1762] D loss: 1.3797, G loss: 0.7066\n",
      "[1524/1762] D loss: 0.0024, G loss: 7.0662\n",
      "[1604/1762] D loss: 0.0005, G loss: 8.2761\n",
      "[1684/1762] D loss: 1.3866, G loss: 0.6647\n",
      "[1762/1762] D loss: 1.3852, G loss: 0.6969\n",
      "train error: \n",
      " D loss: 3.806500, G loss: 1.280169, D accuracy: 50.1%, cell accuracy: 99.8%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 4.390457, G loss: 1.486803, D accuracy: 50.3%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0002, G loss: 9.1812\n",
      "[84/1762] D loss: 1.4577, G loss: 0.7431\n",
      "[164/1762] D loss: 1.3892, G loss: 0.6306\n",
      "[244/1762] D loss: 1.3844, G loss: 0.7902\n",
      "[324/1762] D loss: 1.3726, G loss: 0.6612\n",
      "[404/1762] D loss: 1.3431, G loss: 0.7415\n",
      "[484/1762] D loss: 1.3569, G loss: 0.7417\n",
      "[564/1762] D loss: 1.4068, G loss: 0.5862\n",
      "[644/1762] D loss: 1.3853, G loss: 0.7426\n",
      "[724/1762] D loss: 1.3886, G loss: 0.6782\n",
      "[804/1762] D loss: 1.3843, G loss: 0.6940\n",
      "[884/1762] D loss: 1.3865, G loss: 0.7352\n",
      "[964/1762] D loss: 1.3703, G loss: 0.7614\n",
      "[1044/1762] D loss: 1.3905, G loss: 0.7943\n",
      "[1124/1762] D loss: 1.3896, G loss: 0.6763\n",
      "[1204/1762] D loss: 1.3922, G loss: 0.6974\n",
      "[1284/1762] D loss: 1.4012, G loss: 0.6625\n",
      "[1364/1762] D loss: 1.3827, G loss: 0.6716\n",
      "[1444/1762] D loss: 1.3965, G loss: 0.7675\n",
      "[1524/1762] D loss: 1.3770, G loss: 0.6893\n",
      "[1604/1762] D loss: 0.0118, G loss: 5.3812\n",
      "[1684/1762] D loss: 0.0001, G loss: 14.3777\n",
      "[1762/1762] D loss: 1.3785, G loss: 0.7358\n",
      "train error: \n",
      " D loss: 3.041894, G loss: 1.285529, D accuracy: 49.9%, cell accuracy: 99.8%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 3.435825, G loss: 1.486788, D accuracy: 49.9%, cell accuracy: 99.7%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3842, G loss: 0.6754\n",
      "[84/1762] D loss: 1.3808, G loss: 0.6920\n",
      "[164/1762] D loss: 1.3682, G loss: 0.7272\n",
      "[244/1762] D loss: 1.3839, G loss: 0.6528\n",
      "[324/1762] D loss: 1.3855, G loss: 0.7579\n",
      "[404/1762] D loss: 0.0001, G loss: 14.6650\n",
      "[484/1762] D loss: 1.3806, G loss: 0.7069\n",
      "[564/1762] D loss: 1.3761, G loss: 0.7157\n",
      "[644/1762] D loss: 0.0507, G loss: 4.6460\n",
      "[724/1762] D loss: 0.0782, G loss: 8.9891\n",
      "[804/1762] D loss: 1.2519, G loss: 1.0076\n",
      "[884/1762] D loss: 1.3843, G loss: 0.6776\n",
      "[964/1762] D loss: 0.0032, G loss: 7.1821\n",
      "[1044/1762] D loss: 0.0267, G loss: 3.9337\n",
      "[1124/1762] D loss: 1.4458, G loss: 0.6245\n",
      "[1204/1762] D loss: 0.0000, G loss: 10.8578\n",
      "[1284/1762] D loss: 0.0000, G loss: 10.3284\n",
      "[1364/1762] D loss: 1.3884, G loss: 0.6674\n",
      "[1444/1762] D loss: 0.0005, G loss: 10.2209\n",
      "[1524/1762] D loss: 1.3880, G loss: 0.7373\n",
      "[1604/1762] D loss: 0.0005, G loss: 8.2710\n",
      "[1684/1762] D loss: 1.3669, G loss: 0.6621\n",
      "[1762/1762] D loss: 1.3729, G loss: 0.7193\n",
      "train error: \n",
      " D loss: 2.920250, G loss: 1.221942, D accuracy: 50.3%, cell accuracy: 99.8%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 3.271344, G loss: 1.363269, D accuracy: 49.5%, cell accuracy: 99.7%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0025, G loss: 5.4739\n",
      "[84/1762] D loss: 1.3905, G loss: 0.7367\n",
      "[164/1762] D loss: 1.3849, G loss: 0.6701\n",
      "[244/1762] D loss: 0.1274, G loss: 3.5287\n",
      "[324/1762] D loss: 1.4011, G loss: 0.7377\n",
      "[404/1762] D loss: 1.3782, G loss: 0.6465\n",
      "[484/1762] D loss: 0.0001, G loss: 10.8250\n",
      "[564/1762] D loss: 1.3836, G loss: 0.6667\n",
      "[644/1762] D loss: 0.0002, G loss: 9.3710\n",
      "[724/1762] D loss: 1.3785, G loss: 0.6879\n",
      "[804/1762] D loss: 1.3800, G loss: 0.7080\n",
      "[884/1762] D loss: 1.3556, G loss: 0.7120\n",
      "[964/1762] D loss: 1.3843, G loss: 0.6653\n",
      "[1044/1762] D loss: 1.3945, G loss: 0.6835\n",
      "[1124/1762] D loss: 1.3861, G loss: 0.7233\n",
      "[1204/1762] D loss: 1.3715, G loss: 0.7140\n",
      "[1284/1762] D loss: 1.3772, G loss: 0.7278\n",
      "[1364/1762] D loss: 0.0306, G loss: 4.0550\n",
      "[1444/1762] D loss: 1.3771, G loss: 0.6891\n",
      "[1524/1762] D loss: 0.0000, G loss: 11.2545\n",
      "[1604/1762] D loss: 1.1624, G loss: 4.0925\n",
      "[1684/1762] D loss: 1.3755, G loss: 0.7198\n",
      "[1762/1762] D loss: 1.3625, G loss: 0.6815\n",
      "train error: \n",
      " D loss: 2.265530, G loss: 1.078760, D accuracy: 50.9%, cell accuracy: 99.8%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 2.440300, G loss: 1.183366, D accuracy: 51.5%, cell accuracy: 99.7%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3513, G loss: 0.7612\n",
      "[84/1762] D loss: 1.3946, G loss: 0.8260\n",
      "[164/1762] D loss: 0.0006, G loss: 9.1200\n",
      "[244/1762] D loss: 0.0017, G loss: 7.5445\n",
      "[324/1762] D loss: 1.3111, G loss: 0.7207\n",
      "[404/1762] D loss: 1.3806, G loss: 0.7222\n",
      "[484/1762] D loss: 1.3829, G loss: 0.6524\n",
      "[564/1762] D loss: 0.0007, G loss: 8.0966\n",
      "[644/1762] D loss: 1.3691, G loss: 0.7494\n",
      "[724/1762] D loss: 1.3836, G loss: 0.6870\n",
      "[804/1762] D loss: 1.3748, G loss: 0.6824\n",
      "[884/1762] D loss: 1.3758, G loss: 0.6212\n",
      "[964/1762] D loss: 1.3700, G loss: 0.7256\n",
      "[1044/1762] D loss: 1.3740, G loss: 0.7636\n",
      "[1124/1762] D loss: 0.0001, G loss: 9.9624\n",
      "[1204/1762] D loss: 1.3791, G loss: 0.6777\n",
      "[1284/1762] D loss: 0.0001, G loss: 9.7357\n",
      "[1364/1762] D loss: 1.3753, G loss: 0.6808\n",
      "[1444/1762] D loss: 1.3711, G loss: 0.6925\n",
      "[1524/1762] D loss: 0.0853, G loss: 3.8849\n",
      "[1604/1762] D loss: 1.3908, G loss: 0.8826\n",
      "[1684/1762] D loss: 1.3779, G loss: 0.7773\n",
      "[1762/1762] D loss: 1.3748, G loss: 0.6943\n",
      "train error: \n",
      " D loss: 2.079332, G loss: 1.085517, D accuracy: 50.3%, cell accuracy: 99.8%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 2.202489, G loss: 1.254394, D accuracy: 50.6%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3842, G loss: 0.7333\n",
      "[84/1762] D loss: 1.3783, G loss: 0.7327\n",
      "[164/1762] D loss: 1.3853, G loss: 0.7081\n",
      "[244/1762] D loss: 0.0234, G loss: 6.8857\n",
      "[324/1762] D loss: 1.3962, G loss: 0.7969\n",
      "[404/1762] D loss: 0.0969, G loss: 6.2057\n",
      "[484/1762] D loss: 1.3891, G loss: 0.7241\n",
      "[564/1762] D loss: 0.0000, G loss: 17.4281\n",
      "[644/1762] D loss: 1.3843, G loss: 0.7034\n",
      "[724/1762] D loss: 1.3855, G loss: 0.6963\n",
      "[804/1762] D loss: 1.3835, G loss: 0.6861\n",
      "[884/1762] D loss: 1.3774, G loss: 0.7009\n",
      "[964/1762] D loss: 0.0001, G loss: 10.7373\n",
      "[1044/1762] D loss: 0.0000, G loss: 19.4356\n",
      "[1124/1762] D loss: 1.3828, G loss: 0.6856\n",
      "[1204/1762] D loss: 1.3852, G loss: 0.7299\n",
      "[1284/1762] D loss: 0.0013, G loss: 8.0861\n",
      "[1364/1762] D loss: 1.3608, G loss: 0.7207\n",
      "[1444/1762] D loss: 1.3826, G loss: 0.6754\n",
      "[1524/1762] D loss: 1.3561, G loss: 0.7958\n",
      "[1604/1762] D loss: 1.3950, G loss: 0.6555\n",
      "[1684/1762] D loss: 1.3804, G loss: 0.7112\n",
      "[1762/1762] D loss: 1.3840, G loss: 0.6666\n",
      "train error: \n",
      " D loss: 2.602756, G loss: 1.288846, D accuracy: 50.8%, cell accuracy: 99.8%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 2.857514, G loss: 1.494820, D accuracy: 51.1%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3912, G loss: 0.6903\n",
      "[84/1762] D loss: 1.3847, G loss: 0.6593\n",
      "[164/1762] D loss: 1.3842, G loss: 0.6878\n",
      "[244/1762] D loss: 1.3828, G loss: 0.7389\n",
      "[324/1762] D loss: 0.0013, G loss: 9.0747\n",
      "[404/1762] D loss: 1.3768, G loss: 0.6296\n",
      "[484/1762] D loss: 0.0001, G loss: 13.3555\n",
      "[564/1762] D loss: 1.3863, G loss: 0.7194\n",
      "[644/1762] D loss: 0.0003, G loss: 8.6378\n",
      "[724/1762] D loss: 0.0000, G loss: 15.7051\n",
      "[804/1762] D loss: 1.3877, G loss: 0.6659\n",
      "[884/1762] D loss: 1.3930, G loss: 0.7786\n",
      "[964/1762] D loss: 1.3886, G loss: 0.6457\n",
      "[1044/1762] D loss: 0.0001, G loss: 16.4490\n",
      "[1124/1762] D loss: 1.3926, G loss: 0.6131\n",
      "[1204/1762] D loss: 1.3878, G loss: 0.7142\n",
      "[1284/1762] D loss: 1.3809, G loss: 0.6613\n",
      "[1364/1762] D loss: 0.0002, G loss: 9.5315\n",
      "[1444/1762] D loss: 1.3837, G loss: 0.6643\n",
      "[1524/1762] D loss: 1.3842, G loss: 0.6522\n",
      "[1604/1762] D loss: 1.3858, G loss: 0.7722\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.7518\n",
      "[1762/1762] D loss: 1.3851, G loss: 0.7350\n",
      "train error: \n",
      " D loss: 1.942581, G loss: 1.177187, D accuracy: 50.1%, cell accuracy: 99.8%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 2.002039, G loss: 1.372607, D accuracy: 50.1%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3859, G loss: 0.7191\n",
      "[84/1762] D loss: 1.3824, G loss: 0.6779\n",
      "[164/1762] D loss: 1.3866, G loss: 0.7308\n",
      "[244/1762] D loss: 1.3938, G loss: 0.5879\n",
      "[324/1762] D loss: 1.3885, G loss: 0.7335\n",
      "[404/1762] D loss: 0.0020, G loss: 8.1986\n",
      "[484/1762] D loss: 1.3796, G loss: 0.6670\n",
      "[564/1762] D loss: 1.3884, G loss: 0.7410\n",
      "[644/1762] D loss: 0.0119, G loss: 6.9195\n",
      "[724/1762] D loss: 1.3803, G loss: 0.6769\n",
      "[804/1762] D loss: 1.3678, G loss: 0.7021\n",
      "[884/1762] D loss: 0.0002, G loss: 8.9324\n",
      "[964/1762] D loss: 1.3781, G loss: 0.6481\n",
      "[1044/1762] D loss: 0.0011, G loss: 8.5855\n",
      "[1124/1762] D loss: 1.3672, G loss: 0.7241\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6937\n",
      "[1284/1762] D loss: 1.3865, G loss: 0.6723\n",
      "[1364/1762] D loss: 1.3912, G loss: 0.6363\n",
      "[1444/1762] D loss: 1.3784, G loss: 0.7005\n",
      "[1524/1762] D loss: 0.0160, G loss: 5.6101\n",
      "[1604/1762] D loss: 1.3818, G loss: 0.6758\n",
      "[1684/1762] D loss: 1.3818, G loss: 0.7044\n",
      "[1762/1762] D loss: 1.3906, G loss: 0.6257\n",
      "train error: \n",
      " D loss: 3.941996, G loss: 1.282861, D accuracy: 50.0%, cell accuracy: 99.8%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 4.500362, G loss: 1.497766, D accuracy: 50.1%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3940, G loss: 0.6274\n",
      "[84/1762] D loss: 0.0004, G loss: 8.9888\n",
      "[164/1762] D loss: 0.0010, G loss: 8.3871\n",
      "[244/1762] D loss: 1.3838, G loss: 0.6894\n",
      "[324/1762] D loss: 1.3872, G loss: 0.7413\n",
      "[404/1762] D loss: 1.3928, G loss: 0.6189\n",
      "[484/1762] D loss: 1.4255, G loss: 0.7218\n",
      "[564/1762] D loss: 1.3894, G loss: 0.6493\n",
      "[644/1762] D loss: 1.3856, G loss: 0.7142\n",
      "[724/1762] D loss: 0.0002, G loss: 9.2912\n",
      "[804/1762] D loss: 1.3847, G loss: 0.6972\n",
      "[884/1762] D loss: 1.3807, G loss: 0.7382\n",
      "[964/1762] D loss: 1.4122, G loss: 0.5362\n",
      "[1044/1762] D loss: 0.0067, G loss: 8.9694\n",
      "[1124/1762] D loss: 1.4034, G loss: 0.8560\n",
      "[1204/1762] D loss: 1.3958, G loss: 0.6480\n",
      "[1284/1762] D loss: 1.3827, G loss: 0.7189\n",
      "[1364/1762] D loss: 1.3906, G loss: 0.7282\n",
      "[1444/1762] D loss: 1.3844, G loss: 0.6653\n",
      "[1524/1762] D loss: 1.3670, G loss: 0.7114\n",
      "[1604/1762] D loss: 1.3835, G loss: 0.6986\n",
      "[1684/1762] D loss: 0.5696, G loss: 5.1289\n",
      "[1762/1762] D loss: 0.3869, G loss: 14.5994\n",
      "train error: \n",
      " D loss: 1.642288, G loss: 0.772980, D accuracy: 49.8%, cell accuracy: 99.8%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.612912, G loss: 0.714156, D accuracy: 50.3%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3817, G loss: 0.7406\n",
      "[84/1762] D loss: 1.4000, G loss: 0.6465\n",
      "[164/1762] D loss: 1.4188, G loss: 0.7939\n",
      "[244/1762] D loss: 1.3877, G loss: 0.7736\n",
      "[324/1762] D loss: 1.2776, G loss: 0.5902\n",
      "[404/1762] D loss: 1.2471, G loss: 3.8536\n",
      "[484/1762] D loss: 1.3949, G loss: 0.6697\n",
      "[564/1762] D loss: 1.0907, G loss: 1.2407\n",
      "[644/1762] D loss: 1.1127, G loss: 1.6263\n",
      "[724/1762] D loss: 1.4229, G loss: 0.5462\n",
      "[804/1762] D loss: 1.4039, G loss: 0.7890\n",
      "[884/1762] D loss: 0.8591, G loss: 1.6284\n",
      "[964/1762] D loss: 1.3943, G loss: 0.8529\n",
      "[1044/1762] D loss: 1.1238, G loss: 0.9687\n",
      "[1124/1762] D loss: 1.3934, G loss: 0.6925\n",
      "[1204/1762] D loss: 1.3971, G loss: 0.6059\n",
      "[1284/1762] D loss: 1.3673, G loss: 0.8217\n",
      "[1364/1762] D loss: 2.4613, G loss: 0.9389\n",
      "[1444/1762] D loss: 1.4127, G loss: 0.8327\n",
      "[1524/1762] D loss: 1.3855, G loss: 0.7133\n",
      "[1604/1762] D loss: 1.2810, G loss: 0.6940\n",
      "[1684/1762] D loss: 1.3871, G loss: 0.6726\n",
      "[1762/1762] D loss: 1.3886, G loss: 0.6969\n",
      "train error: \n",
      " D loss: 1.371535, G loss: 0.822038, D accuracy: 51.8%, cell accuracy: 99.8%, board accuracy: 90.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.355141, G loss: 0.978741, D accuracy: 52.6%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4027, G loss: 0.5750\n",
      "[84/1762] D loss: 1.2654, G loss: 1.0536\n",
      "[164/1762] D loss: 1.3832, G loss: 0.6865\n",
      "[244/1762] D loss: 1.3896, G loss: 0.6415\n",
      "[324/1762] D loss: 0.8454, G loss: 2.2644\n",
      "[404/1762] D loss: 1.3986, G loss: 0.6582\n",
      "[484/1762] D loss: 1.3860, G loss: 0.6921\n",
      "[564/1762] D loss: 0.6722, G loss: 1.6915\n",
      "[644/1762] D loss: 1.3958, G loss: 0.6769\n",
      "[724/1762] D loss: 1.3850, G loss: 0.8156\n",
      "[804/1762] D loss: 1.3928, G loss: 0.6461\n",
      "[884/1762] D loss: 1.3149, G loss: 0.8225\n",
      "[964/1762] D loss: 1.3920, G loss: 0.6828\n",
      "[1044/1762] D loss: 1.3730, G loss: 0.6391\n",
      "[1124/1762] D loss: 1.3916, G loss: 0.6743\n",
      "[1204/1762] D loss: 1.3888, G loss: 0.6520\n",
      "[1284/1762] D loss: 1.3988, G loss: 0.5978\n",
      "[1364/1762] D loss: 1.3803, G loss: 0.6579\n",
      "[1444/1762] D loss: 1.3938, G loss: 0.6874\n",
      "[1524/1762] D loss: 1.1920, G loss: 0.8969\n",
      "[1604/1762] D loss: 1.1463, G loss: 1.1058\n",
      "[1684/1762] D loss: 1.4239, G loss: 0.8901\n",
      "[1762/1762] D loss: 1.3986, G loss: 0.6142\n",
      "train error: \n",
      " D loss: 1.424099, G loss: 1.045207, D accuracy: 50.9%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.416357, G loss: 1.136520, D accuracy: 51.5%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3888, G loss: 0.6799\n",
      "[84/1762] D loss: 1.3861, G loss: 0.7112\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6828\n",
      "[244/1762] D loss: 1.3744, G loss: 0.7205\n",
      "[324/1762] D loss: 1.3797, G loss: 0.7571\n",
      "[404/1762] D loss: 1.0996, G loss: 0.9759\n",
      "[484/1762] D loss: 1.3956, G loss: 0.6124\n",
      "[564/1762] D loss: 1.0927, G loss: 0.9264\n",
      "[644/1762] D loss: 1.2951, G loss: 0.7027\n",
      "[724/1762] D loss: 1.4040, G loss: 0.8023\n",
      "[804/1762] D loss: 1.3876, G loss: 0.6950\n",
      "[884/1762] D loss: 1.0666, G loss: 1.2967\n",
      "[964/1762] D loss: 1.3895, G loss: 0.6904\n",
      "[1044/1762] D loss: 1.3916, G loss: 0.7220\n",
      "[1124/1762] D loss: 1.3082, G loss: 0.7257\n",
      "[1204/1762] D loss: 1.0944, G loss: 1.1200\n",
      "[1284/1762] D loss: 1.3890, G loss: 0.6592\n",
      "[1364/1762] D loss: 1.3890, G loss: 0.6991\n",
      "[1444/1762] D loss: 2.5131, G loss: 0.4511\n",
      "[1524/1762] D loss: 1.3884, G loss: 0.7198\n",
      "[1604/1762] D loss: 1.4001, G loss: 0.5985\n",
      "[1684/1762] D loss: 1.3875, G loss: 0.6473\n",
      "[1762/1762] D loss: 1.3932, G loss: 0.7653\n",
      "train error: \n",
      " D loss: 1.332531, G loss: 1.247377, D accuracy: 52.8%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.311335, G loss: 1.355840, D accuracy: 53.4%, cell accuracy: 99.9%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3907, G loss: 0.6488\n",
      "[84/1762] D loss: 1.3853, G loss: 0.7057\n",
      "[164/1762] D loss: 1.3893, G loss: 0.7202\n",
      "[244/1762] D loss: 1.1396, G loss: 0.8688\n",
      "[324/1762] D loss: 1.3881, G loss: 0.6904\n",
      "[404/1762] D loss: 1.3914, G loss: 0.6280\n",
      "[484/1762] D loss: 1.3887, G loss: 0.6899\n",
      "[564/1762] D loss: 0.4655, G loss: 2.6146\n",
      "[644/1762] D loss: 0.3387, G loss: 4.7896\n",
      "[724/1762] D loss: 1.4201, G loss: 0.7269\n",
      "[804/1762] D loss: 1.4282, G loss: 0.5405\n",
      "[884/1762] D loss: 0.4222, G loss: 3.1158\n",
      "[964/1762] D loss: 1.3506, G loss: 0.8610\n",
      "[1044/1762] D loss: 1.4313, G loss: 0.7338\n",
      "[1124/1762] D loss: 1.3988, G loss: 0.7273\n",
      "[1204/1762] D loss: 1.3959, G loss: 0.7531\n",
      "[1284/1762] D loss: 1.4892, G loss: 0.4865\n",
      "[1364/1762] D loss: 1.4167, G loss: 0.5845\n",
      "[1444/1762] D loss: 1.5106, G loss: 0.4044\n",
      "[1524/1762] D loss: 1.4590, G loss: 0.6602\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.8494\n",
      "[1684/1762] D loss: 0.0345, G loss: 7.1764\n",
      "[1762/1762] D loss: 1.3248, G loss: 0.7661\n",
      "train error: \n",
      " D loss: 2.755320, G loss: 1.450467, D accuracy: 48.6%, cell accuracy: 99.8%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 2.756708, G loss: 1.582195, D accuracy: 49.0%, cell accuracy: 99.7%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1133, G loss: 6.2277\n",
      "[84/1762] D loss: 1.3684, G loss: 0.7931\n",
      "[164/1762] D loss: 1.4429, G loss: 0.9234\n",
      "[244/1762] D loss: 1.4140, G loss: 0.8810\n",
      "[324/1762] D loss: 1.4548, G loss: 1.0279\n",
      "[404/1762] D loss: 1.4155, G loss: 0.8948\n",
      "[484/1762] D loss: 1.3805, G loss: 0.6829\n",
      "[564/1762] D loss: 1.3921, G loss: 0.6274\n",
      "[644/1762] D loss: 1.3880, G loss: 0.5816\n",
      "[724/1762] D loss: 1.0776, G loss: 1.3299\n",
      "[804/1762] D loss: 1.0837, G loss: 0.7001\n",
      "[884/1762] D loss: 1.3261, G loss: 0.5181\n",
      "[964/1762] D loss: 1.3955, G loss: 0.6517\n",
      "[1044/1762] D loss: 1.3981, G loss: 0.6303\n",
      "[1124/1762] D loss: 1.3892, G loss: 0.6313\n",
      "[1204/1762] D loss: 1.3208, G loss: 0.8454\n",
      "[1284/1762] D loss: 1.4565, G loss: 0.5327\n",
      "[1364/1762] D loss: 1.4610, G loss: 0.4786\n",
      "[1444/1762] D loss: 1.4076, G loss: 0.8214\n",
      "[1524/1762] D loss: 1.3973, G loss: 0.5851\n",
      "[1604/1762] D loss: 1.3861, G loss: 0.7068\n",
      "[1684/1762] D loss: 0.3422, G loss: 2.6343\n",
      "[1762/1762] D loss: 1.3927, G loss: 0.6505\n",
      "train error: \n",
      " D loss: 1.496056, G loss: 1.158304, D accuracy: 50.6%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.490252, G loss: 1.251241, D accuracy: 52.0%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4289, G loss: 0.5207\n",
      "[84/1762] D loss: 1.4258, G loss: 0.5394\n",
      "[164/1762] D loss: 1.3874, G loss: 0.7263\n",
      "[244/1762] D loss: 1.4063, G loss: 0.5955\n",
      "[324/1762] D loss: 1.3893, G loss: 0.7233\n",
      "[404/1762] D loss: 1.4078, G loss: 0.5923\n",
      "[484/1762] D loss: 0.6005, G loss: 1.6761\n",
      "[564/1762] D loss: 1.3977, G loss: 0.8048\n",
      "[644/1762] D loss: 0.1161, G loss: 4.1187\n",
      "[724/1762] D loss: 1.4333, G loss: 0.7265\n",
      "[804/1762] D loss: 1.4493, G loss: 1.0841\n",
      "[884/1762] D loss: 1.5172, G loss: 1.1366\n",
      "[964/1762] D loss: 1.4307, G loss: 0.5583\n",
      "[1044/1762] D loss: 1.4144, G loss: 0.5691\n",
      "[1124/1762] D loss: 1.3994, G loss: 0.6951\n",
      "[1204/1762] D loss: 1.3250, G loss: 0.9340\n",
      "[1284/1762] D loss: 1.3866, G loss: 0.6884\n",
      "[1364/1762] D loss: 1.3941, G loss: 0.6243\n",
      "[1444/1762] D loss: 1.3964, G loss: 0.7821\n",
      "[1524/1762] D loss: 0.8070, G loss: 1.3039\n",
      "[1604/1762] D loss: 1.3880, G loss: 0.7326\n",
      "[1684/1762] D loss: 1.3857, G loss: 0.6860\n",
      "[1762/1762] D loss: 1.3927, G loss: 0.6177\n",
      "train error: \n",
      " D loss: 1.358532, G loss: 0.757608, D accuracy: 52.4%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.348460, G loss: 0.772401, D accuracy: 53.1%, cell accuracy: 99.9%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3988, G loss: 0.5949\n",
      "[84/1762] D loss: 1.3862, G loss: 0.7044\n",
      "[164/1762] D loss: 1.3886, G loss: 0.6690\n",
      "[244/1762] D loss: 1.3901, G loss: 0.6535\n",
      "[324/1762] D loss: 1.3889, G loss: 0.6722\n",
      "[404/1762] D loss: 1.3898, G loss: 0.7415\n",
      "[484/1762] D loss: 1.3875, G loss: 0.6557\n",
      "[564/1762] D loss: 1.3979, G loss: 0.5997\n",
      "[644/1762] D loss: 1.3909, G loss: 0.6899\n",
      "[724/1762] D loss: 1.3910, G loss: 0.7353\n",
      "[804/1762] D loss: 1.3935, G loss: 0.7857\n",
      "[884/1762] D loss: 1.3892, G loss: 0.7380\n",
      "[964/1762] D loss: 1.3883, G loss: 0.7165\n",
      "[1044/1762] D loss: 1.3623, G loss: 0.6339\n",
      "[1124/1762] D loss: 1.3928, G loss: 0.7758\n",
      "[1204/1762] D loss: 1.4023, G loss: 0.5905\n",
      "[1284/1762] D loss: 1.3925, G loss: 0.6919\n",
      "[1364/1762] D loss: 1.3882, G loss: 0.7042\n",
      "[1444/1762] D loss: 1.3882, G loss: 0.7087\n",
      "[1524/1762] D loss: 1.3926, G loss: 0.7378\n",
      "[1604/1762] D loss: 1.3885, G loss: 0.6944\n",
      "[1684/1762] D loss: 1.3868, G loss: 0.6918\n",
      "[1762/1762] D loss: 1.3883, G loss: 0.6967\n",
      "train error: \n",
      " D loss: 1.381848, G loss: 0.672287, D accuracy: 50.9%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.368650, G loss: 0.681399, D accuracy: 51.4%, cell accuracy: 99.9%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6492, G loss: 1.0898\n",
      "[84/1762] D loss: 1.4014, G loss: 0.6050\n",
      "[164/1762] D loss: 1.3942, G loss: 0.7525\n",
      "[244/1762] D loss: 1.3892, G loss: 0.7364\n",
      "[324/1762] D loss: 1.3902, G loss: 0.7272\n",
      "[404/1762] D loss: 1.3883, G loss: 0.7258\n",
      "[484/1762] D loss: 1.6186, G loss: 0.7576\n",
      "[564/1762] D loss: 1.4023, G loss: 0.7903\n",
      "[644/1762] D loss: 1.3984, G loss: 0.7987\n",
      "[724/1762] D loss: 1.0804, G loss: 2.1122\n",
      "[804/1762] D loss: 1.3835, G loss: 0.7151\n",
      "[884/1762] D loss: 1.3905, G loss: 0.6411\n",
      "[964/1762] D loss: 0.7737, G loss: 0.8631\n",
      "[1044/1762] D loss: 1.3879, G loss: 0.7344\n",
      "[1124/1762] D loss: 1.3896, G loss: 0.7204\n",
      "[1204/1762] D loss: 1.3881, G loss: 0.7159\n",
      "[1284/1762] D loss: 1.3879, G loss: 0.7241\n",
      "[1364/1762] D loss: 0.6613, G loss: 1.2863\n",
      "[1444/1762] D loss: 1.3953, G loss: 0.7740\n",
      "[1524/1762] D loss: 1.3233, G loss: 1.0354\n",
      "[1604/1762] D loss: 1.3955, G loss: 0.7117\n",
      "[1684/1762] D loss: 1.3877, G loss: 0.6918\n",
      "[1762/1762] D loss: 1.3866, G loss: 0.7157\n",
      "train error: \n",
      " D loss: 1.391790, G loss: 0.943819, D accuracy: 50.9%, cell accuracy: 99.9%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.378977, G loss: 0.935981, D accuracy: 51.2%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3881, G loss: 0.6725\n",
      "[84/1762] D loss: 1.4004, G loss: 0.8104\n",
      "[164/1762] D loss: 0.7723, G loss: 0.7965\n",
      "[244/1762] D loss: 1.4246, G loss: 0.8989\n",
      "[324/1762] D loss: 1.4168, G loss: 0.8659\n",
      "[404/1762] D loss: 1.4361, G loss: 0.9392\n",
      "[484/1762] D loss: 1.3883, G loss: 0.6686\n",
      "[564/1762] D loss: 1.3857, G loss: 0.6708\n",
      "[644/1762] D loss: 1.0635, G loss: 1.0787\n",
      "[724/1762] D loss: 0.7532, G loss: 1.3000\n",
      "[804/1762] D loss: 1.3966, G loss: 0.6761\n",
      "[884/1762] D loss: 0.2270, G loss: 2.6406\n",
      "[964/1762] D loss: 1.4226, G loss: 0.5708\n",
      "[1044/1762] D loss: 1.4091, G loss: 0.8131\n",
      "[1124/1762] D loss: 1.3971, G loss: 0.6296\n",
      "[1204/1762] D loss: 1.3954, G loss: 0.7867\n",
      "[1284/1762] D loss: 1.4092, G loss: 0.5690\n",
      "[1364/1762] D loss: 1.3981, G loss: 0.8120\n",
      "[1444/1762] D loss: 1.3859, G loss: 0.6527\n",
      "[1524/1762] D loss: 1.4473, G loss: 0.9667\n",
      "[1604/1762] D loss: 1.3953, G loss: 0.6730\n",
      "[1684/1762] D loss: 1.3373, G loss: 1.3770\n",
      "[1762/1762] D loss: 1.3915, G loss: 0.6507\n",
      "train error: \n",
      " D loss: 1.406999, G loss: 0.773546, D accuracy: 50.3%, cell accuracy: 99.9%, board accuracy: 93.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.392164, G loss: 0.824455, D accuracy: 51.0%, cell accuracy: 99.9%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3889, G loss: 0.6469\n",
      "[84/1762] D loss: 1.3882, G loss: 0.7236\n",
      "[164/1762] D loss: 1.3992, G loss: 0.6432\n",
      "[244/1762] D loss: 1.3925, G loss: 0.7625\n",
      "[324/1762] D loss: 1.3994, G loss: 0.6852\n",
      "[404/1762] D loss: 1.3868, G loss: 0.7247\n",
      "[484/1762] D loss: 1.0618, G loss: 0.8628\n",
      "[564/1762] D loss: 1.3917, G loss: 0.7944\n",
      "[644/1762] D loss: 1.3989, G loss: 0.5884\n",
      "[724/1762] D loss: 1.3990, G loss: 0.6668\n",
      "[804/1762] D loss: 1.4194, G loss: 0.6334\n",
      "[884/1762] D loss: 0.5921, G loss: 0.9196\n",
      "[964/1762] D loss: 1.3905, G loss: 0.6946\n",
      "[1044/1762] D loss: 1.3919, G loss: 0.7609\n",
      "[1124/1762] D loss: 1.4257, G loss: 0.5314\n",
      "[1204/1762] D loss: 1.3882, G loss: 0.7240\n",
      "[1284/1762] D loss: 1.5570, G loss: 1.3970\n",
      "[1364/1762] D loss: 0.6588, G loss: 1.9075\n",
      "[1444/1762] D loss: 0.5146, G loss: 1.1495\n",
      "[1524/1762] D loss: 1.3530, G loss: 1.3157\n",
      "[1604/1762] D loss: 1.2006, G loss: 0.8319\n",
      "[1684/1762] D loss: 0.6771, G loss: 0.9549\n",
      "[1762/1762] D loss: 1.3894, G loss: 0.6405\n",
      "train error: \n",
      " D loss: 1.371134, G loss: 0.936298, D accuracy: 51.5%, cell accuracy: 99.8%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.365016, G loss: 1.047241, D accuracy: 52.6%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7315, G loss: 1.2169\n",
      "[84/1762] D loss: 1.3999, G loss: 0.8045\n",
      "[164/1762] D loss: 1.3864, G loss: 0.6981\n",
      "[244/1762] D loss: 1.4190, G loss: 0.6246\n",
      "[324/1762] D loss: 1.4075, G loss: 0.6982\n",
      "[404/1762] D loss: 1.3890, G loss: 0.7088\n",
      "[484/1762] D loss: 0.3319, G loss: 2.3274\n",
      "[564/1762] D loss: 1.3899, G loss: 0.6659\n",
      "[644/1762] D loss: 1.4008, G loss: 0.6893\n",
      "[724/1762] D loss: 1.4071, G loss: 0.5998\n",
      "[804/1762] D loss: 1.3802, G loss: 0.6587\n",
      "[884/1762] D loss: 1.4203, G loss: 0.7887\n",
      "[964/1762] D loss: 1.4120, G loss: 0.6499\n",
      "[1044/1762] D loss: 1.3905, G loss: 0.7389\n",
      "[1124/1762] D loss: 1.4069, G loss: 0.5730\n",
      "[1204/1762] D loss: 0.0521, G loss: 3.5763\n",
      "[1284/1762] D loss: 0.0698, G loss: 4.0593\n",
      "[1364/1762] D loss: 0.0683, G loss: 3.3084\n",
      "[1444/1762] D loss: 1.4173, G loss: 0.5379\n",
      "[1524/1762] D loss: 0.0603, G loss: 3.9388\n",
      "[1604/1762] D loss: 1.3918, G loss: 0.7168\n",
      "[1684/1762] D loss: 1.3900, G loss: 0.7239\n",
      "[1762/1762] D loss: 1.5256, G loss: 0.4555\n",
      "train error: \n",
      " D loss: 1.898992, G loss: 1.191876, D accuracy: 50.7%, cell accuracy: 99.8%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.808654, G loss: 1.431407, D accuracy: 51.4%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3851, G loss: 0.6969\n",
      "[84/1762] D loss: 0.1791, G loss: 2.4817\n",
      "[164/1762] D loss: 1.3884, G loss: 0.7561\n",
      "[244/1762] D loss: 1.1232, G loss: 1.2426\n",
      "[324/1762] D loss: 0.1478, G loss: 4.4100\n",
      "[404/1762] D loss: 1.3979, G loss: 0.6622\n",
      "[484/1762] D loss: 0.0719, G loss: 4.8025\n",
      "[564/1762] D loss: 0.0667, G loss: 5.0105\n",
      "[644/1762] D loss: 1.4075, G loss: 0.8121\n",
      "[724/1762] D loss: 1.4256, G loss: 0.8760\n",
      "[804/1762] D loss: 0.0379, G loss: 5.3085\n",
      "[884/1762] D loss: 1.3879, G loss: 0.6736\n",
      "[964/1762] D loss: 0.0431, G loss: 5.9013\n",
      "[1044/1762] D loss: 0.0753, G loss: 4.0530\n",
      "[1124/1762] D loss: 1.3925, G loss: 0.6631\n",
      "[1204/1762] D loss: 1.3172, G loss: 0.7986\n",
      "[1284/1762] D loss: 1.3980, G loss: 0.7779\n",
      "[1364/1762] D loss: 1.3853, G loss: 0.7052\n",
      "[1444/1762] D loss: 0.0889, G loss: 3.9828\n",
      "[1524/1762] D loss: 1.3903, G loss: 0.6492\n",
      "[1604/1762] D loss: 1.3914, G loss: 0.7524\n",
      "[1684/1762] D loss: 1.3722, G loss: 0.8960\n",
      "[1762/1762] D loss: 0.0066, G loss: 7.0978\n",
      "train error: \n",
      " D loss: 2.022837, G loss: 0.921288, D accuracy: 50.8%, cell accuracy: 99.8%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.959212, G loss: 1.157056, D accuracy: 51.6%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4050, G loss: 0.7921\n",
      "[84/1762] D loss: 1.3949, G loss: 0.7891\n",
      "[164/1762] D loss: 1.3956, G loss: 0.7309\n",
      "[244/1762] D loss: 1.4002, G loss: 0.8148\n",
      "[324/1762] D loss: 0.0718, G loss: 4.9266\n",
      "[404/1762] D loss: 1.3972, G loss: 0.6211\n",
      "[484/1762] D loss: 1.3885, G loss: 0.7194\n",
      "[564/1762] D loss: 1.3876, G loss: 0.7199\n",
      "[644/1762] D loss: 1.4076, G loss: 0.8133\n",
      "[724/1762] D loss: 1.3840, G loss: 0.6934\n",
      "[804/1762] D loss: 0.0097, G loss: 5.4862\n",
      "[884/1762] D loss: 0.0364, G loss: 5.4055\n",
      "[964/1762] D loss: 1.3895, G loss: 0.6599\n",
      "[1044/1762] D loss: 1.3899, G loss: 0.7025\n",
      "[1124/1762] D loss: 1.3486, G loss: 0.7696\n",
      "[1204/1762] D loss: 1.3872, G loss: 0.6621\n",
      "[1284/1762] D loss: 0.1184, G loss: 3.3333\n",
      "[1364/1762] D loss: 1.3876, G loss: 0.6678\n",
      "[1444/1762] D loss: 1.3960, G loss: 0.7799\n",
      "[1524/1762] D loss: 0.0730, G loss: 3.9210\n",
      "[1604/1762] D loss: 1.4023, G loss: 0.6118\n",
      "[1684/1762] D loss: 1.3929, G loss: 0.7568\n",
      "[1762/1762] D loss: 1.3872, G loss: 0.6708\n",
      "train error: \n",
      " D loss: 2.294734, G loss: 0.935792, D accuracy: 51.1%, cell accuracy: 99.8%, board accuracy: 90.6% \n",
      "\n",
      "test error: \n",
      " D loss: 2.227056, G loss: 1.155693, D accuracy: 51.7%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8268, G loss: 2.7076\n",
      "[84/1762] D loss: 1.3874, G loss: 0.6702\n",
      "[164/1762] D loss: 1.3868, G loss: 0.6726\n",
      "[244/1762] D loss: 0.0293, G loss: 5.7144\n",
      "[324/1762] D loss: 1.4088, G loss: 0.8026\n",
      "[404/1762] D loss: 0.0174, G loss: 5.9814\n",
      "[484/1762] D loss: 0.0171, G loss: 6.0200\n",
      "[564/1762] D loss: 1.3858, G loss: 0.6668\n",
      "[644/1762] D loss: 1.3904, G loss: 0.7640\n",
      "[724/1762] D loss: 1.3877, G loss: 0.6659\n",
      "[804/1762] D loss: 1.3889, G loss: 0.6753\n",
      "[884/1762] D loss: 1.3899, G loss: 0.6349\n",
      "[964/1762] D loss: 1.3872, G loss: 0.6903\n",
      "[1044/1762] D loss: 0.0023, G loss: 12.6519\n",
      "[1124/1762] D loss: 1.3876, G loss: 0.6957\n",
      "[1204/1762] D loss: 1.3874, G loss: 0.7157\n",
      "[1284/1762] D loss: 1.3902, G loss: 0.7429\n",
      "[1364/1762] D loss: 0.0246, G loss: 5.7559\n",
      "[1444/1762] D loss: 1.3872, G loss: 0.7150\n",
      "[1524/1762] D loss: 1.3875, G loss: 0.7269\n",
      "[1604/1762] D loss: 1.3870, G loss: 0.6588\n",
      "[1684/1762] D loss: 0.0016, G loss: 11.8378\n",
      "[1762/1762] D loss: 1.4080, G loss: 0.5550\n",
      "train error: \n",
      " D loss: 2.959024, G loss: 1.110823, D accuracy: 50.1%, cell accuracy: 99.8%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 2.995243, G loss: 1.339184, D accuracy: 50.3%, cell accuracy: 99.7%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3895, G loss: 0.6397\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6948\n",
      "[164/1762] D loss: 1.2542, G loss: 1.3883\n",
      "[244/1762] D loss: 1.3874, G loss: 0.6634\n",
      "[324/1762] D loss: 1.3933, G loss: 0.6646\n",
      "[404/1762] D loss: 1.3910, G loss: 0.6439\n",
      "[484/1762] D loss: 1.3879, G loss: 0.7223\n",
      "[564/1762] D loss: 1.3874, G loss: 0.6726\n",
      "[644/1762] D loss: 1.3893, G loss: 0.7445\n",
      "[724/1762] D loss: 1.3867, G loss: 0.6914\n",
      "[804/1762] D loss: 1.3901, G loss: 0.7590\n",
      "[884/1762] D loss: 0.0619, G loss: 4.8123\n",
      "[964/1762] D loss: 0.0407, G loss: 6.1892\n",
      "[1044/1762] D loss: 1.3913, G loss: 0.7663\n",
      "[1124/1762] D loss: 0.0133, G loss: 4.9823\n",
      "[1204/1762] D loss: 1.3883, G loss: 0.7485\n",
      "[1284/1762] D loss: 1.3941, G loss: 0.6010\n",
      "[1364/1762] D loss: 1.3882, G loss: 0.6721\n",
      "[1444/1762] D loss: 1.3805, G loss: 0.7368\n",
      "[1524/1762] D loss: 0.0080, G loss: 5.7847\n",
      "[1604/1762] D loss: 1.3954, G loss: 0.7667\n",
      "[1684/1762] D loss: 1.3943, G loss: 0.6190\n",
      "[1762/1762] D loss: 1.3975, G loss: 0.5892\n",
      "train error: \n",
      " D loss: 2.657108, G loss: 0.944419, D accuracy: 50.0%, cell accuracy: 99.8%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 2.585720, G loss: 1.173652, D accuracy: 50.0%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3891, G loss: 0.6730\n",
      "[84/1762] D loss: 1.3872, G loss: 0.7136\n",
      "[164/1762] D loss: 1.3886, G loss: 0.6528\n",
      "[244/1762] D loss: 1.3880, G loss: 0.7324\n",
      "[324/1762] D loss: 1.3886, G loss: 0.6693\n",
      "[404/1762] D loss: 1.3810, G loss: 0.6039\n",
      "[484/1762] D loss: 1.4007, G loss: 0.7759\n",
      "[564/1762] D loss: 1.3871, G loss: 0.6954\n",
      "[644/1762] D loss: 0.0414, G loss: 3.9646\n",
      "[724/1762] D loss: 1.3880, G loss: 0.6728\n",
      "[804/1762] D loss: 1.3871, G loss: 0.7086\n",
      "[884/1762] D loss: 1.3875, G loss: 0.7100\n",
      "[964/1762] D loss: 1.3871, G loss: 0.6663\n",
      "[1044/1762] D loss: 0.0244, G loss: 5.9332\n",
      "[1124/1762] D loss: 0.0192, G loss: 6.2133\n",
      "[1204/1762] D loss: 1.3777, G loss: 0.6759\n",
      "[1284/1762] D loss: 0.0189, G loss: 6.0723\n",
      "[1364/1762] D loss: 0.0071, G loss: 7.0869\n",
      "[1444/1762] D loss: 1.3982, G loss: 0.6307\n",
      "[1524/1762] D loss: 1.3933, G loss: 0.6633\n",
      "[1604/1762] D loss: 0.0460, G loss: 5.8878\n",
      "[1684/1762] D loss: 0.0269, G loss: 3.9576\n",
      "[1762/1762] D loss: 1.3824, G loss: 0.7453\n",
      "train error: \n",
      " D loss: 4.050704, G loss: 1.270099, D accuracy: 41.9%, cell accuracy: 99.7%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 4.362121, G loss: 1.443241, D accuracy: 41.0%, cell accuracy: 99.6%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3981, G loss: 0.8038\n",
      "[84/1762] D loss: 1.4040, G loss: 0.8390\n",
      "[164/1762] D loss: 1.4549, G loss: 0.8649\n",
      "[244/1762] D loss: 1.3884, G loss: 0.7231\n",
      "[324/1762] D loss: 0.0771, G loss: 4.0689\n",
      "[404/1762] D loss: 1.3916, G loss: 0.7572\n",
      "[484/1762] D loss: 1.3712, G loss: 0.7405\n",
      "[564/1762] D loss: 0.0008, G loss: 14.8786\n",
      "[644/1762] D loss: 1.3852, G loss: 0.6347\n",
      "[724/1762] D loss: 1.3931, G loss: 0.6961\n",
      "[804/1762] D loss: 1.3654, G loss: 0.6998\n",
      "[884/1762] D loss: 1.3883, G loss: 0.7871\n",
      "[964/1762] D loss: 0.0091, G loss: 7.4053\n",
      "[1044/1762] D loss: 1.2499, G loss: 1.0722\n",
      "[1124/1762] D loss: 1.3569, G loss: 0.7925\n",
      "[1204/1762] D loss: 0.0014, G loss: 20.7577\n",
      "[1284/1762] D loss: 1.4041, G loss: 0.8154\n",
      "[1364/1762] D loss: 1.1330, G loss: 0.9392\n",
      "[1444/1762] D loss: 1.4331, G loss: 0.5370\n",
      "[1524/1762] D loss: 0.0051, G loss: 7.2571\n",
      "[1604/1762] D loss: 1.3881, G loss: 0.7206\n",
      "[1684/1762] D loss: 1.3894, G loss: 0.7179\n",
      "[1762/1762] D loss: 1.3914, G loss: 0.6395\n",
      "train error: \n",
      " D loss: 3.194663, G loss: 1.068475, D accuracy: 50.0%, cell accuracy: 99.7%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 3.294126, G loss: 1.283032, D accuracy: 49.9%, cell accuracy: 99.6%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3840, G loss: 0.7187\n",
      "[84/1762] D loss: 1.3851, G loss: 0.6866\n",
      "[164/1762] D loss: 1.3843, G loss: 0.6769\n",
      "[244/1762] D loss: 0.0095, G loss: 6.8989\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6448\n",
      "[404/1762] D loss: 1.3865, G loss: 0.6817\n",
      "[484/1762] D loss: 1.2188, G loss: 1.1647\n",
      "[564/1762] D loss: 0.0120, G loss: 6.2090\n",
      "[644/1762] D loss: 1.3868, G loss: 0.7089\n",
      "[724/1762] D loss: 0.0006, G loss: 10.0015\n",
      "[804/1762] D loss: 0.0017, G loss: 7.7346\n",
      "[884/1762] D loss: 1.3751, G loss: 0.7498\n",
      "[964/1762] D loss: 0.9008, G loss: 2.7589\n",
      "[1044/1762] D loss: 0.0108, G loss: 6.9781\n",
      "[1124/1762] D loss: 0.0078, G loss: 6.7263\n",
      "[1204/1762] D loss: 1.3867, G loss: 0.7208\n",
      "[1284/1762] D loss: 0.0074, G loss: 6.0872\n",
      "[1364/1762] D loss: 0.2337, G loss: 4.0979\n",
      "[1444/1762] D loss: 1.2000, G loss: 2.2307\n",
      "[1524/1762] D loss: 1.3862, G loss: 0.6944\n",
      "[1604/1762] D loss: 1.3920, G loss: 0.6585\n",
      "[1684/1762] D loss: 1.3935, G loss: 0.7662\n",
      "[1762/1762] D loss: 1.3843, G loss: 0.6762\n",
      "train error: \n",
      " D loss: 3.826343, G loss: 0.975181, D accuracy: 49.9%, cell accuracy: 99.7%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 4.067095, G loss: 1.179733, D accuracy: 49.9%, cell accuracy: 99.7%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4121, G loss: 0.5479\n",
      "[84/1762] D loss: 1.6100, G loss: 1.0641\n",
      "[164/1762] D loss: 0.4236, G loss: 5.1282\n",
      "[244/1762] D loss: 1.3949, G loss: 0.8327\n",
      "[324/1762] D loss: 1.3917, G loss: 0.7473\n",
      "[404/1762] D loss: 1.3947, G loss: 0.6388\n",
      "[484/1762] D loss: 1.3680, G loss: 0.6712\n",
      "[564/1762] D loss: 0.8483, G loss: 0.8873\n",
      "[644/1762] D loss: 1.3531, G loss: 0.5875\n",
      "[724/1762] D loss: 1.3819, G loss: 0.6439\n",
      "[804/1762] D loss: 1.3826, G loss: 0.7206\n",
      "[884/1762] D loss: 1.6480, G loss: 2.1488\n",
      "[964/1762] D loss: 1.2098, G loss: 1.0562\n",
      "[1044/1762] D loss: 1.3902, G loss: 0.7586\n",
      "[1124/1762] D loss: 1.3916, G loss: 0.7322\n",
      "[1204/1762] D loss: 1.2253, G loss: 2.1136\n",
      "[1284/1762] D loss: 1.3870, G loss: 0.6740\n",
      "[1364/1762] D loss: 1.4145, G loss: 0.6125\n",
      "[1444/1762] D loss: 1.3528, G loss: 0.6587\n",
      "[1524/1762] D loss: 0.6247, G loss: 2.1931\n",
      "[1604/1762] D loss: 0.8649, G loss: 0.9285\n",
      "[1684/1762] D loss: 1.3920, G loss: 0.7688\n",
      "[1762/1762] D loss: 1.3871, G loss: 0.7010\n",
      "train error: \n",
      " D loss: 1.412449, G loss: 0.767775, D accuracy: 50.6%, cell accuracy: 99.9%, board accuracy: 90.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.424312, G loss: 0.758336, D accuracy: 50.0%, cell accuracy: 99.9%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2229, G loss: 0.8733\n",
      "[84/1762] D loss: 1.3875, G loss: 0.7047\n",
      "[164/1762] D loss: 0.9259, G loss: 0.8340\n",
      "[244/1762] D loss: 0.8263, G loss: 1.7909\n",
      "[324/1762] D loss: 1.3872, G loss: 0.7435\n",
      "[404/1762] D loss: 1.7207, G loss: 0.4841\n",
      "[484/1762] D loss: 1.3913, G loss: 0.6878\n",
      "[564/1762] D loss: 1.1442, G loss: 0.7867\n",
      "[644/1762] D loss: 1.3928, G loss: 0.7206\n",
      "[724/1762] D loss: 1.3954, G loss: 0.6808\n",
      "[804/1762] D loss: 1.3890, G loss: 0.6745\n",
      "[884/1762] D loss: 1.4547, G loss: 0.4963\n",
      "[964/1762] D loss: 1.3901, G loss: 0.7152\n",
      "[1044/1762] D loss: 1.3876, G loss: 0.6770\n",
      "[1124/1762] D loss: 1.3884, G loss: 0.7150\n",
      "[1204/1762] D loss: 0.5310, G loss: 1.5898\n",
      "[1284/1762] D loss: 1.4228, G loss: 0.8765\n",
      "[1364/1762] D loss: 1.3907, G loss: 0.6681\n",
      "[1444/1762] D loss: 0.7184, G loss: 0.8230\n",
      "[1524/1762] D loss: 1.3905, G loss: 0.7402\n",
      "[1604/1762] D loss: 1.3588, G loss: 0.7986\n",
      "[1684/1762] D loss: 0.7615, G loss: 1.1684\n",
      "[1762/1762] D loss: 1.3873, G loss: 0.7057\n",
      "train error: \n",
      " D loss: 1.430902, G loss: 0.850645, D accuracy: 50.7%, cell accuracy: 99.9%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.445872, G loss: 0.867974, D accuracy: 51.2%, cell accuracy: 99.9%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3906, G loss: 0.6598\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6942\n",
      "[164/1762] D loss: 0.4776, G loss: 1.1367\n",
      "[244/1762] D loss: 1.4200, G loss: 0.9180\n",
      "[324/1762] D loss: 0.5428, G loss: 1.0748\n",
      "[404/1762] D loss: 1.3987, G loss: 0.7388\n",
      "[484/1762] D loss: 1.3987, G loss: 0.5928\n",
      "[564/1762] D loss: 1.3875, G loss: 0.7767\n",
      "[644/1762] D loss: 1.9406, G loss: 0.2378\n",
      "[724/1762] D loss: 1.3882, G loss: 0.6569\n",
      "[804/1762] D loss: 1.3936, G loss: 0.6450\n",
      "[884/1762] D loss: 1.4540, G loss: 0.4733\n",
      "[964/1762] D loss: 1.3862, G loss: 0.7124\n",
      "[1044/1762] D loss: 1.3808, G loss: 0.6827\n",
      "[1124/1762] D loss: 1.3902, G loss: 0.6828\n",
      "[1204/1762] D loss: 1.4124, G loss: 0.5704\n",
      "[1284/1762] D loss: 1.4368, G loss: 1.1139\n",
      "[1364/1762] D loss: 1.3908, G loss: 0.7485\n",
      "[1444/1762] D loss: 1.3872, G loss: 0.7337\n",
      "[1524/1762] D loss: 1.3899, G loss: 0.7434\n",
      "[1604/1762] D loss: 0.5307, G loss: 1.2159\n",
      "[1684/1762] D loss: 1.4029, G loss: 0.8550\n",
      "[1762/1762] D loss: 1.3952, G loss: 0.7750\n",
      "train error: \n",
      " D loss: 1.411794, G loss: 1.000349, D accuracy: 50.0%, cell accuracy: 99.9%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.396769, G loss: 1.035499, D accuracy: 50.3%, cell accuracy: 99.9%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3868, G loss: 0.7307\n",
      "[84/1762] D loss: 0.4529, G loss: 1.2305\n",
      "[164/1762] D loss: 1.5822, G loss: 1.2055\n",
      "[244/1762] D loss: 1.7384, G loss: 1.5303\n",
      "[324/1762] D loss: 1.3812, G loss: 0.6981\n",
      "[404/1762] D loss: 1.2356, G loss: 2.3091\n",
      "[484/1762] D loss: 1.3970, G loss: 0.5952\n",
      "[564/1762] D loss: 1.3891, G loss: 0.6778\n",
      "[644/1762] D loss: 1.3870, G loss: 0.7199\n",
      "[724/1762] D loss: 1.3940, G loss: 0.7015\n",
      "[804/1762] D loss: 1.3917, G loss: 0.7741\n",
      "[884/1762] D loss: 1.3866, G loss: 0.6569\n",
      "[964/1762] D loss: 1.3865, G loss: 0.6891\n",
      "[1044/1762] D loss: 0.6169, G loss: 0.9668\n",
      "[1124/1762] D loss: 1.3871, G loss: 0.6828\n",
      "[1204/1762] D loss: 0.7738, G loss: 0.7796\n",
      "[1284/1762] D loss: 1.3831, G loss: 0.6814\n",
      "[1364/1762] D loss: 1.3868, G loss: 0.7157\n",
      "[1444/1762] D loss: 1.3823, G loss: 0.6543\n",
      "[1524/1762] D loss: 1.3957, G loss: 0.6337\n",
      "[1604/1762] D loss: 1.0119, G loss: 2.0479\n",
      "[1684/1762] D loss: 1.3947, G loss: 0.6164\n",
      "[1762/1762] D loss: 0.1608, G loss: 2.4232\n",
      "train error: \n",
      " D loss: 1.373947, G loss: 0.944146, D accuracy: 51.3%, cell accuracy: 99.9%, board accuracy: 91.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.376609, G loss: 0.963196, D accuracy: 50.8%, cell accuracy: 99.9%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3905, G loss: 0.6607\n",
      "[84/1762] D loss: 1.3945, G loss: 0.6403\n",
      "[164/1762] D loss: 1.1347, G loss: 1.1681\n",
      "[244/1762] D loss: 1.3991, G loss: 0.5935\n",
      "[324/1762] D loss: 1.3961, G loss: 0.6108\n",
      "[404/1762] D loss: 1.3938, G loss: 0.6240\n",
      "[484/1762] D loss: 1.2008, G loss: 0.8440\n",
      "[564/1762] D loss: 0.5542, G loss: 1.5847\n",
      "[644/1762] D loss: 0.2893, G loss: 2.5361\n",
      "[724/1762] D loss: 1.3881, G loss: 0.6815\n",
      "[804/1762] D loss: 1.3868, G loss: 0.6957\n",
      "[884/1762] D loss: 1.4051, G loss: 0.5928\n",
      "[964/1762] D loss: 1.3886, G loss: 0.6488\n",
      "[1044/1762] D loss: 1.3751, G loss: 0.6308\n",
      "[1124/1762] D loss: 1.3884, G loss: 0.7113\n",
      "[1204/1762] D loss: 1.3751, G loss: 0.7111\n",
      "[1284/1762] D loss: 0.3554, G loss: 1.2858\n",
      "[1364/1762] D loss: 1.3868, G loss: 0.6761\n",
      "[1444/1762] D loss: 1.3870, G loss: 0.7083\n",
      "[1524/1762] D loss: 1.3872, G loss: 0.6979\n",
      "[1604/1762] D loss: 1.4063, G loss: 0.8377\n",
      "[1684/1762] D loss: 1.3722, G loss: 0.6827\n",
      "[1762/1762] D loss: 1.3280, G loss: 0.7169\n",
      "train error: \n",
      " D loss: 1.487745, G loss: 1.023238, D accuracy: 50.6%, cell accuracy: 99.8%, board accuracy: 87.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.496948, G loss: 0.973809, D accuracy: 50.7%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8072, G loss: 1.1697\n",
      "[84/1762] D loss: 1.0039, G loss: 1.1989\n",
      "[164/1762] D loss: 0.3704, G loss: 1.3105\n",
      "[244/1762] D loss: 1.3899, G loss: 0.6331\n",
      "[324/1762] D loss: 1.3924, G loss: 0.7694\n",
      "[404/1762] D loss: 1.2293, G loss: 1.3024\n",
      "[484/1762] D loss: 1.2726, G loss: 1.6385\n",
      "[564/1762] D loss: 1.7687, G loss: 1.7370\n",
      "[644/1762] D loss: 1.3904, G loss: 0.6407\n",
      "[724/1762] D loss: 1.3886, G loss: 0.6576\n",
      "[804/1762] D loss: 1.4223, G loss: 0.5771\n",
      "[884/1762] D loss: 1.4208, G loss: 0.6149\n",
      "[964/1762] D loss: 1.3867, G loss: 0.6849\n",
      "[1044/1762] D loss: 1.3890, G loss: 0.6273\n",
      "[1124/1762] D loss: 1.3859, G loss: 0.6626\n",
      "[1204/1762] D loss: 1.2949, G loss: 1.4036\n",
      "[1284/1762] D loss: 1.3856, G loss: 0.6974\n",
      "[1364/1762] D loss: 1.3903, G loss: 0.6972\n",
      "[1444/1762] D loss: 0.2747, G loss: 1.4777\n",
      "[1524/1762] D loss: 1.5371, G loss: 0.4621\n",
      "[1604/1762] D loss: 1.3872, G loss: 0.7240\n",
      "[1684/1762] D loss: 0.2074, G loss: 1.8116\n",
      "[1762/1762] D loss: 1.4008, G loss: 0.8261\n",
      "train error: \n",
      " D loss: 1.397902, G loss: 1.157209, D accuracy: 50.9%, cell accuracy: 99.9%, board accuracy: 90.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.382742, G loss: 1.213294, D accuracy: 51.1%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3919, G loss: 0.7549\n",
      "[84/1762] D loss: 1.3944, G loss: 0.5964\n",
      "[164/1762] D loss: 1.7453, G loss: 1.5657\n",
      "[244/1762] D loss: 1.0814, G loss: 1.5496\n",
      "[324/1762] D loss: 0.3917, G loss: 1.1741\n",
      "[404/1762] D loss: 1.1758, G loss: 0.9240\n",
      "[484/1762] D loss: 1.3601, G loss: 0.7069\n",
      "[564/1762] D loss: 1.3865, G loss: 0.6822\n",
      "[644/1762] D loss: 0.9826, G loss: 3.1313\n",
      "[724/1762] D loss: 0.2647, G loss: 1.4849\n",
      "[804/1762] D loss: 1.3885, G loss: 0.6918\n",
      "[884/1762] D loss: 1.3958, G loss: 0.6555\n",
      "[964/1762] D loss: 1.3981, G loss: 0.7677\n",
      "[1044/1762] D loss: 0.8121, G loss: 1.6060\n",
      "[1124/1762] D loss: 1.3930, G loss: 0.7405\n",
      "[1204/1762] D loss: 1.3917, G loss: 0.6572\n",
      "[1284/1762] D loss: 0.8839, G loss: 1.0950\n",
      "[1364/1762] D loss: 1.4025, G loss: 0.5722\n",
      "[1444/1762] D loss: 1.3954, G loss: 0.6174\n",
      "[1524/1762] D loss: 1.3963, G loss: 0.7053\n",
      "[1604/1762] D loss: 0.1574, G loss: 2.0833\n",
      "[1684/1762] D loss: 1.3934, G loss: 0.7888\n",
      "[1762/1762] D loss: 1.4438, G loss: 0.5418\n",
      "train error: \n",
      " D loss: 1.453873, G loss: 1.039124, D accuracy: 50.7%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.446902, G loss: 1.083231, D accuracy: 51.0%, cell accuracy: 99.9%, board accuracy: 91.1% \n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3886, G loss: 0.6834\n",
      "[84/1762] D loss: 1.4783, G loss: 1.0753\n",
      "[164/1762] D loss: 1.6720, G loss: 1.2474\n",
      "[244/1762] D loss: 1.3861, G loss: 0.7149\n",
      "[324/1762] D loss: 0.1809, G loss: 2.9082\n",
      "[404/1762] D loss: 1.4264, G loss: 0.5184\n",
      "[484/1762] D loss: 1.3881, G loss: 0.6870\n",
      "[564/1762] D loss: 1.3919, G loss: 0.7642\n",
      "[644/1762] D loss: 1.3920, G loss: 0.7564\n",
      "[724/1762] D loss: 1.3942, G loss: 0.6285\n",
      "[804/1762] D loss: 0.4842, G loss: 1.0249\n",
      "[884/1762] D loss: 1.4044, G loss: 0.8091\n",
      "[964/1762] D loss: 0.2214, G loss: 1.6796\n",
      "[1044/1762] D loss: 1.3900, G loss: 0.6586\n",
      "[1124/1762] D loss: 0.4390, G loss: 1.3543\n",
      "[1204/1762] D loss: 1.3870, G loss: 0.6960\n",
      "[1284/1762] D loss: 1.3971, G loss: 0.6020\n",
      "[1364/1762] D loss: 1.4047, G loss: 0.8124\n",
      "[1444/1762] D loss: 1.2627, G loss: 0.6957\n",
      "[1524/1762] D loss: 0.6197, G loss: 0.8869\n",
      "[1604/1762] D loss: 1.3862, G loss: 0.6976\n",
      "[1684/1762] D loss: 1.3968, G loss: 0.6468\n",
      "[1762/1762] D loss: 1.3892, G loss: 0.6298\n",
      "train error: \n",
      " D loss: 1.456998, G loss: 0.721307, D accuracy: 45.9%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.470936, G loss: 0.722553, D accuracy: 45.1%, cell accuracy: 99.9%, board accuracy: 91.1% \n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4436, G loss: 1.0703\n",
      "[84/1762] D loss: 1.3869, G loss: 0.7073\n",
      "[164/1762] D loss: 1.6628, G loss: 1.1913\n",
      "[244/1762] D loss: 1.3884, G loss: 0.6775\n",
      "[324/1762] D loss: 1.3768, G loss: 2.2922\n",
      "[404/1762] D loss: 1.3895, G loss: 0.7351\n",
      "[484/1762] D loss: 1.3918, G loss: 0.6530\n",
      "[564/1762] D loss: 1.3955, G loss: 0.6018\n",
      "[644/1762] D loss: 1.3941, G loss: 0.6018\n",
      "[724/1762] D loss: 0.0187, G loss: 4.4941\n",
      "[804/1762] D loss: 0.0514, G loss: 3.6694\n",
      "[884/1762] D loss: 1.4250, G loss: 0.6373\n",
      "[964/1762] D loss: 1.3937, G loss: 0.6722\n",
      "[1044/1762] D loss: 1.3862, G loss: 0.6772\n",
      "[1124/1762] D loss: 1.3878, G loss: 0.6895\n",
      "[1204/1762] D loss: 0.9039, G loss: 1.0842\n",
      "[1284/1762] D loss: 1.3868, G loss: 0.6996\n",
      "[1364/1762] D loss: 1.3925, G loss: 0.6375\n",
      "[1444/1762] D loss: 1.4033, G loss: 0.5845\n",
      "[1524/1762] D loss: 1.3901, G loss: 0.7432\n",
      "[1604/1762] D loss: 1.3986, G loss: 0.6839\n",
      "[1684/1762] D loss: 1.4117, G loss: 0.5622\n",
      "[1762/1762] D loss: 1.3597, G loss: 0.6487\n",
      "train error: \n",
      " D loss: 1.369262, G loss: 1.087681, D accuracy: 48.9%, cell accuracy: 99.8%, board accuracy: 79.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.364977, G loss: 1.136202, D accuracy: 49.2%, cell accuracy: 99.8%, board accuracy: 79.3% \n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3436, G loss: 0.6485\n",
      "[84/1762] D loss: 1.3847, G loss: 0.6764\n",
      "[164/1762] D loss: 1.3948, G loss: 0.6590\n",
      "[244/1762] D loss: 0.1848, G loss: 3.0387\n",
      "[324/1762] D loss: 1.4050, G loss: 0.8322\n",
      "[404/1762] D loss: 1.3770, G loss: 0.7009\n",
      "[484/1762] D loss: 1.3872, G loss: 0.6997\n",
      "[564/1762] D loss: 1.3930, G loss: 0.6665\n",
      "[644/1762] D loss: 1.3876, G loss: 0.6809\n",
      "[724/1762] D loss: 1.1069, G loss: 1.3958\n",
      "[804/1762] D loss: 1.3983, G loss: 0.6078\n",
      "[884/1762] D loss: 1.3999, G loss: 0.8002\n",
      "[964/1762] D loss: 1.3922, G loss: 0.6308\n",
      "[1044/1762] D loss: 1.3841, G loss: 0.7076\n",
      "[1124/1762] D loss: 1.3991, G loss: 0.6140\n",
      "[1204/1762] D loss: 1.3952, G loss: 0.6031\n",
      "[1284/1762] D loss: 1.3871, G loss: 0.6833\n",
      "[1364/1762] D loss: 1.3886, G loss: 0.6571\n",
      "[1444/1762] D loss: 1.3875, G loss: 0.7092\n",
      "[1524/1762] D loss: 1.3845, G loss: 0.7088\n",
      "[1604/1762] D loss: 1.3872, G loss: 0.6893\n",
      "[1684/1762] D loss: 1.3869, G loss: 0.6757\n",
      "[1762/1762] D loss: 0.2617, G loss: 1.4970\n",
      "train error: \n",
      " D loss: 1.429512, G loss: 0.669007, D accuracy: 48.7%, cell accuracy: 99.9%, board accuracy: 93.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.431083, G loss: 0.669688, D accuracy: 48.8%, cell accuracy: 99.9%, board accuracy: 91.8% \n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3877, G loss: 0.6694\n",
      "[84/1762] D loss: 1.3970, G loss: 0.6051\n",
      "[164/1762] D loss: 1.3985, G loss: 0.7926\n",
      "[244/1762] D loss: 1.3874, G loss: 0.7096\n",
      "[324/1762] D loss: 1.3891, G loss: 0.7386\n",
      "[404/1762] D loss: 1.3853, G loss: 0.6962\n",
      "[484/1762] D loss: 1.3928, G loss: 0.6690\n",
      "[564/1762] D loss: 0.4526, G loss: 1.0445\n",
      "[644/1762] D loss: 1.3925, G loss: 0.7594\n",
      "[724/1762] D loss: 0.4207, G loss: 1.1263\n",
      "[804/1762] D loss: 1.3927, G loss: 0.6698\n",
      "[884/1762] D loss: 0.4652, G loss: 1.0375\n",
      "[964/1762] D loss: 1.4011, G loss: 0.7904\n",
      "[1044/1762] D loss: 0.8318, G loss: 1.2221\n",
      "[1124/1762] D loss: 1.4062, G loss: 0.8331\n",
      "[1204/1762] D loss: 0.3803, G loss: 1.2152\n",
      "[1284/1762] D loss: 1.3916, G loss: 0.6250\n",
      "[1364/1762] D loss: 0.1866, G loss: 1.8383\n",
      "[1444/1762] D loss: 1.3992, G loss: 0.5911\n",
      "[1524/1762] D loss: 0.1435, G loss: 2.1204\n",
      "[1604/1762] D loss: 1.3965, G loss: 0.6138\n",
      "[1684/1762] D loss: 1.4143, G loss: 0.8337\n",
      "[1762/1762] D loss: 1.3918, G loss: 0.7219\n",
      "train error: \n",
      " D loss: 1.546787, G loss: 1.234110, D accuracy: 51.1%, cell accuracy: 99.9%, board accuracy: 93.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.528001, G loss: 1.221646, D accuracy: 51.6%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4265, G loss: 0.7356\n",
      "[84/1762] D loss: 1.3871, G loss: 0.6889\n",
      "[164/1762] D loss: 1.3880, G loss: 0.6684\n",
      "[244/1762] D loss: 1.3864, G loss: 0.6904\n",
      "[324/1762] D loss: 0.2450, G loss: 1.6175\n",
      "[404/1762] D loss: 1.4037, G loss: 0.5865\n",
      "[484/1762] D loss: 1.3885, G loss: 0.7371\n",
      "[564/1762] D loss: 1.3877, G loss: 0.7474\n",
      "[644/1762] D loss: 1.3868, G loss: 0.6768\n",
      "[724/1762] D loss: 1.3870, G loss: 0.6985\n",
      "[804/1762] D loss: 0.2281, G loss: 1.6980\n",
      "[884/1762] D loss: 0.3438, G loss: 1.3179\n",
      "[964/1762] D loss: 1.4002, G loss: 0.5924\n",
      "[1044/1762] D loss: 1.3834, G loss: 0.7583\n",
      "[1124/1762] D loss: 0.2674, G loss: 1.6033\n",
      "[1204/1762] D loss: 1.6940, G loss: 1.3875\n",
      "[1284/1762] D loss: 1.2318, G loss: 1.3909\n",
      "[1364/1762] D loss: 1.3904, G loss: 0.7528\n",
      "[1444/1762] D loss: 0.2554, G loss: 2.1717\n",
      "[1524/1762] D loss: 1.3876, G loss: 0.6908\n",
      "[1604/1762] D loss: 1.4015, G loss: 0.5863\n",
      "[1684/1762] D loss: 0.6137, G loss: 0.9945\n",
      "[1762/1762] D loss: 1.1006, G loss: 1.9139\n",
      "train error: \n",
      " D loss: 1.529652, G loss: 0.926669, D accuracy: 50.3%, cell accuracy: 99.9%, board accuracy: 93.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.533302, G loss: 0.937535, D accuracy: 50.5%, cell accuracy: 99.9%, board accuracy: 91.4% \n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3884, G loss: 0.6521\n",
      "[84/1762] D loss: 0.9816, G loss: 1.3302\n",
      "[164/1762] D loss: 0.2654, G loss: 1.6483\n",
      "[244/1762] D loss: 1.4121, G loss: 0.7921\n",
      "[324/1762] D loss: 1.7916, G loss: 1.3790\n",
      "[404/1762] D loss: 1.3932, G loss: 0.6397\n",
      "[484/1762] D loss: 1.3850, G loss: 0.7028\n",
      "[564/1762] D loss: 0.1685, G loss: 2.1977\n",
      "[644/1762] D loss: 1.9495, G loss: 1.7130\n",
      "[724/1762] D loss: 1.3936, G loss: 0.6283\n",
      "[804/1762] D loss: 1.3872, G loss: 0.7222\n",
      "[884/1762] D loss: 1.3872, G loss: 0.7175\n",
      "[964/1762] D loss: 0.3890, G loss: 1.1616\n",
      "[1044/1762] D loss: 1.3927, G loss: 0.6216\n",
      "[1124/1762] D loss: 1.4845, G loss: 1.0349\n",
      "[1204/1762] D loss: 1.3784, G loss: 0.6771\n",
      "[1284/1762] D loss: 1.3883, G loss: 0.6827\n",
      "[1364/1762] D loss: 1.4233, G loss: 0.5560\n",
      "[1444/1762] D loss: 0.2014, G loss: 1.9423\n",
      "[1524/1762] D loss: 1.9053, G loss: 1.6570\n",
      "[1604/1762] D loss: 1.3883, G loss: 0.6817\n",
      "[1684/1762] D loss: 0.2254, G loss: 1.6271\n",
      "[1762/1762] D loss: 1.3883, G loss: 0.7415\n",
      "train error: \n",
      " D loss: 1.462774, G loss: 0.764248, D accuracy: 50.6%, cell accuracy: 99.9%, board accuracy: 93.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.443919, G loss: 0.797896, D accuracy: 50.8%, cell accuracy: 99.9%, board accuracy: 91.1% \n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3965, G loss: 0.7811\n",
      "[84/1762] D loss: 2.0442, G loss: 2.2225\n",
      "[164/1762] D loss: 0.2799, G loss: 1.4420\n",
      "[244/1762] D loss: 1.3930, G loss: 0.6196\n",
      "[324/1762] D loss: 0.8941, G loss: 1.5549\n",
      "[404/1762] D loss: 1.3910, G loss: 0.6176\n",
      "[484/1762] D loss: 0.3527, G loss: 1.2644\n",
      "[564/1762] D loss: 1.3880, G loss: 0.6451\n",
      "[644/1762] D loss: 0.2907, G loss: 1.4141\n",
      "[724/1762] D loss: 1.3891, G loss: 0.7411\n",
      "[804/1762] D loss: 1.3880, G loss: 0.6808\n",
      "[884/1762] D loss: 1.3932, G loss: 0.8271\n",
      "[964/1762] D loss: 1.3872, G loss: 0.7141\n",
      "[1044/1762] D loss: 0.2987, G loss: 1.3616\n",
      "[1124/1762] D loss: 1.3965, G loss: 0.6125\n",
      "[1204/1762] D loss: 1.4055, G loss: 0.5778\n",
      "[1284/1762] D loss: 1.3886, G loss: 0.6663\n",
      "[1364/1762] D loss: 2.1176, G loss: 0.5014\n",
      "[1444/1762] D loss: 1.4050, G loss: 0.5697\n",
      "[1524/1762] D loss: 0.8668, G loss: 2.3546\n",
      "[1604/1762] D loss: 1.3888, G loss: 0.6702\n",
      "[1684/1762] D loss: 1.3884, G loss: 0.6578\n",
      "[1762/1762] D loss: 0.1746, G loss: 2.1483\n",
      "train error: \n",
      " D loss: 1.426406, G loss: 0.820084, D accuracy: 50.8%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.466072, G loss: 0.767436, D accuracy: 50.7%, cell accuracy: 99.9%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3898, G loss: 0.6992\n",
      "[84/1762] D loss: 1.3920, G loss: 0.6261\n",
      "[164/1762] D loss: 1.3881, G loss: 0.7144\n",
      "[244/1762] D loss: 1.5338, G loss: 0.9530\n",
      "[324/1762] D loss: 1.3990, G loss: 0.7115\n",
      "[404/1762] D loss: 1.4271, G loss: 0.6834\n",
      "[484/1762] D loss: 1.4062, G loss: 0.8280\n",
      "[564/1762] D loss: 1.3921, G loss: 0.6300\n",
      "[644/1762] D loss: 1.3371, G loss: 1.2534\n",
      "[724/1762] D loss: 1.3974, G loss: 0.7988\n",
      "[804/1762] D loss: 1.3871, G loss: 0.6801\n",
      "[884/1762] D loss: 1.3930, G loss: 0.7346\n",
      "[964/1762] D loss: 0.2975, G loss: 1.5061\n",
      "[1044/1762] D loss: 1.4264, G loss: 0.5308\n",
      "[1124/1762] D loss: 1.3866, G loss: 0.6817\n",
      "[1204/1762] D loss: 0.5471, G loss: 1.0410\n",
      "[1284/1762] D loss: 1.3888, G loss: 0.7583\n",
      "[1364/1762] D loss: 1.3847, G loss: 0.7322\n",
      "[1444/1762] D loss: 0.8345, G loss: 1.9786\n",
      "[1524/1762] D loss: 0.2150, G loss: 2.9833\n",
      "[1604/1762] D loss: 1.4250, G loss: 0.8423\n",
      "[1684/1762] D loss: 1.4095, G loss: 0.7451\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.6789\n",
      "train error: \n",
      " D loss: 1.427178, G loss: 0.865910, D accuracy: 49.4%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.428833, G loss: 0.851166, D accuracy: 49.2%, cell accuracy: 99.9%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4012, G loss: 0.7561\n",
      "[84/1762] D loss: 1.4162, G loss: 0.8683\n",
      "[164/1762] D loss: 1.4012, G loss: 0.5784\n",
      "[244/1762] D loss: 0.3466, G loss: 1.2432\n",
      "[324/1762] D loss: 1.3848, G loss: 0.6860\n",
      "[404/1762] D loss: 0.2658, G loss: 1.5897\n",
      "[484/1762] D loss: 1.3878, G loss: 0.6232\n",
      "[564/1762] D loss: 1.3882, G loss: 0.6924\n",
      "[644/1762] D loss: 1.3935, G loss: 0.7781\n",
      "[724/1762] D loss: 1.3833, G loss: 0.7059\n",
      "[804/1762] D loss: 1.3822, G loss: 0.6910\n",
      "[884/1762] D loss: 1.3821, G loss: 0.6987\n",
      "[964/1762] D loss: 1.3730, G loss: 0.6757\n",
      "[1044/1762] D loss: 1.3883, G loss: 0.6671\n",
      "[1124/1762] D loss: 1.5780, G loss: 1.1933\n",
      "[1204/1762] D loss: 1.3870, G loss: 0.7002\n",
      "[1284/1762] D loss: 1.3897, G loss: 0.6496\n",
      "[1364/1762] D loss: 1.3907, G loss: 0.7834\n",
      "[1444/1762] D loss: 1.4193, G loss: 0.5665\n",
      "[1524/1762] D loss: 1.3918, G loss: 0.6884\n",
      "[1604/1762] D loss: 1.3934, G loss: 0.6098\n",
      "[1684/1762] D loss: 0.1688, G loss: 2.2251\n",
      "[1762/1762] D loss: 1.3897, G loss: 0.7228\n",
      "train error: \n",
      " D loss: 1.480622, G loss: 1.180215, D accuracy: 50.6%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.475952, G loss: 1.229978, D accuracy: 50.5%, cell accuracy: 99.9%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3875, G loss: 0.7007\n",
      "[84/1762] D loss: 1.3883, G loss: 0.6475\n",
      "[164/1762] D loss: 1.3866, G loss: 0.6592\n",
      "[244/1762] D loss: 1.3865, G loss: 0.6948\n",
      "[324/1762] D loss: 1.3870, G loss: 0.6981\n",
      "[404/1762] D loss: 1.3865, G loss: 0.6955\n",
      "[484/1762] D loss: 0.8057, G loss: 1.7083\n",
      "[564/1762] D loss: 1.3935, G loss: 0.6476\n",
      "[644/1762] D loss: 1.3873, G loss: 0.7220\n",
      "[724/1762] D loss: 1.3944, G loss: 0.6145\n",
      "[804/1762] D loss: 1.3913, G loss: 0.7591\n",
      "[884/1762] D loss: 1.3883, G loss: 0.6664\n",
      "[964/1762] D loss: 1.4012, G loss: 0.7071\n",
      "[1044/1762] D loss: 1.4000, G loss: 0.6646\n",
      "[1124/1762] D loss: 1.3872, G loss: 0.7154\n",
      "[1204/1762] D loss: 1.3808, G loss: 0.7001\n",
      "[1284/1762] D loss: 0.5805, G loss: 0.9101\n",
      "[1364/1762] D loss: 1.3899, G loss: 0.7535\n",
      "[1444/1762] D loss: 1.3878, G loss: 0.6797\n",
      "[1524/1762] D loss: 1.3905, G loss: 0.6426\n",
      "[1604/1762] D loss: 1.3907, G loss: 0.6355\n",
      "[1684/1762] D loss: 1.3895, G loss: 0.7005\n",
      "[1762/1762] D loss: 1.4212, G loss: 0.7992\n",
      "train error: \n",
      " D loss: 1.468255, G loss: 0.949208, D accuracy: 50.3%, cell accuracy: 99.9%, board accuracy: 93.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.452536, G loss: 1.016965, D accuracy: 50.3%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3909, G loss: 0.7013\n",
      "[84/1762] D loss: 0.1786, G loss: 1.9989\n",
      "[164/1762] D loss: 1.3894, G loss: 0.6428\n",
      "[244/1762] D loss: 1.3885, G loss: 0.6912\n",
      "[324/1762] D loss: 1.3928, G loss: 0.6398\n",
      "[404/1762] D loss: 1.2435, G loss: 0.4417\n",
      "[484/1762] D loss: 1.3908, G loss: 0.6282\n",
      "[564/1762] D loss: 1.3888, G loss: 0.7152\n",
      "[644/1762] D loss: 1.3874, G loss: 0.6945\n",
      "[724/1762] D loss: 1.3980, G loss: 0.5941\n",
      "[804/1762] D loss: 1.3896, G loss: 0.7590\n",
      "[884/1762] D loss: 1.4034, G loss: 0.8235\n",
      "[964/1762] D loss: 1.4890, G loss: 0.5079\n",
      "[1044/1762] D loss: 0.3901, G loss: 1.5032\n",
      "[1124/1762] D loss: 1.3884, G loss: 0.6516\n",
      "[1204/1762] D loss: 1.3893, G loss: 0.7030\n",
      "[1284/1762] D loss: 0.3120, G loss: 1.3501\n",
      "[1364/1762] D loss: 1.3895, G loss: 0.6753\n",
      "[1444/1762] D loss: 0.8062, G loss: 3.1161\n",
      "[1524/1762] D loss: 0.4796, G loss: 1.4420\n",
      "[1604/1762] D loss: 1.3904, G loss: 0.6620\n",
      "[1684/1762] D loss: 1.3905, G loss: 0.7349\n",
      "[1762/1762] D loss: 1.3866, G loss: 0.6927\n",
      "train error: \n",
      " D loss: 1.516513, G loss: 0.969072, D accuracy: 50.4%, cell accuracy: 99.9%, board accuracy: 93.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.512627, G loss: 0.969745, D accuracy: 50.6%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.0574, G loss: 1.6708\n",
      "[84/1762] D loss: 1.7724, G loss: 0.3502\n",
      "[164/1762] D loss: 1.3957, G loss: 0.7823\n",
      "[244/1762] D loss: 1.3870, G loss: 0.7009\n",
      "[324/1762] D loss: 1.3929, G loss: 0.6762\n",
      "[404/1762] D loss: 1.3885, G loss: 0.6676\n",
      "[484/1762] D loss: 0.3987, G loss: 1.1015\n",
      "[564/1762] D loss: 1.3892, G loss: 0.6481\n",
      "[644/1762] D loss: 1.3963, G loss: 0.7987\n",
      "[724/1762] D loss: 1.3878, G loss: 0.6570\n",
      "[804/1762] D loss: 1.3867, G loss: 0.6756\n",
      "[884/1762] D loss: 0.2428, G loss: 1.5897\n",
      "[964/1762] D loss: 1.4028, G loss: 0.6187\n",
      "[1044/1762] D loss: 1.3881, G loss: 0.7188\n",
      "[1124/1762] D loss: 1.3888, G loss: 0.6520\n",
      "[1204/1762] D loss: 1.3904, G loss: 0.6295\n",
      "[1284/1762] D loss: 0.2578, G loss: 1.8178\n",
      "[1364/1762] D loss: 1.3867, G loss: 0.6757\n",
      "[1444/1762] D loss: 1.4249, G loss: 0.9028\n",
      "[1524/1762] D loss: 1.3900, G loss: 0.6695\n",
      "[1604/1762] D loss: 1.3909, G loss: 0.7514\n",
      "[1684/1762] D loss: 0.1780, G loss: 1.9054\n",
      "[1762/1762] D loss: 1.0745, G loss: 0.9154\n",
      "train error: \n",
      " D loss: 1.537903, G loss: 0.443461, D accuracy: 50.3%, cell accuracy: 99.9%, board accuracy: 93.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.523720, G loss: 0.461551, D accuracy: 50.7%, cell accuracy: 99.9%, board accuracy: 91.4% \n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3095, G loss: 1.4660\n",
      "[84/1762] D loss: 1.3878, G loss: 0.6948\n",
      "[164/1762] D loss: 0.2432, G loss: 1.5931\n",
      "[244/1762] D loss: 1.3901, G loss: 0.6283\n",
      "[324/1762] D loss: 1.3889, G loss: 0.6722\n",
      "[404/1762] D loss: 1.3874, G loss: 0.6834\n",
      "[484/1762] D loss: 0.2856, G loss: 1.4416\n",
      "[564/1762] D loss: 1.3876, G loss: 0.7126\n",
      "[644/1762] D loss: 1.3868, G loss: 0.6895\n",
      "[724/1762] D loss: 1.3929, G loss: 0.7193\n",
      "[804/1762] D loss: 1.3884, G loss: 0.6488\n",
      "[884/1762] D loss: 1.3921, G loss: 0.7393\n",
      "[964/1762] D loss: 1.3866, G loss: 0.6840\n",
      "[1044/1762] D loss: 1.3884, G loss: 0.7099\n",
      "[1124/1762] D loss: 0.1686, G loss: 2.1975\n",
      "[1204/1762] D loss: 1.3867, G loss: 0.6930\n",
      "[1284/1762] D loss: 1.3901, G loss: 0.7459\n",
      "[1364/1762] D loss: 1.3912, G loss: 0.7344\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.6885\n",
      "[1524/1762] D loss: 1.3947, G loss: 0.6310\n",
      "[1604/1762] D loss: 1.3884, G loss: 0.6643\n",
      "[1684/1762] D loss: 1.3866, G loss: 0.7156\n",
      "[1762/1762] D loss: 1.3879, G loss: 0.6812\n",
      "train error: \n",
      " D loss: 1.431042, G loss: 0.781763, D accuracy: 50.8%, cell accuracy: 99.9%, board accuracy: 93.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.402064, G loss: 0.822378, D accuracy: 51.1%, cell accuracy: 99.9%, board accuracy: 91.8% \n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3874, G loss: 0.7222\n",
      "[84/1762] D loss: 1.3890, G loss: 0.6650\n",
      "[164/1762] D loss: 0.7858, G loss: 1.7560\n",
      "[244/1762] D loss: 0.9278, G loss: 1.7652\n",
      "[324/1762] D loss: 1.3869, G loss: 0.7191\n",
      "[404/1762] D loss: 1.3895, G loss: 0.6427\n",
      "[484/1762] D loss: 1.3872, G loss: 0.7134\n",
      "[564/1762] D loss: 0.4118, G loss: 1.2521\n",
      "[644/1762] D loss: 0.2377, G loss: 2.8405\n",
      "[724/1762] D loss: 1.3945, G loss: 0.6124\n",
      "[804/1762] D loss: 1.3954, G loss: 0.6376\n",
      "[884/1762] D loss: 1.4293, G loss: 0.5868\n",
      "[964/1762] D loss: 1.4004, G loss: 0.6476\n",
      "[1044/1762] D loss: 1.4178, G loss: 0.8564\n",
      "[1124/1762] D loss: 1.4010, G loss: 0.5892\n",
      "[1204/1762] D loss: 1.3888, G loss: 0.7416\n",
      "[1284/1762] D loss: 1.3895, G loss: 0.6454\n",
      "[1364/1762] D loss: 1.3914, G loss: 0.7385\n",
      "[1444/1762] D loss: 1.3891, G loss: 0.6747\n",
      "[1524/1762] D loss: 1.3932, G loss: 0.7399\n",
      "[1604/1762] D loss: 1.1666, G loss: 0.9563\n",
      "[1684/1762] D loss: 1.4245, G loss: 0.8256\n",
      "[1762/1762] D loss: 1.3962, G loss: 0.6047\n",
      "train error: \n",
      " D loss: 1.812196, G loss: 0.923376, D accuracy: 51.2%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.797363, G loss: 0.947951, D accuracy: 51.5%, cell accuracy: 99.9%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3928, G loss: 0.5855\n",
      "[84/1762] D loss: 1.4493, G loss: 0.8980\n",
      "[164/1762] D loss: 1.3952, G loss: 0.6086\n",
      "[244/1762] D loss: 1.3888, G loss: 0.6679\n",
      "[324/1762] D loss: 1.3925, G loss: 0.7264\n",
      "[404/1762] D loss: 1.3923, G loss: 0.7559\n",
      "[484/1762] D loss: 1.1303, G loss: 0.9897\n",
      "[564/1762] D loss: 1.3896, G loss: 0.7341\n",
      "[644/1762] D loss: 1.3948, G loss: 0.7728\n",
      "[724/1762] D loss: 1.3902, G loss: 0.6420\n",
      "[804/1762] D loss: 0.4004, G loss: 1.1681\n",
      "[884/1762] D loss: 0.1923, G loss: 1.7653\n",
      "[964/1762] D loss: 1.7125, G loss: 1.1814\n",
      "[1044/1762] D loss: 1.7829, G loss: 1.4032\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6763\n",
      "[1204/1762] D loss: 1.3951, G loss: 0.6141\n",
      "[1284/1762] D loss: 1.3881, G loss: 0.7284\n",
      "[1364/1762] D loss: 1.3933, G loss: 0.6159\n",
      "[1444/1762] D loss: 0.6154, G loss: 1.9839\n",
      "[1524/1762] D loss: 0.1645, G loss: 1.8908\n",
      "[1604/1762] D loss: 1.3892, G loss: 0.7194\n",
      "[1684/1762] D loss: 1.3937, G loss: 0.7299\n",
      "[1762/1762] D loss: 1.3869, G loss: 0.6690\n",
      "train error: \n",
      " D loss: 1.468086, G loss: 0.919183, D accuracy: 49.9%, cell accuracy: 99.9%, board accuracy: 93.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.475747, G loss: 0.921583, D accuracy: 49.7%, cell accuracy: 99.9%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3971, G loss: 0.7569\n",
      "[84/1762] D loss: 1.4033, G loss: 0.5949\n",
      "[164/1762] D loss: 1.3892, G loss: 0.6661\n",
      "[244/1762] D loss: 1.4063, G loss: 0.8533\n",
      "[324/1762] D loss: 1.3865, G loss: 0.6969\n",
      "[404/1762] D loss: 1.3981, G loss: 0.6085\n",
      "[484/1762] D loss: 1.3898, G loss: 0.7274\n",
      "[564/1762] D loss: 1.3929, G loss: 0.7498\n",
      "[644/1762] D loss: 0.2305, G loss: 1.6972\n",
      "[724/1762] D loss: 1.3911, G loss: 0.6296\n",
      "[804/1762] D loss: 0.9549, G loss: 1.3638\n",
      "[884/1762] D loss: 1.3926, G loss: 0.6229\n",
      "[964/1762] D loss: 1.3921, G loss: 0.7225\n",
      "[1044/1762] D loss: 1.3868, G loss: 0.6903\n",
      "[1124/1762] D loss: 0.3678, G loss: 1.2749\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6794\n",
      "[1284/1762] D loss: 0.2031, G loss: 1.7173\n",
      "[1364/1762] D loss: 1.3887, G loss: 0.7251\n",
      "[1444/1762] D loss: 1.3943, G loss: 0.6369\n",
      "[1524/1762] D loss: 1.3892, G loss: 0.7191\n",
      "[1604/1762] D loss: 1.3873, G loss: 0.7149\n",
      "[1684/1762] D loss: 0.1978, G loss: 1.7625\n",
      "[1762/1762] D loss: 1.3910, G loss: 0.6286\n",
      "train error: \n",
      " D loss: 1.443922, G loss: 0.728200, D accuracy: 49.8%, cell accuracy: 99.9%, board accuracy: 93.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.446762, G loss: 0.733934, D accuracy: 49.8%, cell accuracy: 99.9%, board accuracy: 91.1% \n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1376, G loss: 2.0549\n",
      "[84/1762] D loss: 1.3871, G loss: 0.7204\n",
      "[164/1762] D loss: 1.3910, G loss: 0.7117\n",
      "[244/1762] D loss: 1.4021, G loss: 0.5922\n",
      "[324/1762] D loss: 1.3917, G loss: 0.7264\n",
      "[404/1762] D loss: 1.4054, G loss: 0.8095\n",
      "[484/1762] D loss: 1.3889, G loss: 0.7407\n",
      "[564/1762] D loss: 0.0973, G loss: 2.4502\n",
      "[644/1762] D loss: 1.3886, G loss: 0.6668\n",
      "[724/1762] D loss: 1.3875, G loss: 0.6812\n",
      "[804/1762] D loss: 1.3866, G loss: 0.6756\n",
      "[884/1762] D loss: 1.3900, G loss: 0.7157\n",
      "[964/1762] D loss: 1.3928, G loss: 0.7603\n",
      "[1044/1762] D loss: 1.3873, G loss: 0.7192\n",
      "[1124/1762] D loss: 1.3883, G loss: 0.7338\n",
      "[1204/1762] D loss: 1.3869, G loss: 0.7134\n",
      "[1284/1762] D loss: 1.3999, G loss: 0.7871\n",
      "[1364/1762] D loss: 0.8829, G loss: 2.1315\n",
      "[1444/1762] D loss: 1.3903, G loss: 0.6462\n",
      "[1524/1762] D loss: 0.2913, G loss: 1.5101\n",
      "[1604/1762] D loss: 1.3903, G loss: 0.6497\n",
      "[1684/1762] D loss: 1.3991, G loss: 0.8209\n",
      "[1762/1762] D loss: 1.4045, G loss: 0.8289\n",
      "train error: \n",
      " D loss: 1.469887, G loss: 0.891641, D accuracy: 49.9%, cell accuracy: 99.9%, board accuracy: 93.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.477371, G loss: 0.868998, D accuracy: 49.9%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3889, G loss: 0.7289\n",
      "[84/1762] D loss: 1.3950, G loss: 0.7346\n",
      "[164/1762] D loss: 1.3894, G loss: 0.6356\n",
      "[244/1762] D loss: 1.3867, G loss: 0.7177\n",
      "[324/1762] D loss: 1.3882, G loss: 0.6622\n",
      "[404/1762] D loss: 1.4024, G loss: 0.5801\n",
      "[484/1762] D loss: 1.4064, G loss: 0.5750\n",
      "[564/1762] D loss: 1.3870, G loss: 0.6857\n",
      "[644/1762] D loss: 1.3864, G loss: 0.7110\n",
      "[724/1762] D loss: 1.3890, G loss: 0.6915\n",
      "[804/1762] D loss: 1.3979, G loss: 0.6031\n",
      "[884/1762] D loss: 1.3872, G loss: 0.7202\n",
      "[964/1762] D loss: 1.3891, G loss: 0.7291\n",
      "[1044/1762] D loss: 0.9591, G loss: 2.9435\n",
      "[1124/1762] D loss: 1.3872, G loss: 0.6854\n",
      "[1204/1762] D loss: 0.2862, G loss: 1.4276\n",
      "[1284/1762] D loss: 1.6109, G loss: 1.5397\n",
      "[1364/1762] D loss: 1.3878, G loss: 0.6664\n",
      "[1444/1762] D loss: 1.3867, G loss: 0.6888\n",
      "[1524/1762] D loss: 1.3904, G loss: 0.6288\n",
      "[1604/1762] D loss: 1.3895, G loss: 0.7620\n",
      "[1684/1762] D loss: 0.3321, G loss: 1.3736\n",
      "[1762/1762] D loss: 1.4113, G loss: 0.5539\n",
      "train error: \n",
      " D loss: 1.397973, G loss: 0.644948, D accuracy: 49.4%, cell accuracy: 99.9%, board accuracy: 93.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.400145, G loss: 0.639076, D accuracy: 49.2%, cell accuracy: 99.9%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1832, G loss: 0.8418\n",
      "[84/1762] D loss: 0.3776, G loss: 1.2593\n",
      "[164/1762] D loss: 1.3892, G loss: 0.6500\n",
      "[244/1762] D loss: 0.2890, G loss: 1.9491\n",
      "[324/1762] D loss: 1.3881, G loss: 0.6647\n",
      "[404/1762] D loss: 0.2795, G loss: 1.5135\n",
      "[484/1762] D loss: 0.2627, G loss: 1.6362\n",
      "[564/1762] D loss: 1.3977, G loss: 0.7401\n",
      "[644/1762] D loss: 1.3866, G loss: 0.6977\n",
      "[724/1762] D loss: 0.3455, G loss: 1.2906\n",
      "[804/1762] D loss: 1.3948, G loss: 0.7733\n",
      "[884/1762] D loss: 0.2659, G loss: 1.5363\n",
      "[964/1762] D loss: 1.3879, G loss: 0.7109\n",
      "[1044/1762] D loss: 1.3922, G loss: 0.7756\n",
      "[1124/1762] D loss: 1.3892, G loss: 0.6425\n",
      "[1204/1762] D loss: 1.4214, G loss: 0.7428\n",
      "[1284/1762] D loss: 1.3875, G loss: 0.7151\n",
      "[1364/1762] D loss: 0.3039, G loss: 1.4270\n",
      "[1444/1762] D loss: 1.3880, G loss: 0.6797\n",
      "[1524/1762] D loss: 1.3871, G loss: 0.6721\n",
      "[1604/1762] D loss: 0.1681, G loss: 1.9410\n",
      "[1684/1762] D loss: 1.3681, G loss: 0.8597\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6805\n",
      "train error: \n",
      " D loss: 1.458410, G loss: 0.878349, D accuracy: 49.9%, cell accuracy: 99.9%, board accuracy: 93.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.484307, G loss: 0.862672, D accuracy: 49.5%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4075, G loss: 0.8148\n",
      "[84/1762] D loss: 1.4460, G loss: 1.3796\n",
      "[164/1762] D loss: 0.2557, G loss: 1.9653\n",
      "[244/1762] D loss: 1.3864, G loss: 0.6934\n",
      "[324/1762] D loss: 0.3632, G loss: 1.3570\n",
      "[404/1762] D loss: 1.1545, G loss: 1.0599\n",
      "[484/1762] D loss: 1.3907, G loss: 0.6360\n",
      "[564/1762] D loss: 1.3866, G loss: 0.7046\n",
      "[644/1762] D loss: 0.3264, G loss: 1.7611\n",
      "[724/1762] D loss: 1.3895, G loss: 0.6348\n",
      "[804/1762] D loss: 1.3927, G loss: 0.7098\n",
      "[884/1762] D loss: 1.3872, G loss: 0.6830\n",
      "[964/1762] D loss: 1.3882, G loss: 0.6596\n",
      "[1044/1762] D loss: 1.5975, G loss: 1.2335\n",
      "[1124/1762] D loss: 1.3886, G loss: 0.7253\n",
      "[1204/1762] D loss: 1.3865, G loss: 0.7091\n",
      "[1284/1762] D loss: 1.2683, G loss: 1.1154\n",
      "[1364/1762] D loss: 1.3938, G loss: 0.7664\n",
      "[1444/1762] D loss: 1.3953, G loss: 0.6106\n",
      "[1524/1762] D loss: 1.4042, G loss: 0.5730\n",
      "[1604/1762] D loss: 1.3889, G loss: 0.6811\n",
      "[1684/1762] D loss: 1.3954, G loss: 0.6096\n",
      "[1762/1762] D loss: 1.3897, G loss: 0.6426\n",
      "train error: \n",
      " D loss: 1.448287, G loss: 0.716604, D accuracy: 47.8%, cell accuracy: 99.9%, board accuracy: 93.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.470005, G loss: 0.685261, D accuracy: 46.6%, cell accuracy: 99.9%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3873, G loss: 0.7109\n",
      "[84/1762] D loss: 1.3882, G loss: 0.7341\n",
      "[164/1762] D loss: 1.3882, G loss: 0.6859\n",
      "[244/1762] D loss: 1.3871, G loss: 0.6963\n",
      "[324/1762] D loss: 1.3869, G loss: 0.6707\n",
      "[404/1762] D loss: 0.3224, G loss: 1.3282\n",
      "[484/1762] D loss: 1.3872, G loss: 0.6709\n",
      "[564/1762] D loss: 1.3878, G loss: 0.7098\n",
      "[644/1762] D loss: 0.3102, G loss: 1.5027\n",
      "[724/1762] D loss: 2.1217, G loss: 1.9161\n",
      "[804/1762] D loss: 1.3866, G loss: 0.6934\n",
      "[884/1762] D loss: 1.4082, G loss: 0.7831\n",
      "[964/1762] D loss: 1.3902, G loss: 0.6402\n",
      "[1044/1762] D loss: 2.2700, G loss: 2.0736\n",
      "[1124/1762] D loss: 1.3874, G loss: 0.6921\n",
      "[1204/1762] D loss: 1.4028, G loss: 0.8154\n",
      "[1284/1762] D loss: 1.3881, G loss: 0.6537\n",
      "[1364/1762] D loss: 1.3876, G loss: 0.6645\n",
      "[1444/1762] D loss: 1.3869, G loss: 0.7179\n",
      "[1524/1762] D loss: 1.7795, G loss: 1.5171\n",
      "[1604/1762] D loss: 0.2242, G loss: 1.6041\n",
      "[1684/1762] D loss: 1.3872, G loss: 0.7103\n",
      "[1762/1762] D loss: 2.3469, G loss: 1.3208\n",
      "train error: \n",
      " D loss: 1.534044, G loss: 1.079508, D accuracy: 50.7%, cell accuracy: 99.9%, board accuracy: 91.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.516864, G loss: 1.067290, D accuracy: 51.1%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3870, G loss: 0.6747\n",
      "[84/1762] D loss: 1.4194, G loss: 1.5203\n",
      "[164/1762] D loss: 1.3864, G loss: 0.7021\n",
      "[244/1762] D loss: 1.5055, G loss: 1.4268\n",
      "[324/1762] D loss: 1.3382, G loss: 0.7605\n",
      "[404/1762] D loss: 1.3990, G loss: 0.5922\n",
      "[484/1762] D loss: 1.3975, G loss: 0.6068\n",
      "[564/1762] D loss: 1.3880, G loss: 0.6712\n",
      "[644/1762] D loss: 1.4069, G loss: 0.5750\n",
      "[724/1762] D loss: 1.3986, G loss: 0.7916\n",
      "[804/1762] D loss: 1.6260, G loss: 1.0898\n",
      "[884/1762] D loss: 0.6008, G loss: 0.9107\n",
      "[964/1762] D loss: 1.3871, G loss: 0.6736\n",
      "[1044/1762] D loss: 1.3870, G loss: 0.7122\n",
      "[1124/1762] D loss: 1.5405, G loss: 1.4484\n",
      "[1204/1762] D loss: 1.4393, G loss: 0.9733\n",
      "[1284/1762] D loss: 0.3396, G loss: 1.7436\n",
      "[1364/1762] D loss: 1.3879, G loss: 0.7134\n",
      "[1444/1762] D loss: 1.3892, G loss: 0.6464\n",
      "[1524/1762] D loss: 1.3885, G loss: 0.6563\n",
      "[1604/1762] D loss: 1.3949, G loss: 0.6098\n",
      "[1684/1762] D loss: 0.4533, G loss: 1.2184\n",
      "[1762/1762] D loss: 1.3879, G loss: 0.7243\n",
      "train error: \n",
      " D loss: 1.491909, G loss: 1.315283, D accuracy: 50.0%, cell accuracy: 99.9%, board accuracy: 93.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.487986, G loss: 1.437711, D accuracy: 50.0%, cell accuracy: 99.9%, board accuracy: 91.8% \n",
      "\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4294, G loss: 0.8846\n",
      "[84/1762] D loss: 1.3872, G loss: 0.6924\n",
      "[164/1762] D loss: 1.3981, G loss: 0.6107\n",
      "[244/1762] D loss: 1.4078, G loss: 0.8140\n",
      "[324/1762] D loss: 1.3888, G loss: 0.6787\n",
      "[404/1762] D loss: 1.4278, G loss: 0.8886\n",
      "[484/1762] D loss: 1.4033, G loss: 0.5827\n",
      "[564/1762] D loss: 1.4176, G loss: 0.8305\n",
      "[644/1762] D loss: 1.3970, G loss: 0.8065\n",
      "[724/1762] D loss: 1.3912, G loss: 0.6042\n",
      "[804/1762] D loss: 1.3885, G loss: 0.6562\n",
      "[884/1762] D loss: 1.3899, G loss: 0.6394\n",
      "[964/1762] D loss: 1.3932, G loss: 0.7560\n",
      "[1044/1762] D loss: 1.3879, G loss: 0.6529\n",
      "[1124/1762] D loss: 1.3879, G loss: 0.7304\n",
      "[1204/1762] D loss: 1.8772, G loss: 1.5238\n",
      "[1284/1762] D loss: 1.3961, G loss: 0.7788\n",
      "[1364/1762] D loss: 0.2635, G loss: 1.5009\n",
      "[1444/1762] D loss: 1.3868, G loss: 0.7074\n",
      "[1524/1762] D loss: 1.3896, G loss: 0.7488\n",
      "[1604/1762] D loss: 1.3883, G loss: 0.6506\n",
      "[1684/1762] D loss: 1.3875, G loss: 0.6864\n",
      "[1762/1762] D loss: 1.3950, G loss: 0.7675\n",
      "train error: \n",
      " D loss: 1.408564, G loss: 0.702327, D accuracy: 51.2%, cell accuracy: 99.9%, board accuracy: 94.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.412028, G loss: 0.700883, D accuracy: 51.7%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2336, G loss: 1.8926\n",
      "[84/1762] D loss: 1.4122, G loss: 0.5790\n",
      "[164/1762] D loss: 1.3864, G loss: 0.6972\n",
      "[244/1762] D loss: 1.3894, G loss: 0.7388\n",
      "[324/1762] D loss: 1.3903, G loss: 0.6296\n",
      "[404/1762] D loss: 1.3895, G loss: 0.7392\n",
      "[484/1762] D loss: 1.3883, G loss: 0.7074\n",
      "[564/1762] D loss: 1.3873, G loss: 0.6877\n",
      "[644/1762] D loss: 1.3873, G loss: 0.7160\n",
      "[724/1762] D loss: 0.1155, G loss: 2.3488\n",
      "[804/1762] D loss: 0.1838, G loss: 1.7902\n",
      "[884/1762] D loss: 1.7989, G loss: 1.5112\n",
      "[964/1762] D loss: 1.3869, G loss: 0.7124\n",
      "[1044/1762] D loss: 1.3877, G loss: 0.6752\n",
      "[1124/1762] D loss: 1.3882, G loss: 0.6494\n",
      "[1204/1762] D loss: 1.3918, G loss: 0.6401\n",
      "[1284/1762] D loss: 0.1592, G loss: 1.9448\n",
      "[1364/1762] D loss: 1.3865, G loss: 0.7086\n",
      "[1444/1762] D loss: 1.3880, G loss: 0.7223\n",
      "[1524/1762] D loss: 1.3927, G loss: 0.6354\n",
      "[1604/1762] D loss: 1.3914, G loss: 0.7618\n",
      "[1684/1762] D loss: 0.2563, G loss: 1.5430\n",
      "[1762/1762] D loss: 1.3900, G loss: 0.7111\n",
      "train error: \n",
      " D loss: 1.467445, G loss: 1.005459, D accuracy: 48.9%, cell accuracy: 99.9%, board accuracy: 93.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.463188, G loss: 1.086504, D accuracy: 48.8%, cell accuracy: 99.9%, board accuracy: 91.8% \n",
      "\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1821, G loss: 1.8453\n",
      "[84/1762] D loss: 1.1551, G loss: 1.4911\n",
      "[164/1762] D loss: 1.3946, G loss: 0.5995\n",
      "[244/1762] D loss: 1.3661, G loss: 0.7122\n",
      "[324/1762] D loss: 1.3835, G loss: 0.7638\n",
      "[404/1762] D loss: 1.3863, G loss: 0.6903\n",
      "[484/1762] D loss: 0.3343, G loss: 1.1651\n",
      "[564/1762] D loss: 1.4180, G loss: 0.8959\n",
      "[644/1762] D loss: 1.3864, G loss: 0.6883\n",
      "[724/1762] D loss: 1.3898, G loss: 0.6419\n",
      "[804/1762] D loss: 0.2299, G loss: 1.8738\n",
      "[884/1762] D loss: 1.3870, G loss: 0.7091\n",
      "[964/1762] D loss: 1.3896, G loss: 0.7557\n",
      "[1044/1762] D loss: 2.0500, G loss: 2.2468\n",
      "[1124/1762] D loss: 1.4375, G loss: 0.9172\n",
      "[1204/1762] D loss: 0.3418, G loss: 2.1407\n",
      "[1284/1762] D loss: 1.4013, G loss: 0.6730\n",
      "[1364/1762] D loss: 1.3925, G loss: 0.7685\n",
      "[1444/1762] D loss: 0.1373, G loss: 2.9891\n",
      "[1524/1762] D loss: 1.3267, G loss: 0.9984\n",
      "[1604/1762] D loss: 1.3879, G loss: 0.6648\n",
      "[1684/1762] D loss: 1.3880, G loss: 0.7164\n",
      "[1762/1762] D loss: 1.3871, G loss: 0.6721\n",
      "train error: \n",
      " D loss: 1.415400, G loss: 0.969229, D accuracy: 52.0%, cell accuracy: 99.9%, board accuracy: 93.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.417295, G loss: 0.955150, D accuracy: 52.5%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3885, G loss: 0.6502\n",
      "[84/1762] D loss: 0.9197, G loss: 1.6397\n",
      "[164/1762] D loss: 1.3872, G loss: 0.6710\n",
      "[244/1762] D loss: 1.3900, G loss: 0.7388\n",
      "[324/1762] D loss: 1.8912, G loss: 1.6559\n",
      "[404/1762] D loss: 0.1915, G loss: 1.8027\n",
      "[484/1762] D loss: 1.3938, G loss: 0.7775\n",
      "[564/1762] D loss: 1.3878, G loss: 0.6711\n",
      "[644/1762] D loss: 0.2097, G loss: 1.6912\n",
      "[724/1762] D loss: 1.3869, G loss: 0.7033\n",
      "[804/1762] D loss: 1.4179, G loss: 0.8380\n",
      "[884/1762] D loss: 0.2348, G loss: 1.5891\n",
      "[964/1762] D loss: 1.3868, G loss: 0.6749\n",
      "[1044/1762] D loss: 1.9311, G loss: 1.7063\n",
      "[1124/1762] D loss: 1.3867, G loss: 0.7089\n",
      "[1204/1762] D loss: 1.3876, G loss: 0.6801\n",
      "[1284/1762] D loss: 1.3876, G loss: 0.6448\n",
      "[1364/1762] D loss: 1.8685, G loss: 1.5931\n",
      "[1444/1762] D loss: 1.3885, G loss: 0.6567\n",
      "[1524/1762] D loss: 1.3866, G loss: 0.6807\n",
      "[1604/1762] D loss: 1.3868, G loss: 0.6921\n",
      "[1684/1762] D loss: 1.3557, G loss: 0.6945\n",
      "[1762/1762] D loss: 1.3998, G loss: 0.5844\n",
      "train error: \n",
      " D loss: 1.952031, G loss: 0.825746, D accuracy: 49.3%, cell accuracy: 99.9%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.917609, G loss: 0.816839, D accuracy: 49.9%, cell accuracy: 99.9%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2801, G loss: 1.4030\n",
      "[84/1762] D loss: 1.3915, G loss: 0.6317\n",
      "[164/1762] D loss: 0.2567, G loss: 1.5221\n",
      "[244/1762] D loss: 1.3483, G loss: 0.6630\n",
      "[324/1762] D loss: 0.2123, G loss: 1.8759\n",
      "[404/1762] D loss: 0.2094, G loss: 1.6927\n",
      "[484/1762] D loss: 1.1977, G loss: 0.9377\n",
      "[564/1762] D loss: 1.3926, G loss: 0.6389\n",
      "[644/1762] D loss: 0.2556, G loss: 1.5715\n",
      "[724/1762] D loss: 1.4014, G loss: 0.7672\n",
      "[804/1762] D loss: 0.3244, G loss: 1.4986\n",
      "[884/1762] D loss: 1.4122, G loss: 0.8357\n",
      "[964/1762] D loss: 1.3926, G loss: 0.6219\n",
      "[1044/1762] D loss: 0.1283, G loss: 2.7762\n",
      "[1124/1762] D loss: 1.1796, G loss: 2.3380\n",
      "[1204/1762] D loss: 1.3887, G loss: 0.6556\n",
      "[1284/1762] D loss: 0.2644, G loss: 1.4893\n",
      "[1364/1762] D loss: 1.3865, G loss: 0.6981\n",
      "[1444/1762] D loss: 0.1985, G loss: 1.7411\n",
      "[1524/1762] D loss: 1.3892, G loss: 0.6373\n",
      "[1604/1762] D loss: 1.3880, G loss: 0.7206\n",
      "[1684/1762] D loss: 1.3861, G loss: 0.6932\n",
      "[1762/1762] D loss: 1.3959, G loss: 0.7871\n",
      "train error: \n",
      " D loss: 1.442460, G loss: 0.903442, D accuracy: 51.0%, cell accuracy: 99.9%, board accuracy: 93.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.404132, G loss: 0.946186, D accuracy: 51.7%, cell accuracy: 99.9%, board accuracy: 91.1% \n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3876, G loss: 0.7275\n",
      "[84/1762] D loss: 1.3860, G loss: 0.6962\n",
      "[164/1762] D loss: 0.1377, G loss: 2.0983\n",
      "[244/1762] D loss: 0.1997, G loss: 1.7515\n",
      "[324/1762] D loss: 0.2680, G loss: 1.7947\n",
      "[404/1762] D loss: 0.1275, G loss: 2.5292\n",
      "[484/1762] D loss: 1.3881, G loss: 0.6555\n",
      "[564/1762] D loss: 1.3887, G loss: 0.6921\n",
      "[644/1762] D loss: 1.3867, G loss: 0.7139\n",
      "[724/1762] D loss: 1.3882, G loss: 0.6712\n",
      "[804/1762] D loss: 1.3863, G loss: 0.6858\n",
      "[884/1762] D loss: 2.2485, G loss: 2.0362\n",
      "[964/1762] D loss: 1.3866, G loss: 0.6838\n",
      "[1044/1762] D loss: 2.3207, G loss: 1.9824\n",
      "[1124/1762] D loss: 1.3835, G loss: 0.7182\n",
      "[1204/1762] D loss: 1.3859, G loss: 0.7049\n",
      "[1284/1762] D loss: 1.3889, G loss: 0.7403\n",
      "[1364/1762] D loss: 1.3882, G loss: 0.6830\n",
      "[1444/1762] D loss: 2.1098, G loss: 1.8981\n",
      "[1524/1762] D loss: 0.1136, G loss: 2.5242\n",
      "[1604/1762] D loss: 1.3859, G loss: 0.6874\n",
      "[1684/1762] D loss: 1.3884, G loss: 0.7429\n",
      "[1762/1762] D loss: 1.3866, G loss: 0.6755\n",
      "train error: \n",
      " D loss: 1.424369, G loss: 0.751115, D accuracy: 51.7%, cell accuracy: 99.9%, board accuracy: 92.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.409521, G loss: 0.769503, D accuracy: 51.9%, cell accuracy: 99.9%, board accuracy: 91.4% \n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.9328, G loss: 1.6971\n",
      "[84/1762] D loss: 1.3871, G loss: 0.7233\n",
      "[164/1762] D loss: 1.3888, G loss: 0.6618\n",
      "[244/1762] D loss: 1.3869, G loss: 0.7329\n",
      "[324/1762] D loss: 0.1526, G loss: 1.9841\n",
      "[404/1762] D loss: 1.3865, G loss: 0.6967\n",
      "[484/1762] D loss: 0.1451, G loss: 2.0575\n",
      "[564/1762] D loss: 1.3889, G loss: 0.6415\n",
      "[644/1762] D loss: 1.3894, G loss: 0.7439\n",
      "[724/1762] D loss: 1.3869, G loss: 0.6688\n",
      "[804/1762] D loss: 1.3874, G loss: 0.7221\n",
      "[884/1762] D loss: 1.3872, G loss: 0.6645\n",
      "[964/1762] D loss: 1.3870, G loss: 0.6992\n",
      "[1044/1762] D loss: 1.3885, G loss: 0.7321\n",
      "[1124/1762] D loss: 1.3930, G loss: 0.6181\n",
      "[1204/1762] D loss: 1.3883, G loss: 0.7382\n",
      "[1284/1762] D loss: 1.3865, G loss: 0.6790\n",
      "[1364/1762] D loss: 1.3877, G loss: 0.6583\n",
      "[1444/1762] D loss: 1.3872, G loss: 0.7067\n",
      "[1524/1762] D loss: 1.3890, G loss: 0.7365\n",
      "[1604/1762] D loss: 1.3882, G loss: 0.6490\n",
      "[1684/1762] D loss: 1.3892, G loss: 0.6541\n",
      "[1762/1762] D loss: 1.3879, G loss: 0.7286\n",
      "train error: \n",
      " D loss: 1.405005, G loss: 0.878328, D accuracy: 51.3%, cell accuracy: 99.9%, board accuracy: 93.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.393988, G loss: 0.923729, D accuracy: 52.0%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2243, G loss: 1.0704\n",
      "[84/1762] D loss: 1.3881, G loss: 0.6635\n",
      "[164/1762] D loss: 1.3975, G loss: 0.7737\n",
      "[244/1762] D loss: 1.3902, G loss: 0.6297\n",
      "[324/1762] D loss: 1.3889, G loss: 0.6584\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6827\n",
      "[484/1762] D loss: 1.3872, G loss: 0.6994\n",
      "[564/1762] D loss: 1.3890, G loss: 0.7331\n",
      "[644/1762] D loss: 0.3169, G loss: 1.4734\n",
      "[724/1762] D loss: 1.3871, G loss: 0.6913\n",
      "[804/1762] D loss: 1.3948, G loss: 0.7817\n",
      "[884/1762] D loss: 1.4138, G loss: 0.6100\n",
      "[964/1762] D loss: 1.3895, G loss: 0.7365\n",
      "[1044/1762] D loss: 1.3876, G loss: 0.6938\n",
      "[1124/1762] D loss: 1.4459, G loss: 0.9529\n",
      "[1204/1762] D loss: 0.7206, G loss: 2.2273\n",
      "[1284/1762] D loss: 1.8228, G loss: 1.5492\n",
      "[1364/1762] D loss: 1.4070, G loss: 0.8613\n",
      "[1444/1762] D loss: 1.3907, G loss: 0.6412\n",
      "[1524/1762] D loss: 1.3838, G loss: 0.7378\n",
      "[1604/1762] D loss: 1.3882, G loss: 0.6684\n",
      "[1684/1762] D loss: 1.3930, G loss: 0.6123\n",
      "[1762/1762] D loss: 1.3868, G loss: 0.7142\n",
      "train error: \n",
      " D loss: 1.613817, G loss: 2.210457, D accuracy: 50.9%, cell accuracy: 99.7%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.560274, G loss: 2.591029, D accuracy: 51.0%, cell accuracy: 99.6%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3877, G loss: 0.7278\n",
      "[84/1762] D loss: 0.2384, G loss: 1.5876\n",
      "[164/1762] D loss: 1.3867, G loss: 0.6766\n",
      "[244/1762] D loss: 1.3931, G loss: 0.6251\n",
      "[324/1762] D loss: 1.3867, G loss: 0.7122\n",
      "[404/1762] D loss: 1.3908, G loss: 0.7029\n",
      "[484/1762] D loss: 1.3921, G loss: 0.6088\n",
      "[564/1762] D loss: 1.3883, G loss: 0.6661\n",
      "[644/1762] D loss: 1.3869, G loss: 0.6928\n",
      "[724/1762] D loss: 1.3887, G loss: 0.7323\n",
      "[804/1762] D loss: 1.3884, G loss: 0.7384\n",
      "[884/1762] D loss: 0.2404, G loss: 1.5532\n",
      "[964/1762] D loss: 1.3884, G loss: 0.7317\n",
      "[1044/1762] D loss: 0.1701, G loss: 2.8234\n",
      "[1124/1762] D loss: 1.3871, G loss: 0.7388\n",
      "[1204/1762] D loss: 0.1949, G loss: 3.1634\n",
      "[1284/1762] D loss: 1.3936, G loss: 0.7790\n",
      "[1364/1762] D loss: 1.3927, G loss: 0.7067\n",
      "[1444/1762] D loss: 0.3504, G loss: 1.3122\n",
      "[1524/1762] D loss: 1.4096, G loss: 0.8288\n",
      "[1604/1762] D loss: 1.3869, G loss: 0.7052\n",
      "[1684/1762] D loss: 1.3871, G loss: 0.7132\n",
      "[1762/1762] D loss: 1.3873, G loss: 0.7253\n",
      "train error: \n",
      " D loss: 1.714657, G loss: 1.003244, D accuracy: 50.7%, cell accuracy: 99.9%, board accuracy: 93.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.692070, G loss: 1.089325, D accuracy: 50.9%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1860, G loss: 2.0623\n",
      "[84/1762] D loss: 1.3869, G loss: 0.7044\n",
      "[164/1762] D loss: 0.3146, G loss: 1.3272\n",
      "[244/1762] D loss: 0.3770, G loss: 1.2698\n",
      "[324/1762] D loss: 1.4380, G loss: 0.8892\n",
      "[404/1762] D loss: 1.3871, G loss: 0.6817\n",
      "[484/1762] D loss: 1.3875, G loss: 0.6669\n",
      "[564/1762] D loss: 0.1440, G loss: 2.0454\n",
      "[644/1762] D loss: 1.3915, G loss: 0.6308\n",
      "[724/1762] D loss: 1.4302, G loss: 0.5769\n",
      "[804/1762] D loss: 0.1609, G loss: 1.9240\n",
      "[884/1762] D loss: 0.2016, G loss: 1.7054\n",
      "[964/1762] D loss: 1.3876, G loss: 0.7262\n",
      "[1044/1762] D loss: 0.1360, G loss: 2.1129\n",
      "[1124/1762] D loss: 1.3878, G loss: 0.6634\n",
      "[1204/1762] D loss: 1.3888, G loss: 0.7407\n",
      "[1284/1762] D loss: 0.1359, G loss: 2.1079\n",
      "[1364/1762] D loss: 1.3882, G loss: 0.7152\n",
      "[1444/1762] D loss: 0.0477, G loss: 3.1464\n",
      "[1524/1762] D loss: 1.3914, G loss: 0.7539\n",
      "[1604/1762] D loss: 1.3881, G loss: 0.6556\n",
      "[1684/1762] D loss: 1.3865, G loss: 0.7233\n",
      "[1762/1762] D loss: 1.3869, G loss: 0.7153\n",
      "train error: \n",
      " D loss: 2.499787, G loss: 1.005280, D accuracy: 50.0%, cell accuracy: 99.9%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 2.552192, G loss: 1.075250, D accuracy: 50.0%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3872, G loss: 0.6808\n",
      "[84/1762] D loss: 1.3877, G loss: 0.6602\n",
      "[164/1762] D loss: 1.4171, G loss: 0.8236\n",
      "[244/1762] D loss: 0.5532, G loss: 2.2585\n",
      "[324/1762] D loss: 1.3899, G loss: 0.7432\n",
      "[404/1762] D loss: 1.4244, G loss: 0.8775\n",
      "[484/1762] D loss: 1.3858, G loss: 0.7070\n",
      "[564/1762] D loss: 1.3945, G loss: 0.7619\n",
      "[644/1762] D loss: 1.4726, G loss: 0.9664\n",
      "[724/1762] D loss: 1.3950, G loss: 0.6286\n",
      "[804/1762] D loss: 0.2856, G loss: 2.1606\n",
      "[884/1762] D loss: 1.4208, G loss: 0.8555\n",
      "[964/1762] D loss: 0.2590, G loss: 1.6198\n",
      "[1044/1762] D loss: 0.2271, G loss: 1.6094\n",
      "[1124/1762] D loss: 0.1703, G loss: 1.9119\n",
      "[1204/1762] D loss: 1.3843, G loss: 0.6733\n",
      "[1284/1762] D loss: 0.1579, G loss: 3.0897\n",
      "[1364/1762] D loss: 1.3699, G loss: 0.8527\n",
      "[1444/1762] D loss: 1.3925, G loss: 0.7054\n",
      "[1524/1762] D loss: 1.3869, G loss: 0.6812\n",
      "[1604/1762] D loss: 1.3883, G loss: 0.6615\n",
      "[1684/1762] D loss: 1.3876, G loss: 0.7104\n",
      "[1762/1762] D loss: 1.3907, G loss: 0.6368\n",
      "train error: \n",
      " D loss: 1.865947, G loss: 0.894751, D accuracy: 49.9%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.878983, G loss: 0.960136, D accuracy: 49.8%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.9763, G loss: 2.0206\n",
      "[84/1762] D loss: 1.3873, G loss: 0.7066\n",
      "[164/1762] D loss: 1.3966, G loss: 0.7590\n",
      "[244/1762] D loss: 1.4399, G loss: 0.8524\n",
      "[324/1762] D loss: 1.3977, G loss: 0.5943\n",
      "[404/1762] D loss: 0.0700, G loss: 2.7703\n",
      "[484/1762] D loss: 1.1053, G loss: 1.0012\n",
      "[564/1762] D loss: 1.3977, G loss: 0.6009\n",
      "[644/1762] D loss: 1.3877, G loss: 0.7295\n",
      "[724/1762] D loss: 1.3866, G loss: 0.6838\n",
      "[804/1762] D loss: 0.1298, G loss: 2.2029\n",
      "[884/1762] D loss: 1.3869, G loss: 0.7145\n",
      "[964/1762] D loss: 1.3903, G loss: 0.6392\n",
      "[1044/1762] D loss: 1.3866, G loss: 0.6924\n",
      "[1124/1762] D loss: 2.6613, G loss: 2.7432\n",
      "[1204/1762] D loss: 0.0969, G loss: 2.7475\n",
      "[1284/1762] D loss: 2.7943, G loss: 2.8962\n",
      "[1364/1762] D loss: 1.3992, G loss: 0.7811\n",
      "[1444/1762] D loss: 1.3893, G loss: 0.7539\n",
      "[1524/1762] D loss: 1.3922, G loss: 0.7528\n",
      "[1604/1762] D loss: 1.3865, G loss: 0.6870\n",
      "[1684/1762] D loss: 1.3870, G loss: 0.6974\n",
      "[1762/1762] D loss: 1.4290, G loss: 0.8449\n",
      "train error: \n",
      " D loss: 2.415233, G loss: 1.641023, D accuracy: 50.0%, cell accuracy: 99.9%, board accuracy: 93.7% \n",
      "\n",
      "test error: \n",
      " D loss: 2.522376, G loss: 1.689044, D accuracy: 50.0%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4257, G loss: 0.8233\n",
      "[84/1762] D loss: 1.3993, G loss: 0.5914\n",
      "[164/1762] D loss: 0.7815, G loss: 0.8812\n",
      "[244/1762] D loss: 1.3932, G loss: 0.7914\n",
      "[324/1762] D loss: 1.3924, G loss: 0.7609\n",
      "[404/1762] D loss: 1.3883, G loss: 0.7177\n",
      "[484/1762] D loss: 2.9817, G loss: 1.3536\n",
      "[564/1762] D loss: 1.3986, G loss: 0.6001\n",
      "[644/1762] D loss: 1.3839, G loss: 0.7256\n",
      "[724/1762] D loss: 0.5541, G loss: 0.8661\n",
      "[804/1762] D loss: 1.3907, G loss: 0.7586\n",
      "[884/1762] D loss: 1.3872, G loss: 0.7183\n",
      "[964/1762] D loss: 1.3877, G loss: 0.7104\n",
      "[1044/1762] D loss: 1.3879, G loss: 0.7341\n",
      "[1124/1762] D loss: 1.3884, G loss: 0.7247\n",
      "[1204/1762] D loss: 1.3880, G loss: 0.7281\n",
      "[1284/1762] D loss: 1.3920, G loss: 0.6183\n",
      "[1364/1762] D loss: 1.3888, G loss: 0.6535\n",
      "[1444/1762] D loss: 1.3871, G loss: 0.6565\n",
      "[1524/1762] D loss: 1.3886, G loss: 0.6513\n",
      "[1604/1762] D loss: 1.3871, G loss: 0.7255\n",
      "[1684/1762] D loss: 1.4380, G loss: 0.9966\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.6864\n",
      "train error: \n",
      " D loss: 1.384349, G loss: 0.933499, D accuracy: 51.7%, cell accuracy: 99.9%, board accuracy: 93.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.369728, G loss: 0.948062, D accuracy: 52.8%, cell accuracy: 99.9%, board accuracy: 91.4% \n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3875, G loss: 0.6702\n",
      "[84/1762] D loss: 1.3957, G loss: 0.5993\n",
      "[164/1762] D loss: 1.3871, G loss: 0.6741\n",
      "[244/1762] D loss: 1.3919, G loss: 0.6272\n",
      "[324/1762] D loss: 1.3877, G loss: 0.6701\n",
      "[404/1762] D loss: 1.4043, G loss: 0.8382\n",
      "[484/1762] D loss: 1.3868, G loss: 0.7019\n",
      "[564/1762] D loss: 1.3888, G loss: 0.6505\n",
      "[644/1762] D loss: 1.3872, G loss: 0.6960\n",
      "[724/1762] D loss: 0.3767, G loss: 1.2753\n",
      "[804/1762] D loss: 1.3874, G loss: 0.7202\n",
      "[884/1762] D loss: 0.1917, G loss: 2.5901\n",
      "[964/1762] D loss: 1.3933, G loss: 0.6231\n",
      "[1044/1762] D loss: 1.3878, G loss: 0.6852\n",
      "[1124/1762] D loss: 1.5264, G loss: 1.2019\n",
      "[1204/1762] D loss: 1.3938, G loss: 0.6240\n",
      "[1284/1762] D loss: 1.5268, G loss: 1.0819\n",
      "[1364/1762] D loss: 1.7155, G loss: 0.8970\n",
      "[1444/1762] D loss: 0.4730, G loss: 0.9950\n",
      "[1524/1762] D loss: 0.3528, G loss: 1.2553\n",
      "[1604/1762] D loss: 1.3868, G loss: 0.7053\n",
      "[1684/1762] D loss: 1.3881, G loss: 0.6609\n",
      "[1762/1762] D loss: 1.3866, G loss: 0.7096\n",
      "train error: \n",
      " D loss: 1.462997, G loss: 0.855610, D accuracy: 47.7%, cell accuracy: 99.9%, board accuracy: 94.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.470972, G loss: 0.849311, D accuracy: 47.0%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3866, G loss: 0.7081\n",
      "[84/1762] D loss: 0.3087, G loss: 1.3794\n",
      "[164/1762] D loss: 1.3871, G loss: 0.6905\n",
      "[244/1762] D loss: 0.1056, G loss: 2.3365\n",
      "[324/1762] D loss: 1.3867, G loss: 0.6791\n",
      "[404/1762] D loss: 1.3871, G loss: 0.6749\n",
      "[484/1762] D loss: 1.3883, G loss: 0.6470\n",
      "[564/1762] D loss: 0.2398, G loss: 1.5619\n",
      "[644/1762] D loss: 1.3872, G loss: 0.6927\n",
      "[724/1762] D loss: 1.3867, G loss: 0.6958\n",
      "[804/1762] D loss: 0.3200, G loss: 1.2885\n",
      "[884/1762] D loss: 0.5445, G loss: 0.9982\n",
      "[964/1762] D loss: 0.4006, G loss: 1.3199\n",
      "[1044/1762] D loss: 0.4160, G loss: 1.0901\n",
      "[1124/1762] D loss: 1.3871, G loss: 0.7081\n",
      "[1204/1762] D loss: 1.3872, G loss: 0.7147\n",
      "[1284/1762] D loss: 1.3877, G loss: 0.7236\n",
      "[1364/1762] D loss: 0.9222, G loss: 1.4226\n",
      "[1444/1762] D loss: 1.3870, G loss: 0.7165\n",
      "[1524/1762] D loss: 1.3867, G loss: 0.6899\n",
      "[1604/1762] D loss: 1.3871, G loss: 0.6789\n",
      "[1684/1762] D loss: 1.3895, G loss: 0.6688\n",
      "[1762/1762] D loss: 1.3866, G loss: 0.7090\n",
      "train error: \n",
      " D loss: 1.598730, G loss: 0.910315, D accuracy: 50.4%, cell accuracy: 99.9%, board accuracy: 93.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.553917, G loss: 0.947504, D accuracy: 50.5%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3917, G loss: 0.7678\n",
      "[84/1762] D loss: 1.3965, G loss: 0.8192\n",
      "[164/1762] D loss: 0.5138, G loss: 1.2463\n",
      "[244/1762] D loss: 1.3894, G loss: 0.6505\n",
      "[324/1762] D loss: 1.3875, G loss: 0.7213\n",
      "[404/1762] D loss: 1.1450, G loss: 1.4982\n",
      "[484/1762] D loss: 1.3869, G loss: 0.6974\n",
      "[564/1762] D loss: 1.3874, G loss: 0.7191\n",
      "[644/1762] D loss: 1.3886, G loss: 0.7360\n",
      "[724/1762] D loss: 0.3598, G loss: 2.8000\n",
      "[804/1762] D loss: 1.4029, G loss: 0.8141\n",
      "[884/1762] D loss: 0.1976, G loss: 4.2623\n",
      "[964/1762] D loss: 0.1874, G loss: 5.3117\n",
      "[1044/1762] D loss: 1.3880, G loss: 0.7046\n",
      "[1124/1762] D loss: 1.4500, G loss: 0.8520\n",
      "[1204/1762] D loss: 0.1317, G loss: 3.7169\n",
      "[1284/1762] D loss: 1.4421, G loss: 0.8069\n",
      "[1364/1762] D loss: 1.3866, G loss: 0.7009\n",
      "[1444/1762] D loss: 1.3866, G loss: 0.6875\n",
      "[1524/1762] D loss: 1.3869, G loss: 0.7071\n",
      "[1604/1762] D loss: 1.1417, G loss: 1.2674\n",
      "[1684/1762] D loss: 1.2823, G loss: 0.7952\n",
      "[1762/1762] D loss: 0.4641, G loss: 1.0305\n",
      "train error: \n",
      " D loss: 4.430563, G loss: 0.205647, D accuracy: 51.6%, cell accuracy: 99.7%, board accuracy: 88.1% \n",
      "\n",
      "test error: \n",
      " D loss: 4.339682, G loss: 0.220526, D accuracy: 52.5%, cell accuracy: 99.5%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4014, G loss: 0.8266\n",
      "[84/1762] D loss: 1.3889, G loss: 0.7302\n",
      "[164/1762] D loss: 1.1944, G loss: 1.1592\n",
      "[244/1762] D loss: 1.3874, G loss: 0.6574\n",
      "[324/1762] D loss: 1.4559, G loss: 0.5578\n",
      "[404/1762] D loss: 1.4022, G loss: 0.7741\n",
      "[484/1762] D loss: 1.3997, G loss: 0.7386\n",
      "[564/1762] D loss: 0.0070, G loss: 6.0103\n",
      "[644/1762] D loss: 0.1048, G loss: 4.6529\n",
      "[724/1762] D loss: 1.4636, G loss: 0.9229\n",
      "[804/1762] D loss: 0.0544, G loss: 4.3460\n",
      "[884/1762] D loss: 1.3891, G loss: 0.7041\n",
      "[964/1762] D loss: 1.4169, G loss: 0.7967\n",
      "[1044/1762] D loss: 1.2413, G loss: 1.1480\n",
      "[1124/1762] D loss: 1.4067, G loss: 0.8282\n",
      "[1204/1762] D loss: 1.3767, G loss: 0.6791\n",
      "[1284/1762] D loss: 1.2932, G loss: 0.6419\n",
      "[1364/1762] D loss: 1.3893, G loss: 0.6478\n",
      "[1444/1762] D loss: 1.3906, G loss: 0.7120\n",
      "[1524/1762] D loss: 1.3877, G loss: 0.7169\n",
      "[1604/1762] D loss: 0.5273, G loss: 1.3155\n",
      "[1684/1762] D loss: 1.3934, G loss: 0.7739\n",
      "[1762/1762] D loss: 1.3936, G loss: 0.6126\n",
      "train error: \n",
      " D loss: 1.537000, G loss: 1.105759, D accuracy: 51.7%, cell accuracy: 99.8%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.471509, G loss: 1.746182, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1109, G loss: 1.2393\n",
      "[84/1762] D loss: 1.4345, G loss: 10.9922\n",
      "[164/1762] D loss: 1.3915, G loss: 0.6260\n",
      "[244/1762] D loss: 1.3886, G loss: 0.6494\n",
      "[324/1762] D loss: 0.8231, G loss: 2.4030\n",
      "[404/1762] D loss: 1.3877, G loss: 0.7285\n",
      "[484/1762] D loss: 1.3907, G loss: 0.7316\n",
      "[564/1762] D loss: 0.0041, G loss: 9.4096\n",
      "[644/1762] D loss: 1.3904, G loss: 0.6322\n",
      "[724/1762] D loss: 1.3887, G loss: 0.6799\n",
      "[804/1762] D loss: 1.3867, G loss: 0.7037\n",
      "[884/1762] D loss: 0.0032, G loss: 15.9396\n",
      "[964/1762] D loss: 1.4700, G loss: 0.8702\n",
      "[1044/1762] D loss: 1.3930, G loss: 0.6204\n",
      "[1124/1762] D loss: 1.3892, G loss: 0.7325\n",
      "[1204/1762] D loss: 0.0282, G loss: 4.8701\n",
      "[1284/1762] D loss: 0.0250, G loss: 5.7583\n",
      "[1364/1762] D loss: 0.0152, G loss: 5.7390\n",
      "[1444/1762] D loss: 1.3872, G loss: 0.7204\n",
      "[1524/1762] D loss: 1.3886, G loss: 0.7341\n",
      "[1604/1762] D loss: 0.0004, G loss: 8.4977\n",
      "[1684/1762] D loss: 1.3884, G loss: 0.6484\n",
      "[1762/1762] D loss: 1.3873, G loss: 0.6633\n",
      "train error: \n",
      " D loss: 1.954447, G loss: 0.915179, D accuracy: 51.4%, cell accuracy: 99.8%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.944544, G loss: 1.069299, D accuracy: 51.9%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0123, G loss: 5.6579\n",
      "[84/1762] D loss: 1.3868, G loss: 0.6943\n",
      "[164/1762] D loss: 1.3872, G loss: 0.6856\n",
      "[244/1762] D loss: 1.3871, G loss: 0.6902\n",
      "[324/1762] D loss: 0.0054, G loss: 9.5246\n",
      "[404/1762] D loss: 1.3890, G loss: 0.6372\n",
      "[484/1762] D loss: 1.3875, G loss: 0.7233\n",
      "[564/1762] D loss: 1.3880, G loss: 0.7328\n",
      "[644/1762] D loss: 1.3869, G loss: 0.6569\n",
      "[724/1762] D loss: 1.3867, G loss: 0.6889\n",
      "[804/1762] D loss: 0.0002, G loss: 11.0231\n",
      "[884/1762] D loss: 1.3870, G loss: 0.6748\n",
      "[964/1762] D loss: 1.3931, G loss: 0.8387\n",
      "[1044/1762] D loss: 0.2225, G loss: 3.5836\n",
      "[1124/1762] D loss: 1.3914, G loss: 0.7557\n",
      "[1204/1762] D loss: 1.3860, G loss: 0.6956\n",
      "[1284/1762] D loss: 1.3874, G loss: 0.6582\n",
      "[1364/1762] D loss: 0.0037, G loss: 6.3551\n",
      "[1444/1762] D loss: 0.0009, G loss: 7.8717\n",
      "[1524/1762] D loss: 1.3876, G loss: 0.7333\n",
      "[1604/1762] D loss: 1.3872, G loss: 0.6688\n",
      "[1684/1762] D loss: 1.3873, G loss: 0.7041\n",
      "[1762/1762] D loss: 1.3862, G loss: 0.6685\n",
      "train error: \n",
      " D loss: 2.277927, G loss: 1.152505, D accuracy: 50.7%, cell accuracy: 99.7%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 2.264435, G loss: 1.305284, D accuracy: 51.6%, cell accuracy: 99.6%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3859, G loss: 0.6825\n",
      "[84/1762] D loss: 1.3879, G loss: 0.7290\n",
      "[164/1762] D loss: 1.3930, G loss: 0.6132\n",
      "[244/1762] D loss: 1.3876, G loss: 0.6747\n",
      "[324/1762] D loss: 1.3872, G loss: 0.7199\n",
      "[404/1762] D loss: 1.3885, G loss: 0.7401\n",
      "[484/1762] D loss: 1.3877, G loss: 0.6548\n",
      "[564/1762] D loss: 0.0000, G loss: 11.5524\n",
      "[644/1762] D loss: 1.3885, G loss: 0.6537\n",
      "[724/1762] D loss: 1.4009, G loss: 0.7616\n",
      "[804/1762] D loss: 1.3814, G loss: 0.6707\n",
      "[884/1762] D loss: 1.3868, G loss: 0.6672\n",
      "[964/1762] D loss: 0.0109, G loss: 5.6347\n",
      "[1044/1762] D loss: 0.0061, G loss: 6.7867\n",
      "[1124/1762] D loss: 1.3990, G loss: 0.7270\n",
      "[1204/1762] D loss: 1.3881, G loss: 0.6684\n",
      "[1284/1762] D loss: 1.2212, G loss: 1.5986\n",
      "[1364/1762] D loss: 1.3894, G loss: 0.6363\n",
      "[1444/1762] D loss: 1.3877, G loss: 0.6553\n",
      "[1524/1762] D loss: 0.0340, G loss: 15.5581\n",
      "[1604/1762] D loss: 1.3889, G loss: 0.6435\n",
      "[1684/1762] D loss: 0.0522, G loss: 5.5628\n",
      "[1762/1762] D loss: 1.3949, G loss: 0.6532\n",
      "train error: \n",
      " D loss: 2.031210, G loss: 1.214757, D accuracy: 50.7%, cell accuracy: 99.7%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 2.022785, G loss: 1.505904, D accuracy: 51.4%, cell accuracy: 99.7%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3862, G loss: 0.7144\n",
      "[84/1762] D loss: 1.3873, G loss: 0.6761\n",
      "[164/1762] D loss: 1.3924, G loss: 0.7819\n",
      "[244/1762] D loss: 1.3868, G loss: 0.7355\n",
      "[324/1762] D loss: 1.4244, G loss: 0.8693\n",
      "[404/1762] D loss: 1.3716, G loss: 1.3599\n",
      "[484/1762] D loss: 1.3885, G loss: 0.6842\n",
      "[564/1762] D loss: 1.3950, G loss: 0.7878\n",
      "[644/1762] D loss: 1.3900, G loss: 0.7491\n",
      "[724/1762] D loss: 1.3888, G loss: 0.7205\n",
      "[804/1762] D loss: 1.3871, G loss: 0.6736\n",
      "[884/1762] D loss: 1.3897, G loss: 0.7153\n",
      "[964/1762] D loss: 1.3871, G loss: 0.6668\n",
      "[1044/1762] D loss: 1.1076, G loss: 4.1652\n",
      "[1124/1762] D loss: 1.3743, G loss: 0.6535\n",
      "[1204/1762] D loss: 1.3855, G loss: 0.7136\n",
      "[1284/1762] D loss: 1.3906, G loss: 0.6279\n",
      "[1364/1762] D loss: 1.3905, G loss: 0.6774\n",
      "[1444/1762] D loss: 1.3867, G loss: 0.6958\n",
      "[1524/1762] D loss: 1.3879, G loss: 0.6946\n",
      "[1604/1762] D loss: 0.0001, G loss: 10.0928\n",
      "[1684/1762] D loss: 1.3936, G loss: 0.6170\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.6934\n",
      "train error: \n",
      " D loss: 2.312071, G loss: 1.200815, D accuracy: 51.0%, cell accuracy: 99.7%, board accuracy: 92.8% \n",
      "\n",
      "test error: \n",
      " D loss: 2.321275, G loss: 1.367365, D accuracy: 51.6%, cell accuracy: 99.7%, board accuracy: 90.7% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3903, G loss: 0.6282\n",
      "[84/1762] D loss: 1.3527, G loss: 0.6305\n",
      "[164/1762] D loss: 1.1250, G loss: 0.7286\n",
      "[244/1762] D loss: 0.7950, G loss: 1.8467\n",
      "[324/1762] D loss: 0.5716, G loss: 2.2168\n",
      "[404/1762] D loss: 0.6533, G loss: 1.4439\n",
      "[484/1762] D loss: 0.6233, G loss: 1.8313\n",
      "[564/1762] D loss: 0.9736, G loss: 0.7991\n",
      "[644/1762] D loss: 0.6135, G loss: 2.3519\n",
      "[724/1762] D loss: 0.6229, G loss: 1.1229\n",
      "[804/1762] D loss: 1.4647, G loss: 2.6990\n",
      "[884/1762] D loss: 1.0035, G loss: 1.1252\n",
      "[964/1762] D loss: 1.2513, G loss: 0.7656\n",
      "[1044/1762] D loss: 0.8345, G loss: 0.8863\n",
      "[1124/1762] D loss: 1.2046, G loss: 1.7901\n",
      "[1204/1762] D loss: 1.2110, G loss: 1.3193\n",
      "[1284/1762] D loss: 1.2279, G loss: 0.9496\n",
      "[1364/1762] D loss: 0.9389, G loss: 1.3315\n",
      "[1444/1762] D loss: 1.0311, G loss: 1.0390\n",
      "[1524/1762] D loss: 1.2328, G loss: 1.0064\n",
      "[1604/1762] D loss: 0.9873, G loss: 0.5135\n",
      "[1684/1762] D loss: 1.2724, G loss: 1.5039\n",
      "[1762/1762] D loss: 1.0902, G loss: 1.0984\n",
      "train error: \n",
      " D loss: 1.227928, G loss: 1.076350, D accuracy: 66.0%, cell accuracy: 99.0%, board accuracy: 25.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.223639, G loss: 1.097285, D accuracy: 65.6%, cell accuracy: 98.9%, board accuracy: 22.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2924, G loss: 0.6823\n",
      "[84/1762] D loss: 1.4426, G loss: 0.7908\n",
      "[164/1762] D loss: 1.4280, G loss: 0.6332\n",
      "[244/1762] D loss: 1.2696, G loss: 1.0135\n",
      "[324/1762] D loss: 1.1322, G loss: 1.2221\n",
      "[404/1762] D loss: 1.2544, G loss: 0.9811\n",
      "[484/1762] D loss: 1.2564, G loss: 0.7918\n",
      "[564/1762] D loss: 1.3455, G loss: 0.6345\n",
      "[644/1762] D loss: 1.3037, G loss: 0.5782\n",
      "[724/1762] D loss: 1.3037, G loss: 0.7312\n",
      "[804/1762] D loss: 1.2136, G loss: 0.7441\n",
      "[884/1762] D loss: 1.2533, G loss: 0.9384\n",
      "[964/1762] D loss: 1.2779, G loss: 1.0170\n",
      "[1044/1762] D loss: 1.5383, G loss: 0.8937\n",
      "[1124/1762] D loss: 1.4119, G loss: 0.8860\n",
      "[1204/1762] D loss: 1.3807, G loss: 1.2901\n",
      "[1284/1762] D loss: 1.6780, G loss: 1.4488\n",
      "[1364/1762] D loss: 1.3702, G loss: 0.5674\n",
      "[1444/1762] D loss: 1.4581, G loss: 0.7123\n",
      "[1524/1762] D loss: 1.3652, G loss: 0.7197\n",
      "[1604/1762] D loss: 1.3283, G loss: 0.6921\n",
      "[1684/1762] D loss: 1.4615, G loss: 0.6746\n",
      "[1762/1762] D loss: 1.2712, G loss: 0.8779\n",
      "train error: \n",
      " D loss: 1.394050, G loss: 0.947380, D accuracy: 52.4%, cell accuracy: 99.7%, board accuracy: 72.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.390975, G loss: 0.950057, D accuracy: 52.8%, cell accuracy: 99.6%, board accuracy: 67.5% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4525, G loss: 0.9124\n",
      "[84/1762] D loss: 1.3600, G loss: 0.7982\n",
      "[164/1762] D loss: 1.3187, G loss: 0.9067\n",
      "[244/1762] D loss: 1.3395, G loss: 0.7783\n",
      "[324/1762] D loss: 1.3574, G loss: 1.1235\n",
      "[404/1762] D loss: 1.3633, G loss: 0.7141\n",
      "[484/1762] D loss: 1.3806, G loss: 0.7307\n",
      "[564/1762] D loss: 1.4022, G loss: 0.6805\n",
      "[644/1762] D loss: 1.3580, G loss: 0.7188\n",
      "[724/1762] D loss: 1.3368, G loss: 0.7161\n",
      "[804/1762] D loss: 1.3420, G loss: 0.5609\n",
      "[884/1762] D loss: 1.3159, G loss: 0.7078\n",
      "[964/1762] D loss: 1.2341, G loss: 0.7531\n",
      "[1044/1762] D loss: 1.3744, G loss: 0.6946\n",
      "[1124/1762] D loss: 1.3666, G loss: 0.6809\n",
      "[1204/1762] D loss: 1.3563, G loss: 0.6273\n",
      "[1284/1762] D loss: 1.3092, G loss: 0.5907\n",
      "[1364/1762] D loss: 1.2471, G loss: 0.8873\n",
      "[1444/1762] D loss: 1.4341, G loss: 0.7759\n",
      "[1524/1762] D loss: 1.4227, G loss: 0.7095\n",
      "[1604/1762] D loss: 1.3817, G loss: 0.8500\n",
      "[1684/1762] D loss: 1.3724, G loss: 0.9421\n",
      "[1762/1762] D loss: 1.3655, G loss: 0.5829\n",
      "train error: \n",
      " D loss: 1.370677, G loss: 0.603636, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 80.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.365235, G loss: 0.603017, D accuracy: 55.2%, cell accuracy: 99.7%, board accuracy: 77.3% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3677, G loss: 0.5132\n",
      "[84/1762] D loss: 1.2508, G loss: 0.6828\n",
      "[164/1762] D loss: 1.3521, G loss: 0.7271\n",
      "[244/1762] D loss: 1.3435, G loss: 0.7769\n",
      "[324/1762] D loss: 1.4626, G loss: 0.9114\n",
      "[404/1762] D loss: 1.4618, G loss: 1.0087\n",
      "[484/1762] D loss: 1.3584, G loss: 0.7004\n",
      "[564/1762] D loss: 1.3465, G loss: 0.6854\n",
      "[644/1762] D loss: 1.3924, G loss: 0.7884\n",
      "[724/1762] D loss: 1.3467, G loss: 0.9727\n",
      "[804/1762] D loss: 1.3648, G loss: 0.6386\n",
      "[884/1762] D loss: 1.3503, G loss: 0.6194\n",
      "[964/1762] D loss: 1.3472, G loss: 0.6616\n",
      "[1044/1762] D loss: 1.3674, G loss: 0.7437\n",
      "[1124/1762] D loss: 1.3340, G loss: 0.8004\n",
      "[1204/1762] D loss: 1.3334, G loss: 0.7048\n",
      "[1284/1762] D loss: 1.3749, G loss: 0.8814\n",
      "[1364/1762] D loss: 1.4417, G loss: 0.7038\n",
      "[1444/1762] D loss: 1.3809, G loss: 0.6221\n",
      "[1524/1762] D loss: 1.3614, G loss: 0.6614\n",
      "[1604/1762] D loss: 1.3937, G loss: 0.7526\n",
      "[1684/1762] D loss: 1.3552, G loss: 0.8612\n",
      "[1762/1762] D loss: 1.4137, G loss: 0.5861\n",
      "train error: \n",
      " D loss: 1.372779, G loss: 0.634231, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 85.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.368517, G loss: 0.633817, D accuracy: 55.6%, cell accuracy: 99.7%, board accuracy: 83.0% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3301, G loss: 0.7670\n",
      "[84/1762] D loss: 1.3340, G loss: 0.5462\n",
      "[164/1762] D loss: 1.3915, G loss: 0.8140\n",
      "[244/1762] D loss: 1.3864, G loss: 0.9741\n",
      "[324/1762] D loss: 1.4046, G loss: 0.5366\n",
      "[404/1762] D loss: 1.2971, G loss: 0.8195\n",
      "[484/1762] D loss: 1.3900, G loss: 0.7293\n",
      "[564/1762] D loss: 1.3069, G loss: 0.8813\n",
      "[644/1762] D loss: 1.3256, G loss: 0.6735\n",
      "[724/1762] D loss: 1.3342, G loss: 0.6899\n",
      "[804/1762] D loss: 1.3237, G loss: 0.7422\n",
      "[884/1762] D loss: 1.3890, G loss: 0.7093\n",
      "[964/1762] D loss: 1.2912, G loss: 0.6527\n",
      "[1044/1762] D loss: 1.3902, G loss: 0.6185\n",
      "[1124/1762] D loss: 1.2996, G loss: 1.0058\n",
      "[1204/1762] D loss: 1.4074, G loss: 0.6970\n",
      "[1284/1762] D loss: 1.3849, G loss: 0.5752\n",
      "[1364/1762] D loss: 1.2881, G loss: 0.8012\n",
      "[1444/1762] D loss: 1.3983, G loss: 0.6119\n",
      "[1524/1762] D loss: 1.3938, G loss: 0.6023\n",
      "[1604/1762] D loss: 1.3027, G loss: 0.8727\n",
      "[1684/1762] D loss: 1.6984, G loss: 0.4343\n",
      "[1762/1762] D loss: 1.3078, G loss: 0.8538\n",
      "train error: \n",
      " D loss: 1.236027, G loss: 0.750204, D accuracy: 70.5%, cell accuracy: 95.2%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.235128, G loss: 0.758898, D accuracy: 69.5%, cell accuracy: 95.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2426, G loss: 0.7101\n",
      "[84/1762] D loss: 1.4006, G loss: 0.8613\n",
      "[164/1762] D loss: 1.3871, G loss: 0.7242\n",
      "[244/1762] D loss: 1.3840, G loss: 0.6105\n",
      "[324/1762] D loss: 1.3888, G loss: 0.7668\n",
      "[404/1762] D loss: 1.3817, G loss: 0.7482\n",
      "[484/1762] D loss: 1.3948, G loss: 0.7440\n",
      "[564/1762] D loss: 1.2906, G loss: 0.7458\n",
      "[644/1762] D loss: 1.3776, G loss: 0.7081\n",
      "[724/1762] D loss: 1.3890, G loss: 0.7023\n",
      "[804/1762] D loss: 1.3541, G loss: 0.7772\n",
      "[884/1762] D loss: 1.3896, G loss: 0.7040\n",
      "[964/1762] D loss: 1.3707, G loss: 0.6894\n",
      "[1044/1762] D loss: 1.3460, G loss: 0.7280\n",
      "[1124/1762] D loss: 1.3917, G loss: 0.7784\n",
      "[1204/1762] D loss: 1.3738, G loss: 0.6031\n",
      "[1284/1762] D loss: 1.3444, G loss: 0.7683\n",
      "[1364/1762] D loss: 1.3660, G loss: 0.8469\n",
      "[1444/1762] D loss: 1.3785, G loss: 0.7442\n",
      "[1524/1762] D loss: 1.3847, G loss: 0.7204\n",
      "[1604/1762] D loss: 1.2444, G loss: 0.9019\n",
      "[1684/1762] D loss: 1.4230, G loss: 0.5225\n",
      "[1762/1762] D loss: 1.4011, G loss: 0.7020\n",
      "train error: \n",
      " D loss: 1.352325, G loss: 0.748763, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 85.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.342337, G loss: 0.753033, D accuracy: 55.6%, cell accuracy: 99.7%, board accuracy: 82.0% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3148, G loss: 0.7002\n",
      "[84/1762] D loss: 1.3990, G loss: 0.8930\n",
      "[164/1762] D loss: 1.2947, G loss: 0.5742\n",
      "[244/1762] D loss: 1.3297, G loss: 0.6580\n",
      "[324/1762] D loss: 1.3970, G loss: 0.7502\n",
      "[404/1762] D loss: 1.3910, G loss: 0.7050\n",
      "[484/1762] D loss: 1.3549, G loss: 0.7502\n",
      "[564/1762] D loss: 1.4011, G loss: 0.8613\n",
      "[644/1762] D loss: 1.2778, G loss: 0.6792\n",
      "[724/1762] D loss: 1.4067, G loss: 0.7735\n",
      "[804/1762] D loss: 1.5136, G loss: 0.5334\n",
      "[884/1762] D loss: 1.3907, G loss: 0.6994\n",
      "[964/1762] D loss: 1.3631, G loss: 0.7169\n",
      "[1044/1762] D loss: 1.2548, G loss: 0.8505\n",
      "[1124/1762] D loss: 1.4574, G loss: 0.6971\n",
      "[1204/1762] D loss: 1.4350, G loss: 0.5628\n",
      "[1284/1762] D loss: 1.3419, G loss: 0.7665\n",
      "[1364/1762] D loss: 1.3680, G loss: 0.7938\n",
      "[1444/1762] D loss: 1.4048, G loss: 0.7625\n",
      "[1524/1762] D loss: 1.3622, G loss: 0.7811\n",
      "[1604/1762] D loss: 1.3952, G loss: 0.5928\n",
      "[1684/1762] D loss: 1.4035, G loss: 1.0204\n",
      "[1762/1762] D loss: 1.3221, G loss: 0.7376\n",
      "train error: \n",
      " D loss: 1.374305, G loss: 0.749769, D accuracy: 54.0%, cell accuracy: 99.0%, board accuracy: 26.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.372939, G loss: 0.753448, D accuracy: 53.8%, cell accuracy: 98.9%, board accuracy: 23.9% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2976, G loss: 0.7736\n",
      "[84/1762] D loss: 1.3685, G loss: 0.8311\n",
      "[164/1762] D loss: 1.4098, G loss: 0.6289\n",
      "[244/1762] D loss: 1.3605, G loss: 0.6906\n",
      "[324/1762] D loss: 1.3783, G loss: 0.7275\n",
      "[404/1762] D loss: 1.3541, G loss: 0.6633\n",
      "[484/1762] D loss: 1.3704, G loss: 0.6610\n",
      "[564/1762] D loss: 1.3900, G loss: 0.6604\n",
      "[644/1762] D loss: 1.3833, G loss: 0.7480\n",
      "[724/1762] D loss: 1.3153, G loss: 0.7184\n",
      "[804/1762] D loss: 1.3893, G loss: 0.6960\n",
      "[884/1762] D loss: 1.3920, G loss: 0.6815\n",
      "[964/1762] D loss: 1.3083, G loss: 0.7890\n",
      "[1044/1762] D loss: 1.3949, G loss: 0.6967\n",
      "[1124/1762] D loss: 1.2890, G loss: 0.7796\n",
      "[1204/1762] D loss: 1.4024, G loss: 0.6874\n",
      "[1284/1762] D loss: 1.3877, G loss: 0.6974\n",
      "[1364/1762] D loss: 1.4039, G loss: 0.7749\n",
      "[1444/1762] D loss: 1.3279, G loss: 0.8176\n",
      "[1524/1762] D loss: 1.3831, G loss: 0.6771\n",
      "[1604/1762] D loss: 1.4431, G loss: 0.5672\n",
      "[1684/1762] D loss: 1.2710, G loss: 0.8242\n",
      "[1762/1762] D loss: 1.3233, G loss: 0.7897\n",
      "train error: \n",
      " D loss: 1.393202, G loss: 0.794103, D accuracy: 51.6%, cell accuracy: 99.7%, board accuracy: 69.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.401964, G loss: 0.797457, D accuracy: 50.6%, cell accuracy: 99.6%, board accuracy: 65.9% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3723, G loss: 0.7321\n",
      "[84/1762] D loss: 1.3565, G loss: 0.6690\n",
      "[164/1762] D loss: 1.3620, G loss: 0.6364\n",
      "[244/1762] D loss: 1.3561, G loss: 0.5998\n",
      "[324/1762] D loss: 1.3799, G loss: 0.7214\n",
      "[404/1762] D loss: 1.3509, G loss: 0.7084\n",
      "[484/1762] D loss: 1.3361, G loss: 0.7550\n",
      "[564/1762] D loss: 1.2827, G loss: 0.7735\n",
      "[644/1762] D loss: 1.3933, G loss: 0.6490\n",
      "[724/1762] D loss: 1.3379, G loss: 0.6896\n",
      "[804/1762] D loss: 1.4367, G loss: 0.6119\n",
      "[884/1762] D loss: 1.3719, G loss: 0.7504\n",
      "[964/1762] D loss: 1.3919, G loss: 0.7617\n",
      "[1044/1762] D loss: 1.3755, G loss: 0.7632\n",
      "[1124/1762] D loss: 1.2879, G loss: 0.7567\n",
      "[1204/1762] D loss: 1.3630, G loss: 0.7031\n",
      "[1284/1762] D loss: 1.4007, G loss: 0.7117\n",
      "[1364/1762] D loss: 1.2619, G loss: 0.7022\n",
      "[1444/1762] D loss: 1.3926, G loss: 0.6447\n",
      "[1524/1762] D loss: 1.3948, G loss: 0.7957\n",
      "[1604/1762] D loss: 1.3963, G loss: 0.5915\n",
      "[1684/1762] D loss: 1.4505, G loss: 0.8719\n",
      "[1762/1762] D loss: 1.3894, G loss: 0.7278\n",
      "train error: \n",
      " D loss: 1.354876, G loss: 0.639864, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 84.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.346385, G loss: 0.640059, D accuracy: 55.6%, cell accuracy: 99.7%, board accuracy: 81.8% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4254, G loss: 0.6528\n",
      "[84/1762] D loss: 1.3941, G loss: 0.6819\n",
      "[164/1762] D loss: 1.2367, G loss: 0.7978\n",
      "[244/1762] D loss: 1.3930, G loss: 0.6225\n",
      "[324/1762] D loss: 1.3869, G loss: 0.7735\n",
      "[404/1762] D loss: 1.3895, G loss: 0.6490\n",
      "[484/1762] D loss: 1.3904, G loss: 0.6214\n",
      "[564/1762] D loss: 1.4899, G loss: 0.7128\n",
      "[644/1762] D loss: 1.2942, G loss: 0.8169\n",
      "[724/1762] D loss: 1.4940, G loss: 0.6306\n",
      "[804/1762] D loss: 1.3869, G loss: 0.7662\n",
      "[884/1762] D loss: 1.3855, G loss: 0.7005\n",
      "[964/1762] D loss: 1.3812, G loss: 0.7414\n",
      "[1044/1762] D loss: 1.3834, G loss: 0.7150\n",
      "[1124/1762] D loss: 1.3731, G loss: 0.7158\n",
      "[1204/1762] D loss: 1.3836, G loss: 0.6840\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6850\n",
      "[1364/1762] D loss: 1.3881, G loss: 0.7141\n",
      "[1444/1762] D loss: 1.3866, G loss: 0.7178\n",
      "[1524/1762] D loss: 1.3830, G loss: 0.7053\n",
      "[1604/1762] D loss: 1.3814, G loss: 0.7148\n",
      "[1684/1762] D loss: 1.3876, G loss: 0.7149\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6697\n",
      "train error: \n",
      " D loss: 1.380453, G loss: 0.695362, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.379015, G loss: 0.696853, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 83.0% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.7047\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6756\n",
      "[164/1762] D loss: 1.3869, G loss: 0.7006\n",
      "[244/1762] D loss: 1.3594, G loss: 0.7314\n",
      "[324/1762] D loss: 1.3845, G loss: 0.6872\n",
      "[404/1762] D loss: 1.3871, G loss: 0.6946\n",
      "[484/1762] D loss: 1.3850, G loss: 0.6933\n",
      "[564/1762] D loss: 1.3812, G loss: 0.7434\n",
      "[644/1762] D loss: 1.3876, G loss: 0.6680\n",
      "[724/1762] D loss: 1.3871, G loss: 0.6962\n",
      "[804/1762] D loss: 1.3869, G loss: 0.6864\n",
      "[884/1762] D loss: 1.6371, G loss: 0.6619\n",
      "[964/1762] D loss: 1.3376, G loss: 0.8021\n",
      "[1044/1762] D loss: 1.4082, G loss: 0.7453\n",
      "[1124/1762] D loss: 1.3834, G loss: 0.6650\n",
      "[1204/1762] D loss: 1.3893, G loss: 0.6932\n",
      "[1284/1762] D loss: 1.3860, G loss: 0.6941\n",
      "[1364/1762] D loss: 1.3814, G loss: 0.6929\n",
      "[1444/1762] D loss: 1.3870, G loss: 0.6885\n",
      "[1524/1762] D loss: 1.3856, G loss: 0.6982\n",
      "[1604/1762] D loss: 1.3374, G loss: 0.7305\n",
      "[1684/1762] D loss: 1.3896, G loss: 0.6875\n",
      "[1762/1762] D loss: 1.3840, G loss: 0.7150\n",
      "train error: \n",
      " D loss: 1.373832, G loss: 0.705131, D accuracy: 53.1%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.369784, G loss: 0.705601, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 82.3% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3870, G loss: 0.7095\n",
      "[84/1762] D loss: 1.3925, G loss: 0.6777\n",
      "[164/1762] D loss: 1.3878, G loss: 0.6682\n",
      "[244/1762] D loss: 1.2915, G loss: 0.6974\n",
      "[324/1762] D loss: 1.3175, G loss: 0.6909\n",
      "[404/1762] D loss: 1.4104, G loss: 0.6831\n",
      "[484/1762] D loss: 1.3965, G loss: 0.6615\n",
      "[564/1762] D loss: 1.3913, G loss: 0.6918\n",
      "[644/1762] D loss: 1.3898, G loss: 0.7069\n",
      "[724/1762] D loss: 1.3871, G loss: 0.7180\n",
      "[804/1762] D loss: 1.2811, G loss: 0.6927\n",
      "[884/1762] D loss: 1.4092, G loss: 0.7369\n",
      "[964/1762] D loss: 1.3332, G loss: 0.7300\n",
      "[1044/1762] D loss: 1.3862, G loss: 0.6963\n",
      "[1124/1762] D loss: 1.2552, G loss: 0.7857\n",
      "[1204/1762] D loss: 1.3798, G loss: 0.6934\n",
      "[1284/1762] D loss: 1.3870, G loss: 0.6845\n",
      "[1364/1762] D loss: 1.3922, G loss: 0.6888\n",
      "[1444/1762] D loss: 1.3550, G loss: 0.6733\n",
      "[1524/1762] D loss: 1.3823, G loss: 0.6726\n",
      "[1604/1762] D loss: 1.3778, G loss: 0.6730\n",
      "[1684/1762] D loss: 1.3905, G loss: 0.7302\n",
      "[1762/1762] D loss: 1.3994, G loss: 0.6590\n",
      "train error: \n",
      " D loss: 1.347100, G loss: 0.648262, D accuracy: 54.1%, cell accuracy: 99.4%, board accuracy: 53.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.329921, G loss: 0.648481, D accuracy: 55.8%, cell accuracy: 99.3%, board accuracy: 50.7% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3878, G loss: 0.7462\n",
      "[84/1762] D loss: 1.3555, G loss: 0.7605\n",
      "[164/1762] D loss: 1.4562, G loss: 0.8765\n",
      "[244/1762] D loss: 1.1684, G loss: 0.8042\n",
      "[324/1762] D loss: 1.3920, G loss: 0.6274\n",
      "[404/1762] D loss: 1.2273, G loss: 0.6541\n",
      "[484/1762] D loss: 1.3902, G loss: 0.7730\n",
      "[564/1762] D loss: 1.4035, G loss: 0.8529\n",
      "[644/1762] D loss: 1.3916, G loss: 0.7212\n",
      "[724/1762] D loss: 1.3905, G loss: 0.7376\n",
      "[804/1762] D loss: 1.1786, G loss: 0.8302\n",
      "[884/1762] D loss: 1.3875, G loss: 0.7001\n",
      "[964/1762] D loss: 1.3867, G loss: 0.6208\n",
      "[1044/1762] D loss: 1.3857, G loss: 0.7430\n",
      "[1124/1762] D loss: 1.3910, G loss: 0.6329\n",
      "[1204/1762] D loss: 1.3861, G loss: 0.7240\n",
      "[1284/1762] D loss: 1.3908, G loss: 0.7438\n",
      "[1364/1762] D loss: 1.3957, G loss: 0.5887\n",
      "[1444/1762] D loss: 1.3984, G loss: 0.8431\n",
      "[1524/1762] D loss: 1.3841, G loss: 0.7396\n",
      "[1604/1762] D loss: 1.3872, G loss: 0.7059\n",
      "[1684/1762] D loss: 1.3867, G loss: 0.7052\n",
      "[1762/1762] D loss: 1.3874, G loss: 0.6512\n",
      "train error: \n",
      " D loss: 1.330611, G loss: 0.675279, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 87.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.319691, G loss: 0.676358, D accuracy: 54.9%, cell accuracy: 99.7%, board accuracy: 83.9% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1848, G loss: 0.7165\n",
      "[84/1762] D loss: 1.3891, G loss: 0.6877\n",
      "[164/1762] D loss: 1.1867, G loss: 0.7716\n",
      "[244/1762] D loss: 1.3924, G loss: 0.6412\n",
      "[324/1762] D loss: 1.3895, G loss: 0.6781\n",
      "[404/1762] D loss: 1.1549, G loss: 0.7884\n",
      "[484/1762] D loss: 1.1597, G loss: 0.7706\n",
      "[564/1762] D loss: 1.3827, G loss: 0.6844\n",
      "[644/1762] D loss: 1.3947, G loss: 0.8116\n",
      "[724/1762] D loss: 1.3910, G loss: 0.7294\n",
      "[804/1762] D loss: 1.4182, G loss: 0.8621\n",
      "[884/1762] D loss: 1.3927, G loss: 0.7139\n",
      "[964/1762] D loss: 1.1750, G loss: 0.8141\n",
      "[1044/1762] D loss: 1.3915, G loss: 0.7251\n",
      "[1124/1762] D loss: 1.3924, G loss: 0.7567\n",
      "[1204/1762] D loss: 1.1712, G loss: 0.8359\n",
      "[1284/1762] D loss: 1.3931, G loss: 0.7859\n",
      "[1364/1762] D loss: 1.1657, G loss: 0.7417\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.6815\n",
      "[1524/1762] D loss: 1.3945, G loss: 0.8310\n",
      "[1604/1762] D loss: 1.3997, G loss: 0.6142\n",
      "[1684/1762] D loss: 1.1517, G loss: 0.7607\n",
      "[1762/1762] D loss: 1.3903, G loss: 0.6362\n",
      "train error: \n",
      " D loss: 1.327918, G loss: 0.654204, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 85.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.308824, G loss: 0.662574, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 82.5% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3922, G loss: 0.6520\n",
      "[84/1762] D loss: 1.3886, G loss: 0.6938\n",
      "[164/1762] D loss: 1.3867, G loss: 0.6825\n",
      "[244/1762] D loss: 1.3919, G loss: 0.7188\n",
      "[324/1762] D loss: 1.1547, G loss: 0.7834\n",
      "[404/1762] D loss: 1.3719, G loss: 0.6582\n",
      "[484/1762] D loss: 1.3858, G loss: 0.7344\n",
      "[564/1762] D loss: 1.3870, G loss: 0.8219\n",
      "[644/1762] D loss: 1.0893, G loss: 0.8458\n",
      "[724/1762] D loss: 0.9440, G loss: 0.8137\n",
      "[804/1762] D loss: 0.5296, G loss: 1.6621\n",
      "[884/1762] D loss: 1.3991, G loss: 0.4313\n",
      "[964/1762] D loss: 1.4196, G loss: 0.8859\n",
      "[1044/1762] D loss: 1.4005, G loss: 0.7814\n",
      "[1124/1762] D loss: 1.3754, G loss: 0.6793\n",
      "[1204/1762] D loss: 1.1945, G loss: 0.6765\n",
      "[1284/1762] D loss: 1.3923, G loss: 0.7141\n",
      "[1364/1762] D loss: 1.3877, G loss: 0.7220\n",
      "[1444/1762] D loss: 1.1531, G loss: 0.8396\n",
      "[1524/1762] D loss: 1.3668, G loss: 0.6878\n",
      "[1604/1762] D loss: 1.1488, G loss: 0.9725\n",
      "[1684/1762] D loss: 1.3870, G loss: 0.6763\n",
      "[1762/1762] D loss: 1.3950, G loss: 0.7660\n",
      "train error: \n",
      " D loss: 1.319733, G loss: 0.754405, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 86.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.306923, G loss: 0.760270, D accuracy: 54.9%, cell accuracy: 99.7%, board accuracy: 83.9% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3834, G loss: 0.6664\n",
      "[84/1762] D loss: 1.3859, G loss: 0.6791\n",
      "[164/1762] D loss: 1.3885, G loss: 0.7096\n",
      "[244/1762] D loss: 1.3793, G loss: 0.7013\n",
      "[324/1762] D loss: 1.3878, G loss: 0.6962\n",
      "[404/1762] D loss: 1.3812, G loss: 0.7117\n",
      "[484/1762] D loss: 1.1454, G loss: 0.8739\n",
      "[564/1762] D loss: 1.4072, G loss: 0.8591\n",
      "[644/1762] D loss: 1.3774, G loss: 0.6098\n",
      "[724/1762] D loss: 1.3879, G loss: 0.7551\n",
      "[804/1762] D loss: 1.1014, G loss: 0.9118\n",
      "[884/1762] D loss: 1.3930, G loss: 0.8033\n",
      "[964/1762] D loss: 1.3863, G loss: 0.6785\n",
      "[1044/1762] D loss: 1.3410, G loss: 0.7280\n",
      "[1124/1762] D loss: 1.3898, G loss: 0.6287\n",
      "[1204/1762] D loss: 1.4035, G loss: 0.7738\n",
      "[1284/1762] D loss: 1.3446, G loss: 0.7240\n",
      "[1364/1762] D loss: 1.3902, G loss: 0.7280\n",
      "[1444/1762] D loss: 1.1729, G loss: 0.7387\n",
      "[1524/1762] D loss: 1.2986, G loss: 0.7988\n",
      "[1604/1762] D loss: 1.3998, G loss: 0.5523\n",
      "[1684/1762] D loss: 1.3881, G loss: 0.7386\n",
      "[1762/1762] D loss: 1.3892, G loss: 0.7162\n",
      "train error: \n",
      " D loss: 1.325691, G loss: 0.717381, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 84.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.309639, G loss: 0.721439, D accuracy: 55.7%, cell accuracy: 99.7%, board accuracy: 81.4% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3947, G loss: 0.7067\n",
      "[84/1762] D loss: 1.4176, G loss: 0.5699\n",
      "[164/1762] D loss: 1.3977, G loss: 0.7754\n",
      "[244/1762] D loss: 1.1607, G loss: 0.7289\n",
      "[324/1762] D loss: 1.4146, G loss: 0.8165\n",
      "[404/1762] D loss: 1.3451, G loss: 0.7580\n",
      "[484/1762] D loss: 1.3896, G loss: 0.7421\n",
      "[564/1762] D loss: 1.2915, G loss: 0.8650\n",
      "[644/1762] D loss: 1.4341, G loss: 0.8598\n",
      "[724/1762] D loss: 1.3896, G loss: 0.6929\n",
      "[804/1762] D loss: 1.3941, G loss: 0.8249\n",
      "[884/1762] D loss: 1.1610, G loss: 0.7516\n",
      "[964/1762] D loss: 1.4379, G loss: 0.9557\n",
      "[1044/1762] D loss: 1.1541, G loss: 0.8171\n",
      "[1124/1762] D loss: 1.4112, G loss: 0.8431\n",
      "[1204/1762] D loss: 1.4018, G loss: 0.6922\n",
      "[1284/1762] D loss: 1.1268, G loss: 0.7775\n",
      "[1364/1762] D loss: 1.3890, G loss: 0.6705\n",
      "[1444/1762] D loss: 1.1345, G loss: 0.8741\n",
      "[1524/1762] D loss: 1.1293, G loss: 0.8434\n",
      "[1604/1762] D loss: 1.3736, G loss: 0.7034\n",
      "[1684/1762] D loss: 1.3907, G loss: 0.7297\n",
      "[1762/1762] D loss: 1.3985, G loss: 0.6398\n",
      "train error: \n",
      " D loss: 1.311349, G loss: 0.781697, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 89.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.288845, G loss: 0.802029, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 85.9% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3857, G loss: 0.7361\n",
      "[84/1762] D loss: 1.3852, G loss: 0.6562\n",
      "[164/1762] D loss: 1.3913, G loss: 0.6763\n",
      "[244/1762] D loss: 1.4102, G loss: 0.8189\n",
      "[324/1762] D loss: 1.1274, G loss: 0.8677\n",
      "[404/1762] D loss: 1.3964, G loss: 0.6428\n",
      "[484/1762] D loss: 1.3722, G loss: 0.7310\n",
      "[564/1762] D loss: 1.1567, G loss: 0.7224\n",
      "[644/1762] D loss: 1.4045, G loss: 0.8302\n",
      "[724/1762] D loss: 1.3748, G loss: 0.6888\n",
      "[804/1762] D loss: 1.3698, G loss: 0.6667\n",
      "[884/1762] D loss: 1.4103, G loss: 0.7643\n",
      "[964/1762] D loss: 1.1370, G loss: 0.7878\n",
      "[1044/1762] D loss: 1.3916, G loss: 0.6365\n",
      "[1124/1762] D loss: 1.4420, G loss: 0.8667\n",
      "[1204/1762] D loss: 1.1356, G loss: 0.8268\n",
      "[1284/1762] D loss: 1.3978, G loss: 0.6136\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6832\n",
      "[1444/1762] D loss: 1.3501, G loss: 0.6801\n",
      "[1524/1762] D loss: 1.1461, G loss: 0.7735\n",
      "[1604/1762] D loss: 1.3871, G loss: 0.6163\n",
      "[1684/1762] D loss: 1.3907, G loss: 0.6069\n",
      "[1762/1762] D loss: 1.3999, G loss: 0.7072\n",
      "train error: \n",
      " D loss: 1.315722, G loss: 0.824541, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 89.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.293936, G loss: 0.844129, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4040, G loss: 0.8211\n",
      "[84/1762] D loss: 1.3873, G loss: 0.6877\n",
      "[164/1762] D loss: 1.3870, G loss: 0.7138\n",
      "[244/1762] D loss: 1.3871, G loss: 0.6570\n",
      "[324/1762] D loss: 1.0862, G loss: 1.0534\n",
      "[404/1762] D loss: 1.3712, G loss: 0.7859\n",
      "[484/1762] D loss: 1.0665, G loss: 0.9400\n",
      "[564/1762] D loss: 1.1299, G loss: 0.8001\n",
      "[644/1762] D loss: 1.4027, G loss: 0.7573\n",
      "[724/1762] D loss: 1.4040, G loss: 0.8168\n",
      "[804/1762] D loss: 1.3959, G loss: 0.5566\n",
      "[884/1762] D loss: 1.4032, G loss: 0.6453\n",
      "[964/1762] D loss: 1.4011, G loss: 0.7518\n",
      "[1044/1762] D loss: 1.3476, G loss: 0.6916\n",
      "[1124/1762] D loss: 1.0695, G loss: 0.7186\n",
      "[1204/1762] D loss: 1.4239, G loss: 0.8227\n",
      "[1284/1762] D loss: 1.3222, G loss: 0.7211\n",
      "[1364/1762] D loss: 1.3950, G loss: 0.6603\n",
      "[1444/1762] D loss: 1.4064, G loss: 0.7113\n",
      "[1524/1762] D loss: 1.3908, G loss: 0.7009\n",
      "[1604/1762] D loss: 1.0913, G loss: 0.9924\n",
      "[1684/1762] D loss: 1.0921, G loss: 1.1547\n",
      "[1762/1762] D loss: 1.3579, G loss: 0.6550\n",
      "train error: \n",
      " D loss: 1.305696, G loss: 0.751605, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 81.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.278553, G loss: 0.780405, D accuracy: 55.7%, cell accuracy: 99.7%, board accuracy: 79.1% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3766, G loss: 0.7202\n",
      "[84/1762] D loss: 1.3993, G loss: 0.5814\n",
      "[164/1762] D loss: 1.3930, G loss: 0.5640\n",
      "[244/1762] D loss: 1.4077, G loss: 0.7699\n",
      "[324/1762] D loss: 1.4051, G loss: 0.6038\n",
      "[404/1762] D loss: 0.7748, G loss: 1.4261\n",
      "[484/1762] D loss: 1.1961, G loss: 0.8313\n",
      "[564/1762] D loss: 1.1704, G loss: 0.8311\n",
      "[644/1762] D loss: 1.3908, G loss: 0.6943\n",
      "[724/1762] D loss: 1.3898, G loss: 0.6871\n",
      "[804/1762] D loss: 1.0954, G loss: 0.9268\n",
      "[884/1762] D loss: 1.1615, G loss: 0.7716\n",
      "[964/1762] D loss: 1.3791, G loss: 0.9077\n",
      "[1044/1762] D loss: 1.0820, G loss: 0.9547\n",
      "[1124/1762] D loss: 1.3908, G loss: 0.6557\n",
      "[1204/1762] D loss: 1.3161, G loss: 0.8257\n",
      "[1284/1762] D loss: 1.1059, G loss: 0.8520\n",
      "[1364/1762] D loss: 1.3962, G loss: 0.7679\n",
      "[1444/1762] D loss: 1.3913, G loss: 0.6780\n",
      "[1524/1762] D loss: 1.3900, G loss: 0.7346\n",
      "[1604/1762] D loss: 1.4013, G loss: 0.7358\n",
      "[1684/1762] D loss: 1.3977, G loss: 0.6908\n",
      "[1762/1762] D loss: 1.3914, G loss: 0.6552\n",
      "train error: \n",
      " D loss: 1.298392, G loss: 0.763075, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 88.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.270400, G loss: 0.806395, D accuracy: 56.1%, cell accuracy: 99.8%, board accuracy: 85.5% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3281, G loss: 0.7100\n",
      "[84/1762] D loss: 0.8188, G loss: 1.1539\n",
      "[164/1762] D loss: 1.3902, G loss: 0.7380\n",
      "[244/1762] D loss: 1.3966, G loss: 0.7036\n",
      "[324/1762] D loss: 1.3960, G loss: 0.7708\n",
      "[404/1762] D loss: 1.3894, G loss: 0.7466\n",
      "[484/1762] D loss: 1.0722, G loss: 1.1622\n",
      "[564/1762] D loss: 1.0891, G loss: 1.0365\n",
      "[644/1762] D loss: 1.4064, G loss: 0.6153\n",
      "[724/1762] D loss: 1.3934, G loss: 0.6032\n",
      "[804/1762] D loss: 1.3962, G loss: 0.5874\n",
      "[884/1762] D loss: 1.3912, G loss: 0.7331\n",
      "[964/1762] D loss: 1.0629, G loss: 1.1539\n",
      "[1044/1762] D loss: 1.3878, G loss: 0.7034\n",
      "[1124/1762] D loss: 1.0816, G loss: 0.9971\n",
      "[1204/1762] D loss: 1.3786, G loss: 0.9389\n",
      "[1284/1762] D loss: 1.3982, G loss: 0.7338\n",
      "[1364/1762] D loss: 1.3210, G loss: 0.8687\n",
      "[1444/1762] D loss: 1.4440, G loss: 0.4760\n",
      "[1524/1762] D loss: 1.4147, G loss: 0.6341\n",
      "[1604/1762] D loss: 1.3971, G loss: 0.7607\n",
      "[1684/1762] D loss: 1.1126, G loss: 0.8706\n",
      "[1762/1762] D loss: 1.3856, G loss: 0.6971\n",
      "train error: \n",
      " D loss: 1.291976, G loss: 0.814796, D accuracy: 55.5%, cell accuracy: 99.6%, board accuracy: 74.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.272883, G loss: 0.833129, D accuracy: 56.1%, cell accuracy: 99.5%, board accuracy: 75.2% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3710, G loss: 0.7815\n",
      "[84/1762] D loss: 1.3493, G loss: 0.6657\n",
      "[164/1762] D loss: 1.3454, G loss: 0.7139\n",
      "[244/1762] D loss: 1.0935, G loss: 0.9365\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6742\n",
      "[404/1762] D loss: 1.3868, G loss: 0.7084\n",
      "[484/1762] D loss: 1.3875, G loss: 0.6835\n",
      "[564/1762] D loss: 1.0804, G loss: 1.0289\n",
      "[644/1762] D loss: 1.4017, G loss: 0.5702\n",
      "[724/1762] D loss: 1.3997, G loss: 0.5912\n",
      "[804/1762] D loss: 1.3998, G loss: 0.5969\n",
      "[884/1762] D loss: 1.3911, G loss: 0.7592\n",
      "[964/1762] D loss: 1.3926, G loss: 0.7253\n",
      "[1044/1762] D loss: 1.3982, G loss: 0.8420\n",
      "[1124/1762] D loss: 1.3875, G loss: 0.7318\n",
      "[1204/1762] D loss: 1.3883, G loss: 0.7072\n",
      "[1284/1762] D loss: 1.4033, G loss: 0.7795\n",
      "[1364/1762] D loss: 1.3664, G loss: 0.7117\n",
      "[1444/1762] D loss: 1.3816, G loss: 0.7151\n",
      "[1524/1762] D loss: 1.0689, G loss: 1.0813\n",
      "[1604/1762] D loss: 1.3895, G loss: 0.6381\n",
      "[1684/1762] D loss: 1.3667, G loss: 0.7033\n",
      "[1762/1762] D loss: 1.3905, G loss: 0.6555\n",
      "train error: \n",
      " D loss: 1.294763, G loss: 0.829818, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.268828, G loss: 0.875668, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3867, G loss: 0.7069\n",
      "[84/1762] D loss: 1.3941, G loss: 0.6632\n",
      "[164/1762] D loss: 0.7280, G loss: 1.7147\n",
      "[244/1762] D loss: 1.0598, G loss: 1.2989\n",
      "[324/1762] D loss: 1.3914, G loss: 0.6815\n",
      "[404/1762] D loss: 1.0609, G loss: 1.1709\n",
      "[484/1762] D loss: 1.0573, G loss: 1.2030\n",
      "[564/1762] D loss: 1.3882, G loss: 0.6796\n",
      "[644/1762] D loss: 1.0683, G loss: 1.2691\n",
      "[724/1762] D loss: 1.0812, G loss: 1.0640\n",
      "[804/1762] D loss: 1.3878, G loss: 0.7268\n",
      "[884/1762] D loss: 1.4074, G loss: 0.6672\n",
      "[964/1762] D loss: 1.3657, G loss: 0.7704\n",
      "[1044/1762] D loss: 1.3990, G loss: 0.7436\n",
      "[1124/1762] D loss: 1.0864, G loss: 1.2538\n",
      "[1204/1762] D loss: 1.0574, G loss: 1.2195\n",
      "[1284/1762] D loss: 1.3209, G loss: 0.6798\n",
      "[1364/1762] D loss: 1.0745, G loss: 1.1585\n",
      "[1444/1762] D loss: 1.4125, G loss: 0.7282\n",
      "[1524/1762] D loss: 1.3883, G loss: 0.7201\n",
      "[1604/1762] D loss: 1.3909, G loss: 0.7351\n",
      "[1684/1762] D loss: 1.0437, G loss: 1.1643\n",
      "[1762/1762] D loss: 1.3880, G loss: 0.7138\n",
      "train error: \n",
      " D loss: 1.293841, G loss: 0.840109, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 91.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.266841, G loss: 0.891088, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3885, G loss: 0.7080\n",
      "[84/1762] D loss: 1.3915, G loss: 0.7041\n",
      "[164/1762] D loss: 1.4035, G loss: 0.7221\n",
      "[244/1762] D loss: 1.2029, G loss: 0.8117\n",
      "[324/1762] D loss: 1.0660, G loss: 1.2328\n",
      "[404/1762] D loss: 1.4002, G loss: 0.7000\n",
      "[484/1762] D loss: 1.3979, G loss: 0.5947\n",
      "[564/1762] D loss: 1.0603, G loss: 1.2025\n",
      "[644/1762] D loss: 1.3933, G loss: 0.7148\n",
      "[724/1762] D loss: 1.3947, G loss: 0.7097\n",
      "[804/1762] D loss: 1.0685, G loss: 1.0508\n",
      "[884/1762] D loss: 1.3967, G loss: 0.6416\n",
      "[964/1762] D loss: 1.3880, G loss: 0.7016\n",
      "[1044/1762] D loss: 1.1847, G loss: 1.1206\n",
      "[1124/1762] D loss: 1.0627, G loss: 1.3566\n",
      "[1204/1762] D loss: 1.3874, G loss: 0.7211\n",
      "[1284/1762] D loss: 1.3457, G loss: 0.6847\n",
      "[1364/1762] D loss: 1.3924, G loss: 0.6856\n",
      "[1444/1762] D loss: 1.4544, G loss: 0.7161\n",
      "[1524/1762] D loss: 1.1435, G loss: 1.1504\n",
      "[1604/1762] D loss: 1.4095, G loss: 0.8058\n",
      "[1684/1762] D loss: 1.3897, G loss: 0.6491\n",
      "[1762/1762] D loss: 1.3870, G loss: 0.7120\n",
      "train error: \n",
      " D loss: 1.295740, G loss: 0.888557, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.270757, G loss: 0.921933, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0568, G loss: 1.3170\n",
      "[84/1762] D loss: 1.3912, G loss: 0.6212\n",
      "[164/1762] D loss: 1.3875, G loss: 0.6932\n",
      "[244/1762] D loss: 1.0544, G loss: 1.2935\n",
      "[324/1762] D loss: 1.0678, G loss: 1.1429\n",
      "[404/1762] D loss: 1.3496, G loss: 0.8247\n",
      "[484/1762] D loss: 1.3738, G loss: 0.6855\n",
      "[564/1762] D loss: 1.3828, G loss: 0.6652\n",
      "[644/1762] D loss: 1.3872, G loss: 0.6597\n",
      "[724/1762] D loss: 1.0593, G loss: 1.2834\n",
      "[804/1762] D loss: 1.3952, G loss: 0.7265\n",
      "[884/1762] D loss: 1.2771, G loss: 0.9818\n",
      "[964/1762] D loss: 1.0566, G loss: 1.2511\n",
      "[1044/1762] D loss: 1.0609, G loss: 1.3459\n",
      "[1124/1762] D loss: 1.0506, G loss: 1.2842\n",
      "[1204/1762] D loss: 1.3897, G loss: 0.7191\n",
      "[1284/1762] D loss: 1.3889, G loss: 0.6737\n",
      "[1364/1762] D loss: 1.6372, G loss: 0.5692\n",
      "[1444/1762] D loss: 1.1895, G loss: 0.7853\n",
      "[1524/1762] D loss: 1.2536, G loss: 1.0803\n",
      "[1604/1762] D loss: 1.4903, G loss: 0.4690\n",
      "[1684/1762] D loss: 1.2211, G loss: 0.5757\n",
      "[1762/1762] D loss: 1.7174, G loss: 0.8114\n",
      "train error: \n",
      " D loss: 1.413967, G loss: 0.764412, D accuracy: 50.9%, cell accuracy: 99.8%, board accuracy: 85.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.416960, G loss: 0.764219, D accuracy: 51.2%, cell accuracy: 99.8%, board accuracy: 83.0% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4578, G loss: 0.8526\n",
      "[84/1762] D loss: 1.4196, G loss: 0.6743\n",
      "[164/1762] D loss: 1.3987, G loss: 0.7021\n",
      "[244/1762] D loss: 1.3881, G loss: 0.6702\n",
      "[324/1762] D loss: 1.3888, G loss: 0.7347\n",
      "[404/1762] D loss: 1.3521, G loss: 0.7135\n",
      "[484/1762] D loss: 1.3522, G loss: 0.6912\n",
      "[564/1762] D loss: 1.3890, G loss: 0.7064\n",
      "[644/1762] D loss: 1.3985, G loss: 0.7180\n",
      "[724/1762] D loss: 1.3538, G loss: 0.7180\n",
      "[804/1762] D loss: 1.3836, G loss: 0.7249\n",
      "[884/1762] D loss: 1.3638, G loss: 0.7007\n",
      "[964/1762] D loss: 1.3908, G loss: 0.7304\n",
      "[1044/1762] D loss: 1.1919, G loss: 0.7291\n",
      "[1124/1762] D loss: 1.3904, G loss: 0.6973\n",
      "[1204/1762] D loss: 1.3112, G loss: 0.7062\n",
      "[1284/1762] D loss: 1.3884, G loss: 0.7015\n",
      "[1364/1762] D loss: 1.1926, G loss: 0.7278\n",
      "[1444/1762] D loss: 1.3880, G loss: 0.7241\n",
      "[1524/1762] D loss: 0.9984, G loss: 0.9726\n",
      "[1604/1762] D loss: 1.3829, G loss: 0.7669\n",
      "[1684/1762] D loss: 1.3988, G loss: 0.7832\n",
      "[1762/1762] D loss: 1.3915, G loss: 0.7410\n",
      "train error: \n",
      " D loss: 1.336825, G loss: 0.769435, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 91.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.320808, G loss: 0.770769, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3976, G loss: 0.6331\n",
      "[84/1762] D loss: 1.3960, G loss: 0.6519\n",
      "[164/1762] D loss: 1.3944, G loss: 0.6167\n",
      "[244/1762] D loss: 1.3932, G loss: 0.6702\n",
      "[324/1762] D loss: 1.3945, G loss: 0.6434\n",
      "[404/1762] D loss: 1.3976, G loss: 0.7818\n",
      "[484/1762] D loss: 1.4243, G loss: 0.8293\n",
      "[564/1762] D loss: 1.2514, G loss: 0.6560\n",
      "[644/1762] D loss: 1.4104, G loss: 0.5414\n",
      "[724/1762] D loss: 1.3926, G loss: 0.6291\n",
      "[804/1762] D loss: 1.3882, G loss: 0.6495\n",
      "[884/1762] D loss: 1.3870, G loss: 0.6816\n",
      "[964/1762] D loss: 1.2552, G loss: 0.7239\n",
      "[1044/1762] D loss: 1.3959, G loss: 0.6663\n",
      "[1124/1762] D loss: 1.0234, G loss: 0.8623\n",
      "[1204/1762] D loss: 1.2001, G loss: 0.8171\n",
      "[1284/1762] D loss: 1.4122, G loss: 0.8293\n",
      "[1364/1762] D loss: 1.3930, G loss: 0.7758\n",
      "[1444/1762] D loss: 1.3871, G loss: 0.6400\n",
      "[1524/1762] D loss: 1.3907, G loss: 0.7054\n",
      "[1604/1762] D loss: 0.9470, G loss: 0.8817\n",
      "[1684/1762] D loss: 1.1310, G loss: 0.8323\n",
      "[1762/1762] D loss: 1.3868, G loss: 0.7241\n",
      "train error: \n",
      " D loss: 1.322529, G loss: 0.792143, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.303158, G loss: 0.805617, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3948, G loss: 0.7750\n",
      "[84/1762] D loss: 1.4018, G loss: 0.5966\n",
      "[164/1762] D loss: 1.3927, G loss: 0.7712\n",
      "[244/1762] D loss: 1.3948, G loss: 0.7516\n",
      "[324/1762] D loss: 1.3941, G loss: 0.7006\n",
      "[404/1762] D loss: 1.1192, G loss: 0.9233\n",
      "[484/1762] D loss: 1.3963, G loss: 0.7648\n",
      "[564/1762] D loss: 1.3977, G loss: 0.7049\n",
      "[644/1762] D loss: 1.1283, G loss: 0.8485\n",
      "[724/1762] D loss: 1.4089, G loss: 0.5958\n",
      "[804/1762] D loss: 1.3921, G loss: 0.7209\n",
      "[884/1762] D loss: 1.4355, G loss: 0.6443\n",
      "[964/1762] D loss: 1.3821, G loss: 0.8287\n",
      "[1044/1762] D loss: 1.0881, G loss: 0.8704\n",
      "[1124/1762] D loss: 1.3911, G loss: 0.6973\n",
      "[1204/1762] D loss: 1.3908, G loss: 0.6714\n",
      "[1284/1762] D loss: 1.3956, G loss: 0.6471\n",
      "[1364/1762] D loss: 1.3944, G loss: 0.6694\n",
      "[1444/1762] D loss: 1.4135, G loss: 0.8174\n",
      "[1524/1762] D loss: 1.4111, G loss: 0.6610\n",
      "[1604/1762] D loss: 0.7570, G loss: 1.7056\n",
      "[1684/1762] D loss: 1.4053, G loss: 0.6135\n",
      "[1762/1762] D loss: 1.4038, G loss: 0.7961\n",
      "train error: \n",
      " D loss: 1.309243, G loss: 0.909581, D accuracy: 53.8%, cell accuracy: 99.7%, board accuracy: 81.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.287526, G loss: 0.931090, D accuracy: 54.9%, cell accuracy: 99.7%, board accuracy: 80.7% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3518, G loss: 0.7905\n",
      "[84/1762] D loss: 1.3942, G loss: 0.6735\n",
      "[164/1762] D loss: 1.1273, G loss: 0.8271\n",
      "[244/1762] D loss: 1.3747, G loss: 0.7049\n",
      "[324/1762] D loss: 1.2865, G loss: 0.7038\n",
      "[404/1762] D loss: 1.3871, G loss: 0.6694\n",
      "[484/1762] D loss: 1.3899, G loss: 0.7481\n",
      "[564/1762] D loss: 1.3857, G loss: 0.6961\n",
      "[644/1762] D loss: 1.3710, G loss: 0.7374\n",
      "[724/1762] D loss: 1.3876, G loss: 0.6862\n",
      "[804/1762] D loss: 1.3958, G loss: 0.6424\n",
      "[884/1762] D loss: 1.2026, G loss: 0.8225\n",
      "[964/1762] D loss: 1.3883, G loss: 0.6642\n",
      "[1044/1762] D loss: 1.3974, G loss: 0.7440\n",
      "[1124/1762] D loss: 1.0856, G loss: 1.0250\n",
      "[1204/1762] D loss: 1.3912, G loss: 0.6289\n",
      "[1284/1762] D loss: 1.1040, G loss: 0.9356\n",
      "[1364/1762] D loss: 1.3899, G loss: 0.6891\n",
      "[1444/1762] D loss: 1.0757, G loss: 1.0962\n",
      "[1524/1762] D loss: 1.2998, G loss: 0.9300\n",
      "[1604/1762] D loss: 1.3780, G loss: 0.6971\n",
      "[1684/1762] D loss: 1.4253, G loss: 0.5371\n",
      "[1762/1762] D loss: 1.4143, G loss: 0.8124\n",
      "train error: \n",
      " D loss: 1.305029, G loss: 0.858179, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 90.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.283019, G loss: 0.885259, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3895, G loss: 0.6869\n",
      "[84/1762] D loss: 0.7901, G loss: 1.3004\n",
      "[164/1762] D loss: 0.7640, G loss: 1.7220\n",
      "[244/1762] D loss: 1.4083, G loss: 0.5686\n",
      "[324/1762] D loss: 1.4083, G loss: 0.7928\n",
      "[404/1762] D loss: 1.4008, G loss: 1.0995\n",
      "[484/1762] D loss: 0.9491, G loss: 1.0564\n",
      "[564/1762] D loss: 1.3728, G loss: 0.9317\n",
      "[644/1762] D loss: 1.0708, G loss: 0.9206\n",
      "[724/1762] D loss: 1.2215, G loss: 1.1114\n",
      "[804/1762] D loss: 1.3276, G loss: 0.8663\n",
      "[884/1762] D loss: 1.3877, G loss: 0.7187\n",
      "[964/1762] D loss: 1.3928, G loss: 0.6681\n",
      "[1044/1762] D loss: 1.3916, G loss: 0.6577\n",
      "[1124/1762] D loss: 1.3950, G loss: 0.7946\n",
      "[1204/1762] D loss: 1.2984, G loss: 0.7815\n",
      "[1284/1762] D loss: 1.3944, G loss: 0.6962\n",
      "[1364/1762] D loss: 1.2147, G loss: 0.8678\n",
      "[1444/1762] D loss: 1.4006, G loss: 0.5987\n",
      "[1524/1762] D loss: 1.3951, G loss: 0.7437\n",
      "[1604/1762] D loss: 1.3859, G loss: 0.6668\n",
      "[1684/1762] D loss: 1.3901, G loss: 0.6884\n",
      "[1762/1762] D loss: 0.7604, G loss: 1.8164\n",
      "train error: \n",
      " D loss: 1.282213, G loss: 1.126437, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 82.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.257089, G loss: 1.174538, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 81.4% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3936, G loss: 0.7406\n",
      "[84/1762] D loss: 1.0595, G loss: 1.2355\n",
      "[164/1762] D loss: 1.3895, G loss: 0.6840\n",
      "[244/1762] D loss: 1.0304, G loss: 1.3970\n",
      "[324/1762] D loss: 1.3948, G loss: 0.7690\n",
      "[404/1762] D loss: 1.3891, G loss: 0.6665\n",
      "[484/1762] D loss: 1.3900, G loss: 0.7126\n",
      "[564/1762] D loss: 1.3877, G loss: 0.7196\n",
      "[644/1762] D loss: 1.3889, G loss: 0.6509\n",
      "[724/1762] D loss: 1.3906, G loss: 0.6872\n",
      "[804/1762] D loss: 1.0637, G loss: 1.3002\n",
      "[884/1762] D loss: 1.3930, G loss: 0.7391\n",
      "[964/1762] D loss: 1.3160, G loss: 1.0412\n",
      "[1044/1762] D loss: 1.4074, G loss: 0.5991\n",
      "[1124/1762] D loss: 1.7270, G loss: 0.5733\n",
      "[1204/1762] D loss: 1.3942, G loss: 0.6237\n",
      "[1284/1762] D loss: 1.3890, G loss: 0.6661\n",
      "[1364/1762] D loss: 1.3646, G loss: 0.8053\n",
      "[1444/1762] D loss: 1.3910, G loss: 0.7302\n",
      "[1524/1762] D loss: 1.2505, G loss: 0.9216\n",
      "[1604/1762] D loss: 1.3917, G loss: 0.7068\n",
      "[1684/1762] D loss: 1.3947, G loss: 0.7245\n",
      "[1762/1762] D loss: 1.3886, G loss: 0.7477\n",
      "train error: \n",
      " D loss: 1.327681, G loss: 0.765051, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.316603, G loss: 0.772292, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3933, G loss: 0.7755\n",
      "[84/1762] D loss: 1.4184, G loss: 0.6850\n",
      "[164/1762] D loss: 1.3906, G loss: 0.7085\n",
      "[244/1762] D loss: 1.3928, G loss: 0.7627\n",
      "[324/1762] D loss: 1.3868, G loss: 0.6879\n",
      "[404/1762] D loss: 0.7570, G loss: 1.4984\n",
      "[484/1762] D loss: 1.3993, G loss: 0.7870\n",
      "[564/1762] D loss: 1.4356, G loss: 0.8117\n",
      "[644/1762] D loss: 1.3747, G loss: 0.6321\n",
      "[724/1762] D loss: 1.4038, G loss: 0.5921\n",
      "[804/1762] D loss: 1.2876, G loss: 0.8689\n",
      "[884/1762] D loss: 2.4702, G loss: 0.3649\n",
      "[964/1762] D loss: 1.3694, G loss: 0.5903\n",
      "[1044/1762] D loss: 1.3572, G loss: 0.7190\n",
      "[1124/1762] D loss: 1.3561, G loss: 0.7107\n",
      "[1204/1762] D loss: 1.3880, G loss: 0.7246\n",
      "[1284/1762] D loss: 1.3390, G loss: 0.7522\n",
      "[1364/1762] D loss: 1.3878, G loss: 0.6950\n",
      "[1444/1762] D loss: 1.3942, G loss: 0.7529\n",
      "[1524/1762] D loss: 1.4042, G loss: 0.7443\n",
      "[1604/1762] D loss: 1.3994, G loss: 0.7656\n",
      "[1684/1762] D loss: 1.3900, G loss: 0.7455\n",
      "[1762/1762] D loss: 1.3995, G loss: 0.8059\n",
      "train error: \n",
      " D loss: 1.316388, G loss: 0.858381, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 91.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.297424, G loss: 0.882152, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0924, G loss: 1.0514\n",
      "[84/1762] D loss: 1.3862, G loss: 0.6955\n",
      "[164/1762] D loss: 1.3871, G loss: 0.6913\n",
      "[244/1762] D loss: 1.0902, G loss: 1.0944\n",
      "[324/1762] D loss: 1.3974, G loss: 0.6715\n",
      "[404/1762] D loss: 1.0680, G loss: 1.0944\n",
      "[484/1762] D loss: 1.3882, G loss: 0.6735\n",
      "[564/1762] D loss: 1.0709, G loss: 1.1292\n",
      "[644/1762] D loss: 1.3877, G loss: 0.6913\n",
      "[724/1762] D loss: 1.3896, G loss: 0.7542\n",
      "[804/1762] D loss: 1.3885, G loss: 0.7327\n",
      "[884/1762] D loss: 1.0618, G loss: 1.3231\n",
      "[964/1762] D loss: 1.0528, G loss: 1.3138\n",
      "[1044/1762] D loss: 1.0612, G loss: 1.3461\n",
      "[1124/1762] D loss: 1.3957, G loss: 0.7118\n",
      "[1204/1762] D loss: 1.3916, G loss: 0.6702\n",
      "[1284/1762] D loss: 1.3415, G loss: 0.7561\n",
      "[1364/1762] D loss: 1.2117, G loss: 1.3532\n",
      "[1444/1762] D loss: 1.3892, G loss: 0.6500\n",
      "[1524/1762] D loss: 1.3959, G loss: 0.7428\n",
      "[1604/1762] D loss: 1.4072, G loss: 0.7668\n",
      "[1684/1762] D loss: 1.0548, G loss: 1.2741\n",
      "[1762/1762] D loss: 1.3102, G loss: 0.7124\n",
      "train error: \n",
      " D loss: 1.280101, G loss: 0.887862, D accuracy: 68.1%, cell accuracy: 98.4%, board accuracy: 32.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.282683, G loss: 0.916324, D accuracy: 68.6%, cell accuracy: 98.3%, board accuracy: 32.7% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3052, G loss: 0.7573\n",
      "[84/1762] D loss: 1.4612, G loss: 0.6597\n",
      "[164/1762] D loss: 1.3867, G loss: 0.6910\n",
      "[244/1762] D loss: 1.3883, G loss: 0.7061\n",
      "[324/1762] D loss: 1.3871, G loss: 0.6908\n",
      "[404/1762] D loss: 1.3941, G loss: 0.8070\n",
      "[484/1762] D loss: 1.3875, G loss: 0.7198\n",
      "[564/1762] D loss: 1.3880, G loss: 0.7121\n",
      "[644/1762] D loss: 1.3838, G loss: 0.7213\n",
      "[724/1762] D loss: 1.3884, G loss: 0.7211\n",
      "[804/1762] D loss: 1.3923, G loss: 0.6501\n",
      "[884/1762] D loss: 1.3874, G loss: 0.6909\n",
      "[964/1762] D loss: 1.2073, G loss: 0.8134\n",
      "[1044/1762] D loss: 1.4112, G loss: 0.6087\n",
      "[1124/1762] D loss: 1.3883, G loss: 0.6650\n",
      "[1204/1762] D loss: 1.3870, G loss: 0.7028\n",
      "[1284/1762] D loss: 1.4012, G loss: 0.6604\n",
      "[1364/1762] D loss: 1.3803, G loss: 0.6598\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.7197\n",
      "[1524/1762] D loss: 1.3647, G loss: 0.7304\n",
      "[1604/1762] D loss: 1.2005, G loss: 0.8105\n",
      "[1684/1762] D loss: 1.3880, G loss: 0.7236\n",
      "[1762/1762] D loss: 1.3015, G loss: 0.8031\n",
      "train error: \n",
      " D loss: 1.323786, G loss: 0.776561, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 83.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.308665, G loss: 0.813169, D accuracy: 54.2%, cell accuracy: 99.7%, board accuracy: 79.8% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3337, G loss: 0.7600\n",
      "[84/1762] D loss: 1.3549, G loss: 0.6748\n",
      "[164/1762] D loss: 1.1569, G loss: 0.9673\n",
      "[244/1762] D loss: 1.3897, G loss: 0.6798\n",
      "[324/1762] D loss: 1.3880, G loss: 0.7234\n",
      "[404/1762] D loss: 1.5171, G loss: 0.5904\n",
      "[484/1762] D loss: 1.4380, G loss: 0.8724\n",
      "[564/1762] D loss: 1.3666, G loss: 0.8456\n",
      "[644/1762] D loss: 1.1635, G loss: 1.1242\n",
      "[724/1762] D loss: 1.3682, G loss: 0.7299\n",
      "[804/1762] D loss: 1.3454, G loss: 0.7767\n",
      "[884/1762] D loss: 1.1514, G loss: 0.8410\n",
      "[964/1762] D loss: 1.4298, G loss: 0.5085\n",
      "[1044/1762] D loss: 1.3987, G loss: 0.6223\n",
      "[1124/1762] D loss: 1.3862, G loss: 0.6820\n",
      "[1204/1762] D loss: 1.1114, G loss: 1.1454\n",
      "[1284/1762] D loss: 1.3951, G loss: 0.7175\n",
      "[1364/1762] D loss: 1.3883, G loss: 0.6774\n",
      "[1444/1762] D loss: 1.3933, G loss: 0.6458\n",
      "[1524/1762] D loss: 1.3887, G loss: 0.6648\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6899\n",
      "[1684/1762] D loss: 1.3896, G loss: 0.7032\n",
      "[1762/1762] D loss: 1.3877, G loss: 0.6932\n",
      "train error: \n",
      " D loss: 1.297133, G loss: 0.872458, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 90.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.267937, G loss: 0.930354, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0601, G loss: 1.2806\n",
      "[84/1762] D loss: 1.3542, G loss: 0.6428\n",
      "[164/1762] D loss: 1.3881, G loss: 0.6791\n",
      "[244/1762] D loss: 1.3866, G loss: 0.6851\n",
      "[324/1762] D loss: 1.3876, G loss: 0.6644\n",
      "[404/1762] D loss: 1.0617, G loss: 1.3515\n",
      "[484/1762] D loss: 1.3933, G loss: 0.6759\n",
      "[564/1762] D loss: 1.3859, G loss: 0.7283\n",
      "[644/1762] D loss: 1.0514, G loss: 1.3775\n",
      "[724/1762] D loss: 1.3876, G loss: 0.7273\n",
      "[804/1762] D loss: 1.0540, G loss: 1.4082\n",
      "[884/1762] D loss: 1.3886, G loss: 0.7200\n",
      "[964/1762] D loss: 1.0475, G loss: 1.6102\n",
      "[1044/1762] D loss: 1.4914, G loss: 0.9963\n",
      "[1124/1762] D loss: 1.3881, G loss: 0.7343\n",
      "[1204/1762] D loss: 0.7237, G loss: 1.9819\n",
      "[1284/1762] D loss: 1.3869, G loss: 0.6902\n",
      "[1364/1762] D loss: 1.0773, G loss: 1.5066\n",
      "[1444/1762] D loss: 1.3982, G loss: 0.6715\n",
      "[1524/1762] D loss: 1.3865, G loss: 0.6864\n",
      "[1604/1762] D loss: 0.7110, G loss: 2.1989\n",
      "[1684/1762] D loss: 1.3902, G loss: 0.6642\n",
      "[1762/1762] D loss: 1.0450, G loss: 1.8878\n",
      "train error: \n",
      " D loss: 1.310413, G loss: 0.847925, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.281768, G loss: 0.894913, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0589, G loss: 1.3553\n",
      "[84/1762] D loss: 0.6758, G loss: 2.2714\n",
      "[164/1762] D loss: 1.1656, G loss: 0.9283\n",
      "[244/1762] D loss: 1.2437, G loss: 1.6480\n",
      "[324/1762] D loss: 1.3891, G loss: 0.6557\n",
      "[404/1762] D loss: 1.3893, G loss: 0.6718\n",
      "[484/1762] D loss: 1.0642, G loss: 1.4973\n",
      "[564/1762] D loss: 1.3298, G loss: 0.7902\n",
      "[644/1762] D loss: 1.2862, G loss: 1.0335\n",
      "[724/1762] D loss: 1.2543, G loss: 0.7937\n",
      "[804/1762] D loss: 1.3894, G loss: 0.6718\n",
      "[884/1762] D loss: 1.3902, G loss: 0.7039\n",
      "[964/1762] D loss: 1.3612, G loss: 0.7550\n",
      "[1044/1762] D loss: 1.3873, G loss: 0.6977\n",
      "[1124/1762] D loss: 0.9965, G loss: 1.4262\n",
      "[1204/1762] D loss: 1.0580, G loss: 1.1915\n",
      "[1284/1762] D loss: 1.1996, G loss: 1.0079\n",
      "[1364/1762] D loss: 1.3915, G loss: 0.8116\n",
      "[1444/1762] D loss: 1.3969, G loss: 0.6085\n",
      "[1524/1762] D loss: 1.3840, G loss: 0.7034\n",
      "[1604/1762] D loss: 1.0526, G loss: 1.3791\n",
      "[1684/1762] D loss: 1.3944, G loss: 0.6091\n",
      "[1762/1762] D loss: 1.3874, G loss: 0.7196\n",
      "train error: \n",
      " D loss: 1.290373, G loss: 0.902669, D accuracy: 54.1%, cell accuracy: 99.9%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.262898, G loss: 0.963170, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3869, G loss: 0.6688\n",
      "[84/1762] D loss: 1.3883, G loss: 0.6831\n",
      "[164/1762] D loss: 1.3882, G loss: 0.7108\n",
      "[244/1762] D loss: 1.3867, G loss: 0.7002\n",
      "[324/1762] D loss: 1.0460, G loss: 1.4713\n",
      "[404/1762] D loss: 1.3153, G loss: 0.7769\n",
      "[484/1762] D loss: 1.0497, G loss: 1.3497\n",
      "[564/1762] D loss: 1.3869, G loss: 0.6997\n",
      "[644/1762] D loss: 1.0562, G loss: 1.4687\n",
      "[724/1762] D loss: 1.3870, G loss: 0.6742\n",
      "[804/1762] D loss: 1.3870, G loss: 0.7247\n",
      "[884/1762] D loss: 1.3881, G loss: 0.6675\n",
      "[964/1762] D loss: 1.3883, G loss: 0.6721\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.6841\n",
      "[1124/1762] D loss: 1.3866, G loss: 0.6922\n",
      "[1204/1762] D loss: 1.0417, G loss: 1.7866\n",
      "[1284/1762] D loss: 1.3843, G loss: 0.7346\n",
      "[1364/1762] D loss: 1.3896, G loss: 0.6803\n",
      "[1444/1762] D loss: 1.3866, G loss: 0.7056\n",
      "[1524/1762] D loss: 0.7009, G loss: 2.4547\n",
      "[1604/1762] D loss: 1.3880, G loss: 0.6781\n",
      "[1684/1762] D loss: 1.0453, G loss: 1.4888\n",
      "[1762/1762] D loss: 1.3875, G loss: 0.6621\n",
      "train error: \n",
      " D loss: 1.285855, G loss: 0.952164, D accuracy: 54.0%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.256270, G loss: 1.042043, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3880, G loss: 0.7057\n",
      "[84/1762] D loss: 1.3878, G loss: 0.7037\n",
      "[164/1762] D loss: 1.0445, G loss: 1.5488\n",
      "[244/1762] D loss: 1.3889, G loss: 0.6485\n",
      "[324/1762] D loss: 1.0439, G loss: 1.5684\n",
      "[404/1762] D loss: 1.3869, G loss: 0.7088\n",
      "[484/1762] D loss: 1.3865, G loss: 0.6879\n",
      "[564/1762] D loss: 1.0429, G loss: 1.6255\n",
      "[644/1762] D loss: 1.3875, G loss: 0.6948\n",
      "[724/1762] D loss: 1.3871, G loss: 0.7013\n",
      "[804/1762] D loss: 1.3870, G loss: 0.6762\n",
      "[884/1762] D loss: 1.3880, G loss: 0.6577\n",
      "[964/1762] D loss: 0.8696, G loss: 2.6428\n",
      "[1044/1762] D loss: 1.3869, G loss: 0.7055\n",
      "[1124/1762] D loss: 1.3921, G loss: 0.7027\n",
      "[1204/1762] D loss: 1.3870, G loss: 0.7032\n",
      "[1284/1762] D loss: 1.3881, G loss: 0.6716\n",
      "[1364/1762] D loss: 1.3858, G loss: 0.6981\n",
      "[1444/1762] D loss: 1.3911, G loss: 0.6512\n",
      "[1524/1762] D loss: 1.3059, G loss: 0.8102\n",
      "[1604/1762] D loss: 1.3865, G loss: 0.6808\n",
      "[1684/1762] D loss: 1.3933, G loss: 0.7270\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.6843\n",
      "train error: \n",
      " D loss: 1.292824, G loss: 0.920107, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.257919, G loss: 1.005298, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3865, G loss: 0.6834\n",
      "[84/1762] D loss: 1.3869, G loss: 0.6980\n",
      "[164/1762] D loss: 1.3875, G loss: 0.7043\n",
      "[244/1762] D loss: 1.3866, G loss: 0.7080\n",
      "[324/1762] D loss: 1.0430, G loss: 1.6291\n",
      "[404/1762] D loss: 1.3871, G loss: 0.7123\n",
      "[484/1762] D loss: 1.4199, G loss: 0.7697\n",
      "[564/1762] D loss: 1.0839, G loss: 1.5354\n",
      "[644/1762] D loss: 1.4017, G loss: 0.5399\n",
      "[724/1762] D loss: 1.3920, G loss: 0.7112\n",
      "[804/1762] D loss: 1.3880, G loss: 0.6995\n",
      "[884/1762] D loss: 0.7085, G loss: 2.3370\n",
      "[964/1762] D loss: 1.3871, G loss: 0.6782\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.6893\n",
      "[1124/1762] D loss: 0.7073, G loss: 2.1209\n",
      "[1204/1762] D loss: 1.3968, G loss: 0.7426\n",
      "[1284/1762] D loss: 1.0429, G loss: 1.6562\n",
      "[1364/1762] D loss: 1.3977, G loss: 0.7216\n",
      "[1444/1762] D loss: 1.0479, G loss: 1.4310\n",
      "[1524/1762] D loss: 1.3897, G loss: 0.6372\n",
      "[1604/1762] D loss: 1.2248, G loss: 1.2267\n",
      "[1684/1762] D loss: 1.3880, G loss: 0.7418\n",
      "[1762/1762] D loss: 1.4225, G loss: 0.8910\n",
      "train error: \n",
      " D loss: 1.297000, G loss: 1.034448, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.277163, G loss: 1.094654, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4037, G loss: 0.7911\n",
      "[84/1762] D loss: 1.0514, G loss: 1.3411\n",
      "[164/1762] D loss: 1.3873, G loss: 0.6902\n",
      "[244/1762] D loss: 1.3864, G loss: 0.6780\n",
      "[324/1762] D loss: 1.3864, G loss: 0.6698\n",
      "[404/1762] D loss: 1.3959, G loss: 0.6351\n",
      "[484/1762] D loss: 1.3873, G loss: 0.7071\n",
      "[564/1762] D loss: 1.0436, G loss: 1.5949\n",
      "[644/1762] D loss: 1.3864, G loss: 0.7002\n",
      "[724/1762] D loss: 1.3866, G loss: 0.6965\n",
      "[804/1762] D loss: 1.3486, G loss: 0.7584\n",
      "[884/1762] D loss: 1.3996, G loss: 0.7478\n",
      "[964/1762] D loss: 1.3916, G loss: 0.6876\n",
      "[1044/1762] D loss: 1.3904, G loss: 0.6608\n",
      "[1124/1762] D loss: 1.3804, G loss: 0.6925\n",
      "[1204/1762] D loss: 1.3921, G loss: 0.6516\n",
      "[1284/1762] D loss: 1.0464, G loss: 1.4957\n",
      "[1364/1762] D loss: 1.3975, G loss: 0.7709\n",
      "[1444/1762] D loss: 1.3336, G loss: 0.8085\n",
      "[1524/1762] D loss: 1.0431, G loss: 1.7399\n",
      "[1604/1762] D loss: 1.0466, G loss: 1.6380\n",
      "[1684/1762] D loss: 1.3867, G loss: 0.6828\n",
      "[1762/1762] D loss: 1.3911, G loss: 0.6360\n",
      "train error: \n",
      " D loss: 1.290657, G loss: 0.876858, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 90.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.260986, G loss: 0.964725, D accuracy: 55.7%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0544, G loss: 1.4121\n",
      "[84/1762] D loss: 1.4084, G loss: 0.5997\n",
      "[164/1762] D loss: 1.3880, G loss: 0.6695\n",
      "[244/1762] D loss: 1.0516, G loss: 1.6496\n",
      "[324/1762] D loss: 1.3890, G loss: 0.6658\n",
      "[404/1762] D loss: 1.0508, G loss: 1.4869\n",
      "[484/1762] D loss: 1.3950, G loss: 0.6707\n",
      "[564/1762] D loss: 1.3903, G loss: 0.6996\n",
      "[644/1762] D loss: 1.3872, G loss: 0.6649\n",
      "[724/1762] D loss: 1.3893, G loss: 0.6635\n",
      "[804/1762] D loss: 1.3868, G loss: 0.6915\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6919\n",
      "[964/1762] D loss: 1.3870, G loss: 0.6995\n",
      "[1044/1762] D loss: 1.3870, G loss: 0.6896\n",
      "[1124/1762] D loss: 1.0472, G loss: 1.4528\n",
      "[1204/1762] D loss: 1.3905, G loss: 0.6630\n",
      "[1284/1762] D loss: 1.3870, G loss: 0.6804\n",
      "[1364/1762] D loss: 1.2630, G loss: 1.1270\n",
      "[1444/1762] D loss: 1.3978, G loss: 0.6524\n",
      "[1524/1762] D loss: 1.4265, G loss: 0.5624\n",
      "[1604/1762] D loss: 1.0567, G loss: 1.2299\n",
      "[1684/1762] D loss: 1.3989, G loss: 0.7137\n",
      "[1762/1762] D loss: 1.3886, G loss: 0.7028\n",
      "train error: \n",
      " D loss: 1.294497, G loss: 0.849413, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.263704, G loss: 0.926441, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3882, G loss: 0.6723\n",
      "[84/1762] D loss: 1.0451, G loss: 1.8377\n",
      "[164/1762] D loss: 1.7518, G loss: 1.1630\n",
      "[244/1762] D loss: 1.3855, G loss: 0.6222\n",
      "[324/1762] D loss: 1.0537, G loss: 1.2858\n",
      "[404/1762] D loss: 1.3868, G loss: 0.6702\n",
      "[484/1762] D loss: 0.7637, G loss: 1.5982\n",
      "[564/1762] D loss: 1.2506, G loss: 1.1079\n",
      "[644/1762] D loss: 1.0510, G loss: 1.4249\n",
      "[724/1762] D loss: 1.3900, G loss: 0.6388\n",
      "[804/1762] D loss: 1.3885, G loss: 0.6677\n",
      "[884/1762] D loss: 1.3892, G loss: 0.6638\n",
      "[964/1762] D loss: 1.0514, G loss: 1.3480\n",
      "[1044/1762] D loss: 1.3880, G loss: 0.7271\n",
      "[1124/1762] D loss: 1.1136, G loss: 1.3480\n",
      "[1204/1762] D loss: 1.3870, G loss: 0.6861\n",
      "[1284/1762] D loss: 1.3889, G loss: 0.6934\n",
      "[1364/1762] D loss: 1.3867, G loss: 0.6809\n",
      "[1444/1762] D loss: 1.3877, G loss: 0.7059\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.6951\n",
      "[1604/1762] D loss: 1.3903, G loss: 0.6612\n",
      "[1684/1762] D loss: 1.3874, G loss: 0.6836\n",
      "[1762/1762] D loss: 0.7020, G loss: 2.4896\n",
      "train error: \n",
      " D loss: 1.287726, G loss: 0.968976, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.259796, G loss: 1.048911, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6894\n",
      "[84/1762] D loss: 1.3885, G loss: 0.6666\n",
      "[164/1762] D loss: 1.0434, G loss: 1.6645\n",
      "[244/1762] D loss: 1.3883, G loss: 0.6613\n",
      "[324/1762] D loss: 1.3879, G loss: 0.6935\n",
      "[404/1762] D loss: 1.4033, G loss: 0.6434\n",
      "[484/1762] D loss: 3.0681, G loss: 0.5337\n",
      "[564/1762] D loss: 1.4906, G loss: 0.6213\n",
      "[644/1762] D loss: 1.3889, G loss: 0.6831\n",
      "[724/1762] D loss: 1.3930, G loss: 0.6989\n",
      "[804/1762] D loss: 1.3873, G loss: 0.6564\n",
      "[884/1762] D loss: 1.3871, G loss: 0.6913\n",
      "[964/1762] D loss: 1.0443, G loss: 1.8836\n",
      "[1044/1762] D loss: 1.3875, G loss: 0.6723\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.6956\n",
      "[1204/1762] D loss: 1.3892, G loss: 0.6641\n",
      "[1284/1762] D loss: 1.3923, G loss: 0.7392\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6989\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6979\n",
      "[1524/1762] D loss: 1.3883, G loss: 0.6579\n",
      "[1604/1762] D loss: 1.3886, G loss: 0.7287\n",
      "[1684/1762] D loss: 1.0450, G loss: 1.5555\n",
      "[1762/1762] D loss: 1.3828, G loss: 0.6564\n",
      "train error: \n",
      " D loss: 1.284392, G loss: 0.966944, D accuracy: 55.2%, cell accuracy: 99.7%, board accuracy: 65.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.256739, G loss: 1.034219, D accuracy: 56.9%, cell accuracy: 99.7%, board accuracy: 60.5% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3870, G loss: 0.6921\n",
      "[84/1762] D loss: 1.3877, G loss: 0.6548\n",
      "[164/1762] D loss: 1.3873, G loss: 0.6994\n",
      "[244/1762] D loss: 1.1756, G loss: 1.5496\n",
      "[324/1762] D loss: 1.3946, G loss: 0.6154\n",
      "[404/1762] D loss: 0.7231, G loss: 2.5281\n",
      "[484/1762] D loss: 1.3884, G loss: 0.7098\n",
      "[564/1762] D loss: 1.3862, G loss: 0.6972\n",
      "[644/1762] D loss: 1.3907, G loss: 0.6835\n",
      "[724/1762] D loss: 1.3892, G loss: 0.6548\n",
      "[804/1762] D loss: 1.2637, G loss: 1.6298\n",
      "[884/1762] D loss: 1.3445, G loss: 0.7296\n",
      "[964/1762] D loss: 1.4064, G loss: 0.8382\n",
      "[1044/1762] D loss: 1.3589, G loss: 0.6613\n",
      "[1124/1762] D loss: 1.4050, G loss: 0.5635\n",
      "[1204/1762] D loss: 1.4034, G loss: 0.6133\n",
      "[1284/1762] D loss: 1.1561, G loss: 0.9131\n",
      "[1364/1762] D loss: 1.3033, G loss: 0.7580\n",
      "[1444/1762] D loss: 1.3511, G loss: 0.7086\n",
      "[1524/1762] D loss: 1.3959, G loss: 0.6016\n",
      "[1604/1762] D loss: 1.3144, G loss: 0.7394\n",
      "[1684/1762] D loss: 1.1983, G loss: 0.9650\n",
      "[1762/1762] D loss: 1.4071, G loss: 0.8375\n",
      "train error: \n",
      " D loss: 1.302421, G loss: 0.827283, D accuracy: 56.6%, cell accuracy: 99.8%, board accuracy: 83.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.282993, G loss: 0.861999, D accuracy: 57.2%, cell accuracy: 99.7%, board accuracy: 80.5% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2291, G loss: 0.8789\n",
      "[84/1762] D loss: 1.3877, G loss: 0.7258\n",
      "[164/1762] D loss: 1.3970, G loss: 0.6016\n",
      "[244/1762] D loss: 1.4014, G loss: 0.7921\n",
      "[324/1762] D loss: 1.5938, G loss: 1.7977\n",
      "[404/1762] D loss: 1.0460, G loss: 1.7325\n",
      "[484/1762] D loss: 1.0659, G loss: 0.9633\n",
      "[564/1762] D loss: 1.5412, G loss: 1.0700\n",
      "[644/1762] D loss: 1.3899, G loss: 0.7381\n",
      "[724/1762] D loss: 1.3155, G loss: 1.4731\n",
      "[804/1762] D loss: 1.1961, G loss: 1.4341\n",
      "[884/1762] D loss: 1.2691, G loss: 0.9581\n",
      "[964/1762] D loss: 1.3879, G loss: 0.7288\n",
      "[1044/1762] D loss: 1.0682, G loss: 1.2570\n",
      "[1124/1762] D loss: 1.3872, G loss: 0.6730\n",
      "[1204/1762] D loss: 1.3939, G loss: 0.6492\n",
      "[1284/1762] D loss: 1.3912, G loss: 0.6544\n",
      "[1364/1762] D loss: 1.0580, G loss: 1.8902\n",
      "[1444/1762] D loss: 1.2773, G loss: 0.7888\n",
      "[1524/1762] D loss: 1.5778, G loss: 0.6308\n",
      "[1604/1762] D loss: 1.3894, G loss: 0.6480\n",
      "[1684/1762] D loss: 1.3889, G loss: 0.6804\n",
      "[1762/1762] D loss: 0.7274, G loss: 3.2109\n",
      "train error: \n",
      " D loss: 1.307800, G loss: 0.800128, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.302435, G loss: 0.836111, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 85.2% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0693, G loss: 1.3338\n",
      "[84/1762] D loss: 1.1102, G loss: 2.8517\n",
      "[164/1762] D loss: 1.3896, G loss: 0.6703\n",
      "[244/1762] D loss: 1.3900, G loss: 0.6994\n",
      "[324/1762] D loss: 1.3972, G loss: 0.6174\n",
      "[404/1762] D loss: 0.9206, G loss: 1.5858\n",
      "[484/1762] D loss: 1.0722, G loss: 1.3681\n",
      "[564/1762] D loss: 1.0882, G loss: 0.9997\n",
      "[644/1762] D loss: 1.3870, G loss: 0.6707\n",
      "[724/1762] D loss: 1.0549, G loss: 1.2824\n",
      "[804/1762] D loss: 1.3156, G loss: 0.7799\n",
      "[884/1762] D loss: 1.0728, G loss: 1.0964\n",
      "[964/1762] D loss: 0.4113, G loss: 2.5488\n",
      "[1044/1762] D loss: 0.7336, G loss: 1.9518\n",
      "[1124/1762] D loss: 1.3906, G loss: 0.6874\n",
      "[1204/1762] D loss: 1.3583, G loss: 0.6745\n",
      "[1284/1762] D loss: 1.3882, G loss: 0.6925\n",
      "[1364/1762] D loss: 1.3897, G loss: 0.6786\n",
      "[1444/1762] D loss: 1.3813, G loss: 0.6627\n",
      "[1524/1762] D loss: 1.3937, G loss: 0.7133\n",
      "[1604/1762] D loss: 1.3910, G loss: 0.7411\n",
      "[1684/1762] D loss: 1.3896, G loss: 0.6881\n",
      "[1762/1762] D loss: 1.4240, G loss: 0.7743\n",
      "train error: \n",
      " D loss: 1.313319, G loss: 1.059821, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.310441, G loss: 1.107751, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3937, G loss: 0.7668\n",
      "[84/1762] D loss: 1.3872, G loss: 0.6722\n",
      "[164/1762] D loss: 1.0583, G loss: 1.4163\n",
      "[244/1762] D loss: 1.3883, G loss: 0.7324\n",
      "[324/1762] D loss: 1.3876, G loss: 0.6898\n",
      "[404/1762] D loss: 1.3877, G loss: 0.7265\n",
      "[484/1762] D loss: 1.0994, G loss: 1.4927\n",
      "[564/1762] D loss: 1.0621, G loss: 1.3987\n",
      "[644/1762] D loss: 1.3894, G loss: 0.7313\n",
      "[724/1762] D loss: 1.3884, G loss: 0.6839\n",
      "[804/1762] D loss: 1.3897, G loss: 0.6661\n",
      "[884/1762] D loss: 1.3877, G loss: 0.6853\n",
      "[964/1762] D loss: 1.0670, G loss: 1.3774\n",
      "[1044/1762] D loss: 1.3927, G loss: 0.6736\n",
      "[1124/1762] D loss: 1.3875, G loss: 0.7014\n",
      "[1204/1762] D loss: 1.0490, G loss: 1.4020\n",
      "[1284/1762] D loss: 1.3903, G loss: 0.7123\n",
      "[1364/1762] D loss: 1.3958, G loss: 0.6589\n",
      "[1444/1762] D loss: 1.3868, G loss: 0.6870\n",
      "[1524/1762] D loss: 1.3857, G loss: 0.6981\n",
      "[1604/1762] D loss: 0.9265, G loss: 2.0212\n",
      "[1684/1762] D loss: 1.2152, G loss: 2.1492\n",
      "[1762/1762] D loss: 1.3895, G loss: 0.6596\n",
      "train error: \n",
      " D loss: 1.284028, G loss: 0.958575, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 90.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.256867, G loss: 1.022839, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3882, G loss: 0.7122\n",
      "[84/1762] D loss: 1.3917, G loss: 0.6655\n",
      "[164/1762] D loss: 1.0454, G loss: 1.6480\n",
      "[244/1762] D loss: 1.4949, G loss: 0.8156\n",
      "[324/1762] D loss: 1.3955, G loss: 0.7800\n",
      "[404/1762] D loss: 1.2476, G loss: 0.9743\n",
      "[484/1762] D loss: 1.0493, G loss: 1.3766\n",
      "[564/1762] D loss: 1.3883, G loss: 0.6727\n",
      "[644/1762] D loss: 1.0509, G loss: 1.4365\n",
      "[724/1762] D loss: 1.0499, G loss: 1.4064\n",
      "[804/1762] D loss: 1.3880, G loss: 0.6526\n",
      "[884/1762] D loss: 1.3811, G loss: 0.7266\n",
      "[964/1762] D loss: 1.3867, G loss: 0.7093\n",
      "[1044/1762] D loss: 1.3877, G loss: 0.6708\n",
      "[1124/1762] D loss: 0.7022, G loss: 2.5292\n",
      "[1204/1762] D loss: 1.3894, G loss: 0.7345\n",
      "[1284/1762] D loss: 1.3879, G loss: 0.7093\n",
      "[1364/1762] D loss: 1.3871, G loss: 0.6734\n",
      "[1444/1762] D loss: 1.3878, G loss: 0.7211\n",
      "[1524/1762] D loss: 1.3874, G loss: 0.6641\n",
      "[1604/1762] D loss: 1.3919, G loss: 0.7300\n",
      "[1684/1762] D loss: 1.3916, G loss: 0.7084\n",
      "[1762/1762] D loss: 1.3902, G loss: 0.7220\n",
      "train error: \n",
      " D loss: 1.287713, G loss: 0.959496, D accuracy: 54.0%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.264055, G loss: 1.032252, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3887, G loss: 0.6941\n",
      "[84/1762] D loss: 1.3866, G loss: 0.6941\n",
      "[164/1762] D loss: 1.3875, G loss: 0.6851\n",
      "[244/1762] D loss: 1.0442, G loss: 1.6395\n",
      "[324/1762] D loss: 1.0462, G loss: 1.6285\n",
      "[404/1762] D loss: 1.2787, G loss: 0.9513\n",
      "[484/1762] D loss: 1.0457, G loss: 1.5996\n",
      "[564/1762] D loss: 1.3868, G loss: 0.6731\n",
      "[644/1762] D loss: 1.3882, G loss: 0.7236\n",
      "[724/1762] D loss: 1.3869, G loss: 0.6912\n",
      "[804/1762] D loss: 1.3889, G loss: 0.6879\n",
      "[884/1762] D loss: 1.3875, G loss: 0.6858\n",
      "[964/1762] D loss: 1.3862, G loss: 0.6881\n",
      "[1044/1762] D loss: 1.3865, G loss: 0.6971\n",
      "[1124/1762] D loss: 1.4032, G loss: 0.5933\n",
      "[1204/1762] D loss: 1.3960, G loss: 0.5812\n",
      "[1284/1762] D loss: 1.3881, G loss: 0.7313\n",
      "[1364/1762] D loss: 1.3871, G loss: 0.6735\n",
      "[1444/1762] D loss: 1.3873, G loss: 0.6756\n",
      "[1524/1762] D loss: 1.3889, G loss: 0.6540\n",
      "[1604/1762] D loss: 1.3871, G loss: 0.6785\n",
      "[1684/1762] D loss: 1.3866, G loss: 0.7053\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.7000\n",
      "train error: \n",
      " D loss: 1.288147, G loss: 0.995576, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.256480, G loss: 1.117090, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3873, G loss: 0.7002\n",
      "[84/1762] D loss: 1.3873, G loss: 0.6912\n",
      "[164/1762] D loss: 1.3868, G loss: 0.6901\n",
      "[244/1762] D loss: 1.0430, G loss: 1.6872\n",
      "[324/1762] D loss: 1.3876, G loss: 0.6818\n",
      "[404/1762] D loss: 1.3874, G loss: 0.6679\n",
      "[484/1762] D loss: 1.0432, G loss: 1.7265\n",
      "[564/1762] D loss: 1.3870, G loss: 0.6785\n",
      "[644/1762] D loss: 1.3883, G loss: 0.6771\n",
      "[724/1762] D loss: 1.1565, G loss: 2.0219\n",
      "[804/1762] D loss: 1.3877, G loss: 0.7121\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6896\n",
      "[964/1762] D loss: 1.0426, G loss: 1.7356\n",
      "[1044/1762] D loss: 1.0413, G loss: 1.9068\n",
      "[1124/1762] D loss: 1.3868, G loss: 0.6936\n",
      "[1204/1762] D loss: 1.3870, G loss: 0.6894\n",
      "[1284/1762] D loss: 1.3992, G loss: 0.7505\n",
      "[1364/1762] D loss: 1.3902, G loss: 0.6976\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.7030\n",
      "[1524/1762] D loss: 1.3868, G loss: 0.6894\n",
      "[1604/1762] D loss: 1.3873, G loss: 0.6647\n",
      "[1684/1762] D loss: 1.0426, G loss: 1.8672\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.6832\n",
      "train error: \n",
      " D loss: 1.300876, G loss: 1.017481, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.275597, G loss: 1.137758, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3866, G loss: 0.6943\n",
      "[84/1762] D loss: 1.3865, G loss: 0.6929\n",
      "[164/1762] D loss: 1.3872, G loss: 0.7058\n",
      "[244/1762] D loss: 1.4313, G loss: 0.5289\n",
      "[324/1762] D loss: 1.3890, G loss: 0.7272\n",
      "[404/1762] D loss: 1.4012, G loss: 0.7109\n",
      "[484/1762] D loss: 1.3872, G loss: 0.7005\n",
      "[564/1762] D loss: 1.3927, G loss: 0.6257\n",
      "[644/1762] D loss: 1.3879, G loss: 0.7198\n",
      "[724/1762] D loss: 1.3874, G loss: 0.7075\n",
      "[804/1762] D loss: 1.3922, G loss: 0.6517\n",
      "[884/1762] D loss: 1.3872, G loss: 0.6686\n",
      "[964/1762] D loss: 1.0436, G loss: 1.7341\n",
      "[1044/1762] D loss: 1.0602, G loss: 2.3800\n",
      "[1124/1762] D loss: 1.0467, G loss: 1.7245\n",
      "[1204/1762] D loss: 1.2570, G loss: 0.9178\n",
      "[1284/1762] D loss: 1.0473, G loss: 1.5126\n",
      "[1364/1762] D loss: 1.0496, G loss: 1.5485\n",
      "[1444/1762] D loss: 1.0472, G loss: 1.5789\n",
      "[1524/1762] D loss: 1.2080, G loss: 1.9988\n",
      "[1604/1762] D loss: 1.3868, G loss: 0.6838\n",
      "[1684/1762] D loss: 1.3867, G loss: 0.7002\n",
      "[1762/1762] D loss: 1.1166, G loss: 1.3696\n",
      "train error: \n",
      " D loss: 1.417695, G loss: 0.878963, D accuracy: 52.8%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.429555, G loss: 0.930114, D accuracy: 53.8%, cell accuracy: 99.7%, board accuracy: 84.1% \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3692, G loss: 0.6687\n",
      "[84/1762] D loss: 1.4014, G loss: 0.7521\n",
      "[164/1762] D loss: 1.3881, G loss: 0.6973\n",
      "[244/1762] D loss: 1.3877, G loss: 0.6654\n",
      "[324/1762] D loss: 1.3879, G loss: 0.6763\n",
      "[404/1762] D loss: 1.3835, G loss: 0.7243\n",
      "[484/1762] D loss: 1.3826, G loss: 0.6992\n",
      "[564/1762] D loss: 1.3933, G loss: 0.7391\n",
      "[644/1762] D loss: 1.3882, G loss: 0.6625\n",
      "[724/1762] D loss: 1.3878, G loss: 0.6959\n",
      "[804/1762] D loss: 1.3867, G loss: 0.6934\n",
      "[884/1762] D loss: 1.0502, G loss: 1.6053\n",
      "[964/1762] D loss: 1.3941, G loss: 0.6416\n",
      "[1044/1762] D loss: 1.2570, G loss: 1.4504\n",
      "[1124/1762] D loss: 1.3910, G loss: 0.6694\n",
      "[1204/1762] D loss: 1.3896, G loss: 0.6789\n",
      "[1284/1762] D loss: 0.7047, G loss: 2.6077\n",
      "[1364/1762] D loss: 1.3902, G loss: 0.7058\n",
      "[1444/1762] D loss: 1.3818, G loss: 0.6775\n",
      "[1524/1762] D loss: 1.0450, G loss: 1.5839\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.7025\n",
      "[1684/1762] D loss: 1.0447, G loss: 1.7165\n",
      "[1762/1762] D loss: 1.3871, G loss: 0.6731\n",
      "train error: \n",
      " D loss: 1.295893, G loss: 0.976788, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 90.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.268822, G loss: 1.059360, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3869, G loss: 0.6894\n",
      "[84/1762] D loss: 1.3865, G loss: 0.6892\n",
      "[164/1762] D loss: 1.3881, G loss: 0.6818\n",
      "[244/1762] D loss: 1.3865, G loss: 0.7062\n",
      "[324/1762] D loss: 1.3883, G loss: 0.6563\n",
      "[404/1762] D loss: 1.3889, G loss: 0.6977\n",
      "[484/1762] D loss: 1.3863, G loss: 0.6932\n",
      "[564/1762] D loss: 1.0483, G loss: 1.7732\n",
      "[644/1762] D loss: 1.3884, G loss: 0.6899\n",
      "[724/1762] D loss: 1.3844, G loss: 0.6752\n",
      "[804/1762] D loss: 1.3874, G loss: 0.6973\n",
      "[884/1762] D loss: 1.3889, G loss: 0.7202\n",
      "[964/1762] D loss: 1.3872, G loss: 0.7108\n",
      "[1044/1762] D loss: 1.3873, G loss: 0.6699\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6807\n",
      "[1204/1762] D loss: 1.3885, G loss: 0.7074\n",
      "[1284/1762] D loss: 1.3878, G loss: 0.6850\n",
      "[1364/1762] D loss: 1.0438, G loss: 1.7158\n",
      "[1444/1762] D loss: 1.0427, G loss: 1.7816\n",
      "[1524/1762] D loss: 1.3869, G loss: 0.6766\n",
      "[1604/1762] D loss: 1.0443, G loss: 1.6603\n",
      "[1684/1762] D loss: 1.3866, G loss: 0.6804\n",
      "[1762/1762] D loss: 1.1299, G loss: 1.1978\n",
      "train error: \n",
      " D loss: 1.267028, G loss: 1.117103, D accuracy: 55.8%, cell accuracy: 99.8%, board accuracy: 85.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.251876, G loss: 1.180757, D accuracy: 55.8%, cell accuracy: 99.8%, board accuracy: 84.3% \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3874, G loss: 0.6608\n",
      "[84/1762] D loss: 1.0568, G loss: 1.4121\n",
      "[164/1762] D loss: 0.6967, G loss: 3.5067\n",
      "[244/1762] D loss: 1.3864, G loss: 0.7019\n",
      "[324/1762] D loss: 1.0780, G loss: 2.5068\n",
      "[404/1762] D loss: 1.3913, G loss: 0.7388\n",
      "[484/1762] D loss: 1.3864, G loss: 0.7062\n",
      "[564/1762] D loss: 1.3867, G loss: 0.6853\n",
      "[644/1762] D loss: 1.3865, G loss: 0.6961\n",
      "[724/1762] D loss: 1.2966, G loss: 0.7818\n",
      "[804/1762] D loss: 1.0705, G loss: 1.2145\n",
      "[884/1762] D loss: 1.3881, G loss: 0.7067\n",
      "[964/1762] D loss: 1.3883, G loss: 0.6652\n",
      "[1044/1762] D loss: 1.3893, G loss: 0.6718\n",
      "[1124/1762] D loss: 1.0449, G loss: 1.7775\n",
      "[1204/1762] D loss: 1.0670, G loss: 1.1589\n",
      "[1284/1762] D loss: 1.0700, G loss: 1.1099\n",
      "[1364/1762] D loss: 1.1085, G loss: 0.9820\n",
      "[1444/1762] D loss: 1.3935, G loss: 0.6447\n",
      "[1524/1762] D loss: 1.2185, G loss: 0.9549\n",
      "[1604/1762] D loss: 1.0610, G loss: 1.0854\n",
      "[1684/1762] D loss: 1.3967, G loss: 0.7196\n",
      "[1762/1762] D loss: 1.2934, G loss: 0.8336\n",
      "train error: \n",
      " D loss: 1.306120, G loss: 0.924267, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 87.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.291621, G loss: 1.000507, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3902, G loss: 0.7155\n",
      "[84/1762] D loss: 1.3874, G loss: 0.7129\n",
      "[164/1762] D loss: 1.3880, G loss: 0.6514\n",
      "[244/1762] D loss: 1.3877, G loss: 0.6979\n",
      "[324/1762] D loss: 1.3875, G loss: 0.6711\n",
      "[404/1762] D loss: 1.3844, G loss: 0.7388\n",
      "[484/1762] D loss: 1.3852, G loss: 0.6666\n",
      "[564/1762] D loss: 1.3882, G loss: 0.7375\n",
      "[644/1762] D loss: 1.3883, G loss: 0.7238\n",
      "[724/1762] D loss: 1.3942, G loss: 0.6264\n",
      "[804/1762] D loss: 1.3920, G loss: 0.7501\n",
      "[884/1762] D loss: 1.3870, G loss: 0.6781\n",
      "[964/1762] D loss: 1.3885, G loss: 0.6737\n",
      "[1044/1762] D loss: 2.0567, G loss: 1.4107\n",
      "[1124/1762] D loss: 1.0669, G loss: 1.1540\n",
      "[1204/1762] D loss: 1.3868, G loss: 0.6738\n",
      "[1284/1762] D loss: 1.3893, G loss: 0.7186\n",
      "[1364/1762] D loss: 1.3868, G loss: 0.6886\n",
      "[1444/1762] D loss: 1.0704, G loss: 1.1511\n",
      "[1524/1762] D loss: 1.3881, G loss: 0.6479\n",
      "[1604/1762] D loss: 1.3847, G loss: 0.6702\n",
      "[1684/1762] D loss: 1.0455, G loss: 1.5182\n",
      "[1762/1762] D loss: 1.3920, G loss: 0.6276\n",
      "train error: \n",
      " D loss: 1.314296, G loss: 0.788078, D accuracy: 53.4%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.301018, G loss: 0.854924, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.7207, G loss: 1.2681\n",
      "[84/1762] D loss: 1.3904, G loss: 0.6937\n",
      "[164/1762] D loss: 1.3907, G loss: 0.6783\n",
      "[244/1762] D loss: 1.3834, G loss: 0.6811\n",
      "[324/1762] D loss: 1.3884, G loss: 0.7196\n",
      "[404/1762] D loss: 1.3871, G loss: 0.6805\n",
      "[484/1762] D loss: 1.1135, G loss: 0.9240\n",
      "[564/1762] D loss: 1.3912, G loss: 0.6393\n",
      "[644/1762] D loss: 1.3867, G loss: 0.6961\n",
      "[724/1762] D loss: 1.3944, G loss: 0.7391\n",
      "[804/1762] D loss: 1.3858, G loss: 0.7101\n",
      "[884/1762] D loss: 1.3879, G loss: 0.7299\n",
      "[964/1762] D loss: 1.3884, G loss: 0.6563\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.6815\n",
      "[1124/1762] D loss: 1.3878, G loss: 0.7017\n",
      "[1204/1762] D loss: 1.3880, G loss: 0.6539\n",
      "[1284/1762] D loss: 1.3866, G loss: 0.6839\n",
      "[1364/1762] D loss: 1.3893, G loss: 0.6814\n",
      "[1444/1762] D loss: 1.0500, G loss: 1.3874\n",
      "[1524/1762] D loss: 1.3872, G loss: 0.6731\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6871\n",
      "[1684/1762] D loss: 1.0445, G loss: 1.6010\n",
      "[1762/1762] D loss: 1.3871, G loss: 0.7039\n",
      "train error: \n",
      " D loss: 1.310962, G loss: 0.968856, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.307699, G loss: 1.058357, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 91.1% \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3859, G loss: 0.7104\n",
      "[84/1762] D loss: 1.3879, G loss: 0.6934\n",
      "[164/1762] D loss: 1.3876, G loss: 0.7262\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6978\n",
      "[324/1762] D loss: 1.3871, G loss: 0.7139\n",
      "[404/1762] D loss: 1.3871, G loss: 0.7033\n",
      "[484/1762] D loss: 1.3868, G loss: 0.7071\n",
      "[564/1762] D loss: 1.0609, G loss: 1.1598\n",
      "[644/1762] D loss: 1.0412, G loss: 2.2672\n",
      "[724/1762] D loss: 1.0733, G loss: 1.0978\n",
      "[804/1762] D loss: 1.3884, G loss: 0.7349\n",
      "[884/1762] D loss: 1.3885, G loss: 0.6684\n",
      "[964/1762] D loss: 1.1058, G loss: 0.8956\n",
      "[1044/1762] D loss: 1.0627, G loss: 1.1730\n",
      "[1124/1762] D loss: 1.3871, G loss: 0.7174\n",
      "[1204/1762] D loss: 1.3886, G loss: 0.6709\n",
      "[1284/1762] D loss: 1.3882, G loss: 0.6790\n",
      "[1364/1762] D loss: 1.3880, G loss: 0.7186\n",
      "[1444/1762] D loss: 1.0645, G loss: 1.1658\n",
      "[1524/1762] D loss: 1.3876, G loss: 0.7235\n",
      "[1604/1762] D loss: 1.3869, G loss: 0.6917\n",
      "[1684/1762] D loss: 1.3687, G loss: 0.7940\n",
      "[1762/1762] D loss: 1.3919, G loss: 0.6202\n",
      "train error: \n",
      " D loss: 1.309388, G loss: 0.893376, D accuracy: 53.4%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.308419, G loss: 0.980228, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 91.1% \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3869, G loss: 0.6795\n",
      "[84/1762] D loss: 1.0479, G loss: 1.4749\n",
      "[164/1762] D loss: 1.3864, G loss: 0.6932\n",
      "[244/1762] D loss: 1.3869, G loss: 0.6719\n",
      "[324/1762] D loss: 1.3874, G loss: 0.6712\n",
      "[404/1762] D loss: 1.3872, G loss: 0.7004\n",
      "[484/1762] D loss: 1.3865, G loss: 0.6943\n",
      "[564/1762] D loss: 1.3911, G loss: 0.6558\n",
      "[644/1762] D loss: 1.0485, G loss: 1.4072\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6859\n",
      "[804/1762] D loss: 0.8151, G loss: 3.1524\n",
      "[884/1762] D loss: 1.3948, G loss: 0.7837\n",
      "[964/1762] D loss: 1.2377, G loss: 1.7945\n",
      "[1044/1762] D loss: 1.4057, G loss: 0.6043\n",
      "[1124/1762] D loss: 1.0806, G loss: 0.9639\n",
      "[1204/1762] D loss: 1.3873, G loss: 0.7076\n",
      "[1284/1762] D loss: 1.3866, G loss: 0.6825\n",
      "[1364/1762] D loss: 1.3874, G loss: 0.6811\n",
      "[1444/1762] D loss: 1.3873, G loss: 0.7093\n",
      "[1524/1762] D loss: 1.3858, G loss: 0.6850\n",
      "[1604/1762] D loss: 0.7285, G loss: 2.3678\n",
      "[1684/1762] D loss: 1.0443, G loss: 2.2562\n",
      "[1762/1762] D loss: 0.6959, G loss: 5.5823\n",
      "train error: \n",
      " D loss: 1.251448, G loss: 1.307938, D accuracy: 56.7%, cell accuracy: 99.7%, board accuracy: 81.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.245650, G loss: 1.405471, D accuracy: 57.0%, cell accuracy: 99.6%, board accuracy: 79.5% \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3986, G loss: 0.6283\n",
      "[84/1762] D loss: 1.0080, G loss: 1.3458\n",
      "[164/1762] D loss: 1.3977, G loss: 0.7379\n",
      "[244/1762] D loss: 1.3908, G loss: 0.7829\n",
      "[324/1762] D loss: 1.3865, G loss: 0.7031\n",
      "[404/1762] D loss: 1.3865, G loss: 0.6981\n",
      "[484/1762] D loss: 1.3565, G loss: 0.7809\n",
      "[564/1762] D loss: 1.3868, G loss: 0.7139\n",
      "[644/1762] D loss: 1.3888, G loss: 0.7319\n",
      "[724/1762] D loss: 1.3868, G loss: 0.7107\n",
      "[804/1762] D loss: 1.3878, G loss: 0.6978\n",
      "[884/1762] D loss: 1.3892, G loss: 0.7193\n",
      "[964/1762] D loss: 1.3953, G loss: 0.6451\n",
      "[1044/1762] D loss: 1.3873, G loss: 0.7256\n",
      "[1124/1762] D loss: 1.3882, G loss: 0.7015\n",
      "[1204/1762] D loss: 1.3868, G loss: 0.6956\n",
      "[1284/1762] D loss: 1.3870, G loss: 0.7097\n",
      "[1364/1762] D loss: 1.3871, G loss: 0.6763\n",
      "[1444/1762] D loss: 1.0502, G loss: 1.4359\n",
      "[1524/1762] D loss: 1.3865, G loss: 0.6832\n",
      "[1604/1762] D loss: 1.3871, G loss: 0.7047\n",
      "[1684/1762] D loss: 1.3869, G loss: 0.7142\n",
      "[1762/1762] D loss: 1.3866, G loss: 0.7099\n",
      "train error: \n",
      " D loss: 1.301727, G loss: 0.834344, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 90.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.292096, G loss: 0.858063, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3874, G loss: 0.7180\n",
      "[84/1762] D loss: 1.3884, G loss: 0.6476\n",
      "[164/1762] D loss: 1.3875, G loss: 0.6998\n",
      "[244/1762] D loss: 1.0585, G loss: 1.2207\n",
      "[324/1762] D loss: 1.0411, G loss: 1.9792\n",
      "[404/1762] D loss: 1.3877, G loss: 0.6712\n",
      "[484/1762] D loss: 1.3870, G loss: 0.6817\n",
      "[564/1762] D loss: 1.6995, G loss: 1.1025\n",
      "[644/1762] D loss: 1.0564, G loss: 1.1797\n",
      "[724/1762] D loss: 1.3867, G loss: 0.6729\n",
      "[804/1762] D loss: 0.7372, G loss: 1.6617\n",
      "[884/1762] D loss: 1.3867, G loss: 0.6964\n",
      "[964/1762] D loss: 1.3871, G loss: 0.7160\n",
      "[1044/1762] D loss: 1.0626, G loss: 1.1107\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.7101\n",
      "[1204/1762] D loss: 1.1018, G loss: 0.9518\n",
      "[1284/1762] D loss: 1.0615, G loss: 1.1543\n",
      "[1364/1762] D loss: 1.3866, G loss: 0.6813\n",
      "[1444/1762] D loss: 1.3875, G loss: 0.6646\n",
      "[1524/1762] D loss: 1.3879, G loss: 0.6762\n",
      "[1604/1762] D loss: 1.3871, G loss: 0.6698\n",
      "[1684/1762] D loss: 1.0563, G loss: 1.2174\n",
      "[1762/1762] D loss: 1.3874, G loss: 0.7108\n",
      "train error: \n",
      " D loss: 1.304745, G loss: 0.831443, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.293401, G loss: 0.867353, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3873, G loss: 0.6729\n",
      "[84/1762] D loss: 1.0709, G loss: 1.1112\n",
      "[164/1762] D loss: 1.0600, G loss: 1.4792\n",
      "[244/1762] D loss: 1.3891, G loss: 0.7431\n",
      "[324/1762] D loss: 1.3902, G loss: 0.7129\n",
      "[404/1762] D loss: 1.3878, G loss: 0.7197\n",
      "[484/1762] D loss: 1.0637, G loss: 1.1306\n",
      "[564/1762] D loss: 1.3869, G loss: 0.6816\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6939\n",
      "[724/1762] D loss: 1.3875, G loss: 0.6992\n",
      "[804/1762] D loss: 1.3879, G loss: 0.6755\n",
      "[884/1762] D loss: 1.3895, G loss: 0.6822\n",
      "[964/1762] D loss: 1.3868, G loss: 0.7023\n",
      "[1044/1762] D loss: 1.3875, G loss: 0.6809\n",
      "[1124/1762] D loss: 1.3867, G loss: 0.6926\n",
      "[1204/1762] D loss: 1.3871, G loss: 0.6758\n",
      "[1284/1762] D loss: 1.3870, G loss: 0.6796\n",
      "[1364/1762] D loss: 1.0760, G loss: 1.0497\n",
      "[1444/1762] D loss: 1.0645, G loss: 1.1102\n",
      "[1524/1762] D loss: 1.3866, G loss: 0.6866\n",
      "[1604/1762] D loss: 1.3866, G loss: 0.6979\n",
      "[1684/1762] D loss: 1.0642, G loss: 1.1133\n",
      "[1762/1762] D loss: 0.7203, G loss: 1.9440\n",
      "train error: \n",
      " D loss: 1.303976, G loss: 0.880965, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.295581, G loss: 0.929815, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 91.1% \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3885, G loss: 0.6850\n",
      "[84/1762] D loss: 1.3871, G loss: 0.6876\n",
      "[164/1762] D loss: 1.3872, G loss: 0.6623\n",
      "[244/1762] D loss: 1.3757, G loss: 0.7058\n",
      "[324/1762] D loss: 1.6176, G loss: 1.0450\n",
      "[404/1762] D loss: 1.3884, G loss: 0.6573\n",
      "[484/1762] D loss: 1.0767, G loss: 1.0238\n",
      "[564/1762] D loss: 1.3873, G loss: 0.6657\n",
      "[644/1762] D loss: 1.3870, G loss: 0.7053\n",
      "[724/1762] D loss: 1.3866, G loss: 0.6812\n",
      "[804/1762] D loss: 1.6949, G loss: 1.1409\n",
      "[884/1762] D loss: 1.3875, G loss: 0.7120\n",
      "[964/1762] D loss: 1.3867, G loss: 0.6797\n",
      "[1044/1762] D loss: 1.3927, G loss: 0.6903\n",
      "[1124/1762] D loss: 1.3866, G loss: 0.6968\n",
      "[1204/1762] D loss: 1.3871, G loss: 0.7005\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6931\n",
      "[1364/1762] D loss: 1.3897, G loss: 0.6878\n",
      "[1444/1762] D loss: 1.0538, G loss: 1.2353\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.6849\n",
      "[1604/1762] D loss: 1.3868, G loss: 0.6729\n",
      "[1684/1762] D loss: 0.7077, G loss: 2.2807\n",
      "[1762/1762] D loss: 0.6990, G loss: 2.6002\n",
      "train error: \n",
      " D loss: 1.306890, G loss: 0.925334, D accuracy: 53.4%, cell accuracy: 99.9%, board accuracy: 93.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.298824, G loss: 1.001097, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6958\n",
      "[84/1762] D loss: 1.3888, G loss: 0.7296\n",
      "[164/1762] D loss: 1.0405, G loss: 1.4441\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6819\n",
      "[324/1762] D loss: 1.0462, G loss: 1.4678\n",
      "[404/1762] D loss: 1.3867, G loss: 0.7051\n",
      "[484/1762] D loss: 1.3868, G loss: 0.6980\n",
      "[564/1762] D loss: 1.3874, G loss: 0.7029\n",
      "[644/1762] D loss: 1.3850, G loss: 0.6875\n",
      "[724/1762] D loss: 1.3882, G loss: 0.7221\n",
      "[804/1762] D loss: 1.3865, G loss: 0.7024\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6959\n",
      "[964/1762] D loss: 1.3882, G loss: 0.6583\n",
      "[1044/1762] D loss: 1.6392, G loss: 1.0729\n",
      "[1124/1762] D loss: 1.3875, G loss: 0.7200\n",
      "[1204/1762] D loss: 1.3877, G loss: 0.7166\n",
      "[1284/1762] D loss: 1.3869, G loss: 0.6944\n",
      "[1364/1762] D loss: 1.3885, G loss: 0.6555\n",
      "[1444/1762] D loss: 1.3866, G loss: 0.6783\n",
      "[1524/1762] D loss: 1.3868, G loss: 0.6833\n",
      "[1604/1762] D loss: 1.3870, G loss: 0.6779\n",
      "[1684/1762] D loss: 1.3867, G loss: 0.6776\n",
      "[1762/1762] D loss: 1.3875, G loss: 0.7265\n",
      "train error: \n",
      " D loss: 1.304970, G loss: 0.914259, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.299205, G loss: 0.979589, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 91.1% \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.7004\n",
      "[84/1762] D loss: 1.3867, G loss: 0.6972\n",
      "[164/1762] D loss: 1.3886, G loss: 0.6470\n",
      "[244/1762] D loss: 1.3822, G loss: 0.7048\n",
      "[324/1762] D loss: 1.3865, G loss: 0.6886\n",
      "[404/1762] D loss: 1.0644, G loss: 1.1508\n",
      "[484/1762] D loss: 1.3868, G loss: 0.6831\n",
      "[564/1762] D loss: 1.3863, G loss: 0.6872\n",
      "[644/1762] D loss: 1.3870, G loss: 0.7086\n",
      "[724/1762] D loss: 1.3866, G loss: 0.6802\n",
      "[804/1762] D loss: 1.3865, G loss: 0.7004\n",
      "[884/1762] D loss: 1.3881, G loss: 0.6985\n",
      "[964/1762] D loss: 1.0505, G loss: 1.3666\n",
      "[1044/1762] D loss: 1.0501, G loss: 1.3830\n",
      "[1124/1762] D loss: 1.0535, G loss: 1.2499\n",
      "[1204/1762] D loss: 1.3880, G loss: 0.6730\n",
      "[1284/1762] D loss: 1.3879, G loss: 0.6918\n",
      "[1364/1762] D loss: 1.3866, G loss: 0.6862\n",
      "[1444/1762] D loss: 1.3933, G loss: 0.6320\n",
      "[1524/1762] D loss: 1.2989, G loss: 0.8497\n",
      "[1604/1762] D loss: 1.3903, G loss: 0.7034\n",
      "[1684/1762] D loss: 1.0589, G loss: 1.1858\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6980\n",
      "train error: \n",
      " D loss: 1.305792, G loss: 0.851499, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.295246, G loss: 0.885857, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 91.1% \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3865, G loss: 0.7021\n",
      "[84/1762] D loss: 1.3871, G loss: 0.6805\n",
      "[164/1762] D loss: 1.3868, G loss: 0.6868\n",
      "[244/1762] D loss: 1.3872, G loss: 0.6713\n",
      "[324/1762] D loss: 1.3895, G loss: 0.7023\n",
      "[404/1762] D loss: 1.3893, G loss: 0.6989\n",
      "[484/1762] D loss: 1.0509, G loss: 1.3076\n",
      "[564/1762] D loss: 1.3871, G loss: 0.6663\n",
      "[644/1762] D loss: 1.8581, G loss: 1.3050\n",
      "[724/1762] D loss: 1.3899, G loss: 0.6783\n",
      "[804/1762] D loss: 1.3866, G loss: 0.6868\n",
      "[884/1762] D loss: 1.0635, G loss: 1.1206\n",
      "[964/1762] D loss: 1.1003, G loss: 0.9151\n",
      "[1044/1762] D loss: 1.3897, G loss: 0.6850\n",
      "[1124/1762] D loss: 1.3870, G loss: 0.7115\n",
      "[1204/1762] D loss: 0.7156, G loss: 2.0497\n",
      "[1284/1762] D loss: 1.3865, G loss: 0.6969\n",
      "[1364/1762] D loss: 1.0751, G loss: 1.0823\n",
      "[1444/1762] D loss: 1.3932, G loss: 0.6303\n",
      "[1524/1762] D loss: 1.0756, G loss: 1.0374\n",
      "[1604/1762] D loss: 1.3865, G loss: 0.6812\n",
      "[1684/1762] D loss: 1.3880, G loss: 0.6615\n",
      "[1762/1762] D loss: 1.3868, G loss: 0.7144\n",
      "train error: \n",
      " D loss: 1.304008, G loss: 0.856341, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.297611, G loss: 0.907405, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3875, G loss: 0.6807\n",
      "[84/1762] D loss: 1.3877, G loss: 0.7168\n",
      "[164/1762] D loss: 1.3877, G loss: 0.6736\n",
      "[244/1762] D loss: 1.3890, G loss: 0.6572\n",
      "[324/1762] D loss: 1.3867, G loss: 0.7049\n",
      "[404/1762] D loss: 1.3865, G loss: 0.6982\n",
      "[484/1762] D loss: 1.3865, G loss: 0.6846\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6957\n",
      "[644/1762] D loss: 1.3867, G loss: 0.7071\n",
      "[724/1762] D loss: 1.3870, G loss: 0.6930\n",
      "[804/1762] D loss: 1.3869, G loss: 0.6690\n",
      "[884/1762] D loss: 1.3870, G loss: 0.7009\n",
      "[964/1762] D loss: 1.0507, G loss: 1.3435\n",
      "[1044/1762] D loss: 1.3867, G loss: 0.6780\n",
      "[1124/1762] D loss: 1.3867, G loss: 0.6983\n",
      "[1204/1762] D loss: 1.3872, G loss: 0.7155\n",
      "[1284/1762] D loss: 1.3866, G loss: 0.6869\n",
      "[1364/1762] D loss: 1.3867, G loss: 0.6938\n",
      "[1444/1762] D loss: 1.0529, G loss: 1.2672\n",
      "[1524/1762] D loss: 1.3880, G loss: 0.6496\n",
      "[1604/1762] D loss: 1.0494, G loss: 1.3494\n",
      "[1684/1762] D loss: 1.3872, G loss: 0.6786\n",
      "[1762/1762] D loss: 0.7337, G loss: 1.5799\n",
      "train error: \n",
      " D loss: 1.305463, G loss: 0.842957, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.297612, G loss: 0.895201, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3941, G loss: 0.6827\n",
      "[84/1762] D loss: 1.3872, G loss: 0.7174\n",
      "[164/1762] D loss: 1.0591, G loss: 1.2146\n",
      "[244/1762] D loss: 1.0530, G loss: 1.3122\n",
      "[324/1762] D loss: 0.7027, G loss: 2.4268\n",
      "[404/1762] D loss: 1.3868, G loss: 0.6881\n",
      "[484/1762] D loss: 1.3865, G loss: 0.6900\n",
      "[564/1762] D loss: 1.3986, G loss: 0.6509\n",
      "[644/1762] D loss: 1.0588, G loss: 1.1741\n",
      "[724/1762] D loss: 1.3877, G loss: 0.6933\n",
      "[804/1762] D loss: 1.3866, G loss: 0.6869\n",
      "[884/1762] D loss: 1.3892, G loss: 0.6571\n",
      "[964/1762] D loss: 1.0652, G loss: 1.1997\n",
      "[1044/1762] D loss: 1.3869, G loss: 0.6899\n",
      "[1124/1762] D loss: 1.0601, G loss: 1.9030\n",
      "[1204/1762] D loss: 1.3930, G loss: 0.7290\n",
      "[1284/1762] D loss: 1.2835, G loss: 0.8680\n",
      "[1364/1762] D loss: 1.3866, G loss: 0.6877\n",
      "[1444/1762] D loss: 1.4336, G loss: 1.9735\n",
      "[1524/1762] D loss: 1.3896, G loss: 0.6762\n",
      "[1604/1762] D loss: 1.3868, G loss: 0.7040\n",
      "[1684/1762] D loss: 1.0648, G loss: 1.1559\n",
      "[1762/1762] D loss: 1.3868, G loss: 0.7122\n",
      "train error: \n",
      " D loss: 1.304936, G loss: 0.817900, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.297829, G loss: 0.848563, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3870, G loss: 0.6890\n",
      "[84/1762] D loss: 1.3889, G loss: 0.6800\n",
      "[164/1762] D loss: 1.3869, G loss: 0.7118\n",
      "[244/1762] D loss: 1.3859, G loss: 0.7016\n",
      "[324/1762] D loss: 1.0484, G loss: 1.3782\n",
      "[404/1762] D loss: 1.4044, G loss: 0.6423\n",
      "[484/1762] D loss: 1.3966, G loss: 0.6111\n",
      "[564/1762] D loss: 1.3870, G loss: 0.6862\n",
      "[644/1762] D loss: 1.3877, G loss: 0.7006\n",
      "[724/1762] D loss: 1.3888, G loss: 0.6984\n",
      "[804/1762] D loss: 1.3870, G loss: 0.6893\n",
      "[884/1762] D loss: 1.3894, G loss: 0.6616\n",
      "[964/1762] D loss: 1.0613, G loss: 1.1732\n",
      "[1044/1762] D loss: 1.3872, G loss: 0.6756\n",
      "[1124/1762] D loss: 1.3871, G loss: 0.6896\n",
      "[1204/1762] D loss: 1.0427, G loss: 1.8127\n",
      "[1284/1762] D loss: 1.3866, G loss: 0.6963\n",
      "[1364/1762] D loss: 1.3867, G loss: 0.6856\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6935\n",
      "[1524/1762] D loss: 1.0493, G loss: 1.3344\n",
      "[1604/1762] D loss: 1.3874, G loss: 0.7063\n",
      "[1684/1762] D loss: 1.3870, G loss: 0.7106\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6850\n",
      "train error: \n",
      " D loss: 1.286017, G loss: 0.913211, D accuracy: 54.2%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.259413, G loss: 0.968421, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0479, G loss: 1.3750\n",
      "[84/1762] D loss: 1.0658, G loss: 1.3606\n",
      "[164/1762] D loss: 0.7079, G loss: 2.1209\n",
      "[244/1762] D loss: 1.3913, G loss: 0.7406\n",
      "[324/1762] D loss: 1.3865, G loss: 0.6821\n",
      "[404/1762] D loss: 1.3864, G loss: 0.7193\n",
      "[484/1762] D loss: 1.3867, G loss: 0.6953\n",
      "[564/1762] D loss: 1.3873, G loss: 0.7107\n",
      "[644/1762] D loss: 1.3870, G loss: 0.6756\n",
      "[724/1762] D loss: 1.4120, G loss: 0.8168\n",
      "[804/1762] D loss: 1.3871, G loss: 0.6684\n",
      "[884/1762] D loss: 1.3993, G loss: 0.6166\n",
      "[964/1762] D loss: 1.4024, G loss: 0.6223\n",
      "[1044/1762] D loss: 1.0404, G loss: 1.4921\n",
      "[1124/1762] D loss: 1.4042, G loss: 0.7791\n",
      "[1204/1762] D loss: 1.3906, G loss: 0.7607\n",
      "[1284/1762] D loss: 1.3842, G loss: 0.6899\n",
      "[1364/1762] D loss: 1.3538, G loss: 0.7246\n",
      "[1444/1762] D loss: 1.3126, G loss: 1.1630\n",
      "[1524/1762] D loss: 1.4057, G loss: 0.7528\n",
      "[1604/1762] D loss: 1.3920, G loss: 0.7521\n",
      "[1684/1762] D loss: 0.7308, G loss: 1.7558\n",
      "[1762/1762] D loss: 1.3876, G loss: 0.6572\n",
      "train error: \n",
      " D loss: 1.302300, G loss: 0.864460, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 89.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.282056, G loss: 0.905687, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3865, G loss: 0.6986\n",
      "[84/1762] D loss: 1.3877, G loss: 0.6267\n",
      "[164/1762] D loss: 1.3882, G loss: 0.7256\n",
      "[244/1762] D loss: 1.3885, G loss: 0.6870\n",
      "[324/1762] D loss: 1.3824, G loss: 0.6891\n",
      "[404/1762] D loss: 1.3709, G loss: 0.7613\n",
      "[484/1762] D loss: 1.4240, G loss: 0.7768\n",
      "[564/1762] D loss: 1.3874, G loss: 0.6739\n",
      "[644/1762] D loss: 1.3879, G loss: 0.6925\n",
      "[724/1762] D loss: 1.0956, G loss: 0.9847\n",
      "[804/1762] D loss: 1.3891, G loss: 0.7322\n",
      "[884/1762] D loss: 1.3869, G loss: 0.6783\n",
      "[964/1762] D loss: 1.3877, G loss: 0.7258\n",
      "[1044/1762] D loss: 1.0738, G loss: 1.0472\n",
      "[1124/1762] D loss: 0.7104, G loss: 2.1067\n",
      "[1204/1762] D loss: 1.3881, G loss: 0.6979\n",
      "[1284/1762] D loss: 1.3736, G loss: 0.7861\n",
      "[1364/1762] D loss: 1.5297, G loss: 1.0569\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.6992\n",
      "[1524/1762] D loss: 1.1019, G loss: 0.9405\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6730\n",
      "[1684/1762] D loss: 1.3865, G loss: 0.6994\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6742\n",
      "train error: \n",
      " D loss: 1.315461, G loss: 0.759652, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.308744, G loss: 0.776676, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0953, G loss: 0.9610\n",
      "[84/1762] D loss: 1.3944, G loss: 0.7075\n",
      "[164/1762] D loss: 1.3877, G loss: 0.6702\n",
      "[244/1762] D loss: 1.3871, G loss: 0.7077\n",
      "[324/1762] D loss: 1.3870, G loss: 0.6781\n",
      "[404/1762] D loss: 1.0556, G loss: 1.3015\n",
      "[484/1762] D loss: 1.0538, G loss: 1.2419\n",
      "[564/1762] D loss: 1.3850, G loss: 0.6736\n",
      "[644/1762] D loss: 1.3867, G loss: 0.6841\n",
      "[724/1762] D loss: 0.7724, G loss: 1.3263\n",
      "[804/1762] D loss: 1.0635, G loss: 1.2389\n",
      "[884/1762] D loss: 1.0545, G loss: 1.2299\n",
      "[964/1762] D loss: 1.3868, G loss: 0.6787\n",
      "[1044/1762] D loss: 1.3880, G loss: 0.6835\n",
      "[1124/1762] D loss: 1.3870, G loss: 0.7116\n",
      "[1204/1762] D loss: 1.3885, G loss: 0.6927\n",
      "[1284/1762] D loss: 1.3877, G loss: 0.6913\n",
      "[1364/1762] D loss: 1.0527, G loss: 1.3103\n",
      "[1444/1762] D loss: 1.0502, G loss: 1.3323\n",
      "[1524/1762] D loss: 1.3875, G loss: 0.6838\n",
      "[1604/1762] D loss: 1.3860, G loss: 0.6692\n",
      "[1684/1762] D loss: 1.3877, G loss: 0.6796\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.7029\n",
      "train error: \n",
      " D loss: 1.306834, G loss: 0.827314, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 90.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.295148, G loss: 0.870087, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.7300, G loss: 1.1432\n",
      "[84/1762] D loss: 1.3878, G loss: 0.7087\n",
      "[164/1762] D loss: 1.3867, G loss: 0.6826\n",
      "[244/1762] D loss: 1.3877, G loss: 0.7100\n",
      "[324/1762] D loss: 1.0614, G loss: 1.2061\n",
      "[404/1762] D loss: 1.0508, G loss: 1.3057\n",
      "[484/1762] D loss: 1.3866, G loss: 0.6791\n",
      "[564/1762] D loss: 1.3868, G loss: 0.6826\n",
      "[644/1762] D loss: 1.3876, G loss: 0.7202\n",
      "[724/1762] D loss: 1.1050, G loss: 0.8698\n",
      "[804/1762] D loss: 1.3871, G loss: 0.6932\n",
      "[884/1762] D loss: 1.3648, G loss: 0.7329\n",
      "[964/1762] D loss: 1.3887, G loss: 0.6562\n",
      "[1044/1762] D loss: 1.3880, G loss: 0.6830\n",
      "[1124/1762] D loss: 1.8421, G loss: 1.3023\n",
      "[1204/1762] D loss: 1.3909, G loss: 0.6436\n",
      "[1284/1762] D loss: 1.0667, G loss: 1.0910\n",
      "[1364/1762] D loss: 1.3883, G loss: 0.6637\n",
      "[1444/1762] D loss: 1.3897, G loss: 0.6520\n",
      "[1524/1762] D loss: 1.3890, G loss: 0.6619\n",
      "[1604/1762] D loss: 1.0523, G loss: 1.3167\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6984\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.6804\n",
      "train error: \n",
      " D loss: 1.307544, G loss: 0.927964, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 93.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.305981, G loss: 0.987195, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3880, G loss: 0.7197\n",
      "[84/1762] D loss: 1.3892, G loss: 0.6778\n",
      "[164/1762] D loss: 1.3867, G loss: 0.6962\n",
      "[244/1762] D loss: 1.3868, G loss: 0.6797\n",
      "[324/1762] D loss: 1.0509, G loss: 1.3122\n",
      "[404/1762] D loss: 1.3882, G loss: 0.7132\n",
      "[484/1762] D loss: 1.3884, G loss: 0.6565\n",
      "[564/1762] D loss: 1.3869, G loss: 0.6800\n",
      "[644/1762] D loss: 1.3866, G loss: 0.7012\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6764\n",
      "[804/1762] D loss: 1.3885, G loss: 0.6976\n",
      "[884/1762] D loss: 1.0468, G loss: 1.4465\n",
      "[964/1762] D loss: 1.3632, G loss: 0.7363\n",
      "[1044/1762] D loss: 1.3871, G loss: 0.6889\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.6971\n",
      "[1204/1762] D loss: 1.3879, G loss: 0.7321\n",
      "[1284/1762] D loss: 1.3866, G loss: 0.6923\n",
      "[1364/1762] D loss: 1.3866, G loss: 0.6843\n",
      "[1444/1762] D loss: 0.4097, G loss: 2.2449\n",
      "[1524/1762] D loss: 1.0538, G loss: 1.2790\n",
      "[1604/1762] D loss: 1.3892, G loss: 0.6544\n",
      "[1684/1762] D loss: 1.3868, G loss: 0.7110\n",
      "[1762/1762] D loss: 0.7494, G loss: 1.5283\n",
      "train error: \n",
      " D loss: 1.304356, G loss: 0.938878, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.301732, G loss: 0.987059, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3861, G loss: 0.7068\n",
      "[84/1762] D loss: 1.0504, G loss: 1.3045\n",
      "[164/1762] D loss: 1.0706, G loss: 1.0756\n",
      "[244/1762] D loss: 1.3866, G loss: 0.7009\n",
      "[324/1762] D loss: 1.3866, G loss: 0.6885\n",
      "[404/1762] D loss: 1.0674, G loss: 1.1777\n",
      "[484/1762] D loss: 1.3877, G loss: 0.7210\n",
      "[564/1762] D loss: 1.0678, G loss: 1.1009\n",
      "[644/1762] D loss: 1.3866, G loss: 0.6842\n",
      "[724/1762] D loss: 1.0418, G loss: 1.7770\n",
      "[804/1762] D loss: 0.7412, G loss: 2.4094\n",
      "[884/1762] D loss: 1.3885, G loss: 0.7070\n",
      "[964/1762] D loss: 1.2525, G loss: 1.0165\n",
      "[1044/1762] D loss: 1.3866, G loss: 0.6933\n",
      "[1124/1762] D loss: 1.3868, G loss: 0.6948\n",
      "[1204/1762] D loss: 1.2379, G loss: 1.0622\n",
      "[1284/1762] D loss: 1.3654, G loss: 1.2663\n",
      "[1364/1762] D loss: 1.0403, G loss: 2.2626\n",
      "[1444/1762] D loss: 1.3959, G loss: 0.6166\n",
      "[1524/1762] D loss: 1.3869, G loss: 0.6918\n",
      "[1604/1762] D loss: 1.3866, G loss: 0.6912\n",
      "[1684/1762] D loss: 1.2518, G loss: 0.9339\n",
      "[1762/1762] D loss: 0.7373, G loss: 1.5884\n",
      "train error: \n",
      " D loss: 1.300975, G loss: 0.870345, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.293634, G loss: 0.923539, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2140, G loss: 1.4216\n",
      "[84/1762] D loss: 1.3918, G loss: 0.7117\n",
      "[164/1762] D loss: 1.3876, G loss: 0.7021\n",
      "[244/1762] D loss: 1.2727, G loss: 0.9146\n",
      "[324/1762] D loss: 1.3877, G loss: 0.6721\n",
      "[404/1762] D loss: 1.3879, G loss: 0.6924\n",
      "[484/1762] D loss: 1.0545, G loss: 1.2876\n",
      "[564/1762] D loss: 1.0406, G loss: 2.0342\n",
      "[644/1762] D loss: 1.3879, G loss: 0.7038\n",
      "[724/1762] D loss: 1.3822, G loss: 0.6798\n",
      "[804/1762] D loss: 1.0500, G loss: 1.2514\n",
      "[884/1762] D loss: 1.3866, G loss: 0.6814\n",
      "[964/1762] D loss: 1.3894, G loss: 0.6513\n",
      "[1044/1762] D loss: 1.0720, G loss: 1.0529\n",
      "[1124/1762] D loss: 1.3896, G loss: 0.7354\n",
      "[1204/1762] D loss: 1.3865, G loss: 0.7119\n",
      "[1284/1762] D loss: 1.3865, G loss: 0.6741\n",
      "[1364/1762] D loss: 1.0878, G loss: 0.9925\n",
      "[1444/1762] D loss: 1.0425, G loss: 1.7445\n",
      "[1524/1762] D loss: 1.3866, G loss: 0.7002\n",
      "[1604/1762] D loss: 1.3875, G loss: 0.6781\n",
      "[1684/1762] D loss: 1.3867, G loss: 0.6847\n",
      "[1762/1762] D loss: 1.3889, G loss: 0.6824\n",
      "train error: \n",
      " D loss: 1.299975, G loss: 0.950095, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.292834, G loss: 1.052037, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3454, G loss: 0.7758\n",
      "[84/1762] D loss: 1.3870, G loss: 0.6986\n",
      "[164/1762] D loss: 1.1981, G loss: 1.8403\n",
      "[244/1762] D loss: 1.3201, G loss: 0.7692\n",
      "[324/1762] D loss: 1.3876, G loss: 0.6839\n",
      "[404/1762] D loss: 1.3866, G loss: 0.6775\n",
      "[484/1762] D loss: 1.3865, G loss: 0.7077\n",
      "[564/1762] D loss: 1.3865, G loss: 0.6906\n",
      "[644/1762] D loss: 1.3867, G loss: 0.6966\n",
      "[724/1762] D loss: 1.3865, G loss: 0.6784\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6972\n",
      "[884/1762] D loss: 1.1953, G loss: 0.7628\n",
      "[964/1762] D loss: 1.3877, G loss: 0.6765\n",
      "[1044/1762] D loss: 1.3874, G loss: 0.6878\n",
      "[1124/1762] D loss: 1.0543, G loss: 1.2507\n",
      "[1204/1762] D loss: 1.3866, G loss: 0.7004\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6951\n",
      "[1364/1762] D loss: 1.0483, G loss: 1.4350\n",
      "[1444/1762] D loss: 0.7061, G loss: 2.1958\n",
      "[1524/1762] D loss: 1.3872, G loss: 0.6759\n",
      "[1604/1762] D loss: 1.3870, G loss: 0.7002\n",
      "[1684/1762] D loss: 1.0483, G loss: 1.4123\n",
      "[1762/1762] D loss: 1.3862, G loss: 0.7048\n",
      "train error: \n",
      " D loss: 1.298619, G loss: 0.832268, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 83.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.273232, G loss: 0.891650, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 80.5% \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6921\n",
      "[84/1762] D loss: 1.3800, G loss: 0.7017\n",
      "[164/1762] D loss: 1.0514, G loss: 1.2952\n",
      "[244/1762] D loss: 1.3921, G loss: 0.7648\n",
      "[324/1762] D loss: 1.3871, G loss: 0.7033\n",
      "[404/1762] D loss: 1.4655, G loss: 0.8281\n",
      "[484/1762] D loss: 1.0587, G loss: 1.2605\n",
      "[564/1762] D loss: 1.3879, G loss: 0.6604\n",
      "[644/1762] D loss: 1.3864, G loss: 0.6890\n",
      "[724/1762] D loss: 0.7347, G loss: 1.7975\n",
      "[804/1762] D loss: 1.0588, G loss: 1.1800\n",
      "[884/1762] D loss: 1.3865, G loss: 0.6920\n",
      "[964/1762] D loss: 1.3871, G loss: 0.6807\n",
      "[1044/1762] D loss: 1.3866, G loss: 0.7029\n",
      "[1124/1762] D loss: 1.0444, G loss: 1.5465\n",
      "[1204/1762] D loss: 1.3881, G loss: 0.6742\n",
      "[1284/1762] D loss: 0.6275, G loss: 2.4468\n",
      "[1364/1762] D loss: 1.3866, G loss: 0.7070\n",
      "[1444/1762] D loss: 1.3884, G loss: 0.7083\n",
      "[1524/1762] D loss: 1.0884, G loss: 0.9680\n",
      "[1604/1762] D loss: 1.3867, G loss: 0.6953\n",
      "[1684/1762] D loss: 1.3878, G loss: 0.6606\n",
      "[1762/1762] D loss: 0.7521, G loss: 1.5028\n",
      "train error: \n",
      " D loss: 1.304123, G loss: 0.865875, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.294919, G loss: 0.919791, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3879, G loss: 0.7304\n",
      "[84/1762] D loss: 1.3925, G loss: 0.6259\n",
      "[164/1762] D loss: 1.3864, G loss: 0.7019\n",
      "[244/1762] D loss: 1.3871, G loss: 0.7091\n",
      "[324/1762] D loss: 1.3867, G loss: 0.6794\n",
      "[404/1762] D loss: 1.3896, G loss: 0.6852\n",
      "[484/1762] D loss: 1.0428, G loss: 1.6915\n",
      "[564/1762] D loss: 1.0612, G loss: 1.1399\n",
      "[644/1762] D loss: 1.0589, G loss: 1.2518\n",
      "[724/1762] D loss: 0.7096, G loss: 2.3798\n",
      "[804/1762] D loss: 1.3866, G loss: 0.6959\n",
      "[884/1762] D loss: 1.3873, G loss: 0.6852\n",
      "[964/1762] D loss: 1.0443, G loss: 1.5552\n",
      "[1044/1762] D loss: 1.3900, G loss: 0.6495\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.6922\n",
      "[1204/1762] D loss: 1.0609, G loss: 1.1576\n",
      "[1284/1762] D loss: 1.3872, G loss: 0.6851\n",
      "[1364/1762] D loss: 1.3878, G loss: 0.7248\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.6691\n",
      "[1524/1762] D loss: 1.2202, G loss: 1.3359\n",
      "[1604/1762] D loss: 1.3879, G loss: 0.6880\n",
      "[1684/1762] D loss: 1.3880, G loss: 0.6565\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6803\n",
      "train error: \n",
      " D loss: 1.299523, G loss: 0.894453, D accuracy: 54.0%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.290472, G loss: 0.966187, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2129, G loss: 1.2306\n",
      "[84/1762] D loss: 1.3881, G loss: 0.6883\n",
      "[164/1762] D loss: 1.3862, G loss: 0.6863\n",
      "[244/1762] D loss: 1.3859, G loss: 0.6899\n",
      "[324/1762] D loss: 1.3898, G loss: 0.7061\n",
      "[404/1762] D loss: 1.3858, G loss: 0.6840\n",
      "[484/1762] D loss: 1.3866, G loss: 0.6856\n",
      "[564/1762] D loss: 1.3862, G loss: 0.6866\n",
      "[644/1762] D loss: 1.3860, G loss: 0.6714\n",
      "[724/1762] D loss: 1.7075, G loss: 1.1933\n",
      "[804/1762] D loss: 1.3862, G loss: 0.6947\n",
      "[884/1762] D loss: 1.3893, G loss: 0.7272\n",
      "[964/1762] D loss: 1.3861, G loss: 0.6932\n",
      "[1044/1762] D loss: 1.3881, G loss: 0.6599\n",
      "[1124/1762] D loss: 1.3888, G loss: 0.7380\n",
      "[1204/1762] D loss: 1.3892, G loss: 0.6825\n",
      "[1284/1762] D loss: 1.3880, G loss: 0.6957\n",
      "[1364/1762] D loss: 1.3867, G loss: 0.6736\n",
      "[1444/1762] D loss: 1.3876, G loss: 0.7072\n",
      "[1524/1762] D loss: 1.3879, G loss: 0.6964\n",
      "[1604/1762] D loss: 1.3871, G loss: 0.7055\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.6908\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.7050\n",
      "train error: \n",
      " D loss: 1.302999, G loss: 0.875140, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.293517, G loss: 0.921725, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.7004\n",
      "[84/1762] D loss: 1.3860, G loss: 0.6833\n",
      "[164/1762] D loss: 1.3873, G loss: 0.6894\n",
      "[244/1762] D loss: 1.0463, G loss: 1.5256\n",
      "[324/1762] D loss: 1.3869, G loss: 0.7091\n",
      "[404/1762] D loss: 1.3870, G loss: 0.6795\n",
      "[484/1762] D loss: 1.3866, G loss: 0.6867\n",
      "[564/1762] D loss: 1.3860, G loss: 0.6984\n",
      "[644/1762] D loss: 1.3886, G loss: 0.6692\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6926\n",
      "[804/1762] D loss: 1.3866, G loss: 0.6900\n",
      "[884/1762] D loss: 1.2082, G loss: 1.5721\n",
      "[964/1762] D loss: 1.0486, G loss: 1.3782\n",
      "[1044/1762] D loss: 1.3869, G loss: 0.6840\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.6831\n",
      "[1204/1762] D loss: 1.0527, G loss: 1.3030\n",
      "[1284/1762] D loss: 1.3852, G loss: 0.6870\n",
      "[1364/1762] D loss: 1.3882, G loss: 0.7254\n",
      "[1444/1762] D loss: 1.0599, G loss: 1.1694\n",
      "[1524/1762] D loss: 1.3870, G loss: 0.6772\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6926\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6954\n",
      "[1762/1762] D loss: 0.7517, G loss: 1.4239\n",
      "train error: \n",
      " D loss: 1.305035, G loss: 0.815588, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.296225, G loss: 0.844520, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3874, G loss: 0.6862\n",
      "[84/1762] D loss: 1.3880, G loss: 0.7363\n",
      "[164/1762] D loss: 1.3869, G loss: 0.6769\n",
      "[244/1762] D loss: 1.3867, G loss: 0.6734\n",
      "[324/1762] D loss: 1.3868, G loss: 0.6802\n",
      "[404/1762] D loss: 1.0421, G loss: 1.8317\n",
      "[484/1762] D loss: 1.0455, G loss: 1.4594\n",
      "[564/1762] D loss: 1.3865, G loss: 0.6865\n",
      "[644/1762] D loss: 1.3866, G loss: 0.6957\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6867\n",
      "[804/1762] D loss: 1.3873, G loss: 0.6782\n",
      "[884/1762] D loss: 1.0493, G loss: 1.3686\n",
      "[964/1762] D loss: 1.0380, G loss: 1.7564\n",
      "[1044/1762] D loss: 1.0448, G loss: 1.6519\n",
      "[1124/1762] D loss: 0.7365, G loss: 1.8815\n",
      "[1204/1762] D loss: 1.3865, G loss: 0.7069\n",
      "[1284/1762] D loss: 1.3870, G loss: 0.6833\n",
      "[1364/1762] D loss: 1.1529, G loss: 1.1426\n",
      "[1444/1762] D loss: 1.3874, G loss: 0.6732\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.7128\n",
      "[1604/1762] D loss: 1.0528, G loss: 1.2637\n",
      "[1684/1762] D loss: 1.4108, G loss: 1.5107\n",
      "[1762/1762] D loss: 1.3870, G loss: 0.7177\n",
      "train error: \n",
      " D loss: 1.305783, G loss: 0.840569, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 92.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.299188, G loss: 0.886213, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2926, G loss: 1.4588\n",
      "[84/1762] D loss: 1.0619, G loss: 1.1487\n",
      "[164/1762] D loss: 1.3864, G loss: 0.6991\n",
      "[244/1762] D loss: 1.3864, G loss: 0.7000\n",
      "[324/1762] D loss: 1.3865, G loss: 0.7019\n",
      "[404/1762] D loss: 1.3863, G loss: 0.6872\n",
      "[484/1762] D loss: 1.3869, G loss: 0.7074\n",
      "[564/1762] D loss: 1.3894, G loss: 0.6556\n",
      "[644/1762] D loss: 1.3871, G loss: 0.6704\n",
      "[724/1762] D loss: 0.7463, G loss: 1.4737\n",
      "[804/1762] D loss: 1.3868, G loss: 0.7147\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6862\n",
      "[964/1762] D loss: 1.3863, G loss: 0.7012\n",
      "[1044/1762] D loss: 1.3867, G loss: 0.6813\n",
      "[1124/1762] D loss: 1.3858, G loss: 0.7048\n",
      "[1204/1762] D loss: 1.3862, G loss: 0.6812\n",
      "[1284/1762] D loss: 1.3857, G loss: 0.6830\n",
      "[1364/1762] D loss: 1.0519, G loss: 1.2940\n",
      "[1444/1762] D loss: 1.3851, G loss: 0.6809\n",
      "[1524/1762] D loss: 1.3717, G loss: 0.7332\n",
      "[1604/1762] D loss: 1.3877, G loss: 0.7375\n",
      "[1684/1762] D loss: 1.3888, G loss: 0.6847\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.6880\n",
      "train error: \n",
      " D loss: 1.306273, G loss: 0.822531, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 90.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.298877, G loss: 0.874915, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3867, G loss: 0.6818\n",
      "[84/1762] D loss: 1.3896, G loss: 0.7308\n",
      "[164/1762] D loss: 1.3895, G loss: 0.7022\n",
      "[244/1762] D loss: 1.3867, G loss: 0.6847\n",
      "[324/1762] D loss: 1.3850, G loss: 0.7101\n",
      "[404/1762] D loss: 1.3867, G loss: 0.6787\n",
      "[484/1762] D loss: 0.7134, G loss: 2.0050\n",
      "[564/1762] D loss: 1.3812, G loss: 0.7205\n",
      "[644/1762] D loss: 1.3875, G loss: 0.6640\n",
      "[724/1762] D loss: 1.3877, G loss: 0.7303\n",
      "[804/1762] D loss: 1.0479, G loss: 1.3795\n",
      "[884/1762] D loss: 1.0484, G loss: 1.3521\n",
      "[964/1762] D loss: 1.3869, G loss: 0.6716\n",
      "[1044/1762] D loss: 1.0593, G loss: 1.1682\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.7026\n",
      "[1204/1762] D loss: 1.3866, G loss: 0.7022\n",
      "[1284/1762] D loss: 1.3887, G loss: 0.7151\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6948\n",
      "[1444/1762] D loss: 1.3873, G loss: 0.7036\n",
      "[1524/1762] D loss: 1.0471, G loss: 1.5509\n",
      "[1604/1762] D loss: 1.3865, G loss: 0.7023\n",
      "[1684/1762] D loss: 1.3873, G loss: 0.6931\n",
      "[1762/1762] D loss: 1.3871, G loss: 0.6988\n",
      "train error: \n",
      " D loss: 1.292260, G loss: 0.909613, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.267958, G loss: 0.971339, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3862, G loss: 0.7069\n",
      "[84/1762] D loss: 1.3866, G loss: 0.6769\n",
      "[164/1762] D loss: 1.3863, G loss: 0.7038\n",
      "[244/1762] D loss: 1.3867, G loss: 0.6855\n",
      "[324/1762] D loss: 1.3865, G loss: 0.7044\n",
      "[404/1762] D loss: 1.0426, G loss: 1.6835\n",
      "[484/1762] D loss: 1.3862, G loss: 0.6868\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6973\n",
      "[644/1762] D loss: 1.3868, G loss: 0.6996\n",
      "[724/1762] D loss: 1.3870, G loss: 0.7113\n",
      "[804/1762] D loss: 1.2360, G loss: 1.0532\n",
      "[884/1762] D loss: 1.3955, G loss: 0.6281\n",
      "[964/1762] D loss: 1.3861, G loss: 0.7710\n",
      "[1044/1762] D loss: 1.0499, G loss: 1.3691\n",
      "[1124/1762] D loss: 1.4030, G loss: 0.7774\n",
      "[1204/1762] D loss: 1.3874, G loss: 0.6675\n",
      "[1284/1762] D loss: 1.4154, G loss: 0.5649\n",
      "[1364/1762] D loss: 1.1038, G loss: 0.8761\n",
      "[1444/1762] D loss: 1.3861, G loss: 0.6855\n",
      "[1524/1762] D loss: 1.3717, G loss: 0.7210\n",
      "[1604/1762] D loss: 1.3873, G loss: 0.6939\n",
      "[1684/1762] D loss: 1.3895, G loss: 0.7405\n",
      "[1762/1762] D loss: 1.3825, G loss: 0.7011\n",
      "train error: \n",
      " D loss: 1.293617, G loss: 0.912486, D accuracy: 55.5%, cell accuracy: 99.7%, board accuracy: 82.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.286553, G loss: 1.029034, D accuracy: 56.1%, cell accuracy: 99.7%, board accuracy: 79.5% \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3803, G loss: 0.6720\n",
      "[84/1762] D loss: 1.3770, G loss: 0.6766\n",
      "[164/1762] D loss: 1.0766, G loss: 1.0125\n",
      "[244/1762] D loss: 1.3882, G loss: 0.6683\n",
      "[324/1762] D loss: 1.3864, G loss: 0.6946\n",
      "[404/1762] D loss: 1.3931, G loss: 0.7322\n",
      "[484/1762] D loss: 1.3875, G loss: 0.6755\n",
      "[564/1762] D loss: 1.0514, G loss: 1.2990\n",
      "[644/1762] D loss: 1.0455, G loss: 1.5137\n",
      "[724/1762] D loss: 1.3927, G loss: 0.6312\n",
      "[804/1762] D loss: 0.7065, G loss: 2.2226\n",
      "[884/1762] D loss: 1.3875, G loss: 0.7074\n",
      "[964/1762] D loss: 1.0503, G loss: 1.3424\n",
      "[1044/1762] D loss: 1.0466, G loss: 1.5631\n",
      "[1124/1762] D loss: 1.3867, G loss: 0.6866\n",
      "[1204/1762] D loss: 1.3881, G loss: 0.7052\n",
      "[1284/1762] D loss: 1.3860, G loss: 0.6894\n",
      "[1364/1762] D loss: 1.0422, G loss: 1.6548\n",
      "[1444/1762] D loss: 1.3883, G loss: 0.7057\n",
      "[1524/1762] D loss: 1.1853, G loss: 1.5006\n",
      "[1604/1762] D loss: 1.0417, G loss: 1.7191\n",
      "[1684/1762] D loss: 1.3874, G loss: 0.6625\n",
      "[1762/1762] D loss: 1.3846, G loss: 0.6846\n",
      "train error: \n",
      " D loss: 1.290603, G loss: 0.924249, D accuracy: 54.1%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.266657, G loss: 1.005149, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3859, G loss: 0.7050\n",
      "[84/1762] D loss: 1.3859, G loss: 0.6950\n",
      "[164/1762] D loss: 1.0929, G loss: 0.9491\n",
      "[244/1762] D loss: 1.0430, G loss: 1.6363\n",
      "[324/1762] D loss: 1.2128, G loss: 1.3552\n",
      "[404/1762] D loss: 1.3993, G loss: 0.6210\n",
      "[484/1762] D loss: 1.0456, G loss: 1.5568\n",
      "[564/1762] D loss: 1.3856, G loss: 0.6919\n",
      "[644/1762] D loss: 1.3883, G loss: 0.6665\n",
      "[724/1762] D loss: 1.0463, G loss: 1.9772\n",
      "[804/1762] D loss: 1.0436, G loss: 1.5698\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6861\n",
      "[964/1762] D loss: 1.3873, G loss: 0.6905\n",
      "[1044/1762] D loss: 1.0427, G loss: 1.6543\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.6862\n",
      "[1204/1762] D loss: 1.3875, G loss: 0.6907\n",
      "[1284/1762] D loss: 1.3861, G loss: 0.6932\n",
      "[1364/1762] D loss: 1.3887, G loss: 0.6940\n",
      "[1444/1762] D loss: 1.3886, G loss: 0.7362\n",
      "[1524/1762] D loss: 1.3949, G loss: 0.7147\n",
      "[1604/1762] D loss: 1.0889, G loss: 0.9812\n",
      "[1684/1762] D loss: 1.3883, G loss: 0.7277\n",
      "[1762/1762] D loss: 1.3875, G loss: 0.7270\n",
      "train error: \n",
      " D loss: 1.305991, G loss: 0.947747, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.304798, G loss: 1.038605, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3867, G loss: 0.7001\n",
      "[84/1762] D loss: 1.3886, G loss: 0.7133\n",
      "[164/1762] D loss: 1.3832, G loss: 0.6637\n",
      "[244/1762] D loss: 1.3829, G loss: 0.6991\n",
      "[324/1762] D loss: 1.0417, G loss: 2.0617\n",
      "[404/1762] D loss: 1.3816, G loss: 0.7498\n",
      "[484/1762] D loss: 1.3873, G loss: 0.6853\n",
      "[564/1762] D loss: 1.0422, G loss: 1.7040\n",
      "[644/1762] D loss: 1.3885, G loss: 0.6705\n",
      "[724/1762] D loss: 1.0499, G loss: 1.3216\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6852\n",
      "[884/1762] D loss: 1.3744, G loss: 0.6262\n",
      "[964/1762] D loss: 1.3865, G loss: 0.7058\n",
      "[1044/1762] D loss: 1.3867, G loss: 0.7214\n",
      "[1124/1762] D loss: 1.6182, G loss: 1.0134\n",
      "[1204/1762] D loss: 1.3882, G loss: 0.7118\n",
      "[1284/1762] D loss: 1.3866, G loss: 0.6792\n",
      "[1364/1762] D loss: 1.3866, G loss: 0.6887\n",
      "[1444/1762] D loss: 1.3876, G loss: 0.7041\n",
      "[1524/1762] D loss: 1.3862, G loss: 1.6068\n",
      "[1604/1762] D loss: 1.3865, G loss: 0.6898\n",
      "[1684/1762] D loss: 1.7425, G loss: 1.1890\n",
      "[1762/1762] D loss: 1.3862, G loss: 0.6981\n",
      "train error: \n",
      " D loss: 1.301358, G loss: 0.872979, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.298807, G loss: 0.925514, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0456, G loss: 1.4933\n",
      "[84/1762] D loss: 1.3854, G loss: 0.6907\n",
      "[164/1762] D loss: 1.0448, G loss: 2.1404\n",
      "[244/1762] D loss: 1.3937, G loss: 0.6997\n",
      "[324/1762] D loss: 1.3886, G loss: 0.7374\n",
      "[404/1762] D loss: 1.0410, G loss: 2.7096\n",
      "[484/1762] D loss: 1.3840, G loss: 0.6788\n",
      "[564/1762] D loss: 1.3870, G loss: 0.6768\n",
      "[644/1762] D loss: 1.3884, G loss: 0.7250\n",
      "[724/1762] D loss: 1.3874, G loss: 0.6716\n",
      "[804/1762] D loss: 1.3844, G loss: 0.6780\n",
      "[884/1762] D loss: 1.0710, G loss: 1.1271\n",
      "[964/1762] D loss: 1.0695, G loss: 1.0417\n",
      "[1044/1762] D loss: 1.0496, G loss: 1.4195\n",
      "[1124/1762] D loss: 1.3862, G loss: 0.6964\n",
      "[1204/1762] D loss: 1.0429, G loss: 2.0785\n",
      "[1284/1762] D loss: 1.3874, G loss: 0.7070\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6832\n",
      "[1444/1762] D loss: 1.0555, G loss: 1.1080\n",
      "[1524/1762] D loss: 1.3854, G loss: 0.6874\n",
      "[1604/1762] D loss: 1.3878, G loss: 0.6809\n",
      "[1684/1762] D loss: 1.3867, G loss: 0.6818\n",
      "[1762/1762] D loss: 1.8410, G loss: 1.3542\n",
      "train error: \n",
      " D loss: 1.305710, G loss: 0.820152, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.296251, G loss: 0.867624, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3867, G loss: 0.6830\n",
      "[84/1762] D loss: 1.3868, G loss: 0.6987\n",
      "[164/1762] D loss: 1.3866, G loss: 0.7023\n",
      "[244/1762] D loss: 1.3865, G loss: 0.6772\n",
      "[324/1762] D loss: 1.3871, G loss: 0.6942\n",
      "[404/1762] D loss: 1.3870, G loss: 0.7106\n",
      "[484/1762] D loss: 1.3860, G loss: 0.6670\n",
      "[564/1762] D loss: 1.3872, G loss: 0.6850\n",
      "[644/1762] D loss: 1.3877, G loss: 0.6954\n",
      "[724/1762] D loss: 1.3867, G loss: 0.6810\n",
      "[804/1762] D loss: 1.3991, G loss: 0.6305\n",
      "[884/1762] D loss: 1.3860, G loss: 0.6780\n",
      "[964/1762] D loss: 1.3886, G loss: 0.7256\n",
      "[1044/1762] D loss: 1.3865, G loss: 0.6838\n",
      "[1124/1762] D loss: 1.3867, G loss: 0.6908\n",
      "[1204/1762] D loss: 1.3865, G loss: 0.6882\n",
      "[1284/1762] D loss: 1.3848, G loss: 0.6959\n",
      "[1364/1762] D loss: 1.3893, G loss: 0.6857\n",
      "[1444/1762] D loss: 1.3899, G loss: 0.6341\n",
      "[1524/1762] D loss: 1.3793, G loss: 0.7107\n",
      "[1604/1762] D loss: 1.3851, G loss: 0.6905\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.6843\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.6903\n",
      "train error: \n",
      " D loss: 1.301228, G loss: 0.865871, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 90.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.299367, G loss: 0.926144, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3803, G loss: 0.6670\n",
      "[84/1762] D loss: 1.0562, G loss: 1.5306\n",
      "[164/1762] D loss: 1.3751, G loss: 0.7033\n",
      "[244/1762] D loss: 1.3869, G loss: 0.7266\n",
      "[324/1762] D loss: 1.3852, G loss: 0.6860\n",
      "[404/1762] D loss: 1.0590, G loss: 1.1787\n",
      "[484/1762] D loss: 1.3951, G loss: 0.7232\n",
      "[564/1762] D loss: 1.1973, G loss: 1.4756\n",
      "[644/1762] D loss: 1.3917, G loss: 0.7630\n",
      "[724/1762] D loss: 1.0578, G loss: 1.2341\n",
      "[804/1762] D loss: 1.4068, G loss: 0.5947\n",
      "[884/1762] D loss: 1.3823, G loss: 0.6816\n",
      "[964/1762] D loss: 1.3878, G loss: 0.7083\n",
      "[1044/1762] D loss: 1.3877, G loss: 0.6909\n",
      "[1124/1762] D loss: 1.0522, G loss: 1.2867\n",
      "[1204/1762] D loss: 1.3919, G loss: 0.6945\n",
      "[1284/1762] D loss: 1.0676, G loss: 1.1364\n",
      "[1364/1762] D loss: 1.3861, G loss: 0.6713\n",
      "[1444/1762] D loss: 1.3955, G loss: 0.6311\n",
      "[1524/1762] D loss: 1.3870, G loss: 0.7056\n",
      "[1604/1762] D loss: 1.3866, G loss: 0.6798\n",
      "[1684/1762] D loss: 1.3842, G loss: 0.6892\n",
      "[1762/1762] D loss: 1.3818, G loss: 0.6663\n",
      "train error: \n",
      " D loss: 1.302526, G loss: 0.823569, D accuracy: 54.1%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.297917, G loss: 0.879094, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0714, G loss: 1.0350\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6791\n",
      "[164/1762] D loss: 1.3861, G loss: 0.6903\n",
      "[244/1762] D loss: 1.0389, G loss: 1.8177\n",
      "[324/1762] D loss: 1.3858, G loss: 0.6730\n",
      "[404/1762] D loss: 1.3821, G loss: 0.7127\n",
      "[484/1762] D loss: 0.7206, G loss: 1.9019\n",
      "[564/1762] D loss: 1.3810, G loss: 0.7069\n",
      "[644/1762] D loss: 1.3772, G loss: 1.6611\n",
      "[724/1762] D loss: 1.3856, G loss: 0.7171\n",
      "[804/1762] D loss: 1.3812, G loss: 0.6423\n",
      "[884/1762] D loss: 1.3846, G loss: 0.6999\n",
      "[964/1762] D loss: 1.3860, G loss: 0.8767\n",
      "[1044/1762] D loss: 1.3870, G loss: 0.6656\n",
      "[1124/1762] D loss: 1.3891, G loss: 0.7329\n",
      "[1204/1762] D loss: 1.3858, G loss: 0.6971\n",
      "[1284/1762] D loss: 1.0677, G loss: 1.0878\n",
      "[1364/1762] D loss: 1.3813, G loss: 0.6920\n",
      "[1444/1762] D loss: 1.3924, G loss: 0.7592\n",
      "[1524/1762] D loss: 1.3868, G loss: 0.6903\n",
      "[1604/1762] D loss: 1.3867, G loss: 0.7025\n",
      "[1684/1762] D loss: 1.3829, G loss: 0.7029\n",
      "[1762/1762] D loss: 1.3869, G loss: 0.6658\n",
      "train error: \n",
      " D loss: 1.303500, G loss: 0.912251, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.305769, G loss: 1.005758, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0569, G loss: 1.1852\n",
      "[84/1762] D loss: 1.3876, G loss: 0.6830\n",
      "[164/1762] D loss: 1.3869, G loss: 0.6730\n",
      "[244/1762] D loss: 1.3932, G loss: 0.6964\n",
      "[324/1762] D loss: 1.3875, G loss: 0.6952\n",
      "[404/1762] D loss: 0.7346, G loss: 1.5879\n",
      "[484/1762] D loss: 1.3863, G loss: 0.6931\n",
      "[564/1762] D loss: 1.3878, G loss: 0.7135\n",
      "[644/1762] D loss: 1.0530, G loss: 1.2674\n",
      "[724/1762] D loss: 1.3889, G loss: 0.6647\n",
      "[804/1762] D loss: 0.7190, G loss: 1.8680\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6836\n",
      "[964/1762] D loss: 1.0627, G loss: 1.1237\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.6549\n",
      "[1124/1762] D loss: 1.4384, G loss: 0.6262\n",
      "[1204/1762] D loss: 1.3873, G loss: 0.6414\n",
      "[1284/1762] D loss: 1.3861, G loss: 0.6624\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6841\n",
      "[1444/1762] D loss: 1.3880, G loss: 0.7306\n",
      "[1524/1762] D loss: 1.3872, G loss: 0.6912\n",
      "[1604/1762] D loss: 1.3691, G loss: 0.7171\n",
      "[1684/1762] D loss: 0.7012, G loss: 2.6512\n",
      "[1762/1762] D loss: 1.1123, G loss: 1.4514\n",
      "train error: \n",
      " D loss: 1.289999, G loss: 0.957326, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.282647, G loss: 1.041389, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3838, G loss: 0.6822\n",
      "[84/1762] D loss: 1.3868, G loss: 0.7353\n",
      "[164/1762] D loss: 1.3868, G loss: 0.6892\n",
      "[244/1762] D loss: 1.0439, G loss: 1.6607\n",
      "[324/1762] D loss: 1.3849, G loss: 0.6790\n",
      "[404/1762] D loss: 1.3879, G loss: 0.7059\n",
      "[484/1762] D loss: 1.3862, G loss: 0.6906\n",
      "[564/1762] D loss: 1.3949, G loss: 0.7637\n",
      "[644/1762] D loss: 1.3757, G loss: 0.7001\n",
      "[724/1762] D loss: 1.3867, G loss: 0.6760\n",
      "[804/1762] D loss: 1.3872, G loss: 0.7441\n",
      "[884/1762] D loss: 1.3815, G loss: 0.6986\n",
      "[964/1762] D loss: 1.3858, G loss: 0.6980\n",
      "[1044/1762] D loss: 1.3870, G loss: 0.6989\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6741\n",
      "[1204/1762] D loss: 1.3851, G loss: 0.6666\n",
      "[1284/1762] D loss: 1.3682, G loss: 0.6995\n",
      "[1364/1762] D loss: 1.3880, G loss: 0.7117\n",
      "[1444/1762] D loss: 1.3874, G loss: 0.6753\n",
      "[1524/1762] D loss: 1.3876, G loss: 0.7102\n",
      "[1604/1762] D loss: 1.0405, G loss: 2.2932\n",
      "[1684/1762] D loss: 1.3953, G loss: 0.6494\n",
      "[1762/1762] D loss: 1.3868, G loss: 0.6857\n",
      "train error: \n",
      " D loss: 1.302813, G loss: 0.862977, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.301876, G loss: 0.920303, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 91.1% \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0693, G loss: 1.0490\n",
      "[84/1762] D loss: 1.3870, G loss: 0.6933\n",
      "[164/1762] D loss: 1.0685, G loss: 1.0936\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6987\n",
      "[324/1762] D loss: 1.3866, G loss: 0.6734\n",
      "[404/1762] D loss: 1.0521, G loss: 1.3178\n",
      "[484/1762] D loss: 1.3866, G loss: 0.6898\n",
      "[564/1762] D loss: 1.3865, G loss: 0.6878\n",
      "[644/1762] D loss: 1.3860, G loss: 0.7039\n",
      "[724/1762] D loss: 1.3861, G loss: 0.6826\n",
      "[804/1762] D loss: 1.0549, G loss: 1.2459\n",
      "[884/1762] D loss: 1.3870, G loss: 0.6777\n",
      "[964/1762] D loss: 1.3883, G loss: 0.7093\n",
      "[1044/1762] D loss: 1.3861, G loss: 0.7029\n",
      "[1124/1762] D loss: 1.0398, G loss: 1.8834\n",
      "[1204/1762] D loss: 1.3771, G loss: 0.6925\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.7148\n",
      "[1364/1762] D loss: 1.3868, G loss: 0.7040\n",
      "[1444/1762] D loss: 1.0423, G loss: 1.5003\n",
      "[1524/1762] D loss: 1.3837, G loss: 0.6969\n",
      "[1604/1762] D loss: 1.3876, G loss: 0.7244\n",
      "[1684/1762] D loss: 1.3839, G loss: 0.6590\n",
      "[1762/1762] D loss: 1.3913, G loss: 0.7467\n",
      "train error: \n",
      " D loss: 1.306002, G loss: 0.847480, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.302844, G loss: 0.894901, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0701, G loss: 1.1404\n",
      "[84/1762] D loss: 1.3869, G loss: 0.6751\n",
      "[164/1762] D loss: 1.3871, G loss: 0.7010\n",
      "[244/1762] D loss: 1.3877, G loss: 0.6734\n",
      "[324/1762] D loss: 1.3872, G loss: 0.7046\n",
      "[404/1762] D loss: 0.6594, G loss: 2.4924\n",
      "[484/1762] D loss: 1.3949, G loss: 0.6677\n",
      "[564/1762] D loss: 1.3894, G loss: 0.7204\n",
      "[644/1762] D loss: 1.3875, G loss: 0.6953\n",
      "[724/1762] D loss: 1.3861, G loss: 0.6953\n",
      "[804/1762] D loss: 1.3904, G loss: 0.6493\n",
      "[884/1762] D loss: 1.3875, G loss: 0.6713\n",
      "[964/1762] D loss: 1.0424, G loss: 1.8389\n",
      "[1044/1762] D loss: 1.3880, G loss: 0.7163\n",
      "[1124/1762] D loss: 1.3868, G loss: 0.6731\n",
      "[1204/1762] D loss: 1.3861, G loss: 0.6733\n",
      "[1284/1762] D loss: 1.3865, G loss: 0.6884\n",
      "[1364/1762] D loss: 1.3867, G loss: 0.7060\n",
      "[1444/1762] D loss: 0.7031, G loss: 2.5027\n",
      "[1524/1762] D loss: 1.3891, G loss: 0.7018\n",
      "[1604/1762] D loss: 1.3878, G loss: 0.7276\n",
      "[1684/1762] D loss: 1.0422, G loss: 1.7531\n",
      "[1762/1762] D loss: 0.6946, G loss: 3.2620\n",
      "train error: \n",
      " D loss: 1.305209, G loss: 0.994244, D accuracy: 53.4%, cell accuracy: 99.9%, board accuracy: 93.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.316512, G loss: 1.110772, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 91.1% \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3877, G loss: 0.6964\n",
      "[84/1762] D loss: 1.3872, G loss: 0.6896\n",
      "[164/1762] D loss: 1.3860, G loss: 0.6978\n",
      "[244/1762] D loss: 1.0478, G loss: 1.4449\n",
      "[324/1762] D loss: 1.4537, G loss: 0.6629\n",
      "[404/1762] D loss: 1.3869, G loss: 0.6717\n",
      "[484/1762] D loss: 1.3877, G loss: 0.7022\n",
      "[564/1762] D loss: 1.3885, G loss: 0.6549\n",
      "[644/1762] D loss: 1.3864, G loss: 0.6957\n",
      "[724/1762] D loss: 1.0718, G loss: 1.0553\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6954\n",
      "[884/1762] D loss: 1.3867, G loss: 0.7148\n",
      "[964/1762] D loss: 1.3858, G loss: 0.6963\n",
      "[1044/1762] D loss: 1.3858, G loss: 0.7000\n",
      "[1124/1762] D loss: 0.7104, G loss: 2.4914\n",
      "[1204/1762] D loss: 1.3870, G loss: 0.6854\n",
      "[1284/1762] D loss: 1.3861, G loss: 0.6751\n",
      "[1364/1762] D loss: 1.3868, G loss: 0.6918\n",
      "[1444/1762] D loss: 1.3850, G loss: 0.7280\n",
      "[1524/1762] D loss: 1.0595, G loss: 1.1855\n",
      "[1604/1762] D loss: 1.3850, G loss: 0.7119\n",
      "[1684/1762] D loss: 1.7305, G loss: 1.1523\n",
      "[1762/1762] D loss: 1.3873, G loss: 0.7009\n",
      "train error: \n",
      " D loss: 1.303150, G loss: 0.924109, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 93.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.304401, G loss: 1.021156, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 91.1% \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.7067\n",
      "[84/1762] D loss: 1.3837, G loss: 0.6689\n",
      "[164/1762] D loss: 1.3872, G loss: 0.6988\n",
      "[244/1762] D loss: 1.3888, G loss: 0.6441\n",
      "[324/1762] D loss: 1.3893, G loss: 0.6310\n",
      "[404/1762] D loss: 1.3871, G loss: 0.7068\n",
      "[484/1762] D loss: 1.3874, G loss: 0.6856\n",
      "[564/1762] D loss: 1.3792, G loss: 0.7361\n",
      "[644/1762] D loss: 1.0798, G loss: 1.0255\n",
      "[724/1762] D loss: 1.3711, G loss: 0.6667\n",
      "[804/1762] D loss: 1.4004, G loss: 0.5853\n",
      "[884/1762] D loss: 1.3863, G loss: 0.7136\n",
      "[964/1762] D loss: 1.3873, G loss: 0.6544\n",
      "[1044/1762] D loss: 1.0427, G loss: 1.6594\n",
      "[1124/1762] D loss: 1.0532, G loss: 1.3905\n",
      "[1204/1762] D loss: 1.0519, G loss: 1.9160\n",
      "[1284/1762] D loss: 1.3876, G loss: 0.7010\n",
      "[1364/1762] D loss: 1.3746, G loss: 0.6998\n",
      "[1444/1762] D loss: 1.1941, G loss: 1.7738\n",
      "[1524/1762] D loss: 0.9965, G loss: 1.6720\n",
      "[1604/1762] D loss: 1.4015, G loss: 0.7246\n",
      "[1684/1762] D loss: 1.3924, G loss: 0.7059\n",
      "[1762/1762] D loss: 1.3906, G loss: 0.6317\n",
      "train error: \n",
      " D loss: 1.291823, G loss: 0.934585, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 82.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.273200, G loss: 1.007601, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 79.8% \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0418, G loss: 1.7443\n",
      "[84/1762] D loss: 1.1411, G loss: 1.3853\n",
      "[164/1762] D loss: 1.3865, G loss: 0.6977\n",
      "[244/1762] D loss: 1.3877, G loss: 0.7149\n",
      "[324/1762] D loss: 1.0450, G loss: 1.5684\n",
      "[404/1762] D loss: 1.0394, G loss: 2.1028\n",
      "[484/1762] D loss: 1.3763, G loss: 0.7036\n",
      "[564/1762] D loss: 1.2306, G loss: 1.1219\n",
      "[644/1762] D loss: 1.3856, G loss: 0.7433\n",
      "[724/1762] D loss: 1.3879, G loss: 0.6751\n",
      "[804/1762] D loss: 1.3816, G loss: 0.7045\n",
      "[884/1762] D loss: 1.3875, G loss: 0.6801\n",
      "[964/1762] D loss: 1.0539, G loss: 1.3978\n",
      "[1044/1762] D loss: 1.3173, G loss: 0.7923\n",
      "[1124/1762] D loss: 1.3880, G loss: 0.6777\n",
      "[1204/1762] D loss: 1.3851, G loss: 0.6820\n",
      "[1284/1762] D loss: 1.3954, G loss: 0.6987\n",
      "[1364/1762] D loss: 1.3078, G loss: 0.8372\n",
      "[1444/1762] D loss: 1.3548, G loss: 0.6272\n",
      "[1524/1762] D loss: 1.3346, G loss: 1.4044\n",
      "[1604/1762] D loss: 1.0497, G loss: 1.2938\n",
      "[1684/1762] D loss: 1.0529, G loss: 1.4622\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.6868\n",
      "train error: \n",
      " D loss: 1.295122, G loss: 0.886908, D accuracy: 54.0%, cell accuracy: 99.9%, board accuracy: 88.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.269998, G loss: 0.943291, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3849, G loss: 0.6800\n",
      "[84/1762] D loss: 1.0805, G loss: 1.4773\n",
      "[164/1762] D loss: 1.3884, G loss: 0.7265\n",
      "[244/1762] D loss: 1.3877, G loss: 0.6790\n",
      "[324/1762] D loss: 1.3885, G loss: 0.6742\n",
      "[404/1762] D loss: 1.3860, G loss: 0.6789\n",
      "[484/1762] D loss: 1.3870, G loss: 0.6850\n",
      "[564/1762] D loss: 1.3888, G loss: 0.7112\n",
      "[644/1762] D loss: 1.3758, G loss: 0.7046\n",
      "[724/1762] D loss: 1.3865, G loss: 0.6577\n",
      "[804/1762] D loss: 1.3869, G loss: 0.7060\n",
      "[884/1762] D loss: 1.3874, G loss: 0.6905\n",
      "[964/1762] D loss: 1.3797, G loss: 0.7218\n",
      "[1044/1762] D loss: 1.3837, G loss: 0.6584\n",
      "[1124/1762] D loss: 1.3785, G loss: 0.6720\n",
      "[1204/1762] D loss: 1.3868, G loss: 0.7222\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6773\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.7000\n",
      "[1444/1762] D loss: 1.3872, G loss: 0.7123\n",
      "[1524/1762] D loss: 1.3991, G loss: 0.7971\n",
      "[1604/1762] D loss: 1.3881, G loss: 0.6582\n",
      "[1684/1762] D loss: 1.0570, G loss: 1.2561\n",
      "[1762/1762] D loss: 1.3868, G loss: 0.6908\n",
      "train error: \n",
      " D loss: 1.290683, G loss: 0.895250, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.262419, G loss: 0.964487, D accuracy: 55.9%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3844, G loss: 0.6772\n",
      "[84/1762] D loss: 1.3189, G loss: 0.8025\n",
      "[164/1762] D loss: 1.3886, G loss: 0.6745\n",
      "[244/1762] D loss: 1.3893, G loss: 0.7133\n",
      "[324/1762] D loss: 1.3809, G loss: 0.6826\n",
      "[404/1762] D loss: 1.3696, G loss: 0.6968\n",
      "[484/1762] D loss: 1.3893, G loss: 0.6778\n",
      "[564/1762] D loss: 1.3850, G loss: 0.7048\n",
      "[644/1762] D loss: 1.3864, G loss: 0.6888\n",
      "[724/1762] D loss: 1.3882, G loss: 0.7316\n",
      "[804/1762] D loss: 1.0423, G loss: 2.5283\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6887\n",
      "[964/1762] D loss: 1.3880, G loss: 0.6899\n",
      "[1044/1762] D loss: 1.3872, G loss: 0.6942\n",
      "[1124/1762] D loss: 1.3875, G loss: 0.6688\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6942\n",
      "[1284/1762] D loss: 1.3853, G loss: 0.6951\n",
      "[1364/1762] D loss: 1.3937, G loss: 0.7444\n",
      "[1444/1762] D loss: 0.7089, G loss: 2.6674\n",
      "[1524/1762] D loss: 0.7155, G loss: 2.1193\n",
      "[1604/1762] D loss: 1.3905, G loss: 0.6372\n",
      "[1684/1762] D loss: 1.0534, G loss: 1.3337\n",
      "[1762/1762] D loss: 1.3882, G loss: 0.6885\n",
      "train error: \n",
      " D loss: 1.301958, G loss: 0.890579, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.293147, G loss: 0.928938, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3873, G loss: 0.6801\n",
      "[84/1762] D loss: 1.3862, G loss: 0.6920\n",
      "[164/1762] D loss: 1.3852, G loss: 0.6980\n",
      "[244/1762] D loss: 1.3873, G loss: 0.7164\n",
      "[324/1762] D loss: 1.3880, G loss: 0.6632\n",
      "[404/1762] D loss: 1.3884, G loss: 0.6595\n",
      "[484/1762] D loss: 1.0441, G loss: 1.5082\n",
      "[564/1762] D loss: 1.3882, G loss: 0.7198\n",
      "[644/1762] D loss: 1.3856, G loss: 0.6867\n",
      "[724/1762] D loss: 1.0556, G loss: 1.2378\n",
      "[804/1762] D loss: 1.0620, G loss: 1.1646\n",
      "[884/1762] D loss: 1.3859, G loss: 0.7061\n",
      "[964/1762] D loss: 1.3869, G loss: 0.6880\n",
      "[1044/1762] D loss: 0.7025, G loss: 2.4820\n",
      "[1124/1762] D loss: 1.3827, G loss: 0.7345\n",
      "[1204/1762] D loss: 1.3862, G loss: 0.6807\n",
      "[1284/1762] D loss: 1.3856, G loss: 0.7221\n",
      "[1364/1762] D loss: 1.3910, G loss: 0.6477\n",
      "[1444/1762] D loss: 1.3870, G loss: 0.6952\n",
      "[1524/1762] D loss: 1.3851, G loss: 0.6926\n",
      "[1604/1762] D loss: 1.0437, G loss: 1.6470\n",
      "[1684/1762] D loss: 1.3879, G loss: 0.6502\n",
      "[1762/1762] D loss: 1.3726, G loss: 0.6790\n",
      "train error: \n",
      " D loss: 1.308074, G loss: 0.811553, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 93.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.297262, G loss: 0.848864, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 91.6% \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0434, G loss: 1.5999\n",
      "[84/1762] D loss: 1.3855, G loss: 0.7040\n",
      "[164/1762] D loss: 1.0600, G loss: 1.1922\n",
      "[244/1762] D loss: 1.0385, G loss: 1.8421\n",
      "[324/1762] D loss: 1.3493, G loss: 0.7024\n",
      "[404/1762] D loss: 1.3869, G loss: 0.6927\n",
      "[484/1762] D loss: 1.0556, G loss: 1.2198\n",
      "[564/1762] D loss: 1.4065, G loss: 0.5837\n",
      "[644/1762] D loss: 1.3880, G loss: 0.7053\n",
      "[724/1762] D loss: 1.3875, G loss: 0.7281\n",
      "[804/1762] D loss: 1.0956, G loss: 0.8945\n",
      "[884/1762] D loss: 1.3869, G loss: 0.7025\n",
      "[964/1762] D loss: 1.0486, G loss: 1.3926\n",
      "[1044/1762] D loss: 1.3792, G loss: 0.7173\n",
      "[1124/1762] D loss: 1.0410, G loss: 1.8233\n",
      "[1204/1762] D loss: 1.3761, G loss: 0.7002\n",
      "[1284/1762] D loss: 1.3878, G loss: 0.6821\n",
      "[1364/1762] D loss: 1.3870, G loss: 0.7130\n",
      "[1444/1762] D loss: 1.0786, G loss: 0.9982\n",
      "[1524/1762] D loss: 1.3870, G loss: 0.6940\n",
      "[1604/1762] D loss: 1.3877, G loss: 0.6674\n",
      "[1684/1762] D loss: 1.3865, G loss: 0.7020\n",
      "[1762/1762] D loss: 1.3861, G loss: 0.6837\n",
      "train error: \n",
      " D loss: 1.301727, G loss: 0.882381, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.293806, G loss: 0.957721, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3866, G loss: 0.6785\n",
      "[84/1762] D loss: 1.3865, G loss: 0.6985\n",
      "[164/1762] D loss: 1.3889, G loss: 0.6744\n",
      "[244/1762] D loss: 1.3952, G loss: 0.5903\n",
      "[324/1762] D loss: 1.3906, G loss: 0.7514\n",
      "[404/1762] D loss: 1.3846, G loss: 0.6752\n",
      "[484/1762] D loss: 1.3860, G loss: 0.6976\n",
      "[564/1762] D loss: 1.3869, G loss: 0.7096\n",
      "[644/1762] D loss: 1.0679, G loss: 1.1201\n",
      "[724/1762] D loss: 1.3859, G loss: 0.6927\n",
      "[804/1762] D loss: 1.0595, G loss: 1.1834\n",
      "[884/1762] D loss: 1.3897, G loss: 0.6843\n",
      "[964/1762] D loss: 1.3876, G loss: 0.7158\n",
      "[1044/1762] D loss: 1.0518, G loss: 1.5495\n",
      "[1124/1762] D loss: 1.0532, G loss: 1.2215\n",
      "[1204/1762] D loss: 1.3870, G loss: 0.7175\n",
      "[1284/1762] D loss: 1.3870, G loss: 0.7057\n",
      "[1364/1762] D loss: 1.3878, G loss: 0.6748\n",
      "[1444/1762] D loss: 1.3889, G loss: 0.7290\n",
      "[1524/1762] D loss: 1.3502, G loss: 0.7579\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.7031\n",
      "[1684/1762] D loss: 1.3876, G loss: 0.6823\n",
      "[1762/1762] D loss: 1.3844, G loss: 0.6939\n",
      "train error: \n",
      " D loss: 1.305696, G loss: 0.850964, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.298998, G loss: 0.884034, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 91.1% \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3876, G loss: 0.7051\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6733\n",
      "[164/1762] D loss: 1.3883, G loss: 0.6945\n",
      "[244/1762] D loss: 1.0521, G loss: 1.3289\n",
      "[324/1762] D loss: 1.2079, G loss: 1.5832\n",
      "[404/1762] D loss: 1.3821, G loss: 0.6846\n",
      "[484/1762] D loss: 1.3882, G loss: 0.6493\n",
      "[564/1762] D loss: 1.3877, G loss: 0.6692\n",
      "[644/1762] D loss: 1.0403, G loss: 2.0924\n",
      "[724/1762] D loss: 1.3799, G loss: 0.6956\n",
      "[804/1762] D loss: 1.3862, G loss: 0.6953\n",
      "[884/1762] D loss: 1.3865, G loss: 0.7078\n",
      "[964/1762] D loss: 1.3918, G loss: 0.7454\n",
      "[1044/1762] D loss: 1.3852, G loss: 0.6717\n",
      "[1124/1762] D loss: 1.3856, G loss: 0.6948\n",
      "[1204/1762] D loss: 1.3851, G loss: 0.7031\n",
      "[1284/1762] D loss: 1.0428, G loss: 2.2380\n",
      "[1364/1762] D loss: 1.0618, G loss: 1.1462\n",
      "[1444/1762] D loss: 1.0563, G loss: 1.2033\n",
      "[1524/1762] D loss: 1.3865, G loss: 0.6909\n",
      "[1604/1762] D loss: 1.3867, G loss: 0.6856\n",
      "[1684/1762] D loss: 1.3876, G loss: 0.6625\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6981\n",
      "train error: \n",
      " D loss: 1.301332, G loss: 0.981920, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 93.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.304195, G loss: 1.072570, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3860, G loss: 0.6856\n",
      "[84/1762] D loss: 1.3866, G loss: 0.7064\n",
      "[164/1762] D loss: 1.3863, G loss: 0.7058\n",
      "[244/1762] D loss: 1.3864, G loss: 0.6967\n",
      "[324/1762] D loss: 1.3854, G loss: 0.7058\n",
      "[404/1762] D loss: 1.3872, G loss: 0.6868\n",
      "[484/1762] D loss: 1.0417, G loss: 2.0374\n",
      "[564/1762] D loss: 1.0431, G loss: 1.6733\n",
      "[644/1762] D loss: 1.3866, G loss: 0.6884\n",
      "[724/1762] D loss: 1.1762, G loss: 1.1132\n",
      "[804/1762] D loss: 1.3872, G loss: 0.7154\n",
      "[884/1762] D loss: 1.3893, G loss: 0.6544\n",
      "[964/1762] D loss: 1.3872, G loss: 0.6778\n",
      "[1044/1762] D loss: 1.3860, G loss: 0.6863\n",
      "[1124/1762] D loss: 1.7224, G loss: 1.1570\n",
      "[1204/1762] D loss: 0.7250, G loss: 1.8481\n",
      "[1284/1762] D loss: 1.4009, G loss: 0.6640\n",
      "[1364/1762] D loss: 1.3861, G loss: 0.7009\n",
      "[1444/1762] D loss: 1.0648, G loss: 1.1145\n",
      "[1524/1762] D loss: 1.3866, G loss: 0.6992\n",
      "[1604/1762] D loss: 1.4200, G loss: 0.6634\n",
      "[1684/1762] D loss: 1.0409, G loss: 2.1383\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.7132\n",
      "train error: \n",
      " D loss: 1.301861, G loss: 0.904646, D accuracy: 53.4%, cell accuracy: 99.9%, board accuracy: 93.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.296382, G loss: 0.965716, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3874, G loss: 0.6819\n",
      "[84/1762] D loss: 1.3873, G loss: 0.6586\n",
      "[164/1762] D loss: 1.3880, G loss: 0.7141\n",
      "[244/1762] D loss: 1.3884, G loss: 0.7184\n",
      "[324/1762] D loss: 1.3878, G loss: 0.7208\n",
      "[404/1762] D loss: 1.0525, G loss: 1.3016\n",
      "[484/1762] D loss: 0.7014, G loss: 2.5253\n",
      "[564/1762] D loss: 1.3869, G loss: 0.7076\n",
      "[644/1762] D loss: 1.0398, G loss: 2.3516\n",
      "[724/1762] D loss: 1.3873, G loss: 0.6997\n",
      "[804/1762] D loss: 1.3899, G loss: 0.7234\n",
      "[884/1762] D loss: 1.0599, G loss: 1.1564\n",
      "[964/1762] D loss: 1.3882, G loss: 0.7044\n",
      "[1044/1762] D loss: 1.3874, G loss: 0.7174\n",
      "[1124/1762] D loss: 1.3882, G loss: 0.7276\n",
      "[1204/1762] D loss: 1.3870, G loss: 0.7036\n",
      "[1284/1762] D loss: 1.3881, G loss: 0.6717\n",
      "[1364/1762] D loss: 1.3882, G loss: 0.6933\n",
      "[1444/1762] D loss: 1.1359, G loss: 0.8072\n",
      "[1524/1762] D loss: 1.3879, G loss: 0.7332\n",
      "[1604/1762] D loss: 1.0582, G loss: 1.1618\n",
      "[1684/1762] D loss: 1.0455, G loss: 1.5142\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.6887\n",
      "train error: \n",
      " D loss: 1.302570, G loss: 0.874164, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.296857, G loss: 0.927412, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0536, G loss: 1.2660\n",
      "[84/1762] D loss: 1.3874, G loss: 0.6645\n",
      "[164/1762] D loss: 1.3868, G loss: 0.7138\n",
      "[244/1762] D loss: 1.3878, G loss: 0.7004\n",
      "[324/1762] D loss: 1.3865, G loss: 0.6862\n",
      "[404/1762] D loss: 1.3868, G loss: 0.6901\n",
      "[484/1762] D loss: 1.0657, G loss: 1.1207\n",
      "[564/1762] D loss: 1.3867, G loss: 0.7057\n",
      "[644/1762] D loss: 1.3930, G loss: 0.6313\n",
      "[724/1762] D loss: 1.0571, G loss: 1.2462\n",
      "[804/1762] D loss: 1.3868, G loss: 0.6860\n",
      "[884/1762] D loss: 1.0400, G loss: 2.6629\n",
      "[964/1762] D loss: 1.3866, G loss: 0.7173\n",
      "[1044/1762] D loss: 1.3870, G loss: 0.6816\n",
      "[1124/1762] D loss: 1.0916, G loss: 0.9536\n",
      "[1204/1762] D loss: 1.4160, G loss: 0.5897\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6910\n",
      "[1364/1762] D loss: 1.3869, G loss: 0.7074\n",
      "[1444/1762] D loss: 1.3874, G loss: 0.7056\n",
      "[1524/1762] D loss: 1.3876, G loss: 0.6642\n",
      "[1604/1762] D loss: 1.3873, G loss: 0.6813\n",
      "[1684/1762] D loss: 1.3870, G loss: 0.6694\n",
      "[1762/1762] D loss: 1.3861, G loss: 0.6628\n",
      "train error: \n",
      " D loss: 1.305047, G loss: 0.955905, D accuracy: 53.4%, cell accuracy: 99.9%, board accuracy: 93.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.315870, G loss: 1.061403, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 91.1% \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3868, G loss: 0.7026\n",
      "[84/1762] D loss: 1.6703, G loss: 1.1118\n",
      "[164/1762] D loss: 1.3865, G loss: 0.7083\n",
      "[244/1762] D loss: 1.3873, G loss: 0.7020\n",
      "[324/1762] D loss: 1.0411, G loss: 2.3227\n",
      "[404/1762] D loss: 1.3867, G loss: 0.7024\n",
      "[484/1762] D loss: 0.7194, G loss: 2.9843\n",
      "[564/1762] D loss: 1.3869, G loss: 0.6754\n",
      "[644/1762] D loss: 1.3874, G loss: 0.7264\n",
      "[724/1762] D loss: 1.3889, G loss: 0.6529\n",
      "[804/1762] D loss: 1.3865, G loss: 0.7036\n",
      "[884/1762] D loss: 1.0523, G loss: 1.2851\n",
      "[964/1762] D loss: 1.0484, G loss: 1.3864\n",
      "[1044/1762] D loss: 1.3866, G loss: 0.7062\n",
      "[1124/1762] D loss: 1.3876, G loss: 0.7261\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6921\n",
      "[1284/1762] D loss: 1.3868, G loss: 0.6999\n",
      "[1364/1762] D loss: 1.3874, G loss: 0.7215\n",
      "[1444/1762] D loss: 1.3877, G loss: 0.6899\n",
      "[1524/1762] D loss: 1.3881, G loss: 0.6681\n",
      "[1604/1762] D loss: 1.3867, G loss: 0.6839\n",
      "[1684/1762] D loss: 1.3870, G loss: 0.7257\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6800\n",
      "train error: \n",
      " D loss: 1.300898, G loss: 0.903745, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 93.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.297172, G loss: 0.964623, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 91.6% \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3862, G loss: 0.6978\n",
      "[84/1762] D loss: 1.0480, G loss: 1.4009\n",
      "[164/1762] D loss: 0.7056, G loss: 2.6942\n",
      "[244/1762] D loss: 1.3866, G loss: 0.6784\n",
      "[324/1762] D loss: 1.3862, G loss: 0.6969\n",
      "[404/1762] D loss: 1.3861, G loss: 0.6881\n",
      "[484/1762] D loss: 1.0585, G loss: 1.2245\n",
      "[564/1762] D loss: 1.5274, G loss: 0.5805\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6898\n",
      "[724/1762] D loss: 1.3867, G loss: 0.7056\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6782\n",
      "[884/1762] D loss: 1.3890, G loss: 0.7136\n",
      "[964/1762] D loss: 1.0512, G loss: 1.3908\n",
      "[1044/1762] D loss: 1.3861, G loss: 0.6919\n",
      "[1124/1762] D loss: 1.3873, G loss: 0.7135\n",
      "[1204/1762] D loss: 1.3839, G loss: 0.7299\n",
      "[1284/1762] D loss: 1.3869, G loss: 0.7067\n",
      "[1364/1762] D loss: 1.0435, G loss: 1.5738\n",
      "[1444/1762] D loss: 1.2182, G loss: 1.6477\n",
      "[1524/1762] D loss: 1.0425, G loss: 1.7132\n",
      "[1604/1762] D loss: 1.3789, G loss: 0.6736\n",
      "[1684/1762] D loss: 1.5176, G loss: 0.9133\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.7061\n",
      "train error: \n",
      " D loss: 1.306175, G loss: 0.832408, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 93.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.298460, G loss: 0.880703, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 91.6% \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1058, G loss: 0.9128\n",
      "[84/1762] D loss: 1.3867, G loss: 0.6927\n",
      "[164/1762] D loss: 1.3872, G loss: 0.6889\n",
      "[244/1762] D loss: 1.0628, G loss: 1.0879\n",
      "[324/1762] D loss: 1.4024, G loss: 0.8058\n",
      "[404/1762] D loss: 1.3878, G loss: 0.6607\n",
      "[484/1762] D loss: 1.0855, G loss: 1.0230\n",
      "[564/1762] D loss: 1.3886, G loss: 0.7425\n",
      "[644/1762] D loss: 1.3866, G loss: 0.7030\n",
      "[724/1762] D loss: 1.3872, G loss: 0.7214\n",
      "[804/1762] D loss: 1.3874, G loss: 0.6948\n",
      "[884/1762] D loss: 1.3876, G loss: 0.6624\n",
      "[964/1762] D loss: 1.3906, G loss: 0.6930\n",
      "[1044/1762] D loss: 1.0397, G loss: 2.6537\n",
      "[1124/1762] D loss: 1.0396, G loss: 2.1934\n",
      "[1204/1762] D loss: 1.3867, G loss: 0.7240\n",
      "[1284/1762] D loss: 1.3853, G loss: 0.6965\n",
      "[1364/1762] D loss: 1.3867, G loss: 0.7201\n",
      "[1444/1762] D loss: 1.3851, G loss: 0.7220\n",
      "[1524/1762] D loss: 1.0843, G loss: 0.9934\n",
      "[1604/1762] D loss: 1.0406, G loss: 1.9877\n",
      "[1684/1762] D loss: 1.0634, G loss: 1.1555\n",
      "[1762/1762] D loss: 1.3854, G loss: 0.6946\n",
      "train error: \n",
      " D loss: 1.300128, G loss: 0.924403, D accuracy: 54.2%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.303637, G loss: 1.005359, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3871, G loss: 0.6816\n",
      "[84/1762] D loss: 1.3861, G loss: 0.6780\n",
      "[164/1762] D loss: 1.3867, G loss: 0.7185\n",
      "[244/1762] D loss: 0.7022, G loss: 2.3676\n",
      "[324/1762] D loss: 1.0420, G loss: 1.6652\n",
      "[404/1762] D loss: 1.3857, G loss: 0.7032\n",
      "[484/1762] D loss: 1.0559, G loss: 1.2172\n",
      "[564/1762] D loss: 1.3873, G loss: 0.6741\n",
      "[644/1762] D loss: 1.3905, G loss: 0.7015\n",
      "[724/1762] D loss: 1.3871, G loss: 0.7100\n",
      "[804/1762] D loss: 1.3879, G loss: 0.7281\n",
      "[884/1762] D loss: 1.0732, G loss: 1.0551\n",
      "[964/1762] D loss: 1.3868, G loss: 0.6802\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6969\n",
      "[1124/1762] D loss: 1.3834, G loss: 0.6903\n",
      "[1204/1762] D loss: 1.3867, G loss: 0.7150\n",
      "[1284/1762] D loss: 1.0580, G loss: 1.2059\n",
      "[1364/1762] D loss: 1.3835, G loss: 0.6729\n",
      "[1444/1762] D loss: 1.3962, G loss: 0.6460\n",
      "[1524/1762] D loss: 1.0407, G loss: 1.7537\n",
      "[1604/1762] D loss: 1.0675, G loss: 1.0633\n",
      "[1684/1762] D loss: 1.3866, G loss: 0.6825\n",
      "[1762/1762] D loss: 1.3531, G loss: 0.6554\n",
      "train error: \n",
      " D loss: 1.298622, G loss: 0.883567, D accuracy: 54.1%, cell accuracy: 99.9%, board accuracy: 92.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.306051, G loss: 0.976329, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 91.1% \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0543, G loss: 1.2700\n",
      "[84/1762] D loss: 1.3857, G loss: 0.7135\n",
      "[164/1762] D loss: 1.3870, G loss: 0.7309\n",
      "[244/1762] D loss: 1.3846, G loss: 0.7222\n",
      "[324/1762] D loss: 1.3774, G loss: 0.6767\n",
      "[404/1762] D loss: 1.3807, G loss: 0.6491\n",
      "[484/1762] D loss: 1.0447, G loss: 1.6281\n",
      "[564/1762] D loss: 1.0440, G loss: 2.2749\n",
      "[644/1762] D loss: 1.3692, G loss: 0.6159\n",
      "[724/1762] D loss: 1.3870, G loss: 0.6673\n",
      "[804/1762] D loss: 1.0424, G loss: 1.7306\n",
      "[884/1762] D loss: 1.3862, G loss: 0.6881\n",
      "[964/1762] D loss: 1.3865, G loss: 0.7030\n",
      "[1044/1762] D loss: 1.0462, G loss: 1.4601\n",
      "[1124/1762] D loss: 1.3861, G loss: 0.6894\n",
      "[1204/1762] D loss: 1.3892, G loss: 0.7378\n",
      "[1284/1762] D loss: 1.2165, G loss: 1.1289\n",
      "[1364/1762] D loss: 1.3872, G loss: 0.7185\n",
      "[1444/1762] D loss: 1.3920, G loss: 0.6560\n",
      "[1524/1762] D loss: 1.3869, G loss: 0.7104\n",
      "[1604/1762] D loss: 1.3865, G loss: 0.6920\n",
      "[1684/1762] D loss: 1.3868, G loss: 0.6992\n",
      "[1762/1762] D loss: 1.3928, G loss: 0.6387\n",
      "train error: \n",
      " D loss: 1.301621, G loss: 0.888392, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 93.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.303136, G loss: 0.972400, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 91.6% \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.7054\n",
      "[84/1762] D loss: 1.3860, G loss: 0.6731\n",
      "[164/1762] D loss: 1.3804, G loss: 0.6945\n",
      "[244/1762] D loss: 1.0573, G loss: 1.2019\n",
      "[324/1762] D loss: 1.3864, G loss: 0.6999\n",
      "[404/1762] D loss: 1.3895, G loss: 0.6653\n",
      "[484/1762] D loss: 1.0404, G loss: 1.8970\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6868\n",
      "[644/1762] D loss: 1.3839, G loss: 0.6924\n",
      "[724/1762] D loss: 1.0445, G loss: 1.5200\n",
      "[804/1762] D loss: 1.3868, G loss: 0.7003\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6840\n",
      "[964/1762] D loss: 1.3870, G loss: 0.7084\n",
      "[1044/1762] D loss: 1.3871, G loss: 0.6957\n",
      "[1124/1762] D loss: 1.3860, G loss: 0.7166\n",
      "[1204/1762] D loss: 1.3878, G loss: 0.7324\n",
      "[1284/1762] D loss: 1.3873, G loss: 0.6767\n",
      "[1364/1762] D loss: 1.3880, G loss: 0.6607\n",
      "[1444/1762] D loss: 1.3870, G loss: 0.6756\n",
      "[1524/1762] D loss: 1.3860, G loss: 0.6943\n",
      "[1604/1762] D loss: 1.3886, G loss: 0.6660\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.7030\n",
      "[1762/1762] D loss: 1.3869, G loss: 0.6837\n",
      "train error: \n",
      " D loss: 1.299038, G loss: 0.997145, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 93.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.313450, G loss: 1.102447, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 91.1% \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3866, G loss: 0.7073\n",
      "[84/1762] D loss: 1.3873, G loss: 0.7161\n",
      "[164/1762] D loss: 1.3872, G loss: 0.6900\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6827\n",
      "[324/1762] D loss: 1.3968, G loss: 0.7258\n",
      "[404/1762] D loss: 1.0494, G loss: 1.3286\n",
      "[484/1762] D loss: 1.3862, G loss: 0.6927\n",
      "[564/1762] D loss: 1.3854, G loss: 0.6917\n",
      "[644/1762] D loss: 1.3866, G loss: 0.6980\n",
      "[724/1762] D loss: 1.3856, G loss: 0.7003\n",
      "[804/1762] D loss: 1.3856, G loss: 0.6880\n",
      "[884/1762] D loss: 1.3873, G loss: 0.7079\n",
      "[964/1762] D loss: 1.4344, G loss: 0.8768\n",
      "[1044/1762] D loss: 1.4261, G loss: 0.5046\n",
      "[1124/1762] D loss: 1.3381, G loss: 0.6497\n",
      "[1204/1762] D loss: 1.0433, G loss: 2.0753\n",
      "[1284/1762] D loss: 1.3862, G loss: 0.7063\n",
      "[1364/1762] D loss: 1.3880, G loss: 0.6734\n",
      "[1444/1762] D loss: 1.3878, G loss: 0.7310\n",
      "[1524/1762] D loss: 1.3871, G loss: 0.7011\n",
      "[1604/1762] D loss: 1.3851, G loss: 0.7062\n",
      "[1684/1762] D loss: 1.3752, G loss: 0.7320\n",
      "[1762/1762] D loss: 1.3868, G loss: 0.6977\n",
      "train error: \n",
      " D loss: 1.299214, G loss: 0.878392, D accuracy: 54.7%, cell accuracy: 99.9%, board accuracy: 89.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.302038, G loss: 0.959423, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0605, G loss: 1.1467\n",
      "[84/1762] D loss: 1.3873, G loss: 0.6664\n",
      "[164/1762] D loss: 1.3873, G loss: 0.6800\n",
      "[244/1762] D loss: 1.3863, G loss: 0.7031\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6974\n",
      "[404/1762] D loss: 1.3868, G loss: 0.6847\n",
      "[484/1762] D loss: 1.3864, G loss: 0.7009\n",
      "[564/1762] D loss: 1.3874, G loss: 0.6889\n",
      "[644/1762] D loss: 1.3897, G loss: 0.6746\n",
      "[724/1762] D loss: 1.4001, G loss: 0.7570\n",
      "[804/1762] D loss: 1.3863, G loss: 0.6839\n",
      "[884/1762] D loss: 1.0216, G loss: 2.0295\n",
      "[964/1762] D loss: 1.3869, G loss: 0.7102\n",
      "[1044/1762] D loss: 1.3875, G loss: 0.6991\n",
      "[1124/1762] D loss: 1.3869, G loss: 0.6815\n",
      "[1204/1762] D loss: 1.3890, G loss: 0.6913\n",
      "[1284/1762] D loss: 1.3845, G loss: 0.6866\n",
      "[1364/1762] D loss: 1.3869, G loss: 0.6790\n",
      "[1444/1762] D loss: 1.3880, G loss: 0.6653\n",
      "[1524/1762] D loss: 1.3859, G loss: 0.6784\n",
      "[1604/1762] D loss: 1.0460, G loss: 1.4576\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6889\n",
      "[1762/1762] D loss: 1.3862, G loss: 0.7044\n",
      "train error: \n",
      " D loss: 1.299103, G loss: 0.899678, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.308782, G loss: 0.996659, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3866, G loss: 0.6851\n",
      "[84/1762] D loss: 1.3862, G loss: 0.7069\n",
      "[164/1762] D loss: 1.3558, G loss: 0.6883\n",
      "[244/1762] D loss: 1.3865, G loss: 0.6974\n",
      "[324/1762] D loss: 1.3881, G loss: 0.6644\n",
      "[404/1762] D loss: 1.3864, G loss: 0.7032\n",
      "[484/1762] D loss: 1.3857, G loss: 0.6779\n",
      "[564/1762] D loss: 1.3871, G loss: 0.7121\n",
      "[644/1762] D loss: 1.0520, G loss: 1.3136\n",
      "[724/1762] D loss: 1.3866, G loss: 0.6713\n",
      "[804/1762] D loss: 1.3870, G loss: 0.6476\n",
      "[884/1762] D loss: 1.3881, G loss: 0.6783\n",
      "[964/1762] D loss: 1.3881, G loss: 0.6760\n",
      "[1044/1762] D loss: 1.3816, G loss: 0.6990\n",
      "[1124/1762] D loss: 1.3887, G loss: 0.7064\n",
      "[1204/1762] D loss: 1.0706, G loss: 1.1084\n",
      "[1284/1762] D loss: 1.3878, G loss: 0.7234\n",
      "[1364/1762] D loss: 1.3872, G loss: 0.6722\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.7038\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.7069\n",
      "[1604/1762] D loss: 1.3859, G loss: 0.7078\n",
      "[1684/1762] D loss: 1.3868, G loss: 0.6631\n",
      "[1762/1762] D loss: 1.3866, G loss: 0.6828\n",
      "train error: \n",
      " D loss: 1.298538, G loss: 0.914292, D accuracy: 54.1%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.308099, G loss: 0.982611, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.7053\n",
      "[84/1762] D loss: 1.3851, G loss: 0.6771\n",
      "[164/1762] D loss: 1.3446, G loss: 0.7150\n",
      "[244/1762] D loss: 1.3942, G loss: 0.7752\n",
      "[324/1762] D loss: 1.3875, G loss: 0.6825\n",
      "[404/1762] D loss: 1.3806, G loss: 0.7575\n",
      "[484/1762] D loss: 1.3818, G loss: 0.6572\n",
      "[564/1762] D loss: 1.3894, G loss: 0.7059\n",
      "[644/1762] D loss: 1.3659, G loss: 0.6882\n",
      "[724/1762] D loss: 1.3874, G loss: 0.7033\n",
      "[804/1762] D loss: 1.3872, G loss: 0.6766\n",
      "[884/1762] D loss: 1.0655, G loss: 1.1217\n",
      "[964/1762] D loss: 1.0502, G loss: 1.3261\n",
      "[1044/1762] D loss: 1.3878, G loss: 0.6647\n",
      "[1124/1762] D loss: 1.3867, G loss: 0.7086\n",
      "[1204/1762] D loss: 0.7738, G loss: 2.2064\n",
      "[1284/1762] D loss: 1.3534, G loss: 0.6873\n",
      "[1364/1762] D loss: 1.3868, G loss: 0.7162\n",
      "[1444/1762] D loss: 1.3925, G loss: 0.6250\n",
      "[1524/1762] D loss: 1.3876, G loss: 0.7190\n",
      "[1604/1762] D loss: 1.0523, G loss: 1.3192\n",
      "[1684/1762] D loss: 1.0415, G loss: 1.7450\n",
      "[1762/1762] D loss: 1.3850, G loss: 0.6944\n",
      "train error: \n",
      " D loss: 1.294727, G loss: 0.894734, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.300410, G loss: 0.942978, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3853, G loss: 0.6947\n",
      "[84/1762] D loss: 1.3860, G loss: 0.6878\n",
      "[164/1762] D loss: 1.3770, G loss: 0.7196\n",
      "[244/1762] D loss: 1.3650, G loss: 0.7338\n",
      "[324/1762] D loss: 1.0419, G loss: 1.7343\n",
      "[404/1762] D loss: 1.3869, G loss: 0.7003\n",
      "[484/1762] D loss: 1.4838, G loss: 1.9388\n",
      "[564/1762] D loss: 1.3871, G loss: 0.7048\n",
      "[644/1762] D loss: 1.3861, G loss: 0.6908\n",
      "[724/1762] D loss: 0.7136, G loss: 2.0799\n",
      "[804/1762] D loss: 1.3888, G loss: 0.6618\n",
      "[884/1762] D loss: 1.3824, G loss: 0.6674\n",
      "[964/1762] D loss: 1.3855, G loss: 0.6851\n",
      "[1044/1762] D loss: 1.3901, G loss: 0.6499\n",
      "[1124/1762] D loss: 1.3861, G loss: 0.6729\n",
      "[1204/1762] D loss: 1.3868, G loss: 0.7060\n",
      "[1284/1762] D loss: 1.3872, G loss: 0.7009\n",
      "[1364/1762] D loss: 0.7195, G loss: 2.7459\n",
      "[1444/1762] D loss: 1.3869, G loss: 0.6769\n",
      "[1524/1762] D loss: 1.3871, G loss: 0.7186\n",
      "[1604/1762] D loss: 1.3948, G loss: 0.6891\n",
      "[1684/1762] D loss: 1.3876, G loss: 0.7147\n",
      "[1762/1762] D loss: 1.3862, G loss: 0.6985\n",
      "train error: \n",
      " D loss: 1.300483, G loss: 0.929502, D accuracy: 53.4%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.304974, G loss: 0.997611, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 91.1% \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3879, G loss: 0.6654\n",
      "[84/1762] D loss: 1.3861, G loss: 0.6905\n",
      "[164/1762] D loss: 1.0445, G loss: 1.5298\n",
      "[244/1762] D loss: 1.3866, G loss: 0.6901\n",
      "[324/1762] D loss: 1.0545, G loss: 1.2489\n",
      "[404/1762] D loss: 1.3828, G loss: 0.6849\n",
      "[484/1762] D loss: 1.0441, G loss: 1.5442\n",
      "[564/1762] D loss: 1.3857, G loss: 0.7010\n",
      "[644/1762] D loss: 1.0413, G loss: 2.4855\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6983\n",
      "[804/1762] D loss: 1.3829, G loss: 0.7039\n",
      "[884/1762] D loss: 1.3869, G loss: 0.6835\n",
      "[964/1762] D loss: 1.0485, G loss: 1.3788\n",
      "[1044/1762] D loss: 1.0467, G loss: 1.4355\n",
      "[1124/1762] D loss: 1.3871, G loss: 0.6673\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.7008\n",
      "[1284/1762] D loss: 1.0497, G loss: 1.3430\n",
      "[1364/1762] D loss: 1.1297, G loss: 1.4537\n",
      "[1444/1762] D loss: 1.3875, G loss: 0.7006\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.7019\n",
      "[1604/1762] D loss: 1.3871, G loss: 0.6711\n",
      "[1684/1762] D loss: 1.0578, G loss: 1.1788\n",
      "[1762/1762] D loss: 1.0475, G loss: 2.8656\n",
      "train error: \n",
      " D loss: 1.293496, G loss: 0.967935, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 91.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.302454, G loss: 1.046219, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3870, G loss: 0.7039\n",
      "[84/1762] D loss: 1.3912, G loss: 0.6735\n",
      "[164/1762] D loss: 1.3913, G loss: 0.6616\n",
      "[244/1762] D loss: 1.3881, G loss: 0.6810\n",
      "[324/1762] D loss: 1.0472, G loss: 1.4339\n",
      "[404/1762] D loss: 1.3863, G loss: 0.6995\n",
      "[484/1762] D loss: 1.0439, G loss: 1.4967\n",
      "[564/1762] D loss: 0.6943, G loss: 5.5938\n",
      "[644/1762] D loss: 1.3875, G loss: 0.6693\n",
      "[724/1762] D loss: 1.2099, G loss: 1.6231\n",
      "[804/1762] D loss: 1.3867, G loss: 0.6973\n",
      "[884/1762] D loss: 1.3865, G loss: 0.7054\n",
      "[964/1762] D loss: 1.3867, G loss: 0.6989\n",
      "[1044/1762] D loss: 1.3921, G loss: 0.6973\n",
      "[1124/1762] D loss: 1.3852, G loss: 0.7061\n",
      "[1204/1762] D loss: 1.3648, G loss: 0.7347\n",
      "[1284/1762] D loss: 1.0399, G loss: 2.1189\n",
      "[1364/1762] D loss: 1.3872, G loss: 0.7101\n",
      "[1444/1762] D loss: 1.3876, G loss: 0.6949\n",
      "[1524/1762] D loss: 1.3862, G loss: 0.6983\n",
      "[1604/1762] D loss: 1.3926, G loss: 0.6793\n",
      "[1684/1762] D loss: 1.3905, G loss: 0.6843\n",
      "[1762/1762] D loss: 1.3868, G loss: 0.6834\n",
      "train error: \n",
      " D loss: 1.299861, G loss: 0.971837, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.309097, G loss: 1.063174, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3829, G loss: 0.6976\n",
      "[84/1762] D loss: 1.3855, G loss: 0.6957\n",
      "[164/1762] D loss: 1.0604, G loss: 1.1930\n",
      "[244/1762] D loss: 1.3792, G loss: 0.7011\n",
      "[324/1762] D loss: 1.3797, G loss: 0.6943\n",
      "[404/1762] D loss: 1.2127, G loss: 2.2426\n",
      "[484/1762] D loss: 1.3826, G loss: 0.6706\n",
      "[564/1762] D loss: 1.3868, G loss: 0.6971\n",
      "[644/1762] D loss: 1.3828, G loss: 0.7041\n",
      "[724/1762] D loss: 1.0451, G loss: 2.3661\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6894\n",
      "[884/1762] D loss: 1.3855, G loss: 0.6951\n",
      "[964/1762] D loss: 1.3407, G loss: 0.8050\n",
      "[1044/1762] D loss: 0.7025, G loss: 2.6539\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.7130\n",
      "[1204/1762] D loss: 1.3865, G loss: 0.7100\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6767\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6992\n",
      "[1444/1762] D loss: 1.3866, G loss: 0.7026\n",
      "[1524/1762] D loss: 1.3880, G loss: 0.6765\n",
      "[1604/1762] D loss: 1.3782, G loss: 0.7005\n",
      "[1684/1762] D loss: 1.0408, G loss: 1.9980\n",
      "[1762/1762] D loss: 1.3814, G loss: 0.7115\n",
      "train error: \n",
      " D loss: 1.289871, G loss: 0.994307, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 91.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.274925, G loss: 1.103644, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6944\n",
      "[84/1762] D loss: 1.0416, G loss: 1.8319\n",
      "[164/1762] D loss: 0.3545, G loss: 3.6427\n",
      "[244/1762] D loss: 1.3880, G loss: 0.6733\n",
      "[324/1762] D loss: 1.3859, G loss: 0.7041\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6943\n",
      "[484/1762] D loss: 1.3812, G loss: 0.6734\n",
      "[564/1762] D loss: 1.3854, G loss: 0.7031\n",
      "[644/1762] D loss: 1.3877, G loss: 0.7215\n",
      "[724/1762] D loss: 1.3872, G loss: 0.6948\n",
      "[804/1762] D loss: 1.3886, G loss: 0.7158\n",
      "[884/1762] D loss: 1.3888, G loss: 0.6909\n",
      "[964/1762] D loss: 1.3863, G loss: 0.6942\n",
      "[1044/1762] D loss: 1.3865, G loss: 0.6898\n",
      "[1124/1762] D loss: 1.3880, G loss: 0.7202\n",
      "[1204/1762] D loss: 1.0454, G loss: 1.6677\n",
      "[1284/1762] D loss: 1.0400, G loss: 2.2709\n",
      "[1364/1762] D loss: 1.3860, G loss: 0.6995\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.6946\n",
      "[1524/1762] D loss: 1.3866, G loss: 0.7046\n",
      "[1604/1762] D loss: 1.0403, G loss: 2.1153\n",
      "[1684/1762] D loss: 1.3870, G loss: 0.6763\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6902\n",
      "train error: \n",
      " D loss: 1.292770, G loss: 1.051209, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.261934, G loss: 1.172351, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6909\n",
      "[84/1762] D loss: 1.0410, G loss: 1.9643\n",
      "[164/1762] D loss: 1.0407, G loss: 1.8978\n",
      "[244/1762] D loss: 1.3865, G loss: 0.7034\n",
      "[324/1762] D loss: 1.0405, G loss: 2.0093\n",
      "[404/1762] D loss: 1.3865, G loss: 0.6866\n",
      "[484/1762] D loss: 1.3867, G loss: 0.7001\n",
      "[564/1762] D loss: 1.0404, G loss: 1.9960\n",
      "[644/1762] D loss: 1.0416, G loss: 1.6726\n",
      "[724/1762] D loss: 1.3868, G loss: 0.7021\n",
      "[804/1762] D loss: 1.3472, G loss: 0.7516\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6963\n",
      "[964/1762] D loss: 1.3891, G loss: 0.7106\n",
      "[1044/1762] D loss: 0.6975, G loss: 2.8094\n",
      "[1124/1762] D loss: 1.1180, G loss: 0.8261\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6771\n",
      "[1284/1762] D loss: 1.3896, G loss: 0.7259\n",
      "[1364/1762] D loss: 1.3877, G loss: 0.7184\n",
      "[1444/1762] D loss: 1.3874, G loss: 0.6994\n",
      "[1524/1762] D loss: 1.0405, G loss: 2.0982\n",
      "[1604/1762] D loss: 1.0451, G loss: 1.6106\n",
      "[1684/1762] D loss: 1.3872, G loss: 0.6878\n",
      "[1762/1762] D loss: 1.3901, G loss: 0.6272\n",
      "train error: \n",
      " D loss: 1.305825, G loss: 0.991787, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.322319, G loss: 1.205811, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0459, G loss: 2.3168\n",
      "[84/1762] D loss: 1.3910, G loss: 0.6993\n",
      "[164/1762] D loss: 1.3876, G loss: 0.6937\n",
      "[244/1762] D loss: 1.3901, G loss: 0.7256\n",
      "[324/1762] D loss: 1.0614, G loss: 1.1237\n",
      "[404/1762] D loss: 1.3865, G loss: 0.7004\n",
      "[484/1762] D loss: 1.3870, G loss: 0.6907\n",
      "[564/1762] D loss: 1.0394, G loss: 2.7780\n",
      "[644/1762] D loss: 1.3898, G loss: 0.7044\n",
      "[724/1762] D loss: 1.3870, G loss: 0.7122\n",
      "[804/1762] D loss: 1.0401, G loss: 2.9445\n",
      "[884/1762] D loss: 1.3866, G loss: 0.7014\n",
      "[964/1762] D loss: 1.3872, G loss: 0.7038\n",
      "[1044/1762] D loss: 1.3899, G loss: 0.6934\n",
      "[1124/1762] D loss: 1.3866, G loss: 0.7064\n",
      "[1204/1762] D loss: 1.3866, G loss: 0.6986\n",
      "[1284/1762] D loss: 1.3867, G loss: 0.6805\n",
      "[1364/1762] D loss: 1.0607, G loss: 1.1525\n",
      "[1444/1762] D loss: 1.3872, G loss: 0.6984\n",
      "[1524/1762] D loss: 1.3866, G loss: 0.6888\n",
      "[1604/1762] D loss: 1.3868, G loss: 0.6884\n",
      "[1684/1762] D loss: 1.3871, G loss: 0.6725\n",
      "[1762/1762] D loss: 0.7003, G loss: 2.5377\n",
      "train error: \n",
      " D loss: 1.300901, G loss: 0.912688, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 93.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.301434, G loss: 0.976736, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3878, G loss: 0.6746\n",
      "[84/1762] D loss: 1.3859, G loss: 0.6791\n",
      "[164/1762] D loss: 1.0409, G loss: 2.0211\n",
      "[244/1762] D loss: 1.0414, G loss: 1.7980\n",
      "[324/1762] D loss: 1.0405, G loss: 1.9829\n",
      "[404/1762] D loss: 1.3606, G loss: 0.7945\n",
      "[484/1762] D loss: 1.3863, G loss: 0.6979\n",
      "[564/1762] D loss: 1.0572, G loss: 1.2267\n",
      "[644/1762] D loss: 1.3885, G loss: 0.7241\n",
      "[724/1762] D loss: 1.4035, G loss: 0.6615\n",
      "[804/1762] D loss: 1.3868, G loss: 0.6900\n",
      "[884/1762] D loss: 1.1061, G loss: 0.8872\n",
      "[964/1762] D loss: 1.3867, G loss: 0.7011\n",
      "[1044/1762] D loss: 1.3877, G loss: 0.7178\n",
      "[1124/1762] D loss: 1.3862, G loss: 0.6868\n",
      "[1204/1762] D loss: 1.3847, G loss: 0.6941\n",
      "[1284/1762] D loss: 1.0416, G loss: 2.9336\n",
      "[1364/1762] D loss: 1.3871, G loss: 0.7183\n",
      "[1444/1762] D loss: 1.2243, G loss: 1.2537\n",
      "[1524/1762] D loss: 1.0617, G loss: 1.1704\n",
      "[1604/1762] D loss: 1.0506, G loss: 1.3617\n",
      "[1684/1762] D loss: 1.3871, G loss: 0.7202\n",
      "[1762/1762] D loss: 1.3783, G loss: 0.6696\n",
      "train error: \n",
      " D loss: 1.300940, G loss: 1.014186, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 93.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.321235, G loss: 1.140266, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3855, G loss: 0.6923\n",
      "[84/1762] D loss: 1.3855, G loss: 0.7062\n",
      "[164/1762] D loss: 1.3891, G loss: 0.6449\n",
      "[244/1762] D loss: 1.3864, G loss: 0.6871\n",
      "[324/1762] D loss: 1.0533, G loss: 1.4625\n",
      "[404/1762] D loss: 1.3894, G loss: 0.6503\n",
      "[484/1762] D loss: 0.7224, G loss: 1.7995\n",
      "[564/1762] D loss: 1.3861, G loss: 0.7083\n",
      "[644/1762] D loss: 1.3563, G loss: 0.7533\n",
      "[724/1762] D loss: 1.3770, G loss: 0.7070\n",
      "[804/1762] D loss: 1.3757, G loss: 0.6824\n",
      "[884/1762] D loss: 1.3889, G loss: 0.7218\n",
      "[964/1762] D loss: 1.3862, G loss: 0.6890\n",
      "[1044/1762] D loss: 1.3735, G loss: 0.6947\n",
      "[1124/1762] D loss: 1.3907, G loss: 0.7449\n",
      "[1204/1762] D loss: 1.3867, G loss: 0.6994\n",
      "[1284/1762] D loss: 1.3858, G loss: 0.6657\n",
      "[1364/1762] D loss: 1.3784, G loss: 0.6960\n",
      "[1444/1762] D loss: 1.3873, G loss: 0.7074\n",
      "[1524/1762] D loss: 1.0422, G loss: 1.6945\n",
      "[1604/1762] D loss: 1.3868, G loss: 0.6781\n",
      "[1684/1762] D loss: 1.0432, G loss: 1.5954\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6918\n",
      "train error: \n",
      " D loss: 1.299180, G loss: 0.984416, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.315429, G loss: 1.076949, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3859, G loss: 0.6859\n",
      "[84/1762] D loss: 1.3876, G loss: 0.6925\n",
      "[164/1762] D loss: 1.3866, G loss: 0.6845\n",
      "[244/1762] D loss: 1.0419, G loss: 1.7691\n",
      "[324/1762] D loss: 1.3863, G loss: 0.7069\n",
      "[404/1762] D loss: 1.3865, G loss: 0.6969\n",
      "[484/1762] D loss: 1.3860, G loss: 0.7093\n",
      "[564/1762] D loss: 1.3865, G loss: 0.7158\n",
      "[644/1762] D loss: 1.3887, G loss: 0.6433\n",
      "[724/1762] D loss: 1.0613, G loss: 1.3636\n",
      "[804/1762] D loss: 1.3875, G loss: 0.7266\n",
      "[884/1762] D loss: 1.3874, G loss: 0.7227\n",
      "[964/1762] D loss: 1.3869, G loss: 0.7110\n",
      "[1044/1762] D loss: 1.3822, G loss: 0.7039\n",
      "[1124/1762] D loss: 1.0896, G loss: 0.9696\n",
      "[1204/1762] D loss: 1.0429, G loss: 1.6560\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.7028\n",
      "[1364/1762] D loss: 1.3853, G loss: 0.6903\n",
      "[1444/1762] D loss: 1.0399, G loss: 2.5915\n",
      "[1524/1762] D loss: 1.3892, G loss: 0.7108\n",
      "[1604/1762] D loss: 1.3867, G loss: 0.6792\n",
      "[1684/1762] D loss: 1.1241, G loss: 0.8242\n",
      "[1762/1762] D loss: 0.6967, G loss: 3.1896\n",
      "train error: \n",
      " D loss: 1.299268, G loss: 1.020029, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 91.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.321066, G loss: 1.102286, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3850, G loss: 0.6736\n",
      "[84/1762] D loss: 1.3865, G loss: 0.6854\n",
      "[164/1762] D loss: 1.0404, G loss: 1.9567\n",
      "[244/1762] D loss: 1.0491, G loss: 1.3462\n",
      "[324/1762] D loss: 1.3869, G loss: 0.6739\n",
      "[404/1762] D loss: 1.3867, G loss: 0.7028\n",
      "[484/1762] D loss: 1.3863, G loss: 0.6917\n",
      "[564/1762] D loss: 1.0538, G loss: 1.2485\n",
      "[644/1762] D loss: 1.3868, G loss: 0.7079\n",
      "[724/1762] D loss: 0.6936, G loss: 5.9341\n",
      "[804/1762] D loss: 1.3872, G loss: 0.6979\n",
      "[884/1762] D loss: 1.2230, G loss: 2.2994\n",
      "[964/1762] D loss: 1.3857, G loss: 0.6905\n",
      "[1044/1762] D loss: 1.3865, G loss: 0.7091\n",
      "[1124/1762] D loss: 1.3896, G loss: 0.6610\n",
      "[1204/1762] D loss: 1.3870, G loss: 0.7137\n",
      "[1284/1762] D loss: 1.3874, G loss: 0.7197\n",
      "[1364/1762] D loss: 1.1480, G loss: 0.9934\n",
      "[1444/1762] D loss: 1.3850, G loss: 0.7078\n",
      "[1524/1762] D loss: 1.2394, G loss: 1.0457\n",
      "[1604/1762] D loss: 2.6821, G loss: 2.1175\n",
      "[1684/1762] D loss: 1.0867, G loss: 0.9032\n",
      "[1762/1762] D loss: 0.7189, G loss: 2.0223\n",
      "train error: \n",
      " D loss: 1.305164, G loss: 0.909159, D accuracy: 55.4%, cell accuracy: 99.8%, board accuracy: 81.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.314914, G loss: 0.981404, D accuracy: 56.5%, cell accuracy: 99.7%, board accuracy: 79.1% \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0961, G loss: 1.6552\n",
      "[84/1762] D loss: 1.0586, G loss: 1.5660\n",
      "[164/1762] D loss: 1.3840, G loss: 0.6519\n",
      "[244/1762] D loss: 1.3819, G loss: 0.6979\n",
      "[324/1762] D loss: 1.3953, G loss: 0.7047\n",
      "[404/1762] D loss: 1.3792, G loss: 0.6874\n",
      "[484/1762] D loss: 1.3871, G loss: 0.7199\n",
      "[564/1762] D loss: 1.3881, G loss: 0.7229\n",
      "[644/1762] D loss: 1.0806, G loss: 1.1094\n",
      "[724/1762] D loss: 1.3858, G loss: 0.6908\n",
      "[804/1762] D loss: 1.1166, G loss: 0.8315\n",
      "[884/1762] D loss: 1.3866, G loss: 0.6958\n",
      "[964/1762] D loss: 1.3767, G loss: 0.6882\n",
      "[1044/1762] D loss: 1.3814, G loss: 0.6480\n",
      "[1124/1762] D loss: 1.3904, G loss: 0.6420\n",
      "[1204/1762] D loss: 0.5475, G loss: 3.5765\n",
      "[1284/1762] D loss: 1.0887, G loss: 1.1005\n",
      "[1364/1762] D loss: 0.7220, G loss: 4.0261\n",
      "[1444/1762] D loss: 1.0410, G loss: 2.1944\n",
      "[1524/1762] D loss: 1.0509, G loss: 1.3231\n",
      "[1604/1762] D loss: 1.3859, G loss: 0.7126\n",
      "[1684/1762] D loss: 1.2446, G loss: 0.8333\n",
      "[1762/1762] D loss: 1.3896, G loss: 0.7416\n",
      "train error: \n",
      " D loss: 1.328657, G loss: 0.769395, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.334849, G loss: 0.831820, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1374, G loss: 0.7739\n",
      "[84/1762] D loss: 1.3882, G loss: 0.7291\n",
      "[164/1762] D loss: 1.3867, G loss: 0.7039\n",
      "[244/1762] D loss: 1.3864, G loss: 0.6810\n",
      "[324/1762] D loss: 1.3878, G loss: 0.6616\n",
      "[404/1762] D loss: 1.3914, G loss: 0.7435\n",
      "[484/1762] D loss: 1.3870, G loss: 0.6782\n",
      "[564/1762] D loss: 1.3880, G loss: 0.7281\n",
      "[644/1762] D loss: 1.3926, G loss: 0.7655\n",
      "[724/1762] D loss: 1.0702, G loss: 1.1051\n",
      "[804/1762] D loss: 1.1070, G loss: 0.8898\n",
      "[884/1762] D loss: 1.0444, G loss: 1.5430\n",
      "[964/1762] D loss: 1.3866, G loss: 0.6922\n",
      "[1044/1762] D loss: 1.3866, G loss: 0.6666\n",
      "[1124/1762] D loss: 1.3868, G loss: 0.7077\n",
      "[1204/1762] D loss: 1.1574, G loss: 0.7753\n",
      "[1284/1762] D loss: 1.3927, G loss: 0.7258\n",
      "[1364/1762] D loss: 1.3865, G loss: 0.7082\n",
      "[1444/1762] D loss: 1.3873, G loss: 0.6860\n",
      "[1524/1762] D loss: 1.1369, G loss: 0.8292\n",
      "[1604/1762] D loss: 1.3865, G loss: 0.6868\n",
      "[1684/1762] D loss: 1.3865, G loss: 0.6918\n",
      "[1762/1762] D loss: 1.3915, G loss: 0.6269\n",
      "train error: \n",
      " D loss: 1.326630, G loss: 0.756792, D accuracy: 53.2%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.343936, G loss: 0.785036, D accuracy: 53.4%, cell accuracy: 99.9%, board accuracy: 91.1% \n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4232, G loss: 0.7388\n",
      "[84/1762] D loss: 1.3883, G loss: 0.6894\n",
      "[164/1762] D loss: 1.3886, G loss: 0.6600\n",
      "[244/1762] D loss: 1.0921, G loss: 0.9259\n",
      "[324/1762] D loss: 1.1840, G loss: 0.8086\n",
      "[404/1762] D loss: 1.3827, G loss: 0.7514\n",
      "[484/1762] D loss: 1.3869, G loss: 0.6860\n",
      "[564/1762] D loss: 1.3870, G loss: 0.6677\n",
      "[644/1762] D loss: 1.3882, G loss: 0.6738\n",
      "[724/1762] D loss: 1.5760, G loss: 0.6388\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6931\n",
      "[884/1762] D loss: 1.2278, G loss: 0.8497\n",
      "[964/1762] D loss: 1.3873, G loss: 0.6775\n",
      "[1044/1762] D loss: 1.0468, G loss: 1.7201\n",
      "[1124/1762] D loss: 1.0921, G loss: 0.9447\n",
      "[1204/1762] D loss: 1.0583, G loss: 1.3834\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6835\n",
      "[1364/1762] D loss: 1.3881, G loss: 0.7232\n",
      "[1444/1762] D loss: 1.3866, G loss: 0.6876\n",
      "[1524/1762] D loss: 1.4047, G loss: 0.8248\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6872\n",
      "[1684/1762] D loss: 1.3869, G loss: 0.6915\n",
      "[1762/1762] D loss: 1.3872, G loss: 0.7202\n",
      "train error: \n",
      " D loss: 1.327533, G loss: 0.760719, D accuracy: 52.9%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.335335, G loss: 0.778839, D accuracy: 52.5%, cell accuracy: 99.9%, board accuracy: 91.4% \n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3862, G loss: 0.6938\n",
      "[84/1762] D loss: 1.3865, G loss: 0.6942\n",
      "[164/1762] D loss: 1.3914, G loss: 0.7304\n",
      "[244/1762] D loss: 1.3868, G loss: 0.6976\n",
      "[324/1762] D loss: 1.3882, G loss: 0.6619\n",
      "[404/1762] D loss: 1.3894, G loss: 0.6577\n",
      "[484/1762] D loss: 1.3867, G loss: 0.6697\n",
      "[564/1762] D loss: 1.3866, G loss: 0.7001\n",
      "[644/1762] D loss: 1.3859, G loss: 0.6933\n",
      "[724/1762] D loss: 1.1922, G loss: 1.1691\n",
      "[804/1762] D loss: 1.3866, G loss: 0.6925\n",
      "[884/1762] D loss: 1.3863, G loss: 0.7006\n",
      "[964/1762] D loss: 1.3864, G loss: 0.7059\n",
      "[1044/1762] D loss: 1.3787, G loss: 0.6988\n",
      "[1124/1762] D loss: 1.3868, G loss: 0.6928\n",
      "[1204/1762] D loss: 1.3867, G loss: 0.7028\n",
      "[1284/1762] D loss: 1.3865, G loss: 0.6911\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6995\n",
      "[1444/1762] D loss: 1.1517, G loss: 0.8173\n",
      "[1524/1762] D loss: 1.3871, G loss: 0.6682\n",
      "[1604/1762] D loss: 1.3877, G loss: 0.7174\n",
      "[1684/1762] D loss: 1.3872, G loss: 0.7119\n",
      "[1762/1762] D loss: 0.8030, G loss: 1.1606\n",
      "train error: \n",
      " D loss: 1.325094, G loss: 0.740103, D accuracy: 53.1%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.328483, G loss: 0.765187, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3217, G loss: 0.7407\n",
      "[84/1762] D loss: 1.0621, G loss: 1.1434\n",
      "[164/1762] D loss: 1.3864, G loss: 0.6992\n",
      "[244/1762] D loss: 1.3886, G loss: 0.6771\n",
      "[324/1762] D loss: 1.2635, G loss: 0.8802\n",
      "[404/1762] D loss: 1.3877, G loss: 0.6881\n",
      "[484/1762] D loss: 1.3928, G loss: 0.6494\n",
      "[564/1762] D loss: 1.3866, G loss: 0.6866\n",
      "[644/1762] D loss: 1.2612, G loss: 0.9557\n",
      "[724/1762] D loss: 1.0446, G loss: 1.5275\n",
      "[804/1762] D loss: 1.3865, G loss: 0.6887\n",
      "[884/1762] D loss: 1.3889, G loss: 0.6728\n",
      "[964/1762] D loss: 1.3870, G loss: 0.7072\n",
      "[1044/1762] D loss: 1.3833, G loss: 0.7076\n",
      "[1124/1762] D loss: 1.2562, G loss: 0.8325\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.7042\n",
      "[1284/1762] D loss: 1.3873, G loss: 0.6757\n",
      "[1364/1762] D loss: 1.3879, G loss: 0.7209\n",
      "[1444/1762] D loss: 1.3862, G loss: 0.6932\n",
      "[1524/1762] D loss: 1.3865, G loss: 0.7190\n",
      "[1604/1762] D loss: 1.0681, G loss: 1.1031\n",
      "[1684/1762] D loss: 1.3138, G loss: 0.7831\n",
      "[1762/1762] D loss: 1.3862, G loss: 0.6966\n",
      "train error: \n",
      " D loss: 1.317716, G loss: 0.788539, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 91.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.332513, G loss: 0.826540, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3883, G loss: 0.6846\n",
      "[84/1762] D loss: 1.3870, G loss: 0.6982\n",
      "[164/1762] D loss: 1.0454, G loss: 1.5253\n",
      "[244/1762] D loss: 1.4056, G loss: 0.7689\n",
      "[324/1762] D loss: 1.3867, G loss: 0.7066\n",
      "[404/1762] D loss: 1.3876, G loss: 0.6922\n",
      "[484/1762] D loss: 1.3740, G loss: 0.6508\n",
      "[564/1762] D loss: 1.3874, G loss: 0.7006\n",
      "[644/1762] D loss: 1.3862, G loss: 0.7101\n",
      "[724/1762] D loss: 1.3866, G loss: 0.6637\n",
      "[804/1762] D loss: 1.3857, G loss: 0.6793\n",
      "[884/1762] D loss: 1.1968, G loss: 0.8769\n",
      "[964/1762] D loss: 1.3864, G loss: 0.7153\n",
      "[1044/1762] D loss: 1.3856, G loss: 0.6969\n",
      "[1124/1762] D loss: 1.3900, G loss: 0.6846\n",
      "[1204/1762] D loss: 1.3894, G loss: 0.6918\n",
      "[1284/1762] D loss: 1.2013, G loss: 1.1541\n",
      "[1364/1762] D loss: 1.3805, G loss: 0.6806\n",
      "[1444/1762] D loss: 1.3867, G loss: 0.6906\n",
      "[1524/1762] D loss: 1.3893, G loss: 0.7038\n",
      "[1604/1762] D loss: 1.3871, G loss: 0.6926\n",
      "[1684/1762] D loss: 1.0769, G loss: 1.3618\n",
      "[1762/1762] D loss: 1.3957, G loss: 0.6117\n",
      "train error: \n",
      " D loss: 1.319211, G loss: 0.730606, D accuracy: 56.6%, cell accuracy: 99.5%, board accuracy: 24.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.313355, G loss: 0.752600, D accuracy: 57.5%, cell accuracy: 99.5%, board accuracy: 25.0% \n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3813, G loss: 0.7349\n",
      "[84/1762] D loss: 1.1585, G loss: 1.0577\n",
      "[164/1762] D loss: 1.2599, G loss: 1.1744\n",
      "[244/1762] D loss: 1.3650, G loss: 0.7583\n",
      "[324/1762] D loss: 1.3889, G loss: 0.6610\n",
      "[404/1762] D loss: 1.3864, G loss: 0.7027\n",
      "[484/1762] D loss: 1.1120, G loss: 0.8832\n",
      "[564/1762] D loss: 1.3866, G loss: 0.7102\n",
      "[644/1762] D loss: 1.1094, G loss: 0.9391\n",
      "[724/1762] D loss: 1.3862, G loss: 0.7037\n",
      "[804/1762] D loss: 1.4115, G loss: 0.6286\n",
      "[884/1762] D loss: 1.3914, G loss: 0.7386\n",
      "[964/1762] D loss: 1.0640, G loss: 1.0960\n",
      "[1044/1762] D loss: 1.3918, G loss: 0.6689\n",
      "[1124/1762] D loss: 1.0699, G loss: 1.2018\n",
      "[1204/1762] D loss: 1.3904, G loss: 0.7564\n",
      "[1284/1762] D loss: 1.3865, G loss: 0.7016\n",
      "[1364/1762] D loss: 1.3877, G loss: 0.6591\n",
      "[1444/1762] D loss: 1.3859, G loss: 0.7021\n",
      "[1524/1762] D loss: 1.3817, G loss: 0.7018\n",
      "[1604/1762] D loss: 1.3919, G loss: 0.7672\n",
      "[1684/1762] D loss: 1.3891, G loss: 0.6638\n",
      "[1762/1762] D loss: 1.3871, G loss: 0.7223\n",
      "train error: \n",
      " D loss: 1.319955, G loss: 0.797000, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 90.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.306580, G loss: 0.818191, D accuracy: 54.3%, cell accuracy: 99.9%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3871, G loss: 0.6934\n",
      "[84/1762] D loss: 1.3874, G loss: 0.6839\n",
      "[164/1762] D loss: 1.3872, G loss: 0.7010\n",
      "[244/1762] D loss: 1.0896, G loss: 1.0024\n",
      "[324/1762] D loss: 1.3868, G loss: 0.6967\n",
      "[404/1762] D loss: 1.3867, G loss: 0.7017\n",
      "[484/1762] D loss: 1.1684, G loss: 0.8655\n",
      "[564/1762] D loss: 1.3873, G loss: 0.7126\n",
      "[644/1762] D loss: 1.3903, G loss: 0.6674\n",
      "[724/1762] D loss: 1.0753, G loss: 1.0319\n",
      "[804/1762] D loss: 1.0628, G loss: 1.1370\n",
      "[884/1762] D loss: 1.3878, G loss: 0.6718\n",
      "[964/1762] D loss: 1.0486, G loss: 1.3481\n",
      "[1044/1762] D loss: 1.3871, G loss: 0.6883\n",
      "[1124/1762] D loss: 1.3868, G loss: 0.6993\n",
      "[1204/1762] D loss: 1.3874, G loss: 0.7113\n",
      "[1284/1762] D loss: 1.3870, G loss: 0.7198\n",
      "[1364/1762] D loss: 1.3870, G loss: 0.7015\n",
      "[1444/1762] D loss: 1.3870, G loss: 0.7032\n",
      "[1524/1762] D loss: 1.3872, G loss: 0.6765\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6920\n",
      "[1684/1762] D loss: 1.0564, G loss: 1.2206\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6759\n",
      "train error: \n",
      " D loss: 1.317457, G loss: 0.758751, D accuracy: 53.2%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.301829, G loss: 0.780894, D accuracy: 54.0%, cell accuracy: 99.9%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3879, G loss: 0.6661\n",
      "[84/1762] D loss: 1.3874, G loss: 0.6800\n",
      "[164/1762] D loss: 1.0648, G loss: 1.1483\n",
      "[244/1762] D loss: 1.0601, G loss: 1.1530\n",
      "[324/1762] D loss: 1.3872, G loss: 0.7071\n",
      "[404/1762] D loss: 1.3866, G loss: 0.6790\n",
      "[484/1762] D loss: 1.3864, G loss: 0.6900\n",
      "[564/1762] D loss: 1.3868, G loss: 0.6891\n",
      "[644/1762] D loss: 1.3872, G loss: 0.6951\n",
      "[724/1762] D loss: 1.3873, G loss: 0.6637\n",
      "[804/1762] D loss: 1.0491, G loss: 1.3639\n",
      "[884/1762] D loss: 1.5991, G loss: 1.1959\n",
      "[964/1762] D loss: 1.3865, G loss: 0.6719\n",
      "[1044/1762] D loss: 1.3877, G loss: 0.7197\n",
      "[1124/1762] D loss: 1.3888, G loss: 0.6774\n",
      "[1204/1762] D loss: 1.0799, G loss: 1.0089\n",
      "[1284/1762] D loss: 1.0665, G loss: 1.1838\n",
      "[1364/1762] D loss: 1.3871, G loss: 0.7091\n",
      "[1444/1762] D loss: 1.3867, G loss: 0.7046\n",
      "[1524/1762] D loss: 1.3865, G loss: 0.7082\n",
      "[1604/1762] D loss: 1.3870, G loss: 0.6912\n",
      "[1684/1762] D loss: 1.3865, G loss: 0.6946\n",
      "[1762/1762] D loss: 1.3874, G loss: 0.7226\n",
      "train error: \n",
      " D loss: 1.316874, G loss: 0.780641, D accuracy: 53.2%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.301676, G loss: 0.798467, D accuracy: 54.0%, cell accuracy: 99.9%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0787, G loss: 1.0128\n",
      "[84/1762] D loss: 1.3865, G loss: 0.6881\n",
      "[164/1762] D loss: 1.0815, G loss: 1.0098\n",
      "[244/1762] D loss: 1.3865, G loss: 0.6990\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6868\n",
      "[404/1762] D loss: 1.3861, G loss: 0.6841\n",
      "[484/1762] D loss: 1.3867, G loss: 0.7122\n",
      "[564/1762] D loss: 1.3864, G loss: 0.7031\n",
      "[644/1762] D loss: 1.3874, G loss: 0.7192\n",
      "[724/1762] D loss: 1.3865, G loss: 0.6851\n",
      "[804/1762] D loss: 1.3871, G loss: 0.7151\n",
      "[884/1762] D loss: 0.8904, G loss: 1.5377\n",
      "[964/1762] D loss: 1.3870, G loss: 0.6919\n",
      "[1044/1762] D loss: 1.3866, G loss: 0.6932\n",
      "[1124/1762] D loss: 1.3869, G loss: 0.6799\n",
      "[1204/1762] D loss: 1.0752, G loss: 1.0496\n",
      "[1284/1762] D loss: 1.3871, G loss: 0.6863\n",
      "[1364/1762] D loss: 1.3885, G loss: 0.6806\n",
      "[1444/1762] D loss: 1.7500, G loss: 1.1336\n",
      "[1524/1762] D loss: 1.3862, G loss: 0.6913\n",
      "[1604/1762] D loss: 1.3858, G loss: 0.6806\n",
      "[1684/1762] D loss: 1.0522, G loss: 1.3083\n",
      "[1762/1762] D loss: 1.3877, G loss: 0.7303\n",
      "train error: \n",
      " D loss: 1.307996, G loss: 0.863202, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 90.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.292300, G loss: 0.908370, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3867, G loss: 0.6954\n",
      "[84/1762] D loss: 1.3872, G loss: 0.6874\n",
      "[164/1762] D loss: 1.3906, G loss: 0.7092\n",
      "[244/1762] D loss: 1.0453, G loss: 1.5063\n",
      "[324/1762] D loss: 1.3869, G loss: 0.6937\n",
      "[404/1762] D loss: 1.1339, G loss: 0.8143\n",
      "[484/1762] D loss: 1.3363, G loss: 0.7766\n",
      "[564/1762] D loss: 1.0498, G loss: 2.7109\n",
      "[644/1762] D loss: 1.3862, G loss: 0.7134\n",
      "[724/1762] D loss: 0.8784, G loss: 1.0037\n",
      "[804/1762] D loss: 1.3872, G loss: 0.6928\n",
      "[884/1762] D loss: 1.0451, G loss: 1.6708\n",
      "[964/1762] D loss: 1.0615, G loss: 1.2510\n",
      "[1044/1762] D loss: 1.3868, G loss: 0.6918\n",
      "[1124/1762] D loss: 1.2546, G loss: 0.9017\n",
      "[1204/1762] D loss: 1.2692, G loss: 0.8703\n",
      "[1284/1762] D loss: 1.2487, G loss: 1.3132\n",
      "[1364/1762] D loss: 1.3871, G loss: 0.6862\n",
      "[1444/1762] D loss: 1.3880, G loss: 0.6726\n",
      "[1524/1762] D loss: 1.3865, G loss: 0.7283\n",
      "[1604/1762] D loss: 1.3870, G loss: 0.7011\n",
      "[1684/1762] D loss: 1.3880, G loss: 0.7266\n",
      "[1762/1762] D loss: 1.3879, G loss: 0.6861\n",
      "train error: \n",
      " D loss: 1.310169, G loss: 0.796183, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 87.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.288510, G loss: 0.850236, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 85.2% \n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1029, G loss: 0.9704\n",
      "[84/1762] D loss: 1.3867, G loss: 0.7053\n",
      "[164/1762] D loss: 1.3882, G loss: 0.6736\n",
      "[244/1762] D loss: 1.3881, G loss: 0.7273\n",
      "[324/1762] D loss: 1.0737, G loss: 1.1674\n",
      "[404/1762] D loss: 1.3890, G loss: 0.7373\n",
      "[484/1762] D loss: 1.2764, G loss: 0.8966\n",
      "[564/1762] D loss: 1.3813, G loss: 0.6556\n",
      "[644/1762] D loss: 1.3861, G loss: 0.7113\n",
      "[724/1762] D loss: 1.3010, G loss: 0.8351\n",
      "[804/1762] D loss: 1.3865, G loss: 0.6879\n",
      "[884/1762] D loss: 1.2784, G loss: 0.9468\n",
      "[964/1762] D loss: 1.1001, G loss: 0.9048\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.6990\n",
      "[1124/1762] D loss: 1.3876, G loss: 0.6738\n",
      "[1204/1762] D loss: 1.0723, G loss: 1.0252\n",
      "[1284/1762] D loss: 1.1077, G loss: 0.9092\n",
      "[1364/1762] D loss: 1.3887, G loss: 0.6472\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.6847\n",
      "[1524/1762] D loss: 1.3872, G loss: 0.6746\n",
      "[1604/1762] D loss: 1.0619, G loss: 1.0937\n",
      "[1684/1762] D loss: 1.0404, G loss: 2.0346\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.6994\n",
      "train error: \n",
      " D loss: 1.324961, G loss: 0.765459, D accuracy: 52.9%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.327186, G loss: 0.781073, D accuracy: 53.1%, cell accuracy: 99.9%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3883, G loss: 0.6869\n",
      "[84/1762] D loss: 1.0965, G loss: 0.9530\n",
      "[164/1762] D loss: 1.3872, G loss: 0.7000\n",
      "[244/1762] D loss: 1.3874, G loss: 0.6689\n",
      "[324/1762] D loss: 1.9349, G loss: 1.1320\n",
      "[404/1762] D loss: 1.3867, G loss: 0.7062\n",
      "[484/1762] D loss: 1.3872, G loss: 0.6961\n",
      "[564/1762] D loss: 1.5189, G loss: 0.8801\n",
      "[644/1762] D loss: 1.0728, G loss: 1.0411\n",
      "[724/1762] D loss: 1.4947, G loss: 0.9110\n",
      "[804/1762] D loss: 1.3865, G loss: 0.7031\n",
      "[884/1762] D loss: 1.3857, G loss: 0.7020\n",
      "[964/1762] D loss: 1.3876, G loss: 0.6632\n",
      "[1044/1762] D loss: 1.3872, G loss: 0.7122\n",
      "[1124/1762] D loss: 1.3871, G loss: 0.6657\n",
      "[1204/1762] D loss: 1.3879, G loss: 0.6940\n",
      "[1284/1762] D loss: 1.3866, G loss: 0.7087\n",
      "[1364/1762] D loss: 1.3866, G loss: 0.6904\n",
      "[1444/1762] D loss: 1.3871, G loss: 0.7156\n",
      "[1524/1762] D loss: 1.4322, G loss: 0.8312\n",
      "[1604/1762] D loss: 1.3867, G loss: 0.6794\n",
      "[1684/1762] D loss: 1.3868, G loss: 0.7006\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6972\n",
      "train error: \n",
      " D loss: 1.322763, G loss: 0.789758, D accuracy: 52.9%, cell accuracy: 99.9%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.333145, G loss: 0.819030, D accuracy: 53.0%, cell accuracy: 99.9%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3872, G loss: 0.6835\n",
      "[84/1762] D loss: 1.0948, G loss: 0.9204\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6877\n",
      "[244/1762] D loss: 1.3867, G loss: 0.6818\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6958\n",
      "[404/1762] D loss: 1.3865, G loss: 0.7022\n",
      "[484/1762] D loss: 1.3923, G loss: 0.6618\n",
      "[564/1762] D loss: 0.9948, G loss: 0.8747\n",
      "[644/1762] D loss: 1.3884, G loss: 0.6777\n",
      "[724/1762] D loss: 1.3909, G loss: 0.7027\n",
      "[804/1762] D loss: 1.3863, G loss: 0.7065\n",
      "[884/1762] D loss: 1.3876, G loss: 0.6749\n",
      "[964/1762] D loss: 1.3868, G loss: 0.6789\n",
      "[1044/1762] D loss: 1.3870, G loss: 0.7123\n",
      "[1124/1762] D loss: 1.3875, G loss: 0.6850\n",
      "[1204/1762] D loss: 1.3865, G loss: 0.7021\n",
      "[1284/1762] D loss: 1.5412, G loss: 0.8889\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6869\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.6910\n",
      "[1524/1762] D loss: 1.3862, G loss: 0.6947\n",
      "[1604/1762] D loss: 1.0809, G loss: 0.9542\n",
      "[1684/1762] D loss: 1.3865, G loss: 0.7028\n",
      "[1762/1762] D loss: 1.3862, G loss: 0.6895\n",
      "train error: \n",
      " D loss: 1.319763, G loss: 0.789656, D accuracy: 53.0%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.325948, G loss: 0.830078, D accuracy: 53.0%, cell accuracy: 99.9%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3874, G loss: 0.6798\n",
      "[84/1762] D loss: 1.1973, G loss: 0.7706\n",
      "[164/1762] D loss: 1.2571, G loss: 0.9804\n",
      "[244/1762] D loss: 1.3865, G loss: 0.7127\n",
      "[324/1762] D loss: 1.3868, G loss: 0.6755\n",
      "[404/1762] D loss: 0.7756, G loss: 1.6433\n",
      "[484/1762] D loss: 1.0611, G loss: 1.1731\n",
      "[564/1762] D loss: 1.3872, G loss: 0.7083\n",
      "[644/1762] D loss: 1.3866, G loss: 0.6854\n",
      "[724/1762] D loss: 1.0645, G loss: 1.1102\n",
      "[804/1762] D loss: 1.3871, G loss: 0.7255\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6988\n",
      "[964/1762] D loss: 1.3870, G loss: 0.6730\n",
      "[1044/1762] D loss: 1.3880, G loss: 0.7169\n",
      "[1124/1762] D loss: 1.3874, G loss: 0.7095\n",
      "[1204/1762] D loss: 1.3871, G loss: 0.6742\n",
      "[1284/1762] D loss: 1.3868, G loss: 0.6933\n",
      "[1364/1762] D loss: 1.3866, G loss: 0.6884\n",
      "[1444/1762] D loss: 1.3868, G loss: 0.6877\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.7004\n",
      "[1604/1762] D loss: 1.4023, G loss: 0.7018\n",
      "[1684/1762] D loss: 1.3866, G loss: 0.7103\n",
      "[1762/1762] D loss: 1.3866, G loss: 0.6826\n",
      "train error: \n",
      " D loss: 1.310583, G loss: 0.791530, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.310958, G loss: 0.817889, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0953, G loss: 0.9298\n",
      "[84/1762] D loss: 1.3865, G loss: 0.7005\n",
      "[164/1762] D loss: 1.3863, G loss: 0.7077\n",
      "[244/1762] D loss: 1.3866, G loss: 0.6857\n",
      "[324/1762] D loss: 1.3866, G loss: 0.6912\n",
      "[404/1762] D loss: 0.7268, G loss: 1.6773\n",
      "[484/1762] D loss: 1.3939, G loss: 0.6396\n",
      "[564/1762] D loss: 1.3870, G loss: 0.7066\n",
      "[644/1762] D loss: 1.3866, G loss: 0.6882\n",
      "[724/1762] D loss: 1.3874, G loss: 0.6937\n",
      "[804/1762] D loss: 1.3874, G loss: 0.6841\n",
      "[884/1762] D loss: 1.3877, G loss: 0.6936\n",
      "[964/1762] D loss: 1.3877, G loss: 0.7159\n",
      "[1044/1762] D loss: 1.3876, G loss: 0.6827\n",
      "[1124/1762] D loss: 1.3870, G loss: 0.6960\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6927\n",
      "[1284/1762] D loss: 1.3878, G loss: 0.6534\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6927\n",
      "[1444/1762] D loss: 1.3889, G loss: 0.7274\n",
      "[1524/1762] D loss: 1.3843, G loss: 0.6978\n",
      "[1604/1762] D loss: 1.3869, G loss: 0.6750\n",
      "[1684/1762] D loss: 1.3872, G loss: 0.6639\n",
      "[1762/1762] D loss: 1.3873, G loss: 0.6645\n",
      "train error: \n",
      " D loss: 1.340074, G loss: 0.796965, D accuracy: 52.9%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.334328, G loss: 0.816898, D accuracy: 52.7%, cell accuracy: 99.9%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3865, G loss: 0.6854\n",
      "[84/1762] D loss: 1.2437, G loss: 1.0014\n",
      "[164/1762] D loss: 1.3865, G loss: 0.6910\n",
      "[244/1762] D loss: 1.3881, G loss: 0.6576\n",
      "[324/1762] D loss: 1.3872, G loss: 0.6933\n",
      "[404/1762] D loss: 1.3867, G loss: 0.6845\n",
      "[484/1762] D loss: 1.0940, G loss: 0.9129\n",
      "[564/1762] D loss: 1.3874, G loss: 0.7113\n",
      "[644/1762] D loss: 1.0948, G loss: 0.9639\n",
      "[724/1762] D loss: 1.3871, G loss: 0.6736\n",
      "[804/1762] D loss: 1.3866, G loss: 0.6894\n",
      "[884/1762] D loss: 1.0908, G loss: 0.9350\n",
      "[964/1762] D loss: 1.3871, G loss: 0.6832\n",
      "[1044/1762] D loss: 1.4652, G loss: 0.8760\n",
      "[1124/1762] D loss: 1.4788, G loss: 0.9066\n",
      "[1204/1762] D loss: 1.3865, G loss: 0.6979\n",
      "[1284/1762] D loss: 1.0820, G loss: 1.0235\n",
      "[1364/1762] D loss: 1.3868, G loss: 0.6936\n",
      "[1444/1762] D loss: 1.0473, G loss: 1.4335\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.6974\n",
      "[1604/1762] D loss: 1.3639, G loss: 0.6852\n",
      "[1684/1762] D loss: 1.3879, G loss: 0.7152\n",
      "[1762/1762] D loss: 1.3880, G loss: 0.7239\n",
      "train error: \n",
      " D loss: 1.329634, G loss: 0.787594, D accuracy: 53.2%, cell accuracy: 99.9%, board accuracy: 93.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.312991, G loss: 0.831656, D accuracy: 54.5%, cell accuracy: 99.9%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5416, G loss: 0.9795\n",
      "[84/1762] D loss: 1.3857, G loss: 0.6893\n",
      "[164/1762] D loss: 1.3865, G loss: 0.7012\n",
      "[244/1762] D loss: 1.3871, G loss: 0.7016\n",
      "[324/1762] D loss: 1.3870, G loss: 0.6889\n",
      "[404/1762] D loss: 1.3866, G loss: 0.6964\n",
      "[484/1762] D loss: 1.3875, G loss: 0.6701\n",
      "[564/1762] D loss: 1.3871, G loss: 0.6686\n",
      "[644/1762] D loss: 1.3868, G loss: 0.6940\n",
      "[724/1762] D loss: 1.2171, G loss: 1.5035\n",
      "[804/1762] D loss: 1.3876, G loss: 0.6655\n",
      "[884/1762] D loss: 1.1681, G loss: 0.9748\n",
      "[964/1762] D loss: 1.3865, G loss: 0.7006\n",
      "[1044/1762] D loss: 1.5120, G loss: 0.9421\n",
      "[1124/1762] D loss: 1.3883, G loss: 0.6883\n",
      "[1204/1762] D loss: 1.3870, G loss: 0.7115\n",
      "[1284/1762] D loss: 1.3870, G loss: 0.6931\n",
      "[1364/1762] D loss: 1.3884, G loss: 0.6651\n",
      "[1444/1762] D loss: 1.3887, G loss: 0.7123\n",
      "[1524/1762] D loss: 1.3873, G loss: 0.6901\n",
      "[1604/1762] D loss: 1.3165, G loss: 0.6990\n",
      "[1684/1762] D loss: 1.4034, G loss: 0.5983\n",
      "[1762/1762] D loss: 1.3870, G loss: 0.6760\n",
      "train error: \n",
      " D loss: 1.341573, G loss: 0.751273, D accuracy: 53.1%, cell accuracy: 99.9%, board accuracy: 89.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.342639, G loss: 0.751586, D accuracy: 53.0%, cell accuracy: 99.9%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3882, G loss: 0.6831\n",
      "[84/1762] D loss: 1.4950, G loss: 0.9188\n",
      "[164/1762] D loss: 1.3877, G loss: 0.6881\n",
      "[244/1762] D loss: 1.3915, G loss: 0.7422\n",
      "[324/1762] D loss: 1.3864, G loss: 0.6855\n",
      "[404/1762] D loss: 1.1847, G loss: 0.9249\n",
      "[484/1762] D loss: 1.3874, G loss: 0.7200\n",
      "[564/1762] D loss: 1.3870, G loss: 0.7060\n",
      "[644/1762] D loss: 1.0744, G loss: 1.0528\n",
      "[724/1762] D loss: 1.3869, G loss: 0.7161\n",
      "[804/1762] D loss: 0.7368, G loss: 1.7109\n",
      "[884/1762] D loss: 1.3871, G loss: 0.6727\n",
      "[964/1762] D loss: 1.0525, G loss: 1.5029\n",
      "[1044/1762] D loss: 1.3885, G loss: 0.7177\n",
      "[1124/1762] D loss: 1.6799, G loss: 1.1358\n",
      "[1204/1762] D loss: 0.7468, G loss: 1.4967\n",
      "[1284/1762] D loss: 1.0048, G loss: 1.0412\n",
      "[1364/1762] D loss: 1.3868, G loss: 0.6981\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6931\n",
      "[1524/1762] D loss: 1.0651, G loss: 1.1528\n",
      "[1604/1762] D loss: 1.0739, G loss: 1.0256\n",
      "[1684/1762] D loss: 1.3865, G loss: 0.7020\n",
      "[1762/1762] D loss: 1.3877, G loss: 0.6652\n",
      "train error: \n",
      " D loss: 1.311195, G loss: 0.800158, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 90.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.314780, G loss: 0.830039, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7481, G loss: 1.5488\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6922\n",
      "[164/1762] D loss: 1.3865, G loss: 0.6852\n",
      "[244/1762] D loss: 1.3870, G loss: 0.6705\n",
      "[324/1762] D loss: 1.3874, G loss: 0.6715\n",
      "[404/1762] D loss: 1.0823, G loss: 0.9946\n",
      "[484/1762] D loss: 1.3866, G loss: 0.6714\n",
      "[564/1762] D loss: 1.3903, G loss: 0.6569\n",
      "[644/1762] D loss: 1.3857, G loss: 0.6739\n",
      "[724/1762] D loss: 1.3869, G loss: 0.6833\n",
      "[804/1762] D loss: 1.3862, G loss: 0.6934\n",
      "[884/1762] D loss: 1.3862, G loss: 0.6987\n",
      "[964/1762] D loss: 1.3864, G loss: 0.6822\n",
      "[1044/1762] D loss: 1.3772, G loss: 0.7183\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.6812\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6922\n",
      "[1284/1762] D loss: 1.3633, G loss: 0.7019\n",
      "[1364/1762] D loss: 1.3860, G loss: 0.6883\n",
      "[1444/1762] D loss: 1.3792, G loss: 0.6957\n",
      "[1524/1762] D loss: 1.3874, G loss: 0.6903\n",
      "[1604/1762] D loss: 1.2771, G loss: 0.9624\n",
      "[1684/1762] D loss: 1.4163, G loss: 0.5493\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6773\n",
      "train error: \n",
      " D loss: 1.329766, G loss: 0.745886, D accuracy: 52.8%, cell accuracy: 99.9%, board accuracy: 90.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.342251, G loss: 0.769202, D accuracy: 53.4%, cell accuracy: 99.9%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4688, G loss: 0.6620\n",
      "[84/1762] D loss: 1.1682, G loss: 0.7158\n",
      "[164/1762] D loss: 1.3858, G loss: 0.7012\n",
      "[244/1762] D loss: 1.2169, G loss: 1.1985\n",
      "[324/1762] D loss: 1.3867, G loss: 0.7060\n",
      "[404/1762] D loss: 1.3882, G loss: 0.7173\n",
      "[484/1762] D loss: 1.3857, G loss: 0.6782\n",
      "[564/1762] D loss: 1.3830, G loss: 0.7126\n",
      "[644/1762] D loss: 1.3876, G loss: 0.6765\n",
      "[724/1762] D loss: 1.0872, G loss: 0.9744\n",
      "[804/1762] D loss: 1.3873, G loss: 0.7060\n",
      "[884/1762] D loss: 1.2876, G loss: 0.8431\n",
      "[964/1762] D loss: 1.3878, G loss: 0.6984\n",
      "[1044/1762] D loss: 1.0681, G loss: 1.0786\n",
      "[1124/1762] D loss: 1.3868, G loss: 0.6889\n",
      "[1204/1762] D loss: 1.3880, G loss: 0.6531\n",
      "[1284/1762] D loss: 1.3871, G loss: 0.6827\n",
      "[1364/1762] D loss: 1.0564, G loss: 1.2330\n",
      "[1444/1762] D loss: 1.3875, G loss: 0.7204\n",
      "[1524/1762] D loss: 1.3881, G loss: 0.6730\n",
      "[1604/1762] D loss: 1.3878, G loss: 0.6871\n",
      "[1684/1762] D loss: 1.0975, G loss: 0.9136\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.7017\n",
      "train error: \n",
      " D loss: 1.319111, G loss: 0.800415, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 91.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.324424, G loss: 0.845866, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0845, G loss: 0.9878\n",
      "[84/1762] D loss: 1.3895, G loss: 0.6759\n",
      "[164/1762] D loss: 1.3855, G loss: 0.6969\n",
      "[244/1762] D loss: 1.0981, G loss: 0.9480\n",
      "[324/1762] D loss: 1.3874, G loss: 0.7015\n",
      "[404/1762] D loss: 1.0705, G loss: 1.0601\n",
      "[484/1762] D loss: 1.3872, G loss: 0.6810\n",
      "[564/1762] D loss: 1.3813, G loss: 0.7143\n",
      "[644/1762] D loss: 1.3870, G loss: 0.7107\n",
      "[724/1762] D loss: 1.3879, G loss: 0.7168\n",
      "[804/1762] D loss: 1.3871, G loss: 0.6961\n",
      "[884/1762] D loss: 1.3873, G loss: 0.6819\n",
      "[964/1762] D loss: 1.0527, G loss: 1.4311\n",
      "[1044/1762] D loss: 1.3873, G loss: 0.6732\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.6897\n",
      "[1204/1762] D loss: 1.3870, G loss: 0.7191\n",
      "[1284/1762] D loss: 1.3866, G loss: 0.7035\n",
      "[1364/1762] D loss: 1.3862, G loss: 0.6975\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6943\n",
      "[1524/1762] D loss: 1.6696, G loss: 0.5796\n",
      "[1604/1762] D loss: 1.3879, G loss: 0.6470\n",
      "[1684/1762] D loss: 1.5399, G loss: 0.9547\n",
      "[1762/1762] D loss: 0.8109, G loss: 1.1263\n",
      "train error: \n",
      " D loss: 1.318724, G loss: 0.786451, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 91.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.320033, G loss: 0.808285, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 91.4% \n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1046, G loss: 0.9021\n",
      "[84/1762] D loss: 1.3875, G loss: 0.7027\n",
      "[164/1762] D loss: 1.3840, G loss: 0.7277\n",
      "[244/1762] D loss: 1.3879, G loss: 0.7424\n",
      "[324/1762] D loss: 1.0965, G loss: 0.9297\n",
      "[404/1762] D loss: 1.3867, G loss: 0.7077\n",
      "[484/1762] D loss: 1.3813, G loss: 0.7041\n",
      "[564/1762] D loss: 1.1487, G loss: 1.3908\n",
      "[644/1762] D loss: 1.4388, G loss: 0.8465\n",
      "[724/1762] D loss: 1.3862, G loss: 0.6997\n",
      "[804/1762] D loss: 1.3866, G loss: 0.6796\n",
      "[884/1762] D loss: 1.3873, G loss: 0.6852\n",
      "[964/1762] D loss: 1.1117, G loss: 1.0334\n",
      "[1044/1762] D loss: 1.7311, G loss: 1.1260\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.7003\n",
      "[1204/1762] D loss: 1.3878, G loss: 0.7173\n",
      "[1284/1762] D loss: 1.3862, G loss: 0.6855\n",
      "[1364/1762] D loss: 1.3875, G loss: 0.6916\n",
      "[1444/1762] D loss: 1.3437, G loss: 0.6136\n",
      "[1524/1762] D loss: 1.3933, G loss: 0.7531\n",
      "[1604/1762] D loss: 1.3901, G loss: 0.7045\n",
      "[1684/1762] D loss: 1.0455, G loss: 1.4922\n",
      "[1762/1762] D loss: 1.3857, G loss: 0.7207\n",
      "train error: \n",
      " D loss: 1.302193, G loss: 0.926964, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 90.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.336374, G loss: 1.008681, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3884, G loss: 0.6846\n",
      "[84/1762] D loss: 1.3869, G loss: 0.6948\n",
      "[164/1762] D loss: 1.3855, G loss: 0.6821\n",
      "[244/1762] D loss: 1.2415, G loss: 0.8878\n",
      "[324/1762] D loss: 1.2456, G loss: 1.0434\n",
      "[404/1762] D loss: 1.1030, G loss: 0.8930\n",
      "[484/1762] D loss: 1.3848, G loss: 0.7532\n",
      "[564/1762] D loss: 1.3877, G loss: 0.7237\n",
      "[644/1762] D loss: 1.3867, G loss: 0.7240\n",
      "[724/1762] D loss: 1.0887, G loss: 0.9566\n",
      "[804/1762] D loss: 1.3993, G loss: 0.7544\n",
      "[884/1762] D loss: 1.0687, G loss: 1.1255\n",
      "[964/1762] D loss: 1.3894, G loss: 0.6917\n",
      "[1044/1762] D loss: 1.3871, G loss: 0.6955\n",
      "[1124/1762] D loss: 1.0433, G loss: 1.6325\n",
      "[1204/1762] D loss: 1.0625, G loss: 1.1291\n",
      "[1284/1762] D loss: 1.3866, G loss: 0.6878\n",
      "[1364/1762] D loss: 0.7230, G loss: 1.8888\n",
      "[1444/1762] D loss: 1.3895, G loss: 0.7010\n",
      "[1524/1762] D loss: 1.3862, G loss: 0.6895\n",
      "[1604/1762] D loss: 1.0438, G loss: 1.5554\n",
      "[1684/1762] D loss: 1.0406, G loss: 2.0352\n",
      "[1762/1762] D loss: 1.3848, G loss: 0.7009\n",
      "train error: \n",
      " D loss: 1.289291, G loss: 0.968482, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 90.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.261680, G loss: 1.058996, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3867, G loss: 0.6974\n",
      "[84/1762] D loss: 1.0471, G loss: 1.4921\n",
      "[164/1762] D loss: 1.3882, G loss: 0.7319\n",
      "[244/1762] D loss: 1.3866, G loss: 0.6817\n",
      "[324/1762] D loss: 1.3865, G loss: 0.6839\n",
      "[404/1762] D loss: 1.3867, G loss: 0.6860\n",
      "[484/1762] D loss: 0.7028, G loss: 2.3960\n",
      "[564/1762] D loss: 1.3867, G loss: 0.7001\n",
      "[644/1762] D loss: 1.0401, G loss: 2.3008\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6931\n",
      "[804/1762] D loss: 1.3867, G loss: 0.7031\n",
      "[884/1762] D loss: 1.3883, G loss: 0.7273\n",
      "[964/1762] D loss: 1.0443, G loss: 1.6008\n",
      "[1044/1762] D loss: 1.3869, G loss: 0.7065\n",
      "[1124/1762] D loss: 1.3873, G loss: 0.7155\n",
      "[1204/1762] D loss: 1.3876, G loss: 0.6624\n",
      "[1284/1762] D loss: 1.3892, G loss: 0.6449\n",
      "[1364/1762] D loss: 1.0402, G loss: 2.2901\n",
      "[1444/1762] D loss: 1.3875, G loss: 0.6950\n",
      "[1524/1762] D loss: 1.3865, G loss: 0.6803\n",
      "[1604/1762] D loss: 1.0419, G loss: 1.7602\n",
      "[1684/1762] D loss: 1.3873, G loss: 0.6781\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.6875\n",
      "train error: \n",
      " D loss: 1.283749, G loss: 1.064669, D accuracy: 54.4%, cell accuracy: 99.9%, board accuracy: 89.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.251499, G loss: 1.181204, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 85.9% \n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3848, G loss: 0.7091\n",
      "[84/1762] D loss: 1.3896, G loss: 0.6924\n",
      "[164/1762] D loss: 1.0414, G loss: 2.7284\n",
      "[244/1762] D loss: 1.0413, G loss: 1.9074\n",
      "[324/1762] D loss: 1.3922, G loss: 0.6344\n",
      "[404/1762] D loss: 1.0418, G loss: 2.0533\n",
      "[484/1762] D loss: 1.3941, G loss: 0.7344\n",
      "[564/1762] D loss: 1.2677, G loss: 1.1547\n",
      "[644/1762] D loss: 1.3880, G loss: 0.7422\n",
      "[724/1762] D loss: 1.2027, G loss: 1.8718\n",
      "[804/1762] D loss: 1.3863, G loss: 0.6952\n",
      "[884/1762] D loss: 1.3861, G loss: 0.6867\n",
      "[964/1762] D loss: 1.3399, G loss: 0.7616\n",
      "[1044/1762] D loss: 1.3869, G loss: 0.6867\n",
      "[1124/1762] D loss: 1.3871, G loss: 0.6769\n",
      "[1204/1762] D loss: 1.3866, G loss: 0.6963\n",
      "[1284/1762] D loss: 1.0410, G loss: 2.2487\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6955\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6944\n",
      "[1524/1762] D loss: 1.0453, G loss: 1.7062\n",
      "[1604/1762] D loss: 1.0425, G loss: 1.7348\n",
      "[1684/1762] D loss: 1.0447, G loss: 1.8191\n",
      "[1762/1762] D loss: 1.3878, G loss: 0.7282\n",
      "train error: \n",
      " D loss: 1.287261, G loss: 1.064511, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 91.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.259716, G loss: 1.192015, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0433, G loss: 1.6259\n",
      "[84/1762] D loss: 1.3861, G loss: 0.6880\n",
      "[164/1762] D loss: 1.3862, G loss: 0.6971\n",
      "[244/1762] D loss: 1.3889, G loss: 0.6950\n",
      "[324/1762] D loss: 1.3880, G loss: 0.6846\n",
      "[404/1762] D loss: 1.0374, G loss: 2.3436\n",
      "[484/1762] D loss: 1.3096, G loss: 1.7993\n",
      "[564/1762] D loss: 0.6961, G loss: 3.0407\n",
      "[644/1762] D loss: 1.3910, G loss: 0.7150\n",
      "[724/1762] D loss: 1.3860, G loss: 0.7019\n",
      "[804/1762] D loss: 1.0445, G loss: 1.6008\n",
      "[884/1762] D loss: 1.3873, G loss: 0.6977\n",
      "[964/1762] D loss: 1.3858, G loss: 0.6906\n",
      "[1044/1762] D loss: 1.3868, G loss: 0.7067\n",
      "[1124/1762] D loss: 1.3878, G loss: 0.6875\n",
      "[1204/1762] D loss: 1.3866, G loss: 0.6865\n",
      "[1284/1762] D loss: 1.3889, G loss: 0.6907\n",
      "[1364/1762] D loss: 1.0463, G loss: 1.8912\n",
      "[1444/1762] D loss: 1.3882, G loss: 0.6585\n",
      "[1524/1762] D loss: 1.3894, G loss: 0.7334\n",
      "[1604/1762] D loss: 1.3833, G loss: 0.7026\n",
      "[1684/1762] D loss: 1.3872, G loss: 0.7138\n",
      "[1762/1762] D loss: 1.3939, G loss: 0.7814\n",
      "train error: \n",
      " D loss: 1.313615, G loss: 0.815211, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 89.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.292077, G loss: 0.860786, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3871, G loss: 0.6878\n",
      "[84/1762] D loss: 1.0411, G loss: 1.8427\n",
      "[164/1762] D loss: 1.3876, G loss: 0.6681\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6899\n",
      "[324/1762] D loss: 1.0456, G loss: 1.5233\n",
      "[404/1762] D loss: 1.0433, G loss: 1.6532\n",
      "[484/1762] D loss: 1.3876, G loss: 0.7093\n",
      "[564/1762] D loss: 1.3871, G loss: 0.6789\n",
      "[644/1762] D loss: 1.3868, G loss: 0.7205\n",
      "[724/1762] D loss: 1.3866, G loss: 0.7090\n",
      "[804/1762] D loss: 1.3888, G loss: 0.6925\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6940\n",
      "[964/1762] D loss: 1.3865, G loss: 0.6826\n",
      "[1044/1762] D loss: 1.3874, G loss: 0.6630\n",
      "[1124/1762] D loss: 1.3873, G loss: 0.6735\n",
      "[1204/1762] D loss: 1.3865, G loss: 0.7158\n",
      "[1284/1762] D loss: 1.3899, G loss: 0.7448\n",
      "[1364/1762] D loss: 1.0400, G loss: 2.1644\n",
      "[1444/1762] D loss: 1.3122, G loss: 0.8505\n",
      "[1524/1762] D loss: 0.6939, G loss: 4.0514\n",
      "[1604/1762] D loss: 1.0440, G loss: 1.7363\n",
      "[1684/1762] D loss: 1.3874, G loss: 0.7160\n",
      "[1762/1762] D loss: 1.3866, G loss: 0.7030\n",
      "train error: \n",
      " D loss: 1.276161, G loss: 1.175466, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 86.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.257085, G loss: 1.290284, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 83.4% \n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3867, G loss: 0.7014\n",
      "[84/1762] D loss: 1.1561, G loss: 3.6700\n",
      "[164/1762] D loss: 1.3881, G loss: 0.6594\n",
      "[244/1762] D loss: 1.0457, G loss: 1.9749\n",
      "[324/1762] D loss: 1.3893, G loss: 0.6671\n",
      "[404/1762] D loss: 1.3874, G loss: 0.6649\n",
      "[484/1762] D loss: 1.3868, G loss: 0.6998\n",
      "[564/1762] D loss: 1.3870, G loss: 0.6798\n",
      "[644/1762] D loss: 1.0411, G loss: 2.0294\n",
      "[724/1762] D loss: 1.0434, G loss: 2.1014\n",
      "[804/1762] D loss: 1.0407, G loss: 2.1542\n",
      "[884/1762] D loss: 0.6936, G loss: 4.0735\n",
      "[964/1762] D loss: 1.3932, G loss: 0.7300\n",
      "[1044/1762] D loss: 1.3883, G loss: 0.7257\n",
      "[1124/1762] D loss: 1.0573, G loss: 2.1959\n",
      "[1204/1762] D loss: 1.3881, G loss: 0.7216\n",
      "[1284/1762] D loss: 1.3870, G loss: 0.7206\n",
      "[1364/1762] D loss: 1.3869, G loss: 0.7046\n",
      "[1444/1762] D loss: 1.0396, G loss: 2.2277\n",
      "[1524/1762] D loss: 1.3868, G loss: 0.6721\n",
      "[1604/1762] D loss: 1.3866, G loss: 0.6947\n",
      "[1684/1762] D loss: 1.3855, G loss: 0.6795\n",
      "[1762/1762] D loss: 1.3866, G loss: 0.7086\n",
      "train error: \n",
      " D loss: 1.280384, G loss: 1.225810, D accuracy: 55.4%, cell accuracy: 99.8%, board accuracy: 82.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.259051, G loss: 1.387535, D accuracy: 56.6%, cell accuracy: 99.8%, board accuracy: 82.0% \n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2662, G loss: 0.8456\n",
      "[84/1762] D loss: 1.0401, G loss: 2.8025\n",
      "[164/1762] D loss: 1.3927, G loss: 0.6548\n",
      "[244/1762] D loss: 1.3879, G loss: 0.7063\n",
      "[324/1762] D loss: 1.2057, G loss: 3.0915\n",
      "[404/1762] D loss: 1.3879, G loss: 0.6772\n",
      "[484/1762] D loss: 1.3867, G loss: 0.6499\n",
      "[564/1762] D loss: 1.0398, G loss: 2.6374\n",
      "[644/1762] D loss: 1.3922, G loss: 0.6305\n",
      "[724/1762] D loss: 1.4130, G loss: 0.7828\n",
      "[804/1762] D loss: 1.3917, G loss: 0.6832\n",
      "[884/1762] D loss: 1.1890, G loss: 1.6471\n",
      "[964/1762] D loss: 1.0311, G loss: 2.0311\n",
      "[1044/1762] D loss: 1.2690, G loss: 0.8540\n",
      "[1124/1762] D loss: 1.0410, G loss: 1.7878\n",
      "[1204/1762] D loss: 1.3881, G loss: 0.6712\n",
      "[1284/1762] D loss: 1.3867, G loss: 0.6969\n",
      "[1364/1762] D loss: 1.3873, G loss: 0.6879\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.7169\n",
      "[1524/1762] D loss: 1.3894, G loss: 0.6604\n",
      "[1604/1762] D loss: 1.3708, G loss: 0.7103\n",
      "[1684/1762] D loss: 1.3891, G loss: 0.7146\n",
      "[1762/1762] D loss: 1.3875, G loss: 0.6635\n",
      "train error: \n",
      " D loss: 1.285378, G loss: 1.143086, D accuracy: 54.0%, cell accuracy: 99.9%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.262932, G loss: 1.276064, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0402, G loss: 2.2713\n",
      "[84/1762] D loss: 1.3871, G loss: 0.6734\n",
      "[164/1762] D loss: 1.0414, G loss: 2.3231\n",
      "[244/1762] D loss: 1.3867, G loss: 0.6947\n",
      "[324/1762] D loss: 0.6940, G loss: 3.7454\n",
      "[404/1762] D loss: 1.3873, G loss: 0.6717\n",
      "[484/1762] D loss: 1.0403, G loss: 2.3571\n",
      "[564/1762] D loss: 1.3863, G loss: 0.6921\n",
      "[644/1762] D loss: 1.3865, G loss: 0.7012\n",
      "[724/1762] D loss: 1.3869, G loss: 0.6810\n",
      "[804/1762] D loss: 1.3862, G loss: 0.6991\n",
      "[884/1762] D loss: 1.3898, G loss: 0.7462\n",
      "[964/1762] D loss: 1.3869, G loss: 0.6836\n",
      "[1044/1762] D loss: 1.0401, G loss: 2.2929\n",
      "[1124/1762] D loss: 1.0409, G loss: 2.0021\n",
      "[1204/1762] D loss: 1.3865, G loss: 0.6899\n",
      "[1284/1762] D loss: 1.3866, G loss: 0.6851\n",
      "[1364/1762] D loss: 1.3868, G loss: 0.7020\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.6922\n",
      "[1524/1762] D loss: 1.3875, G loss: 0.6818\n",
      "[1604/1762] D loss: 1.0404, G loss: 2.3206\n",
      "[1684/1762] D loss: 1.3897, G loss: 0.6484\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.7026\n",
      "train error: \n",
      " D loss: 1.286611, G loss: 1.148359, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.264563, G loss: 1.253628, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3865, G loss: 0.6938\n",
      "[84/1762] D loss: 1.3867, G loss: 0.6926\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6965\n",
      "[244/1762] D loss: 1.3864, G loss: 0.6986\n",
      "[324/1762] D loss: 1.3866, G loss: 0.6932\n",
      "[404/1762] D loss: 1.3865, G loss: 0.6971\n",
      "[484/1762] D loss: 1.0410, G loss: 2.2948\n",
      "[564/1762] D loss: 1.3866, G loss: 0.6954\n",
      "[644/1762] D loss: 1.3868, G loss: 0.6741\n",
      "[724/1762] D loss: 1.3861, G loss: 0.6943\n",
      "[804/1762] D loss: 1.3866, G loss: 0.6823\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6977\n",
      "[964/1762] D loss: 1.3865, G loss: 0.6865\n",
      "[1044/1762] D loss: 1.0399, G loss: 2.6124\n",
      "[1124/1762] D loss: 1.0420, G loss: 2.4851\n",
      "[1204/1762] D loss: 1.3978, G loss: 0.6033\n",
      "[1284/1762] D loss: 1.0470, G loss: 1.4725\n",
      "[1364/1762] D loss: 1.3873, G loss: 0.7108\n",
      "[1444/1762] D loss: 1.0408, G loss: 2.1578\n",
      "[1524/1762] D loss: 1.0408, G loss: 2.0600\n",
      "[1604/1762] D loss: 1.0403, G loss: 2.4285\n",
      "[1684/1762] D loss: 1.3866, G loss: 0.6995\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.7073\n",
      "train error: \n",
      " D loss: 1.289887, G loss: 1.070204, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.262511, G loss: 1.152201, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6938\n",
      "[84/1762] D loss: 1.0402, G loss: 2.1157\n",
      "[164/1762] D loss: 1.0403, G loss: 2.0900\n",
      "[244/1762] D loss: 1.3869, G loss: 0.6653\n",
      "[324/1762] D loss: 1.3868, G loss: 0.7034\n",
      "[404/1762] D loss: 1.0399, G loss: 2.3901\n",
      "[484/1762] D loss: 1.0404, G loss: 2.1214\n",
      "[564/1762] D loss: 1.0399, G loss: 2.3847\n",
      "[644/1762] D loss: 1.3865, G loss: 0.6840\n",
      "[724/1762] D loss: 1.3867, G loss: 0.6976\n",
      "[804/1762] D loss: 0.6937, G loss: 3.7554\n",
      "[884/1762] D loss: 1.3863, G loss: 0.7005\n",
      "[964/1762] D loss: 1.3864, G loss: 0.6905\n",
      "[1044/1762] D loss: 1.3868, G loss: 0.6817\n",
      "[1124/1762] D loss: 1.3861, G loss: 0.6919\n",
      "[1204/1762] D loss: 1.3865, G loss: 0.7004\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.7057\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6893\n",
      "[1444/1762] D loss: 1.3869, G loss: 0.6710\n",
      "[1524/1762] D loss: 1.0397, G loss: 2.4363\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6926\n",
      "[1684/1762] D loss: 1.0390, G loss: 2.4452\n",
      "[1762/1762] D loss: 0.6952, G loss: 3.7141\n",
      "train error: \n",
      " D loss: 1.290467, G loss: 1.223698, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 91.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.264562, G loss: 1.395565, D accuracy: 55.2%, cell accuracy: 99.7%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6954\n",
      "[84/1762] D loss: 1.0377, G loss: 2.5017\n",
      "[164/1762] D loss: 1.3896, G loss: 0.7422\n",
      "[244/1762] D loss: 1.3611, G loss: 0.7262\n",
      "[324/1762] D loss: 0.9043, G loss: 4.6575\n",
      "[404/1762] D loss: 1.0414, G loss: 9.1338\n",
      "[484/1762] D loss: 1.3900, G loss: 0.6380\n",
      "[564/1762] D loss: 1.3877, G loss: 0.6693\n",
      "[644/1762] D loss: 1.0424, G loss: 2.5058\n",
      "[724/1762] D loss: 1.3879, G loss: 0.7017\n",
      "[804/1762] D loss: 1.3891, G loss: 0.6498\n",
      "[884/1762] D loss: 1.3523, G loss: 0.7846\n",
      "[964/1762] D loss: 1.3862, G loss: 0.6737\n",
      "[1044/1762] D loss: 1.0418, G loss: 2.7280\n",
      "[1124/1762] D loss: 1.3868, G loss: 0.7070\n",
      "[1204/1762] D loss: 1.0434, G loss: 2.0928\n",
      "[1284/1762] D loss: 1.3876, G loss: 0.6776\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6809\n",
      "[1444/1762] D loss: 1.0404, G loss: 2.0512\n",
      "[1524/1762] D loss: 1.0406, G loss: 2.2064\n",
      "[1604/1762] D loss: 1.3866, G loss: 0.6999\n",
      "[1684/1762] D loss: 1.3870, G loss: 0.6989\n",
      "[1762/1762] D loss: 1.3869, G loss: 0.6700\n",
      "train error: \n",
      " D loss: 1.282598, G loss: 1.228600, D accuracy: 54.2%, cell accuracy: 99.9%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.258886, G loss: 1.366561, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3662, G loss: 0.7481\n",
      "[84/1762] D loss: 1.3870, G loss: 0.7129\n",
      "[164/1762] D loss: 1.3864, G loss: 0.6833\n",
      "[244/1762] D loss: 1.3871, G loss: 0.6684\n",
      "[324/1762] D loss: 1.3867, G loss: 0.6965\n",
      "[404/1762] D loss: 1.3863, G loss: 0.6948\n",
      "[484/1762] D loss: 1.0403, G loss: 2.2302\n",
      "[564/1762] D loss: 1.3886, G loss: 0.6456\n",
      "[644/1762] D loss: 1.3880, G loss: 0.6561\n",
      "[724/1762] D loss: 1.3864, G loss: 0.7040\n",
      "[804/1762] D loss: 1.3867, G loss: 0.6769\n",
      "[884/1762] D loss: 1.3865, G loss: 0.7105\n",
      "[964/1762] D loss: 1.3911, G loss: 0.6382\n",
      "[1044/1762] D loss: 1.3915, G loss: 0.7036\n",
      "[1124/1762] D loss: 1.0402, G loss: 2.2391\n",
      "[1204/1762] D loss: 1.3865, G loss: 0.6954\n",
      "[1284/1762] D loss: 1.3872, G loss: 0.6724\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6906\n",
      "[1444/1762] D loss: 1.3887, G loss: 0.6931\n",
      "[1524/1762] D loss: 1.3865, G loss: 0.6735\n",
      "[1604/1762] D loss: 1.3861, G loss: 0.6901\n",
      "[1684/1762] D loss: 1.2582, G loss: 1.0346\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6941\n",
      "train error: \n",
      " D loss: 1.285523, G loss: 1.286588, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.263811, G loss: 1.312044, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3949, G loss: 0.7197\n",
      "[84/1762] D loss: 1.3868, G loss: 0.7059\n",
      "[164/1762] D loss: 1.0403, G loss: 2.4812\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6839\n",
      "[324/1762] D loss: 1.3864, G loss: 0.6979\n",
      "[404/1762] D loss: 1.3866, G loss: 0.6901\n",
      "[484/1762] D loss: 1.3886, G loss: 0.6851\n",
      "[564/1762] D loss: 1.3870, G loss: 0.7142\n",
      "[644/1762] D loss: 1.3867, G loss: 0.6776\n",
      "[724/1762] D loss: 1.3869, G loss: 0.7037\n",
      "[804/1762] D loss: 1.3877, G loss: 0.6698\n",
      "[884/1762] D loss: 1.0400, G loss: 2.4262\n",
      "[964/1762] D loss: 1.0400, G loss: 2.3846\n",
      "[1044/1762] D loss: 1.3874, G loss: 0.6943\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.6881\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6961\n",
      "[1284/1762] D loss: 0.6941, G loss: 3.5731\n",
      "[1364/1762] D loss: 1.3866, G loss: 0.6934\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6988\n",
      "[1524/1762] D loss: 1.3867, G loss: 0.7098\n",
      "[1604/1762] D loss: 1.0401, G loss: 2.3551\n",
      "[1684/1762] D loss: 1.0399, G loss: 2.4103\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.6803\n",
      "train error: \n",
      " D loss: 1.287871, G loss: 1.196682, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.260868, G loss: 1.287408, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6885\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6928\n",
      "[164/1762] D loss: 0.6934, G loss: 4.4038\n",
      "[244/1762] D loss: 1.0400, G loss: 2.3194\n",
      "[324/1762] D loss: 1.3864, G loss: 0.6975\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6871\n",
      "[484/1762] D loss: 1.3866, G loss: 0.6834\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6834\n",
      "[644/1762] D loss: 1.3866, G loss: 0.6789\n",
      "[724/1762] D loss: 1.0400, G loss: 2.8462\n",
      "[804/1762] D loss: 1.3891, G loss: 0.6840\n",
      "[884/1762] D loss: 1.3875, G loss: 0.6718\n",
      "[964/1762] D loss: 1.3873, G loss: 0.6738\n",
      "[1044/1762] D loss: 1.2252, G loss: 4.8874\n",
      "[1124/1762] D loss: 0.9885, G loss: 2.2324\n",
      "[1204/1762] D loss: 0.6936, G loss: 3.8810\n",
      "[1284/1762] D loss: 1.3868, G loss: 0.6706\n",
      "[1364/1762] D loss: 1.3869, G loss: 0.7104\n",
      "[1444/1762] D loss: 1.0408, G loss: 1.9550\n",
      "[1524/1762] D loss: 1.3881, G loss: 0.6599\n",
      "[1604/1762] D loss: 1.0400, G loss: 2.2926\n",
      "[1684/1762] D loss: 1.0383, G loss: 2.2677\n",
      "[1762/1762] D loss: 1.3878, G loss: 0.6602\n",
      "train error: \n",
      " D loss: 1.287148, G loss: 1.185988, D accuracy: 54.0%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.260847, G loss: 1.326669, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3876, G loss: 0.6795\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6832\n",
      "[164/1762] D loss: 1.0406, G loss: 2.4441\n",
      "[244/1762] D loss: 1.0413, G loss: 2.0932\n",
      "[324/1762] D loss: 1.3867, G loss: 0.6782\n",
      "[404/1762] D loss: 1.3868, G loss: 0.7040\n",
      "[484/1762] D loss: 1.0399, G loss: 2.3357\n",
      "[564/1762] D loss: 1.3876, G loss: 0.6831\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6958\n",
      "[724/1762] D loss: 1.3861, G loss: 0.6889\n",
      "[804/1762] D loss: 1.3862, G loss: 0.6887\n",
      "[884/1762] D loss: 1.3871, G loss: 0.6801\n",
      "[964/1762] D loss: 1.3862, G loss: 0.6903\n",
      "[1044/1762] D loss: 1.0399, G loss: 2.5498\n",
      "[1124/1762] D loss: 1.0400, G loss: 2.2617\n",
      "[1204/1762] D loss: 1.0399, G loss: 2.4001\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6927\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6859\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6875\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.6960\n",
      "[1604/1762] D loss: 1.3868, G loss: 0.7159\n",
      "[1684/1762] D loss: 1.3860, G loss: 0.6996\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6923\n",
      "train error: \n",
      " D loss: 1.286686, G loss: 1.167856, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.259354, G loss: 1.248352, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3871, G loss: 0.7113\n",
      "[84/1762] D loss: 1.3865, G loss: 0.6784\n",
      "[164/1762] D loss: 1.3866, G loss: 0.6759\n",
      "[244/1762] D loss: 1.0400, G loss: 2.2352\n",
      "[324/1762] D loss: 1.3870, G loss: 0.6676\n",
      "[404/1762] D loss: 1.3860, G loss: 0.6722\n",
      "[484/1762] D loss: 1.3870, G loss: 0.7033\n",
      "[564/1762] D loss: 1.3869, G loss: 0.6999\n",
      "[644/1762] D loss: 1.0400, G loss: 2.3357\n",
      "[724/1762] D loss: 1.3860, G loss: 0.6934\n",
      "[804/1762] D loss: 1.3874, G loss: 0.6977\n",
      "[884/1762] D loss: 1.3890, G loss: 0.6481\n",
      "[964/1762] D loss: 1.3865, G loss: 0.6985\n",
      "[1044/1762] D loss: 1.0399, G loss: 2.4486\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6821\n",
      "[1204/1762] D loss: 1.3851, G loss: 0.6876\n",
      "[1284/1762] D loss: 1.3853, G loss: 0.6876\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6804\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.7019\n",
      "[1524/1762] D loss: 1.0406, G loss: 2.6727\n",
      "[1604/1762] D loss: 1.3867, G loss: 0.7008\n",
      "[1684/1762] D loss: 1.0401, G loss: 2.7238\n",
      "[1762/1762] D loss: 0.7005, G loss: 5.5356\n",
      "train error: \n",
      " D loss: 1.302929, G loss: 1.069991, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.278360, G loss: 1.217814, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3967, G loss: 0.5806\n",
      "[84/1762] D loss: 1.0440, G loss: 1.6771\n",
      "[164/1762] D loss: 1.3865, G loss: 0.6896\n",
      "[244/1762] D loss: 1.3865, G loss: 0.6931\n",
      "[324/1762] D loss: 1.3867, G loss: 0.7095\n",
      "[404/1762] D loss: 1.3866, G loss: 0.6923\n",
      "[484/1762] D loss: 1.3866, G loss: 0.6821\n",
      "[564/1762] D loss: 1.3864, G loss: 0.7002\n",
      "[644/1762] D loss: 1.3869, G loss: 0.6718\n",
      "[724/1762] D loss: 1.0399, G loss: 2.4926\n",
      "[804/1762] D loss: 1.3866, G loss: 0.7068\n",
      "[884/1762] D loss: 1.3865, G loss: 0.7061\n",
      "[964/1762] D loss: 1.3865, G loss: 0.6992\n",
      "[1044/1762] D loss: 1.0398, G loss: 2.7108\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.6943\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6904\n",
      "[1284/1762] D loss: 1.0398, G loss: 2.5264\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6837\n",
      "[1444/1762] D loss: 1.0396, G loss: 2.5800\n",
      "[1524/1762] D loss: 1.3867, G loss: 0.6771\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6925\n",
      "[1684/1762] D loss: 1.0398, G loss: 2.5781\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.7008\n",
      "train error: \n",
      " D loss: 1.287035, G loss: 1.267371, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.260429, G loss: 1.437248, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3866, G loss: 0.7020\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6826\n",
      "[164/1762] D loss: 1.0398, G loss: 2.7821\n",
      "[244/1762] D loss: 1.0398, G loss: 2.6889\n",
      "[324/1762] D loss: 1.3862, G loss: 0.6914\n",
      "[404/1762] D loss: 1.0399, G loss: 2.6263\n",
      "[484/1762] D loss: 1.3862, G loss: 0.6982\n",
      "[564/1762] D loss: 1.3863, G loss: 0.6952\n",
      "[644/1762] D loss: 0.6931, G loss: 4.7128\n",
      "[724/1762] D loss: 1.3862, G loss: 0.6948\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6863\n",
      "[884/1762] D loss: 1.3862, G loss: 0.6963\n",
      "[964/1762] D loss: 1.3864, G loss: 0.6902\n",
      "[1044/1762] D loss: 1.3866, G loss: 0.7085\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6991\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6946\n",
      "[1284/1762] D loss: 1.3867, G loss: 0.6836\n",
      "[1364/1762] D loss: 1.0399, G loss: 2.5930\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.7005\n",
      "[1524/1762] D loss: 1.3897, G loss: 0.7387\n",
      "[1604/1762] D loss: 1.2075, G loss: 3.0889\n",
      "[1684/1762] D loss: 0.9624, G loss: 3.7111\n",
      "[1762/1762] D loss: 1.3886, G loss: 0.7506\n",
      "train error: \n",
      " D loss: 1.291970, G loss: 1.292057, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.265910, G loss: 1.423727, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6946, G loss: 4.6691\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6909\n",
      "[164/1762] D loss: 1.3868, G loss: 0.6891\n",
      "[244/1762] D loss: 1.3865, G loss: 0.6888\n",
      "[324/1762] D loss: 1.0400, G loss: 2.5714\n",
      "[404/1762] D loss: 1.3856, G loss: 0.6840\n",
      "[484/1762] D loss: 1.3860, G loss: 0.6855\n",
      "[564/1762] D loss: 1.3865, G loss: 0.6869\n",
      "[644/1762] D loss: 1.3862, G loss: 0.7047\n",
      "[724/1762] D loss: 1.3865, G loss: 0.7064\n",
      "[804/1762] D loss: 1.3863, G loss: 0.6994\n",
      "[884/1762] D loss: 1.3842, G loss: 0.6873\n",
      "[964/1762] D loss: 1.3861, G loss: 0.6904\n",
      "[1044/1762] D loss: 1.3682, G loss: 0.7104\n",
      "[1124/1762] D loss: 1.3849, G loss: 0.6936\n",
      "[1204/1762] D loss: 1.3870, G loss: 0.6714\n",
      "[1284/1762] D loss: 1.3859, G loss: 0.7181\n",
      "[1364/1762] D loss: 1.3788, G loss: 0.6963\n",
      "[1444/1762] D loss: 1.2814, G loss: 0.9011\n",
      "[1524/1762] D loss: 1.3859, G loss: 0.6960\n",
      "[1604/1762] D loss: 1.3904, G loss: 0.6340\n",
      "[1684/1762] D loss: 1.3868, G loss: 0.7009\n",
      "[1762/1762] D loss: 1.3866, G loss: 0.7230\n",
      "train error: \n",
      " D loss: 1.285346, G loss: 1.383702, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.253832, G loss: 1.474980, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3866, G loss: 0.6860\n",
      "[84/1762] D loss: 1.0395, G loss: 2.9942\n",
      "[164/1762] D loss: 1.3865, G loss: 0.6755\n",
      "[244/1762] D loss: 1.3864, G loss: 0.6957\n",
      "[324/1762] D loss: 1.3872, G loss: 0.6723\n",
      "[404/1762] D loss: 1.0401, G loss: 2.0802\n",
      "[484/1762] D loss: 1.0406, G loss: 2.0985\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6928\n",
      "[644/1762] D loss: 1.3885, G loss: 0.6527\n",
      "[724/1762] D loss: 1.0408, G loss: 1.9121\n",
      "[804/1762] D loss: 1.3902, G loss: 0.7012\n",
      "[884/1762] D loss: 1.3869, G loss: 0.7111\n",
      "[964/1762] D loss: 1.0407, G loss: 2.0287\n",
      "[1044/1762] D loss: 1.3870, G loss: 0.6800\n",
      "[1124/1762] D loss: 1.3879, G loss: 0.7062\n",
      "[1204/1762] D loss: 1.0402, G loss: 2.1169\n",
      "[1284/1762] D loss: 1.3874, G loss: 0.6716\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6950\n",
      "[1444/1762] D loss: 1.3877, G loss: 0.6683\n",
      "[1524/1762] D loss: 1.3866, G loss: 0.6877\n",
      "[1604/1762] D loss: 1.0402, G loss: 2.1303\n",
      "[1684/1762] D loss: 1.3866, G loss: 0.6942\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6867\n",
      "train error: \n",
      " D loss: 1.286338, G loss: 1.163727, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.260403, G loss: 1.276823, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0405, G loss: 2.1442\n",
      "[84/1762] D loss: 1.3866, G loss: 0.6718\n",
      "[164/1762] D loss: 1.3868, G loss: 0.6763\n",
      "[244/1762] D loss: 1.3864, G loss: 0.6941\n",
      "[324/1762] D loss: 1.3866, G loss: 0.6867\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6890\n",
      "[484/1762] D loss: 1.3865, G loss: 0.6888\n",
      "[564/1762] D loss: 1.0403, G loss: 2.4064\n",
      "[644/1762] D loss: 1.0399, G loss: 2.6132\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6980\n",
      "[804/1762] D loss: 1.3856, G loss: 0.6968\n",
      "[884/1762] D loss: 1.3867, G loss: 0.6824\n",
      "[964/1762] D loss: 1.3863, G loss: 0.6847\n",
      "[1044/1762] D loss: 1.0401, G loss: 2.3540\n",
      "[1124/1762] D loss: 1.0399, G loss: 2.4255\n",
      "[1204/1762] D loss: 1.3868, G loss: 0.6846\n",
      "[1284/1762] D loss: 1.3866, G loss: 0.6865\n",
      "[1364/1762] D loss: 1.3865, G loss: 0.6919\n",
      "[1444/1762] D loss: 1.3910, G loss: 0.6516\n",
      "[1524/1762] D loss: 1.3882, G loss: 0.6538\n",
      "[1604/1762] D loss: 1.3867, G loss: 0.6873\n",
      "[1684/1762] D loss: 1.3865, G loss: 0.6884\n",
      "[1762/1762] D loss: 1.3995, G loss: 0.6831\n",
      "train error: \n",
      " D loss: 1.289404, G loss: 1.281844, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.262004, G loss: 1.424046, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0399, G loss: 2.6711\n",
      "[84/1762] D loss: 1.3867, G loss: 0.7098\n",
      "[164/1762] D loss: 1.3831, G loss: 0.7038\n",
      "[244/1762] D loss: 1.3868, G loss: 0.6874\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6969\n",
      "[404/1762] D loss: 1.3865, G loss: 0.6925\n",
      "[484/1762] D loss: 1.3862, G loss: 0.6916\n",
      "[564/1762] D loss: 1.3863, G loss: 0.7004\n",
      "[644/1762] D loss: 1.3864, G loss: 0.6996\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6985\n",
      "[804/1762] D loss: 1.0403, G loss: 2.5299\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6958\n",
      "[964/1762] D loss: 1.3869, G loss: 0.6795\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6898\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.6910\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6886\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6884\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6908\n",
      "[1444/1762] D loss: 1.3867, G loss: 0.7117\n",
      "[1524/1762] D loss: 1.3857, G loss: 0.6948\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6931\n",
      "[1684/1762] D loss: 1.3871, G loss: 0.6965\n",
      "[1762/1762] D loss: 1.3907, G loss: 0.6182\n",
      "train error: \n",
      " D loss: 1.291396, G loss: 1.219112, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.263343, G loss: 1.450080, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3938, G loss: 0.6078\n",
      "[84/1762] D loss: 1.3883, G loss: 0.6905\n",
      "[164/1762] D loss: 1.0417, G loss: 2.6649\n",
      "[244/1762] D loss: 1.0401, G loss: 2.4819\n",
      "[324/1762] D loss: 1.3864, G loss: 0.6980\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6964\n",
      "[484/1762] D loss: 1.3908, G loss: 0.6733\n",
      "[564/1762] D loss: 1.3865, G loss: 0.6783\n",
      "[644/1762] D loss: 1.0396, G loss: 3.1805\n",
      "[724/1762] D loss: 1.3865, G loss: 0.7025\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6950\n",
      "[884/1762] D loss: 1.3864, G loss: 0.7024\n",
      "[964/1762] D loss: 1.3862, G loss: 0.6941\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6941\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6965\n",
      "[1204/1762] D loss: 1.0399, G loss: 2.7032\n",
      "[1284/1762] D loss: 1.0397, G loss: 2.5238\n",
      "[1364/1762] D loss: 1.0400, G loss: 3.4179\n",
      "[1444/1762] D loss: 1.3895, G loss: 0.7146\n",
      "[1524/1762] D loss: 1.3877, G loss: 0.6688\n",
      "[1604/1762] D loss: 1.3866, G loss: 0.6770\n",
      "[1684/1762] D loss: 1.3867, G loss: 0.6954\n",
      "[1762/1762] D loss: 1.3866, G loss: 0.6876\n",
      "train error: \n",
      " D loss: 1.306921, G loss: 0.912470, D accuracy: 53.1%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.299730, G loss: 0.935744, D accuracy: 52.8%, cell accuracy: 99.9%, board accuracy: 91.1% \n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3865, G loss: 0.6985\n",
      "[84/1762] D loss: 1.3864, G loss: 0.7012\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6963\n",
      "[244/1762] D loss: 1.2943, G loss: 1.6241\n",
      "[324/1762] D loss: 1.2059, G loss: 0.6943\n",
      "[404/1762] D loss: 1.3863, G loss: 0.6890\n",
      "[484/1762] D loss: 1.3874, G loss: 0.7243\n",
      "[564/1762] D loss: 1.2702, G loss: 0.8898\n",
      "[644/1762] D loss: 1.0773, G loss: 1.0761\n",
      "[724/1762] D loss: 1.2611, G loss: 0.9218\n",
      "[804/1762] D loss: 1.1448, G loss: 0.7771\n",
      "[884/1762] D loss: 1.3873, G loss: 0.7053\n",
      "[964/1762] D loss: 1.3875, G loss: 0.7233\n",
      "[1044/1762] D loss: 1.2167, G loss: 1.1314\n",
      "[1124/1762] D loss: 1.2261, G loss: 1.1688\n",
      "[1204/1762] D loss: 1.3872, G loss: 0.6651\n",
      "[1284/1762] D loss: 1.3873, G loss: 0.6778\n",
      "[1364/1762] D loss: 1.0783, G loss: 0.9726\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6901\n",
      "[1524/1762] D loss: 1.3866, G loss: 0.6962\n",
      "[1604/1762] D loss: 1.3857, G loss: 0.7026\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.6935\n",
      "[1762/1762] D loss: 1.3861, G loss: 0.6848\n",
      "train error: \n",
      " D loss: 1.302465, G loss: 0.885653, D accuracy: 54.0%, cell accuracy: 99.9%, board accuracy: 89.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.318328, G loss: 0.926627, D accuracy: 54.0%, cell accuracy: 99.9%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3865, G loss: 0.7085\n",
      "[84/1762] D loss: 1.3864, G loss: 0.7036\n",
      "[164/1762] D loss: 1.3864, G loss: 0.6870\n",
      "[244/1762] D loss: 1.3874, G loss: 0.7251\n",
      "[324/1762] D loss: 1.3866, G loss: 0.6947\n",
      "[404/1762] D loss: 1.3863, G loss: 0.6925\n",
      "[484/1762] D loss: 1.3861, G loss: 0.6888\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6957\n",
      "[644/1762] D loss: 1.3868, G loss: 0.6956\n",
      "[724/1762] D loss: 1.3861, G loss: 0.6938\n",
      "[804/1762] D loss: 1.3883, G loss: 0.7358\n",
      "[884/1762] D loss: 1.3865, G loss: 0.6883\n",
      "[964/1762] D loss: 1.0611, G loss: 1.2246\n",
      "[1044/1762] D loss: 1.3859, G loss: 0.6948\n",
      "[1124/1762] D loss: 1.3880, G loss: 0.6528\n",
      "[1204/1762] D loss: 1.3877, G loss: 0.6573\n",
      "[1284/1762] D loss: 1.3868, G loss: 0.7133\n",
      "[1364/1762] D loss: 1.3861, G loss: 0.6888\n",
      "[1444/1762] D loss: 1.2429, G loss: 0.9739\n",
      "[1524/1762] D loss: 1.3862, G loss: 0.6937\n",
      "[1604/1762] D loss: 1.0841, G loss: 0.9815\n",
      "[1684/1762] D loss: 1.3866, G loss: 0.6857\n",
      "[1762/1762] D loss: 1.3884, G loss: 0.7320\n",
      "train error: \n",
      " D loss: 1.309779, G loss: 0.846292, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.323343, G loss: 0.856772, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3883, G loss: 0.7213\n",
      "[84/1762] D loss: 1.0415, G loss: 1.7374\n",
      "[164/1762] D loss: 1.3868, G loss: 0.6792\n",
      "[244/1762] D loss: 1.3865, G loss: 0.6920\n",
      "[324/1762] D loss: 1.3865, G loss: 0.7055\n",
      "[404/1762] D loss: 1.0478, G loss: 1.3895\n",
      "[484/1762] D loss: 1.3866, G loss: 0.6877\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6961\n",
      "[644/1762] D loss: 1.3859, G loss: 0.7061\n",
      "[724/1762] D loss: 1.3834, G loss: 0.7014\n",
      "[804/1762] D loss: 1.3863, G loss: 0.6906\n",
      "[884/1762] D loss: 1.0793, G loss: 1.0030\n",
      "[964/1762] D loss: 1.0969, G loss: 0.9225\n",
      "[1044/1762] D loss: 1.3902, G loss: 0.6345\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.6928\n",
      "[1204/1762] D loss: 1.0713, G loss: 1.0539\n",
      "[1284/1762] D loss: 1.3868, G loss: 0.6780\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6834\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.7000\n",
      "[1524/1762] D loss: 1.0463, G loss: 1.4274\n",
      "[1604/1762] D loss: 1.3866, G loss: 0.6792\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.6736\n",
      "[1762/1762] D loss: 1.3870, G loss: 0.6722\n",
      "train error: \n",
      " D loss: 1.297346, G loss: 1.004142, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.292535, G loss: 1.079531, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3147, G loss: 0.7368\n",
      "[84/1762] D loss: 1.3869, G loss: 0.6671\n",
      "[164/1762] D loss: 1.0425, G loss: 1.9222\n",
      "[244/1762] D loss: 1.3870, G loss: 0.7095\n",
      "[324/1762] D loss: 1.0390, G loss: 3.1577\n",
      "[404/1762] D loss: 1.3865, G loss: 0.6993\n",
      "[484/1762] D loss: 1.0394, G loss: 2.0430\n",
      "[564/1762] D loss: 1.3864, G loss: 0.7003\n",
      "[644/1762] D loss: 1.0401, G loss: 2.3685\n",
      "[724/1762] D loss: 0.7314, G loss: 3.4340\n",
      "[804/1762] D loss: 1.3866, G loss: 0.6963\n",
      "[884/1762] D loss: 1.3866, G loss: 0.6928\n",
      "[964/1762] D loss: 1.3865, G loss: 0.7039\n",
      "[1044/1762] D loss: 1.0401, G loss: 2.4432\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.6900\n",
      "[1204/1762] D loss: 1.0400, G loss: 2.1905\n",
      "[1284/1762] D loss: 1.3887, G loss: 0.7208\n",
      "[1364/1762] D loss: 1.0446, G loss: 1.5246\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6893\n",
      "[1524/1762] D loss: 1.3865, G loss: 0.7037\n",
      "[1604/1762] D loss: 1.2203, G loss: 0.7596\n",
      "[1684/1762] D loss: 1.3912, G loss: 0.6741\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6923\n",
      "train error: \n",
      " D loss: 1.289137, G loss: 0.979114, D accuracy: 55.8%, cell accuracy: 99.8%, board accuracy: 88.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.298195, G loss: 1.004780, D accuracy: 55.8%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3865, G loss: 0.6751\n",
      "[84/1762] D loss: 1.3866, G loss: 0.7098\n",
      "[164/1762] D loss: 1.0337, G loss: 2.2170\n",
      "[244/1762] D loss: 1.3865, G loss: 0.6888\n",
      "[324/1762] D loss: 1.3871, G loss: 0.7142\n",
      "[404/1762] D loss: 1.3878, G loss: 0.6969\n",
      "[484/1762] D loss: 1.3864, G loss: 0.6947\n",
      "[564/1762] D loss: 1.3873, G loss: 0.7058\n",
      "[644/1762] D loss: 1.3835, G loss: 0.6673\n",
      "[724/1762] D loss: 1.3867, G loss: 0.7013\n",
      "[804/1762] D loss: 1.3868, G loss: 0.6802\n",
      "[884/1762] D loss: 1.3880, G loss: 0.6697\n",
      "[964/1762] D loss: 1.3883, G loss: 0.6907\n",
      "[1044/1762] D loss: 1.3874, G loss: 0.6746\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.6941\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6927\n",
      "[1284/1762] D loss: 1.1144, G loss: 0.8670\n",
      "[1364/1762] D loss: 1.3874, G loss: 0.7185\n",
      "[1444/1762] D loss: 1.3879, G loss: 0.6662\n",
      "[1524/1762] D loss: 1.3869, G loss: 0.6695\n",
      "[1604/1762] D loss: 1.4703, G loss: 0.8727\n",
      "[1684/1762] D loss: 1.3868, G loss: 0.7080\n",
      "[1762/1762] D loss: 1.3870, G loss: 0.6769\n",
      "train error: \n",
      " D loss: 1.324379, G loss: 0.790003, D accuracy: 53.1%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.347094, G loss: 0.814997, D accuracy: 52.8%, cell accuracy: 99.9%, board accuracy: 91.1% \n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0709, G loss: 1.0590\n",
      "[84/1762] D loss: 1.3865, G loss: 0.7091\n",
      "[164/1762] D loss: 1.3865, G loss: 0.6926\n",
      "[244/1762] D loss: 1.3666, G loss: 0.6962\n",
      "[324/1762] D loss: 1.3704, G loss: 0.7081\n",
      "[404/1762] D loss: 1.3867, G loss: 0.7114\n",
      "[484/1762] D loss: 1.0793, G loss: 1.0018\n",
      "[564/1762] D loss: 1.3869, G loss: 0.7110\n",
      "[644/1762] D loss: 1.0729, G loss: 1.0488\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6825\n",
      "[804/1762] D loss: 1.3863, G loss: 0.6986\n",
      "[884/1762] D loss: 1.3884, G loss: 0.7333\n",
      "[964/1762] D loss: 1.0460, G loss: 1.4539\n",
      "[1044/1762] D loss: 1.3011, G loss: 0.6837\n",
      "[1124/1762] D loss: 1.4340, G loss: 0.5337\n",
      "[1204/1762] D loss: 1.2789, G loss: 0.8460\n",
      "[1284/1762] D loss: 1.5154, G loss: 0.9706\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6796\n",
      "[1444/1762] D loss: 1.3861, G loss: 0.6833\n",
      "[1524/1762] D loss: 1.3817, G loss: 0.6909\n",
      "[1604/1762] D loss: 1.4209, G loss: 0.7903\n",
      "[1684/1762] D loss: 1.3366, G loss: 0.7698\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.7036\n",
      "train error: \n",
      " D loss: 1.316519, G loss: 0.812184, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.323521, G loss: 0.818730, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3881, G loss: 0.7167\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6882\n",
      "[164/1762] D loss: 1.0390, G loss: 3.0222\n",
      "[244/1762] D loss: 1.3871, G loss: 0.7126\n",
      "[324/1762] D loss: 1.3870, G loss: 0.6914\n",
      "[404/1762] D loss: 1.3867, G loss: 0.7081\n",
      "[484/1762] D loss: 1.3863, G loss: 0.6875\n",
      "[564/1762] D loss: 1.0459, G loss: 2.1861\n",
      "[644/1762] D loss: 1.3860, G loss: 0.7040\n",
      "[724/1762] D loss: 1.2022, G loss: 2.0483\n",
      "[804/1762] D loss: 1.3878, G loss: 0.6851\n",
      "[884/1762] D loss: 1.3866, G loss: 0.6985\n",
      "[964/1762] D loss: 1.3865, G loss: 0.6917\n",
      "[1044/1762] D loss: 1.3866, G loss: 0.7106\n",
      "[1124/1762] D loss: 1.3869, G loss: 0.6980\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.7034\n",
      "[1284/1762] D loss: 1.0630, G loss: 1.1437\n",
      "[1364/1762] D loss: 1.3867, G loss: 0.6830\n",
      "[1444/1762] D loss: 1.3904, G loss: 0.6443\n",
      "[1524/1762] D loss: 1.3874, G loss: 0.6724\n",
      "[1604/1762] D loss: 1.3876, G loss: 0.6562\n",
      "[1684/1762] D loss: 1.3872, G loss: 0.6772\n",
      "[1762/1762] D loss: 1.3874, G loss: 0.6758\n",
      "train error: \n",
      " D loss: 1.309631, G loss: 0.793113, D accuracy: 53.4%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.315204, G loss: 0.829220, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 91.8% \n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3861, G loss: 0.6932\n",
      "[84/1762] D loss: 1.3847, G loss: 0.6957\n",
      "[164/1762] D loss: 1.0712, G loss: 1.0619\n",
      "[244/1762] D loss: 1.3869, G loss: 0.6878\n",
      "[324/1762] D loss: 1.3865, G loss: 0.6955\n",
      "[404/1762] D loss: 1.3858, G loss: 0.7016\n",
      "[484/1762] D loss: 1.3863, G loss: 0.6960\n",
      "[564/1762] D loss: 1.0663, G loss: 1.0763\n",
      "[644/1762] D loss: 1.3868, G loss: 0.6714\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6950\n",
      "[804/1762] D loss: 1.0600, G loss: 1.1684\n",
      "[884/1762] D loss: 1.1868, G loss: 1.5558\n",
      "[964/1762] D loss: 1.3861, G loss: 0.7011\n",
      "[1044/1762] D loss: 1.0567, G loss: 1.1990\n",
      "[1124/1762] D loss: 1.3840, G loss: 0.6860\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.7051\n",
      "[1284/1762] D loss: 1.0704, G loss: 1.0546\n",
      "[1364/1762] D loss: 1.3855, G loss: 0.6851\n",
      "[1444/1762] D loss: 1.0499, G loss: 1.3254\n",
      "[1524/1762] D loss: 1.3858, G loss: 0.6855\n",
      "[1604/1762] D loss: 1.3858, G loss: 0.6874\n",
      "[1684/1762] D loss: 1.3741, G loss: 0.6675\n",
      "[1762/1762] D loss: 0.7304, G loss: 1.6569\n",
      "train error: \n",
      " D loss: 1.301230, G loss: 0.829683, D accuracy: 55.6%, cell accuracy: 99.9%, board accuracy: 89.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.328576, G loss: 0.886611, D accuracy: 55.6%, cell accuracy: 99.9%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3788, G loss: 0.6823\n",
      "[84/1762] D loss: 1.3844, G loss: 0.6848\n",
      "[164/1762] D loss: 1.3955, G loss: 0.6481\n",
      "[244/1762] D loss: 1.1831, G loss: 1.1838\n",
      "[324/1762] D loss: 1.3925, G loss: 0.7653\n",
      "[404/1762] D loss: 1.3925, G loss: 0.6063\n",
      "[484/1762] D loss: 1.3873, G loss: 0.7089\n",
      "[564/1762] D loss: 1.8052, G loss: 1.1716\n",
      "[644/1762] D loss: 1.3865, G loss: 0.6914\n",
      "[724/1762] D loss: 1.3852, G loss: 0.6898\n",
      "[804/1762] D loss: 1.3862, G loss: 0.6971\n",
      "[884/1762] D loss: 1.1031, G loss: 0.8701\n",
      "[964/1762] D loss: 1.0385, G loss: 1.6774\n",
      "[1044/1762] D loss: 1.3870, G loss: 0.7183\n",
      "[1124/1762] D loss: 1.2265, G loss: 1.1295\n",
      "[1204/1762] D loss: 1.3879, G loss: 0.7037\n",
      "[1284/1762] D loss: 1.3869, G loss: 0.6620\n",
      "[1364/1762] D loss: 1.3857, G loss: 0.7021\n",
      "[1444/1762] D loss: 1.3873, G loss: 0.6563\n",
      "[1524/1762] D loss: 1.3866, G loss: 0.7105\n",
      "[1604/1762] D loss: 1.3867, G loss: 0.6976\n",
      "[1684/1762] D loss: 1.3852, G loss: 0.6882\n",
      "[1762/1762] D loss: 1.3861, G loss: 0.7026\n",
      "train error: \n",
      " D loss: 1.319607, G loss: 0.770983, D accuracy: 53.2%, cell accuracy: 99.9%, board accuracy: 93.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.331447, G loss: 0.807669, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3866, G loss: 0.6790\n",
      "[84/1762] D loss: 1.3883, G loss: 0.6692\n",
      "[164/1762] D loss: 1.2001, G loss: 1.3241\n",
      "[244/1762] D loss: 1.3863, G loss: 0.7011\n",
      "[324/1762] D loss: 1.0602, G loss: 1.1762\n",
      "[404/1762] D loss: 1.3861, G loss: 0.6987\n",
      "[484/1762] D loss: 1.7577, G loss: 1.1420\n",
      "[564/1762] D loss: 1.3872, G loss: 0.6712\n",
      "[644/1762] D loss: 1.3868, G loss: 0.7029\n",
      "[724/1762] D loss: 1.3865, G loss: 0.7060\n",
      "[804/1762] D loss: 1.3862, G loss: 0.6842\n",
      "[884/1762] D loss: 1.3876, G loss: 0.6643\n",
      "[964/1762] D loss: 1.3867, G loss: 0.7088\n",
      "[1044/1762] D loss: 1.3870, G loss: 0.6757\n",
      "[1124/1762] D loss: 1.3867, G loss: 0.6824\n",
      "[1204/1762] D loss: 1.3870, G loss: 0.6818\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6964\n",
      "[1364/1762] D loss: 1.3873, G loss: 0.7124\n",
      "[1444/1762] D loss: 1.3878, G loss: 0.7139\n",
      "[1524/1762] D loss: 1.3874, G loss: 0.7243\n",
      "[1604/1762] D loss: 1.3867, G loss: 0.6791\n",
      "[1684/1762] D loss: 1.3865, G loss: 0.6858\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.7056\n",
      "train error: \n",
      " D loss: 1.317521, G loss: 0.815131, D accuracy: 53.0%, cell accuracy: 99.9%, board accuracy: 93.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.333863, G loss: 0.856209, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 91.4% \n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1975, G loss: 1.0149\n",
      "[84/1762] D loss: 1.3903, G loss: 0.6963\n",
      "[164/1762] D loss: 1.3868, G loss: 0.7028\n",
      "[244/1762] D loss: 1.3885, G loss: 0.6373\n",
      "[324/1762] D loss: 1.3861, G loss: 0.6919\n",
      "[404/1762] D loss: 1.0655, G loss: 1.1171\n",
      "[484/1762] D loss: 1.3862, G loss: 0.6775\n",
      "[564/1762] D loss: 1.3866, G loss: 0.6811\n",
      "[644/1762] D loss: 1.3875, G loss: 0.7080\n",
      "[724/1762] D loss: 1.3868, G loss: 0.7133\n",
      "[804/1762] D loss: 1.3865, G loss: 0.6936\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6938\n",
      "[964/1762] D loss: 1.1271, G loss: 1.3013\n",
      "[1044/1762] D loss: 1.1162, G loss: 0.8572\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.6935\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6989\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.7035\n",
      "[1364/1762] D loss: 1.1111, G loss: 0.8653\n",
      "[1444/1762] D loss: 1.3866, G loss: 0.6784\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.6831\n",
      "[1604/1762] D loss: 1.3818, G loss: 0.6845\n",
      "[1684/1762] D loss: 1.3865, G loss: 0.6920\n",
      "[1762/1762] D loss: 1.3884, G loss: 0.6547\n",
      "train error: \n",
      " D loss: 1.314272, G loss: 0.823376, D accuracy: 53.1%, cell accuracy: 99.9%, board accuracy: 90.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.341319, G loss: 0.868091, D accuracy: 53.2%, cell accuracy: 99.9%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3867, G loss: 0.6798\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6998\n",
      "[164/1762] D loss: 1.3864, G loss: 0.6881\n",
      "[244/1762] D loss: 1.3866, G loss: 0.7022\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6929\n",
      "[404/1762] D loss: 1.3865, G loss: 0.7077\n",
      "[484/1762] D loss: 1.3892, G loss: 0.6952\n",
      "[564/1762] D loss: 1.0460, G loss: 1.4957\n",
      "[644/1762] D loss: 1.3874, G loss: 0.7270\n",
      "[724/1762] D loss: 1.1970, G loss: 0.7455\n",
      "[804/1762] D loss: 1.3886, G loss: 0.6903\n",
      "[884/1762] D loss: 1.0465, G loss: 1.4593\n",
      "[964/1762] D loss: 1.3868, G loss: 0.6707\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6964\n",
      "[1124/1762] D loss: 1.3840, G loss: 0.7053\n",
      "[1204/1762] D loss: 1.3867, G loss: 0.6956\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6961\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.7053\n",
      "[1444/1762] D loss: 1.0796, G loss: 0.9932\n",
      "[1524/1762] D loss: 1.3823, G loss: 0.6721\n",
      "[1604/1762] D loss: 1.3895, G loss: 0.7238\n",
      "[1684/1762] D loss: 1.3900, G loss: 0.7387\n",
      "[1762/1762] D loss: 1.3868, G loss: 0.7191\n",
      "train error: \n",
      " D loss: 1.308578, G loss: 0.850223, D accuracy: 53.4%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.319289, G loss: 0.890813, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0545, G loss: 1.2982\n",
      "[84/1762] D loss: 1.3805, G loss: 0.6730\n",
      "[164/1762] D loss: 1.0570, G loss: 1.2037\n",
      "[244/1762] D loss: 1.0619, G loss: 1.1438\n",
      "[324/1762] D loss: 1.3914, G loss: 0.6744\n",
      "[404/1762] D loss: 1.3871, G loss: 0.7150\n",
      "[484/1762] D loss: 1.3865, G loss: 0.6946\n",
      "[564/1762] D loss: 1.3853, G loss: 0.7005\n",
      "[644/1762] D loss: 1.5843, G loss: 1.0164\n",
      "[724/1762] D loss: 1.3893, G loss: 0.6858\n",
      "[804/1762] D loss: 1.3870, G loss: 0.6875\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6929\n",
      "[964/1762] D loss: 1.3872, G loss: 0.6789\n",
      "[1044/1762] D loss: 1.3868, G loss: 0.7044\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.6800\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6968\n",
      "[1284/1762] D loss: 1.3866, G loss: 0.7026\n",
      "[1364/1762] D loss: 1.3865, G loss: 0.6989\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.7068\n",
      "[1524/1762] D loss: 1.3871, G loss: 0.6710\n",
      "[1604/1762] D loss: 1.3867, G loss: 0.6747\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.6692\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6956\n",
      "train error: \n",
      " D loss: 1.325207, G loss: 0.887977, D accuracy: 52.7%, cell accuracy: 99.9%, board accuracy: 90.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.376675, G loss: 0.936189, D accuracy: 52.7%, cell accuracy: 99.9%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0532, G loss: 1.2671\n",
      "[84/1762] D loss: 1.3860, G loss: 0.6854\n",
      "[164/1762] D loss: 1.3864, G loss: 0.6951\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6897\n",
      "[324/1762] D loss: 1.0697, G loss: 1.0745\n",
      "[404/1762] D loss: 1.3864, G loss: 0.7044\n",
      "[484/1762] D loss: 1.3873, G loss: 0.7216\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6808\n",
      "[644/1762] D loss: 1.3868, G loss: 0.6654\n",
      "[724/1762] D loss: 1.3864, G loss: 0.7054\n",
      "[804/1762] D loss: 1.2857, G loss: 0.7832\n",
      "[884/1762] D loss: 1.3868, G loss: 0.7121\n",
      "[964/1762] D loss: 1.3871, G loss: 0.7143\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.6925\n",
      "[1124/1762] D loss: 1.0654, G loss: 1.0837\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6983\n",
      "[1284/1762] D loss: 1.3866, G loss: 0.7015\n",
      "[1364/1762] D loss: 1.0420, G loss: 1.6168\n",
      "[1444/1762] D loss: 1.3834, G loss: 0.7014\n",
      "[1524/1762] D loss: 1.3892, G loss: 0.6616\n",
      "[1604/1762] D loss: 1.3870, G loss: 0.6927\n",
      "[1684/1762] D loss: 1.0500, G loss: 1.3365\n",
      "[1762/1762] D loss: 1.3871, G loss: 0.7182\n",
      "train error: \n",
      " D loss: 1.314090, G loss: 0.804021, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.333780, G loss: 0.828255, D accuracy: 53.2%, cell accuracy: 99.9%, board accuracy: 91.4% \n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0483, G loss: 1.3670\n",
      "[84/1762] D loss: 1.3868, G loss: 0.6757\n",
      "[164/1762] D loss: 1.3866, G loss: 0.6825\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6933\n",
      "[324/1762] D loss: 1.3866, G loss: 0.6917\n",
      "[404/1762] D loss: 0.8061, G loss: 1.1402\n",
      "[484/1762] D loss: 1.3868, G loss: 0.6658\n",
      "[564/1762] D loss: 1.3873, G loss: 0.6951\n",
      "[644/1762] D loss: 1.3867, G loss: 0.7044\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6909\n",
      "[804/1762] D loss: 1.3843, G loss: 0.6901\n",
      "[884/1762] D loss: 1.3876, G loss: 0.6690\n",
      "[964/1762] D loss: 1.3869, G loss: 0.7070\n",
      "[1044/1762] D loss: 1.3879, G loss: 0.6888\n",
      "[1124/1762] D loss: 1.3868, G loss: 0.6784\n",
      "[1204/1762] D loss: 1.3862, G loss: 0.6987\n",
      "[1284/1762] D loss: 1.3862, G loss: 0.6933\n",
      "[1364/1762] D loss: 1.3862, G loss: 0.6882\n",
      "[1444/1762] D loss: 1.0510, G loss: 1.2933\n",
      "[1524/1762] D loss: 1.0437, G loss: 1.5696\n",
      "[1604/1762] D loss: 1.3874, G loss: 0.6774\n",
      "[1684/1762] D loss: 1.3894, G loss: 0.6450\n",
      "[1762/1762] D loss: 1.3862, G loss: 0.6669\n",
      "train error: \n",
      " D loss: 1.309792, G loss: 0.794716, D accuracy: 53.4%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.326980, G loss: 0.828330, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 91.1% \n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0474, G loss: 1.4104\n",
      "[84/1762] D loss: 1.3868, G loss: 0.6846\n",
      "[164/1762] D loss: 1.1111, G loss: 0.8651\n",
      "[244/1762] D loss: 1.0500, G loss: 1.3354\n",
      "[324/1762] D loss: 1.3864, G loss: 0.6889\n",
      "[404/1762] D loss: 1.3807, G loss: 0.6989\n",
      "[484/1762] D loss: 1.3850, G loss: 0.6850\n",
      "[564/1762] D loss: 1.3774, G loss: 0.6870\n",
      "[644/1762] D loss: 1.3865, G loss: 0.6835\n",
      "[724/1762] D loss: 1.3866, G loss: 0.7203\n",
      "[804/1762] D loss: 1.3861, G loss: 0.6841\n",
      "[884/1762] D loss: 1.3865, G loss: 0.6954\n",
      "[964/1762] D loss: 1.4583, G loss: 0.8669\n",
      "[1044/1762] D loss: 1.0410, G loss: 1.8348\n",
      "[1124/1762] D loss: 1.3868, G loss: 0.7091\n",
      "[1204/1762] D loss: 1.3865, G loss: 0.6945\n",
      "[1284/1762] D loss: 1.3874, G loss: 0.6840\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6885\n",
      "[1444/1762] D loss: 1.0647, G loss: 1.1013\n",
      "[1524/1762] D loss: 1.3470, G loss: 0.7248\n",
      "[1604/1762] D loss: 1.3846, G loss: 0.6955\n",
      "[1684/1762] D loss: 1.2112, G loss: 1.2629\n",
      "[1762/1762] D loss: 1.3884, G loss: 0.8170\n",
      "train error: \n",
      " D loss: 1.328449, G loss: 1.028731, D accuracy: 53.0%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.397726, G loss: 1.078966, D accuracy: 52.7%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4090, G loss: 0.6922\n",
      "[84/1762] D loss: 1.3871, G loss: 0.6931\n",
      "[164/1762] D loss: 1.3875, G loss: 0.6800\n",
      "[244/1762] D loss: 1.3866, G loss: 0.6884\n",
      "[324/1762] D loss: 1.3867, G loss: 0.7094\n",
      "[404/1762] D loss: 1.0672, G loss: 1.1190\n",
      "[484/1762] D loss: 1.3864, G loss: 0.7109\n",
      "[564/1762] D loss: 1.3863, G loss: 0.6942\n",
      "[644/1762] D loss: 1.3850, G loss: 0.6842\n",
      "[724/1762] D loss: 1.3876, G loss: 0.6660\n",
      "[804/1762] D loss: 1.3883, G loss: 0.7308\n",
      "[884/1762] D loss: 1.3870, G loss: 0.7106\n",
      "[964/1762] D loss: 1.3866, G loss: 0.6809\n",
      "[1044/1762] D loss: 1.0404, G loss: 2.0551\n",
      "[1124/1762] D loss: 1.3872, G loss: 0.6775\n",
      "[1204/1762] D loss: 1.3867, G loss: 0.6725\n",
      "[1284/1762] D loss: 1.3872, G loss: 0.6725\n",
      "[1364/1762] D loss: 1.3874, G loss: 0.6648\n",
      "[1444/1762] D loss: 1.3823, G loss: 0.7006\n",
      "[1524/1762] D loss: 1.3815, G loss: 0.6630\n",
      "[1604/1762] D loss: 1.3939, G loss: 0.6701\n",
      "[1684/1762] D loss: 1.3930, G loss: 0.6365\n",
      "[1762/1762] D loss: 1.4250, G loss: 0.7778\n",
      "train error: \n",
      " D loss: 1.293449, G loss: 0.939962, D accuracy: 56.4%, cell accuracy: 99.9%, board accuracy: 87.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.344710, G loss: 0.949120, D accuracy: 55.1%, cell accuracy: 99.9%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3845, G loss: 0.7104\n",
      "[84/1762] D loss: 1.3881, G loss: 0.7147\n",
      "[164/1762] D loss: 1.3891, G loss: 0.6484\n",
      "[244/1762] D loss: 1.3924, G loss: 0.6382\n",
      "[324/1762] D loss: 1.3872, G loss: 0.6556\n",
      "[404/1762] D loss: 1.3889, G loss: 0.6741\n",
      "[484/1762] D loss: 1.3864, G loss: 0.7027\n",
      "[564/1762] D loss: 1.3871, G loss: 0.6897\n",
      "[644/1762] D loss: 1.0609, G loss: 1.1577\n",
      "[724/1762] D loss: 1.3869, G loss: 0.6891\n",
      "[804/1762] D loss: 1.3871, G loss: 0.6860\n",
      "[884/1762] D loss: 1.3870, G loss: 0.7077\n",
      "[964/1762] D loss: 1.3884, G loss: 0.6640\n",
      "[1044/1762] D loss: 1.0463, G loss: 1.4471\n",
      "[1124/1762] D loss: 1.5208, G loss: 0.9379\n",
      "[1204/1762] D loss: 1.0700, G loss: 1.0524\n",
      "[1284/1762] D loss: 1.3868, G loss: 0.7109\n",
      "[1364/1762] D loss: 1.0601, G loss: 1.1790\n",
      "[1444/1762] D loss: 1.3867, G loss: 0.7144\n",
      "[1524/1762] D loss: 1.3866, G loss: 0.7048\n",
      "[1604/1762] D loss: 1.0419, G loss: 2.3649\n",
      "[1684/1762] D loss: 1.0627, G loss: 1.1295\n",
      "[1762/1762] D loss: 1.3866, G loss: 0.6998\n",
      "train error: \n",
      " D loss: 1.318541, G loss: 0.950997, D accuracy: 52.9%, cell accuracy: 99.9%, board accuracy: 93.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.399140, G loss: 1.030138, D accuracy: 53.2%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3869, G loss: 0.6880\n",
      "[84/1762] D loss: 1.3872, G loss: 0.6887\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6800\n",
      "[244/1762] D loss: 1.3810, G loss: 0.6879\n",
      "[324/1762] D loss: 1.3873, G loss: 0.7124\n",
      "[404/1762] D loss: 1.3871, G loss: 0.6981\n",
      "[484/1762] D loss: 1.3890, G loss: 0.7068\n",
      "[564/1762] D loss: 1.3829, G loss: 0.6833\n",
      "[644/1762] D loss: 1.3888, G loss: 0.6468\n",
      "[724/1762] D loss: 1.3862, G loss: 0.7008\n",
      "[804/1762] D loss: 1.3853, G loss: 0.6835\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6995\n",
      "[964/1762] D loss: 1.3868, G loss: 0.6826\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.7022\n",
      "[1124/1762] D loss: 1.0471, G loss: 1.4477\n",
      "[1204/1762] D loss: 1.3840, G loss: 0.7179\n",
      "[1284/1762] D loss: 1.3870, G loss: 0.6848\n",
      "[1364/1762] D loss: 1.3888, G loss: 0.6580\n",
      "[1444/1762] D loss: 1.4464, G loss: 0.8395\n",
      "[1524/1762] D loss: 1.3866, G loss: 0.6736\n",
      "[1604/1762] D loss: 1.3867, G loss: 0.6833\n",
      "[1684/1762] D loss: 1.3850, G loss: 0.6930\n",
      "[1762/1762] D loss: 0.7042, G loss: 2.2759\n",
      "train error: \n",
      " D loss: 1.312959, G loss: 0.918125, D accuracy: 53.0%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.367722, G loss: 1.006320, D accuracy: 53.1%, cell accuracy: 99.9%, board accuracy: 91.8% \n",
      "\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3865, G loss: 0.6819\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6937\n",
      "[164/1762] D loss: 1.0406, G loss: 1.8321\n",
      "[244/1762] D loss: 1.0827, G loss: 0.9784\n",
      "[324/1762] D loss: 1.3876, G loss: 0.6741\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6976\n",
      "[484/1762] D loss: 1.3866, G loss: 0.6814\n",
      "[564/1762] D loss: 1.0415, G loss: 2.7160\n",
      "[644/1762] D loss: 1.3870, G loss: 0.6885\n",
      "[724/1762] D loss: 1.0396, G loss: 2.7930\n",
      "[804/1762] D loss: 1.3865, G loss: 0.6847\n",
      "[884/1762] D loss: 1.3864, G loss: 0.7021\n",
      "[964/1762] D loss: 1.3862, G loss: 0.6925\n",
      "[1044/1762] D loss: 1.3860, G loss: 0.6862\n",
      "[1124/1762] D loss: 1.0397, G loss: 2.9539\n",
      "[1204/1762] D loss: 1.0400, G loss: 2.1388\n",
      "[1284/1762] D loss: 1.3865, G loss: 0.6797\n",
      "[1364/1762] D loss: 1.3865, G loss: 0.7072\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.6814\n",
      "[1524/1762] D loss: 1.1412, G loss: 0.8098\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6869\n",
      "[1684/1762] D loss: 1.3866, G loss: 0.6825\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6807\n",
      "train error: \n",
      " D loss: 1.312921, G loss: 0.905475, D accuracy: 53.2%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.368434, G loss: 0.992710, D accuracy: 53.4%, cell accuracy: 99.9%, board accuracy: 91.1% \n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3851, G loss: 0.6919\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6897\n",
      "[164/1762] D loss: 1.3871, G loss: 0.6717\n",
      "[244/1762] D loss: 1.3888, G loss: 0.6748\n",
      "[324/1762] D loss: 1.3865, G loss: 0.7067\n",
      "[404/1762] D loss: 1.3862, G loss: 0.6965\n",
      "[484/1762] D loss: 1.3867, G loss: 0.6692\n",
      "[564/1762] D loss: 1.3869, G loss: 0.6923\n",
      "[644/1762] D loss: 1.3822, G loss: 0.6961\n",
      "[724/1762] D loss: 1.3866, G loss: 0.6954\n",
      "[804/1762] D loss: 0.8460, G loss: 1.0280\n",
      "[884/1762] D loss: 1.3876, G loss: 0.6679\n",
      "[964/1762] D loss: 1.3863, G loss: 0.6941\n",
      "[1044/1762] D loss: 1.3854, G loss: 0.6850\n",
      "[1124/1762] D loss: 1.3869, G loss: 0.6904\n",
      "[1204/1762] D loss: 1.3849, G loss: 0.6983\n",
      "[1284/1762] D loss: 1.3873, G loss: 0.7242\n",
      "[1364/1762] D loss: 1.0926, G loss: 0.9100\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.6941\n",
      "[1524/1762] D loss: 1.3869, G loss: 0.6893\n",
      "[1604/1762] D loss: 1.3897, G loss: 0.7155\n",
      "[1684/1762] D loss: 1.0406, G loss: 2.2756\n",
      "[1762/1762] D loss: 1.3856, G loss: 0.6860\n",
      "train error: \n",
      " D loss: 1.307857, G loss: 1.093241, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.386252, G loss: 1.216331, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3861, G loss: 0.6972\n",
      "[84/1762] D loss: 1.3865, G loss: 0.7015\n",
      "[164/1762] D loss: 1.3869, G loss: 0.7102\n",
      "[244/1762] D loss: 1.1732, G loss: 1.0983\n",
      "[324/1762] D loss: 1.4054, G loss: 0.5860\n",
      "[404/1762] D loss: 1.3862, G loss: 0.6626\n",
      "[484/1762] D loss: 1.3831, G loss: 0.7613\n",
      "[564/1762] D loss: 1.3868, G loss: 0.6805\n",
      "[644/1762] D loss: 0.7469, G loss: 1.7099\n",
      "[724/1762] D loss: 1.3870, G loss: 0.6911\n",
      "[804/1762] D loss: 1.3863, G loss: 0.6859\n",
      "[884/1762] D loss: 1.3870, G loss: 0.6954\n",
      "[964/1762] D loss: 1.3877, G loss: 0.6975\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6845\n",
      "[1124/1762] D loss: 1.3872, G loss: 0.6714\n",
      "[1204/1762] D loss: 1.3909, G loss: 0.6364\n",
      "[1284/1762] D loss: 1.3873, G loss: 0.6857\n",
      "[1364/1762] D loss: 1.3888, G loss: 0.6562\n",
      "[1444/1762] D loss: 0.9165, G loss: 1.6340\n",
      "[1524/1762] D loss: 1.0465, G loss: 4.0456\n",
      "[1604/1762] D loss: 0.8903, G loss: 3.5081\n",
      "[1684/1762] D loss: 1.1453, G loss: 0.9063\n",
      "[1762/1762] D loss: 1.3895, G loss: 0.6473\n",
      "train error: \n",
      " D loss: 1.333553, G loss: 0.900677, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 89.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.379663, G loss: 0.914457, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3879, G loss: 0.6767\n",
      "[84/1762] D loss: 1.3619, G loss: 0.8325\n",
      "[164/1762] D loss: 1.3864, G loss: 0.6824\n",
      "[244/1762] D loss: 1.2088, G loss: 1.3330\n",
      "[324/1762] D loss: 1.3862, G loss: 0.6895\n",
      "[404/1762] D loss: 1.3876, G loss: 0.7238\n",
      "[484/1762] D loss: 0.4499, G loss: 1.8267\n",
      "[564/1762] D loss: 1.3867, G loss: 0.6819\n",
      "[644/1762] D loss: 1.3868, G loss: 0.6963\n",
      "[724/1762] D loss: 1.3864, G loss: 0.7018\n",
      "[804/1762] D loss: 1.3861, G loss: 0.6816\n",
      "[884/1762] D loss: 1.3741, G loss: 2.5849\n",
      "[964/1762] D loss: 1.3874, G loss: 0.6613\n",
      "[1044/1762] D loss: 1.3880, G loss: 0.6598\n",
      "[1124/1762] D loss: 1.3859, G loss: 0.7476\n",
      "[1204/1762] D loss: 1.3870, G loss: 0.6780\n",
      "[1284/1762] D loss: 1.1018, G loss: 0.9013\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6967\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6956\n",
      "[1524/1762] D loss: 1.3866, G loss: 0.6895\n",
      "[1604/1762] D loss: 1.0868, G loss: 1.0064\n",
      "[1684/1762] D loss: 1.3868, G loss: 0.6810\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6933\n",
      "train error: \n",
      " D loss: 1.334523, G loss: 0.800098, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.354987, G loss: 0.833279, D accuracy: 52.8%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3873, G loss: 0.6630\n",
      "[84/1762] D loss: 1.3861, G loss: 0.6798\n",
      "[164/1762] D loss: 1.3876, G loss: 0.6620\n",
      "[244/1762] D loss: 1.3866, G loss: 0.6830\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6908\n",
      "[404/1762] D loss: 1.3867, G loss: 0.6802\n",
      "[484/1762] D loss: 1.3902, G loss: 0.6540\n",
      "[564/1762] D loss: 1.1617, G loss: 1.1386\n",
      "[644/1762] D loss: 1.3918, G loss: 0.6765\n",
      "[724/1762] D loss: 1.3902, G loss: 0.6675\n",
      "[804/1762] D loss: 1.3872, G loss: 0.6646\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6995\n",
      "[964/1762] D loss: 1.2352, G loss: 1.0362\n",
      "[1044/1762] D loss: 1.3907, G loss: 0.6447\n",
      "[1124/1762] D loss: 1.3870, G loss: 0.6812\n",
      "[1204/1762] D loss: 1.3862, G loss: 0.6982\n",
      "[1284/1762] D loss: 1.3865, G loss: 0.6815\n",
      "[1364/1762] D loss: 1.3932, G loss: 0.6796\n",
      "[1444/1762] D loss: 1.3896, G loss: 0.6499\n",
      "[1524/1762] D loss: 1.3917, G loss: 0.6998\n",
      "[1604/1762] D loss: 1.3868, G loss: 0.6795\n",
      "[1684/1762] D loss: 1.3872, G loss: 0.6684\n",
      "[1762/1762] D loss: 1.3872, G loss: 0.7091\n",
      "train error: \n",
      " D loss: 1.314191, G loss: 0.864772, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.322783, G loss: 0.931896, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3835, G loss: 0.6758\n",
      "[84/1762] D loss: 1.3886, G loss: 0.6652\n",
      "[164/1762] D loss: 1.3867, G loss: 0.6903\n",
      "[244/1762] D loss: 1.3888, G loss: 0.7004\n",
      "[324/1762] D loss: 1.0546, G loss: 1.2321\n",
      "[404/1762] D loss: 1.3861, G loss: 0.6919\n",
      "[484/1762] D loss: 1.3859, G loss: 0.6862\n",
      "[564/1762] D loss: 1.3908, G loss: 0.6450\n",
      "[644/1762] D loss: 1.0485, G loss: 1.6386\n",
      "[724/1762] D loss: 1.2393, G loss: 1.1516\n",
      "[804/1762] D loss: 1.2010, G loss: 1.5655\n",
      "[884/1762] D loss: 1.0416, G loss: 2.4328\n",
      "[964/1762] D loss: 1.0556, G loss: 1.2169\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.6797\n",
      "[1124/1762] D loss: 1.3957, G loss: 0.6171\n",
      "[1204/1762] D loss: 1.3891, G loss: 0.6972\n",
      "[1284/1762] D loss: 1.3848, G loss: 0.7110\n",
      "[1364/1762] D loss: 1.3869, G loss: 0.6956\n",
      "[1444/1762] D loss: 1.0874, G loss: 2.9015\n",
      "[1524/1762] D loss: 1.3872, G loss: 0.7013\n",
      "[1604/1762] D loss: 1.0444, G loss: 1.4516\n",
      "[1684/1762] D loss: 1.3871, G loss: 0.7107\n",
      "[1762/1762] D loss: 1.3861, G loss: 0.6948\n",
      "train error: \n",
      " D loss: 1.296829, G loss: 0.980564, D accuracy: 56.5%, cell accuracy: 99.7%, board accuracy: 66.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.352521, G loss: 1.077424, D accuracy: 56.6%, cell accuracy: 99.7%, board accuracy: 65.2% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3931, G loss: 0.6170\n",
      "[84/1762] D loss: 1.2816, G loss: 0.7013\n",
      "[164/1762] D loss: 0.5732, G loss: 3.3322\n",
      "[244/1762] D loss: 0.1961, G loss: 4.4804\n",
      "[324/1762] D loss: 0.2816, G loss: 5.7497\n",
      "[404/1762] D loss: 0.1122, G loss: 6.5488\n",
      "[484/1762] D loss: 0.0657, G loss: 6.5855\n",
      "[564/1762] D loss: 0.1514, G loss: 5.7544\n",
      "[644/1762] D loss: 0.5883, G loss: 1.3422\n",
      "[724/1762] D loss: 1.1776, G loss: 1.9676\n",
      "[804/1762] D loss: 0.2651, G loss: 2.9561\n",
      "[884/1762] D loss: 0.1706, G loss: 3.0031\n",
      "[964/1762] D loss: 0.4509, G loss: 0.9636\n",
      "[1044/1762] D loss: 1.4183, G loss: 0.9205\n",
      "[1124/1762] D loss: 0.3252, G loss: 2.5006\n",
      "[1204/1762] D loss: 0.9092, G loss: 2.5053\n",
      "[1284/1762] D loss: 0.8457, G loss: 2.4745\n",
      "[1364/1762] D loss: 0.8874, G loss: 0.5415\n",
      "[1444/1762] D loss: 0.9530, G loss: 1.0420\n",
      "[1524/1762] D loss: 0.8898, G loss: 0.6170\n",
      "[1604/1762] D loss: 0.6132, G loss: 1.4315\n",
      "[1684/1762] D loss: 0.7055, G loss: 1.7954\n",
      "[1762/1762] D loss: 1.1233, G loss: 0.7004\n",
      "train error: \n",
      " D loss: 1.065476, G loss: 0.646538, D accuracy: 67.5%, cell accuracy: 97.4%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.093749, G loss: 0.613633, D accuracy: 65.9%, cell accuracy: 97.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4446, G loss: 1.4237\n",
      "[84/1762] D loss: 0.6956, G loss: 2.1406\n",
      "[164/1762] D loss: 2.1383, G loss: 2.3962\n",
      "[244/1762] D loss: 1.6108, G loss: 2.0381\n",
      "[324/1762] D loss: 1.0934, G loss: 1.1961\n",
      "[404/1762] D loss: 1.2410, G loss: 1.4745\n",
      "[484/1762] D loss: 1.1603, G loss: 0.7557\n",
      "[564/1762] D loss: 1.5637, G loss: 1.3057\n",
      "[644/1762] D loss: 1.1182, G loss: 0.7629\n",
      "[724/1762] D loss: 1.0751, G loss: 0.6706\n",
      "[804/1762] D loss: 1.0928, G loss: 0.7944\n",
      "[884/1762] D loss: 1.4632, G loss: 1.2270\n",
      "[964/1762] D loss: 1.4171, G loss: 1.3003\n",
      "[1044/1762] D loss: 1.2141, G loss: 0.5178\n",
      "[1124/1762] D loss: 1.2611, G loss: 0.5691\n",
      "[1204/1762] D loss: 1.2848, G loss: 0.7542\n",
      "[1284/1762] D loss: 1.4245, G loss: 1.1794\n",
      "[1364/1762] D loss: 1.2369, G loss: 1.1191\n",
      "[1444/1762] D loss: 1.1596, G loss: 1.0299\n",
      "[1524/1762] D loss: 1.2676, G loss: 0.7422\n",
      "[1604/1762] D loss: 1.1073, G loss: 1.2176\n",
      "[1684/1762] D loss: 1.2994, G loss: 1.0411\n",
      "[1762/1762] D loss: 1.1802, G loss: 0.9715\n",
      "train error: \n",
      " D loss: 1.190432, G loss: 1.034829, D accuracy: 70.9%, cell accuracy: 99.1%, board accuracy: 20.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.192133, G loss: 1.034283, D accuracy: 71.7%, cell accuracy: 99.0%, board accuracy: 19.1% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1634, G loss: 0.7438\n",
      "[84/1762] D loss: 1.2092, G loss: 1.6946\n",
      "[164/1762] D loss: 1.1011, G loss: 0.8624\n",
      "[244/1762] D loss: 1.1013, G loss: 0.8799\n",
      "[324/1762] D loss: 1.0377, G loss: 0.9800\n",
      "[404/1762] D loss: 1.2845, G loss: 0.8467\n",
      "[484/1762] D loss: 1.2363, G loss: 0.5677\n",
      "[564/1762] D loss: 1.3939, G loss: 0.8506\n",
      "[644/1762] D loss: 1.3410, G loss: 0.9322\n",
      "[724/1762] D loss: 1.4090, G loss: 0.6364\n",
      "[804/1762] D loss: 1.2501, G loss: 0.8213\n",
      "[884/1762] D loss: 1.3427, G loss: 0.4606\n",
      "[964/1762] D loss: 1.3225, G loss: 0.5276\n",
      "[1044/1762] D loss: 1.3686, G loss: 0.6152\n",
      "[1124/1762] D loss: 1.3182, G loss: 0.6791\n",
      "[1204/1762] D loss: 1.3565, G loss: 0.7953\n",
      "[1284/1762] D loss: 1.3272, G loss: 0.6638\n",
      "[1364/1762] D loss: 1.3496, G loss: 0.8010\n",
      "[1444/1762] D loss: 1.1924, G loss: 0.9210\n",
      "[1524/1762] D loss: 1.3534, G loss: 0.6589\n",
      "[1604/1762] D loss: 1.4009, G loss: 0.5157\n",
      "[1684/1762] D loss: 1.2618, G loss: 0.4450\n",
      "[1762/1762] D loss: 1.3478, G loss: 0.5391\n",
      "train error: \n",
      " D loss: 1.354195, G loss: 0.534106, D accuracy: 56.8%, cell accuracy: 99.5%, board accuracy: 52.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.348967, G loss: 0.536366, D accuracy: 57.0%, cell accuracy: 99.4%, board accuracy: 48.6% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3488, G loss: 0.6500\n",
      "[84/1762] D loss: 1.5814, G loss: 0.5078\n",
      "[164/1762] D loss: 1.3167, G loss: 0.7743\n",
      "[244/1762] D loss: 1.3237, G loss: 0.8557\n",
      "[324/1762] D loss: 1.3240, G loss: 1.0792\n",
      "[404/1762] D loss: 1.3631, G loss: 1.0233\n",
      "[484/1762] D loss: 1.3349, G loss: 0.9233\n",
      "[564/1762] D loss: 1.3956, G loss: 0.7071\n",
      "[644/1762] D loss: 1.4437, G loss: 0.5749\n",
      "[724/1762] D loss: 1.3219, G loss: 0.7474\n",
      "[804/1762] D loss: 1.3946, G loss: 0.6399\n",
      "[884/1762] D loss: 1.3800, G loss: 0.4084\n",
      "[964/1762] D loss: 1.3765, G loss: 1.0357\n",
      "[1044/1762] D loss: 1.3819, G loss: 0.8654\n",
      "[1124/1762] D loss: 1.3217, G loss: 0.7051\n",
      "[1204/1762] D loss: 1.3689, G loss: 0.6191\n",
      "[1284/1762] D loss: 1.3306, G loss: 0.7663\n",
      "[1364/1762] D loss: 1.3235, G loss: 0.7475\n",
      "[1444/1762] D loss: 1.3287, G loss: 0.9282\n",
      "[1524/1762] D loss: 1.3910, G loss: 0.6084\n",
      "[1604/1762] D loss: 1.3471, G loss: 0.8028\n",
      "[1684/1762] D loss: 1.3073, G loss: 0.8421\n",
      "[1762/1762] D loss: 1.3672, G loss: 0.5896\n",
      "train error: \n",
      " D loss: 1.369341, G loss: 0.555241, D accuracy: 55.0%, cell accuracy: 99.6%, board accuracy: 65.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.375181, G loss: 0.546906, D accuracy: 55.6%, cell accuracy: 99.6%, board accuracy: 63.4% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1491, G loss: 0.6776\n",
      "[84/1762] D loss: 1.4319, G loss: 0.6848\n",
      "[164/1762] D loss: 1.3763, G loss: 0.8364\n",
      "[244/1762] D loss: 1.3921, G loss: 0.6449\n",
      "[324/1762] D loss: 1.2284, G loss: 0.7447\n",
      "[404/1762] D loss: 1.2923, G loss: 0.7044\n",
      "[484/1762] D loss: 1.2889, G loss: 0.7649\n",
      "[564/1762] D loss: 1.3411, G loss: 0.9107\n",
      "[644/1762] D loss: 1.2525, G loss: 0.7894\n",
      "[724/1762] D loss: 1.3847, G loss: 0.6891\n",
      "[804/1762] D loss: 1.2997, G loss: 0.9995\n",
      "[884/1762] D loss: 1.4280, G loss: 0.5590\n",
      "[964/1762] D loss: 1.3212, G loss: 0.8331\n",
      "[1044/1762] D loss: 1.4061, G loss: 0.6854\n",
      "[1124/1762] D loss: 1.3885, G loss: 0.6402\n",
      "[1204/1762] D loss: 1.3598, G loss: 0.7387\n",
      "[1284/1762] D loss: 1.4013, G loss: 1.0093\n",
      "[1364/1762] D loss: 1.3314, G loss: 0.6513\n",
      "[1444/1762] D loss: 1.4172, G loss: 0.5685\n",
      "[1524/1762] D loss: 1.3949, G loss: 0.7322\n",
      "[1604/1762] D loss: 1.3817, G loss: 0.6581\n",
      "[1684/1762] D loss: 1.3833, G loss: 0.7266\n",
      "[1762/1762] D loss: 1.1431, G loss: 1.0699\n",
      "train error: \n",
      " D loss: 1.352488, G loss: 0.705127, D accuracy: 56.4%, cell accuracy: 99.8%, board accuracy: 77.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.345273, G loss: 0.703593, D accuracy: 56.6%, cell accuracy: 99.7%, board accuracy: 72.3% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3584, G loss: 0.7410\n",
      "[84/1762] D loss: 1.3103, G loss: 0.7193\n",
      "[164/1762] D loss: 1.3840, G loss: 0.7166\n",
      "[244/1762] D loss: 1.3833, G loss: 0.6776\n",
      "[324/1762] D loss: 1.3891, G loss: 0.6290\n",
      "[404/1762] D loss: 1.3862, G loss: 0.6997\n",
      "[484/1762] D loss: 1.3497, G loss: 0.8540\n",
      "[564/1762] D loss: 1.3709, G loss: 0.7837\n",
      "[644/1762] D loss: 1.3484, G loss: 0.5294\n",
      "[724/1762] D loss: 1.3882, G loss: 0.7186\n",
      "[804/1762] D loss: 1.3617, G loss: 0.6421\n",
      "[884/1762] D loss: 1.2259, G loss: 0.9955\n",
      "[964/1762] D loss: 1.4263, G loss: 0.7882\n",
      "[1044/1762] D loss: 1.3986, G loss: 0.7723\n",
      "[1124/1762] D loss: 1.2449, G loss: 0.8812\n",
      "[1204/1762] D loss: 1.4048, G loss: 0.8510\n",
      "[1284/1762] D loss: 1.3836, G loss: 0.6504\n",
      "[1364/1762] D loss: 1.3527, G loss: 0.8332\n",
      "[1444/1762] D loss: 1.3685, G loss: 0.6694\n",
      "[1524/1762] D loss: 1.4049, G loss: 0.6441\n",
      "[1604/1762] D loss: 1.2973, G loss: 0.7396\n",
      "[1684/1762] D loss: 1.3634, G loss: 0.7696\n",
      "[1762/1762] D loss: 1.3089, G loss: 0.7412\n",
      "train error: \n",
      " D loss: 1.390228, G loss: 0.540265, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 82.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.386703, G loss: 0.538116, D accuracy: 54.4%, cell accuracy: 99.7%, board accuracy: 79.1% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4052, G loss: 0.5667\n",
      "[84/1762] D loss: 0.9715, G loss: 1.0994\n",
      "[164/1762] D loss: 1.2250, G loss: 0.7927\n",
      "[244/1762] D loss: 1.3995, G loss: 0.7727\n",
      "[324/1762] D loss: 1.4324, G loss: 0.4803\n",
      "[404/1762] D loss: 1.3749, G loss: 0.7818\n",
      "[484/1762] D loss: 1.3906, G loss: 0.7818\n",
      "[564/1762] D loss: 1.3896, G loss: 0.7045\n",
      "[644/1762] D loss: 1.4547, G loss: 0.5964\n",
      "[724/1762] D loss: 1.2376, G loss: 0.9709\n",
      "[804/1762] D loss: 1.3562, G loss: 0.8018\n",
      "[884/1762] D loss: 1.3838, G loss: 0.6858\n",
      "[964/1762] D loss: 1.3859, G loss: 0.6690\n",
      "[1044/1762] D loss: 1.4031, G loss: 0.6821\n",
      "[1124/1762] D loss: 1.3223, G loss: 0.7762\n",
      "[1204/1762] D loss: 1.3196, G loss: 0.7298\n",
      "[1284/1762] D loss: 1.3750, G loss: 0.6538\n",
      "[1364/1762] D loss: 1.3500, G loss: 0.7599\n",
      "[1444/1762] D loss: 1.3156, G loss: 0.8344\n",
      "[1524/1762] D loss: 1.4008, G loss: 0.6479\n",
      "[1604/1762] D loss: 1.3092, G loss: 0.6692\n",
      "[1684/1762] D loss: 1.3911, G loss: 0.6909\n",
      "[1762/1762] D loss: 1.3946, G loss: 0.7535\n",
      "train error: \n",
      " D loss: 1.359083, G loss: 0.850019, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 84.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.348941, G loss: 0.849290, D accuracy: 54.2%, cell accuracy: 99.7%, board accuracy: 80.7% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2923, G loss: 0.8064\n",
      "[84/1762] D loss: 1.2486, G loss: 0.8683\n",
      "[164/1762] D loss: 1.3954, G loss: 0.7504\n",
      "[244/1762] D loss: 1.3886, G loss: 0.6674\n",
      "[324/1762] D loss: 1.3180, G loss: 0.6570\n",
      "[404/1762] D loss: 1.3861, G loss: 0.6357\n",
      "[484/1762] D loss: 1.3423, G loss: 0.7490\n",
      "[564/1762] D loss: 1.4130, G loss: 0.5414\n",
      "[644/1762] D loss: 1.2374, G loss: 1.2556\n",
      "[724/1762] D loss: 1.3989, G loss: 0.8248\n",
      "[804/1762] D loss: 1.4830, G loss: 0.5003\n",
      "[884/1762] D loss: 1.5176, G loss: 1.0461\n",
      "[964/1762] D loss: 1.4387, G loss: 0.9604\n",
      "[1044/1762] D loss: 1.2874, G loss: 0.8565\n",
      "[1124/1762] D loss: 1.3807, G loss: 0.7150\n",
      "[1204/1762] D loss: 1.4035, G loss: 0.6337\n",
      "[1284/1762] D loss: 1.3780, G loss: 0.6537\n",
      "[1364/1762] D loss: 1.3118, G loss: 0.7110\n",
      "[1444/1762] D loss: 1.3135, G loss: 0.6817\n",
      "[1524/1762] D loss: 1.3548, G loss: 0.6410\n",
      "[1604/1762] D loss: 1.4218, G loss: 0.5178\n",
      "[1684/1762] D loss: 1.4074, G loss: 0.9437\n",
      "[1762/1762] D loss: 1.3295, G loss: 0.6838\n",
      "train error: \n",
      " D loss: 1.302583, G loss: 0.700903, D accuracy: 63.0%, cell accuracy: 99.5%, board accuracy: 52.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.290719, G loss: 0.703435, D accuracy: 64.7%, cell accuracy: 99.4%, board accuracy: 50.9% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2821, G loss: 0.7060\n",
      "[84/1762] D loss: 1.3193, G loss: 0.7330\n",
      "[164/1762] D loss: 1.4110, G loss: 0.4790\n",
      "[244/1762] D loss: 1.2741, G loss: 0.6982\n",
      "[324/1762] D loss: 1.3854, G loss: 0.8086\n",
      "[404/1762] D loss: 1.3970, G loss: 0.7084\n",
      "[484/1762] D loss: 1.2173, G loss: 0.7837\n",
      "[564/1762] D loss: 1.3777, G loss: 0.6563\n",
      "[644/1762] D loss: 1.1628, G loss: 0.9617\n",
      "[724/1762] D loss: 1.3161, G loss: 0.8726\n",
      "[804/1762] D loss: 1.3402, G loss: 0.7624\n",
      "[884/1762] D loss: 1.1158, G loss: 0.8921\n",
      "[964/1762] D loss: 1.4372, G loss: 0.8400\n",
      "[1044/1762] D loss: 1.2266, G loss: 0.7323\n",
      "[1124/1762] D loss: 1.3754, G loss: 0.7811\n",
      "[1204/1762] D loss: 1.1783, G loss: 0.8513\n",
      "[1284/1762] D loss: 1.3960, G loss: 0.6307\n",
      "[1364/1762] D loss: 1.3602, G loss: 0.6202\n",
      "[1444/1762] D loss: 1.3357, G loss: 0.7997\n",
      "[1524/1762] D loss: 1.3957, G loss: 0.7498\n",
      "[1604/1762] D loss: 1.4135, G loss: 0.8841\n",
      "[1684/1762] D loss: 1.3349, G loss: 0.7128\n",
      "[1762/1762] D loss: 1.3842, G loss: 0.6177\n",
      "train error: \n",
      " D loss: 1.300277, G loss: 0.663588, D accuracy: 59.4%, cell accuracy: 99.6%, board accuracy: 63.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.290807, G loss: 0.664728, D accuracy: 59.8%, cell accuracy: 99.5%, board accuracy: 64.8% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1860, G loss: 0.8153\n",
      "[84/1762] D loss: 1.3487, G loss: 0.8800\n",
      "[164/1762] D loss: 1.0781, G loss: 0.8149\n",
      "[244/1762] D loss: 1.4173, G loss: 0.5269\n",
      "[324/1762] D loss: 1.3621, G loss: 0.7659\n",
      "[404/1762] D loss: 1.3797, G loss: 0.7063\n",
      "[484/1762] D loss: 1.1891, G loss: 0.9289\n",
      "[564/1762] D loss: 1.0860, G loss: 0.9657\n",
      "[644/1762] D loss: 1.1637, G loss: 0.6299\n",
      "[724/1762] D loss: 1.1240, G loss: 0.8836\n",
      "[804/1762] D loss: 1.4047, G loss: 0.7444\n",
      "[884/1762] D loss: 1.4458, G loss: 0.8910\n",
      "[964/1762] D loss: 1.3942, G loss: 0.6768\n",
      "[1044/1762] D loss: 1.3966, G loss: 0.6707\n",
      "[1124/1762] D loss: 1.4115, G loss: 0.5385\n",
      "[1204/1762] D loss: 1.3949, G loss: 0.7234\n",
      "[1284/1762] D loss: 1.3849, G loss: 0.5970\n",
      "[1364/1762] D loss: 1.2078, G loss: 0.8302\n",
      "[1444/1762] D loss: 1.3964, G loss: 0.6310\n",
      "[1524/1762] D loss: 1.3940, G loss: 0.7539\n",
      "[1604/1762] D loss: 1.1867, G loss: 0.7465\n",
      "[1684/1762] D loss: 1.1953, G loss: 0.8974\n",
      "[1762/1762] D loss: 1.3590, G loss: 0.8821\n",
      "train error: \n",
      " D loss: 1.326282, G loss: 0.744798, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 86.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.307122, G loss: 0.754291, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 83.6% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3940, G loss: 0.6698\n",
      "[84/1762] D loss: 1.4150, G loss: 0.7522\n",
      "[164/1762] D loss: 1.3890, G loss: 0.6777\n",
      "[244/1762] D loss: 1.3871, G loss: 0.6016\n",
      "[324/1762] D loss: 0.9219, G loss: 1.0524\n",
      "[404/1762] D loss: 1.1291, G loss: 0.8262\n",
      "[484/1762] D loss: 1.3817, G loss: 0.6496\n",
      "[564/1762] D loss: 1.4437, G loss: 0.8614\n",
      "[644/1762] D loss: 1.3904, G loss: 0.6467\n",
      "[724/1762] D loss: 1.3893, G loss: 0.6470\n",
      "[804/1762] D loss: 1.3943, G loss: 0.7868\n",
      "[884/1762] D loss: 1.3880, G loss: 0.7303\n",
      "[964/1762] D loss: 1.4947, G loss: 0.5427\n",
      "[1044/1762] D loss: 1.2232, G loss: 0.7230\n",
      "[1124/1762] D loss: 1.3775, G loss: 0.7411\n",
      "[1204/1762] D loss: 1.2727, G loss: 0.7332\n",
      "[1284/1762] D loss: 1.4232, G loss: 0.7585\n",
      "[1364/1762] D loss: 1.2306, G loss: 0.9709\n",
      "[1444/1762] D loss: 1.4122, G loss: 0.6128\n",
      "[1524/1762] D loss: 1.3955, G loss: 0.9015\n",
      "[1604/1762] D loss: 1.1768, G loss: 0.7934\n",
      "[1684/1762] D loss: 1.3910, G loss: 0.6051\n",
      "[1762/1762] D loss: 1.4027, G loss: 0.5803\n",
      "train error: \n",
      " D loss: 1.327998, G loss: 0.636092, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 85.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.310182, G loss: 0.644427, D accuracy: 55.9%, cell accuracy: 99.8%, board accuracy: 82.7% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1922, G loss: 0.7139\n",
      "[84/1762] D loss: 1.3833, G loss: 0.7320\n",
      "[164/1762] D loss: 1.3669, G loss: 0.8033\n",
      "[244/1762] D loss: 1.3879, G loss: 0.6467\n",
      "[324/1762] D loss: 1.3873, G loss: 0.7220\n",
      "[404/1762] D loss: 1.3990, G loss: 0.7399\n",
      "[484/1762] D loss: 1.3977, G loss: 0.6781\n",
      "[564/1762] D loss: 1.3925, G loss: 0.6027\n",
      "[644/1762] D loss: 1.4433, G loss: 0.5482\n",
      "[724/1762] D loss: 1.4768, G loss: 0.4362\n",
      "[804/1762] D loss: 1.2357, G loss: 0.7662\n",
      "[884/1762] D loss: 1.3682, G loss: 0.7858\n",
      "[964/1762] D loss: 1.3731, G loss: 0.7783\n",
      "[1044/1762] D loss: 1.1849, G loss: 0.7663\n",
      "[1124/1762] D loss: 1.4138, G loss: 0.8675\n",
      "[1204/1762] D loss: 0.9726, G loss: 0.7959\n",
      "[1284/1762] D loss: 1.1521, G loss: 0.7742\n",
      "[1364/1762] D loss: 1.1460, G loss: 0.8657\n",
      "[1444/1762] D loss: 1.3501, G loss: 0.8426\n",
      "[1524/1762] D loss: 1.3746, G loss: 0.5727\n",
      "[1604/1762] D loss: 1.3929, G loss: 0.6174\n",
      "[1684/1762] D loss: 1.3868, G loss: 0.6871\n",
      "[1762/1762] D loss: 1.3874, G loss: 0.7258\n",
      "train error: \n",
      " D loss: 1.340241, G loss: 0.706296, D accuracy: 52.3%, cell accuracy: 99.8%, board accuracy: 82.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.326941, G loss: 0.707221, D accuracy: 53.2%, cell accuracy: 99.7%, board accuracy: 78.0% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2306, G loss: 0.6614\n",
      "[84/1762] D loss: 1.2035, G loss: 0.7618\n",
      "[164/1762] D loss: 1.3917, G loss: 0.7419\n",
      "[244/1762] D loss: 1.3870, G loss: 0.7063\n",
      "[324/1762] D loss: 1.3870, G loss: 0.6659\n",
      "[404/1762] D loss: 1.1933, G loss: 0.7456\n",
      "[484/1762] D loss: 1.3846, G loss: 0.8191\n",
      "[564/1762] D loss: 1.3876, G loss: 0.6484\n",
      "[644/1762] D loss: 1.3162, G loss: 0.7998\n",
      "[724/1762] D loss: 1.3793, G loss: 0.7381\n",
      "[804/1762] D loss: 1.3958, G loss: 0.6098\n",
      "[884/1762] D loss: 1.3882, G loss: 0.6462\n",
      "[964/1762] D loss: 1.3883, G loss: 0.6526\n",
      "[1044/1762] D loss: 1.3870, G loss: 0.6644\n",
      "[1124/1762] D loss: 1.3873, G loss: 0.6673\n",
      "[1204/1762] D loss: 1.0649, G loss: 0.6788\n",
      "[1284/1762] D loss: 1.3866, G loss: 0.7067\n",
      "[1364/1762] D loss: 1.3867, G loss: 0.7131\n",
      "[1444/1762] D loss: 1.3876, G loss: 0.7257\n",
      "[1524/1762] D loss: 1.3888, G loss: 0.7263\n",
      "[1604/1762] D loss: 1.3869, G loss: 0.7058\n",
      "[1684/1762] D loss: 1.3856, G loss: 0.6817\n",
      "[1762/1762] D loss: 1.3937, G loss: 0.7125\n",
      "train error: \n",
      " D loss: 1.334809, G loss: 0.713952, D accuracy: 52.7%, cell accuracy: 99.7%, board accuracy: 70.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.319633, G loss: 0.714483, D accuracy: 53.8%, cell accuracy: 99.7%, board accuracy: 70.5% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3879, G loss: 0.7240\n",
      "[84/1762] D loss: 1.3972, G loss: 0.6884\n",
      "[164/1762] D loss: 1.1835, G loss: 0.7573\n",
      "[244/1762] D loss: 1.4171, G loss: 0.7842\n",
      "[324/1762] D loss: 1.3786, G loss: 0.7009\n",
      "[404/1762] D loss: 1.2906, G loss: 0.8940\n",
      "[484/1762] D loss: 1.1598, G loss: 0.7475\n",
      "[564/1762] D loss: 1.3880, G loss: 0.7279\n",
      "[644/1762] D loss: 1.4408, G loss: 0.5817\n",
      "[724/1762] D loss: 1.3900, G loss: 0.7140\n",
      "[804/1762] D loss: 1.3883, G loss: 0.7471\n",
      "[884/1762] D loss: 1.3776, G loss: 0.6629\n",
      "[964/1762] D loss: 0.8137, G loss: 1.0948\n",
      "[1044/1762] D loss: 1.2920, G loss: 0.8355\n",
      "[1124/1762] D loss: 1.3086, G loss: 0.8406\n",
      "[1204/1762] D loss: 0.7024, G loss: 2.9005\n",
      "[1284/1762] D loss: 1.4555, G loss: 0.6530\n",
      "[1364/1762] D loss: 1.2753, G loss: 1.2117\n",
      "[1444/1762] D loss: 0.8849, G loss: 2.1922\n",
      "[1524/1762] D loss: 1.2338, G loss: 0.8572\n",
      "[1604/1762] D loss: 0.8578, G loss: 0.8980\n",
      "[1684/1762] D loss: 1.2178, G loss: 1.3742\n",
      "[1762/1762] D loss: 1.1281, G loss: 0.9778\n",
      "train error: \n",
      " D loss: 1.244274, G loss: 0.853031, D accuracy: 71.7%, cell accuracy: 98.7%, board accuracy: 14.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.232101, G loss: 0.863489, D accuracy: 72.5%, cell accuracy: 98.6%, board accuracy: 13.4% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2913, G loss: 0.8581\n",
      "[84/1762] D loss: 1.2670, G loss: 0.8656\n",
      "[164/1762] D loss: 1.4073, G loss: 0.5404\n",
      "[244/1762] D loss: 1.3962, G loss: 0.5680\n",
      "[324/1762] D loss: 1.3522, G loss: 0.7394\n",
      "[404/1762] D loss: 1.3899, G loss: 0.7529\n",
      "[484/1762] D loss: 1.5246, G loss: 1.0185\n",
      "[564/1762] D loss: 1.2937, G loss: 1.1482\n",
      "[644/1762] D loss: 1.4273, G loss: 0.5074\n",
      "[724/1762] D loss: 1.5497, G loss: 0.9141\n",
      "[804/1762] D loss: 1.3982, G loss: 0.6045\n",
      "[884/1762] D loss: 1.3929, G loss: 0.6425\n",
      "[964/1762] D loss: 1.1634, G loss: 0.7898\n",
      "[1044/1762] D loss: 1.2419, G loss: 0.8397\n",
      "[1124/1762] D loss: 1.1875, G loss: 0.9338\n",
      "[1204/1762] D loss: 1.2242, G loss: 1.0723\n",
      "[1284/1762] D loss: 1.3948, G loss: 0.5830\n",
      "[1364/1762] D loss: 1.0843, G loss: 1.0235\n",
      "[1444/1762] D loss: 1.3556, G loss: 1.0008\n",
      "[1524/1762] D loss: 1.3542, G loss: 1.0471\n",
      "[1604/1762] D loss: 1.1801, G loss: 0.6624\n",
      "[1684/1762] D loss: 1.3812, G loss: 0.6588\n",
      "[1762/1762] D loss: 1.4075, G loss: 0.8374\n",
      "train error: \n",
      " D loss: 1.277761, G loss: 1.423379, D accuracy: 55.1%, cell accuracy: 99.6%, board accuracy: 68.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.243047, G loss: 1.475031, D accuracy: 56.2%, cell accuracy: 99.5%, board accuracy: 64.5% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3544, G loss: 1.0716\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6204\n",
      "[164/1762] D loss: 1.3951, G loss: 0.6049\n",
      "[244/1762] D loss: 1.9592, G loss: 1.1285\n",
      "[324/1762] D loss: 1.3140, G loss: 0.8300\n",
      "[404/1762] D loss: 1.3880, G loss: 0.6959\n",
      "[484/1762] D loss: 1.2074, G loss: 1.0573\n",
      "[564/1762] D loss: 0.8528, G loss: 1.1355\n",
      "[644/1762] D loss: 0.8914, G loss: 1.8951\n",
      "[724/1762] D loss: 0.7838, G loss: 3.8902\n",
      "[804/1762] D loss: 1.0652, G loss: 1.3155\n",
      "[884/1762] D loss: 1.3613, G loss: 0.5602\n",
      "[964/1762] D loss: 1.2669, G loss: 0.6031\n",
      "[1044/1762] D loss: 1.3623, G loss: 0.6480\n",
      "[1124/1762] D loss: 1.3641, G loss: 0.6877\n",
      "[1204/1762] D loss: 1.2020, G loss: 0.8005\n",
      "[1284/1762] D loss: 1.2248, G loss: 1.1109\n",
      "[1364/1762] D loss: 1.3925, G loss: 0.7753\n",
      "[1444/1762] D loss: 1.3965, G loss: 0.6106\n",
      "[1524/1762] D loss: 1.0726, G loss: 1.1580\n",
      "[1604/1762] D loss: 0.7462, G loss: 1.7850\n",
      "[1684/1762] D loss: 1.3659, G loss: 0.6672\n",
      "[1762/1762] D loss: 1.6763, G loss: 0.4221\n",
      "train error: \n",
      " D loss: 1.196710, G loss: 1.123417, D accuracy: 63.3%, cell accuracy: 99.5%, board accuracy: 64.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.159305, G loss: 1.169770, D accuracy: 64.7%, cell accuracy: 99.5%, board accuracy: 60.5% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2188, G loss: 1.0635\n",
      "[84/1762] D loss: 1.3579, G loss: 0.6198\n",
      "[164/1762] D loss: 1.0025, G loss: 1.1824\n",
      "[244/1762] D loss: 1.1943, G loss: 1.4054\n",
      "[324/1762] D loss: 1.2365, G loss: 1.4888\n",
      "[404/1762] D loss: 1.1496, G loss: 1.5896\n",
      "[484/1762] D loss: 0.8052, G loss: 1.3704\n",
      "[564/1762] D loss: 1.3962, G loss: 0.6593\n",
      "[644/1762] D loss: 1.4050, G loss: 0.8133\n",
      "[724/1762] D loss: 1.0858, G loss: 0.9141\n",
      "[804/1762] D loss: 1.4006, G loss: 0.5917\n",
      "[884/1762] D loss: 1.2490, G loss: 0.9831\n",
      "[964/1762] D loss: 1.3924, G loss: 0.6609\n",
      "[1044/1762] D loss: 1.3884, G loss: 0.6569\n",
      "[1124/1762] D loss: 1.0511, G loss: 1.3435\n",
      "[1204/1762] D loss: 1.2101, G loss: 1.6477\n",
      "[1284/1762] D loss: 1.3932, G loss: 0.6393\n",
      "[1364/1762] D loss: 1.3736, G loss: 0.8144\n",
      "[1444/1762] D loss: 1.0493, G loss: 1.5676\n",
      "[1524/1762] D loss: 1.3815, G loss: 0.6825\n",
      "[1604/1762] D loss: 1.3961, G loss: 0.7276\n",
      "[1684/1762] D loss: 1.3856, G loss: 0.6726\n",
      "[1762/1762] D loss: 1.0425, G loss: 1.5759\n",
      "train error: \n",
      " D loss: 1.297206, G loss: 0.726277, D accuracy: 56.9%, cell accuracy: 99.3%, board accuracy: 39.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.277421, G loss: 0.729810, D accuracy: 57.0%, cell accuracy: 99.3%, board accuracy: 40.2% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1088, G loss: 0.8645\n",
      "[84/1762] D loss: 1.3875, G loss: 0.6693\n",
      "[164/1762] D loss: 1.1423, G loss: 0.8704\n",
      "[244/1762] D loss: 1.0710, G loss: 1.1393\n",
      "[324/1762] D loss: 0.9783, G loss: 1.2402\n",
      "[404/1762] D loss: 1.2180, G loss: 1.2391\n",
      "[484/1762] D loss: 1.6769, G loss: 0.4985\n",
      "[564/1762] D loss: 1.3892, G loss: 0.6451\n",
      "[644/1762] D loss: 1.3893, G loss: 0.6436\n",
      "[724/1762] D loss: 1.3787, G loss: 0.6986\n",
      "[804/1762] D loss: 1.3843, G loss: 0.6803\n",
      "[884/1762] D loss: 1.3878, G loss: 0.6692\n",
      "[964/1762] D loss: 0.9893, G loss: 1.6324\n",
      "[1044/1762] D loss: 1.4104, G loss: 0.7563\n",
      "[1124/1762] D loss: 1.0522, G loss: 1.4927\n",
      "[1204/1762] D loss: 1.3936, G loss: 0.6530\n",
      "[1284/1762] D loss: 1.0700, G loss: 1.0427\n",
      "[1364/1762] D loss: 1.2803, G loss: 0.9639\n",
      "[1444/1762] D loss: 1.3898, G loss: 0.6399\n",
      "[1524/1762] D loss: 1.0541, G loss: 1.3448\n",
      "[1604/1762] D loss: 1.3791, G loss: 0.7263\n",
      "[1684/1762] D loss: 1.3919, G loss: 0.6313\n",
      "[1762/1762] D loss: 1.3912, G loss: 0.6487\n",
      "train error: \n",
      " D loss: 1.292564, G loss: 0.830598, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 83.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.267775, G loss: 0.865743, D accuracy: 55.6%, cell accuracy: 99.8%, board accuracy: 84.1% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3874, G loss: 0.7053\n",
      "[84/1762] D loss: 1.3893, G loss: 0.6894\n",
      "[164/1762] D loss: 1.3851, G loss: 0.6639\n",
      "[244/1762] D loss: 1.3889, G loss: 0.6643\n",
      "[324/1762] D loss: 1.3871, G loss: 0.6897\n",
      "[404/1762] D loss: 1.3857, G loss: 0.6854\n",
      "[484/1762] D loss: 1.3755, G loss: 0.6943\n",
      "[564/1762] D loss: 1.3167, G loss: 0.7714\n",
      "[644/1762] D loss: 1.0613, G loss: 0.7366\n",
      "[724/1762] D loss: 1.0971, G loss: 0.9935\n",
      "[804/1762] D loss: 1.1449, G loss: 2.3205\n",
      "[884/1762] D loss: 1.4281, G loss: 0.6720\n",
      "[964/1762] D loss: 0.9369, G loss: 2.2769\n",
      "[1044/1762] D loss: 1.4815, G loss: 0.4757\n",
      "[1124/1762] D loss: 1.4102, G loss: 0.5891\n",
      "[1204/1762] D loss: 1.3972, G loss: 0.6787\n",
      "[1284/1762] D loss: 1.3964, G loss: 0.6250\n",
      "[1364/1762] D loss: 1.3926, G loss: 0.6210\n",
      "[1444/1762] D loss: 1.0674, G loss: 1.0757\n",
      "[1524/1762] D loss: 1.3929, G loss: 0.7136\n",
      "[1604/1762] D loss: 1.0618, G loss: 1.1614\n",
      "[1684/1762] D loss: 1.2082, G loss: 1.1135\n",
      "[1762/1762] D loss: 0.8478, G loss: 2.1596\n",
      "train error: \n",
      " D loss: 1.226736, G loss: 1.263910, D accuracy: 62.8%, cell accuracy: 98.8%, board accuracy: 40.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.229815, G loss: 1.268520, D accuracy: 62.5%, cell accuracy: 98.8%, board accuracy: 40.7% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1212, G loss: 1.5331\n",
      "[84/1762] D loss: 1.4193, G loss: 0.6475\n",
      "[164/1762] D loss: 1.0594, G loss: 1.2013\n",
      "[244/1762] D loss: 1.4212, G loss: 0.6787\n",
      "[324/1762] D loss: 1.3897, G loss: 0.6995\n",
      "[404/1762] D loss: 1.3779, G loss: 0.6568\n",
      "[484/1762] D loss: 1.2358, G loss: 1.5728\n",
      "[564/1762] D loss: 1.0529, G loss: 1.4574\n",
      "[644/1762] D loss: 1.3911, G loss: 0.6390\n",
      "[724/1762] D loss: 1.3825, G loss: 0.6602\n",
      "[804/1762] D loss: 1.3349, G loss: 1.5471\n",
      "[884/1762] D loss: 0.7409, G loss: 1.9859\n",
      "[964/1762] D loss: 1.3877, G loss: 0.6855\n",
      "[1044/1762] D loss: 1.0457, G loss: 1.4585\n",
      "[1124/1762] D loss: 1.3897, G loss: 0.6468\n",
      "[1204/1762] D loss: 1.3900, G loss: 0.6245\n",
      "[1284/1762] D loss: 1.3827, G loss: 0.6767\n",
      "[1364/1762] D loss: 1.3926, G loss: 0.6207\n",
      "[1444/1762] D loss: 1.3866, G loss: 0.7006\n",
      "[1524/1762] D loss: 1.4218, G loss: 0.6009\n",
      "[1604/1762] D loss: 1.3277, G loss: 0.7031\n",
      "[1684/1762] D loss: 1.3714, G loss: 0.6873\n",
      "[1762/1762] D loss: 1.2530, G loss: 0.9222\n",
      "train error: \n",
      " D loss: 1.278292, G loss: 0.889697, D accuracy: 59.4%, cell accuracy: 99.7%, board accuracy: 72.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.261487, G loss: 0.935534, D accuracy: 59.2%, cell accuracy: 99.7%, board accuracy: 70.9% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3805, G loss: 0.7006\n",
      "[84/1762] D loss: 1.0572, G loss: 1.6232\n",
      "[164/1762] D loss: 1.3844, G loss: 0.7082\n",
      "[244/1762] D loss: 1.3460, G loss: 0.7251\n",
      "[324/1762] D loss: 1.3873, G loss: 0.6474\n",
      "[404/1762] D loss: 1.3886, G loss: 0.6158\n",
      "[484/1762] D loss: 0.6729, G loss: 1.9580\n",
      "[564/1762] D loss: 1.3896, G loss: 0.6784\n",
      "[644/1762] D loss: 1.3900, G loss: 0.6514\n",
      "[724/1762] D loss: 1.4003, G loss: 0.6840\n",
      "[804/1762] D loss: 0.9725, G loss: 1.4786\n",
      "[884/1762] D loss: 1.3963, G loss: 0.6400\n",
      "[964/1762] D loss: 1.0367, G loss: 1.4739\n",
      "[1044/1762] D loss: 1.3861, G loss: 0.6813\n",
      "[1124/1762] D loss: 1.3927, G loss: 0.6229\n",
      "[1204/1762] D loss: 1.3816, G loss: 0.6248\n",
      "[1284/1762] D loss: 1.3860, G loss: 0.6648\n",
      "[1364/1762] D loss: 1.3565, G loss: 0.6978\n",
      "[1444/1762] D loss: 1.1462, G loss: 1.1497\n",
      "[1524/1762] D loss: 1.4304, G loss: 0.5981\n",
      "[1604/1762] D loss: 1.2687, G loss: 1.4723\n",
      "[1684/1762] D loss: 1.0296, G loss: 1.4576\n",
      "[1762/1762] D loss: 1.3880, G loss: 0.6894\n",
      "train error: \n",
      " D loss: 1.248858, G loss: 1.187116, D accuracy: 56.5%, cell accuracy: 99.7%, board accuracy: 86.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.211539, G loss: 1.311626, D accuracy: 58.5%, cell accuracy: 99.7%, board accuracy: 83.2% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2065, G loss: 1.5979\n",
      "[84/1762] D loss: 1.0437, G loss: 1.6027\n",
      "[164/1762] D loss: 1.4477, G loss: 0.5935\n",
      "[244/1762] D loss: 1.3864, G loss: 0.6926\n",
      "[324/1762] D loss: 1.3977, G loss: 0.7872\n",
      "[404/1762] D loss: 1.3800, G loss: 0.7034\n",
      "[484/1762] D loss: 1.3819, G loss: 0.6407\n",
      "[564/1762] D loss: 1.2208, G loss: 1.4173\n",
      "[644/1762] D loss: 1.3904, G loss: 0.6590\n",
      "[724/1762] D loss: 1.1948, G loss: 1.6730\n",
      "[804/1762] D loss: 1.1829, G loss: 1.5857\n",
      "[884/1762] D loss: 1.2860, G loss: 0.9000\n",
      "[964/1762] D loss: 1.4065, G loss: 0.7200\n",
      "[1044/1762] D loss: 1.4006, G loss: 0.6465\n",
      "[1124/1762] D loss: 1.0162, G loss: 2.2769\n",
      "[1204/1762] D loss: 0.6676, G loss: 3.0614\n",
      "[1284/1762] D loss: 1.0540, G loss: 1.4953\n",
      "[1364/1762] D loss: 1.3876, G loss: 0.7008\n",
      "[1444/1762] D loss: 1.3913, G loss: 0.6207\n",
      "[1524/1762] D loss: 1.4017, G loss: 0.5788\n",
      "[1604/1762] D loss: 1.3928, G loss: 0.7727\n",
      "[1684/1762] D loss: 1.1756, G loss: 1.4545\n",
      "[1762/1762] D loss: 1.0112, G loss: 5.2821\n",
      "train error: \n",
      " D loss: 1.214918, G loss: 1.201910, D accuracy: 62.7%, cell accuracy: 99.5%, board accuracy: 54.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.180647, G loss: 1.313785, D accuracy: 64.4%, cell accuracy: 99.5%, board accuracy: 51.8% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3866, G loss: 0.5834\n",
      "[84/1762] D loss: 1.1660, G loss: 2.0919\n",
      "[164/1762] D loss: 0.6698, G loss: 9.9779\n",
      "[244/1762] D loss: 1.6398, G loss: 0.3043\n",
      "[324/1762] D loss: 0.9675, G loss: 1.2987\n",
      "[404/1762] D loss: 1.4074, G loss: 0.5630\n",
      "[484/1762] D loss: 1.3402, G loss: 0.6711\n",
      "[564/1762] D loss: 1.3196, G loss: 0.7470\n",
      "[644/1762] D loss: 1.3870, G loss: 0.7455\n",
      "[724/1762] D loss: 1.0699, G loss: 1.1195\n",
      "[804/1762] D loss: 1.3769, G loss: 0.6969\n",
      "[884/1762] D loss: 1.3833, G loss: 0.7078\n",
      "[964/1762] D loss: 1.3828, G loss: 0.6892\n",
      "[1044/1762] D loss: 1.3631, G loss: 0.7095\n",
      "[1124/1762] D loss: 1.0451, G loss: 1.6030\n",
      "[1204/1762] D loss: 1.0447, G loss: 1.5656\n",
      "[1284/1762] D loss: 1.3814, G loss: 0.6674\n",
      "[1364/1762] D loss: 1.0417, G loss: 1.8484\n",
      "[1444/1762] D loss: 1.0437, G loss: 1.5449\n",
      "[1524/1762] D loss: 1.0424, G loss: 2.0763\n",
      "[1604/1762] D loss: 1.3878, G loss: 0.7266\n",
      "[1684/1762] D loss: 1.3887, G loss: 0.6951\n",
      "[1762/1762] D loss: 1.3855, G loss: 0.7218\n",
      "train error: \n",
      " D loss: 1.274572, G loss: 1.042408, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 88.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.253423, G loss: 1.110593, D accuracy: 55.6%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3861, G loss: 0.7496\n",
      "[84/1762] D loss: 1.3994, G loss: 0.8384\n",
      "[164/1762] D loss: 1.3922, G loss: 0.6466\n",
      "[244/1762] D loss: 1.4198, G loss: 0.7638\n",
      "[324/1762] D loss: 1.3914, G loss: 0.7023\n",
      "[404/1762] D loss: 1.3920, G loss: 0.6556\n",
      "[484/1762] D loss: 1.0448, G loss: 1.6489\n",
      "[564/1762] D loss: 1.0456, G loss: 1.5309\n",
      "[644/1762] D loss: 1.3878, G loss: 0.6908\n",
      "[724/1762] D loss: 1.3877, G loss: 0.6848\n",
      "[804/1762] D loss: 1.3891, G loss: 0.6877\n",
      "[884/1762] D loss: 1.0459, G loss: 1.4615\n",
      "[964/1762] D loss: 1.3862, G loss: 0.6980\n",
      "[1044/1762] D loss: 1.3852, G loss: 0.7051\n",
      "[1124/1762] D loss: 1.0428, G loss: 1.7769\n",
      "[1204/1762] D loss: 1.3871, G loss: 0.6906\n",
      "[1284/1762] D loss: 1.3811, G loss: 0.6750\n",
      "[1364/1762] D loss: 1.4833, G loss: 0.7576\n",
      "[1444/1762] D loss: 1.3872, G loss: 0.6813\n",
      "[1524/1762] D loss: 1.3872, G loss: 0.6832\n",
      "[1604/1762] D loss: 1.0433, G loss: 1.6122\n",
      "[1684/1762] D loss: 1.3867, G loss: 0.6941\n",
      "[1762/1762] D loss: 1.3858, G loss: 0.6941\n",
      "train error: \n",
      " D loss: 1.278532, G loss: 1.006172, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.249309, G loss: 1.109628, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0435, G loss: 1.6553\n",
      "[84/1762] D loss: 1.3869, G loss: 0.7006\n",
      "[164/1762] D loss: 1.0603, G loss: 1.8450\n",
      "[244/1762] D loss: 1.0432, G loss: 1.7499\n",
      "[324/1762] D loss: 1.3385, G loss: 0.7366\n",
      "[404/1762] D loss: 1.3861, G loss: 0.6870\n",
      "[484/1762] D loss: 1.0437, G loss: 1.8321\n",
      "[564/1762] D loss: 1.3972, G loss: 0.6073\n",
      "[644/1762] D loss: 1.3901, G loss: 0.6472\n",
      "[724/1762] D loss: 1.3871, G loss: 0.7089\n",
      "[804/1762] D loss: 1.0419, G loss: 2.1446\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6890\n",
      "[964/1762] D loss: 1.1871, G loss: 1.8636\n",
      "[1044/1762] D loss: 1.4013, G loss: 0.5929\n",
      "[1124/1762] D loss: 1.5814, G loss: 0.8512\n",
      "[1204/1762] D loss: 0.6951, G loss: 4.3322\n",
      "[1284/1762] D loss: 1.3915, G loss: 0.6498\n",
      "[1364/1762] D loss: 1.3870, G loss: 0.7266\n",
      "[1444/1762] D loss: 1.3188, G loss: 0.9382\n",
      "[1524/1762] D loss: 1.3841, G loss: 0.6045\n",
      "[1604/1762] D loss: 1.3765, G loss: 0.6214\n",
      "[1684/1762] D loss: 1.4074, G loss: 0.5810\n",
      "[1762/1762] D loss: 1.4075, G loss: 0.7193\n",
      "train error: \n",
      " D loss: 1.285522, G loss: 0.980386, D accuracy: 54.6%, cell accuracy: 99.7%, board accuracy: 74.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.256151, G loss: 1.058158, D accuracy: 55.9%, cell accuracy: 99.6%, board accuracy: 71.4% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3872, G loss: 0.7032\n",
      "[84/1762] D loss: 1.3911, G loss: 0.6776\n",
      "[164/1762] D loss: 1.0500, G loss: 1.4138\n",
      "[244/1762] D loss: 1.0077, G loss: 1.6410\n",
      "[324/1762] D loss: 0.9869, G loss: 1.6457\n",
      "[404/1762] D loss: 1.0292, G loss: 1.7058\n",
      "[484/1762] D loss: 1.3791, G loss: 0.6890\n",
      "[564/1762] D loss: 1.0425, G loss: 1.7413\n",
      "[644/1762] D loss: 1.3835, G loss: 0.6938\n",
      "[724/1762] D loss: 1.0410, G loss: 1.8757\n",
      "[804/1762] D loss: 1.3823, G loss: 0.6763\n",
      "[884/1762] D loss: 1.3765, G loss: 0.6901\n",
      "[964/1762] D loss: 1.3993, G loss: 0.6394\n",
      "[1044/1762] D loss: 1.3200, G loss: 0.6683\n",
      "[1124/1762] D loss: 1.3330, G loss: 0.7389\n",
      "[1204/1762] D loss: 1.2589, G loss: 0.8439\n",
      "[1284/1762] D loss: 1.3293, G loss: 0.7075\n",
      "[1364/1762] D loss: 1.3899, G loss: 0.6448\n",
      "[1444/1762] D loss: 0.3841, G loss: 4.9202\n",
      "[1524/1762] D loss: 1.3912, G loss: 0.6421\n",
      "[1604/1762] D loss: 1.2848, G loss: 1.0344\n",
      "[1684/1762] D loss: 1.3001, G loss: 0.7426\n",
      "[1762/1762] D loss: 1.3858, G loss: 0.7336\n",
      "train error: \n",
      " D loss: 1.267555, G loss: 1.110590, D accuracy: 56.5%, cell accuracy: 99.8%, board accuracy: 81.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.244027, G loss: 1.222126, D accuracy: 57.4%, cell accuracy: 99.7%, board accuracy: 78.9% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0474, G loss: 2.3401\n",
      "[84/1762] D loss: 1.0401, G loss: 2.2500\n",
      "[164/1762] D loss: 1.2031, G loss: 2.8057\n",
      "[244/1762] D loss: 1.3249, G loss: 0.8488\n",
      "[324/1762] D loss: 1.3970, G loss: 0.7483\n",
      "[404/1762] D loss: 1.0501, G loss: 1.9132\n",
      "[484/1762] D loss: 1.3933, G loss: 0.6840\n",
      "[564/1762] D loss: 1.3904, G loss: 0.6631\n",
      "[644/1762] D loss: 1.2748, G loss: 1.1314\n",
      "[724/1762] D loss: 1.3803, G loss: 0.6891\n",
      "[804/1762] D loss: 0.6988, G loss: 3.3691\n",
      "[884/1762] D loss: 1.3893, G loss: 0.6635\n",
      "[964/1762] D loss: 1.4347, G loss: 0.6276\n",
      "[1044/1762] D loss: 1.3880, G loss: 0.7060\n",
      "[1124/1762] D loss: 1.0415, G loss: 2.3143\n",
      "[1204/1762] D loss: 1.3929, G loss: 0.6319\n",
      "[1284/1762] D loss: 1.0337, G loss: 1.9913\n",
      "[1364/1762] D loss: 1.3916, G loss: 0.7249\n",
      "[1444/1762] D loss: 1.0362, G loss: 1.0370\n",
      "[1524/1762] D loss: 1.3946, G loss: 0.7450\n",
      "[1604/1762] D loss: 1.3900, G loss: 0.7580\n",
      "[1684/1762] D loss: 1.0480, G loss: 2.1173\n",
      "[1762/1762] D loss: 1.3895, G loss: 0.6699\n",
      "train error: \n",
      " D loss: 1.280935, G loss: 1.220180, D accuracy: 56.2%, cell accuracy: 99.9%, board accuracy: 90.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.249685, G loss: 1.408892, D accuracy: 56.7%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3958, G loss: 0.6439\n",
      "[84/1762] D loss: 1.0394, G loss: 2.9404\n",
      "[164/1762] D loss: 1.4010, G loss: 0.6025\n",
      "[244/1762] D loss: 1.3912, G loss: 0.6182\n",
      "[324/1762] D loss: 1.3917, G loss: 0.6228\n",
      "[404/1762] D loss: 1.3868, G loss: 0.6823\n",
      "[484/1762] D loss: 1.3205, G loss: 0.6984\n",
      "[564/1762] D loss: 1.3877, G loss: 0.6724\n",
      "[644/1762] D loss: 1.3872, G loss: 0.6647\n",
      "[724/1762] D loss: 1.3853, G loss: 0.6788\n",
      "[804/1762] D loss: 1.0407, G loss: 1.8238\n",
      "[884/1762] D loss: 1.3692, G loss: 0.7099\n",
      "[964/1762] D loss: 1.3876, G loss: 0.6686\n",
      "[1044/1762] D loss: 1.0388, G loss: 2.1355\n",
      "[1124/1762] D loss: 1.3925, G loss: 0.6227\n",
      "[1204/1762] D loss: 1.3875, G loss: 0.6812\n",
      "[1284/1762] D loss: 1.3927, G loss: 0.6246\n",
      "[1364/1762] D loss: 1.3899, G loss: 0.6840\n",
      "[1444/1762] D loss: 1.3987, G loss: 0.7838\n",
      "[1524/1762] D loss: 0.8582, G loss: 3.6897\n",
      "[1604/1762] D loss: 1.3844, G loss: 0.6866\n",
      "[1684/1762] D loss: 1.3293, G loss: 0.7434\n",
      "[1762/1762] D loss: 1.3466, G loss: 0.7076\n",
      "train error: \n",
      " D loss: 1.269252, G loss: 1.058455, D accuracy: 56.7%, cell accuracy: 99.7%, board accuracy: 84.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.252772, G loss: 1.099921, D accuracy: 56.8%, cell accuracy: 99.7%, board accuracy: 81.6% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0386, G loss: 1.1058\n",
      "[84/1762] D loss: 1.0461, G loss: 1.7797\n",
      "[164/1762] D loss: 1.0428, G loss: 1.8769\n",
      "[244/1762] D loss: 1.0488, G loss: 2.1165\n",
      "[324/1762] D loss: 1.2772, G loss: 0.7554\n",
      "[404/1762] D loss: 1.3882, G loss: 0.7082\n",
      "[484/1762] D loss: 1.3895, G loss: 0.7414\n",
      "[564/1762] D loss: 1.3676, G loss: 0.7144\n",
      "[644/1762] D loss: 1.3562, G loss: 0.6794\n",
      "[724/1762] D loss: 1.2446, G loss: 0.9488\n",
      "[804/1762] D loss: 1.3895, G loss: 0.6645\n",
      "[884/1762] D loss: 1.0530, G loss: 2.2644\n",
      "[964/1762] D loss: 1.2952, G loss: 0.8572\n",
      "[1044/1762] D loss: 1.2715, G loss: 1.9199\n",
      "[1124/1762] D loss: 1.3907, G loss: 0.7275\n",
      "[1204/1762] D loss: 1.0440, G loss: 1.7201\n",
      "[1284/1762] D loss: 1.3875, G loss: 0.6985\n",
      "[1364/1762] D loss: 1.3879, G loss: 0.6740\n",
      "[1444/1762] D loss: 1.3856, G loss: 0.6841\n",
      "[1524/1762] D loss: 1.3883, G loss: 0.6970\n",
      "[1604/1762] D loss: 1.3871, G loss: 0.6624\n",
      "[1684/1762] D loss: 1.0425, G loss: 3.1568\n",
      "[1762/1762] D loss: 1.3882, G loss: 0.6489\n",
      "train error: \n",
      " D loss: 1.263894, G loss: 1.149801, D accuracy: 56.4%, cell accuracy: 99.8%, board accuracy: 87.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.234123, G loss: 1.270711, D accuracy: 57.2%, cell accuracy: 99.8%, board accuracy: 83.6% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3880, G loss: 0.6752\n",
      "[84/1762] D loss: 0.6965, G loss: 2.6911\n",
      "[164/1762] D loss: 1.3874, G loss: 0.7177\n",
      "[244/1762] D loss: 1.3248, G loss: 1.8920\n",
      "[324/1762] D loss: 1.2936, G loss: 0.7264\n",
      "[404/1762] D loss: 1.3771, G loss: 0.8183\n",
      "[484/1762] D loss: 1.3866, G loss: 0.7089\n",
      "[564/1762] D loss: 1.3878, G loss: 0.7202\n",
      "[644/1762] D loss: 1.4746, G loss: 0.7583\n",
      "[724/1762] D loss: 1.3871, G loss: 0.7119\n",
      "[804/1762] D loss: 1.3974, G loss: 0.5387\n",
      "[884/1762] D loss: 1.0330, G loss: 1.7559\n",
      "[964/1762] D loss: 1.3891, G loss: 0.6450\n",
      "[1044/1762] D loss: 1.1865, G loss: 2.0302\n",
      "[1124/1762] D loss: 1.3887, G loss: 0.6663\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6801\n",
      "[1284/1762] D loss: 1.3877, G loss: 0.7119\n",
      "[1364/1762] D loss: 1.3348, G loss: 0.7336\n",
      "[1444/1762] D loss: 1.3880, G loss: 0.7217\n",
      "[1524/1762] D loss: 1.0411, G loss: 2.1087\n",
      "[1604/1762] D loss: 1.0405, G loss: 2.8751\n",
      "[1684/1762] D loss: 1.0422, G loss: 2.0061\n",
      "[1762/1762] D loss: 1.0764, G loss: 2.5811\n",
      "train error: \n",
      " D loss: 1.270036, G loss: 1.475278, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 87.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.241148, G loss: 1.718895, D accuracy: 55.5%, cell accuracy: 99.7%, board accuracy: 84.5% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4164, G loss: 0.7426\n",
      "[84/1762] D loss: 1.9953, G loss: 0.6204\n",
      "[164/1762] D loss: 1.3884, G loss: 0.6833\n",
      "[244/1762] D loss: 1.3881, G loss: 0.7105\n",
      "[324/1762] D loss: 1.0610, G loss: 1.2005\n",
      "[404/1762] D loss: 1.3869, G loss: 0.6924\n",
      "[484/1762] D loss: 1.3623, G loss: 0.7185\n",
      "[564/1762] D loss: 1.3833, G loss: 0.6488\n",
      "[644/1762] D loss: 1.3874, G loss: 0.6938\n",
      "[724/1762] D loss: 1.3912, G loss: 0.6781\n",
      "[804/1762] D loss: 1.0398, G loss: 1.9353\n",
      "[884/1762] D loss: 1.3859, G loss: 0.6794\n",
      "[964/1762] D loss: 1.3860, G loss: 0.7229\n",
      "[1044/1762] D loss: 1.3868, G loss: 0.7364\n",
      "[1124/1762] D loss: 1.3877, G loss: 0.6596\n",
      "[1204/1762] D loss: 1.3180, G loss: 0.8047\n",
      "[1284/1762] D loss: 1.3400, G loss: 0.6613\n",
      "[1364/1762] D loss: 1.1955, G loss: 2.2939\n",
      "[1444/1762] D loss: 0.8247, G loss: 3.4737\n",
      "[1524/1762] D loss: 0.9172, G loss: 4.4245\n",
      "[1604/1762] D loss: 1.0429, G loss: 2.9910\n",
      "[1684/1762] D loss: 1.3855, G loss: 0.6393\n",
      "[1762/1762] D loss: 1.3998, G loss: 0.7734\n",
      "train error: \n",
      " D loss: 1.295402, G loss: 1.073434, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.265304, G loss: 1.186025, D accuracy: 55.2%, cell accuracy: 99.7%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6960, G loss: 3.2154\n",
      "[84/1762] D loss: 1.0414, G loss: 1.8459\n",
      "[164/1762] D loss: 1.4250, G loss: 0.7568\n",
      "[244/1762] D loss: 1.3992, G loss: 0.7090\n",
      "[324/1762] D loss: 1.3793, G loss: 0.7296\n",
      "[404/1762] D loss: 1.3872, G loss: 0.6813\n",
      "[484/1762] D loss: 1.3881, G loss: 0.6201\n",
      "[564/1762] D loss: 1.3870, G loss: 0.7068\n",
      "[644/1762] D loss: 1.3866, G loss: 0.6917\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6879\n",
      "[804/1762] D loss: 1.0401, G loss: 2.1541\n",
      "[884/1762] D loss: 1.3869, G loss: 0.6999\n",
      "[964/1762] D loss: 1.0406, G loss: 1.9676\n",
      "[1044/1762] D loss: 1.3869, G loss: 0.6882\n",
      "[1124/1762] D loss: 1.3876, G loss: 0.6682\n",
      "[1204/1762] D loss: 1.3871, G loss: 0.6997\n",
      "[1284/1762] D loss: 1.0407, G loss: 2.0828\n",
      "[1364/1762] D loss: 1.3874, G loss: 0.6816\n",
      "[1444/1762] D loss: 1.0407, G loss: 2.2195\n",
      "[1524/1762] D loss: 0.6970, G loss: 3.3583\n",
      "[1604/1762] D loss: 1.3880, G loss: 0.6699\n",
      "[1684/1762] D loss: 1.3866, G loss: 0.6835\n",
      "[1762/1762] D loss: 1.3870, G loss: 0.7249\n",
      "train error: \n",
      " D loss: 1.286083, G loss: 1.077971, D accuracy: 54.0%, cell accuracy: 99.9%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.255541, G loss: 1.207443, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0402, G loss: 2.4515\n",
      "[84/1762] D loss: 1.3867, G loss: 0.6824\n",
      "[164/1762] D loss: 1.3872, G loss: 0.7089\n",
      "[244/1762] D loss: 1.0400, G loss: 2.0011\n",
      "[324/1762] D loss: 1.3873, G loss: 0.7248\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6925\n",
      "[484/1762] D loss: 1.3871, G loss: 0.7027\n",
      "[564/1762] D loss: 1.3865, G loss: 0.6792\n",
      "[644/1762] D loss: 0.6963, G loss: 3.4563\n",
      "[724/1762] D loss: 1.3865, G loss: 0.6912\n",
      "[804/1762] D loss: 1.1988, G loss: 2.3124\n",
      "[884/1762] D loss: 1.0406, G loss: 2.0408\n",
      "[964/1762] D loss: 1.0407, G loss: 2.0423\n",
      "[1044/1762] D loss: 1.0414, G loss: 2.1758\n",
      "[1124/1762] D loss: 1.0371, G loss: 2.3030\n",
      "[1204/1762] D loss: 0.6938, G loss: 4.1799\n",
      "[1284/1762] D loss: 0.9931, G loss: 1.6736\n",
      "[1364/1762] D loss: 1.3945, G loss: 0.6094\n",
      "[1444/1762] D loss: 1.3874, G loss: 0.6431\n",
      "[1524/1762] D loss: 1.2095, G loss: 0.8617\n",
      "[1604/1762] D loss: 1.2168, G loss: 1.4099\n",
      "[1684/1762] D loss: 1.0455, G loss: 1.4684\n",
      "[1762/1762] D loss: 1.3878, G loss: 0.7182\n",
      "train error: \n",
      " D loss: 1.286370, G loss: 0.965772, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 87.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.254928, G loss: 1.049331, D accuracy: 56.1%, cell accuracy: 99.7%, board accuracy: 83.4% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3912, G loss: 0.7524\n",
      "[84/1762] D loss: 1.3879, G loss: 0.7250\n",
      "[164/1762] D loss: 1.3851, G loss: 0.6881\n",
      "[244/1762] D loss: 0.9682, G loss: 1.7376\n",
      "[324/1762] D loss: 1.3866, G loss: 0.6505\n",
      "[404/1762] D loss: 1.0426, G loss: 2.1046\n",
      "[484/1762] D loss: 1.3872, G loss: 0.6927\n",
      "[564/1762] D loss: 1.3982, G loss: 0.6399\n",
      "[644/1762] D loss: 1.3871, G loss: 0.7081\n",
      "[724/1762] D loss: 1.3887, G loss: 0.7104\n",
      "[804/1762] D loss: 1.3889, G loss: 0.6909\n",
      "[884/1762] D loss: 1.3868, G loss: 0.6841\n",
      "[964/1762] D loss: 1.3861, G loss: 0.6932\n",
      "[1044/1762] D loss: 1.3844, G loss: 0.7075\n",
      "[1124/1762] D loss: 1.3905, G loss: 0.6552\n",
      "[1204/1762] D loss: 1.3870, G loss: 0.7059\n",
      "[1284/1762] D loss: 1.1381, G loss: 0.8464\n",
      "[1364/1762] D loss: 1.3866, G loss: 0.7070\n",
      "[1444/1762] D loss: 1.3894, G loss: 0.6551\n",
      "[1524/1762] D loss: 1.3892, G loss: 0.6557\n",
      "[1604/1762] D loss: 1.3845, G loss: 0.7023\n",
      "[1684/1762] D loss: 1.3874, G loss: 0.6950\n",
      "[1762/1762] D loss: 1.3743, G loss: 0.7051\n",
      "train error: \n",
      " D loss: 1.288962, G loss: 1.130893, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 79.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.257651, G loss: 1.319167, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 74.8% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0420, G loss: 2.0586\n",
      "[84/1762] D loss: 1.0390, G loss: 1.8065\n",
      "[164/1762] D loss: 1.3949, G loss: 0.6856\n",
      "[244/1762] D loss: 1.3901, G loss: 0.7019\n",
      "[324/1762] D loss: 1.3876, G loss: 0.7245\n",
      "[404/1762] D loss: 1.3441, G loss: 0.7335\n",
      "[484/1762] D loss: 1.3995, G loss: 0.7619\n",
      "[564/1762] D loss: 1.3862, G loss: 0.6896\n",
      "[644/1762] D loss: 1.3891, G loss: 0.6276\n",
      "[724/1762] D loss: 1.3875, G loss: 0.7333\n",
      "[804/1762] D loss: 1.3880, G loss: 0.6684\n",
      "[884/1762] D loss: 0.6959, G loss: 3.4850\n",
      "[964/1762] D loss: 1.3875, G loss: 0.6815\n",
      "[1044/1762] D loss: 1.3849, G loss: 0.7056\n",
      "[1124/1762] D loss: 1.3868, G loss: 0.7085\n",
      "[1204/1762] D loss: 1.0416, G loss: 1.9747\n",
      "[1284/1762] D loss: 1.0414, G loss: 2.1705\n",
      "[1364/1762] D loss: 1.3883, G loss: 0.6547\n",
      "[1444/1762] D loss: 1.0409, G loss: 2.1131\n",
      "[1524/1762] D loss: 1.3874, G loss: 0.6897\n",
      "[1604/1762] D loss: 1.3866, G loss: 0.7064\n",
      "[1684/1762] D loss: 1.3871, G loss: 0.6852\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6821\n",
      "train error: \n",
      " D loss: 1.285786, G loss: 1.128744, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.256304, G loss: 1.267211, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0403, G loss: 2.2804\n",
      "[84/1762] D loss: 1.0311, G loss: 2.3226\n",
      "[164/1762] D loss: 1.3864, G loss: 0.6886\n",
      "[244/1762] D loss: 1.3864, G loss: 0.6937\n",
      "[324/1762] D loss: 1.0401, G loss: 2.2420\n",
      "[404/1762] D loss: 1.3843, G loss: 0.6982\n",
      "[484/1762] D loss: 1.0402, G loss: 2.0645\n",
      "[564/1762] D loss: 1.0400, G loss: 2.3650\n",
      "[644/1762] D loss: 1.0371, G loss: 2.4177\n",
      "[724/1762] D loss: 1.3883, G loss: 0.7204\n",
      "[804/1762] D loss: 0.6939, G loss: 4.1637\n",
      "[884/1762] D loss: 1.3867, G loss: 0.6965\n",
      "[964/1762] D loss: 1.3867, G loss: 0.7148\n",
      "[1044/1762] D loss: 1.3849, G loss: 0.6703\n",
      "[1124/1762] D loss: 1.3880, G loss: 0.7314\n",
      "[1204/1762] D loss: 1.3450, G loss: 0.7400\n",
      "[1284/1762] D loss: 1.3952, G loss: 0.6231\n",
      "[1364/1762] D loss: 1.0426, G loss: 2.0766\n",
      "[1444/1762] D loss: 1.0411, G loss: 1.9514\n",
      "[1524/1762] D loss: 1.3873, G loss: 0.6733\n",
      "[1604/1762] D loss: 1.3794, G loss: 0.7092\n",
      "[1684/1762] D loss: 1.3866, G loss: 0.6805\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6921\n",
      "train error: \n",
      " D loss: 1.277668, G loss: 1.168571, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 90.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.252209, G loss: 1.267139, D accuracy: 55.8%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3868, G loss: 0.6807\n",
      "[84/1762] D loss: 1.3866, G loss: 0.6784\n",
      "[164/1762] D loss: 1.3862, G loss: 0.6973\n",
      "[244/1762] D loss: 1.3869, G loss: 0.6708\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6978\n",
      "[404/1762] D loss: 1.3826, G loss: 0.7082\n",
      "[484/1762] D loss: 1.3860, G loss: 0.6815\n",
      "[564/1762] D loss: 1.3870, G loss: 0.6904\n",
      "[644/1762] D loss: 1.3867, G loss: 0.6758\n",
      "[724/1762] D loss: 1.3866, G loss: 0.6843\n",
      "[804/1762] D loss: 1.0400, G loss: 2.3197\n",
      "[884/1762] D loss: 1.3865, G loss: 0.6972\n",
      "[964/1762] D loss: 1.3869, G loss: 0.6639\n",
      "[1044/1762] D loss: 1.0402, G loss: 2.2980\n",
      "[1124/1762] D loss: 1.3866, G loss: 0.7081\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6981\n",
      "[1284/1762] D loss: 1.0402, G loss: 2.2554\n",
      "[1364/1762] D loss: 1.0348, G loss: 2.4293\n",
      "[1444/1762] D loss: 1.3858, G loss: 0.6852\n",
      "[1524/1762] D loss: 1.3884, G loss: 0.6556\n",
      "[1604/1762] D loss: 1.3464, G loss: 0.7800\n",
      "[1684/1762] D loss: 1.3871, G loss: 0.6568\n",
      "[1762/1762] D loss: 1.3871, G loss: 0.7569\n",
      "train error: \n",
      " D loss: 1.290560, G loss: 0.970672, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.260267, G loss: 1.053299, D accuracy: 55.6%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0284, G loss: 1.6296\n",
      "[84/1762] D loss: 1.3862, G loss: 0.6769\n",
      "[164/1762] D loss: 0.6988, G loss: 2.6384\n",
      "[244/1762] D loss: 1.3849, G loss: 0.7279\n",
      "[324/1762] D loss: 1.2464, G loss: 0.9612\n",
      "[404/1762] D loss: 1.1779, G loss: 4.0875\n",
      "[484/1762] D loss: 1.4964, G loss: 0.4663\n",
      "[564/1762] D loss: 1.0985, G loss: 0.9267\n",
      "[644/1762] D loss: 0.7258, G loss: 1.7944\n",
      "[724/1762] D loss: 1.3883, G loss: 0.7291\n",
      "[804/1762] D loss: 1.3867, G loss: 0.7186\n",
      "[884/1762] D loss: 1.3891, G loss: 0.7022\n",
      "[964/1762] D loss: 1.3871, G loss: 0.7111\n",
      "[1044/1762] D loss: 1.4852, G loss: 0.7433\n",
      "[1124/1762] D loss: 1.0582, G loss: 1.2391\n",
      "[1204/1762] D loss: 1.4006, G loss: 0.6806\n",
      "[1284/1762] D loss: 1.0451, G loss: 1.6756\n",
      "[1364/1762] D loss: 1.3899, G loss: 0.7113\n",
      "[1444/1762] D loss: 1.0659, G loss: 1.1541\n",
      "[1524/1762] D loss: 1.3845, G loss: 0.6956\n",
      "[1604/1762] D loss: 1.3866, G loss: 0.6868\n",
      "[1684/1762] D loss: 1.3836, G loss: 0.6872\n",
      "[1762/1762] D loss: 0.0041, G loss: 5.6064\n",
      "train error: \n",
      " D loss: 1.279064, G loss: 1.012275, D accuracy: 54.6%, cell accuracy: 99.4%, board accuracy: 44.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.257118, G loss: 1.105150, D accuracy: 55.5%, cell accuracy: 99.4%, board accuracy: 43.6% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3869, G loss: 0.7134\n",
      "[84/1762] D loss: 1.3638, G loss: 0.7311\n",
      "[164/1762] D loss: 0.7127, G loss: 2.6134\n",
      "[244/1762] D loss: 1.2409, G loss: 1.1776\n",
      "[324/1762] D loss: 1.0499, G loss: 2.6230\n",
      "[404/1762] D loss: 0.8106, G loss: 5.4027\n",
      "[484/1762] D loss: 1.3685, G loss: 0.5806\n",
      "[564/1762] D loss: 1.3879, G loss: 0.6706\n",
      "[644/1762] D loss: 1.3602, G loss: 0.6946\n",
      "[724/1762] D loss: 1.3946, G loss: 0.6396\n",
      "[804/1762] D loss: 1.2387, G loss: 1.0685\n",
      "[884/1762] D loss: 1.0416, G loss: 1.9985\n",
      "[964/1762] D loss: 0.9665, G loss: 1.2470\n",
      "[1044/1762] D loss: 1.2952, G loss: 0.8551\n",
      "[1124/1762] D loss: 0.7382, G loss: 1.3675\n",
      "[1204/1762] D loss: 1.3963, G loss: 1.2824\n",
      "[1284/1762] D loss: 1.4860, G loss: 0.3946\n",
      "[1364/1762] D loss: 1.3887, G loss: 0.7414\n",
      "[1444/1762] D loss: 1.4012, G loss: 0.6733\n",
      "[1524/1762] D loss: 1.3755, G loss: 0.6432\n",
      "[1604/1762] D loss: 1.3888, G loss: 0.7261\n",
      "[1684/1762] D loss: 1.3890, G loss: 0.6738\n",
      "[1762/1762] D loss: 1.3881, G loss: 0.6367\n",
      "train error: \n",
      " D loss: 1.291811, G loss: 0.966250, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.263024, G loss: 1.037015, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 84.8% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0538, G loss: 1.6226\n",
      "[84/1762] D loss: 1.3879, G loss: 0.7291\n",
      "[164/1762] D loss: 1.4072, G loss: 0.6351\n",
      "[244/1762] D loss: 1.3919, G loss: 0.6856\n",
      "[324/1762] D loss: 1.3881, G loss: 0.6880\n",
      "[404/1762] D loss: 1.3800, G loss: 0.7038\n",
      "[484/1762] D loss: 1.0455, G loss: 1.7530\n",
      "[564/1762] D loss: 1.3859, G loss: 0.6817\n",
      "[644/1762] D loss: 1.3870, G loss: 0.6906\n",
      "[724/1762] D loss: 1.3958, G loss: 0.6873\n",
      "[804/1762] D loss: 1.0419, G loss: 1.8407\n",
      "[884/1762] D loss: 1.3869, G loss: 0.6651\n",
      "[964/1762] D loss: 1.3806, G loss: 0.7055\n",
      "[1044/1762] D loss: 1.3873, G loss: 0.6754\n",
      "[1124/1762] D loss: 0.8765, G loss: 1.8081\n",
      "[1204/1762] D loss: 1.2381, G loss: 1.0214\n",
      "[1284/1762] D loss: 1.3867, G loss: 0.6683\n",
      "[1364/1762] D loss: 1.2301, G loss: 1.1150\n",
      "[1444/1762] D loss: 1.3887, G loss: 0.6937\n",
      "[1524/1762] D loss: 1.3790, G loss: 0.7080\n",
      "[1604/1762] D loss: 1.0412, G loss: 1.8856\n",
      "[1684/1762] D loss: 0.6976, G loss: 3.3594\n",
      "[1762/1762] D loss: 1.3971, G loss: 0.7822\n",
      "train error: \n",
      " D loss: 1.293467, G loss: 1.095501, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 86.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.261112, G loss: 1.190649, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0406, G loss: 2.6003\n",
      "[84/1762] D loss: 1.3877, G loss: 0.7063\n",
      "[164/1762] D loss: 1.3889, G loss: 0.7298\n",
      "[244/1762] D loss: 1.0401, G loss: 3.0360\n",
      "[324/1762] D loss: 1.3811, G loss: 0.6883\n",
      "[404/1762] D loss: 1.0405, G loss: 1.8363\n",
      "[484/1762] D loss: 1.3877, G loss: 0.6737\n",
      "[564/1762] D loss: 0.6933, G loss: 3.1915\n",
      "[644/1762] D loss: 1.3876, G loss: 0.7149\n",
      "[724/1762] D loss: 1.3808, G loss: 0.6246\n",
      "[804/1762] D loss: 1.3599, G loss: 0.7504\n",
      "[884/1762] D loss: 1.1969, G loss: 0.8369\n",
      "[964/1762] D loss: 1.3869, G loss: 0.6937\n",
      "[1044/1762] D loss: 1.3906, G loss: 0.7036\n",
      "[1124/1762] D loss: 1.3871, G loss: 0.6943\n",
      "[1204/1762] D loss: 1.3887, G loss: 0.7205\n",
      "[1284/1762] D loss: 1.0406, G loss: 1.9847\n",
      "[1364/1762] D loss: 1.3885, G loss: 0.6802\n",
      "[1444/1762] D loss: 1.0402, G loss: 2.0314\n",
      "[1524/1762] D loss: 1.3858, G loss: 0.6734\n",
      "[1604/1762] D loss: 1.3861, G loss: 0.6815\n",
      "[1684/1762] D loss: 1.3861, G loss: 0.7025\n",
      "[1762/1762] D loss: 1.3914, G loss: 0.6727\n",
      "train error: \n",
      " D loss: 1.286413, G loss: 1.079895, D accuracy: 54.3%, cell accuracy: 99.9%, board accuracy: 91.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.256133, G loss: 1.201263, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0411, G loss: 1.9465\n",
      "[84/1762] D loss: 1.0404, G loss: 2.0421\n",
      "[164/1762] D loss: 1.0413, G loss: 2.0635\n",
      "[244/1762] D loss: 1.3820, G loss: 0.7123\n",
      "[324/1762] D loss: 1.0403, G loss: 2.0829\n",
      "[404/1762] D loss: 1.0450, G loss: 2.0686\n",
      "[484/1762] D loss: 1.3863, G loss: 0.6796\n",
      "[564/1762] D loss: 1.3789, G loss: 0.6684\n",
      "[644/1762] D loss: 1.0410, G loss: 2.0264\n",
      "[724/1762] D loss: 1.0402, G loss: 2.1275\n",
      "[804/1762] D loss: 1.3855, G loss: 0.6942\n",
      "[884/1762] D loss: 1.3785, G loss: 0.7171\n",
      "[964/1762] D loss: 1.3834, G loss: 0.6879\n",
      "[1044/1762] D loss: 1.3825, G loss: 0.6719\n",
      "[1124/1762] D loss: 1.3697, G loss: 0.6925\n",
      "[1204/1762] D loss: 1.2693, G loss: 0.7304\n",
      "[1284/1762] D loss: 1.3398, G loss: 0.6591\n",
      "[1364/1762] D loss: 1.3872, G loss: 0.7196\n",
      "[1444/1762] D loss: 1.2112, G loss: 0.8355\n",
      "[1524/1762] D loss: 1.3914, G loss: 0.7464\n",
      "[1604/1762] D loss: 1.3859, G loss: 0.6937\n",
      "[1684/1762] D loss: 1.0446, G loss: 1.7360\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6982\n",
      "train error: \n",
      " D loss: 1.260361, G loss: 1.225548, D accuracy: 55.8%, cell accuracy: 99.3%, board accuracy: 86.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.217686, G loss: 1.443259, D accuracy: 57.5%, cell accuracy: 99.1%, board accuracy: 82.7% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0369, G loss: 2.2621\n",
      "[84/1762] D loss: 1.3183, G loss: 0.7039\n",
      "[164/1762] D loss: 1.3557, G loss: 0.6721\n",
      "[244/1762] D loss: 1.3749, G loss: 0.6816\n",
      "[324/1762] D loss: 1.3843, G loss: 0.6145\n",
      "[404/1762] D loss: 1.4064, G loss: 0.8298\n",
      "[484/1762] D loss: 1.4003, G loss: 0.7024\n",
      "[564/1762] D loss: 1.0489, G loss: 2.2517\n",
      "[644/1762] D loss: 1.0201, G loss: 1.6066\n",
      "[724/1762] D loss: 1.3362, G loss: 0.6910\n",
      "[804/1762] D loss: 1.3616, G loss: 0.7010\n",
      "[884/1762] D loss: 1.0353, G loss: 1.3554\n",
      "[964/1762] D loss: 1.3875, G loss: 0.7133\n",
      "[1044/1762] D loss: 1.3540, G loss: 0.7673\n",
      "[1124/1762] D loss: 1.3946, G loss: 0.6655\n",
      "[1204/1762] D loss: 1.0073, G loss: 2.5801\n",
      "[1284/1762] D loss: 1.3881, G loss: 0.7103\n",
      "[1364/1762] D loss: 1.4079, G loss: 0.5554\n",
      "[1444/1762] D loss: 1.0493, G loss: 1.5776\n",
      "[1524/1762] D loss: 1.3702, G loss: 0.7796\n",
      "[1604/1762] D loss: 1.0753, G loss: 1.2611\n",
      "[1684/1762] D loss: 1.4086, G loss: 0.4714\n",
      "[1762/1762] D loss: 0.7629, G loss: 1.3717\n",
      "train error: \n",
      " D loss: 0.950909, G loss: 2.494999, D accuracy: 77.1%, cell accuracy: 98.8%, board accuracy: 7.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.946189, G loss: 2.939890, D accuracy: 76.6%, cell accuracy: 98.7%, board accuracy: 7.3% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0206, G loss: 4.2916\n",
      "[84/1762] D loss: 0.5932, G loss: 4.0264\n",
      "[164/1762] D loss: 1.3774, G loss: 0.8115\n",
      "[244/1762] D loss: 0.7095, G loss: 2.5144\n",
      "[324/1762] D loss: 1.3932, G loss: 0.6428\n",
      "[404/1762] D loss: 1.3913, G loss: 0.6432\n",
      "[484/1762] D loss: 2.7018, G loss: 0.7729\n",
      "[564/1762] D loss: 1.3934, G loss: 0.7560\n",
      "[644/1762] D loss: 1.3893, G loss: 0.6511\n",
      "[724/1762] D loss: 1.3857, G loss: 0.7293\n",
      "[804/1762] D loss: 1.0537, G loss: 1.3092\n",
      "[884/1762] D loss: 1.0639, G loss: 1.1385\n",
      "[964/1762] D loss: 1.3854, G loss: 0.6648\n",
      "[1044/1762] D loss: 1.0976, G loss: 1.3221\n",
      "[1124/1762] D loss: 1.0849, G loss: 0.9300\n",
      "[1204/1762] D loss: 1.3757, G loss: 0.6458\n",
      "[1284/1762] D loss: 1.0929, G loss: 0.9939\n",
      "[1364/1762] D loss: 1.3883, G loss: 0.7439\n",
      "[1444/1762] D loss: 1.0235, G loss: 1.8291\n",
      "[1524/1762] D loss: 1.1166, G loss: 1.0786\n",
      "[1604/1762] D loss: 1.0543, G loss: 1.6068\n",
      "[1684/1762] D loss: 1.3853, G loss: 0.6531\n",
      "[1762/1762] D loss: 1.3803, G loss: 0.7623\n",
      "train error: \n",
      " D loss: 1.291933, G loss: 1.015782, D accuracy: 55.2%, cell accuracy: 99.7%, board accuracy: 84.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.261817, G loss: 1.155469, D accuracy: 56.1%, cell accuracy: 99.6%, board accuracy: 83.6% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2738, G loss: 0.8466\n",
      "[84/1762] D loss: 1.3911, G loss: 0.6802\n",
      "[164/1762] D loss: 1.0412, G loss: 2.9602\n",
      "[244/1762] D loss: 1.2493, G loss: 0.9081\n",
      "[324/1762] D loss: 1.3027, G loss: 0.8475\n",
      "[404/1762] D loss: 1.3902, G loss: 0.6660\n",
      "[484/1762] D loss: 1.3846, G loss: 0.7198\n",
      "[564/1762] D loss: 1.3908, G loss: 0.6486\n",
      "[644/1762] D loss: 1.3857, G loss: 0.7017\n",
      "[724/1762] D loss: 1.3880, G loss: 0.6289\n",
      "[804/1762] D loss: 1.3062, G loss: 0.7890\n",
      "[884/1762] D loss: 1.0460, G loss: 1.9796\n",
      "[964/1762] D loss: 1.0178, G loss: 2.6527\n",
      "[1044/1762] D loss: 1.0283, G loss: 3.6507\n",
      "[1124/1762] D loss: 1.3994, G loss: 0.7196\n",
      "[1204/1762] D loss: 1.4393, G loss: 0.5059\n",
      "[1284/1762] D loss: 1.0694, G loss: 1.2276\n",
      "[1364/1762] D loss: 1.0429, G loss: 1.8314\n",
      "[1444/1762] D loss: 1.3919, G loss: 0.7093\n",
      "[1524/1762] D loss: 1.3861, G loss: 0.6629\n",
      "[1604/1762] D loss: 1.3873, G loss: 0.6721\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6997\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.6882\n",
      "train error: \n",
      " D loss: 1.291431, G loss: 0.974983, D accuracy: 54.1%, cell accuracy: 99.7%, board accuracy: 89.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.264302, G loss: 1.072536, D accuracy: 54.7%, cell accuracy: 99.6%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0419, G loss: 2.0989\n",
      "[84/1762] D loss: 1.2174, G loss: 2.0752\n",
      "[164/1762] D loss: 1.3867, G loss: 0.6703\n",
      "[244/1762] D loss: 0.6943, G loss: 4.1988\n",
      "[324/1762] D loss: 1.3815, G loss: 0.7008\n",
      "[404/1762] D loss: 1.3871, G loss: 0.6694\n",
      "[484/1762] D loss: 1.3869, G loss: 0.6853\n",
      "[564/1762] D loss: 1.0408, G loss: 2.1898\n",
      "[644/1762] D loss: 1.0396, G loss: 2.4192\n",
      "[724/1762] D loss: 1.3865, G loss: 0.6915\n",
      "[804/1762] D loss: 1.0445, G loss: 1.4879\n",
      "[884/1762] D loss: 1.3873, G loss: 0.6926\n",
      "[964/1762] D loss: 1.3647, G loss: 0.7499\n",
      "[1044/1762] D loss: 1.3837, G loss: 0.6950\n",
      "[1124/1762] D loss: 1.0405, G loss: 2.9774\n",
      "[1204/1762] D loss: 1.3880, G loss: 0.7151\n",
      "[1284/1762] D loss: 1.3826, G loss: 0.7099\n",
      "[1364/1762] D loss: 1.4009, G loss: 0.6681\n",
      "[1444/1762] D loss: 1.3883, G loss: 0.6883\n",
      "[1524/1762] D loss: 1.3949, G loss: 0.6920\n",
      "[1604/1762] D loss: 1.0366, G loss: 2.6535\n",
      "[1684/1762] D loss: 1.3875, G loss: 0.6650\n",
      "[1762/1762] D loss: 1.3870, G loss: 0.6761\n",
      "train error: \n",
      " D loss: 1.276701, G loss: 1.556278, D accuracy: 56.6%, cell accuracy: 99.6%, board accuracy: 80.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.250595, G loss: 1.842429, D accuracy: 57.4%, cell accuracy: 99.5%, board accuracy: 79.3% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0406, G loss: 2.2755\n",
      "[84/1762] D loss: 1.0405, G loss: 2.6963\n",
      "[164/1762] D loss: 1.3857, G loss: 0.6968\n",
      "[244/1762] D loss: 1.3869, G loss: 0.7291\n",
      "[324/1762] D loss: 1.3839, G loss: 0.6735\n",
      "[404/1762] D loss: 1.3844, G loss: 0.6788\n",
      "[484/1762] D loss: 1.3866, G loss: 0.7065\n",
      "[564/1762] D loss: 1.3871, G loss: 0.7241\n",
      "[644/1762] D loss: 1.0414, G loss: 1.6788\n",
      "[724/1762] D loss: 1.0421, G loss: 1.8974\n",
      "[804/1762] D loss: 1.1021, G loss: 0.9897\n",
      "[884/1762] D loss: 1.1885, G loss: 0.7801\n",
      "[964/1762] D loss: 1.0398, G loss: 2.2260\n",
      "[1044/1762] D loss: 1.3644, G loss: 0.6815\n",
      "[1124/1762] D loss: 1.3861, G loss: 0.6765\n",
      "[1204/1762] D loss: 1.3874, G loss: 0.7137\n",
      "[1284/1762] D loss: 1.3878, G loss: 0.7397\n",
      "[1364/1762] D loss: 1.3866, G loss: 0.7013\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.7079\n",
      "[1524/1762] D loss: 1.3850, G loss: 0.6782\n",
      "[1604/1762] D loss: 1.0430, G loss: 3.7048\n",
      "[1684/1762] D loss: 1.0178, G loss: 2.1434\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6702\n",
      "train error: \n",
      " D loss: 1.287152, G loss: 1.418594, D accuracy: 54.3%, cell accuracy: 99.7%, board accuracy: 89.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.258786, G loss: 1.653602, D accuracy: 55.3%, cell accuracy: 99.6%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3858, G loss: 0.7195\n",
      "[84/1762] D loss: 1.3813, G loss: 0.6841\n",
      "[164/1762] D loss: 1.2849, G loss: 1.0124\n",
      "[244/1762] D loss: 1.0403, G loss: 2.8272\n",
      "[324/1762] D loss: 1.3886, G loss: 0.6522\n",
      "[404/1762] D loss: 1.3862, G loss: 0.7055\n",
      "[484/1762] D loss: 1.0402, G loss: 4.2154\n",
      "[564/1762] D loss: 1.3975, G loss: 0.7165\n",
      "[644/1762] D loss: 1.3870, G loss: 0.6542\n",
      "[724/1762] D loss: 1.3842, G loss: 0.7574\n",
      "[804/1762] D loss: 1.4018, G loss: 0.5967\n",
      "[884/1762] D loss: 1.3866, G loss: 0.6794\n",
      "[964/1762] D loss: 1.3867, G loss: 0.6763\n",
      "[1044/1762] D loss: 1.0406, G loss: 1.8690\n",
      "[1124/1762] D loss: 1.2860, G loss: 0.8397\n",
      "[1204/1762] D loss: 1.3969, G loss: 0.6191\n",
      "[1284/1762] D loss: 1.0438, G loss: 2.3106\n",
      "[1364/1762] D loss: 1.0376, G loss: 1.9053\n",
      "[1444/1762] D loss: 1.3874, G loss: 0.6686\n",
      "[1524/1762] D loss: 1.3880, G loss: 0.7309\n",
      "[1604/1762] D loss: 1.2035, G loss: 2.1617\n",
      "[1684/1762] D loss: 1.3379, G loss: 0.6627\n",
      "[1762/1762] D loss: 1.3866, G loss: 0.7040\n",
      "train error: \n",
      " D loss: 1.276699, G loss: 1.322716, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.256276, G loss: 1.450197, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3880, G loss: 0.6653\n",
      "[84/1762] D loss: 0.6964, G loss: 4.3359\n",
      "[164/1762] D loss: 1.3947, G loss: 0.7593\n",
      "[244/1762] D loss: 1.3865, G loss: 0.6978\n",
      "[324/1762] D loss: 1.0419, G loss: 1.7819\n",
      "[404/1762] D loss: 1.3885, G loss: 0.6744\n",
      "[484/1762] D loss: 1.3887, G loss: 0.6901\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6883\n",
      "[644/1762] D loss: 1.3871, G loss: 0.6714\n",
      "[724/1762] D loss: 1.3829, G loss: 0.6900\n",
      "[804/1762] D loss: 1.3858, G loss: 0.7004\n",
      "[884/1762] D loss: 0.9210, G loss: 2.5902\n",
      "[964/1762] D loss: 1.3919, G loss: 0.6488\n",
      "[1044/1762] D loss: 0.7017, G loss: 4.7654\n",
      "[1124/1762] D loss: 1.3960, G loss: 0.6057\n",
      "[1204/1762] D loss: 1.0491, G loss: 2.2984\n",
      "[1284/1762] D loss: 1.3869, G loss: 0.6568\n",
      "[1364/1762] D loss: 1.3885, G loss: 0.7053\n",
      "[1444/1762] D loss: 1.3884, G loss: 0.6490\n",
      "[1524/1762] D loss: 0.8496, G loss: 3.4672\n",
      "[1604/1762] D loss: 1.3887, G loss: 0.6563\n",
      "[1684/1762] D loss: 1.3882, G loss: 0.6786\n",
      "[1762/1762] D loss: 1.3856, G loss: 0.6987\n",
      "train error: \n",
      " D loss: 1.275667, G loss: 1.265049, D accuracy: 55.4%, cell accuracy: 99.8%, board accuracy: 88.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.245726, G loss: 1.499643, D accuracy: 55.9%, cell accuracy: 99.7%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3412, G loss: 0.7449\n",
      "[84/1762] D loss: 1.3833, G loss: 0.7202\n",
      "[164/1762] D loss: 1.0420, G loss: 2.4043\n",
      "[244/1762] D loss: 1.3877, G loss: 0.7180\n",
      "[324/1762] D loss: 1.0363, G loss: 4.3454\n",
      "[404/1762] D loss: 1.0428, G loss: 2.6640\n",
      "[484/1762] D loss: 1.3867, G loss: 0.7175\n",
      "[564/1762] D loss: 1.3244, G loss: 0.8080\n",
      "[644/1762] D loss: 1.3862, G loss: 0.7020\n",
      "[724/1762] D loss: 1.3887, G loss: 0.6499\n",
      "[804/1762] D loss: 1.3881, G loss: 0.6991\n",
      "[884/1762] D loss: 1.0404, G loss: 2.2509\n",
      "[964/1762] D loss: 1.3875, G loss: 0.7288\n",
      "[1044/1762] D loss: 1.3900, G loss: 0.6562\n",
      "[1124/1762] D loss: 1.3701, G loss: 0.8079\n",
      "[1204/1762] D loss: 1.3854, G loss: 0.6668\n",
      "[1284/1762] D loss: 1.3851, G loss: 0.7134\n",
      "[1364/1762] D loss: 1.3898, G loss: 0.6945\n",
      "[1444/1762] D loss: 1.3862, G loss: 0.6988\n",
      "[1524/1762] D loss: 1.3856, G loss: 0.6868\n",
      "[1604/1762] D loss: 1.3666, G loss: 0.7416\n",
      "[1684/1762] D loss: 1.3518, G loss: 0.6871\n",
      "[1762/1762] D loss: 0.6208, G loss: 3.1646\n",
      "train error: \n",
      " D loss: 1.267392, G loss: 1.010711, D accuracy: 60.1%, cell accuracy: 99.8%, board accuracy: 88.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.234733, G loss: 1.141185, D accuracy: 61.5%, cell accuracy: 99.8%, board accuracy: 85.0% \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3557, G loss: 0.7505\n",
      "[84/1762] D loss: 1.2174, G loss: 0.8642\n",
      "[164/1762] D loss: 1.0396, G loss: 2.6415\n",
      "[244/1762] D loss: 1.3510, G loss: 0.6650\n",
      "[324/1762] D loss: 1.3824, G loss: 0.8186\n",
      "[404/1762] D loss: 1.3826, G loss: 0.6242\n",
      "[484/1762] D loss: 1.3758, G loss: 0.6662\n",
      "[564/1762] D loss: 1.3501, G loss: 0.7104\n",
      "[644/1762] D loss: 1.3748, G loss: 0.7513\n",
      "[724/1762] D loss: 1.3854, G loss: 0.7733\n",
      "[804/1762] D loss: 1.3131, G loss: 0.6662\n",
      "[884/1762] D loss: 1.0403, G loss: 4.9660\n",
      "[964/1762] D loss: 1.3309, G loss: 0.7381\n",
      "[1044/1762] D loss: 1.3615, G loss: 0.7510\n",
      "[1124/1762] D loss: 1.0420, G loss: 2.0755\n",
      "[1204/1762] D loss: 1.3883, G loss: 0.6407\n",
      "[1284/1762] D loss: 1.0399, G loss: 2.3378\n",
      "[1364/1762] D loss: 1.3855, G loss: 0.6707\n",
      "[1444/1762] D loss: 1.3677, G loss: 0.7129\n",
      "[1524/1762] D loss: 1.1364, G loss: 4.1806\n",
      "[1604/1762] D loss: 1.3980, G loss: 0.6327\n",
      "[1684/1762] D loss: 1.3880, G loss: 0.6868\n",
      "[1762/1762] D loss: 1.3878, G loss: 0.6678\n",
      "train error: \n",
      " D loss: 1.277364, G loss: 1.096314, D accuracy: 54.7%, cell accuracy: 99.9%, board accuracy: 91.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.241606, G loss: 1.290819, D accuracy: 55.9%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3943, G loss: 0.6723\n",
      "[84/1762] D loss: 1.3816, G loss: 0.6461\n",
      "[164/1762] D loss: 1.3969, G loss: 0.6410\n",
      "[244/1762] D loss: 1.0428, G loss: 2.0061\n",
      "[324/1762] D loss: 1.4125, G loss: 0.5643\n",
      "[404/1762] D loss: 1.3861, G loss: 0.6672\n",
      "[484/1762] D loss: 1.3869, G loss: 0.7187\n",
      "[564/1762] D loss: 1.3873, G loss: 0.6680\n",
      "[644/1762] D loss: 1.3860, G loss: 0.6877\n",
      "[724/1762] D loss: 1.3859, G loss: 0.6814\n",
      "[804/1762] D loss: 1.3867, G loss: 0.6738\n",
      "[884/1762] D loss: 1.3825, G loss: 0.6836\n",
      "[964/1762] D loss: 1.0403, G loss: 2.0922\n",
      "[1044/1762] D loss: 1.0995, G loss: 0.9039\n",
      "[1124/1762] D loss: 1.0435, G loss: 2.6583\n",
      "[1204/1762] D loss: 1.0272, G loss: 1.7211\n",
      "[1284/1762] D loss: 1.0411, G loss: 2.3482\n",
      "[1364/1762] D loss: 1.3840, G loss: 0.6753\n",
      "[1444/1762] D loss: 1.0342, G loss: 1.5989\n",
      "[1524/1762] D loss: 1.3869, G loss: 0.6898\n",
      "[1604/1762] D loss: 1.3891, G loss: 0.7018\n",
      "[1684/1762] D loss: 1.3895, G loss: 0.6562\n",
      "[1762/1762] D loss: 1.3881, G loss: 0.6799\n",
      "train error: \n",
      " D loss: 1.291736, G loss: 1.040644, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.262635, G loss: 1.143855, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0423, G loss: 1.8102\n",
      "[84/1762] D loss: 1.0430, G loss: 1.8296\n",
      "[164/1762] D loss: 1.3857, G loss: 0.6921\n",
      "[244/1762] D loss: 1.3857, G loss: 0.7157\n",
      "[324/1762] D loss: 1.3856, G loss: 0.6849\n",
      "[404/1762] D loss: 1.3850, G loss: 0.6865\n",
      "[484/1762] D loss: 1.3862, G loss: 0.7179\n",
      "[564/1762] D loss: 1.3863, G loss: 0.6711\n",
      "[644/1762] D loss: 1.3915, G loss: 0.6999\n",
      "[724/1762] D loss: 1.3826, G loss: 0.6822\n",
      "[804/1762] D loss: 1.3896, G loss: 0.6670\n",
      "[884/1762] D loss: 1.4724, G loss: 0.4466\n",
      "[964/1762] D loss: 1.4360, G loss: 0.5363\n",
      "[1044/1762] D loss: 1.3872, G loss: 0.6652\n",
      "[1124/1762] D loss: 1.3878, G loss: 0.6533\n",
      "[1204/1762] D loss: 1.3896, G loss: 0.7297\n",
      "[1284/1762] D loss: 1.3901, G loss: 0.6655\n",
      "[1364/1762] D loss: 1.3842, G loss: 0.7026\n",
      "[1444/1762] D loss: 1.3866, G loss: 0.6883\n",
      "[1524/1762] D loss: 1.0357, G loss: 2.2260\n",
      "[1604/1762] D loss: 1.0409, G loss: 1.9111\n",
      "[1684/1762] D loss: 1.2500, G loss: 1.3192\n",
      "[1762/1762] D loss: 1.3862, G loss: 0.6958\n",
      "train error: \n",
      " D loss: 1.259750, G loss: 1.132879, D accuracy: 56.5%, cell accuracy: 99.8%, board accuracy: 89.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.217570, G loss: 1.260126, D accuracy: 58.8%, cell accuracy: 99.7%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0424, G loss: 1.9355\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6667\n",
      "[164/1762] D loss: 1.0417, G loss: 1.9084\n",
      "[244/1762] D loss: 1.3883, G loss: 0.7166\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6902\n",
      "[404/1762] D loss: 1.3876, G loss: 0.6825\n",
      "[484/1762] D loss: 1.3866, G loss: 0.6851\n",
      "[564/1762] D loss: 1.3912, G loss: 0.6449\n",
      "[644/1762] D loss: 1.2129, G loss: 6.7971\n",
      "[724/1762] D loss: 1.0871, G loss: 2.6016\n",
      "[804/1762] D loss: 1.3904, G loss: 0.6191\n",
      "[884/1762] D loss: 1.2354, G loss: 2.5123\n",
      "[964/1762] D loss: 1.3852, G loss: 0.6518\n",
      "[1044/1762] D loss: 1.3825, G loss: 0.7122\n",
      "[1124/1762] D loss: 1.0404, G loss: 2.0713\n",
      "[1204/1762] D loss: 1.3833, G loss: 0.7258\n",
      "[1284/1762] D loss: 1.3832, G loss: 0.6789\n",
      "[1364/1762] D loss: 1.3835, G loss: 0.7056\n",
      "[1444/1762] D loss: 1.3854, G loss: 0.6882\n",
      "[1524/1762] D loss: 1.3751, G loss: 0.7089\n",
      "[1604/1762] D loss: 1.3824, G loss: 0.6726\n",
      "[1684/1762] D loss: 1.3775, G loss: 0.7116\n",
      "[1762/1762] D loss: 0.6935, G loss: 6.6793\n",
      "train error: \n",
      " D loss: 1.268983, G loss: 1.210434, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.237790, G loss: 1.322317, D accuracy: 56.4%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3306, G loss: 0.7728\n",
      "[84/1762] D loss: 1.3895, G loss: 0.6567\n",
      "[164/1762] D loss: 1.3820, G loss: 0.7175\n",
      "[244/1762] D loss: 1.3822, G loss: 0.7114\n",
      "[324/1762] D loss: 1.0422, G loss: 3.1969\n",
      "[404/1762] D loss: 1.3848, G loss: 0.6779\n",
      "[484/1762] D loss: 1.3832, G loss: 0.6536\n",
      "[564/1762] D loss: 1.4014, G loss: 0.5920\n",
      "[644/1762] D loss: 1.0416, G loss: 3.1776\n",
      "[724/1762] D loss: 1.3873, G loss: 0.6744\n",
      "[804/1762] D loss: 1.3906, G loss: 0.6611\n",
      "[884/1762] D loss: 1.3851, G loss: 0.7351\n",
      "[964/1762] D loss: 1.0622, G loss: 1.1614\n",
      "[1044/1762] D loss: 1.3845, G loss: 0.6729\n",
      "[1124/1762] D loss: 1.3858, G loss: 0.7267\n",
      "[1204/1762] D loss: 1.0400, G loss: 3.0371\n",
      "[1284/1762] D loss: 1.0412, G loss: 2.2104\n",
      "[1364/1762] D loss: 1.3811, G loss: 0.7092\n",
      "[1444/1762] D loss: 1.0411, G loss: 2.2835\n",
      "[1524/1762] D loss: 1.3881, G loss: 0.7090\n",
      "[1604/1762] D loss: 1.3873, G loss: 0.6569\n",
      "[1684/1762] D loss: 1.3727, G loss: 0.6473\n",
      "[1762/1762] D loss: 1.3874, G loss: 0.6615\n",
      "train error: \n",
      " D loss: 1.283074, G loss: 1.202505, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.245666, G loss: 1.479880, D accuracy: 57.0%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3723, G loss: 0.6416\n",
      "[84/1762] D loss: 1.3752, G loss: 0.7125\n",
      "[164/1762] D loss: 1.3873, G loss: 0.7180\n",
      "[244/1762] D loss: 1.3868, G loss: 0.7119\n",
      "[324/1762] D loss: 1.3784, G loss: 0.7181\n",
      "[404/1762] D loss: 1.3845, G loss: 0.6642\n",
      "[484/1762] D loss: 1.3863, G loss: 0.6845\n",
      "[564/1762] D loss: 1.3714, G loss: 0.6831\n",
      "[644/1762] D loss: 1.0483, G loss: 3.6149\n",
      "[724/1762] D loss: 1.3927, G loss: 0.6738\n",
      "[804/1762] D loss: 1.3894, G loss: 0.7281\n",
      "[884/1762] D loss: 1.3908, G loss: 0.6375\n",
      "[964/1762] D loss: 1.1809, G loss: 1.6282\n",
      "[1044/1762] D loss: 1.3910, G loss: 0.6951\n",
      "[1124/1762] D loss: 0.6964, G loss: 3.2489\n",
      "[1204/1762] D loss: 1.3916, G loss: 0.6630\n",
      "[1284/1762] D loss: 1.0406, G loss: 2.6455\n",
      "[1364/1762] D loss: 1.3877, G loss: 0.6615\n",
      "[1444/1762] D loss: 1.3870, G loss: 0.7033\n",
      "[1524/1762] D loss: 1.1353, G loss: 1.0409\n",
      "[1604/1762] D loss: 1.3886, G loss: 0.7069\n",
      "[1684/1762] D loss: 1.0410, G loss: 2.1343\n",
      "[1762/1762] D loss: 1.3812, G loss: 0.6712\n",
      "train error: \n",
      " D loss: 1.294250, G loss: 1.061658, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.263553, G loss: 1.179256, D accuracy: 55.8%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3096, G loss: 0.7429\n",
      "[84/1762] D loss: 1.3864, G loss: 0.7026\n",
      "[164/1762] D loss: 1.0418, G loss: 2.5582\n",
      "[244/1762] D loss: 1.3942, G loss: 0.7571\n",
      "[324/1762] D loss: 1.3903, G loss: 0.7178\n",
      "[404/1762] D loss: 1.3843, G loss: 0.6695\n",
      "[484/1762] D loss: 1.3865, G loss: 0.6936\n",
      "[564/1762] D loss: 1.0399, G loss: 2.5061\n",
      "[644/1762] D loss: 1.3902, G loss: 0.7283\n",
      "[724/1762] D loss: 1.3884, G loss: 0.6563\n",
      "[804/1762] D loss: 1.3841, G loss: 0.6814\n",
      "[884/1762] D loss: 1.3867, G loss: 0.7111\n",
      "[964/1762] D loss: 1.3863, G loss: 0.6841\n",
      "[1044/1762] D loss: 1.3826, G loss: 0.6640\n",
      "[1124/1762] D loss: 1.3886, G loss: 0.6795\n",
      "[1204/1762] D loss: 1.3774, G loss: 0.7157\n",
      "[1284/1762] D loss: 1.3660, G loss: 0.6734\n",
      "[1364/1762] D loss: 1.3853, G loss: 0.6773\n",
      "[1444/1762] D loss: 1.3944, G loss: 0.7516\n",
      "[1524/1762] D loss: 1.3812, G loss: 0.6482\n",
      "[1604/1762] D loss: 0.8857, G loss: 4.7468\n",
      "[1684/1762] D loss: 1.3960, G loss: 0.7582\n",
      "[1762/1762] D loss: 0.6942, G loss: 2.5613\n",
      "train error: \n",
      " D loss: 1.276384, G loss: 0.984309, D accuracy: 56.2%, cell accuracy: 99.8%, board accuracy: 89.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.244548, G loss: 1.094737, D accuracy: 56.5%, cell accuracy: 99.7%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3851, G loss: 0.7606\n",
      "[84/1762] D loss: 1.4250, G loss: 0.8717\n",
      "[164/1762] D loss: 1.0437, G loss: 1.6035\n",
      "[244/1762] D loss: 1.3874, G loss: 0.7503\n",
      "[324/1762] D loss: 1.0857, G loss: 0.9457\n",
      "[404/1762] D loss: 1.1618, G loss: 1.3847\n",
      "[484/1762] D loss: 1.4043, G loss: 0.7357\n",
      "[564/1762] D loss: 1.0471, G loss: 1.8790\n",
      "[644/1762] D loss: 1.0385, G loss: 2.3608\n",
      "[724/1762] D loss: 1.2787, G loss: 0.9195\n",
      "[804/1762] D loss: 1.4166, G loss: 0.6813\n",
      "[884/1762] D loss: 1.0516, G loss: 1.8124\n",
      "[964/1762] D loss: 0.7831, G loss: 2.2206\n",
      "[1044/1762] D loss: 1.3300, G loss: 0.7898\n",
      "[1124/1762] D loss: 1.3862, G loss: 0.7065\n",
      "[1204/1762] D loss: 1.0636, G loss: 1.1572\n",
      "[1284/1762] D loss: 1.2293, G loss: 1.4618\n",
      "[1364/1762] D loss: 1.3987, G loss: 0.7475\n",
      "[1444/1762] D loss: 1.4562, G loss: 0.7929\n",
      "[1524/1762] D loss: 1.0432, G loss: 1.7868\n",
      "[1604/1762] D loss: 1.3292, G loss: 0.7467\n",
      "[1684/1762] D loss: 1.2292, G loss: 1.2857\n",
      "[1762/1762] D loss: 1.3866, G loss: 0.7038\n",
      "train error: \n",
      " D loss: 1.267182, G loss: 1.103315, D accuracy: 55.6%, cell accuracy: 99.7%, board accuracy: 80.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.242029, G loss: 1.294636, D accuracy: 56.8%, cell accuracy: 99.7%, board accuracy: 80.9% \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3979, G loss: 0.6284\n",
      "[84/1762] D loss: 1.3816, G loss: 0.6987\n",
      "[164/1762] D loss: 1.3864, G loss: 0.6804\n",
      "[244/1762] D loss: 1.3478, G loss: 0.6879\n",
      "[324/1762] D loss: 1.3821, G loss: 0.6989\n",
      "[404/1762] D loss: 0.6981, G loss: 3.1869\n",
      "[484/1762] D loss: 1.3698, G loss: 0.6996\n",
      "[564/1762] D loss: 1.3863, G loss: 0.6959\n",
      "[644/1762] D loss: 1.3867, G loss: 0.6912\n",
      "[724/1762] D loss: 1.0406, G loss: 2.3623\n",
      "[804/1762] D loss: 1.3220, G loss: 0.7758\n",
      "[884/1762] D loss: 1.0398, G loss: 3.0075\n",
      "[964/1762] D loss: 1.3868, G loss: 0.7249\n",
      "[1044/1762] D loss: 1.3908, G loss: 0.6469\n",
      "[1124/1762] D loss: 1.3840, G loss: 0.7019\n",
      "[1204/1762] D loss: 1.3336, G loss: 0.7511\n",
      "[1284/1762] D loss: 1.0399, G loss: 2.5870\n",
      "[1364/1762] D loss: 1.3965, G loss: 0.6510\n",
      "[1444/1762] D loss: 1.3942, G loss: 0.6598\n",
      "[1524/1762] D loss: 1.3875, G loss: 0.7184\n",
      "[1604/1762] D loss: 1.3825, G loss: 0.7066\n",
      "[1684/1762] D loss: 0.6895, G loss: 3.6032\n",
      "[1762/1762] D loss: 1.3862, G loss: 0.6918\n",
      "train error: \n",
      " D loss: 1.278170, G loss: 1.208479, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.241421, G loss: 1.453453, D accuracy: 56.0%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3866, G loss: 0.7046\n",
      "[84/1762] D loss: 1.0424, G loss: 1.8541\n",
      "[164/1762] D loss: 1.3865, G loss: 0.6774\n",
      "[244/1762] D loss: 1.2085, G loss: 1.8005\n",
      "[324/1762] D loss: 1.0416, G loss: 1.7524\n",
      "[404/1762] D loss: 1.0460, G loss: 1.8010\n",
      "[484/1762] D loss: 1.3875, G loss: 0.6659\n",
      "[564/1762] D loss: 0.6956, G loss: 3.0071\n",
      "[644/1762] D loss: 1.3890, G loss: 0.7364\n",
      "[724/1762] D loss: 1.3872, G loss: 0.6946\n",
      "[804/1762] D loss: 1.3872, G loss: 0.6955\n",
      "[884/1762] D loss: 0.6946, G loss: 3.6318\n",
      "[964/1762] D loss: 1.0403, G loss: 2.2206\n",
      "[1044/1762] D loss: 1.3882, G loss: 0.7286\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.6964\n",
      "[1204/1762] D loss: 1.3889, G loss: 0.7363\n",
      "[1284/1762] D loss: 1.0405, G loss: 2.1428\n",
      "[1364/1762] D loss: 0.6942, G loss: 3.5021\n",
      "[1444/1762] D loss: 1.3861, G loss: 0.6865\n",
      "[1524/1762] D loss: 1.3752, G loss: 0.7075\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6966\n",
      "[1684/1762] D loss: 1.0640, G loss: 2.3487\n",
      "[1762/1762] D loss: 1.3859, G loss: 0.6959\n",
      "train error: \n",
      " D loss: 1.234642, G loss: 1.911703, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 80.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.204278, G loss: 1.983024, D accuracy: 57.4%, cell accuracy: 99.8%, board accuracy: 79.3% \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2425, G loss: 2.5312\n",
      "[84/1762] D loss: 1.3862, G loss: 0.6805\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6925\n",
      "[244/1762] D loss: 1.3870, G loss: 0.6968\n",
      "[324/1762] D loss: 0.6938, G loss: 3.6514\n",
      "[404/1762] D loss: 1.3853, G loss: 0.6712\n",
      "[484/1762] D loss: 1.3871, G loss: 0.6955\n",
      "[564/1762] D loss: 1.3838, G loss: 0.6746\n",
      "[644/1762] D loss: 1.3878, G loss: 0.7000\n",
      "[724/1762] D loss: 1.0408, G loss: 2.3354\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6852\n",
      "[884/1762] D loss: 1.3861, G loss: 0.6802\n",
      "[964/1762] D loss: 1.0399, G loss: 3.6395\n",
      "[1044/1762] D loss: 1.3866, G loss: 0.6733\n",
      "[1124/1762] D loss: 1.3852, G loss: 0.6961\n",
      "[1204/1762] D loss: 1.3840, G loss: 0.6820\n",
      "[1284/1762] D loss: 1.0408, G loss: 2.1662\n",
      "[1364/1762] D loss: 1.3854, G loss: 0.6985\n",
      "[1444/1762] D loss: 1.2097, G loss: 1.9768\n",
      "[1524/1762] D loss: 1.0409, G loss: 2.3528\n",
      "[1604/1762] D loss: 1.3857, G loss: 0.7025\n",
      "[1684/1762] D loss: 1.3824, G loss: 0.6915\n",
      "[1762/1762] D loss: 1.3888, G loss: 0.6727\n",
      "train error: \n",
      " D loss: 1.293027, G loss: 1.091691, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 92.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.263502, G loss: 1.238427, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0451, G loss: 2.8092\n",
      "[84/1762] D loss: 1.2872, G loss: 0.7840\n",
      "[164/1762] D loss: 1.3900, G loss: 0.7355\n",
      "[244/1762] D loss: 1.3908, G loss: 0.7459\n",
      "[324/1762] D loss: 1.3711, G loss: 0.7174\n",
      "[404/1762] D loss: 1.0405, G loss: 2.1608\n",
      "[484/1762] D loss: 1.3877, G loss: 0.6746\n",
      "[564/1762] D loss: 1.3883, G loss: 0.7104\n",
      "[644/1762] D loss: 1.3862, G loss: 0.7018\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6889\n",
      "[804/1762] D loss: 1.3817, G loss: 0.6966\n",
      "[884/1762] D loss: 1.3866, G loss: 0.6787\n",
      "[964/1762] D loss: 1.3846, G loss: 0.6820\n",
      "[1044/1762] D loss: 1.3848, G loss: 0.6744\n",
      "[1124/1762] D loss: 1.3867, G loss: 0.7079\n",
      "[1204/1762] D loss: 1.3884, G loss: 0.6839\n",
      "[1284/1762] D loss: 1.0869, G loss: 2.5627\n",
      "[1364/1762] D loss: 1.3868, G loss: 0.6743\n",
      "[1444/1762] D loss: 1.3871, G loss: 0.7042\n",
      "[1524/1762] D loss: 1.0407, G loss: 2.3211\n",
      "[1604/1762] D loss: 1.0461, G loss: 2.3801\n",
      "[1684/1762] D loss: 1.3873, G loss: 0.6682\n",
      "[1762/1762] D loss: 1.3874, G loss: 0.6678\n",
      "train error: \n",
      " D loss: 1.286346, G loss: 1.174292, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.258121, G loss: 1.327231, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3809, G loss: 0.6834\n",
      "[84/1762] D loss: 1.3866, G loss: 0.6938\n",
      "[164/1762] D loss: 1.0397, G loss: 2.1630\n",
      "[244/1762] D loss: 1.0400, G loss: 2.3047\n",
      "[324/1762] D loss: 1.0200, G loss: 2.3941\n",
      "[404/1762] D loss: 1.0389, G loss: 2.3758\n",
      "[484/1762] D loss: 1.3819, G loss: 0.7013\n",
      "[564/1762] D loss: 1.3893, G loss: 0.6582\n",
      "[644/1762] D loss: 1.3868, G loss: 0.7032\n",
      "[724/1762] D loss: 1.0413, G loss: 2.1910\n",
      "[804/1762] D loss: 1.3871, G loss: 0.7097\n",
      "[884/1762] D loss: 1.3866, G loss: 0.6822\n",
      "[964/1762] D loss: 1.3864, G loss: 0.6866\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6974\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.6984\n",
      "[1204/1762] D loss: 1.3866, G loss: 0.6827\n",
      "[1284/1762] D loss: 1.3866, G loss: 0.6864\n",
      "[1364/1762] D loss: 1.3885, G loss: 0.6849\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.6730\n",
      "[1524/1762] D loss: 1.3850, G loss: 0.7131\n",
      "[1604/1762] D loss: 1.3759, G loss: 0.6811\n",
      "[1684/1762] D loss: 1.3981, G loss: 0.7029\n",
      "[1762/1762] D loss: 1.3859, G loss: 0.6921\n",
      "train error: \n",
      " D loss: 1.290320, G loss: 0.945632, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 82.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.253733, G loss: 1.101540, D accuracy: 55.7%, cell accuracy: 99.7%, board accuracy: 79.5% \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3868, G loss: 0.6857\n",
      "[84/1762] D loss: 1.3883, G loss: 0.6667\n",
      "[164/1762] D loss: 1.0453, G loss: 1.8985\n",
      "[244/1762] D loss: 1.3858, G loss: 0.6970\n",
      "[324/1762] D loss: 1.3875, G loss: 0.7144\n",
      "[404/1762] D loss: 1.0412, G loss: 2.2546\n",
      "[484/1762] D loss: 1.3925, G loss: 0.6342\n",
      "[564/1762] D loss: 1.3739, G loss: 0.7022\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6977\n",
      "[724/1762] D loss: 1.3872, G loss: 0.6635\n",
      "[804/1762] D loss: 1.3870, G loss: 0.6723\n",
      "[884/1762] D loss: 1.3873, G loss: 0.6899\n",
      "[964/1762] D loss: 1.3867, G loss: 0.6800\n",
      "[1044/1762] D loss: 1.3870, G loss: 0.7160\n",
      "[1124/1762] D loss: 1.3869, G loss: 0.7100\n",
      "[1204/1762] D loss: 1.0388, G loss: 2.0129\n",
      "[1284/1762] D loss: 1.0407, G loss: 2.0657\n",
      "[1364/1762] D loss: 1.3836, G loss: 0.7040\n",
      "[1444/1762] D loss: 1.3867, G loss: 0.7148\n",
      "[1524/1762] D loss: 1.3865, G loss: 0.6888\n",
      "[1604/1762] D loss: 1.0519, G loss: 0.9514\n",
      "[1684/1762] D loss: 1.0477, G loss: 1.4551\n",
      "[1762/1762] D loss: 1.3875, G loss: 0.6919\n",
      "train error: \n",
      " D loss: 1.292239, G loss: 1.136862, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.256668, G loss: 1.291381, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0449, G loss: 2.3973\n",
      "[84/1762] D loss: 1.0400, G loss: 2.2634\n",
      "[164/1762] D loss: 1.0444, G loss: 2.0989\n",
      "[244/1762] D loss: 1.3852, G loss: 0.6877\n",
      "[324/1762] D loss: 1.3926, G loss: 0.6999\n",
      "[404/1762] D loss: 0.6960, G loss: 4.1353\n",
      "[484/1762] D loss: 1.0417, G loss: 1.6470\n",
      "[564/1762] D loss: 1.3875, G loss: 0.6683\n",
      "[644/1762] D loss: 1.3865, G loss: 0.6801\n",
      "[724/1762] D loss: 1.3825, G loss: 0.7408\n",
      "[804/1762] D loss: 1.3863, G loss: 0.6880\n",
      "[884/1762] D loss: 1.3866, G loss: 0.6874\n",
      "[964/1762] D loss: 1.3875, G loss: 0.6776\n",
      "[1044/1762] D loss: 1.3879, G loss: 0.7251\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.6838\n",
      "[1204/1762] D loss: 1.3874, G loss: 0.7092\n",
      "[1284/1762] D loss: 1.3861, G loss: 0.6904\n",
      "[1364/1762] D loss: 1.0403, G loss: 2.0247\n",
      "[1444/1762] D loss: 1.3866, G loss: 0.6859\n",
      "[1524/1762] D loss: 1.3856, G loss: 0.6843\n",
      "[1604/1762] D loss: 1.3869, G loss: 0.7139\n",
      "[1684/1762] D loss: 1.3865, G loss: 0.6810\n",
      "[1762/1762] D loss: 1.3882, G loss: 0.6486\n",
      "train error: \n",
      " D loss: 1.267316, G loss: 1.232814, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 87.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.238472, G loss: 1.313858, D accuracy: 56.0%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1904, G loss: 2.9110\n",
      "[84/1762] D loss: 1.3869, G loss: 0.7095\n",
      "[164/1762] D loss: 1.2196, G loss: 1.4844\n",
      "[244/1762] D loss: 1.3868, G loss: 0.7219\n",
      "[324/1762] D loss: 1.3879, G loss: 0.6756\n",
      "[404/1762] D loss: 1.3863, G loss: 0.6929\n",
      "[484/1762] D loss: 1.0407, G loss: 2.1745\n",
      "[564/1762] D loss: 1.0415, G loss: 2.1202\n",
      "[644/1762] D loss: 1.0402, G loss: 2.1175\n",
      "[724/1762] D loss: 0.6935, G loss: 5.5177\n",
      "[804/1762] D loss: 1.3867, G loss: 0.6852\n",
      "[884/1762] D loss: 1.0394, G loss: 4.0145\n",
      "[964/1762] D loss: 1.3856, G loss: 0.6849\n",
      "[1044/1762] D loss: 1.0400, G loss: 2.3190\n",
      "[1124/1762] D loss: 1.0411, G loss: 1.8688\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6866\n",
      "[1284/1762] D loss: 1.3865, G loss: 0.6944\n",
      "[1364/1762] D loss: 1.3869, G loss: 0.6795\n",
      "[1444/1762] D loss: 1.3866, G loss: 0.6913\n",
      "[1524/1762] D loss: 1.3867, G loss: 0.7022\n",
      "[1604/1762] D loss: 1.0409, G loss: 1.9928\n",
      "[1684/1762] D loss: 1.0400, G loss: 2.2417\n",
      "[1762/1762] D loss: 0.6940, G loss: 3.5429\n",
      "train error: \n",
      " D loss: 1.283392, G loss: 1.126677, D accuracy: 54.2%, cell accuracy: 99.9%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.253112, G loss: 1.249800, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3882, G loss: 0.6731\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6769\n",
      "[164/1762] D loss: 1.3862, G loss: 0.6923\n",
      "[244/1762] D loss: 1.2115, G loss: 2.3591\n",
      "[324/1762] D loss: 1.3878, G loss: 0.6586\n",
      "[404/1762] D loss: 1.3925, G loss: 0.6534\n",
      "[484/1762] D loss: 1.3863, G loss: 0.7234\n",
      "[564/1762] D loss: 1.1849, G loss: 7.1106\n",
      "[644/1762] D loss: 1.3931, G loss: 0.7603\n",
      "[724/1762] D loss: 1.3865, G loss: 0.6876\n",
      "[804/1762] D loss: 1.3867, G loss: 0.6867\n",
      "[884/1762] D loss: 1.3874, G loss: 0.6847\n",
      "[964/1762] D loss: 1.3863, G loss: 0.6951\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6937\n",
      "[1124/1762] D loss: 1.0418, G loss: 1.7412\n",
      "[1204/1762] D loss: 1.3865, G loss: 0.6893\n",
      "[1284/1762] D loss: 1.3865, G loss: 0.7086\n",
      "[1364/1762] D loss: 1.3867, G loss: 0.6765\n",
      "[1444/1762] D loss: 1.3878, G loss: 0.6801\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.6933\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6973\n",
      "[1684/1762] D loss: 1.0404, G loss: 2.2063\n",
      "[1762/1762] D loss: 0.6895, G loss: 3.7757\n",
      "train error: \n",
      " D loss: 1.283858, G loss: 1.140535, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 90.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.253289, G loss: 1.266039, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3859, G loss: 0.6847\n",
      "[84/1762] D loss: 1.2340, G loss: 1.2011\n",
      "[164/1762] D loss: 1.0407, G loss: 1.9428\n",
      "[244/1762] D loss: 1.3713, G loss: 0.7332\n",
      "[324/1762] D loss: 1.3749, G loss: 0.7439\n",
      "[404/1762] D loss: 1.3823, G loss: 0.6893\n",
      "[484/1762] D loss: 1.3867, G loss: 0.6709\n",
      "[564/1762] D loss: 0.6945, G loss: 3.3525\n",
      "[644/1762] D loss: 1.3858, G loss: 0.6909\n",
      "[724/1762] D loss: 1.0407, G loss: 2.1875\n",
      "[804/1762] D loss: 1.0433, G loss: 2.2599\n",
      "[884/1762] D loss: 1.3712, G loss: 0.7264\n",
      "[964/1762] D loss: 1.3831, G loss: 0.6916\n",
      "[1044/1762] D loss: 0.9395, G loss: 2.3402\n",
      "[1124/1762] D loss: 1.0459, G loss: 6.5385\n",
      "[1204/1762] D loss: 1.3919, G loss: 0.6820\n",
      "[1284/1762] D loss: 1.3870, G loss: 0.7090\n",
      "[1364/1762] D loss: 1.0377, G loss: 1.8968\n",
      "[1444/1762] D loss: 1.0431, G loss: 1.9274\n",
      "[1524/1762] D loss: 1.3867, G loss: 0.6832\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6963\n",
      "[1684/1762] D loss: 1.0541, G loss: 1.2701\n",
      "[1762/1762] D loss: 1.3868, G loss: 0.6808\n",
      "train error: \n",
      " D loss: 1.292134, G loss: 1.069686, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.261204, G loss: 1.179205, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3875, G loss: 0.6685\n",
      "[84/1762] D loss: 1.0402, G loss: 2.1341\n",
      "[164/1762] D loss: 1.3871, G loss: 0.7028\n",
      "[244/1762] D loss: 1.0403, G loss: 2.0573\n",
      "[324/1762] D loss: 1.3860, G loss: 0.6836\n",
      "[404/1762] D loss: 1.3860, G loss: 0.6951\n",
      "[484/1762] D loss: 1.0401, G loss: 2.2512\n",
      "[564/1762] D loss: 1.3864, G loss: 0.7022\n",
      "[644/1762] D loss: 1.3865, G loss: 0.6813\n",
      "[724/1762] D loss: 1.3869, G loss: 0.7157\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6959\n",
      "[884/1762] D loss: 1.3865, G loss: 0.6979\n",
      "[964/1762] D loss: 1.0405, G loss: 2.2613\n",
      "[1044/1762] D loss: 1.3869, G loss: 0.6835\n",
      "[1124/1762] D loss: 1.3856, G loss: 0.6953\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.7002\n",
      "[1284/1762] D loss: 1.0453, G loss: 1.6657\n",
      "[1364/1762] D loss: 1.3867, G loss: 0.7054\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6898\n",
      "[1524/1762] D loss: 1.3794, G loss: 0.7151\n",
      "[1604/1762] D loss: 1.0403, G loss: 2.2321\n",
      "[1684/1762] D loss: 1.0403, G loss: 2.2117\n",
      "[1762/1762] D loss: 0.6970, G loss: 4.4512\n",
      "train error: \n",
      " D loss: 1.285189, G loss: 1.176751, D accuracy: 54.1%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.256528, G loss: 1.342859, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0417, G loss: 2.2009\n",
      "[84/1762] D loss: 1.3872, G loss: 0.6653\n",
      "[164/1762] D loss: 1.3864, G loss: 0.7064\n",
      "[244/1762] D loss: 1.3870, G loss: 0.6726\n",
      "[324/1762] D loss: 1.0406, G loss: 2.2215\n",
      "[404/1762] D loss: 1.3863, G loss: 0.6884\n",
      "[484/1762] D loss: 1.3865, G loss: 0.6960\n",
      "[564/1762] D loss: 1.0400, G loss: 2.2497\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6880\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6918\n",
      "[804/1762] D loss: 1.3873, G loss: 0.6691\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6902\n",
      "[964/1762] D loss: 1.3908, G loss: 0.6621\n",
      "[1044/1762] D loss: 1.3861, G loss: 0.6856\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6921\n",
      "[1204/1762] D loss: 1.3866, G loss: 0.6873\n",
      "[1284/1762] D loss: 1.3614, G loss: 0.7167\n",
      "[1364/1762] D loss: 1.3862, G loss: 0.6921\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6877\n",
      "[1524/1762] D loss: 1.3911, G loss: 0.7334\n",
      "[1604/1762] D loss: 1.3861, G loss: 0.6945\n",
      "[1684/1762] D loss: 1.3860, G loss: 0.7054\n",
      "[1762/1762] D loss: 1.3852, G loss: 0.6962\n",
      "train error: \n",
      " D loss: 1.280416, G loss: 1.235081, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 84.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.250742, G loss: 1.385001, D accuracy: 56.4%, cell accuracy: 99.8%, board accuracy: 82.3% \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6976\n",
      "[84/1762] D loss: 1.3906, G loss: 0.6476\n",
      "[164/1762] D loss: 1.0402, G loss: 2.3422\n",
      "[244/1762] D loss: 1.0392, G loss: 2.1979\n",
      "[324/1762] D loss: 1.3864, G loss: 0.6906\n",
      "[404/1762] D loss: 1.0400, G loss: 2.2446\n",
      "[484/1762] D loss: 1.3863, G loss: 0.6969\n",
      "[564/1762] D loss: 1.3861, G loss: 0.6911\n",
      "[644/1762] D loss: 1.3828, G loss: 0.6909\n",
      "[724/1762] D loss: 1.3868, G loss: 0.7001\n",
      "[804/1762] D loss: 1.2703, G loss: 0.7985\n",
      "[884/1762] D loss: 0.6943, G loss: 3.9821\n",
      "[964/1762] D loss: 1.3864, G loss: 0.6896\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6897\n",
      "[1124/1762] D loss: 1.3768, G loss: 0.7069\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6937\n",
      "[1284/1762] D loss: 1.3876, G loss: 0.6993\n",
      "[1364/1762] D loss: 1.3865, G loss: 0.6854\n",
      "[1444/1762] D loss: 1.3862, G loss: 0.6849\n",
      "[1524/1762] D loss: 1.0400, G loss: 2.5779\n",
      "[1604/1762] D loss: 1.3849, G loss: 0.6893\n",
      "[1684/1762] D loss: 1.3866, G loss: 0.6746\n",
      "[1762/1762] D loss: 1.3860, G loss: 0.6842\n",
      "train error: \n",
      " D loss: 1.285003, G loss: 1.307705, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.252636, G loss: 1.468505, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3850, G loss: 0.7235\n",
      "[84/1762] D loss: 1.3861, G loss: 0.6780\n",
      "[164/1762] D loss: 1.3867, G loss: 0.6758\n",
      "[244/1762] D loss: 1.0399, G loss: 2.7766\n",
      "[324/1762] D loss: 1.3864, G loss: 0.6955\n",
      "[404/1762] D loss: 1.0432, G loss: 1.5854\n",
      "[484/1762] D loss: 1.3867, G loss: 0.6877\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6859\n",
      "[644/1762] D loss: 1.3865, G loss: 0.7030\n",
      "[724/1762] D loss: 1.0398, G loss: 2.4598\n",
      "[804/1762] D loss: 1.3817, G loss: 0.6811\n",
      "[884/1762] D loss: 1.4008, G loss: 0.7196\n",
      "[964/1762] D loss: 1.3886, G loss: 0.6478\n",
      "[1044/1762] D loss: 1.3869, G loss: 0.7084\n",
      "[1124/1762] D loss: 0.9120, G loss: 2.2488\n",
      "[1204/1762] D loss: 1.1677, G loss: 2.0957\n",
      "[1284/1762] D loss: 1.4217, G loss: 0.5962\n",
      "[1364/1762] D loss: 1.0370, G loss: 2.0724\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6954\n",
      "[1524/1762] D loss: 1.3957, G loss: 0.6844\n",
      "[1604/1762] D loss: 1.3837, G loss: 0.6972\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.6985\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6967\n",
      "train error: \n",
      " D loss: 1.273085, G loss: 1.105897, D accuracy: 56.0%, cell accuracy: 99.8%, board accuracy: 85.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.243067, G loss: 1.225022, D accuracy: 57.0%, cell accuracy: 99.8%, board accuracy: 83.4% \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3866, G loss: 0.7011\n",
      "[84/1762] D loss: 1.3892, G loss: 0.6713\n",
      "[164/1762] D loss: 1.3865, G loss: 0.7081\n",
      "[244/1762] D loss: 1.0419, G loss: 2.3124\n",
      "[324/1762] D loss: 1.0410, G loss: 3.7227\n",
      "[404/1762] D loss: 1.3873, G loss: 0.7174\n",
      "[484/1762] D loss: 1.0405, G loss: 2.4311\n",
      "[564/1762] D loss: 1.3830, G loss: 0.6886\n",
      "[644/1762] D loss: 1.0403, G loss: 2.3710\n",
      "[724/1762] D loss: 1.3791, G loss: 0.6722\n",
      "[804/1762] D loss: 1.3863, G loss: 0.6770\n",
      "[884/1762] D loss: 1.3859, G loss: 0.6923\n",
      "[964/1762] D loss: 0.6951, G loss: 3.6719\n",
      "[1044/1762] D loss: 1.3859, G loss: 0.7415\n",
      "[1124/1762] D loss: 1.3821, G loss: 0.7454\n",
      "[1204/1762] D loss: 1.3981, G loss: 0.6917\n",
      "[1284/1762] D loss: 1.3710, G loss: 0.7218\n",
      "[1364/1762] D loss: 1.3230, G loss: 0.8096\n",
      "[1444/1762] D loss: 0.8784, G loss: 2.1270\n",
      "[1524/1762] D loss: 1.3781, G loss: 0.7488\n",
      "[1604/1762] D loss: 1.0445, G loss: 2.2753\n",
      "[1684/1762] D loss: 1.3844, G loss: 0.6433\n",
      "[1762/1762] D loss: 1.3878, G loss: 0.6701\n",
      "train error: \n",
      " D loss: 1.253783, G loss: 1.402687, D accuracy: 56.0%, cell accuracy: 99.7%, board accuracy: 83.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.226620, G loss: 1.472156, D accuracy: 57.4%, cell accuracy: 99.6%, board accuracy: 81.8% \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3861, G loss: 0.6940\n",
      "[84/1762] D loss: 1.3855, G loss: 0.7037\n",
      "[164/1762] D loss: 1.3858, G loss: 0.7083\n",
      "[244/1762] D loss: 1.2404, G loss: 1.0370\n",
      "[324/1762] D loss: 1.3778, G loss: 0.7132\n",
      "[404/1762] D loss: 1.4185, G loss: 0.6690\n",
      "[484/1762] D loss: 1.4146, G loss: 0.6228\n",
      "[564/1762] D loss: 1.1736, G loss: 1.0869\n",
      "[644/1762] D loss: 1.3847, G loss: 0.6877\n",
      "[724/1762] D loss: 1.0376, G loss: 2.7308\n",
      "[804/1762] D loss: 1.3846, G loss: 0.6953\n",
      "[884/1762] D loss: 1.3866, G loss: 0.7055\n",
      "[964/1762] D loss: 1.0416, G loss: 2.8951\n",
      "[1044/1762] D loss: 1.3872, G loss: 0.6726\n",
      "[1124/1762] D loss: 1.0398, G loss: 2.5501\n",
      "[1204/1762] D loss: 1.3873, G loss: 0.6658\n",
      "[1284/1762] D loss: 1.3843, G loss: 0.6965\n",
      "[1364/1762] D loss: 1.3731, G loss: 0.6953\n",
      "[1444/1762] D loss: 1.3961, G loss: 0.6190\n",
      "[1524/1762] D loss: 1.0400, G loss: 2.2215\n",
      "[1604/1762] D loss: 1.3785, G loss: 0.7386\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.6926\n",
      "[1762/1762] D loss: 1.3891, G loss: 0.6547\n",
      "train error: \n",
      " D loss: 1.282764, G loss: 1.227690, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 89.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.252049, G loss: 1.374285, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6967\n",
      "[84/1762] D loss: 1.3913, G loss: 0.7370\n",
      "[164/1762] D loss: 1.4009, G loss: 0.7727\n",
      "[244/1762] D loss: 1.0895, G loss: 1.0240\n",
      "[324/1762] D loss: 1.3864, G loss: 0.6983\n",
      "[404/1762] D loss: 1.0402, G loss: 2.5455\n",
      "[484/1762] D loss: 1.3866, G loss: 0.6878\n",
      "[564/1762] D loss: 1.0417, G loss: 2.7800\n",
      "[644/1762] D loss: 1.3868, G loss: 0.7071\n",
      "[724/1762] D loss: 1.3886, G loss: 0.7164\n",
      "[804/1762] D loss: 1.3887, G loss: 0.7170\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6812\n",
      "[964/1762] D loss: 1.0404, G loss: 2.3199\n",
      "[1044/1762] D loss: 1.3878, G loss: 0.7058\n",
      "[1124/1762] D loss: 1.3876, G loss: 0.7049\n",
      "[1204/1762] D loss: 1.0418, G loss: 2.2328\n",
      "[1284/1762] D loss: 1.3866, G loss: 0.6829\n",
      "[1364/1762] D loss: 1.3882, G loss: 0.6764\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6949\n",
      "[1524/1762] D loss: 1.3500, G loss: 0.7080\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6923\n",
      "[1684/1762] D loss: 1.3861, G loss: 0.6713\n",
      "[1762/1762] D loss: 1.3926, G loss: 0.6434\n",
      "train error: \n",
      " D loss: 1.279296, G loss: 1.111501, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 90.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.244482, G loss: 1.243517, D accuracy: 56.1%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2172, G loss: 1.0698\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6976\n",
      "[164/1762] D loss: 1.3865, G loss: 0.6992\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6872\n",
      "[324/1762] D loss: 1.2243, G loss: 0.9206\n",
      "[404/1762] D loss: 1.3924, G loss: 0.7400\n",
      "[484/1762] D loss: 1.3900, G loss: 0.6543\n",
      "[564/1762] D loss: 1.0428, G loss: 2.9618\n",
      "[644/1762] D loss: 1.3864, G loss: 0.7022\n",
      "[724/1762] D loss: 1.0395, G loss: 2.4072\n",
      "[804/1762] D loss: 1.3871, G loss: 0.6770\n",
      "[884/1762] D loss: 1.3864, G loss: 0.7007\n",
      "[964/1762] D loss: 1.3868, G loss: 0.7135\n",
      "[1044/1762] D loss: 0.6932, G loss: 4.8166\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.7015\n",
      "[1204/1762] D loss: 1.3834, G loss: 0.6805\n",
      "[1284/1762] D loss: 1.3868, G loss: 0.7008\n",
      "[1364/1762] D loss: 1.3865, G loss: 0.7027\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6975\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.6951\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.7003\n",
      "[1684/1762] D loss: 1.3879, G loss: 0.7031\n",
      "[1762/1762] D loss: 1.3837, G loss: 0.6911\n",
      "train error: \n",
      " D loss: 1.285127, G loss: 1.246045, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.255422, G loss: 1.424673, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0402, G loss: 2.7291\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6884\n",
      "[164/1762] D loss: 1.3854, G loss: 0.7069\n",
      "[244/1762] D loss: 1.3866, G loss: 0.6865\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6921\n",
      "[404/1762] D loss: 1.3863, G loss: 0.6941\n",
      "[484/1762] D loss: 1.3041, G loss: 0.8768\n",
      "[564/1762] D loss: 1.3794, G loss: 0.6765\n",
      "[644/1762] D loss: 1.3870, G loss: 0.7218\n",
      "[724/1762] D loss: 1.3865, G loss: 0.7068\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6936\n",
      "[884/1762] D loss: 1.3971, G loss: 0.6385\n",
      "[964/1762] D loss: 1.3865, G loss: 0.6776\n",
      "[1044/1762] D loss: 1.3867, G loss: 0.7066\n",
      "[1124/1762] D loss: 1.3862, G loss: 0.7160\n",
      "[1204/1762] D loss: 1.3898, G loss: 0.6602\n",
      "[1284/1762] D loss: 1.3865, G loss: 0.6953\n",
      "[1364/1762] D loss: 1.3847, G loss: 0.6969\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6942\n",
      "[1524/1762] D loss: 1.3877, G loss: 0.7206\n",
      "[1604/1762] D loss: 0.3467, G loss: 7.0447\n",
      "[1684/1762] D loss: 1.0398, G loss: 2.7940\n",
      "[1762/1762] D loss: 1.3874, G loss: 0.7167\n",
      "train error: \n",
      " D loss: 1.285512, G loss: 1.323290, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.256909, G loss: 1.528042, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3871, G loss: 0.6949\n",
      "[84/1762] D loss: 1.3869, G loss: 0.6855\n",
      "[164/1762] D loss: 1.0398, G loss: 2.7962\n",
      "[244/1762] D loss: 1.3865, G loss: 0.6879\n",
      "[324/1762] D loss: 0.6936, G loss: 4.9317\n",
      "[404/1762] D loss: 1.3864, G loss: 0.7047\n",
      "[484/1762] D loss: 1.3868, G loss: 0.7040\n",
      "[564/1762] D loss: 1.3863, G loss: 0.6956\n",
      "[644/1762] D loss: 1.3865, G loss: 0.6960\n",
      "[724/1762] D loss: 1.3865, G loss: 0.6860\n",
      "[804/1762] D loss: 1.3863, G loss: 0.6897\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6940\n",
      "[964/1762] D loss: 1.0398, G loss: 2.7776\n",
      "[1044/1762] D loss: 1.3865, G loss: 0.6855\n",
      "[1124/1762] D loss: 1.0422, G loss: 2.7506\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6959\n",
      "[1284/1762] D loss: 1.3875, G loss: 0.6820\n",
      "[1364/1762] D loss: 1.0408, G loss: 2.7739\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6891\n",
      "[1524/1762] D loss: 1.3497, G loss: 1.0931\n",
      "[1604/1762] D loss: 1.4008, G loss: 0.6265\n",
      "[1684/1762] D loss: 1.3959, G loss: 0.6428\n",
      "[1762/1762] D loss: 1.3889, G loss: 0.6523\n",
      "train error: \n",
      " D loss: 1.287097, G loss: 1.280813, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.259225, G loss: 1.436882, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3892, G loss: 0.7141\n",
      "[84/1762] D loss: 1.3300, G loss: 0.7855\n",
      "[164/1762] D loss: 1.2127, G loss: 0.6755\n",
      "[244/1762] D loss: 1.3863, G loss: 0.7228\n",
      "[324/1762] D loss: 1.3864, G loss: 0.6799\n",
      "[404/1762] D loss: 1.3912, G loss: 0.6391\n",
      "[484/1762] D loss: 1.3876, G loss: 0.6874\n",
      "[564/1762] D loss: 1.3867, G loss: 0.7022\n",
      "[644/1762] D loss: 1.3860, G loss: 0.6953\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6884\n",
      "[804/1762] D loss: 1.4073, G loss: 0.5500\n",
      "[884/1762] D loss: 1.3956, G loss: 0.6711\n",
      "[964/1762] D loss: 1.2943, G loss: 1.0542\n",
      "[1044/1762] D loss: 1.3954, G loss: 0.6731\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.6806\n",
      "[1204/1762] D loss: 1.3873, G loss: 0.7044\n",
      "[1284/1762] D loss: 1.0403, G loss: 2.5560\n",
      "[1364/1762] D loss: 1.0399, G loss: 2.5479\n",
      "[1444/1762] D loss: 1.3901, G loss: 0.7015\n",
      "[1524/1762] D loss: 1.3890, G loss: 0.6956\n",
      "[1604/1762] D loss: 1.3846, G loss: 0.6733\n",
      "[1684/1762] D loss: 1.3868, G loss: 0.6996\n",
      "[1762/1762] D loss: 0.6934, G loss: 4.2400\n",
      "train error: \n",
      " D loss: 1.284801, G loss: 1.214462, D accuracy: 55.4%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.257569, G loss: 1.358481, D accuracy: 56.5%, cell accuracy: 99.8%, board accuracy: 83.6% \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3867, G loss: 0.6862\n",
      "[84/1762] D loss: 1.3911, G loss: 0.6874\n",
      "[164/1762] D loss: 1.0410, G loss: 2.4784\n",
      "[244/1762] D loss: 1.3769, G loss: 0.7006\n",
      "[324/1762] D loss: 1.3868, G loss: 0.6910\n",
      "[404/1762] D loss: 1.3874, G loss: 0.7044\n",
      "[484/1762] D loss: 1.3870, G loss: 0.6703\n",
      "[564/1762] D loss: 1.0407, G loss: 2.5377\n",
      "[644/1762] D loss: 1.3102, G loss: 0.8908\n",
      "[724/1762] D loss: 1.2114, G loss: 1.8270\n",
      "[804/1762] D loss: 1.3865, G loss: 0.6800\n",
      "[884/1762] D loss: 1.2153, G loss: 2.4820\n",
      "[964/1762] D loss: 1.0399, G loss: 2.4712\n",
      "[1044/1762] D loss: 1.3865, G loss: 0.7033\n",
      "[1124/1762] D loss: 0.6934, G loss: 4.2564\n",
      "[1204/1762] D loss: 1.0398, G loss: 2.4792\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6971\n",
      "[1364/1762] D loss: 1.3871, G loss: 0.6873\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6905\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.6924\n",
      "[1604/1762] D loss: 0.6936, G loss: 4.2379\n",
      "[1684/1762] D loss: 1.3861, G loss: 0.6922\n",
      "[1762/1762] D loss: 0.6933, G loss: 4.2995\n",
      "train error: \n",
      " D loss: 1.287631, G loss: 1.223429, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 90.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.257568, G loss: 1.373078, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3873, G loss: 0.7006\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6871\n",
      "[164/1762] D loss: 1.3865, G loss: 0.6981\n",
      "[244/1762] D loss: 1.3864, G loss: 0.6961\n",
      "[324/1762] D loss: 1.3864, G loss: 0.6849\n",
      "[404/1762] D loss: 1.3856, G loss: 0.6956\n",
      "[484/1762] D loss: 1.0398, G loss: 2.4998\n",
      "[564/1762] D loss: 0.6937, G loss: 4.6791\n",
      "[644/1762] D loss: 1.3867, G loss: 0.6864\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6935\n",
      "[804/1762] D loss: 1.3877, G loss: 0.7031\n",
      "[884/1762] D loss: 1.0405, G loss: 2.5105\n",
      "[964/1762] D loss: 1.3863, G loss: 0.6939\n",
      "[1044/1762] D loss: 0.6938, G loss: 4.3992\n",
      "[1124/1762] D loss: 1.0401, G loss: 2.5244\n",
      "[1204/1762] D loss: 1.2070, G loss: 2.5393\n",
      "[1284/1762] D loss: 1.0398, G loss: 2.5281\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6870\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6921\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.6908\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6910\n",
      "[1684/1762] D loss: 1.3865, G loss: 0.7008\n",
      "[1762/1762] D loss: 1.3860, G loss: 0.6934\n",
      "train error: \n",
      " D loss: 1.285261, G loss: 1.244291, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.255462, G loss: 1.422373, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6899\n",
      "[84/1762] D loss: 1.3865, G loss: 0.6788\n",
      "[164/1762] D loss: 1.0398, G loss: 2.5344\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6962\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6912\n",
      "[404/1762] D loss: 1.3893, G loss: 0.7154\n",
      "[484/1762] D loss: 0.6934, G loss: 4.3288\n",
      "[564/1762] D loss: 1.3868, G loss: 0.6869\n",
      "[644/1762] D loss: 1.3864, G loss: 0.6919\n",
      "[724/1762] D loss: 1.3869, G loss: 0.7095\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6865\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6954\n",
      "[964/1762] D loss: 1.3879, G loss: 0.7223\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.6901\n",
      "[1124/1762] D loss: 1.3773, G loss: 0.7054\n",
      "[1204/1762] D loss: 1.3869, G loss: 0.7113\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6919\n",
      "[1364/1762] D loss: 1.0398, G loss: 2.5613\n",
      "[1444/1762] D loss: 1.0401, G loss: 2.5736\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.6951\n",
      "[1604/1762] D loss: 1.3877, G loss: 0.6704\n",
      "[1684/1762] D loss: 1.3868, G loss: 0.7160\n",
      "[1762/1762] D loss: 0.6935, G loss: 4.2815\n",
      "train error: \n",
      " D loss: 1.285652, G loss: 1.228227, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.255673, G loss: 1.402175, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6954\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6967\n",
      "[164/1762] D loss: 1.0412, G loss: 2.5343\n",
      "[244/1762] D loss: 1.3864, G loss: 0.6984\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6912\n",
      "[404/1762] D loss: 1.0399, G loss: 2.5131\n",
      "[484/1762] D loss: 1.3864, G loss: 0.6867\n",
      "[564/1762] D loss: 0.6937, G loss: 4.3370\n",
      "[644/1762] D loss: 1.0399, G loss: 2.5844\n",
      "[724/1762] D loss: 1.0398, G loss: 2.5887\n",
      "[804/1762] D loss: 1.3793, G loss: 0.6880\n",
      "[884/1762] D loss: 1.3851, G loss: 0.6915\n",
      "[964/1762] D loss: 1.3864, G loss: 0.6961\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.6957\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.7000\n",
      "[1204/1762] D loss: 1.0398, G loss: 2.5107\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6890\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6887\n",
      "[1444/1762] D loss: 1.3869, G loss: 0.6795\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.7039\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6897\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6960\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6995\n",
      "train error: \n",
      " D loss: 1.276277, G loss: 1.341161, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.243737, G loss: 1.553739, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0402, G loss: 2.6780\n",
      "[84/1762] D loss: 0.7060, G loss: 4.4480\n",
      "[164/1762] D loss: 1.0434, G loss: 2.5658\n",
      "[244/1762] D loss: 1.3871, G loss: 0.6724\n",
      "[324/1762] D loss: 1.0399, G loss: 2.5389\n",
      "[404/1762] D loss: 1.2013, G loss: 2.5276\n",
      "[484/1762] D loss: 1.3864, G loss: 0.7044\n",
      "[564/1762] D loss: 1.3863, G loss: 0.6927\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6973\n",
      "[724/1762] D loss: 1.3864, G loss: 0.7013\n",
      "[804/1762] D loss: 1.0402, G loss: 2.6860\n",
      "[884/1762] D loss: 1.3952, G loss: 0.6246\n",
      "[964/1762] D loss: 1.0400, G loss: 2.2180\n",
      "[1044/1762] D loss: 0.8609, G loss: 3.7289\n",
      "[1124/1762] D loss: 1.3873, G loss: 0.6700\n",
      "[1204/1762] D loss: 1.3873, G loss: 0.7102\n",
      "[1284/1762] D loss: 1.3871, G loss: 0.7113\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6943\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6930\n",
      "[1524/1762] D loss: 1.0399, G loss: 2.3021\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6950\n",
      "[1684/1762] D loss: 1.3867, G loss: 0.6896\n",
      "[1762/1762] D loss: 1.3875, G loss: 0.7140\n",
      "train error: \n",
      " D loss: 1.286067, G loss: 1.178911, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.256090, G loss: 1.329461, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3868, G loss: 0.6948\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6937\n",
      "[164/1762] D loss: 1.3869, G loss: 0.6718\n",
      "[244/1762] D loss: 1.0399, G loss: 2.3102\n",
      "[324/1762] D loss: 1.0403, G loss: 2.3139\n",
      "[404/1762] D loss: 1.3863, G loss: 0.6899\n",
      "[484/1762] D loss: 1.3863, G loss: 0.7003\n",
      "[564/1762] D loss: 1.3868, G loss: 0.7037\n",
      "[644/1762] D loss: 1.3870, G loss: 0.7162\n",
      "[724/1762] D loss: 1.0399, G loss: 2.3392\n",
      "[804/1762] D loss: 1.0399, G loss: 2.3429\n",
      "[884/1762] D loss: 1.3884, G loss: 0.6621\n",
      "[964/1762] D loss: 1.3863, G loss: 0.6943\n",
      "[1044/1762] D loss: 1.0402, G loss: 2.3484\n",
      "[1124/1762] D loss: 1.0399, G loss: 2.3914\n",
      "[1204/1762] D loss: 1.0397, G loss: 2.3559\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6935\n",
      "[1364/1762] D loss: 1.0399, G loss: 2.3788\n",
      "[1444/1762] D loss: 1.0399, G loss: 2.3822\n",
      "[1524/1762] D loss: 1.3878, G loss: 0.6777\n",
      "[1604/1762] D loss: 1.3866, G loss: 0.7012\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6937\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.6841\n",
      "train error: \n",
      " D loss: 1.286631, G loss: 1.180778, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.256090, G loss: 1.344055, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3896, G loss: 0.6499\n",
      "[84/1762] D loss: 1.0399, G loss: 2.4057\n",
      "[164/1762] D loss: 1.3865, G loss: 0.6856\n",
      "[244/1762] D loss: 1.0400, G loss: 2.4085\n",
      "[324/1762] D loss: 1.3865, G loss: 0.6889\n",
      "[404/1762] D loss: 1.3881, G loss: 0.6807\n",
      "[484/1762] D loss: 1.3864, G loss: 0.6903\n",
      "[564/1762] D loss: 1.3863, G loss: 0.6925\n",
      "[644/1762] D loss: 1.3865, G loss: 0.7003\n",
      "[724/1762] D loss: 1.0399, G loss: 2.4195\n",
      "[804/1762] D loss: 1.3874, G loss: 0.6677\n",
      "[884/1762] D loss: 1.0397, G loss: 4.3065\n",
      "[964/1762] D loss: 1.3863, G loss: 0.6985\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6912\n",
      "[1124/1762] D loss: 1.0397, G loss: 3.0739\n",
      "[1204/1762] D loss: 1.3861, G loss: 0.6858\n",
      "[1284/1762] D loss: 1.3875, G loss: 0.6754\n",
      "[1364/1762] D loss: 1.0400, G loss: 2.4244\n",
      "[1444/1762] D loss: 1.3851, G loss: 0.7037\n",
      "[1524/1762] D loss: 1.3871, G loss: 0.7006\n",
      "[1604/1762] D loss: 1.3860, G loss: 0.6875\n",
      "[1684/1762] D loss: 1.3872, G loss: 0.7111\n",
      "[1762/1762] D loss: 1.3875, G loss: 0.6758\n",
      "train error: \n",
      " D loss: 1.287392, G loss: 1.204203, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.262070, G loss: 1.311263, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6990\n",
      "[84/1762] D loss: 1.3866, G loss: 0.7021\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6948\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6955\n",
      "[324/1762] D loss: 1.3869, G loss: 0.7050\n",
      "[404/1762] D loss: 1.0400, G loss: 2.5006\n",
      "[484/1762] D loss: 1.3875, G loss: 0.6967\n",
      "[564/1762] D loss: 1.3804, G loss: 0.7084\n",
      "[644/1762] D loss: 1.4014, G loss: 0.7097\n",
      "[724/1762] D loss: 1.3881, G loss: 0.6891\n",
      "[804/1762] D loss: 1.3885, G loss: 0.7452\n",
      "[884/1762] D loss: 1.3882, G loss: 0.6701\n",
      "[964/1762] D loss: 1.0404, G loss: 2.3422\n",
      "[1044/1762] D loss: 1.3865, G loss: 0.7061\n",
      "[1124/1762] D loss: 1.0400, G loss: 2.3483\n",
      "[1204/1762] D loss: 1.3816, G loss: 0.8756\n",
      "[1284/1762] D loss: 1.3868, G loss: 0.7113\n",
      "[1364/1762] D loss: 1.0404, G loss: 2.4704\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6871\n",
      "[1524/1762] D loss: 1.0399, G loss: 2.4878\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6919\n",
      "[1684/1762] D loss: 1.3878, G loss: 0.6768\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6870\n",
      "train error: \n",
      " D loss: 1.287022, G loss: 1.223270, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.257394, G loss: 1.396049, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.7022\n",
      "[84/1762] D loss: 1.3871, G loss: 0.7119\n",
      "[164/1762] D loss: 1.0400, G loss: 2.3869\n",
      "[244/1762] D loss: 1.3864, G loss: 0.6999\n",
      "[324/1762] D loss: 1.3858, G loss: 0.6914\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6849\n",
      "[484/1762] D loss: 1.3863, G loss: 0.6888\n",
      "[564/1762] D loss: 1.3863, G loss: 0.6967\n",
      "[644/1762] D loss: 1.0399, G loss: 2.4294\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6908\n",
      "[804/1762] D loss: 1.2152, G loss: 5.7642\n",
      "[884/1762] D loss: 1.2075, G loss: 3.0306\n",
      "[964/1762] D loss: 1.3865, G loss: 0.6718\n",
      "[1044/1762] D loss: 0.6929, G loss: 4.3308\n",
      "[1124/1762] D loss: 1.3935, G loss: 0.6224\n",
      "[1204/1762] D loss: 1.3911, G loss: 0.7346\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.7031\n",
      "[1364/1762] D loss: 1.3865, G loss: 0.7012\n",
      "[1444/1762] D loss: 1.3877, G loss: 0.7077\n",
      "[1524/1762] D loss: 1.0407, G loss: 2.0020\n",
      "[1604/1762] D loss: 1.3884, G loss: 0.6663\n",
      "[1684/1762] D loss: 1.0433, G loss: 1.9842\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6920\n",
      "train error: \n",
      " D loss: 1.285254, G loss: 1.089622, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 90.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.255654, G loss: 1.217208, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6939\n",
      "[84/1762] D loss: 1.3865, G loss: 0.6875\n",
      "[164/1762] D loss: 1.3773, G loss: 0.7171\n",
      "[244/1762] D loss: 1.0404, G loss: 2.0273\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6950\n",
      "[404/1762] D loss: 1.3865, G loss: 0.6837\n",
      "[484/1762] D loss: 1.3875, G loss: 0.6777\n",
      "[564/1762] D loss: 1.3863, G loss: 0.6929\n",
      "[644/1762] D loss: 1.3864, G loss: 0.6989\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6912\n",
      "[804/1762] D loss: 1.3863, G loss: 0.6919\n",
      "[884/1762] D loss: 1.0395, G loss: 2.1084\n",
      "[964/1762] D loss: 1.3863, G loss: 0.6892\n",
      "[1044/1762] D loss: 1.0402, G loss: 2.1243\n",
      "[1124/1762] D loss: 1.0404, G loss: 2.1289\n",
      "[1204/1762] D loss: 1.3865, G loss: 0.6812\n",
      "[1284/1762] D loss: 1.3866, G loss: 0.6826\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6989\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6894\n",
      "[1524/1762] D loss: 1.0401, G loss: 2.1528\n",
      "[1604/1762] D loss: 1.0401, G loss: 2.1634\n",
      "[1684/1762] D loss: 1.3870, G loss: 0.6863\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6968\n",
      "train error: \n",
      " D loss: 1.289427, G loss: 1.134486, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 88.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.262178, G loss: 1.270947, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3891, G loss: 0.6952\n",
      "[84/1762] D loss: 1.3868, G loss: 0.7029\n",
      "[164/1762] D loss: 1.3868, G loss: 0.7003\n",
      "[244/1762] D loss: 1.0411, G loss: 1.9804\n",
      "[324/1762] D loss: 1.3868, G loss: 0.6711\n",
      "[404/1762] D loss: 1.3862, G loss: 0.6942\n",
      "[484/1762] D loss: 1.3864, G loss: 0.6983\n",
      "[564/1762] D loss: 1.3865, G loss: 0.6818\n",
      "[644/1762] D loss: 1.3868, G loss: 0.6731\n",
      "[724/1762] D loss: 1.3871, G loss: 0.6701\n",
      "[804/1762] D loss: 1.3869, G loss: 0.6852\n",
      "[884/1762] D loss: 1.3851, G loss: 0.6977\n",
      "[964/1762] D loss: 1.0400, G loss: 2.1874\n",
      "[1044/1762] D loss: 1.3869, G loss: 0.7095\n",
      "[1124/1762] D loss: 1.3866, G loss: 0.6819\n",
      "[1204/1762] D loss: 1.3847, G loss: 0.7015\n",
      "[1284/1762] D loss: 1.0495, G loss: 2.2837\n",
      "[1364/1762] D loss: 0.5220, G loss: 7.7796\n",
      "[1444/1762] D loss: 1.3921, G loss: 0.7143\n",
      "[1524/1762] D loss: 1.3862, G loss: 0.7023\n",
      "[1604/1762] D loss: 1.3880, G loss: 0.6800\n",
      "[1684/1762] D loss: 1.0423, G loss: 1.6766\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.7054\n",
      "train error: \n",
      " D loss: 1.297635, G loss: 1.022304, D accuracy: 52.3%, cell accuracy: 99.7%, board accuracy: 65.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.272141, G loss: 1.121315, D accuracy: 53.6%, cell accuracy: 99.7%, board accuracy: 66.6% \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3845, G loss: 0.7061\n",
      "[84/1762] D loss: 1.3937, G loss: 0.7375\n",
      "[164/1762] D loss: 1.3811, G loss: 0.6971\n",
      "[244/1762] D loss: 1.3862, G loss: 0.6863\n",
      "[324/1762] D loss: 1.3871, G loss: 0.6949\n",
      "[404/1762] D loss: 1.0408, G loss: 2.1454\n",
      "[484/1762] D loss: 1.3884, G loss: 0.7087\n",
      "[564/1762] D loss: 1.3878, G loss: 0.6815\n",
      "[644/1762] D loss: 1.3872, G loss: 0.7206\n",
      "[724/1762] D loss: 1.3908, G loss: 0.7147\n",
      "[804/1762] D loss: 1.3861, G loss: 0.6997\n",
      "[884/1762] D loss: 1.3868, G loss: 0.6883\n",
      "[964/1762] D loss: 1.3868, G loss: 0.6986\n",
      "[1044/1762] D loss: 1.3865, G loss: 0.7001\n",
      "[1124/1762] D loss: 1.3869, G loss: 0.6933\n",
      "[1204/1762] D loss: 1.3867, G loss: 0.6829\n",
      "[1284/1762] D loss: 1.4305, G loss: 1.4840\n",
      "[1364/1762] D loss: 1.3740, G loss: 0.6069\n",
      "[1444/1762] D loss: 1.3658, G loss: 0.7343\n",
      "[1524/1762] D loss: 1.3805, G loss: 0.6726\n",
      "[1604/1762] D loss: 1.3895, G loss: 0.6807\n",
      "[1684/1762] D loss: 1.3921, G loss: 0.6215\n",
      "[1762/1762] D loss: 1.3907, G loss: 0.7168\n",
      "train error: \n",
      " D loss: 1.286778, G loss: 0.986762, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.256655, G loss: 1.105443, D accuracy: 55.9%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3890, G loss: 0.6668\n",
      "[84/1762] D loss: 1.0418, G loss: 1.8338\n",
      "[164/1762] D loss: 1.0428, G loss: 1.8213\n",
      "[244/1762] D loss: 1.3867, G loss: 0.7015\n",
      "[324/1762] D loss: 1.3214, G loss: 0.7848\n",
      "[404/1762] D loss: 1.3870, G loss: 0.6711\n",
      "[484/1762] D loss: 1.0404, G loss: 1.9626\n",
      "[564/1762] D loss: 1.0404, G loss: 1.9730\n",
      "[644/1762] D loss: 1.0411, G loss: 1.9394\n",
      "[724/1762] D loss: 1.3896, G loss: 0.6735\n",
      "[804/1762] D loss: 1.3870, G loss: 0.6929\n",
      "[884/1762] D loss: 1.4068, G loss: 0.5977\n",
      "[964/1762] D loss: 1.0406, G loss: 2.1299\n",
      "[1044/1762] D loss: 1.3866, G loss: 0.6769\n",
      "[1124/1762] D loss: 1.2210, G loss: 2.1817\n",
      "[1204/1762] D loss: 1.0401, G loss: 2.1997\n",
      "[1284/1762] D loss: 1.3886, G loss: 0.6731\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6937\n",
      "[1444/1762] D loss: 0.6937, G loss: 4.2515\n",
      "[1524/1762] D loss: 1.3867, G loss: 0.6968\n",
      "[1604/1762] D loss: 1.0401, G loss: 2.1695\n",
      "[1684/1762] D loss: 1.3876, G loss: 0.6866\n",
      "[1762/1762] D loss: 0.6937, G loss: 3.7642\n",
      "train error: \n",
      " D loss: 1.289847, G loss: 1.199947, D accuracy: 54.1%, cell accuracy: 99.9%, board accuracy: 91.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.256272, G loss: 1.314959, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3862, G loss: 0.6916\n",
      "[84/1762] D loss: 1.3923, G loss: 0.7600\n",
      "[164/1762] D loss: 1.0416, G loss: 1.9514\n",
      "[244/1762] D loss: 0.9938, G loss: 2.0147\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6916\n",
      "[404/1762] D loss: 1.0407, G loss: 2.0331\n",
      "[484/1762] D loss: 1.3867, G loss: 0.7129\n",
      "[564/1762] D loss: 1.3496, G loss: 0.7368\n",
      "[644/1762] D loss: 1.3873, G loss: 0.7182\n",
      "[724/1762] D loss: 1.3879, G loss: 0.6977\n",
      "[804/1762] D loss: 1.0414, G loss: 2.0658\n",
      "[884/1762] D loss: 1.3533, G loss: 0.7514\n",
      "[964/1762] D loss: 1.3866, G loss: 0.7106\n",
      "[1044/1762] D loss: 1.3865, G loss: 0.6836\n",
      "[1124/1762] D loss: 1.3862, G loss: 0.6867\n",
      "[1204/1762] D loss: 1.3778, G loss: 0.6782\n",
      "[1284/1762] D loss: 1.2679, G loss: 1.0000\n",
      "[1364/1762] D loss: 1.4402, G loss: 0.6438\n",
      "[1444/1762] D loss: 1.4218, G loss: 0.5878\n",
      "[1524/1762] D loss: 1.0405, G loss: 2.5307\n",
      "[1604/1762] D loss: 1.0406, G loss: 2.0932\n",
      "[1684/1762] D loss: 1.0399, G loss: 2.4750\n",
      "[1762/1762] D loss: 1.3875, G loss: 0.6809\n",
      "train error: \n",
      " D loss: 1.287804, G loss: 1.105345, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.260009, G loss: 1.298049, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0449, G loss: 2.1677\n",
      "[84/1762] D loss: 1.3878, G loss: 0.6788\n",
      "[164/1762] D loss: 1.3868, G loss: 0.6958\n",
      "[244/1762] D loss: 1.3867, G loss: 0.6914\n",
      "[324/1762] D loss: 1.3899, G loss: 0.6741\n",
      "[404/1762] D loss: 1.3897, G loss: 0.6901\n",
      "[484/1762] D loss: 1.3863, G loss: 0.6905\n",
      "[564/1762] D loss: 1.3872, G loss: 0.7107\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6914\n",
      "[724/1762] D loss: 1.3886, G loss: 0.6559\n",
      "[804/1762] D loss: 1.3886, G loss: 0.6773\n",
      "[884/1762] D loss: 1.3936, G loss: 0.6446\n",
      "[964/1762] D loss: 1.0400, G loss: 2.1932\n",
      "[1044/1762] D loss: 1.0402, G loss: 2.2128\n",
      "[1124/1762] D loss: 1.3885, G loss: 0.6760\n",
      "[1204/1762] D loss: 1.3877, G loss: 0.6920\n",
      "[1284/1762] D loss: 1.0403, G loss: 2.1779\n",
      "[1364/1762] D loss: 1.3871, G loss: 0.6867\n",
      "[1444/1762] D loss: 1.0395, G loss: 2.1968\n",
      "[1524/1762] D loss: 1.3886, G loss: 0.6617\n",
      "[1604/1762] D loss: 1.0412, G loss: 2.2073\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6912\n",
      "[1762/1762] D loss: 1.3862, G loss: 0.6812\n",
      "train error: \n",
      " D loss: 1.286929, G loss: 1.142054, D accuracy: 54.0%, cell accuracy: 99.9%, board accuracy: 91.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.255034, G loss: 1.314798, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3699, G loss: 0.7098\n",
      "[84/1762] D loss: 1.3905, G loss: 0.6997\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6929\n",
      "[244/1762] D loss: 1.3557, G loss: 0.7184\n",
      "[324/1762] D loss: 1.3929, G loss: 0.6435\n",
      "[404/1762] D loss: 1.3867, G loss: 0.6974\n",
      "[484/1762] D loss: 1.3915, G loss: 0.6505\n",
      "[564/1762] D loss: 1.0420, G loss: 2.2351\n",
      "[644/1762] D loss: 1.3864, G loss: 0.6966\n",
      "[724/1762] D loss: 1.3855, G loss: 0.6826\n",
      "[804/1762] D loss: 1.3863, G loss: 0.6941\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6943\n",
      "[964/1762] D loss: 1.3863, G loss: 0.6953\n",
      "[1044/1762] D loss: 1.0405, G loss: 2.2536\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6943\n",
      "[1204/1762] D loss: 1.0400, G loss: 2.3416\n",
      "[1284/1762] D loss: 1.0395, G loss: 2.2883\n",
      "[1364/1762] D loss: 1.3848, G loss: 0.6853\n",
      "[1444/1762] D loss: 0.6994, G loss: 4.8523\n",
      "[1524/1762] D loss: 1.3706, G loss: 0.7362\n",
      "[1604/1762] D loss: 1.3025, G loss: 1.0100\n",
      "[1684/1762] D loss: 1.3971, G loss: 0.6636\n",
      "[1762/1762] D loss: 1.3989, G loss: 0.6189\n",
      "train error: \n",
      " D loss: 1.291236, G loss: 1.037228, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 89.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.262713, G loss: 1.145722, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3891, G loss: 0.6667\n",
      "[84/1762] D loss: 1.3869, G loss: 0.7053\n",
      "[164/1762] D loss: 1.3879, G loss: 0.6726\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6949\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6918\n",
      "[404/1762] D loss: 1.0404, G loss: 2.0569\n",
      "[484/1762] D loss: 1.3868, G loss: 0.6940\n",
      "[564/1762] D loss: 1.3865, G loss: 0.6930\n",
      "[644/1762] D loss: 1.3850, G loss: 0.6877\n",
      "[724/1762] D loss: 1.0408, G loss: 2.1611\n",
      "[804/1762] D loss: 1.3872, G loss: 0.6781\n",
      "[884/1762] D loss: 1.3870, G loss: 0.7125\n",
      "[964/1762] D loss: 1.3862, G loss: 0.6866\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6919\n",
      "[1124/1762] D loss: 1.3869, G loss: 0.7025\n",
      "[1204/1762] D loss: 1.3865, G loss: 0.7017\n",
      "[1284/1762] D loss: 1.3867, G loss: 0.6953\n",
      "[1364/1762] D loss: 1.3865, G loss: 0.6878\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6912\n",
      "[1524/1762] D loss: 1.3867, G loss: 0.6961\n",
      "[1604/1762] D loss: 1.3853, G loss: 0.6889\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6898\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6906\n",
      "train error: \n",
      " D loss: 1.287599, G loss: 1.139152, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 91.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.259163, G loss: 1.260960, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6937, G loss: 3.7738\n",
      "[84/1762] D loss: 1.0399, G loss: 2.2734\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6913\n",
      "[244/1762] D loss: 1.0401, G loss: 2.2195\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6915\n",
      "[404/1762] D loss: 1.3865, G loss: 0.6870\n",
      "[484/1762] D loss: 1.3875, G loss: 0.6955\n",
      "[564/1762] D loss: 1.3865, G loss: 0.6879\n",
      "[644/1762] D loss: 1.3879, G loss: 0.6739\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6916\n",
      "[804/1762] D loss: 1.3772, G loss: 0.7116\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6932\n",
      "[964/1762] D loss: 1.3864, G loss: 0.6928\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6931\n",
      "[1124/1762] D loss: 1.0400, G loss: 2.2924\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6926\n",
      "[1284/1762] D loss: 1.3866, G loss: 0.6989\n",
      "[1364/1762] D loss: 1.3866, G loss: 0.6944\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6927\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.6931\n",
      "[1604/1762] D loss: 1.0399, G loss: 2.2480\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6911\n",
      "[1762/1762] D loss: 0.6955, G loss: 3.8344\n",
      "train error: \n",
      " D loss: 1.286231, G loss: 1.168748, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.257324, G loss: 1.327154, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6982\n",
      "[84/1762] D loss: 1.3811, G loss: 0.7031\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6916\n",
      "[244/1762] D loss: 1.3867, G loss: 0.6957\n",
      "[324/1762] D loss: 1.3864, G loss: 0.6912\n",
      "[404/1762] D loss: 1.3862, G loss: 0.6882\n",
      "[484/1762] D loss: 1.3863, G loss: 0.6923\n",
      "[564/1762] D loss: 1.3865, G loss: 0.6937\n",
      "[644/1762] D loss: 1.0399, G loss: 2.3529\n",
      "[724/1762] D loss: 1.3874, G loss: 0.6776\n",
      "[804/1762] D loss: 1.0401, G loss: 2.3117\n",
      "[884/1762] D loss: 1.3875, G loss: 0.6693\n",
      "[964/1762] D loss: 1.3863, G loss: 0.6942\n",
      "[1044/1762] D loss: 1.0400, G loss: 2.3390\n",
      "[1124/1762] D loss: 1.3861, G loss: 0.6831\n",
      "[1204/1762] D loss: 1.3866, G loss: 0.7038\n",
      "[1284/1762] D loss: 1.3872, G loss: 0.7121\n",
      "[1364/1762] D loss: 1.0399, G loss: 2.3243\n",
      "[1444/1762] D loss: 1.0402, G loss: 2.3818\n",
      "[1524/1762] D loss: 1.0400, G loss: 2.3771\n",
      "[1604/1762] D loss: 1.3856, G loss: 0.7012\n",
      "[1684/1762] D loss: 1.3865, G loss: 0.6941\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6990\n",
      "train error: \n",
      " D loss: 1.286551, G loss: 1.186811, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.258849, G loss: 1.357253, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6904\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6888\n",
      "[164/1762] D loss: 1.3868, G loss: 0.7050\n",
      "[244/1762] D loss: 1.0399, G loss: 2.4002\n",
      "[324/1762] D loss: 1.0393, G loss: 2.3734\n",
      "[404/1762] D loss: 1.3863, G loss: 0.6905\n",
      "[484/1762] D loss: 1.0401, G loss: 2.4611\n",
      "[564/1762] D loss: 1.0398, G loss: 2.4569\n",
      "[644/1762] D loss: 1.3865, G loss: 0.6954\n",
      "[724/1762] D loss: 1.0399, G loss: 2.4377\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6950\n",
      "[884/1762] D loss: 1.3861, G loss: 0.6866\n",
      "[964/1762] D loss: 1.3880, G loss: 0.6774\n",
      "[1044/1762] D loss: 1.3669, G loss: 0.6634\n",
      "[1124/1762] D loss: 1.1431, G loss: 22.3339\n",
      "[1204/1762] D loss: 1.1136, G loss: 1.0284\n",
      "[1284/1762] D loss: 1.3945, G loss: 0.6249\n",
      "[1364/1762] D loss: 1.2029, G loss: 1.5530\n",
      "[1444/1762] D loss: 1.3873, G loss: 0.6630\n",
      "[1524/1762] D loss: 1.3869, G loss: 0.6686\n",
      "[1604/1762] D loss: 1.3869, G loss: 0.6866\n",
      "[1684/1762] D loss: 1.0401, G loss: 2.4202\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.6782\n",
      "train error: \n",
      " D loss: 1.281016, G loss: 1.172108, D accuracy: 56.7%, cell accuracy: 99.8%, board accuracy: 90.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.257750, G loss: 1.265436, D accuracy: 56.7%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2357, G loss: 0.6697\n",
      "[84/1762] D loss: 1.3870, G loss: 0.7043\n",
      "[164/1762] D loss: 1.2230, G loss: 0.6980\n",
      "[244/1762] D loss: 1.3865, G loss: 0.6946\n",
      "[324/1762] D loss: 0.8592, G loss: 4.8304\n",
      "[404/1762] D loss: 1.0044, G loss: 2.6122\n",
      "[484/1762] D loss: 1.2509, G loss: 0.8901\n",
      "[564/1762] D loss: 1.3933, G loss: 0.6995\n",
      "[644/1762] D loss: 1.3927, G loss: 0.7161\n",
      "[724/1762] D loss: 1.3876, G loss: 0.6792\n",
      "[804/1762] D loss: 1.3902, G loss: 0.6747\n",
      "[884/1762] D loss: 1.3954, G loss: 0.6196\n",
      "[964/1762] D loss: 0.8015, G loss: 2.9975\n",
      "[1044/1762] D loss: 1.3937, G loss: 0.6453\n",
      "[1124/1762] D loss: 1.3868, G loss: 0.6887\n",
      "[1204/1762] D loss: 0.8603, G loss: 4.1645\n",
      "[1284/1762] D loss: 1.3895, G loss: 0.6473\n",
      "[1364/1762] D loss: 1.2139, G loss: 1.4668\n",
      "[1444/1762] D loss: 1.3889, G loss: 0.6863\n",
      "[1524/1762] D loss: 1.3962, G loss: 0.6146\n",
      "[1604/1762] D loss: 1.2810, G loss: 0.9329\n",
      "[1684/1762] D loss: 1.3772, G loss: 0.7119\n",
      "[1762/1762] D loss: 0.6942, G loss: 3.6681\n",
      "train error: \n",
      " D loss: 1.270841, G loss: 1.205420, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 86.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.241222, G loss: 1.325895, D accuracy: 56.4%, cell accuracy: 99.7%, board accuracy: 82.5% \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3455, G loss: 0.7419\n",
      "[84/1762] D loss: 1.0402, G loss: 2.2118\n",
      "[164/1762] D loss: 1.3865, G loss: 0.6929\n",
      "[244/1762] D loss: 1.0400, G loss: 2.2149\n",
      "[324/1762] D loss: 1.3877, G loss: 0.6697\n",
      "[404/1762] D loss: 1.0392, G loss: 2.1987\n",
      "[484/1762] D loss: 1.3871, G loss: 0.7036\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6912\n",
      "[644/1762] D loss: 1.3882, G loss: 0.6933\n",
      "[724/1762] D loss: 1.0402, G loss: 2.2203\n",
      "[804/1762] D loss: 1.3865, G loss: 0.6806\n",
      "[884/1762] D loss: 1.0402, G loss: 2.2273\n",
      "[964/1762] D loss: 1.3867, G loss: 0.6871\n",
      "[1044/1762] D loss: 1.3869, G loss: 0.6776\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.6838\n",
      "[1204/1762] D loss: 1.0352, G loss: 2.2526\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6962\n",
      "[1364/1762] D loss: 1.0400, G loss: 2.2556\n",
      "[1444/1762] D loss: 1.0405, G loss: 2.2676\n",
      "[1524/1762] D loss: 1.0401, G loss: 2.2572\n",
      "[1604/1762] D loss: 1.2377, G loss: 1.1400\n",
      "[1684/1762] D loss: 1.3869, G loss: 0.6726\n",
      "[1762/1762] D loss: 1.3873, G loss: 0.7024\n",
      "train error: \n",
      " D loss: 1.275103, G loss: 1.254203, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.245327, G loss: 1.426008, D accuracy: 55.2%, cell accuracy: 99.7%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3865, G loss: 0.6858\n",
      "[84/1762] D loss: 1.0403, G loss: 2.2495\n",
      "[164/1762] D loss: 1.0400, G loss: 2.2526\n",
      "[244/1762] D loss: 1.3868, G loss: 0.6830\n",
      "[324/1762] D loss: 1.3854, G loss: 0.6949\n",
      "[404/1762] D loss: 1.3870, G loss: 0.6883\n",
      "[484/1762] D loss: 1.2587, G loss: 1.0512\n",
      "[564/1762] D loss: 1.3881, G loss: 0.6501\n",
      "[644/1762] D loss: 1.3905, G loss: 0.6345\n",
      "[724/1762] D loss: 1.3868, G loss: 0.6817\n",
      "[804/1762] D loss: 1.3880, G loss: 0.6679\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6986\n",
      "[964/1762] D loss: 1.3867, G loss: 0.7034\n",
      "[1044/1762] D loss: 1.0466, G loss: 6.3271\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.6950\n",
      "[1204/1762] D loss: 1.3873, G loss: 0.6728\n",
      "[1284/1762] D loss: 1.3869, G loss: 0.7051\n",
      "[1364/1762] D loss: 1.3861, G loss: 0.6931\n",
      "[1444/1762] D loss: 1.3873, G loss: 0.6758\n",
      "[1524/1762] D loss: 1.3867, G loss: 0.7027\n",
      "[1604/1762] D loss: 1.3866, G loss: 0.7034\n",
      "[1684/1762] D loss: 1.3874, G loss: 0.6912\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6946\n",
      "train error: \n",
      " D loss: 1.282939, G loss: 1.207991, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 91.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.255564, G loss: 1.268474, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6984\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6947\n",
      "[164/1762] D loss: 1.2695, G loss: 1.0533\n",
      "[244/1762] D loss: 0.6943, G loss: 3.9174\n",
      "[324/1762] D loss: 1.3632, G loss: 0.7354\n",
      "[404/1762] D loss: 1.3888, G loss: 0.6551\n",
      "[484/1762] D loss: 1.3825, G loss: 0.7040\n",
      "[564/1762] D loss: 1.4038, G loss: 0.7677\n",
      "[644/1762] D loss: 1.0479, G loss: 2.2977\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6866\n",
      "[804/1762] D loss: 1.3894, G loss: 0.7184\n",
      "[884/1762] D loss: 1.3861, G loss: 0.6842\n",
      "[964/1762] D loss: 1.0411, G loss: 2.5704\n",
      "[1044/1762] D loss: 1.3854, G loss: 0.6833\n",
      "[1124/1762] D loss: 1.0399, G loss: 2.6328\n",
      "[1204/1762] D loss: 1.3887, G loss: 0.7144\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6909\n",
      "[1364/1762] D loss: 1.3854, G loss: 0.6873\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6867\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.6932\n",
      "[1604/1762] D loss: 1.3849, G loss: 0.7022\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6930\n",
      "[1762/1762] D loss: 1.3873, G loss: 0.7080\n",
      "train error: \n",
      " D loss: 1.285097, G loss: 1.258938, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.258609, G loss: 1.409433, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6936\n",
      "[84/1762] D loss: 1.3865, G loss: 0.6891\n",
      "[164/1762] D loss: 1.3875, G loss: 0.7112\n",
      "[244/1762] D loss: 1.3867, G loss: 0.6911\n",
      "[324/1762] D loss: 1.3546, G loss: 0.7690\n",
      "[404/1762] D loss: 1.3865, G loss: 0.6872\n",
      "[484/1762] D loss: 1.0398, G loss: 2.5330\n",
      "[564/1762] D loss: 1.3872, G loss: 0.6749\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6836\n",
      "[724/1762] D loss: 1.3869, G loss: 0.6632\n",
      "[804/1762] D loss: 1.3866, G loss: 0.6806\n",
      "[884/1762] D loss: 1.3885, G loss: 0.6760\n",
      "[964/1762] D loss: 1.3877, G loss: 0.7043\n",
      "[1044/1762] D loss: 1.3873, G loss: 0.6807\n",
      "[1124/1762] D loss: 1.3866, G loss: 0.6902\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6911\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6878\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6915\n",
      "[1444/1762] D loss: 1.3859, G loss: 0.6876\n",
      "[1524/1762] D loss: 1.0399, G loss: 2.7504\n",
      "[1604/1762] D loss: 1.3870, G loss: 0.7005\n",
      "[1684/1762] D loss: 1.0400, G loss: 2.6730\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6972\n",
      "train error: \n",
      " D loss: 1.288836, G loss: 1.281885, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.259122, G loss: 1.462055, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.7015\n",
      "[84/1762] D loss: 1.0398, G loss: 2.7006\n",
      "[164/1762] D loss: 1.3881, G loss: 0.7054\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6945\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6942\n",
      "[404/1762] D loss: 1.3868, G loss: 0.6947\n",
      "[484/1762] D loss: 1.0409, G loss: 2.8160\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6954\n",
      "[644/1762] D loss: 1.3867, G loss: 0.6835\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6921\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6859\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6964\n",
      "[964/1762] D loss: 1.3872, G loss: 0.7176\n",
      "[1044/1762] D loss: 1.3867, G loss: 0.6769\n",
      "[1124/1762] D loss: 1.0399, G loss: 2.7272\n",
      "[1204/1762] D loss: 1.3865, G loss: 0.6981\n",
      "[1284/1762] D loss: 1.0400, G loss: 4.8103\n",
      "[1364/1762] D loss: 1.0405, G loss: 2.6501\n",
      "[1444/1762] D loss: 1.2166, G loss: 1.6086\n",
      "[1524/1762] D loss: 1.3923, G loss: 0.6431\n",
      "[1604/1762] D loss: 1.3881, G loss: 0.6687\n",
      "[1684/1762] D loss: 1.3878, G loss: 0.7103\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6857\n",
      "train error: \n",
      " D loss: 1.282873, G loss: 1.365738, D accuracy: 54.0%, cell accuracy: 99.9%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.254885, G loss: 1.482996, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6857\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6879\n",
      "[164/1762] D loss: 1.3866, G loss: 0.6864\n",
      "[244/1762] D loss: 1.3864, G loss: 0.6898\n",
      "[324/1762] D loss: 0.6933, G loss: 4.6109\n",
      "[404/1762] D loss: 1.3866, G loss: 0.6863\n",
      "[484/1762] D loss: 1.0398, G loss: 2.6510\n",
      "[564/1762] D loss: 1.3863, G loss: 0.6896\n",
      "[644/1762] D loss: 1.0398, G loss: 2.6161\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6953\n",
      "[804/1762] D loss: 1.3863, G loss: 0.6918\n",
      "[884/1762] D loss: 0.6934, G loss: 4.5259\n",
      "[964/1762] D loss: 1.3864, G loss: 0.6880\n",
      "[1044/1762] D loss: 1.0403, G loss: 2.6250\n",
      "[1124/1762] D loss: 1.0405, G loss: 2.6054\n",
      "[1204/1762] D loss: 1.0640, G loss: 1.3452\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6884\n",
      "[1364/1762] D loss: 1.0396, G loss: 2.6720\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6936\n",
      "[1524/1762] D loss: 1.3867, G loss: 0.6827\n",
      "[1604/1762] D loss: 1.3887, G loss: 0.6593\n",
      "[1684/1762] D loss: 1.3867, G loss: 0.6970\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6910\n",
      "train error: \n",
      " D loss: 1.287145, G loss: 1.253291, D accuracy: 54.2%, cell accuracy: 99.9%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.258394, G loss: 1.376876, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6918\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6996\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6932\n",
      "[244/1762] D loss: 1.3866, G loss: 0.6961\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6916\n",
      "[404/1762] D loss: 1.3863, G loss: 0.6942\n",
      "[484/1762] D loss: 1.3863, G loss: 0.6905\n",
      "[564/1762] D loss: 1.0398, G loss: 2.5742\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6956\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6942\n",
      "[804/1762] D loss: 1.3862, G loss: 0.6975\n",
      "[884/1762] D loss: 1.3872, G loss: 0.6934\n",
      "[964/1762] D loss: 1.2138, G loss: 2.8046\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6856\n",
      "[1124/1762] D loss: 1.3822, G loss: 0.6748\n",
      "[1204/1762] D loss: 1.3865, G loss: 0.6885\n",
      "[1284/1762] D loss: 1.0397, G loss: 3.4780\n",
      "[1364/1762] D loss: 1.3597, G loss: 0.7304\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6914\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.6905\n",
      "[1604/1762] D loss: 1.0422, G loss: 2.4935\n",
      "[1684/1762] D loss: 1.0385, G loss: 2.4643\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6922\n",
      "train error: \n",
      " D loss: 1.287476, G loss: 1.213628, D accuracy: 54.2%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.263078, G loss: 1.269855, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0398, G loss: 2.4705\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6919\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6925\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6888\n",
      "[324/1762] D loss: 1.3867, G loss: 0.7034\n",
      "[404/1762] D loss: 1.0411, G loss: 2.4981\n",
      "[484/1762] D loss: 1.3864, G loss: 0.6957\n",
      "[564/1762] D loss: 1.0401, G loss: 2.4938\n",
      "[644/1762] D loss: 1.3864, G loss: 0.6818\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6860\n",
      "[804/1762] D loss: 1.0400, G loss: 2.4618\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6885\n",
      "[964/1762] D loss: 1.0400, G loss: 2.4751\n",
      "[1044/1762] D loss: 1.2100, G loss: 2.0147\n",
      "[1124/1762] D loss: 1.4279, G loss: 0.7990\n",
      "[1204/1762] D loss: 1.3880, G loss: 0.6646\n",
      "[1284/1762] D loss: 1.0433, G loss: 1.9449\n",
      "[1364/1762] D loss: 1.0410, G loss: 2.3775\n",
      "[1444/1762] D loss: 1.0403, G loss: 2.1066\n",
      "[1524/1762] D loss: 1.3997, G loss: 0.7529\n",
      "[1604/1762] D loss: 1.3917, G loss: 0.7514\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6906\n",
      "[1762/1762] D loss: 1.4078, G loss: 0.8197\n",
      "train error: \n",
      " D loss: 1.286564, G loss: 1.169078, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.257350, G loss: 1.314572, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3460, G loss: 0.8143\n",
      "[84/1762] D loss: 1.3799, G loss: 0.7075\n",
      "[164/1762] D loss: 1.3826, G loss: 0.7042\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6951\n",
      "[324/1762] D loss: 1.0426, G loss: 2.1795\n",
      "[404/1762] D loss: 0.6942, G loss: 3.4932\n",
      "[484/1762] D loss: 1.0400, G loss: 2.2501\n",
      "[564/1762] D loss: 1.3867, G loss: 0.6850\n",
      "[644/1762] D loss: 1.0400, G loss: 2.2261\n",
      "[724/1762] D loss: 1.3836, G loss: 0.7071\n",
      "[804/1762] D loss: 1.3868, G loss: 0.7648\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6977\n",
      "[964/1762] D loss: 1.4439, G loss: 0.7994\n",
      "[1044/1762] D loss: 0.7476, G loss: 4.9014\n",
      "[1124/1762] D loss: 1.5124, G loss: 0.9468\n",
      "[1204/1762] D loss: 1.3833, G loss: 0.6752\n",
      "[1284/1762] D loss: 1.0455, G loss: 1.4016\n",
      "[1364/1762] D loss: 1.2906, G loss: 0.7584\n",
      "[1444/1762] D loss: 1.3768, G loss: 0.6694\n",
      "[1524/1762] D loss: 1.3802, G loss: 0.7120\n",
      "[1604/1762] D loss: 1.3810, G loss: 0.7077\n",
      "[1684/1762] D loss: 1.3820, G loss: 0.6727\n",
      "[1762/1762] D loss: 2.8208, G loss: 2.1366\n",
      "train error: \n",
      " D loss: 1.246885, G loss: 1.099159, D accuracy: 60.8%, cell accuracy: 99.6%, board accuracy: 79.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.229992, G loss: 1.192318, D accuracy: 60.0%, cell accuracy: 99.6%, board accuracy: 80.2% \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3649, G loss: 0.6999\n",
      "[84/1762] D loss: 1.3865, G loss: 0.7040\n",
      "[164/1762] D loss: 1.3837, G loss: 0.6763\n",
      "[244/1762] D loss: 1.1591, G loss: 0.8437\n",
      "[324/1762] D loss: 1.3770, G loss: 0.6860\n",
      "[404/1762] D loss: 1.3874, G loss: 0.6943\n",
      "[484/1762] D loss: 1.3804, G loss: 0.7035\n",
      "[564/1762] D loss: 0.9618, G loss: 1.3109\n",
      "[644/1762] D loss: 1.3865, G loss: 0.7071\n",
      "[724/1762] D loss: 1.3872, G loss: 0.6754\n",
      "[804/1762] D loss: 1.0914, G loss: 0.9358\n",
      "[884/1762] D loss: 1.3893, G loss: 0.7305\n",
      "[964/1762] D loss: 1.3864, G loss: 0.7022\n",
      "[1044/1762] D loss: 1.3908, G loss: 0.6676\n",
      "[1124/1762] D loss: 1.0806, G loss: 1.0479\n",
      "[1204/1762] D loss: 1.3440, G loss: 0.7587\n",
      "[1284/1762] D loss: 1.3860, G loss: 0.6874\n",
      "[1364/1762] D loss: 1.3857, G loss: 0.6999\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6981\n",
      "[1524/1762] D loss: 1.3857, G loss: 0.6927\n",
      "[1604/1762] D loss: 1.0906, G loss: 0.9333\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6948\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6975\n",
      "train error: \n",
      " D loss: 1.296743, G loss: 0.822516, D accuracy: 54.3%, cell accuracy: 99.9%, board accuracy: 89.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.271707, G loss: 0.864182, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3861, G loss: 0.6978\n",
      "[84/1762] D loss: 1.3831, G loss: 0.6681\n",
      "[164/1762] D loss: 1.3855, G loss: 0.7035\n",
      "[244/1762] D loss: 1.3880, G loss: 0.7194\n",
      "[324/1762] D loss: 1.3864, G loss: 0.7063\n",
      "[404/1762] D loss: 1.3878, G loss: 0.6802\n",
      "[484/1762] D loss: 1.4637, G loss: 0.9792\n",
      "[564/1762] D loss: 1.3731, G loss: 0.6952\n",
      "[644/1762] D loss: 1.3884, G loss: 0.6710\n",
      "[724/1762] D loss: 1.0840, G loss: 0.9515\n",
      "[804/1762] D loss: 1.3607, G loss: 0.6390\n",
      "[884/1762] D loss: 1.0615, G loss: 1.1395\n",
      "[964/1762] D loss: 1.3863, G loss: 0.6936\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6939\n",
      "[1124/1762] D loss: 1.3617, G loss: 0.7289\n",
      "[1204/1762] D loss: 1.3286, G loss: 0.8163\n",
      "[1284/1762] D loss: 1.0778, G loss: 1.0339\n",
      "[1364/1762] D loss: 1.3773, G loss: 0.7042\n",
      "[1444/1762] D loss: 1.3876, G loss: 0.7074\n",
      "[1524/1762] D loss: 1.3843, G loss: 0.6772\n",
      "[1604/1762] D loss: 1.0527, G loss: 1.2778\n",
      "[1684/1762] D loss: 1.3866, G loss: 0.6751\n",
      "[1762/1762] D loss: 1.3915, G loss: 0.6317\n",
      "train error: \n",
      " D loss: 1.289652, G loss: 0.831493, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.274776, G loss: 0.860360, D accuracy: 56.5%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3848, G loss: 0.6901\n",
      "[84/1762] D loss: 1.3832, G loss: 0.6837\n",
      "[164/1762] D loss: 1.0654, G loss: 1.0968\n",
      "[244/1762] D loss: 1.0616, G loss: 1.2048\n",
      "[324/1762] D loss: 1.3848, G loss: 0.6573\n",
      "[404/1762] D loss: 1.3862, G loss: 0.7006\n",
      "[484/1762] D loss: 1.3873, G loss: 0.6826\n",
      "[564/1762] D loss: 1.3831, G loss: 0.6994\n",
      "[644/1762] D loss: 1.3878, G loss: 0.6958\n",
      "[724/1762] D loss: 1.2976, G loss: 0.7893\n",
      "[804/1762] D loss: 1.0701, G loss: 1.0595\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6856\n",
      "[964/1762] D loss: 1.3897, G loss: 0.6581\n",
      "[1044/1762] D loss: 1.3874, G loss: 0.6710\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.6832\n",
      "[1204/1762] D loss: 1.3913, G loss: 0.6519\n",
      "[1284/1762] D loss: 1.3956, G loss: 0.7355\n",
      "[1364/1762] D loss: 1.0701, G loss: 1.0970\n",
      "[1444/1762] D loss: 1.3905, G loss: 0.6491\n",
      "[1524/1762] D loss: 1.3987, G loss: 0.7788\n",
      "[1604/1762] D loss: 1.3865, G loss: 0.6943\n",
      "[1684/1762] D loss: 1.3898, G loss: 0.6784\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6863\n",
      "train error: \n",
      " D loss: 1.299369, G loss: 0.825022, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 90.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.276393, G loss: 0.888396, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4317, G loss: 1.3649\n",
      "[84/1762] D loss: 1.1854, G loss: 0.7668\n",
      "[164/1762] D loss: 1.0744, G loss: 1.1848\n",
      "[244/1762] D loss: 1.3934, G loss: 0.6547\n",
      "[324/1762] D loss: 1.3944, G loss: 0.6698\n",
      "[404/1762] D loss: 1.0801, G loss: 1.1742\n",
      "[484/1762] D loss: 1.2802, G loss: 0.9554\n",
      "[564/1762] D loss: 1.3863, G loss: 0.6858\n",
      "[644/1762] D loss: 1.3909, G loss: 0.6624\n",
      "[724/1762] D loss: 1.4037, G loss: 0.6872\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6853\n",
      "[884/1762] D loss: 1.0432, G loss: 2.1387\n",
      "[964/1762] D loss: 1.3863, G loss: 0.6865\n",
      "[1044/1762] D loss: 1.3869, G loss: 0.6912\n",
      "[1124/1762] D loss: 1.0426, G loss: 2.3156\n",
      "[1204/1762] D loss: 0.6994, G loss: 3.6015\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6889\n",
      "[1364/1762] D loss: 1.0398, G loss: 2.5743\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6885\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.6988\n",
      "[1604/1762] D loss: 1.3896, G loss: 0.7225\n",
      "[1684/1762] D loss: 1.3875, G loss: 0.7068\n",
      "[1762/1762] D loss: 1.3860, G loss: 0.6882\n",
      "train error: \n",
      " D loss: 1.305001, G loss: 1.134717, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 86.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.273915, G loss: 1.264866, D accuracy: 55.3%, cell accuracy: 99.7%, board accuracy: 83.2% \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0385, G loss: 2.3490\n",
      "[84/1762] D loss: 1.3867, G loss: 0.6905\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6903\n",
      "[244/1762] D loss: 1.3867, G loss: 0.7016\n",
      "[324/1762] D loss: 1.3865, G loss: 0.7057\n",
      "[404/1762] D loss: 1.0399, G loss: 2.2850\n",
      "[484/1762] D loss: 1.3862, G loss: 0.6992\n",
      "[564/1762] D loss: 1.0383, G loss: 2.2928\n",
      "[644/1762] D loss: 1.3835, G loss: 0.6994\n",
      "[724/1762] D loss: 1.0401, G loss: 2.2898\n",
      "[804/1762] D loss: 1.3856, G loss: 0.6666\n",
      "[884/1762] D loss: 1.3719, G loss: 0.6985\n",
      "[964/1762] D loss: 1.3863, G loss: 0.6902\n",
      "[1044/1762] D loss: 1.4367, G loss: 1.5824\n",
      "[1124/1762] D loss: 1.3847, G loss: 0.6766\n",
      "[1204/1762] D loss: 1.3885, G loss: 0.7189\n",
      "[1284/1762] D loss: 1.3851, G loss: 0.6840\n",
      "[1364/1762] D loss: 1.0425, G loss: 2.0746\n",
      "[1444/1762] D loss: 1.0407, G loss: 2.0186\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.6861\n",
      "[1604/1762] D loss: 1.3449, G loss: 0.7175\n",
      "[1684/1762] D loss: 0.3191, G loss: 4.3412\n",
      "[1762/1762] D loss: 1.3860, G loss: 0.6628\n",
      "train error: \n",
      " D loss: 1.276533, G loss: 1.163193, D accuracy: 56.9%, cell accuracy: 99.7%, board accuracy: 87.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.252672, G loss: 1.396845, D accuracy: 56.4%, cell accuracy: 99.7%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0435, G loss: 2.7317\n",
      "[84/1762] D loss: 0.6939, G loss: 4.4781\n",
      "[164/1762] D loss: 1.3871, G loss: 0.7862\n",
      "[244/1762] D loss: 1.0410, G loss: 2.1194\n",
      "[324/1762] D loss: 0.9970, G loss: 2.1954\n",
      "[404/1762] D loss: 1.3852, G loss: 0.6916\n",
      "[484/1762] D loss: 1.3855, G loss: 0.6519\n",
      "[564/1762] D loss: 1.3969, G loss: 0.7199\n",
      "[644/1762] D loss: 1.0896, G loss: 1.2189\n",
      "[724/1762] D loss: 1.3865, G loss: 0.6790\n",
      "[804/1762] D loss: 1.4002, G loss: 1.2841\n",
      "[884/1762] D loss: 1.3847, G loss: 0.6810\n",
      "[964/1762] D loss: 1.3855, G loss: 0.6861\n",
      "[1044/1762] D loss: 1.3542, G loss: 0.7320\n",
      "[1124/1762] D loss: 1.3837, G loss: 0.7116\n",
      "[1204/1762] D loss: 1.3443, G loss: 0.7236\n",
      "[1284/1762] D loss: 1.3239, G loss: 0.7452\n",
      "[1364/1762] D loss: 1.3964, G loss: 0.6946\n",
      "[1444/1762] D loss: 1.3879, G loss: 0.6607\n",
      "[1524/1762] D loss: 1.0666, G loss: 1.1028\n",
      "[1604/1762] D loss: 1.0697, G loss: 1.9949\n",
      "[1684/1762] D loss: 1.0505, G loss: 2.0253\n",
      "[1762/1762] D loss: 1.3965, G loss: 0.7629\n",
      "train error: \n",
      " D loss: 1.308942, G loss: 0.862392, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.305121, G loss: 0.818073, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3806, G loss: 0.6925\n",
      "[84/1762] D loss: 1.3684, G loss: 0.6868\n",
      "[164/1762] D loss: 1.3860, G loss: 0.6831\n",
      "[244/1762] D loss: 1.3864, G loss: 0.6796\n",
      "[324/1762] D loss: 1.1762, G loss: 0.7470\n",
      "[404/1762] D loss: 1.0775, G loss: 1.4588\n",
      "[484/1762] D loss: 1.0607, G loss: 1.4439\n",
      "[564/1762] D loss: 1.0770, G loss: 1.0206\n",
      "[644/1762] D loss: 1.3850, G loss: 0.6886\n",
      "[724/1762] D loss: 1.3867, G loss: 0.7029\n",
      "[804/1762] D loss: 1.2272, G loss: 1.8825\n",
      "[884/1762] D loss: 1.3865, G loss: 0.6788\n",
      "[964/1762] D loss: 1.3866, G loss: 0.6787\n",
      "[1044/1762] D loss: 1.0431, G loss: 1.9855\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.6790\n",
      "[1204/1762] D loss: 1.3865, G loss: 0.6792\n",
      "[1284/1762] D loss: 1.0437, G loss: 2.0363\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6799\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6849\n",
      "[1524/1762] D loss: 1.0410, G loss: 2.0359\n",
      "[1604/1762] D loss: 1.3873, G loss: 0.7095\n",
      "[1684/1762] D loss: 1.0482, G loss: 1.7057\n",
      "[1762/1762] D loss: 1.3881, G loss: 0.6623\n",
      "train error: \n",
      " D loss: 1.296330, G loss: 1.061629, D accuracy: 53.4%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.267532, G loss: 1.193227, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3869, G loss: 0.6758\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6832\n",
      "[164/1762] D loss: 1.3861, G loss: 0.6838\n",
      "[244/1762] D loss: 1.3870, G loss: 0.6701\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6832\n",
      "[404/1762] D loss: 1.3878, G loss: 0.7152\n",
      "[484/1762] D loss: 1.3904, G loss: 0.6552\n",
      "[564/1762] D loss: 1.0478, G loss: 1.9748\n",
      "[644/1762] D loss: 1.3861, G loss: 0.6941\n",
      "[724/1762] D loss: 1.3871, G loss: 0.6708\n",
      "[804/1762] D loss: 1.1388, G loss: 0.8017\n",
      "[884/1762] D loss: 1.0630, G loss: 2.3237\n",
      "[964/1762] D loss: 1.3874, G loss: 0.7159\n",
      "[1044/1762] D loss: 1.3876, G loss: 0.6671\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.6850\n",
      "[1204/1762] D loss: 0.8173, G loss: 1.3370\n",
      "[1284/1762] D loss: 0.7286, G loss: 1.7229\n",
      "[1364/1762] D loss: 1.0985, G loss: 0.9435\n",
      "[1444/1762] D loss: 1.1229, G loss: 0.8445\n",
      "[1524/1762] D loss: 1.0911, G loss: 1.0554\n",
      "[1604/1762] D loss: 1.3645, G loss: 0.6932\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6877\n",
      "[1762/1762] D loss: 1.3857, G loss: 0.7001\n",
      "train error: \n",
      " D loss: 1.275437, G loss: 1.312733, D accuracy: 55.7%, cell accuracy: 99.7%, board accuracy: 83.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.263728, G loss: 1.537178, D accuracy: 55.8%, cell accuracy: 99.6%, board accuracy: 83.9% \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3870, G loss: 0.6943\n",
      "[84/1762] D loss: 1.3572, G loss: 0.7304\n",
      "[164/1762] D loss: 1.0737, G loss: 1.0563\n",
      "[244/1762] D loss: 1.3865, G loss: 0.6898\n",
      "[324/1762] D loss: 1.3864, G loss: 0.6774\n",
      "[404/1762] D loss: 0.3851, G loss: 3.2776\n",
      "[484/1762] D loss: 1.3860, G loss: 0.6821\n",
      "[564/1762] D loss: 1.2372, G loss: 0.9248\n",
      "[644/1762] D loss: 1.3853, G loss: 0.6876\n",
      "[724/1762] D loss: 1.0870, G loss: 0.9575\n",
      "[804/1762] D loss: 1.0840, G loss: 0.9703\n",
      "[884/1762] D loss: 1.3943, G loss: 0.6904\n",
      "[964/1762] D loss: 1.0645, G loss: 1.1170\n",
      "[1044/1762] D loss: 1.0318, G loss: 1.5851\n",
      "[1124/1762] D loss: 1.3870, G loss: 0.6752\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6877\n",
      "[1284/1762] D loss: 1.3874, G loss: 0.7033\n",
      "[1364/1762] D loss: 1.6597, G loss: 1.9662\n",
      "[1444/1762] D loss: 1.3870, G loss: 0.6651\n",
      "[1524/1762] D loss: 1.1429, G loss: 0.7782\n",
      "[1604/1762] D loss: 1.3870, G loss: 0.6674\n",
      "[1684/1762] D loss: 1.2682, G loss: 1.2410\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.6845\n",
      "train error: \n",
      " D loss: 1.297748, G loss: 0.887249, D accuracy: 54.4%, cell accuracy: 99.9%, board accuracy: 90.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.283494, G loss: 0.878996, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3868, G loss: 0.6753\n",
      "[84/1762] D loss: 1.3880, G loss: 0.6546\n",
      "[164/1762] D loss: 1.3851, G loss: 0.7078\n",
      "[244/1762] D loss: 1.3870, G loss: 0.6639\n",
      "[324/1762] D loss: 1.3908, G loss: 0.6497\n",
      "[404/1762] D loss: 1.4480, G loss: 0.7698\n",
      "[484/1762] D loss: 1.3861, G loss: 0.6741\n",
      "[564/1762] D loss: 1.1885, G loss: 1.3746\n",
      "[644/1762] D loss: 1.3861, G loss: 0.6705\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6823\n",
      "[804/1762] D loss: 1.2110, G loss: 1.2034\n",
      "[884/1762] D loss: 1.3818, G loss: 0.7130\n",
      "[964/1762] D loss: 1.3864, G loss: 0.6861\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.6852\n",
      "[1124/1762] D loss: 1.3955, G loss: 0.6317\n",
      "[1204/1762] D loss: 1.3861, G loss: 0.6915\n",
      "[1284/1762] D loss: 1.3778, G loss: 0.6787\n",
      "[1364/1762] D loss: 1.3862, G loss: 0.6819\n",
      "[1444/1762] D loss: 1.3892, G loss: 0.6727\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.6815\n",
      "[1604/1762] D loss: 1.0974, G loss: 0.9746\n",
      "[1684/1762] D loss: 1.3877, G loss: 0.6943\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6845\n",
      "train error: \n",
      " D loss: 1.304662, G loss: 0.826298, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.290729, G loss: 0.883483, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7522, G loss: 1.4617\n",
      "[84/1762] D loss: 1.3832, G loss: 0.6970\n",
      "[164/1762] D loss: 1.3868, G loss: 0.6740\n",
      "[244/1762] D loss: 1.0506, G loss: 1.3482\n",
      "[324/1762] D loss: 1.2515, G loss: 0.9929\n",
      "[404/1762] D loss: 1.3873, G loss: 0.6494\n",
      "[484/1762] D loss: 1.3864, G loss: 0.6851\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6917\n",
      "[644/1762] D loss: 1.3867, G loss: 0.6740\n",
      "[724/1762] D loss: 1.3842, G loss: 0.6953\n",
      "[804/1762] D loss: 1.0874, G loss: 1.0407\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6861\n",
      "[964/1762] D loss: 1.0712, G loss: 1.0511\n",
      "[1044/1762] D loss: 1.0603, G loss: 1.1712\n",
      "[1124/1762] D loss: 1.3817, G loss: 0.6883\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6891\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.7014\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6909\n",
      "[1444/1762] D loss: 1.3866, G loss: 0.6816\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.6937\n",
      "[1604/1762] D loss: 1.3871, G loss: 0.6745\n",
      "[1684/1762] D loss: 1.3865, G loss: 0.6836\n",
      "[1762/1762] D loss: 1.3861, G loss: 0.6986\n",
      "train error: \n",
      " D loss: 1.297798, G loss: 0.866217, D accuracy: 54.5%, cell accuracy: 99.9%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.278991, G loss: 0.926878, D accuracy: 55.6%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6914\n",
      "[84/1762] D loss: 1.3865, G loss: 0.6965\n",
      "[164/1762] D loss: 1.3875, G loss: 0.7164\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6921\n",
      "[324/1762] D loss: 1.0572, G loss: 1.2443\n",
      "[404/1762] D loss: 1.3873, G loss: 0.6925\n",
      "[484/1762] D loss: 1.3870, G loss: 0.7046\n",
      "[564/1762] D loss: 1.3870, G loss: 0.6741\n",
      "[644/1762] D loss: 1.3867, G loss: 0.7066\n",
      "[724/1762] D loss: 1.3869, G loss: 0.6791\n",
      "[804/1762] D loss: 1.0627, G loss: 1.1438\n",
      "[884/1762] D loss: 1.3862, G loss: 0.6958\n",
      "[964/1762] D loss: 1.3903, G loss: 0.6643\n",
      "[1044/1762] D loss: 1.0500, G loss: 1.3260\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.6885\n",
      "[1204/1762] D loss: 1.3866, G loss: 0.6703\n",
      "[1284/1762] D loss: 1.3861, G loss: 0.7087\n",
      "[1364/1762] D loss: 1.3956, G loss: 0.6301\n",
      "[1444/1762] D loss: 1.2108, G loss: 0.7082\n",
      "[1524/1762] D loss: 1.3855, G loss: 0.6625\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6772\n",
      "[1684/1762] D loss: 1.3866, G loss: 0.7015\n",
      "[1762/1762] D loss: 1.3850, G loss: 0.6801\n",
      "train error: \n",
      " D loss: 1.305976, G loss: 0.829518, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.289344, G loss: 0.849774, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3860, G loss: 0.6910\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6917\n",
      "[164/1762] D loss: 1.0578, G loss: 1.2184\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6900\n",
      "[324/1762] D loss: 1.3857, G loss: 0.7006\n",
      "[404/1762] D loss: 1.3863, G loss: 0.6913\n",
      "[484/1762] D loss: 1.3838, G loss: 0.7003\n",
      "[564/1762] D loss: 1.3862, G loss: 0.6885\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6911\n",
      "[724/1762] D loss: 1.3873, G loss: 0.6930\n",
      "[804/1762] D loss: 1.3862, G loss: 0.6910\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6943\n",
      "[964/1762] D loss: 1.0418, G loss: 1.7274\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6936\n",
      "[1124/1762] D loss: 1.2543, G loss: 0.8749\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6931\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6939\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6948\n",
      "[1444/1762] D loss: 1.2845, G loss: 0.6751\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.6972\n",
      "[1604/1762] D loss: 1.3865, G loss: 0.6936\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6894\n",
      "[1762/1762] D loss: 1.3860, G loss: 0.6890\n",
      "train error: \n",
      " D loss: 1.305412, G loss: 0.882726, D accuracy: 53.4%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.290699, G loss: 0.921480, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6940\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6951\n",
      "[164/1762] D loss: 1.7196, G loss: 1.1746\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6920\n",
      "[324/1762] D loss: 1.3866, G loss: 0.6839\n",
      "[404/1762] D loss: 1.3871, G loss: 0.6732\n",
      "[484/1762] D loss: 1.3864, G loss: 0.6962\n",
      "[564/1762] D loss: 1.0535, G loss: 1.2799\n",
      "[644/1762] D loss: 1.0446, G loss: 1.5327\n",
      "[724/1762] D loss: 1.3878, G loss: 0.7115\n",
      "[804/1762] D loss: 0.7781, G loss: 1.2779\n",
      "[884/1762] D loss: 1.3865, G loss: 0.6802\n",
      "[964/1762] D loss: 1.3867, G loss: 0.6968\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.6843\n",
      "[1124/1762] D loss: 1.0586, G loss: 1.1729\n",
      "[1204/1762] D loss: 1.2221, G loss: 1.2966\n",
      "[1284/1762] D loss: 1.3878, G loss: 0.7061\n",
      "[1364/1762] D loss: 1.0593, G loss: 1.1838\n",
      "[1444/1762] D loss: 1.3833, G loss: 0.7004\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.6868\n",
      "[1604/1762] D loss: 1.3861, G loss: 0.6978\n",
      "[1684/1762] D loss: 1.3871, G loss: 0.7030\n",
      "[1762/1762] D loss: 1.9966, G loss: 1.2462\n",
      "train error: \n",
      " D loss: 1.305019, G loss: 0.852520, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.290708, G loss: 0.888547, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3862, G loss: 0.6895\n",
      "[84/1762] D loss: 1.1559, G loss: 0.7393\n",
      "[164/1762] D loss: 1.3864, G loss: 0.6814\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6861\n",
      "[324/1762] D loss: 1.3862, G loss: 0.7149\n",
      "[404/1762] D loss: 1.0601, G loss: 1.1822\n",
      "[484/1762] D loss: 1.3786, G loss: 0.6987\n",
      "[564/1762] D loss: 1.3862, G loss: 0.6840\n",
      "[644/1762] D loss: 1.3841, G loss: 0.6976\n",
      "[724/1762] D loss: 1.7844, G loss: 1.1917\n",
      "[804/1762] D loss: 1.3863, G loss: 0.6875\n",
      "[884/1762] D loss: 1.3871, G loss: 0.7162\n",
      "[964/1762] D loss: 1.3863, G loss: 0.6876\n",
      "[1044/1762] D loss: 1.3959, G loss: 0.7118\n",
      "[1124/1762] D loss: 1.3908, G loss: 0.6462\n",
      "[1204/1762] D loss: 1.2546, G loss: 0.9197\n",
      "[1284/1762] D loss: 1.3891, G loss: 0.7139\n",
      "[1364/1762] D loss: 1.0634, G loss: 1.1251\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.7051\n",
      "[1524/1762] D loss: 1.3861, G loss: 0.6978\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6914\n",
      "[1684/1762] D loss: 1.3865, G loss: 0.7001\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6932\n",
      "train error: \n",
      " D loss: 1.306693, G loss: 0.835143, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.291224, G loss: 0.910318, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3862, G loss: 0.6911\n",
      "[84/1762] D loss: 1.3862, G loss: 0.6897\n",
      "[164/1762] D loss: 1.3864, G loss: 0.6999\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6929\n",
      "[324/1762] D loss: 1.3868, G loss: 0.7129\n",
      "[404/1762] D loss: 1.3870, G loss: 0.6830\n",
      "[484/1762] D loss: 1.3862, G loss: 0.6909\n",
      "[564/1762] D loss: 1.3863, G loss: 0.6925\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6958\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6928\n",
      "[804/1762] D loss: 1.3865, G loss: 0.7025\n",
      "[884/1762] D loss: 1.0498, G loss: 1.3364\n",
      "[964/1762] D loss: 1.3868, G loss: 0.6844\n",
      "[1044/1762] D loss: 1.3862, G loss: 0.6926\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6913\n",
      "[1204/1762] D loss: 1.3875, G loss: 0.6894\n",
      "[1284/1762] D loss: 1.0453, G loss: 1.4900\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6962\n",
      "[1444/1762] D loss: 1.0444, G loss: 1.5230\n",
      "[1524/1762] D loss: 1.3862, G loss: 0.6894\n",
      "[1604/1762] D loss: 1.3889, G loss: 0.6701\n",
      "[1684/1762] D loss: 1.0733, G loss: 1.0388\n",
      "[1762/1762] D loss: 1.9466, G loss: 1.5115\n",
      "train error: \n",
      " D loss: 1.306197, G loss: 0.807892, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.290880, G loss: 0.839379, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2054, G loss: 1.0558\n",
      "[84/1762] D loss: 1.3869, G loss: 0.7062\n",
      "[164/1762] D loss: 1.0885, G loss: 0.9529\n",
      "[244/1762] D loss: 1.3862, G loss: 0.6938\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6932\n",
      "[404/1762] D loss: 1.3861, G loss: 0.6916\n",
      "[484/1762] D loss: 1.0676, G loss: 1.0829\n",
      "[564/1762] D loss: 1.3863, G loss: 0.6904\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6939\n",
      "[724/1762] D loss: 1.7028, G loss: 1.1297\n",
      "[804/1762] D loss: 1.3863, G loss: 0.6914\n",
      "[884/1762] D loss: 1.2135, G loss: 1.8741\n",
      "[964/1762] D loss: 1.3863, G loss: 0.6867\n",
      "[1044/1762] D loss: 1.0902, G loss: 0.9619\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6913\n",
      "[1204/1762] D loss: 1.3919, G loss: 0.6507\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6963\n",
      "[1364/1762] D loss: 1.6516, G loss: 1.0816\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6940\n",
      "[1524/1762] D loss: 1.3861, G loss: 0.6908\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6975\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.6909\n",
      "[1762/1762] D loss: 1.3896, G loss: 0.6619\n",
      "train error: \n",
      " D loss: 1.306381, G loss: 0.830091, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.292958, G loss: 0.871460, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3881, G loss: 0.6790\n",
      "[84/1762] D loss: 1.3865, G loss: 0.6831\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6939\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6928\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6925\n",
      "[404/1762] D loss: 1.0622, G loss: 1.1358\n",
      "[484/1762] D loss: 1.0561, G loss: 1.2182\n",
      "[564/1762] D loss: 1.3870, G loss: 0.6862\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6973\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6942\n",
      "[804/1762] D loss: 1.3862, G loss: 0.6930\n",
      "[884/1762] D loss: 1.0560, G loss: 1.2173\n",
      "[964/1762] D loss: 1.0499, G loss: 1.3349\n",
      "[1044/1762] D loss: 1.0488, G loss: 1.3583\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6944\n",
      "[1204/1762] D loss: 1.1294, G loss: 0.8596\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6909\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6938\n",
      "[1444/1762] D loss: 1.0626, G loss: 1.1299\n",
      "[1524/1762] D loss: 1.0671, G loss: 1.0871\n",
      "[1604/1762] D loss: 1.0630, G loss: 1.1278\n",
      "[1684/1762] D loss: 1.3865, G loss: 0.7025\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.7018\n",
      "train error: \n",
      " D loss: 1.306707, G loss: 0.824556, D accuracy: 53.4%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.293053, G loss: 0.859354, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 91.1% \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0646, G loss: 1.1112\n",
      "[84/1762] D loss: 1.3878, G loss: 0.6747\n",
      "[164/1762] D loss: 1.3866, G loss: 0.7044\n",
      "[244/1762] D loss: 1.3875, G loss: 0.6864\n",
      "[324/1762] D loss: 1.3877, G loss: 0.6737\n",
      "[404/1762] D loss: 1.3863, G loss: 0.6956\n",
      "[484/1762] D loss: 1.0631, G loss: 1.1259\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6900\n",
      "[644/1762] D loss: 1.3864, G loss: 0.6864\n",
      "[724/1762] D loss: 1.0821, G loss: 1.0050\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6979\n",
      "[884/1762] D loss: 1.7465, G loss: 1.1623\n",
      "[964/1762] D loss: 1.3863, G loss: 0.6967\n",
      "[1044/1762] D loss: 1.0667, G loss: 1.0966\n",
      "[1124/1762] D loss: 1.0696, G loss: 1.0702\n",
      "[1204/1762] D loss: 1.3865, G loss: 0.6978\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6862\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6903\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6928\n",
      "[1524/1762] D loss: 1.3865, G loss: 0.6797\n",
      "[1604/1762] D loss: 1.0639, G loss: 1.1239\n",
      "[1684/1762] D loss: 1.3862, G loss: 0.6968\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6938\n",
      "train error: \n",
      " D loss: 1.296043, G loss: 1.044072, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.284725, G loss: 1.017890, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3874, G loss: 0.6789\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6875\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6888\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6936\n",
      "[324/1762] D loss: 1.3870, G loss: 0.7236\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6887\n",
      "[484/1762] D loss: 1.3797, G loss: 0.7072\n",
      "[564/1762] D loss: 1.3886, G loss: 0.6649\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6866\n",
      "[724/1762] D loss: 1.0805, G loss: 1.1037\n",
      "[804/1762] D loss: 1.3865, G loss: 0.6811\n",
      "[884/1762] D loss: 1.1312, G loss: 0.8594\n",
      "[964/1762] D loss: 1.3864, G loss: 0.6839\n",
      "[1044/1762] D loss: 1.3889, G loss: 0.7174\n",
      "[1124/1762] D loss: 1.3884, G loss: 0.6659\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6841\n",
      "[1284/1762] D loss: 1.3865, G loss: 0.6939\n",
      "[1364/1762] D loss: 1.3869, G loss: 0.6779\n",
      "[1444/1762] D loss: 1.3871, G loss: 0.7079\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.6869\n",
      "[1604/1762] D loss: 1.3887, G loss: 0.7012\n",
      "[1684/1762] D loss: 1.5792, G loss: 0.8343\n",
      "[1762/1762] D loss: 1.3858, G loss: 0.6876\n",
      "train error: \n",
      " D loss: 1.322269, G loss: 0.713415, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.313972, G loss: 0.723551, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3980, G loss: 0.6148\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6844\n",
      "[164/1762] D loss: 1.3849, G loss: 0.6725\n",
      "[244/1762] D loss: 1.0772, G loss: 1.0117\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6858\n",
      "[404/1762] D loss: 1.3925, G loss: 0.6870\n",
      "[484/1762] D loss: 1.0901, G loss: 0.9358\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6966\n",
      "[644/1762] D loss: 1.3864, G loss: 0.6971\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6895\n",
      "[804/1762] D loss: 1.3863, G loss: 0.6878\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6933\n",
      "[964/1762] D loss: 1.3865, G loss: 0.6835\n",
      "[1044/1762] D loss: 1.3892, G loss: 0.6963\n",
      "[1124/1762] D loss: 1.2429, G loss: 1.0418\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6859\n",
      "[1284/1762] D loss: 1.0698, G loss: 1.0736\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6920\n",
      "[1444/1762] D loss: 1.0678, G loss: 1.0946\n",
      "[1524/1762] D loss: 1.0639, G loss: 1.1847\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6896\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6873\n",
      "[1762/1762] D loss: 0.7666, G loss: 1.3514\n",
      "train error: \n",
      " D loss: 1.305383, G loss: 0.822354, D accuracy: 53.4%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.291457, G loss: 0.854451, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2485, G loss: 1.0658\n",
      "[84/1762] D loss: 1.0599, G loss: 1.1727\n",
      "[164/1762] D loss: 1.0481, G loss: 1.3727\n",
      "[244/1762] D loss: 1.3883, G loss: 0.7131\n",
      "[324/1762] D loss: 1.3867, G loss: 0.6784\n",
      "[404/1762] D loss: 1.0590, G loss: 1.2669\n",
      "[484/1762] D loss: 1.3863, G loss: 0.6912\n",
      "[564/1762] D loss: 1.3885, G loss: 0.7185\n",
      "[644/1762] D loss: 1.3866, G loss: 0.6795\n",
      "[724/1762] D loss: 1.0488, G loss: 1.3692\n",
      "[804/1762] D loss: 1.3858, G loss: 0.6924\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6906\n",
      "[964/1762] D loss: 1.3779, G loss: 0.6871\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6933\n",
      "[1124/1762] D loss: 1.3860, G loss: 0.6827\n",
      "[1204/1762] D loss: 1.5911, G loss: 1.3964\n",
      "[1284/1762] D loss: 1.3867, G loss: 0.7014\n",
      "[1364/1762] D loss: 1.0426, G loss: 1.6515\n",
      "[1444/1762] D loss: 1.3870, G loss: 0.7064\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.6943\n",
      "[1604/1762] D loss: 1.3915, G loss: 0.7195\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.6810\n",
      "[1762/1762] D loss: 1.3847, G loss: 0.6790\n",
      "train error: \n",
      " D loss: 1.285301, G loss: 0.877420, D accuracy: 56.0%, cell accuracy: 99.8%, board accuracy: 86.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.275249, G loss: 0.982260, D accuracy: 55.8%, cell accuracy: 99.7%, board accuracy: 83.9% \n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3871, G loss: 0.6645\n",
      "[84/1762] D loss: 1.3876, G loss: 0.6664\n",
      "[164/1762] D loss: 1.3865, G loss: 0.6970\n",
      "[244/1762] D loss: 1.0663, G loss: 1.1176\n",
      "[324/1762] D loss: 1.2647, G loss: 0.9319\n",
      "[404/1762] D loss: 1.3863, G loss: 0.6872\n",
      "[484/1762] D loss: 1.3861, G loss: 0.7002\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6920\n",
      "[644/1762] D loss: 1.4807, G loss: 1.3983\n",
      "[724/1762] D loss: 1.3891, G loss: 0.7132\n",
      "[804/1762] D loss: 1.3852, G loss: 0.6964\n",
      "[884/1762] D loss: 1.3835, G loss: 0.7081\n",
      "[964/1762] D loss: 1.2195, G loss: 1.2862\n",
      "[1044/1762] D loss: 1.3877, G loss: 0.7348\n",
      "[1124/1762] D loss: 1.3866, G loss: 0.6789\n",
      "[1204/1762] D loss: 1.3855, G loss: 0.6977\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6894\n",
      "[1364/1762] D loss: 1.3886, G loss: 0.7123\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6845\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.6832\n",
      "[1604/1762] D loss: 1.3866, G loss: 0.6975\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6879\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6849\n",
      "train error: \n",
      " D loss: 1.307625, G loss: 0.793271, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.293496, G loss: 0.834195, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3855, G loss: 0.6672\n",
      "[84/1762] D loss: 1.3872, G loss: 0.6722\n",
      "[164/1762] D loss: 1.0602, G loss: 1.1590\n",
      "[244/1762] D loss: 1.0547, G loss: 1.2428\n",
      "[324/1762] D loss: 1.0699, G loss: 1.0881\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6847\n",
      "[484/1762] D loss: 0.7465, G loss: 1.5004\n",
      "[564/1762] D loss: 1.3873, G loss: 0.7110\n",
      "[644/1762] D loss: 1.3866, G loss: 0.6783\n",
      "[724/1762] D loss: 1.3878, G loss: 0.6737\n",
      "[804/1762] D loss: 1.3834, G loss: 0.7262\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6851\n",
      "[964/1762] D loss: 1.3861, G loss: 0.6887\n",
      "[1044/1762] D loss: 1.0639, G loss: 1.1157\n",
      "[1124/1762] D loss: 1.3645, G loss: 0.7272\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6954\n",
      "[1284/1762] D loss: 1.3951, G loss: 0.7576\n",
      "[1364/1762] D loss: 1.3866, G loss: 0.6780\n",
      "[1444/1762] D loss: 1.3896, G loss: 0.7340\n",
      "[1524/1762] D loss: 1.3867, G loss: 0.6931\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6856\n",
      "[1684/1762] D loss: 1.6554, G loss: 1.1358\n",
      "[1762/1762] D loss: 1.3872, G loss: 0.6973\n",
      "train error: \n",
      " D loss: 1.307846, G loss: 0.791910, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 90.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.300833, G loss: 0.821478, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0850, G loss: 0.9991\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6838\n",
      "[164/1762] D loss: 1.3864, G loss: 0.6841\n",
      "[244/1762] D loss: 1.3864, G loss: 0.6821\n",
      "[324/1762] D loss: 1.3859, G loss: 0.6712\n",
      "[404/1762] D loss: 1.3867, G loss: 0.6914\n",
      "[484/1762] D loss: 1.3863, G loss: 0.6908\n",
      "[564/1762] D loss: 1.0522, G loss: 1.3088\n",
      "[644/1762] D loss: 1.0447, G loss: 1.5144\n",
      "[724/1762] D loss: 1.0805, G loss: 1.0128\n",
      "[804/1762] D loss: 1.3669, G loss: 0.7307\n",
      "[884/1762] D loss: 1.0505, G loss: 1.3555\n",
      "[964/1762] D loss: 1.3868, G loss: 0.6880\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6919\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.6997\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6852\n",
      "[1284/1762] D loss: 1.3866, G loss: 0.6814\n",
      "[1364/1762] D loss: 1.3874, G loss: 0.6658\n",
      "[1444/1762] D loss: 1.0634, G loss: 1.1209\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.6912\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6850\n",
      "[1684/1762] D loss: 1.3865, G loss: 0.7010\n",
      "[1762/1762] D loss: 1.3936, G loss: 0.6268\n",
      "train error: \n",
      " D loss: 1.306622, G loss: 0.838415, D accuracy: 54.3%, cell accuracy: 99.9%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.286386, G loss: 0.936453, D accuracy: 55.6%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.6862, G loss: 1.1080\n",
      "[84/1762] D loss: 1.0697, G loss: 1.0683\n",
      "[164/1762] D loss: 1.3875, G loss: 0.6795\n",
      "[244/1762] D loss: 1.3865, G loss: 0.6786\n",
      "[324/1762] D loss: 1.3864, G loss: 0.6824\n",
      "[404/1762] D loss: 1.0826, G loss: 0.9780\n",
      "[484/1762] D loss: 1.3895, G loss: 0.6812\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6852\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6900\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6897\n",
      "[804/1762] D loss: 1.0726, G loss: 1.0442\n",
      "[884/1762] D loss: 1.3861, G loss: 0.6936\n",
      "[964/1762] D loss: 1.3863, G loss: 0.6920\n",
      "[1044/1762] D loss: 1.3862, G loss: 0.6941\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6925\n",
      "[1204/1762] D loss: 1.3866, G loss: 0.6927\n",
      "[1284/1762] D loss: 1.3873, G loss: 0.6760\n",
      "[1364/1762] D loss: 1.3867, G loss: 0.6946\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6931\n",
      "[1524/1762] D loss: 1.3867, G loss: 0.6994\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6936\n",
      "[1684/1762] D loss: 1.3960, G loss: 0.7231\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6937\n",
      "train error: \n",
      " D loss: 1.308749, G loss: 0.869477, D accuracy: 53.4%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.297115, G loss: 0.935672, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 91.1% \n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6937\n",
      "[84/1762] D loss: 1.3868, G loss: 0.6813\n",
      "[164/1762] D loss: 1.3826, G loss: 0.6662\n",
      "[244/1762] D loss: 1.3796, G loss: 0.6940\n",
      "[324/1762] D loss: 1.3792, G loss: 0.7040\n",
      "[404/1762] D loss: 1.3890, G loss: 0.6388\n",
      "[484/1762] D loss: 1.3863, G loss: 0.6929\n",
      "[564/1762] D loss: 1.3897, G loss: 0.6463\n",
      "[644/1762] D loss: 1.0722, G loss: 1.0503\n",
      "[724/1762] D loss: 1.0586, G loss: 1.1932\n",
      "[804/1762] D loss: 1.3863, G loss: 0.6924\n",
      "[884/1762] D loss: 1.0651, G loss: 1.1011\n",
      "[964/1762] D loss: 1.3861, G loss: 0.6936\n",
      "[1044/1762] D loss: 0.7260, G loss: 1.7409\n",
      "[1124/1762] D loss: 1.3888, G loss: 0.7208\n",
      "[1204/1762] D loss: 1.3402, G loss: 0.7159\n",
      "[1284/1762] D loss: 1.3865, G loss: 0.7001\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6942\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.6877\n",
      "[1524/1762] D loss: 1.0435, G loss: 1.9207\n",
      "[1604/1762] D loss: 1.0410, G loss: 1.9588\n",
      "[1684/1762] D loss: 1.0849, G loss: 0.9613\n",
      "[1762/1762] D loss: 0.7635, G loss: 1.3753\n",
      "train error: \n",
      " D loss: 1.314288, G loss: 0.795918, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.295713, G loss: 0.835950, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6936\n",
      "[84/1762] D loss: 1.3255, G loss: 0.7844\n",
      "[164/1762] D loss: 1.3888, G loss: 0.6556\n",
      "[244/1762] D loss: 1.1138, G loss: 0.8406\n",
      "[324/1762] D loss: 1.3865, G loss: 0.6926\n",
      "[404/1762] D loss: 1.3878, G loss: 0.7057\n",
      "[484/1762] D loss: 1.3871, G loss: 0.6764\n",
      "[564/1762] D loss: 1.0955, G loss: 0.9538\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6928\n",
      "[724/1762] D loss: 1.3865, G loss: 0.6842\n",
      "[804/1762] D loss: 1.3883, G loss: 0.6662\n",
      "[884/1762] D loss: 1.2186, G loss: 1.3405\n",
      "[964/1762] D loss: 1.3863, G loss: 0.6889\n",
      "[1044/1762] D loss: 1.3794, G loss: 0.6785\n",
      "[1124/1762] D loss: 0.6952, G loss: 3.3610\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6858\n",
      "[1284/1762] D loss: 1.3879, G loss: 0.6725\n",
      "[1364/1762] D loss: 1.0493, G loss: 2.0408\n",
      "[1444/1762] D loss: 1.3853, G loss: 0.6904\n",
      "[1524/1762] D loss: 1.3423, G loss: 0.7485\n",
      "[1604/1762] D loss: 1.3872, G loss: 0.6868\n",
      "[1684/1762] D loss: 1.3880, G loss: 0.6831\n",
      "[1762/1762] D loss: 1.3869, G loss: 0.6970\n",
      "train error: \n",
      " D loss: 1.290023, G loss: 1.309564, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 88.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.296594, G loss: 1.302526, D accuracy: 55.7%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6870\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6838\n",
      "[164/1762] D loss: 1.3864, G loss: 0.6852\n",
      "[244/1762] D loss: 1.1933, G loss: 1.3455\n",
      "[324/1762] D loss: 1.3866, G loss: 0.6792\n",
      "[404/1762] D loss: 1.3863, G loss: 0.6872\n",
      "[484/1762] D loss: 1.3865, G loss: 0.6888\n",
      "[564/1762] D loss: 1.3863, G loss: 0.6891\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6873\n",
      "[724/1762] D loss: 1.0557, G loss: 1.2662\n",
      "[804/1762] D loss: 1.3874, G loss: 0.6753\n",
      "[884/1762] D loss: 1.2938, G loss: 0.8428\n",
      "[964/1762] D loss: 1.3875, G loss: 0.6723\n",
      "[1044/1762] D loss: 1.3887, G loss: 0.7190\n",
      "[1124/1762] D loss: 1.3870, G loss: 0.6796\n",
      "[1204/1762] D loss: 1.0536, G loss: 1.2472\n",
      "[1284/1762] D loss: 1.3857, G loss: 0.6944\n",
      "[1364/1762] D loss: 1.3901, G loss: 0.6499\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6864\n",
      "[1524/1762] D loss: 1.0610, G loss: 1.1513\n",
      "[1604/1762] D loss: 1.0571, G loss: 1.1870\n",
      "[1684/1762] D loss: 1.3896, G loss: 0.6897\n",
      "[1762/1762] D loss: 1.3862, G loss: 0.6952\n",
      "train error: \n",
      " D loss: 1.310999, G loss: 0.866262, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.305102, G loss: 0.918920, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6932\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6898\n",
      "[164/1762] D loss: 1.0648, G loss: 1.1107\n",
      "[244/1762] D loss: 1.6548, G loss: 0.9705\n",
      "[324/1762] D loss: 0.7852, G loss: 1.2376\n",
      "[404/1762] D loss: 1.3862, G loss: 0.6919\n",
      "[484/1762] D loss: 1.3863, G loss: 0.6899\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6892\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6933\n",
      "[724/1762] D loss: 1.3874, G loss: 0.6597\n",
      "[804/1762] D loss: 1.0671, G loss: 1.1046\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6920\n",
      "[964/1762] D loss: 1.3887, G loss: 0.7170\n",
      "[1044/1762] D loss: 1.3854, G loss: 0.7186\n",
      "[1124/1762] D loss: 1.0739, G loss: 1.0378\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6898\n",
      "[1284/1762] D loss: 1.0647, G loss: 1.1718\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.7012\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6906\n",
      "[1524/1762] D loss: 1.3873, G loss: 0.7232\n",
      "[1604/1762] D loss: 1.7287, G loss: 1.1799\n",
      "[1684/1762] D loss: 1.3866, G loss: 0.7029\n",
      "[1762/1762] D loss: 1.3838, G loss: 0.7150\n",
      "train error: \n",
      " D loss: 1.307732, G loss: 0.838398, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.301825, G loss: 0.888774, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6931\n",
      "[84/1762] D loss: 0.7440, G loss: 1.5195\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6922\n",
      "[244/1762] D loss: 0.9775, G loss: 1.3154\n",
      "[324/1762] D loss: 1.0524, G loss: 1.2787\n",
      "[404/1762] D loss: 1.3870, G loss: 0.7042\n",
      "[484/1762] D loss: 1.7544, G loss: 1.5243\n",
      "[564/1762] D loss: 1.3873, G loss: 0.6755\n",
      "[644/1762] D loss: 1.3866, G loss: 0.7005\n",
      "[724/1762] D loss: 1.3854, G loss: 0.6863\n",
      "[804/1762] D loss: 1.3881, G loss: 0.6719\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6918\n",
      "[964/1762] D loss: 1.3865, G loss: 0.6879\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6931\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6946\n",
      "[1204/1762] D loss: 1.3932, G loss: 0.6457\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6958\n",
      "[1364/1762] D loss: 1.3858, G loss: 0.6970\n",
      "[1444/1762] D loss: 0.7519, G loss: 1.4473\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.6946\n",
      "[1604/1762] D loss: 1.3649, G loss: 0.6943\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6930\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6906\n",
      "train error: \n",
      " D loss: 1.307670, G loss: 0.794538, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.294979, G loss: 0.834425, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6907\n",
      "[84/1762] D loss: 1.3850, G loss: 0.7032\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6934\n",
      "[244/1762] D loss: 1.0570, G loss: 1.2027\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6958\n",
      "[404/1762] D loss: 1.6101, G loss: 1.2134\n",
      "[484/1762] D loss: 1.3863, G loss: 0.6966\n",
      "[564/1762] D loss: 1.3863, G loss: 0.6966\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6969\n",
      "[724/1762] D loss: 1.3876, G loss: 0.6833\n",
      "[804/1762] D loss: 1.3880, G loss: 0.7180\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6908\n",
      "[964/1762] D loss: 1.3863, G loss: 0.6950\n",
      "[1044/1762] D loss: 1.3859, G loss: 0.6880\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6974\n",
      "[1204/1762] D loss: 1.3866, G loss: 0.6970\n",
      "[1284/1762] D loss: 1.3872, G loss: 0.6793\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6929\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.7035\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.6931\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6958\n",
      "[1684/1762] D loss: 1.0604, G loss: 1.1489\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6927\n",
      "train error: \n",
      " D loss: 1.309890, G loss: 0.792277, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.295786, G loss: 0.832708, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0505, G loss: 1.3236\n",
      "[84/1762] D loss: 1.4006, G loss: 0.6405\n",
      "[164/1762] D loss: 1.0563, G loss: 1.2423\n",
      "[244/1762] D loss: 1.3883, G loss: 0.6746\n",
      "[324/1762] D loss: 1.3864, G loss: 0.6892\n",
      "[404/1762] D loss: 1.3863, G loss: 0.6924\n",
      "[484/1762] D loss: 1.3863, G loss: 0.6926\n",
      "[564/1762] D loss: 1.0661, G loss: 1.1123\n",
      "[644/1762] D loss: 1.3848, G loss: 0.6973\n",
      "[724/1762] D loss: 1.0630, G loss: 1.1096\n",
      "[804/1762] D loss: 1.2085, G loss: 1.0186\n",
      "[884/1762] D loss: 1.3823, G loss: 0.7248\n",
      "[964/1762] D loss: 1.0542, G loss: 1.2512\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6948\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.7043\n",
      "[1204/1762] D loss: 1.3859, G loss: 0.6903\n",
      "[1284/1762] D loss: 1.0674, G loss: 1.0728\n",
      "[1364/1762] D loss: 1.0688, G loss: 1.0893\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6905\n",
      "[1524/1762] D loss: 1.3869, G loss: 0.6739\n",
      "[1604/1762] D loss: 1.3847, G loss: 0.7030\n",
      "[1684/1762] D loss: 1.3875, G loss: 0.6804\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6937\n",
      "train error: \n",
      " D loss: 1.310944, G loss: 0.779514, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 88.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.300989, G loss: 0.811461, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0671, G loss: 1.0842\n",
      "[84/1762] D loss: 1.0579, G loss: 1.2200\n",
      "[164/1762] D loss: 1.6786, G loss: 1.1242\n",
      "[244/1762] D loss: 1.0564, G loss: 1.2909\n",
      "[324/1762] D loss: 1.3866, G loss: 0.6976\n",
      "[404/1762] D loss: 1.3875, G loss: 0.6848\n",
      "[484/1762] D loss: 1.1884, G loss: 1.1843\n",
      "[564/1762] D loss: 1.3596, G loss: 0.7301\n",
      "[644/1762] D loss: 1.2408, G loss: 0.9932\n",
      "[724/1762] D loss: 0.7652, G loss: 1.5916\n",
      "[804/1762] D loss: 1.3870, G loss: 0.6668\n",
      "[884/1762] D loss: 1.3868, G loss: 0.6704\n",
      "[964/1762] D loss: 1.3869, G loss: 0.6704\n",
      "[1044/1762] D loss: 1.0560, G loss: 1.2390\n",
      "[1124/1762] D loss: 1.3926, G loss: 0.6361\n",
      "[1204/1762] D loss: 1.4075, G loss: 0.6660\n",
      "[1284/1762] D loss: 1.0656, G loss: 1.0975\n",
      "[1364/1762] D loss: 1.3880, G loss: 0.6676\n",
      "[1444/1762] D loss: 1.0666, G loss: 1.0933\n",
      "[1524/1762] D loss: 1.0513, G loss: 1.2982\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6833\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.6923\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.6813\n",
      "train error: \n",
      " D loss: 1.302196, G loss: 0.896934, D accuracy: 54.1%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.291098, G loss: 0.894307, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6864\n",
      "[84/1762] D loss: 1.3963, G loss: 0.7010\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6876\n",
      "[244/1762] D loss: 1.3866, G loss: 0.6809\n",
      "[324/1762] D loss: 1.3864, G loss: 0.6848\n",
      "[404/1762] D loss: 1.3878, G loss: 0.6739\n",
      "[484/1762] D loss: 1.3848, G loss: 0.6276\n",
      "[564/1762] D loss: 1.3766, G loss: 0.6772\n",
      "[644/1762] D loss: 1.3864, G loss: 0.6853\n",
      "[724/1762] D loss: 1.3361, G loss: 0.8277\n",
      "[804/1762] D loss: 1.3714, G loss: 0.7050\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6834\n",
      "[964/1762] D loss: 1.3874, G loss: 0.6721\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.6805\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6873\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6861\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6893\n",
      "[1364/1762] D loss: 1.3903, G loss: 0.7206\n",
      "[1444/1762] D loss: 1.0633, G loss: 1.1103\n",
      "[1524/1762] D loss: 1.0423, G loss: 1.7357\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6873\n",
      "[1684/1762] D loss: 1.0414, G loss: 1.2616\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.7039\n",
      "train error: \n",
      " D loss: 1.281396, G loss: 1.039596, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.275694, G loss: 1.066630, D accuracy: 56.1%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7095, G loss: 2.4331\n",
      "[84/1762] D loss: 1.3871, G loss: 0.6718\n",
      "[164/1762] D loss: 0.7451, G loss: 1.5080\n",
      "[244/1762] D loss: 0.3854, G loss: 2.5949\n",
      "[324/1762] D loss: 1.3866, G loss: 0.6962\n",
      "[404/1762] D loss: 1.3863, G loss: 0.6891\n",
      "[484/1762] D loss: 1.0436, G loss: 1.7985\n",
      "[564/1762] D loss: 1.3863, G loss: 0.6892\n",
      "[644/1762] D loss: 1.3865, G loss: 0.6844\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6880\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6953\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6896\n",
      "[964/1762] D loss: 1.3863, G loss: 0.6869\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6862\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.6780\n",
      "[1204/1762] D loss: 1.0802, G loss: 0.9817\n",
      "[1284/1762] D loss: 1.3881, G loss: 0.6663\n",
      "[1364/1762] D loss: 1.3874, G loss: 0.7023\n",
      "[1444/1762] D loss: 1.3868, G loss: 0.6757\n",
      "[1524/1762] D loss: 1.2317, G loss: 1.1048\n",
      "[1604/1762] D loss: 1.0649, G loss: 1.1180\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.6819\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.6749\n",
      "train error: \n",
      " D loss: 1.302246, G loss: 0.827247, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 90.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.290938, G loss: 0.853987, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2008, G loss: 1.0585\n",
      "[84/1762] D loss: 1.0783, G loss: 1.0016\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6976\n",
      "[244/1762] D loss: 1.3878, G loss: 0.6834\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6882\n",
      "[404/1762] D loss: 1.3863, G loss: 0.6880\n",
      "[484/1762] D loss: 1.3865, G loss: 0.6825\n",
      "[564/1762] D loss: 1.0398, G loss: 3.9555\n",
      "[644/1762] D loss: 1.0698, G loss: 1.0681\n",
      "[724/1762] D loss: 1.3866, G loss: 0.6778\n",
      "[804/1762] D loss: 1.3865, G loss: 0.6795\n",
      "[884/1762] D loss: 1.3884, G loss: 0.6604\n",
      "[964/1762] D loss: 1.0601, G loss: 1.1593\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6896\n",
      "[1124/1762] D loss: 1.3866, G loss: 0.6811\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6890\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6887\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6884\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6917\n",
      "[1524/1762] D loss: 1.0609, G loss: 1.1542\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6925\n",
      "[1684/1762] D loss: 1.3865, G loss: 0.6932\n",
      "[1762/1762] D loss: 0.7336, G loss: 1.6131\n",
      "train error: \n",
      " D loss: 1.305998, G loss: 0.834714, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.292494, G loss: 0.865973, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3865, G loss: 0.6823\n",
      "[84/1762] D loss: 1.0752, G loss: 1.0242\n",
      "[164/1762] D loss: 1.3873, G loss: 0.7091\n",
      "[244/1762] D loss: 1.3865, G loss: 0.6826\n",
      "[324/1762] D loss: 1.3866, G loss: 0.6773\n",
      "[404/1762] D loss: 1.3863, G loss: 0.6853\n",
      "[484/1762] D loss: 1.3863, G loss: 0.6924\n",
      "[564/1762] D loss: 1.3863, G loss: 0.6942\n",
      "[644/1762] D loss: 0.7099, G loss: 5.6215\n",
      "[724/1762] D loss: 1.3873, G loss: 0.6862\n",
      "[804/1762] D loss: 1.3863, G loss: 0.6969\n",
      "[884/1762] D loss: 1.0526, G loss: 1.2753\n",
      "[964/1762] D loss: 1.3863, G loss: 0.6962\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6944\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6982\n",
      "[1204/1762] D loss: 1.3868, G loss: 0.6782\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6937\n",
      "[1364/1762] D loss: 1.8191, G loss: 0.8221\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6922\n",
      "[1524/1762] D loss: 1.3870, G loss: 0.6783\n",
      "[1604/1762] D loss: 1.3836, G loss: 0.6932\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.7003\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.6800\n",
      "train error: \n",
      " D loss: 1.313140, G loss: 0.798542, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.296622, G loss: 0.821895, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 91.1% \n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6929\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6903\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6953\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6987\n",
      "[324/1762] D loss: 1.0606, G loss: 1.1779\n",
      "[404/1762] D loss: 1.3863, G loss: 0.6946\n",
      "[484/1762] D loss: 1.0510, G loss: 1.3025\n",
      "[564/1762] D loss: 1.3860, G loss: 0.6999\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6944\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6916\n",
      "[804/1762] D loss: 1.0672, G loss: 1.1301\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6910\n",
      "[964/1762] D loss: 1.3871, G loss: 0.6755\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.6865\n",
      "[1124/1762] D loss: 1.0880, G loss: 0.9587\n",
      "[1204/1762] D loss: 1.0660, G loss: 1.0971\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6922\n",
      "[1364/1762] D loss: 1.0398, G loss: 2.7348\n",
      "[1444/1762] D loss: 1.3855, G loss: 0.7016\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.6938\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6941\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6937\n",
      "[1762/1762] D loss: 1.3860, G loss: 0.6929\n",
      "train error: \n",
      " D loss: 1.306304, G loss: 0.880753, D accuracy: 53.4%, cell accuracy: 99.9%, board accuracy: 93.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.295968, G loss: 0.914265, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3857, G loss: 0.7062\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6960\n",
      "[164/1762] D loss: 1.0619, G loss: 1.1411\n",
      "[244/1762] D loss: 1.3862, G loss: 0.6955\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6938\n",
      "[404/1762] D loss: 1.3863, G loss: 0.6934\n",
      "[484/1762] D loss: 1.0683, G loss: 1.0606\n",
      "[564/1762] D loss: 1.3865, G loss: 0.6836\n",
      "[644/1762] D loss: 1.0740, G loss: 1.0403\n",
      "[724/1762] D loss: 1.3869, G loss: 0.6827\n",
      "[804/1762] D loss: 1.0701, G loss: 1.0600\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6938\n",
      "[964/1762] D loss: 1.3865, G loss: 0.7021\n",
      "[1044/1762] D loss: 1.0400, G loss: 2.3138\n",
      "[1124/1762] D loss: 1.0579, G loss: 1.1884\n",
      "[1204/1762] D loss: 1.3865, G loss: 0.6858\n",
      "[1284/1762] D loss: 1.3865, G loss: 0.6973\n",
      "[1364/1762] D loss: 1.3870, G loss: 0.7043\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6948\n",
      "[1524/1762] D loss: 1.0517, G loss: 1.3093\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6984\n",
      "[1684/1762] D loss: 1.0486, G loss: 1.3695\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6900\n",
      "train error: \n",
      " D loss: 1.305279, G loss: 0.814094, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 93.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.294949, G loss: 0.841543, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3862, G loss: 0.6908\n",
      "[84/1762] D loss: 1.0735, G loss: 1.0536\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6915\n",
      "[244/1762] D loss: 0.7336, G loss: 1.7759\n",
      "[324/1762] D loss: 1.3866, G loss: 0.6856\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6867\n",
      "[484/1762] D loss: 1.0616, G loss: 1.1250\n",
      "[564/1762] D loss: 1.3867, G loss: 0.6928\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6900\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6933\n",
      "[804/1762] D loss: 1.0736, G loss: 1.0356\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6958\n",
      "[964/1762] D loss: 1.3925, G loss: 0.6407\n",
      "[1044/1762] D loss: 1.0569, G loss: 1.2015\n",
      "[1124/1762] D loss: 1.3774, G loss: 0.7184\n",
      "[1204/1762] D loss: 1.0481, G loss: 1.4627\n",
      "[1284/1762] D loss: 1.3873, G loss: 0.6760\n",
      "[1364/1762] D loss: 1.0518, G loss: 1.2842\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6889\n",
      "[1524/1762] D loss: 1.0581, G loss: 1.1823\n",
      "[1604/1762] D loss: 1.6568, G loss: 1.0876\n",
      "[1684/1762] D loss: 1.3867, G loss: 0.6782\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6918\n",
      "train error: \n",
      " D loss: 1.305940, G loss: 0.837322, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 93.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.296270, G loss: 0.884663, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3856, G loss: 0.6887\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6890\n",
      "[164/1762] D loss: 1.0648, G loss: 1.1238\n",
      "[244/1762] D loss: 1.3821, G loss: 0.7037\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6947\n",
      "[404/1762] D loss: 1.3840, G loss: 0.7049\n",
      "[484/1762] D loss: 1.3863, G loss: 0.6931\n",
      "[564/1762] D loss: 1.3876, G loss: 0.6807\n",
      "[644/1762] D loss: 1.3865, G loss: 0.6867\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6948\n",
      "[804/1762] D loss: 1.3863, G loss: 0.6948\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6899\n",
      "[964/1762] D loss: 1.3863, G loss: 0.6915\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6914\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6929\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6930\n",
      "[1284/1762] D loss: 1.3871, G loss: 0.7091\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6940\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6945\n",
      "[1524/1762] D loss: 1.3866, G loss: 0.7046\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6941\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6969\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6934\n",
      "train error: \n",
      " D loss: 1.306660, G loss: 0.846838, D accuracy: 53.4%, cell accuracy: 99.9%, board accuracy: 93.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.299284, G loss: 0.915559, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 91.8% \n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2330, G loss: 0.8842\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6980\n",
      "[164/1762] D loss: 1.3869, G loss: 0.7050\n",
      "[244/1762] D loss: 1.3864, G loss: 0.6997\n",
      "[324/1762] D loss: 0.7240, G loss: 1.8401\n",
      "[404/1762] D loss: 1.3871, G loss: 0.6806\n",
      "[484/1762] D loss: 1.3863, G loss: 0.6936\n",
      "[564/1762] D loss: 1.3809, G loss: 0.6995\n",
      "[644/1762] D loss: 1.3861, G loss: 0.6967\n",
      "[724/1762] D loss: 1.0622, G loss: 1.1318\n",
      "[804/1762] D loss: 1.3893, G loss: 0.7239\n",
      "[884/1762] D loss: 1.3877, G loss: 0.7169\n",
      "[964/1762] D loss: 1.3863, G loss: 0.6907\n",
      "[1044/1762] D loss: 1.3860, G loss: 0.6559\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6899\n",
      "[1204/1762] D loss: 1.0561, G loss: 1.2160\n",
      "[1284/1762] D loss: 1.3871, G loss: 0.6760\n",
      "[1364/1762] D loss: 1.3891, G loss: 0.7170\n",
      "[1444/1762] D loss: 1.0635, G loss: 1.1217\n",
      "[1524/1762] D loss: 1.3869, G loss: 0.6991\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6928\n",
      "[1684/1762] D loss: 1.3865, G loss: 0.6870\n",
      "[1762/1762] D loss: 0.7574, G loss: 1.4063\n",
      "train error: \n",
      " D loss: 1.307499, G loss: 0.799543, D accuracy: 53.4%, cell accuracy: 99.9%, board accuracy: 93.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.298895, G loss: 0.831202, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 91.6% \n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6914\n",
      "[84/1762] D loss: 1.0960, G loss: 1.0759\n",
      "[164/1762] D loss: 1.3867, G loss: 0.6825\n",
      "[244/1762] D loss: 1.0687, G loss: 1.0892\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6952\n",
      "[404/1762] D loss: 1.3869, G loss: 0.7070\n",
      "[484/1762] D loss: 1.3863, G loss: 0.6935\n",
      "[564/1762] D loss: 1.3863, G loss: 0.6947\n",
      "[644/1762] D loss: 1.3870, G loss: 0.7034\n",
      "[724/1762] D loss: 1.0682, G loss: 1.0886\n",
      "[804/1762] D loss: 1.3866, G loss: 0.6903\n",
      "[884/1762] D loss: 1.3869, G loss: 0.7045\n",
      "[964/1762] D loss: 1.6853, G loss: 1.1310\n",
      "[1044/1762] D loss: 1.0851, G loss: 0.9640\n",
      "[1124/1762] D loss: 1.0892, G loss: 0.9436\n",
      "[1204/1762] D loss: 1.0853, G loss: 0.9705\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6937\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6929\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6932\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.6966\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.7012\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6960\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6962\n",
      "train error: \n",
      " D loss: 1.306821, G loss: 0.904890, D accuracy: 53.4%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.300490, G loss: 0.946060, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 91.1% \n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6962\n",
      "[84/1762] D loss: 1.3866, G loss: 0.6838\n",
      "[164/1762] D loss: 1.3883, G loss: 0.6710\n",
      "[244/1762] D loss: 1.0593, G loss: 1.1860\n",
      "[324/1762] D loss: 1.0596, G loss: 1.1473\n",
      "[404/1762] D loss: 1.3869, G loss: 0.6792\n",
      "[484/1762] D loss: 1.3656, G loss: 0.7523\n",
      "[564/1762] D loss: 1.3877, G loss: 0.7051\n",
      "[644/1762] D loss: 1.0588, G loss: 1.1764\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6847\n",
      "[804/1762] D loss: 1.0686, G loss: 1.0657\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6845\n",
      "[964/1762] D loss: 1.4805, G loss: 1.7098\n",
      "[1044/1762] D loss: 1.0591, G loss: 1.1485\n",
      "[1124/1762] D loss: 1.3866, G loss: 0.7087\n",
      "[1204/1762] D loss: 1.0549, G loss: 1.2269\n",
      "[1284/1762] D loss: 1.1449, G loss: 2.9166\n",
      "[1364/1762] D loss: 1.1714, G loss: 0.7590\n",
      "[1444/1762] D loss: 1.3914, G loss: 0.7130\n",
      "[1524/1762] D loss: 1.3871, G loss: 0.6708\n",
      "[1604/1762] D loss: 1.3432, G loss: 1.8668\n",
      "[1684/1762] D loss: 1.3874, G loss: 0.6678\n",
      "[1762/1762] D loss: 0.7414, G loss: 1.4972\n",
      "train error: \n",
      " D loss: 1.314440, G loss: 0.774435, D accuracy: 52.6%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.301227, G loss: 0.801581, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2433, G loss: 1.2681\n",
      "[84/1762] D loss: 1.3867, G loss: 0.6840\n",
      "[164/1762] D loss: 1.3852, G loss: 0.6771\n",
      "[244/1762] D loss: 1.3867, G loss: 0.6734\n",
      "[324/1762] D loss: 1.3872, G loss: 0.6918\n",
      "[404/1762] D loss: 1.3863, G loss: 0.6917\n",
      "[484/1762] D loss: 1.3863, G loss: 0.6959\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6903\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6947\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6941\n",
      "[804/1762] D loss: 1.0511, G loss: 1.3253\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6987\n",
      "[964/1762] D loss: 1.3865, G loss: 0.7017\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.6923\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.7002\n",
      "[1204/1762] D loss: 1.2616, G loss: 1.2321\n",
      "[1284/1762] D loss: 1.3896, G loss: 0.7002\n",
      "[1364/1762] D loss: 1.0756, G loss: 1.0208\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.6931\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.6964\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6904\n",
      "[1684/1762] D loss: 1.3866, G loss: 0.6950\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6961\n",
      "train error: \n",
      " D loss: 1.308576, G loss: 0.875679, D accuracy: 52.8%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.303493, G loss: 0.910954, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6962\n",
      "[84/1762] D loss: 1.3871, G loss: 0.6742\n",
      "[164/1762] D loss: 1.9078, G loss: 1.3583\n",
      "[244/1762] D loss: 1.3879, G loss: 0.6851\n",
      "[324/1762] D loss: 1.0716, G loss: 1.0442\n",
      "[404/1762] D loss: 1.3873, G loss: 0.7089\n",
      "[484/1762] D loss: 1.3864, G loss: 0.6965\n",
      "[564/1762] D loss: 1.0655, G loss: 1.0982\n",
      "[644/1762] D loss: 1.0617, G loss: 1.1419\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6906\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6866\n",
      "[884/1762] D loss: 1.3850, G loss: 0.6825\n",
      "[964/1762] D loss: 1.0606, G loss: 1.1483\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.6880\n",
      "[1124/1762] D loss: 1.0667, G loss: 1.0924\n",
      "[1204/1762] D loss: 1.2242, G loss: 3.4032\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6890\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6928\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.6854\n",
      "[1524/1762] D loss: 1.3856, G loss: 0.6962\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6921\n",
      "[1684/1762] D loss: 1.3868, G loss: 0.7141\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6918\n",
      "train error: \n",
      " D loss: 1.309569, G loss: 0.857365, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.302668, G loss: 0.908625, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6978\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6926\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6932\n",
      "[244/1762] D loss: 1.0485, G loss: 1.3805\n",
      "[324/1762] D loss: 1.3859, G loss: 0.6722\n",
      "[404/1762] D loss: 1.3835, G loss: 0.6926\n",
      "[484/1762] D loss: 1.2921, G loss: 0.8393\n",
      "[564/1762] D loss: 1.2972, G loss: 0.9503\n",
      "[644/1762] D loss: 1.4486, G loss: 0.9122\n",
      "[724/1762] D loss: 1.3883, G loss: 0.6724\n",
      "[804/1762] D loss: 1.0437, G loss: 1.9850\n",
      "[884/1762] D loss: 1.3862, G loss: 0.6860\n",
      "[964/1762] D loss: 1.0462, G loss: 1.6625\n",
      "[1044/1762] D loss: 1.2439, G loss: 1.2152\n",
      "[1124/1762] D loss: 1.2274, G loss: 1.9225\n",
      "[1204/1762] D loss: 1.3867, G loss: 0.6739\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6825\n",
      "[1364/1762] D loss: 1.3867, G loss: 0.6839\n",
      "[1444/1762] D loss: 1.3850, G loss: 0.6992\n",
      "[1524/1762] D loss: 1.3861, G loss: 0.6873\n",
      "[1604/1762] D loss: 1.3866, G loss: 0.6824\n",
      "[1684/1762] D loss: 1.3866, G loss: 0.6780\n",
      "[1762/1762] D loss: 1.3813, G loss: 0.6858\n",
      "train error: \n",
      " D loss: 1.280692, G loss: 1.214420, D accuracy: 54.9%, cell accuracy: 99.7%, board accuracy: 85.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.258925, G loss: 1.335755, D accuracy: 56.5%, cell accuracy: 99.6%, board accuracy: 82.5% \n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3894, G loss: 0.6826\n",
      "[84/1762] D loss: 1.1218, G loss: 1.7404\n",
      "[164/1762] D loss: 1.3870, G loss: 0.6676\n",
      "[244/1762] D loss: 1.3868, G loss: 0.7061\n",
      "[324/1762] D loss: 1.3859, G loss: 0.6772\n",
      "[404/1762] D loss: 1.3883, G loss: 0.6553\n",
      "[484/1762] D loss: 1.3869, G loss: 0.6759\n",
      "[564/1762] D loss: 1.0421, G loss: 1.6923\n",
      "[644/1762] D loss: 1.3869, G loss: 0.6910\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6847\n",
      "[804/1762] D loss: 1.3866, G loss: 0.6924\n",
      "[884/1762] D loss: 1.3921, G loss: 0.7245\n",
      "[964/1762] D loss: 1.3865, G loss: 0.6919\n",
      "[1044/1762] D loss: 1.3866, G loss: 0.6922\n",
      "[1124/1762] D loss: 1.3873, G loss: 0.7041\n",
      "[1204/1762] D loss: 1.3881, G loss: 0.6637\n",
      "[1284/1762] D loss: 1.3865, G loss: 0.6804\n",
      "[1364/1762] D loss: 1.3867, G loss: 0.6969\n",
      "[1444/1762] D loss: 1.3872, G loss: 0.6741\n",
      "[1524/1762] D loss: 1.3885, G loss: 0.6943\n",
      "[1604/1762] D loss: 1.0406, G loss: 1.9279\n",
      "[1684/1762] D loss: 1.3865, G loss: 0.6925\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.6815\n",
      "train error: \n",
      " D loss: 1.288810, G loss: 1.067726, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.265387, G loss: 1.168527, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3886, G loss: 0.7010\n",
      "[84/1762] D loss: 1.3866, G loss: 0.6836\n",
      "[164/1762] D loss: 1.3865, G loss: 0.6835\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6910\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6879\n",
      "[404/1762] D loss: 1.3863, G loss: 0.6919\n",
      "[484/1762] D loss: 1.3863, G loss: 0.6916\n",
      "[564/1762] D loss: 1.3863, G loss: 0.6918\n",
      "[644/1762] D loss: 1.3864, G loss: 0.6942\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6955\n",
      "[804/1762] D loss: 0.6942, G loss: 3.4377\n",
      "[884/1762] D loss: 1.3867, G loss: 0.6890\n",
      "[964/1762] D loss: 1.3868, G loss: 0.6903\n",
      "[1044/1762] D loss: 1.0401, G loss: 2.1222\n",
      "[1124/1762] D loss: 1.3870, G loss: 0.6796\n",
      "[1204/1762] D loss: 1.0402, G loss: 2.1165\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6843\n",
      "[1364/1762] D loss: 1.3826, G loss: 0.7353\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6883\n",
      "[1524/1762] D loss: 1.3866, G loss: 0.6925\n",
      "[1604/1762] D loss: 1.3694, G loss: 0.7047\n",
      "[1684/1762] D loss: 1.3813, G loss: 0.6931\n",
      "[1762/1762] D loss: 1.3881, G loss: 0.6708\n",
      "train error: \n",
      " D loss: 1.285452, G loss: 1.133088, D accuracy: 54.4%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.257476, G loss: 1.289849, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3861, G loss: 0.6916\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6927\n",
      "[164/1762] D loss: 1.3840, G loss: 0.6923\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6930\n",
      "[324/1762] D loss: 1.0401, G loss: 2.1619\n",
      "[404/1762] D loss: 1.0402, G loss: 2.1696\n",
      "[484/1762] D loss: 1.3863, G loss: 0.6897\n",
      "[564/1762] D loss: 1.3860, G loss: 0.6954\n",
      "[644/1762] D loss: 1.0415, G loss: 1.8151\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6919\n",
      "[804/1762] D loss: 1.3863, G loss: 0.6899\n",
      "[884/1762] D loss: 0.6932, G loss: 3.9238\n",
      "[964/1762] D loss: 1.3919, G loss: 0.6375\n",
      "[1044/1762] D loss: 1.3867, G loss: 0.6982\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6861\n",
      "[1204/1762] D loss: 1.3873, G loss: 0.6761\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6932\n",
      "[1364/1762] D loss: 1.3862, G loss: 0.6780\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6917\n",
      "[1524/1762] D loss: 1.0400, G loss: 2.2389\n",
      "[1604/1762] D loss: 1.0400, G loss: 2.2119\n",
      "[1684/1762] D loss: 1.3884, G loss: 0.7135\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.6998\n",
      "train error: \n",
      " D loss: 1.284659, G loss: 1.131623, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.256944, G loss: 1.283931, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3894, G loss: 0.7154\n",
      "[84/1762] D loss: 1.3804, G loss: 0.7115\n",
      "[164/1762] D loss: 1.0399, G loss: 2.4231\n",
      "[244/1762] D loss: 1.0401, G loss: 2.3659\n",
      "[324/1762] D loss: 1.3864, G loss: 0.6855\n",
      "[404/1762] D loss: 1.3863, G loss: 0.6909\n",
      "[484/1762] D loss: 1.3874, G loss: 0.7093\n",
      "[564/1762] D loss: 1.3865, G loss: 0.6862\n",
      "[644/1762] D loss: 1.3867, G loss: 0.7014\n",
      "[724/1762] D loss: 1.3856, G loss: 0.6908\n",
      "[804/1762] D loss: 1.3863, G loss: 0.6873\n",
      "[884/1762] D loss: 1.0399, G loss: 2.3333\n",
      "[964/1762] D loss: 1.3863, G loss: 0.6918\n",
      "[1044/1762] D loss: 1.3869, G loss: 0.6807\n",
      "[1124/1762] D loss: 1.0401, G loss: 2.2963\n",
      "[1204/1762] D loss: 1.0399, G loss: 2.2783\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6917\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6933\n",
      "[1444/1762] D loss: 1.0404, G loss: 2.1344\n",
      "[1524/1762] D loss: 1.3877, G loss: 0.6788\n",
      "[1604/1762] D loss: 1.0399, G loss: 2.5573\n",
      "[1684/1762] D loss: 1.0408, G loss: 2.3439\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6895\n",
      "train error: \n",
      " D loss: 1.280193, G loss: 1.216443, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 87.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.256788, G loss: 1.334983, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0399, G loss: 2.5485\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6867\n",
      "[164/1762] D loss: 1.3864, G loss: 0.6853\n",
      "[244/1762] D loss: 1.3083, G loss: 0.7481\n",
      "[324/1762] D loss: 1.3405, G loss: 0.7840\n",
      "[404/1762] D loss: 1.3880, G loss: 0.7241\n",
      "[484/1762] D loss: 1.3865, G loss: 0.6766\n",
      "[564/1762] D loss: 1.3868, G loss: 0.6703\n",
      "[644/1762] D loss: 1.3969, G loss: 0.6151\n",
      "[724/1762] D loss: 1.3874, G loss: 0.7012\n",
      "[804/1762] D loss: 1.0404, G loss: 3.1571\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6822\n",
      "[964/1762] D loss: 1.3876, G loss: 0.6684\n",
      "[1044/1762] D loss: 1.0439, G loss: 1.8609\n",
      "[1124/1762] D loss: 1.0408, G loss: 1.9010\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6881\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6890\n",
      "[1364/1762] D loss: 1.0406, G loss: 1.9497\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6902\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.6917\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6922\n",
      "[1684/1762] D loss: 1.0415, G loss: 2.1577\n",
      "[1762/1762] D loss: 1.3897, G loss: 0.6527\n",
      "train error: \n",
      " D loss: 1.287084, G loss: 1.186289, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.260882, G loss: 1.253853, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6919\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6933\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6931\n",
      "[244/1762] D loss: 1.3877, G loss: 0.7275\n",
      "[324/1762] D loss: 1.0401, G loss: 2.1879\n",
      "[404/1762] D loss: 1.0404, G loss: 2.1114\n",
      "[484/1762] D loss: 1.3863, G loss: 0.6914\n",
      "[564/1762] D loss: 1.3859, G loss: 0.6954\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6923\n",
      "[724/1762] D loss: 1.3492, G loss: 0.7473\n",
      "[804/1762] D loss: 1.3858, G loss: 0.6902\n",
      "[884/1762] D loss: 1.3855, G loss: 0.6928\n",
      "[964/1762] D loss: 1.3830, G loss: 0.6778\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6943\n",
      "[1124/1762] D loss: 1.0399, G loss: 2.3413\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.7014\n",
      "[1284/1762] D loss: 1.0401, G loss: 2.1784\n",
      "[1364/1762] D loss: 1.0172, G loss: 7.1186\n",
      "[1444/1762] D loss: 1.3604, G loss: 0.7392\n",
      "[1524/1762] D loss: 1.2100, G loss: 3.9185\n",
      "[1604/1762] D loss: 1.3865, G loss: 0.6796\n",
      "[1684/1762] D loss: 1.3188, G loss: 0.7990\n",
      "[1762/1762] D loss: 0.6948, G loss: 3.5287\n",
      "train error: \n",
      " D loss: 1.272977, G loss: 1.493358, D accuracy: 55.4%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.264171, G loss: 1.541720, D accuracy: 56.2%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3865, G loss: 0.6786\n",
      "[84/1762] D loss: 1.3834, G loss: 0.6848\n",
      "[164/1762] D loss: 1.0401, G loss: 2.2825\n",
      "[244/1762] D loss: 1.3870, G loss: 0.6925\n",
      "[324/1762] D loss: 1.2163, G loss: 4.7006\n",
      "[404/1762] D loss: 1.3868, G loss: 0.6908\n",
      "[484/1762] D loss: 1.3865, G loss: 0.6782\n",
      "[564/1762] D loss: 1.3865, G loss: 0.6792\n",
      "[644/1762] D loss: 1.3865, G loss: 0.6782\n",
      "[724/1762] D loss: 1.1962, G loss: 7.9723\n",
      "[804/1762] D loss: 1.0406, G loss: 1.9736\n",
      "[884/1762] D loss: 1.3865, G loss: 0.6876\n",
      "[964/1762] D loss: 1.3799, G loss: 0.7098\n",
      "[1044/1762] D loss: 1.3867, G loss: 0.6745\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.6816\n",
      "[1204/1762] D loss: 1.3877, G loss: 0.6533\n",
      "[1284/1762] D loss: 1.3856, G loss: 0.6949\n",
      "[1364/1762] D loss: 1.0403, G loss: 2.0572\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6871\n",
      "[1524/1762] D loss: 1.3891, G loss: 0.6635\n",
      "[1604/1762] D loss: 1.3859, G loss: 0.6608\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6881\n",
      "[1762/1762] D loss: 1.3868, G loss: 0.7048\n",
      "train error: \n",
      " D loss: 1.273048, G loss: 1.735609, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.252301, G loss: 1.993022, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3887, G loss: 0.6663\n",
      "[84/1762] D loss: 1.3868, G loss: 0.6978\n",
      "[164/1762] D loss: 1.3900, G loss: 0.6409\n",
      "[244/1762] D loss: 1.0406, G loss: 2.1532\n",
      "[324/1762] D loss: 1.2120, G loss: 6.1710\n",
      "[404/1762] D loss: 1.3850, G loss: 0.7008\n",
      "[484/1762] D loss: 1.0402, G loss: 2.1068\n",
      "[564/1762] D loss: 1.3144, G loss: 0.8137\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6906\n",
      "[724/1762] D loss: 1.0400, G loss: 2.2457\n",
      "[804/1762] D loss: 1.0400, G loss: 2.2448\n",
      "[884/1762] D loss: 1.3529, G loss: 0.7428\n",
      "[964/1762] D loss: 1.0400, G loss: 2.2191\n",
      "[1044/1762] D loss: 0.6967, G loss: 3.2455\n",
      "[1124/1762] D loss: 1.3882, G loss: 0.6850\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6814\n",
      "[1284/1762] D loss: 1.0398, G loss: 4.3323\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6878\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6930\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.6894\n",
      "[1604/1762] D loss: 1.3865, G loss: 0.7022\n",
      "[1684/1762] D loss: 0.7009, G loss: 3.7991\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6866\n",
      "train error: \n",
      " D loss: 1.287231, G loss: 1.169850, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.259044, G loss: 1.296550, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6867\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6916\n",
      "[164/1762] D loss: 1.0400, G loss: 2.2734\n",
      "[244/1762] D loss: 1.3862, G loss: 0.7105\n",
      "[324/1762] D loss: 1.3857, G loss: 0.6845\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6970\n",
      "[484/1762] D loss: 1.3862, G loss: 0.6910\n",
      "[564/1762] D loss: 1.2082, G loss: 1.9258\n",
      "[644/1762] D loss: 1.0399, G loss: 2.3972\n",
      "[724/1762] D loss: 1.0402, G loss: 2.3159\n",
      "[804/1762] D loss: 1.3863, G loss: 0.6926\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6927\n",
      "[964/1762] D loss: 1.3863, G loss: 0.6928\n",
      "[1044/1762] D loss: 1.3870, G loss: 0.6805\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6870\n",
      "[1204/1762] D loss: 1.3866, G loss: 0.7100\n",
      "[1284/1762] D loss: 1.3871, G loss: 0.6776\n",
      "[1364/1762] D loss: 1.3865, G loss: 0.6770\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6944\n",
      "[1524/1762] D loss: 1.0402, G loss: 2.4777\n",
      "[1604/1762] D loss: 1.0403, G loss: 2.4763\n",
      "[1684/1762] D loss: 0.6934, G loss: 4.1993\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6920\n",
      "train error: \n",
      " D loss: 1.283823, G loss: 1.270982, D accuracy: 54.4%, cell accuracy: 99.9%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.258016, G loss: 1.364168, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0399, G loss: 2.2757\n",
      "[84/1762] D loss: 1.3789, G loss: 0.6980\n",
      "[164/1762] D loss: 1.3870, G loss: 0.7101\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6938\n",
      "[324/1762] D loss: 1.3867, G loss: 0.6799\n",
      "[404/1762] D loss: 1.3863, G loss: 0.6935\n",
      "[484/1762] D loss: 1.0544, G loss: 2.7311\n",
      "[564/1762] D loss: 1.0398, G loss: 2.7048\n",
      "[644/1762] D loss: 1.3860, G loss: 0.6932\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6965\n",
      "[804/1762] D loss: 1.3769, G loss: 0.6977\n",
      "[884/1762] D loss: 0.6932, G loss: 8.3164\n",
      "[964/1762] D loss: 1.3839, G loss: 0.6773\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6926\n",
      "[1124/1762] D loss: 1.3850, G loss: 0.7074\n",
      "[1204/1762] D loss: 1.0402, G loss: 2.5846\n",
      "[1284/1762] D loss: 1.3740, G loss: 0.7033\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6921\n",
      "[1444/1762] D loss: 1.3853, G loss: 0.6925\n",
      "[1524/1762] D loss: 1.0398, G loss: 2.8169\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6906\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6911\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6914\n",
      "train error: \n",
      " D loss: 1.289785, G loss: 1.329864, D accuracy: 54.1%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.263554, G loss: 1.475118, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3837, G loss: 0.7032\n",
      "[84/1762] D loss: 1.3824, G loss: 0.6870\n",
      "[164/1762] D loss: 1.3849, G loss: 0.6876\n",
      "[244/1762] D loss: 1.0411, G loss: 2.1058\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6918\n",
      "[404/1762] D loss: 1.3866, G loss: 0.6823\n",
      "[484/1762] D loss: 1.3863, G loss: 0.6899\n",
      "[564/1762] D loss: 1.3863, G loss: 0.6888\n",
      "[644/1762] D loss: 1.3879, G loss: 0.7193\n",
      "[724/1762] D loss: 1.3865, G loss: 0.6888\n",
      "[804/1762] D loss: 0.6932, G loss: 5.0056\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6908\n",
      "[964/1762] D loss: 1.0402, G loss: 4.1019\n",
      "[1044/1762] D loss: 1.0402, G loss: 6.6906\n",
      "[1124/1762] D loss: 1.3571, G loss: 0.7255\n",
      "[1204/1762] D loss: 1.3868, G loss: 0.6819\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6807\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6924\n",
      "[1444/1762] D loss: 1.3860, G loss: 0.6873\n",
      "[1524/1762] D loss: 1.3816, G loss: 0.6829\n",
      "[1604/1762] D loss: 1.3861, G loss: 0.6990\n",
      "[1684/1762] D loss: 1.3853, G loss: 0.7062\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6934\n",
      "train error: \n",
      " D loss: 1.286415, G loss: 1.534668, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.256102, G loss: 1.700340, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3866, G loss: 0.7029\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6906\n",
      "[164/1762] D loss: 1.3847, G loss: 0.7099\n",
      "[244/1762] D loss: 1.3876, G loss: 0.6725\n",
      "[324/1762] D loss: 1.3876, G loss: 0.6633\n",
      "[404/1762] D loss: 1.3860, G loss: 0.6941\n",
      "[484/1762] D loss: 1.3863, G loss: 0.6935\n",
      "[564/1762] D loss: 1.0398, G loss: 2.6144\n",
      "[644/1762] D loss: 1.3859, G loss: 0.6967\n",
      "[724/1762] D loss: 1.3785, G loss: 0.6910\n",
      "[804/1762] D loss: 1.3863, G loss: 0.6942\n",
      "[884/1762] D loss: 1.0398, G loss: 2.5604\n",
      "[964/1762] D loss: 1.3795, G loss: 0.7019\n",
      "[1044/1762] D loss: 1.0399, G loss: 2.7655\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6916\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6907\n",
      "[1284/1762] D loss: 1.0398, G loss: 2.5530\n",
      "[1364/1762] D loss: 1.3855, G loss: 0.6922\n",
      "[1444/1762] D loss: 1.3862, G loss: 0.6991\n",
      "[1524/1762] D loss: 1.3848, G loss: 0.6975\n",
      "[1604/1762] D loss: 1.3856, G loss: 0.6890\n",
      "[1684/1762] D loss: 1.3783, G loss: 0.6759\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6925\n",
      "train error: \n",
      " D loss: 1.270054, G loss: 1.450774, D accuracy: 56.4%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.243650, G loss: 1.592529, D accuracy: 57.4%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6928\n",
      "[84/1762] D loss: 1.3845, G loss: 0.7073\n",
      "[164/1762] D loss: 1.3773, G loss: 0.7002\n",
      "[244/1762] D loss: 1.3861, G loss: 0.6830\n",
      "[324/1762] D loss: 1.3312, G loss: 0.6351\n",
      "[404/1762] D loss: 1.3778, G loss: 0.6688\n",
      "[484/1762] D loss: 1.3868, G loss: 0.6832\n",
      "[564/1762] D loss: 1.3992, G loss: 0.6719\n",
      "[644/1762] D loss: 1.3861, G loss: 0.6953\n",
      "[724/1762] D loss: 1.4027, G loss: 0.6380\n",
      "[804/1762] D loss: 0.6935, G loss: 4.2552\n",
      "[884/1762] D loss: 1.3951, G loss: 0.6462\n",
      "[964/1762] D loss: 1.3864, G loss: 0.6833\n",
      "[1044/1762] D loss: 1.3856, G loss: 0.6569\n",
      "[1124/1762] D loss: 1.0410, G loss: 2.2703\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6825\n",
      "[1284/1762] D loss: 1.0415, G loss: 2.2236\n",
      "[1364/1762] D loss: 1.3860, G loss: 0.6878\n",
      "[1444/1762] D loss: 1.3872, G loss: 0.7032\n",
      "[1524/1762] D loss: 1.3719, G loss: 0.7028\n",
      "[1604/1762] D loss: 1.3862, G loss: 0.6899\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6890\n",
      "[1762/1762] D loss: 1.3868, G loss: 0.6685\n",
      "train error: \n",
      " D loss: 1.283908, G loss: 1.256685, D accuracy: 54.4%, cell accuracy: 99.9%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.257048, G loss: 1.364809, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0406, G loss: 2.3868\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6892\n",
      "[164/1762] D loss: 1.0399, G loss: 2.3423\n",
      "[244/1762] D loss: 1.3857, G loss: 0.6982\n",
      "[324/1762] D loss: 1.0404, G loss: 2.3083\n",
      "[404/1762] D loss: 0.6945, G loss: 3.8437\n",
      "[484/1762] D loss: 1.3868, G loss: 0.6575\n",
      "[564/1762] D loss: 1.3862, G loss: 0.6919\n",
      "[644/1762] D loss: 1.3858, G loss: 0.6951\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6897\n",
      "[804/1762] D loss: 1.3873, G loss: 0.7100\n",
      "[884/1762] D loss: 1.3789, G loss: 0.6989\n",
      "[964/1762] D loss: 1.3863, G loss: 0.6892\n",
      "[1044/1762] D loss: 1.3861, G loss: 0.6799\n",
      "[1124/1762] D loss: 1.3871, G loss: 0.6779\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6900\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6914\n",
      "[1364/1762] D loss: 1.3867, G loss: 0.6953\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6907\n",
      "[1524/1762] D loss: 0.6939, G loss: 3.9820\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6918\n",
      "[1684/1762] D loss: 1.0409, G loss: 2.4253\n",
      "[1762/1762] D loss: 1.3859, G loss: 0.6812\n",
      "train error: \n",
      " D loss: 1.285445, G loss: 1.177322, D accuracy: 54.0%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.257656, G loss: 1.339978, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6927\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6926\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6930\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6930\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6931\n",
      "[404/1762] D loss: 1.3861, G loss: 0.7046\n",
      "[484/1762] D loss: 1.3856, G loss: 0.6784\n",
      "[564/1762] D loss: 1.0398, G loss: 2.4443\n",
      "[644/1762] D loss: 1.2421, G loss: 0.9081\n",
      "[724/1762] D loss: 1.3883, G loss: 0.6654\n",
      "[804/1762] D loss: 1.3863, G loss: 0.6918\n",
      "[884/1762] D loss: 1.0400, G loss: 2.6504\n",
      "[964/1762] D loss: 1.3876, G loss: 0.6767\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6926\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6935\n",
      "[1204/1762] D loss: 1.0412, G loss: 2.5485\n",
      "[1284/1762] D loss: 1.0419, G loss: 2.5485\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6919\n",
      "[1444/1762] D loss: 1.3868, G loss: 0.6970\n",
      "[1524/1762] D loss: 1.3818, G loss: 0.7061\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6912\n",
      "[1684/1762] D loss: 1.3873, G loss: 0.6720\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6907\n",
      "train error: \n",
      " D loss: 1.285791, G loss: 1.237225, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.258359, G loss: 1.368919, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6907\n",
      "[84/1762] D loss: 1.0398, G loss: 2.6314\n",
      "[164/1762] D loss: 1.3882, G loss: 0.7052\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6888\n",
      "[324/1762] D loss: 1.3833, G loss: 0.7104\n",
      "[404/1762] D loss: 1.0398, G loss: 2.6522\n",
      "[484/1762] D loss: 1.3860, G loss: 0.6955\n",
      "[564/1762] D loss: 1.3862, G loss: 0.6920\n",
      "[644/1762] D loss: 1.0398, G loss: 2.6812\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6923\n",
      "[804/1762] D loss: 1.3866, G loss: 0.7010\n",
      "[884/1762] D loss: 1.3872, G loss: 0.6754\n",
      "[964/1762] D loss: 1.3863, G loss: 0.6927\n",
      "[1044/1762] D loss: 1.0397, G loss: 2.7489\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.6901\n",
      "[1204/1762] D loss: 1.0395, G loss: 2.6633\n",
      "[1284/1762] D loss: 1.3910, G loss: 0.6591\n",
      "[1364/1762] D loss: 1.3946, G loss: 0.6417\n",
      "[1444/1762] D loss: 1.4071, G loss: 0.6291\n",
      "[1524/1762] D loss: 1.0423, G loss: 3.6825\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6897\n",
      "[1684/1762] D loss: 1.3844, G loss: 0.7083\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6854\n",
      "train error: \n",
      " D loss: 1.284225, G loss: 1.279169, D accuracy: 54.2%, cell accuracy: 99.9%, board accuracy: 90.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.257028, G loss: 1.436904, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3866, G loss: 0.6770\n",
      "[84/1762] D loss: 1.0400, G loss: 2.2470\n",
      "[164/1762] D loss: 1.0400, G loss: 2.2483\n",
      "[244/1762] D loss: 1.3868, G loss: 0.7059\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6897\n",
      "[404/1762] D loss: 1.3863, G loss: 0.6909\n",
      "[484/1762] D loss: 1.3816, G loss: 0.6979\n",
      "[564/1762] D loss: 1.3862, G loss: 0.6845\n",
      "[644/1762] D loss: 1.0404, G loss: 2.6019\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6924\n",
      "[804/1762] D loss: 1.3588, G loss: 0.7354\n",
      "[884/1762] D loss: 1.3844, G loss: 0.7003\n",
      "[964/1762] D loss: 1.0449, G loss: 2.6814\n",
      "[1044/1762] D loss: 1.3876, G loss: 0.7115\n",
      "[1124/1762] D loss: 1.3869, G loss: 0.6745\n",
      "[1204/1762] D loss: 1.0398, G loss: 2.6966\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6900\n",
      "[1364/1762] D loss: 1.0398, G loss: 2.7310\n",
      "[1444/1762] D loss: 1.3867, G loss: 0.6854\n",
      "[1524/1762] D loss: 1.0399, G loss: 2.6146\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6915\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6912\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6928\n",
      "train error: \n",
      " D loss: 1.285346, G loss: 1.261016, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.258315, G loss: 1.401951, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3834, G loss: 0.6944\n",
      "[84/1762] D loss: 1.3860, G loss: 0.7039\n",
      "[164/1762] D loss: 1.3860, G loss: 0.6953\n",
      "[244/1762] D loss: 1.0398, G loss: 2.5879\n",
      "[324/1762] D loss: 1.3872, G loss: 0.6578\n",
      "[404/1762] D loss: 1.0398, G loss: 2.5831\n",
      "[484/1762] D loss: 2.4541, G loss: 2.9665\n",
      "[564/1762] D loss: 1.0408, G loss: 2.1396\n",
      "[644/1762] D loss: 1.3866, G loss: 0.7032\n",
      "[724/1762] D loss: 1.3893, G loss: 0.6681\n",
      "[804/1762] D loss: 1.3863, G loss: 0.6919\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6935\n",
      "[964/1762] D loss: 1.3865, G loss: 0.7000\n",
      "[1044/1762] D loss: 1.0408, G loss: 2.0765\n",
      "[1124/1762] D loss: 1.3872, G loss: 0.7102\n",
      "[1204/1762] D loss: 1.3878, G loss: 0.7203\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6893\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6902\n",
      "[1444/1762] D loss: 1.3810, G loss: 0.6991\n",
      "[1524/1762] D loss: 1.3865, G loss: 0.6967\n",
      "[1604/1762] D loss: 1.3865, G loss: 0.6880\n",
      "[1684/1762] D loss: 1.3866, G loss: 0.7014\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6914\n",
      "train error: \n",
      " D loss: 1.289506, G loss: 1.137894, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.261738, G loss: 1.266450, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3867, G loss: 0.6821\n",
      "[84/1762] D loss: 1.3865, G loss: 0.6845\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6948\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6936\n",
      "[324/1762] D loss: 1.3866, G loss: 0.6916\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6919\n",
      "[484/1762] D loss: 1.3863, G loss: 0.6907\n",
      "[564/1762] D loss: 1.3863, G loss: 0.6908\n",
      "[644/1762] D loss: 1.0400, G loss: 2.1995\n",
      "[724/1762] D loss: 1.3867, G loss: 0.6987\n",
      "[804/1762] D loss: 1.3863, G loss: 0.6912\n",
      "[884/1762] D loss: 0.6961, G loss: 3.8423\n",
      "[964/1762] D loss: 1.3863, G loss: 0.6962\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.6999\n",
      "[1124/1762] D loss: 1.0399, G loss: 2.3166\n",
      "[1204/1762] D loss: 1.3865, G loss: 0.6856\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6996\n",
      "[1364/1762] D loss: 1.3866, G loss: 0.6824\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6945\n",
      "[1524/1762] D loss: 1.1855, G loss: 2.6760\n",
      "[1604/1762] D loss: 1.0418, G loss: 2.5459\n",
      "[1684/1762] D loss: 1.3818, G loss: 0.7013\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6886\n",
      "train error: \n",
      " D loss: 1.294104, G loss: 1.157913, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.272313, G loss: 1.298888, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0467, G loss: 2.3240\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6981\n",
      "[164/1762] D loss: 1.3838, G loss: 0.6767\n",
      "[244/1762] D loss: 1.3864, G loss: 0.6975\n",
      "[324/1762] D loss: 1.3864, G loss: 0.6901\n",
      "[404/1762] D loss: 1.3865, G loss: 0.6938\n",
      "[484/1762] D loss: 0.6934, G loss: 4.1247\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6986\n",
      "[644/1762] D loss: 1.3864, G loss: 0.6883\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6889\n",
      "[804/1762] D loss: 1.0400, G loss: 2.3313\n",
      "[884/1762] D loss: 1.0405, G loss: 2.3217\n",
      "[964/1762] D loss: 1.3871, G loss: 0.6850\n",
      "[1044/1762] D loss: 1.3873, G loss: 0.7164\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.7007\n",
      "[1204/1762] D loss: 1.3866, G loss: 0.6883\n",
      "[1284/1762] D loss: 1.3875, G loss: 0.7271\n",
      "[1364/1762] D loss: 1.1056, G loss: 0.8746\n",
      "[1444/1762] D loss: 1.3869, G loss: 0.7063\n",
      "[1524/1762] D loss: 1.3870, G loss: 0.6999\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6888\n",
      "[1684/1762] D loss: 1.0644, G loss: 1.1063\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6833\n",
      "train error: \n",
      " D loss: 1.300033, G loss: 0.911705, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 90.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.294209, G loss: 0.962311, D accuracy: 54.1%, cell accuracy: 99.7%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6894\n",
      "[84/1762] D loss: 1.1960, G loss: 1.4285\n",
      "[164/1762] D loss: 0.7470, G loss: 1.5065\n",
      "[244/1762] D loss: 1.0521, G loss: 1.2807\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6885\n",
      "[404/1762] D loss: 0.9120, G loss: 1.9246\n",
      "[484/1762] D loss: 1.2312, G loss: 1.1821\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6806\n",
      "[644/1762] D loss: 1.3866, G loss: 0.6783\n",
      "[724/1762] D loss: 0.8412, G loss: 3.3184\n",
      "[804/1762] D loss: 1.3866, G loss: 0.6904\n",
      "[884/1762] D loss: 0.9062, G loss: 1.1304\n",
      "[964/1762] D loss: 0.7888, G loss: 2.4182\n",
      "[1044/1762] D loss: 1.0419, G loss: 2.6445\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.6833\n",
      "[1204/1762] D loss: 1.3868, G loss: 0.6725\n",
      "[1284/1762] D loss: 1.3876, G loss: 0.6716\n",
      "[1364/1762] D loss: 1.3867, G loss: 0.6989\n",
      "[1444/1762] D loss: 1.0556, G loss: 1.3213\n",
      "[1524/1762] D loss: 1.0495, G loss: 1.3573\n",
      "[1604/1762] D loss: 0.7179, G loss: 1.9985\n",
      "[1684/1762] D loss: 1.3869, G loss: 0.6757\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.7062\n",
      "train error: \n",
      " D loss: 1.300881, G loss: 0.868693, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.291864, G loss: 0.912356, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2234, G loss: 1.2465\n",
      "[84/1762] D loss: 1.3906, G loss: 0.6428\n",
      "[164/1762] D loss: 1.4308, G loss: 0.8377\n",
      "[244/1762] D loss: 1.0485, G loss: 1.4104\n",
      "[324/1762] D loss: 1.0480, G loss: 1.4505\n",
      "[404/1762] D loss: 1.2258, G loss: 1.2195\n",
      "[484/1762] D loss: 1.0685, G loss: 1.1423\n",
      "[564/1762] D loss: 1.0520, G loss: 1.2866\n",
      "[644/1762] D loss: 1.3865, G loss: 0.6803\n",
      "[724/1762] D loss: 1.0554, G loss: 1.2463\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6803\n",
      "[884/1762] D loss: 1.0553, G loss: 1.1997\n",
      "[964/1762] D loss: 1.3891, G loss: 0.7073\n",
      "[1044/1762] D loss: 1.0601, G loss: 1.1497\n",
      "[1124/1762] D loss: 1.0540, G loss: 1.2384\n",
      "[1204/1762] D loss: 1.8441, G loss: 1.2779\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6883\n",
      "[1364/1762] D loss: 1.3868, G loss: 0.6950\n",
      "[1444/1762] D loss: 1.0610, G loss: 1.1481\n",
      "[1524/1762] D loss: 1.3871, G loss: 0.6803\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6823\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.6822\n",
      "[1762/1762] D loss: 0.7595, G loss: 1.4090\n",
      "train error: \n",
      " D loss: 1.299299, G loss: 0.827653, D accuracy: 54.0%, cell accuracy: 99.9%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.293368, G loss: 0.859925, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0696, G loss: 1.0653\n",
      "[84/1762] D loss: 1.0628, G loss: 1.1209\n",
      "[164/1762] D loss: 1.3864, G loss: 0.6817\n",
      "[244/1762] D loss: 0.7376, G loss: 1.5941\n",
      "[324/1762] D loss: 1.3878, G loss: 0.6663\n",
      "[404/1762] D loss: 1.0989, G loss: 0.9048\n",
      "[484/1762] D loss: 1.3865, G loss: 0.6782\n",
      "[564/1762] D loss: 1.1977, G loss: 1.3038\n",
      "[644/1762] D loss: 1.3865, G loss: 0.6796\n",
      "[724/1762] D loss: 1.0469, G loss: 1.4142\n",
      "[804/1762] D loss: 1.5075, G loss: 1.8914\n",
      "[884/1762] D loss: 1.3866, G loss: 0.6775\n",
      "[964/1762] D loss: 1.3866, G loss: 0.6773\n",
      "[1044/1762] D loss: 1.3865, G loss: 0.6791\n",
      "[1124/1762] D loss: 1.3871, G loss: 0.6702\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6823\n",
      "[1284/1762] D loss: 1.3867, G loss: 0.6969\n",
      "[1364/1762] D loss: 1.3865, G loss: 0.6787\n",
      "[1444/1762] D loss: 1.0628, G loss: 1.1233\n",
      "[1524/1762] D loss: 1.3871, G loss: 0.6786\n",
      "[1604/1762] D loss: 1.3878, G loss: 0.6677\n",
      "[1684/1762] D loss: 1.3868, G loss: 0.6886\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6817\n",
      "train error: \n",
      " D loss: 1.297056, G loss: 0.936701, D accuracy: 54.3%, cell accuracy: 99.9%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.294682, G loss: 0.995746, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6904\n",
      "[84/1762] D loss: 1.3865, G loss: 0.6799\n",
      "[164/1762] D loss: 1.3865, G loss: 0.6808\n",
      "[244/1762] D loss: 1.0536, G loss: 1.2379\n",
      "[324/1762] D loss: 1.3865, G loss: 0.6806\n",
      "[404/1762] D loss: 1.2200, G loss: 1.3384\n",
      "[484/1762] D loss: 1.3865, G loss: 0.6803\n",
      "[564/1762] D loss: 1.0469, G loss: 1.4320\n",
      "[644/1762] D loss: 1.3864, G loss: 0.6813\n",
      "[724/1762] D loss: 1.2175, G loss: 1.4040\n",
      "[804/1762] D loss: 1.3865, G loss: 0.6868\n",
      "[884/1762] D loss: 1.3742, G loss: 0.6953\n",
      "[964/1762] D loss: 1.6336, G loss: 0.9557\n",
      "[1044/1762] D loss: 1.1150, G loss: 0.8854\n",
      "[1124/1762] D loss: 1.3866, G loss: 0.6817\n",
      "[1204/1762] D loss: 1.3867, G loss: 0.6797\n",
      "[1284/1762] D loss: 1.2169, G loss: 1.3921\n",
      "[1364/1762] D loss: 1.6560, G loss: 1.0811\n",
      "[1444/1762] D loss: 1.3866, G loss: 0.6788\n",
      "[1524/1762] D loss: 1.0607, G loss: 1.1806\n",
      "[1604/1762] D loss: 1.3870, G loss: 0.6869\n",
      "[1684/1762] D loss: 1.0508, G loss: 1.2992\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.6803\n",
      "train error: \n",
      " D loss: 1.298843, G loss: 0.881627, D accuracy: 54.2%, cell accuracy: 99.9%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.299795, G loss: 0.927467, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3865, G loss: 0.6787\n",
      "[84/1762] D loss: 1.0907, G loss: 0.9221\n",
      "[164/1762] D loss: 0.9398, G loss: 1.4081\n",
      "[244/1762] D loss: 1.3864, G loss: 0.6809\n",
      "[324/1762] D loss: 1.3865, G loss: 0.6802\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6811\n",
      "[484/1762] D loss: 1.0688, G loss: 1.0708\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6814\n",
      "[644/1762] D loss: 1.3864, G loss: 0.6857\n",
      "[724/1762] D loss: 1.3865, G loss: 0.6913\n",
      "[804/1762] D loss: 1.3839, G loss: 0.6976\n",
      "[884/1762] D loss: 1.2156, G loss: 1.5029\n",
      "[964/1762] D loss: 1.3866, G loss: 0.6770\n",
      "[1044/1762] D loss: 1.0406, G loss: 2.1317\n",
      "[1124/1762] D loss: 1.3866, G loss: 0.6832\n",
      "[1204/1762] D loss: 0.8902, G loss: 2.4171\n",
      "[1284/1762] D loss: 1.0421, G loss: 1.9433\n",
      "[1364/1762] D loss: 1.3866, G loss: 0.6887\n",
      "[1444/1762] D loss: 1.0410, G loss: 2.0341\n",
      "[1524/1762] D loss: 1.3865, G loss: 0.6806\n",
      "[1604/1762] D loss: 0.6943, G loss: 3.4007\n",
      "[1684/1762] D loss: 1.3865, G loss: 0.6906\n",
      "[1762/1762] D loss: 1.0608, G loss: 1.8233\n",
      "train error: \n",
      " D loss: 1.280831, G loss: 1.109863, D accuracy: 54.3%, cell accuracy: 99.9%, board accuracy: 90.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.261769, G loss: 1.212235, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0403, G loss: 2.0846\n",
      "[84/1762] D loss: 1.3865, G loss: 0.6812\n",
      "[164/1762] D loss: 1.3865, G loss: 0.6793\n",
      "[244/1762] D loss: 1.3865, G loss: 0.6827\n",
      "[324/1762] D loss: 1.3864, G loss: 0.6815\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6843\n",
      "[484/1762] D loss: 1.3846, G loss: 0.6914\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6951\n",
      "[644/1762] D loss: 1.3860, G loss: 0.6901\n",
      "[724/1762] D loss: 1.0423, G loss: 1.6773\n",
      "[804/1762] D loss: 1.0438, G loss: 1.7669\n",
      "[884/1762] D loss: 1.0407, G loss: 1.9296\n",
      "[964/1762] D loss: 1.0412, G loss: 1.8218\n",
      "[1044/1762] D loss: 2.4849, G loss: 1.6855\n",
      "[1124/1762] D loss: 1.3867, G loss: 0.7038\n",
      "[1204/1762] D loss: 1.1036, G loss: 0.9317\n",
      "[1284/1762] D loss: 1.0990, G loss: 0.8965\n",
      "[1364/1762] D loss: 1.3866, G loss: 0.6819\n",
      "[1444/1762] D loss: 1.0501, G loss: 1.8544\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.6836\n",
      "[1604/1762] D loss: 1.3865, G loss: 0.6765\n",
      "[1684/1762] D loss: 1.3874, G loss: 0.6818\n",
      "[1762/1762] D loss: 0.7175, G loss: 1.9147\n",
      "train error: \n",
      " D loss: 1.289371, G loss: 1.016017, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.289142, G loss: 1.087580, D accuracy: 55.7%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6820\n",
      "[84/1762] D loss: 1.2109, G loss: 1.8559\n",
      "[164/1762] D loss: 1.3865, G loss: 0.6975\n",
      "[244/1762] D loss: 1.3875, G loss: 0.6667\n",
      "[324/1762] D loss: 1.0559, G loss: 1.2088\n",
      "[404/1762] D loss: 1.3866, G loss: 0.6849\n",
      "[484/1762] D loss: 1.0575, G loss: 1.1869\n",
      "[564/1762] D loss: 1.3868, G loss: 0.6926\n",
      "[644/1762] D loss: 1.3897, G loss: 0.7087\n",
      "[724/1762] D loss: 1.3866, G loss: 0.6907\n",
      "[804/1762] D loss: 1.0538, G loss: 1.2442\n",
      "[884/1762] D loss: 1.3931, G loss: 0.7613\n",
      "[964/1762] D loss: 1.0542, G loss: 1.2157\n",
      "[1044/1762] D loss: 1.0400, G loss: 2.9032\n",
      "[1124/1762] D loss: 1.3866, G loss: 0.6887\n",
      "[1204/1762] D loss: 1.3866, G loss: 0.6775\n",
      "[1284/1762] D loss: 1.3866, G loss: 0.6913\n",
      "[1364/1762] D loss: 1.3865, G loss: 0.6867\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.6907\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.6827\n",
      "[1604/1762] D loss: 1.3866, G loss: 0.6793\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.6845\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6878\n",
      "train error: \n",
      " D loss: 1.302686, G loss: 0.888406, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 90.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.296775, G loss: 1.049048, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6879\n",
      "[84/1762] D loss: 1.0760, G loss: 1.0267\n",
      "[164/1762] D loss: 1.8325, G loss: 1.2792\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6891\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6896\n",
      "[404/1762] D loss: 1.3869, G loss: 0.6919\n",
      "[484/1762] D loss: 1.3913, G loss: 0.6677\n",
      "[564/1762] D loss: 1.0758, G loss: 1.0203\n",
      "[644/1762] D loss: 1.1697, G loss: 2.5529\n",
      "[724/1762] D loss: 1.3881, G loss: 0.7170\n",
      "[804/1762] D loss: 1.0531, G loss: 1.3015\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6822\n",
      "[964/1762] D loss: 1.0712, G loss: 1.1005\n",
      "[1044/1762] D loss: 1.0601, G loss: 1.1851\n",
      "[1124/1762] D loss: 1.0509, G loss: 1.3113\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6847\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6856\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6863\n",
      "[1444/1762] D loss: 1.3870, G loss: 0.6738\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.6830\n",
      "[1604/1762] D loss: 1.3885, G loss: 0.6824\n",
      "[1684/1762] D loss: 1.3870, G loss: 0.6716\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6862\n",
      "train error: \n",
      " D loss: 1.280529, G loss: 0.975074, D accuracy: 55.5%, cell accuracy: 99.6%, board accuracy: 72.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.274355, G loss: 1.022771, D accuracy: 55.8%, cell accuracy: 99.5%, board accuracy: 70.2% \n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3879, G loss: 0.6800\n",
      "[84/1762] D loss: 1.3744, G loss: 0.7066\n",
      "[164/1762] D loss: 1.3864, G loss: 0.6840\n",
      "[244/1762] D loss: 1.3926, G loss: 0.6566\n",
      "[324/1762] D loss: 1.3869, G loss: 0.7012\n",
      "[404/1762] D loss: 1.3091, G loss: 0.7381\n",
      "[484/1762] D loss: 1.0581, G loss: 1.1846\n",
      "[564/1762] D loss: 1.0523, G loss: 1.3057\n",
      "[644/1762] D loss: 1.0492, G loss: 1.3410\n",
      "[724/1762] D loss: 1.3865, G loss: 0.6999\n",
      "[804/1762] D loss: 1.3879, G loss: 0.7117\n",
      "[884/1762] D loss: 1.0646, G loss: 1.0926\n",
      "[964/1762] D loss: 1.0682, G loss: 1.0756\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6901\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6912\n",
      "[1204/1762] D loss: 1.3865, G loss: 0.6914\n",
      "[1284/1762] D loss: 1.0413, G loss: 1.7817\n",
      "[1364/1762] D loss: 1.0413, G loss: 1.7907\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6857\n",
      "[1524/1762] D loss: 1.3876, G loss: 0.6772\n",
      "[1604/1762] D loss: 1.3866, G loss: 0.6848\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6893\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6872\n",
      "train error: \n",
      " D loss: 1.303719, G loss: 0.825450, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 90.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.290341, G loss: 0.943707, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6905\n",
      "[84/1762] D loss: 1.3867, G loss: 0.6766\n",
      "[164/1762] D loss: 1.0718, G loss: 1.0560\n",
      "[244/1762] D loss: 1.1915, G loss: 1.1696\n",
      "[324/1762] D loss: 1.3912, G loss: 0.6474\n",
      "[404/1762] D loss: 1.1952, G loss: 1.1453\n",
      "[484/1762] D loss: 1.3864, G loss: 0.6867\n",
      "[564/1762] D loss: 1.3866, G loss: 0.7019\n",
      "[644/1762] D loss: 1.3869, G loss: 0.6780\n",
      "[724/1762] D loss: 1.3868, G loss: 0.6802\n",
      "[804/1762] D loss: 1.3865, G loss: 0.6993\n",
      "[884/1762] D loss: 1.0505, G loss: 1.3084\n",
      "[964/1762] D loss: 1.3863, G loss: 0.6890\n",
      "[1044/1762] D loss: 1.3865, G loss: 0.6836\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.6967\n",
      "[1204/1762] D loss: 1.0554, G loss: 1.2175\n",
      "[1284/1762] D loss: 1.3876, G loss: 0.6725\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6891\n",
      "[1444/1762] D loss: 1.3899, G loss: 0.6684\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.6886\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6896\n",
      "[1684/1762] D loss: 1.3900, G loss: 0.7372\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6908\n",
      "train error: \n",
      " D loss: 1.306163, G loss: 0.891229, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.293320, G loss: 0.984863, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6908\n",
      "[84/1762] D loss: 1.3872, G loss: 0.6755\n",
      "[164/1762] D loss: 1.0631, G loss: 1.1261\n",
      "[244/1762] D loss: 1.3864, G loss: 0.6960\n",
      "[324/1762] D loss: 1.3865, G loss: 0.6902\n",
      "[404/1762] D loss: 1.3554, G loss: 1.7747\n",
      "[484/1762] D loss: 1.3863, G loss: 0.6897\n",
      "[564/1762] D loss: 1.3863, G loss: 0.6907\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6918\n",
      "[724/1762] D loss: 1.0599, G loss: 1.1757\n",
      "[804/1762] D loss: 0.7516, G loss: 1.4767\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6913\n",
      "[964/1762] D loss: 1.3864, G loss: 0.6890\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6948\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.6876\n",
      "[1204/1762] D loss: 1.0433, G loss: 1.5930\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6979\n",
      "[1364/1762] D loss: 1.3870, G loss: 0.6814\n",
      "[1444/1762] D loss: 1.0425, G loss: 1.6576\n",
      "[1524/1762] D loss: 1.3905, G loss: 0.7188\n",
      "[1604/1762] D loss: 1.3867, G loss: 0.6812\n",
      "[1684/1762] D loss: 1.3870, G loss: 0.6747\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6966\n",
      "train error: \n",
      " D loss: 1.302568, G loss: 0.857637, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.294725, G loss: 0.892698, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3876, G loss: 0.7199\n",
      "[84/1762] D loss: 1.0528, G loss: 1.2719\n",
      "[164/1762] D loss: 1.3764, G loss: 0.7060\n",
      "[244/1762] D loss: 1.1512, G loss: 1.1758\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6969\n",
      "[404/1762] D loss: 1.3865, G loss: 0.7031\n",
      "[484/1762] D loss: 1.3881, G loss: 0.6746\n",
      "[564/1762] D loss: 1.3889, G loss: 0.6724\n",
      "[644/1762] D loss: 1.4376, G loss: 0.6825\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6909\n",
      "[804/1762] D loss: 1.3879, G loss: 0.7065\n",
      "[884/1762] D loss: 1.3416, G loss: 0.6613\n",
      "[964/1762] D loss: 1.3810, G loss: 0.7048\n",
      "[1044/1762] D loss: 1.3865, G loss: 0.6808\n",
      "[1124/1762] D loss: 1.3858, G loss: 0.6794\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6827\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6814\n",
      "[1364/1762] D loss: 1.3874, G loss: 0.6670\n",
      "[1444/1762] D loss: 1.5947, G loss: 0.5801\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.6843\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6834\n",
      "[1684/1762] D loss: 1.0571, G loss: 1.1915\n",
      "[1762/1762] D loss: 1.3871, G loss: 0.7052\n",
      "train error: \n",
      " D loss: 1.298521, G loss: 0.864260, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.277699, G loss: 0.931124, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7860, G loss: 1.2645\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6871\n",
      "[164/1762] D loss: 1.0447, G loss: 1.6019\n",
      "[244/1762] D loss: 1.0543, G loss: 1.2412\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6927\n",
      "[404/1762] D loss: 1.0478, G loss: 1.3892\n",
      "[484/1762] D loss: 1.3879, G loss: 0.6698\n",
      "[564/1762] D loss: 1.7853, G loss: 1.2713\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6924\n",
      "[724/1762] D loss: 1.3865, G loss: 0.6827\n",
      "[804/1762] D loss: 1.3863, G loss: 0.6884\n",
      "[884/1762] D loss: 0.7867, G loss: 1.6206\n",
      "[964/1762] D loss: 1.3872, G loss: 0.6770\n",
      "[1044/1762] D loss: 1.3882, G loss: 0.6693\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6908\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6919\n",
      "[1284/1762] D loss: 1.0500, G loss: 1.3228\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6935\n",
      "[1444/1762] D loss: 1.3862, G loss: 0.6947\n",
      "[1524/1762] D loss: 1.3866, G loss: 0.6916\n",
      "[1604/1762] D loss: 1.3865, G loss: 0.6855\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6941\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6941\n",
      "train error: \n",
      " D loss: 1.302962, G loss: 0.947854, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.296254, G loss: 1.026464, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0511, G loss: 2.3914\n",
      "[84/1762] D loss: 1.3865, G loss: 0.6878\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6930\n",
      "[244/1762] D loss: 1.3867, G loss: 0.6859\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6936\n",
      "[404/1762] D loss: 1.3863, G loss: 0.6940\n",
      "[484/1762] D loss: 1.0655, G loss: 1.1080\n",
      "[564/1762] D loss: 1.3865, G loss: 0.7021\n",
      "[644/1762] D loss: 1.3874, G loss: 0.7056\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6894\n",
      "[804/1762] D loss: 1.3869, G loss: 0.6971\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6917\n",
      "[964/1762] D loss: 1.3867, G loss: 0.6813\n",
      "[1044/1762] D loss: 1.0745, G loss: 1.0196\n",
      "[1124/1762] D loss: 1.3959, G loss: 0.6487\n",
      "[1204/1762] D loss: 1.3899, G loss: 0.7209\n",
      "[1284/1762] D loss: 1.3865, G loss: 0.6887\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6950\n",
      "[1444/1762] D loss: 1.0762, G loss: 1.0148\n",
      "[1524/1762] D loss: 1.4098, G loss: 0.6519\n",
      "[1604/1762] D loss: 1.3875, G loss: 0.7026\n",
      "[1684/1762] D loss: 1.3867, G loss: 0.6978\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6950\n",
      "train error: \n",
      " D loss: 1.301592, G loss: 0.869800, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.290961, G loss: 0.934130, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6950\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6894\n",
      "[164/1762] D loss: 0.9933, G loss: 1.2964\n",
      "[244/1762] D loss: 1.3866, G loss: 0.6873\n",
      "[324/1762] D loss: 1.3881, G loss: 0.6717\n",
      "[404/1762] D loss: 1.3863, G loss: 0.6953\n",
      "[484/1762] D loss: 1.8272, G loss: 1.2728\n",
      "[564/1762] D loss: 1.3863, G loss: 0.6940\n",
      "[644/1762] D loss: 0.7255, G loss: 1.7483\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6897\n",
      "[804/1762] D loss: 1.0501, G loss: 1.3907\n",
      "[884/1762] D loss: 1.3864, G loss: 0.7007\n",
      "[964/1762] D loss: 1.0663, G loss: 1.2832\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6935\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6926\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6959\n",
      "[1284/1762] D loss: 1.3867, G loss: 0.7002\n",
      "[1364/1762] D loss: 1.3836, G loss: 0.6905\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6919\n",
      "[1524/1762] D loss: 1.3867, G loss: 0.6834\n",
      "[1604/1762] D loss: 1.6388, G loss: 1.0801\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.6979\n",
      "[1762/1762] D loss: 1.3866, G loss: 0.6847\n",
      "train error: \n",
      " D loss: 1.302237, G loss: 0.848393, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.289989, G loss: 0.890590, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7432, G loss: 1.6768\n",
      "[84/1762] D loss: 1.3870, G loss: 0.6832\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6963\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6963\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6935\n",
      "[404/1762] D loss: 1.0717, G loss: 1.1606\n",
      "[484/1762] D loss: 1.0610, G loss: 1.2849\n",
      "[564/1762] D loss: 1.3880, G loss: 0.7144\n",
      "[644/1762] D loss: 1.3866, G loss: 0.7098\n",
      "[724/1762] D loss: 1.3880, G loss: 0.6784\n",
      "[804/1762] D loss: 1.0484, G loss: 1.3797\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6962\n",
      "[964/1762] D loss: 1.0404, G loss: 2.0089\n",
      "[1044/1762] D loss: 1.0451, G loss: 1.4395\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6890\n",
      "[1204/1762] D loss: 1.0725, G loss: 1.1537\n",
      "[1284/1762] D loss: 1.3873, G loss: 0.6769\n",
      "[1364/1762] D loss: 1.3873, G loss: 0.7107\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6880\n",
      "[1524/1762] D loss: 1.3865, G loss: 0.6894\n",
      "[1604/1762] D loss: 1.3879, G loss: 0.6684\n",
      "[1684/1762] D loss: 1.3904, G loss: 0.7439\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6895\n",
      "train error: \n",
      " D loss: 1.308214, G loss: 0.765414, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.293101, G loss: 0.789310, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3865, G loss: 0.6841\n",
      "[84/1762] D loss: 1.0919, G loss: 0.9349\n",
      "[164/1762] D loss: 1.0732, G loss: 1.0457\n",
      "[244/1762] D loss: 1.3865, G loss: 0.7021\n",
      "[324/1762] D loss: 1.0646, G loss: 1.1124\n",
      "[404/1762] D loss: 1.3863, G loss: 0.6970\n",
      "[484/1762] D loss: 1.3866, G loss: 0.6910\n",
      "[564/1762] D loss: 1.3863, G loss: 0.6979\n",
      "[644/1762] D loss: 1.0467, G loss: 1.4247\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6972\n",
      "[804/1762] D loss: 1.0468, G loss: 1.4169\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6965\n",
      "[964/1762] D loss: 1.3955, G loss: 0.6558\n",
      "[1044/1762] D loss: 1.6320, G loss: 1.0704\n",
      "[1124/1762] D loss: 1.1539, G loss: 1.0523\n",
      "[1204/1762] D loss: 1.3881, G loss: 0.6688\n",
      "[1284/1762] D loss: 1.3868, G loss: 0.7045\n",
      "[1364/1762] D loss: 1.3867, G loss: 0.7029\n",
      "[1444/1762] D loss: 1.3880, G loss: 0.6755\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.6929\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6938\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.6890\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6940\n",
      "train error: \n",
      " D loss: 1.301999, G loss: 0.843803, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.291108, G loss: 0.884848, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0726, G loss: 1.0771\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6959\n",
      "[164/1762] D loss: 1.3864, G loss: 0.6913\n",
      "[244/1762] D loss: 1.6068, G loss: 1.0441\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6907\n",
      "[404/1762] D loss: 0.4055, G loss: 3.2551\n",
      "[484/1762] D loss: 1.3802, G loss: 0.7012\n",
      "[564/1762] D loss: 1.3863, G loss: 0.6939\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6939\n",
      "[724/1762] D loss: 1.3865, G loss: 0.6854\n",
      "[804/1762] D loss: 1.3863, G loss: 0.6950\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6935\n",
      "[964/1762] D loss: 1.0613, G loss: 1.1456\n",
      "[1044/1762] D loss: 1.3865, G loss: 0.6938\n",
      "[1124/1762] D loss: 1.0685, G loss: 1.1064\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6940\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6928\n",
      "[1364/1762] D loss: 1.3867, G loss: 0.6968\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6950\n",
      "[1524/1762] D loss: 1.3904, G loss: 0.6699\n",
      "[1604/1762] D loss: 1.2167, G loss: 1.1281\n",
      "[1684/1762] D loss: 1.3893, G loss: 0.6587\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6933\n",
      "train error: \n",
      " D loss: 1.303426, G loss: 0.935364, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.302979, G loss: 1.044699, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6975\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6876\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6917\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6913\n",
      "[324/1762] D loss: 1.3860, G loss: 0.6847\n",
      "[404/1762] D loss: 1.3863, G loss: 0.6885\n",
      "[484/1762] D loss: 1.0779, G loss: 1.0069\n",
      "[564/1762] D loss: 1.3863, G loss: 0.6899\n",
      "[644/1762] D loss: 1.1036, G loss: 0.9895\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6997\n",
      "[804/1762] D loss: 1.3862, G loss: 0.6991\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6923\n",
      "[964/1762] D loss: 1.3863, G loss: 0.6953\n",
      "[1044/1762] D loss: 1.0414, G loss: 1.8197\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6951\n",
      "[1204/1762] D loss: 1.0611, G loss: 1.1362\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6911\n",
      "[1364/1762] D loss: 1.0892, G loss: 0.9406\n",
      "[1444/1762] D loss: 1.3867, G loss: 0.6819\n",
      "[1524/1762] D loss: 1.1152, G loss: 0.8650\n",
      "[1604/1762] D loss: 1.0864, G loss: 0.9780\n",
      "[1684/1762] D loss: 1.0716, G loss: 1.0589\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6908\n",
      "train error: \n",
      " D loss: 1.317451, G loss: 0.838910, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.327350, G loss: 0.892950, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0729, G loss: 1.0784\n",
      "[84/1762] D loss: 1.3876, G loss: 0.7105\n",
      "[164/1762] D loss: 1.2719, G loss: 0.7040\n",
      "[244/1762] D loss: 1.3871, G loss: 0.7140\n",
      "[324/1762] D loss: 1.3897, G loss: 0.6932\n",
      "[404/1762] D loss: 1.3868, G loss: 0.6991\n",
      "[484/1762] D loss: 1.3933, G loss: 0.6522\n",
      "[564/1762] D loss: 1.0584, G loss: 1.1788\n",
      "[644/1762] D loss: 1.3864, G loss: 0.6946\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6909\n",
      "[804/1762] D loss: 1.3863, G loss: 0.6902\n",
      "[884/1762] D loss: 1.3867, G loss: 0.6884\n",
      "[964/1762] D loss: 1.3864, G loss: 0.6850\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6906\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.6966\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6953\n",
      "[1284/1762] D loss: 1.3867, G loss: 0.7070\n",
      "[1364/1762] D loss: 1.5047, G loss: 0.9253\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6912\n",
      "[1524/1762] D loss: 1.0955, G loss: 0.9125\n",
      "[1604/1762] D loss: 1.4776, G loss: 1.0120\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6913\n",
      "[1762/1762] D loss: 0.7310, G loss: 1.6971\n",
      "train error: \n",
      " D loss: 1.322266, G loss: 0.802240, D accuracy: 53.0%, cell accuracy: 99.9%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.327726, G loss: 0.838281, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4490, G loss: 0.9810\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6899\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6895\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6927\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6891\n",
      "[404/1762] D loss: 1.3865, G loss: 0.6819\n",
      "[484/1762] D loss: 1.3863, G loss: 0.6879\n",
      "[564/1762] D loss: 1.3908, G loss: 0.6771\n",
      "[644/1762] D loss: 1.3865, G loss: 0.6811\n",
      "[724/1762] D loss: 1.3869, G loss: 0.7025\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6826\n",
      "[884/1762] D loss: 1.1004, G loss: 0.9331\n",
      "[964/1762] D loss: 1.2492, G loss: 1.0307\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6898\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6881\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6848\n",
      "[1284/1762] D loss: 0.8183, G loss: 1.2254\n",
      "[1364/1762] D loss: 1.3865, G loss: 0.6924\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6857\n",
      "[1524/1762] D loss: 1.3866, G loss: 0.6918\n",
      "[1604/1762] D loss: 1.3868, G loss: 0.6800\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.6816\n",
      "[1762/1762] D loss: 1.3870, G loss: 0.6726\n",
      "train error: \n",
      " D loss: 1.316430, G loss: 0.811535, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.315416, G loss: 0.878098, D accuracy: 54.1%, cell accuracy: 99.9%, board accuracy: 91.1% \n",
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3895, G loss: 0.6553\n",
      "[84/1762] D loss: 1.0701, G loss: 1.1478\n",
      "[164/1762] D loss: 1.3895, G loss: 0.7279\n",
      "[244/1762] D loss: 1.3873, G loss: 0.6731\n",
      "[324/1762] D loss: 1.3864, G loss: 0.6925\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6943\n",
      "[484/1762] D loss: 1.3865, G loss: 0.6852\n",
      "[564/1762] D loss: 1.2134, G loss: 2.5372\n",
      "[644/1762] D loss: 1.2508, G loss: 1.0164\n",
      "[724/1762] D loss: 1.1165, G loss: 0.8927\n",
      "[804/1762] D loss: 1.3863, G loss: 0.6898\n",
      "[884/1762] D loss: 1.0526, G loss: 1.2440\n",
      "[964/1762] D loss: 1.3879, G loss: 0.7185\n",
      "[1044/1762] D loss: 1.2096, G loss: 0.8232\n",
      "[1124/1762] D loss: 1.4201, G loss: 0.6245\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6853\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6951\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6887\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6884\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.6879\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6896\n",
      "[1684/1762] D loss: 1.0716, G loss: 1.1472\n",
      "[1762/1762] D loss: 1.3882, G loss: 0.6567\n",
      "train error: \n",
      " D loss: 1.328444, G loss: 0.895540, D accuracy: 53.4%, cell accuracy: 99.9%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.321510, G loss: 0.939588, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3866, G loss: 0.6814\n",
      "[84/1762] D loss: 1.3865, G loss: 0.6940\n",
      "[164/1762] D loss: 1.3870, G loss: 0.6865\n",
      "[244/1762] D loss: 1.3905, G loss: 0.7326\n",
      "[324/1762] D loss: 1.2514, G loss: 1.0432\n",
      "[404/1762] D loss: 1.3868, G loss: 0.6753\n",
      "[484/1762] D loss: 1.3874, G loss: 0.6728\n",
      "[564/1762] D loss: 1.0559, G loss: 1.2958\n",
      "[644/1762] D loss: 1.3864, G loss: 0.6930\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6959\n",
      "[804/1762] D loss: 1.0462, G loss: 1.4380\n",
      "[884/1762] D loss: 1.2123, G loss: 2.2027\n",
      "[964/1762] D loss: 1.3863, G loss: 0.6881\n",
      "[1044/1762] D loss: 1.8296, G loss: 1.2666\n",
      "[1124/1762] D loss: 1.3870, G loss: 0.6704\n",
      "[1204/1762] D loss: 1.2139, G loss: 1.6994\n",
      "[1284/1762] D loss: 1.2159, G loss: 1.7725\n",
      "[1364/1762] D loss: 1.3867, G loss: 0.6784\n",
      "[1444/1762] D loss: 1.0691, G loss: 1.0710\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.6834\n",
      "[1604/1762] D loss: 1.0505, G loss: 1.3109\n",
      "[1684/1762] D loss: 1.0476, G loss: 1.3683\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6829\n",
      "train error: \n",
      " D loss: 1.306240, G loss: 0.788328, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.285624, G loss: 0.852423, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3801, G loss: 0.8065\n",
      "[84/1762] D loss: 0.7040, G loss: 1.6884\n",
      "[164/1762] D loss: 0.2192, G loss: 3.1461\n",
      "[244/1762] D loss: 0.1016, G loss: 3.6194\n",
      "[324/1762] D loss: 0.0308, G loss: 5.3429\n",
      "[404/1762] D loss: 0.0875, G loss: 4.9020\n",
      "[484/1762] D loss: 0.0295, G loss: 3.9229\n",
      "[564/1762] D loss: 0.0161, G loss: 5.2064\n",
      "[644/1762] D loss: 0.0256, G loss: 4.4416\n",
      "[724/1762] D loss: 0.0367, G loss: 4.9273\n",
      "[804/1762] D loss: 1.2008, G loss: 1.0862\n",
      "[884/1762] D loss: 0.5796, G loss: 3.0127\n",
      "[964/1762] D loss: 0.2060, G loss: 3.7341\n",
      "[1044/1762] D loss: 0.8010, G loss: 2.7775\n",
      "[1124/1762] D loss: 0.5156, G loss: 1.9538\n",
      "[1204/1762] D loss: 0.6009, G loss: 2.1076\n",
      "[1284/1762] D loss: 1.2473, G loss: 1.1721\n",
      "[1364/1762] D loss: 1.2915, G loss: 1.4819\n",
      "[1444/1762] D loss: 2.0348, G loss: 0.2437\n",
      "[1524/1762] D loss: 1.2331, G loss: 1.5116\n",
      "[1604/1762] D loss: 1.3067, G loss: 1.0733\n",
      "[1684/1762] D loss: 1.3382, G loss: 0.6417\n",
      "[1762/1762] D loss: 0.8078, G loss: 1.4607\n",
      "train error: \n",
      " D loss: 1.306468, G loss: 0.996517, D accuracy: 57.8%, cell accuracy: 99.6%, board accuracy: 67.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.306327, G loss: 1.024564, D accuracy: 57.8%, cell accuracy: 99.6%, board accuracy: 65.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3069, G loss: 1.1538\n",
      "[84/1762] D loss: 1.4098, G loss: 0.6879\n",
      "[164/1762] D loss: 1.1919, G loss: 0.8104\n",
      "[244/1762] D loss: 1.1994, G loss: 0.5689\n",
      "[324/1762] D loss: 1.2698, G loss: 0.6645\n",
      "[404/1762] D loss: 1.2487, G loss: 0.7218\n",
      "[484/1762] D loss: 1.0474, G loss: 0.9291\n",
      "[564/1762] D loss: 1.1554, G loss: 0.9593\n",
      "[644/1762] D loss: 1.2900, G loss: 1.3500\n",
      "[724/1762] D loss: 1.2536, G loss: 0.8283\n",
      "[804/1762] D loss: 1.2489, G loss: 0.8536\n",
      "[884/1762] D loss: 1.2414, G loss: 1.5573\n",
      "[964/1762] D loss: 1.2730, G loss: 0.7255\n",
      "[1044/1762] D loss: 1.3773, G loss: 1.0201\n",
      "[1124/1762] D loss: 1.5579, G loss: 1.7814\n",
      "[1204/1762] D loss: 1.2390, G loss: 1.1623\n",
      "[1284/1762] D loss: 1.0198, G loss: 1.1847\n",
      "[1364/1762] D loss: 1.1200, G loss: 0.9082\n",
      "[1444/1762] D loss: 1.1014, G loss: 1.1314\n",
      "[1524/1762] D loss: 1.0675, G loss: 1.1264\n",
      "[1604/1762] D loss: 1.4151, G loss: 0.6778\n",
      "[1684/1762] D loss: 1.3202, G loss: 0.6526\n",
      "[1762/1762] D loss: 1.4323, G loss: 0.5213\n",
      "train error: \n",
      " D loss: 1.270753, G loss: 0.770258, D accuracy: 60.7%, cell accuracy: 99.7%, board accuracy: 81.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.261023, G loss: 0.808783, D accuracy: 62.0%, cell accuracy: 99.6%, board accuracy: 78.9% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3761, G loss: 0.7906\n",
      "[84/1762] D loss: 1.3451, G loss: 0.5237\n",
      "[164/1762] D loss: 1.1942, G loss: 1.1812\n",
      "[244/1762] D loss: 1.1367, G loss: 0.8819\n",
      "[324/1762] D loss: 1.3900, G loss: 0.9369\n",
      "[404/1762] D loss: 1.4434, G loss: 0.4653\n",
      "[484/1762] D loss: 1.3088, G loss: 0.6945\n",
      "[564/1762] D loss: 1.5727, G loss: 0.4835\n",
      "[644/1762] D loss: 0.9395, G loss: 1.7954\n",
      "[724/1762] D loss: 1.3106, G loss: 0.4663\n",
      "[804/1762] D loss: 1.1893, G loss: 1.1146\n",
      "[884/1762] D loss: 0.8095, G loss: 1.7464\n",
      "[964/1762] D loss: 1.4340, G loss: 0.3511\n",
      "[1044/1762] D loss: 1.3314, G loss: 0.7914\n",
      "[1124/1762] D loss: 0.9457, G loss: 1.0985\n",
      "[1204/1762] D loss: 1.4175, G loss: 0.5663\n",
      "[1284/1762] D loss: 1.4114, G loss: 0.7401\n",
      "[1364/1762] D loss: 1.2484, G loss: 0.7284\n",
      "[1444/1762] D loss: 1.1243, G loss: 0.7119\n",
      "[1524/1762] D loss: 1.4717, G loss: 0.9239\n",
      "[1604/1762] D loss: 1.3732, G loss: 0.4525\n",
      "[1684/1762] D loss: 1.6816, G loss: 0.6345\n",
      "[1762/1762] D loss: 1.2769, G loss: 0.8804\n",
      "train error: \n",
      " D loss: 0.960824, G loss: 1.483289, D accuracy: 79.6%, cell accuracy: 98.9%, board accuracy: 33.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.981531, G loss: 1.461624, D accuracy: 77.8%, cell accuracy: 98.8%, board accuracy: 32.3% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2680, G loss: 0.8174\n",
      "[84/1762] D loss: 0.9816, G loss: 0.9563\n",
      "[164/1762] D loss: 0.9753, G loss: 1.0277\n",
      "[244/1762] D loss: 1.0552, G loss: 0.9703\n",
      "[324/1762] D loss: 1.1161, G loss: 0.7319\n",
      "[404/1762] D loss: 1.3315, G loss: 0.8312\n",
      "[484/1762] D loss: 0.9357, G loss: 0.9812\n",
      "[564/1762] D loss: 0.8017, G loss: 1.7093\n",
      "[644/1762] D loss: 1.3979, G loss: 0.8347\n",
      "[724/1762] D loss: 1.3887, G loss: 0.5671\n",
      "[804/1762] D loss: 1.0193, G loss: 1.4574\n",
      "[884/1762] D loss: 1.3542, G loss: 0.7581\n",
      "[964/1762] D loss: 1.3724, G loss: 0.6611\n",
      "[1044/1762] D loss: 1.1521, G loss: 1.4551\n",
      "[1124/1762] D loss: 1.2960, G loss: 0.7628\n",
      "[1204/1762] D loss: 0.8720, G loss: 1.1454\n",
      "[1284/1762] D loss: 0.5184, G loss: 2.3072\n",
      "[1364/1762] D loss: 1.5563, G loss: 0.3835\n",
      "[1444/1762] D loss: 1.4285, G loss: 0.7355\n",
      "[1524/1762] D loss: 0.7395, G loss: 1.4052\n",
      "[1604/1762] D loss: 1.3605, G loss: 0.6263\n",
      "[1684/1762] D loss: 1.6671, G loss: 1.0977\n",
      "[1762/1762] D loss: 1.5309, G loss: 0.4047\n",
      "train error: \n",
      " D loss: 1.358642, G loss: 0.574205, D accuracy: 55.7%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.340235, G loss: 0.599418, D accuracy: 56.5%, cell accuracy: 99.8%, board accuracy: 85.0% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8428, G loss: 0.9259\n",
      "[84/1762] D loss: 1.7107, G loss: 0.3831\n",
      "[164/1762] D loss: 0.6058, G loss: 2.8874\n",
      "[244/1762] D loss: 1.3326, G loss: 0.6875\n",
      "[324/1762] D loss: 1.4020, G loss: 0.7874\n",
      "[404/1762] D loss: 1.3410, G loss: 0.7791\n",
      "[484/1762] D loss: 1.3501, G loss: 0.6688\n",
      "[564/1762] D loss: 1.4178, G loss: 0.4969\n",
      "[644/1762] D loss: 1.4091, G loss: 0.7944\n",
      "[724/1762] D loss: 1.4296, G loss: 0.8518\n",
      "[804/1762] D loss: 1.2681, G loss: 1.0629\n",
      "[884/1762] D loss: 1.3259, G loss: 0.8728\n",
      "[964/1762] D loss: 1.3849, G loss: 0.8509\n",
      "[1044/1762] D loss: 1.4282, G loss: 0.9059\n",
      "[1124/1762] D loss: 0.8258, G loss: 0.9562\n",
      "[1204/1762] D loss: 1.3827, G loss: 0.5689\n",
      "[1284/1762] D loss: 0.9009, G loss: 1.6245\n",
      "[1364/1762] D loss: 1.1304, G loss: 1.3421\n",
      "[1444/1762] D loss: 1.6492, G loss: 0.4101\n",
      "[1524/1762] D loss: 1.3668, G loss: 0.6668\n",
      "[1604/1762] D loss: 1.3817, G loss: 0.5955\n",
      "[1684/1762] D loss: 0.5032, G loss: 2.2723\n",
      "[1762/1762] D loss: 1.1753, G loss: 0.8211\n",
      "train error: \n",
      " D loss: 1.274358, G loss: 0.731295, D accuracy: 64.4%, cell accuracy: 99.6%, board accuracy: 73.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.271065, G loss: 0.755196, D accuracy: 63.9%, cell accuracy: 99.6%, board accuracy: 71.4% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4762, G loss: 0.4338\n",
      "[84/1762] D loss: 1.4129, G loss: 0.5364\n",
      "[164/1762] D loss: 1.3992, G loss: 0.6110\n",
      "[244/1762] D loss: 0.9168, G loss: 1.1085\n",
      "[324/1762] D loss: 1.4147, G loss: 0.7311\n",
      "[404/1762] D loss: 1.4289, G loss: 0.5808\n",
      "[484/1762] D loss: 1.1950, G loss: 0.7606\n",
      "[564/1762] D loss: 0.7127, G loss: 1.0097\n",
      "[644/1762] D loss: 1.4171, G loss: 0.7187\n",
      "[724/1762] D loss: 1.4062, G loss: 0.8347\n",
      "[804/1762] D loss: 1.4289, G loss: 0.8371\n",
      "[884/1762] D loss: 1.1305, G loss: 1.3044\n",
      "[964/1762] D loss: 0.6484, G loss: 1.5320\n",
      "[1044/1762] D loss: 1.3368, G loss: 0.5487\n",
      "[1124/1762] D loss: 1.3522, G loss: 1.8035\n",
      "[1204/1762] D loss: 0.7107, G loss: 1.8054\n",
      "[1284/1762] D loss: 0.6315, G loss: 1.3689\n",
      "[1364/1762] D loss: 0.3066, G loss: 1.7260\n",
      "[1444/1762] D loss: 0.5734, G loss: 1.3394\n",
      "[1524/1762] D loss: 0.6930, G loss: 0.8679\n",
      "[1604/1762] D loss: 1.4558, G loss: 0.8266\n",
      "[1684/1762] D loss: 1.3992, G loss: 0.6339\n",
      "[1762/1762] D loss: 1.4214, G loss: 0.7676\n",
      "train error: \n",
      " D loss: 1.192600, G loss: 1.055053, D accuracy: 63.3%, cell accuracy: 99.0%, board accuracy: 46.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.177444, G loss: 1.088402, D accuracy: 63.1%, cell accuracy: 98.9%, board accuracy: 45.0% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4814, G loss: 0.8010\n",
      "[84/1762] D loss: 1.2926, G loss: 1.8137\n",
      "[164/1762] D loss: 0.5908, G loss: 1.2670\n",
      "[244/1762] D loss: 1.3890, G loss: 0.6803\n",
      "[324/1762] D loss: 1.4089, G loss: 0.7193\n",
      "[404/1762] D loss: 0.5711, G loss: 1.2873\n",
      "[484/1762] D loss: 0.2742, G loss: 1.8913\n",
      "[564/1762] D loss: 0.5288, G loss: 1.6175\n",
      "[644/1762] D loss: 1.4541, G loss: 0.6317\n",
      "[724/1762] D loss: 1.4428, G loss: 0.6381\n",
      "[804/1762] D loss: 1.4942, G loss: 0.9910\n",
      "[884/1762] D loss: 1.4788, G loss: 0.5109\n",
      "[964/1762] D loss: 1.3417, G loss: 1.0678\n",
      "[1044/1762] D loss: 1.4090, G loss: 0.5836\n",
      "[1124/1762] D loss: 0.4820, G loss: 1.5169\n",
      "[1204/1762] D loss: 0.1840, G loss: 2.3432\n",
      "[1284/1762] D loss: 0.4889, G loss: 1.4375\n",
      "[1364/1762] D loss: 1.4054, G loss: 0.6770\n",
      "[1444/1762] D loss: 1.4138, G loss: 0.9115\n",
      "[1524/1762] D loss: 0.5017, G loss: 1.4338\n",
      "[1604/1762] D loss: 1.4640, G loss: 0.5009\n",
      "[1684/1762] D loss: 1.5416, G loss: 0.9426\n",
      "[1762/1762] D loss: 0.2214, G loss: 2.5029\n",
      "train error: \n",
      " D loss: 1.350492, G loss: 0.745393, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 89.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.338193, G loss: 0.771202, D accuracy: 56.1%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6875, G loss: 1.2031\n",
      "[84/1762] D loss: 0.4917, G loss: 1.7729\n",
      "[164/1762] D loss: 0.6265, G loss: 1.0568\n",
      "[244/1762] D loss: 1.3910, G loss: 0.6769\n",
      "[324/1762] D loss: 1.5566, G loss: 1.0465\n",
      "[404/1762] D loss: 1.3013, G loss: 1.0009\n",
      "[484/1762] D loss: 1.1157, G loss: 1.3910\n",
      "[564/1762] D loss: 1.4144, G loss: 0.6994\n",
      "[644/1762] D loss: 1.4137, G loss: 0.8636\n",
      "[724/1762] D loss: 0.7074, G loss: 0.9755\n",
      "[804/1762] D loss: 1.3921, G loss: 0.6271\n",
      "[884/1762] D loss: 1.2975, G loss: 0.6717\n",
      "[964/1762] D loss: 1.3865, G loss: 0.6768\n",
      "[1044/1762] D loss: 1.4391, G loss: 0.6670\n",
      "[1124/1762] D loss: 1.4539, G loss: 0.8341\n",
      "[1204/1762] D loss: 0.5440, G loss: 1.5568\n",
      "[1284/1762] D loss: 1.3799, G loss: 0.5229\n",
      "[1364/1762] D loss: 1.4678, G loss: 0.8572\n",
      "[1444/1762] D loss: 1.4219, G loss: 0.9680\n",
      "[1524/1762] D loss: 1.4869, G loss: 0.8706\n",
      "[1604/1762] D loss: 1.4243, G loss: 0.8301\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.7965\n",
      "[1762/1762] D loss: 1.3856, G loss: 0.7601\n",
      "train error: \n",
      " D loss: 1.337440, G loss: 0.685877, D accuracy: 54.4%, cell accuracy: 99.9%, board accuracy: 90.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.323075, G loss: 0.702408, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4265, G loss: 0.8126\n",
      "[84/1762] D loss: 1.3865, G loss: 1.1755\n",
      "[164/1762] D loss: 1.3995, G loss: 0.6457\n",
      "[244/1762] D loss: 1.4311, G loss: 0.8150\n",
      "[324/1762] D loss: 1.3602, G loss: 1.0682\n",
      "[404/1762] D loss: 1.0723, G loss: 0.6694\n",
      "[484/1762] D loss: 1.3948, G loss: 0.6754\n",
      "[564/1762] D loss: 1.2941, G loss: 0.9819\n",
      "[644/1762] D loss: 0.4669, G loss: 1.5003\n",
      "[724/1762] D loss: 1.4731, G loss: 0.9606\n",
      "[804/1762] D loss: 1.4065, G loss: 0.7859\n",
      "[884/1762] D loss: 0.3752, G loss: 1.7724\n",
      "[964/1762] D loss: 0.6352, G loss: 0.8682\n",
      "[1044/1762] D loss: 1.4807, G loss: 0.8071\n",
      "[1124/1762] D loss: 1.4058, G loss: 0.5923\n",
      "[1204/1762] D loss: 1.3978, G loss: 0.6537\n",
      "[1284/1762] D loss: 1.4915, G loss: 0.8850\n",
      "[1364/1762] D loss: 0.2693, G loss: 1.7834\n",
      "[1444/1762] D loss: 1.4167, G loss: 0.7724\n",
      "[1524/1762] D loss: 1.5195, G loss: 1.1583\n",
      "[1604/1762] D loss: 1.2695, G loss: 1.6232\n",
      "[1684/1762] D loss: 1.3364, G loss: 0.4271\n",
      "[1762/1762] D loss: 1.5462, G loss: 0.2990\n",
      "train error: \n",
      " D loss: 1.504948, G loss: 0.446300, D accuracy: 52.5%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.487483, G loss: 0.471748, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 84.8% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0949, G loss: 0.6216\n",
      "[84/1762] D loss: 0.5920, G loss: 1.3605\n",
      "[164/1762] D loss: 1.5217, G loss: 0.8295\n",
      "[244/1762] D loss: 1.4359, G loss: 0.8978\n",
      "[324/1762] D loss: 1.4063, G loss: 0.6037\n",
      "[404/1762] D loss: 1.4386, G loss: 0.9400\n",
      "[484/1762] D loss: 1.6621, G loss: 1.1339\n",
      "[564/1762] D loss: 1.3507, G loss: 1.1684\n",
      "[644/1762] D loss: 1.4542, G loss: 0.9340\n",
      "[724/1762] D loss: 1.4182, G loss: 0.5527\n",
      "[804/1762] D loss: 0.6422, G loss: 1.6516\n",
      "[884/1762] D loss: 1.4049, G loss: 0.7124\n",
      "[964/1762] D loss: 1.3994, G loss: 0.7546\n",
      "[1044/1762] D loss: 1.3758, G loss: 0.6138\n",
      "[1124/1762] D loss: 0.5491, G loss: 1.3139\n",
      "[1204/1762] D loss: 1.4222, G loss: 0.8114\n",
      "[1284/1762] D loss: 1.2325, G loss: 1.3941\n",
      "[1364/1762] D loss: 1.4075, G loss: 0.6467\n",
      "[1444/1762] D loss: 1.3964, G loss: 0.8164\n",
      "[1524/1762] D loss: 1.3906, G loss: 0.6850\n",
      "[1604/1762] D loss: 1.3782, G loss: 0.8459\n",
      "[1684/1762] D loss: 1.3909, G loss: 0.7250\n",
      "[1762/1762] D loss: 1.4263, G loss: 0.8127\n",
      "train error: \n",
      " D loss: 1.333144, G loss: 0.753533, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.315507, G loss: 0.786946, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3949, G loss: 0.7766\n",
      "[84/1762] D loss: 0.3489, G loss: 1.6615\n",
      "[164/1762] D loss: 1.4099, G loss: 0.7609\n",
      "[244/1762] D loss: 0.3146, G loss: 2.0029\n",
      "[324/1762] D loss: 1.3900, G loss: 0.6034\n",
      "[404/1762] D loss: 0.4042, G loss: 1.3375\n",
      "[484/1762] D loss: 1.5238, G loss: 1.0643\n",
      "[564/1762] D loss: 0.5961, G loss: 1.0739\n",
      "[644/1762] D loss: 1.4241, G loss: 1.1003\n",
      "[724/1762] D loss: 1.4075, G loss: 0.7744\n",
      "[804/1762] D loss: 1.3570, G loss: 1.0245\n",
      "[884/1762] D loss: 0.3872, G loss: 1.6359\n",
      "[964/1762] D loss: 1.4318, G loss: 0.8333\n",
      "[1044/1762] D loss: 0.5150, G loss: 1.3565\n",
      "[1124/1762] D loss: 1.4110, G loss: 0.8332\n",
      "[1204/1762] D loss: 1.4655, G loss: 1.0064\n",
      "[1284/1762] D loss: 0.0785, G loss: 2.8383\n",
      "[1364/1762] D loss: 0.3562, G loss: 1.7475\n",
      "[1444/1762] D loss: 1.3352, G loss: 0.9107\n",
      "[1524/1762] D loss: 1.4772, G loss: 0.4835\n",
      "[1604/1762] D loss: 1.7301, G loss: 1.5403\n",
      "[1684/1762] D loss: 1.4020, G loss: 0.9181\n",
      "[1762/1762] D loss: 0.1807, G loss: 1.7958\n",
      "train error: \n",
      " D loss: 1.620240, G loss: 0.333602, D accuracy: 50.9%, cell accuracy: 99.9%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.610582, G loss: 0.339791, D accuracy: 51.0%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.7499, G loss: 0.3425\n",
      "[84/1762] D loss: 1.4028, G loss: 0.7475\n",
      "[164/1762] D loss: 1.4052, G loss: 0.7637\n",
      "[244/1762] D loss: 0.6966, G loss: 0.7875\n",
      "[324/1762] D loss: 1.4668, G loss: 0.9537\n",
      "[404/1762] D loss: 1.4387, G loss: 0.8909\n",
      "[484/1762] D loss: 1.3485, G loss: 1.2568\n",
      "[564/1762] D loss: 0.5515, G loss: 1.1537\n",
      "[644/1762] D loss: 1.4450, G loss: 0.6023\n",
      "[724/1762] D loss: 1.5786, G loss: 1.0518\n",
      "[804/1762] D loss: 1.3879, G loss: 0.7081\n",
      "[884/1762] D loss: 1.3957, G loss: 0.6872\n",
      "[964/1762] D loss: 1.4453, G loss: 0.9232\n",
      "[1044/1762] D loss: 1.4031, G loss: 0.8117\n",
      "[1124/1762] D loss: 0.2811, G loss: 1.7284\n",
      "[1204/1762] D loss: 1.1572, G loss: 1.8297\n",
      "[1284/1762] D loss: 0.3172, G loss: 2.1214\n",
      "[1364/1762] D loss: 1.5930, G loss: 0.3984\n",
      "[1444/1762] D loss: 1.5886, G loss: 1.2643\n",
      "[1524/1762] D loss: 1.4602, G loss: 0.5322\n",
      "[1604/1762] D loss: 1.6565, G loss: 0.3746\n",
      "[1684/1762] D loss: 1.3942, G loss: 0.7617\n",
      "[1762/1762] D loss: 1.4184, G loss: 0.6514\n",
      "train error: \n",
      " D loss: 1.325774, G loss: 0.655195, D accuracy: 56.7%, cell accuracy: 99.7%, board accuracy: 83.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.316451, G loss: 0.662336, D accuracy: 57.7%, cell accuracy: 99.7%, board accuracy: 81.1% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2485, G loss: 1.9295\n",
      "[84/1762] D loss: 1.4115, G loss: 0.5763\n",
      "[164/1762] D loss: 1.4013, G loss: 0.8805\n",
      "[244/1762] D loss: 0.2675, G loss: 1.7567\n",
      "[324/1762] D loss: 1.4618, G loss: 0.7924\n",
      "[404/1762] D loss: 0.4451, G loss: 1.3793\n",
      "[484/1762] D loss: 1.4604, G loss: 0.8393\n",
      "[564/1762] D loss: 1.3224, G loss: 0.8432\n",
      "[644/1762] D loss: 1.4772, G loss: 0.8933\n",
      "[724/1762] D loss: 1.4566, G loss: 0.5281\n",
      "[804/1762] D loss: 1.3943, G loss: 0.7472\n",
      "[884/1762] D loss: 0.3334, G loss: 1.5940\n",
      "[964/1762] D loss: 0.0596, G loss: 3.2659\n",
      "[1044/1762] D loss: 1.4857, G loss: 0.9485\n",
      "[1124/1762] D loss: 1.4113, G loss: 0.6444\n",
      "[1204/1762] D loss: 1.5130, G loss: 1.0707\n",
      "[1284/1762] D loss: 1.4269, G loss: 0.4614\n",
      "[1364/1762] D loss: 0.2183, G loss: 1.9927\n",
      "[1444/1762] D loss: 1.0678, G loss: 1.3996\n",
      "[1524/1762] D loss: 1.4483, G loss: 0.6639\n",
      "[1604/1762] D loss: 1.5362, G loss: 0.8484\n",
      "[1684/1762] D loss: 2.5721, G loss: 0.2713\n",
      "[1762/1762] D loss: 1.3835, G loss: 0.7313\n",
      "train error: \n",
      " D loss: 1.491972, G loss: 1.287846, D accuracy: 50.9%, cell accuracy: 99.7%, board accuracy: 82.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.506457, G loss: 1.313309, D accuracy: 50.8%, cell accuracy: 99.6%, board accuracy: 77.3% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4791, G loss: 1.4766\n",
      "[84/1762] D loss: 1.3925, G loss: 0.8076\n",
      "[164/1762] D loss: 1.3890, G loss: 0.7483\n",
      "[244/1762] D loss: 1.4387, G loss: 0.4990\n",
      "[324/1762] D loss: 0.7673, G loss: 2.1215\n",
      "[404/1762] D loss: 1.5873, G loss: 0.9503\n",
      "[484/1762] D loss: 1.4135, G loss: 0.8878\n",
      "[564/1762] D loss: 1.4051, G loss: 0.7491\n",
      "[644/1762] D loss: 1.4261, G loss: 0.7385\n",
      "[724/1762] D loss: 1.3959, G loss: 0.6803\n",
      "[804/1762] D loss: 1.3999, G loss: 0.6185\n",
      "[884/1762] D loss: 1.3992, G loss: 0.6528\n",
      "[964/1762] D loss: 1.4430, G loss: 1.0483\n",
      "[1044/1762] D loss: 0.3604, G loss: 1.3386\n",
      "[1124/1762] D loss: 1.9151, G loss: 1.3798\n",
      "[1204/1762] D loss: 0.3467, G loss: 1.6291\n",
      "[1284/1762] D loss: 1.5906, G loss: 1.0725\n",
      "[1364/1762] D loss: 0.3601, G loss: 1.4979\n",
      "[1444/1762] D loss: 1.3824, G loss: 0.6565\n",
      "[1524/1762] D loss: 1.3497, G loss: 0.7972\n",
      "[1604/1762] D loss: 1.3228, G loss: 0.8887\n",
      "[1684/1762] D loss: 1.4124, G loss: 0.4826\n",
      "[1762/1762] D loss: 1.4048, G loss: 0.7854\n",
      "train error: \n",
      " D loss: 1.338397, G loss: 0.705751, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 90.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.320197, G loss: 0.729183, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4048, G loss: 0.5567\n",
      "[84/1762] D loss: 1.4004, G loss: 0.8893\n",
      "[164/1762] D loss: 1.4181, G loss: 0.4949\n",
      "[244/1762] D loss: 0.2766, G loss: 1.8248\n",
      "[324/1762] D loss: 0.3380, G loss: 1.4276\n",
      "[404/1762] D loss: 0.2839, G loss: 1.8413\n",
      "[484/1762] D loss: 1.4001, G loss: 0.6818\n",
      "[564/1762] D loss: 1.5190, G loss: 1.0955\n",
      "[644/1762] D loss: 1.3941, G loss: 0.6795\n",
      "[724/1762] D loss: 1.4108, G loss: 0.8386\n",
      "[804/1762] D loss: 1.3975, G loss: 0.7565\n",
      "[884/1762] D loss: 1.3938, G loss: 0.8631\n",
      "[964/1762] D loss: 1.4397, G loss: 0.9959\n",
      "[1044/1762] D loss: 1.4943, G loss: 0.5618\n",
      "[1124/1762] D loss: 1.5285, G loss: 0.9306\n",
      "[1204/1762] D loss: 1.4273, G loss: 0.5643\n",
      "[1284/1762] D loss: 1.4818, G loss: 0.9033\n",
      "[1364/1762] D loss: 1.4205, G loss: 0.8464\n",
      "[1444/1762] D loss: 1.3495, G loss: 0.6857\n",
      "[1524/1762] D loss: 1.4454, G loss: 0.5905\n",
      "[1604/1762] D loss: 0.2290, G loss: 2.2870\n",
      "[1684/1762] D loss: 1.4797, G loss: 0.9876\n",
      "[1762/1762] D loss: 0.4797, G loss: 1.9285\n",
      "train error: \n",
      " D loss: 0.656231, G loss: 2.210711, D accuracy: 85.0%, cell accuracy: 98.8%, board accuracy: 27.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.649434, G loss: 2.228711, D accuracy: 85.1%, cell accuracy: 98.8%, board accuracy: 26.8% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5610, G loss: 0.6347\n",
      "[84/1762] D loss: 1.4875, G loss: 0.7657\n",
      "[164/1762] D loss: 0.0702, G loss: 3.3549\n",
      "[244/1762] D loss: 1.3537, G loss: 0.6419\n",
      "[324/1762] D loss: 0.3108, G loss: 1.8321\n",
      "[404/1762] D loss: 1.4841, G loss: 0.5251\n",
      "[484/1762] D loss: 1.4645, G loss: 0.9054\n",
      "[564/1762] D loss: 1.4285, G loss: 0.5642\n",
      "[644/1762] D loss: 1.6233, G loss: 1.2110\n",
      "[724/1762] D loss: 0.3791, G loss: 1.3811\n",
      "[804/1762] D loss: 1.3903, G loss: 0.7073\n",
      "[884/1762] D loss: 0.4084, G loss: 1.2988\n",
      "[964/1762] D loss: 1.4288, G loss: 0.9057\n",
      "[1044/1762] D loss: 0.3219, G loss: 1.3679\n",
      "[1124/1762] D loss: 0.2309, G loss: 1.9083\n",
      "[1204/1762] D loss: 1.4024, G loss: 0.6855\n",
      "[1284/1762] D loss: 1.3966, G loss: 0.5184\n",
      "[1364/1762] D loss: 0.0963, G loss: 3.0459\n",
      "[1444/1762] D loss: 0.3411, G loss: 1.4223\n",
      "[1524/1762] D loss: 1.3473, G loss: 0.7127\n",
      "[1604/1762] D loss: 1.3920, G loss: 0.8679\n",
      "[1684/1762] D loss: 1.4258, G loss: 0.6872\n",
      "[1762/1762] D loss: 1.3838, G loss: 0.8158\n",
      "train error: \n",
      " D loss: 1.356484, G loss: 0.896781, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.342146, G loss: 0.915157, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5248, G loss: 1.1213\n",
      "[84/1762] D loss: 1.4835, G loss: 1.1680\n",
      "[164/1762] D loss: 1.3979, G loss: 0.6784\n",
      "[244/1762] D loss: 0.1986, G loss: 2.4562\n",
      "[324/1762] D loss: 1.4432, G loss: 0.4091\n",
      "[404/1762] D loss: 0.4879, G loss: 1.4220\n",
      "[484/1762] D loss: 1.4176, G loss: 0.7427\n",
      "[564/1762] D loss: 1.4024, G loss: 0.6616\n",
      "[644/1762] D loss: 1.4257, G loss: 0.5719\n",
      "[724/1762] D loss: 1.4835, G loss: 1.0111\n",
      "[804/1762] D loss: 1.5166, G loss: 1.0446\n",
      "[884/1762] D loss: 0.2642, G loss: 1.9026\n",
      "[964/1762] D loss: 1.5012, G loss: 1.0198\n",
      "[1044/1762] D loss: 0.2653, G loss: 1.5191\n",
      "[1124/1762] D loss: 1.4165, G loss: 0.8144\n",
      "[1204/1762] D loss: 0.0582, G loss: 3.0025\n",
      "[1284/1762] D loss: 1.3926, G loss: 0.7553\n",
      "[1364/1762] D loss: 1.3467, G loss: 0.8369\n",
      "[1444/1762] D loss: 0.3460, G loss: 1.6741\n",
      "[1524/1762] D loss: 1.4674, G loss: 0.9424\n",
      "[1604/1762] D loss: 1.3933, G loss: 0.7192\n",
      "[1684/1762] D loss: 1.4128, G loss: 0.9695\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6964\n",
      "train error: \n",
      " D loss: 1.348013, G loss: 0.691330, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.327995, G loss: 0.699122, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3916, G loss: 0.7483\n",
      "[84/1762] D loss: 1.6113, G loss: 1.1566\n",
      "[164/1762] D loss: 0.3159, G loss: 1.3329\n",
      "[244/1762] D loss: 1.4060, G loss: 0.7488\n",
      "[324/1762] D loss: 1.4702, G loss: 0.9185\n",
      "[404/1762] D loss: 1.3958, G loss: 0.7549\n",
      "[484/1762] D loss: 1.4148, G loss: 0.7953\n",
      "[564/1762] D loss: 1.3954, G loss: 0.5775\n",
      "[644/1762] D loss: 1.3979, G loss: 0.7014\n",
      "[724/1762] D loss: 1.4163, G loss: 0.9544\n",
      "[804/1762] D loss: 1.1380, G loss: 1.3519\n",
      "[884/1762] D loss: 1.4230, G loss: 0.6740\n",
      "[964/1762] D loss: 0.2509, G loss: 1.7712\n",
      "[1044/1762] D loss: 1.4505, G loss: 0.8452\n",
      "[1124/1762] D loss: 1.4277, G loss: 0.7085\n",
      "[1204/1762] D loss: 1.4282, G loss: 0.8199\n",
      "[1284/1762] D loss: 0.1702, G loss: 2.2006\n",
      "[1364/1762] D loss: 1.3573, G loss: 0.5802\n",
      "[1444/1762] D loss: 1.4097, G loss: 0.6840\n",
      "[1524/1762] D loss: 1.2976, G loss: 0.8133\n",
      "[1604/1762] D loss: 0.1179, G loss: 2.6217\n",
      "[1684/1762] D loss: 1.3791, G loss: 0.7680\n",
      "[1762/1762] D loss: 0.0445, G loss: 3.4830\n",
      "train error: \n",
      " D loss: 1.351583, G loss: 0.785035, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.341347, G loss: 0.803420, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3913, G loss: 0.7192\n",
      "[84/1762] D loss: 1.5273, G loss: 0.4958\n",
      "[164/1762] D loss: 1.3852, G loss: 0.6981\n",
      "[244/1762] D loss: 0.2973, G loss: 1.5783\n",
      "[324/1762] D loss: 1.4066, G loss: 0.4555\n",
      "[404/1762] D loss: 1.4703, G loss: 1.1390\n",
      "[484/1762] D loss: 0.3160, G loss: 1.5852\n",
      "[564/1762] D loss: 1.4750, G loss: 0.8786\n",
      "[644/1762] D loss: 1.4624, G loss: 0.9828\n",
      "[724/1762] D loss: 1.4106, G loss: 0.4950\n",
      "[804/1762] D loss: 0.1764, G loss: 2.4194\n",
      "[884/1762] D loss: 0.1183, G loss: 2.3149\n",
      "[964/1762] D loss: 1.5622, G loss: 0.4442\n",
      "[1044/1762] D loss: 1.0621, G loss: 0.8661\n",
      "[1124/1762] D loss: 0.4514, G loss: 3.0782\n",
      "[1204/1762] D loss: 0.9897, G loss: 3.0924\n",
      "[1284/1762] D loss: 1.6424, G loss: 1.9392\n",
      "[1364/1762] D loss: 1.4115, G loss: 0.9414\n",
      "[1444/1762] D loss: 1.4010, G loss: 0.6602\n",
      "[1524/1762] D loss: 1.5274, G loss: 1.1779\n",
      "[1604/1762] D loss: 1.3949, G loss: 0.7687\n",
      "[1684/1762] D loss: 0.2448, G loss: 1.6410\n",
      "[1762/1762] D loss: 1.4712, G loss: 0.9270\n",
      "train error: \n",
      " D loss: 1.363387, G loss: 0.901972, D accuracy: 52.9%, cell accuracy: 99.9%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.354706, G loss: 0.914706, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4095, G loss: 0.6749\n",
      "[84/1762] D loss: 0.1903, G loss: 2.0931\n",
      "[164/1762] D loss: 0.1889, G loss: 1.9712\n",
      "[244/1762] D loss: 0.3390, G loss: 1.6052\n",
      "[324/1762] D loss: 1.3944, G loss: 0.8399\n",
      "[404/1762] D loss: 0.2759, G loss: 1.4789\n",
      "[484/1762] D loss: 1.5008, G loss: 0.9207\n",
      "[564/1762] D loss: 0.2378, G loss: 1.7437\n",
      "[644/1762] D loss: 0.2412, G loss: 1.4957\n",
      "[724/1762] D loss: 0.0400, G loss: 3.7303\n",
      "[804/1762] D loss: 0.1842, G loss: 1.7066\n",
      "[884/1762] D loss: 0.2496, G loss: 1.5323\n",
      "[964/1762] D loss: 1.4279, G loss: 0.7418\n",
      "[1044/1762] D loss: 0.3168, G loss: 1.6591\n",
      "[1124/1762] D loss: 1.4008, G loss: 0.9932\n",
      "[1204/1762] D loss: 0.2855, G loss: 1.4438\n",
      "[1284/1762] D loss: 0.2506, G loss: 1.8037\n",
      "[1364/1762] D loss: 0.1374, G loss: 1.8807\n",
      "[1444/1762] D loss: 1.4089, G loss: 0.6296\n",
      "[1524/1762] D loss: 1.4401, G loss: 0.8584\n",
      "[1604/1762] D loss: 0.1669, G loss: 2.1948\n",
      "[1684/1762] D loss: 1.4192, G loss: 0.6246\n",
      "[1762/1762] D loss: 1.5397, G loss: 1.0485\n",
      "train error: \n",
      " D loss: 1.353024, G loss: 0.814418, D accuracy: 53.2%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.341266, G loss: 0.831992, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1383, G loss: 2.4781\n",
      "[84/1762] D loss: 1.4048, G loss: 0.8186\n",
      "[164/1762] D loss: 1.5507, G loss: 0.3675\n",
      "[244/1762] D loss: 0.0418, G loss: 3.6998\n",
      "[324/1762] D loss: 0.8641, G loss: 2.3145\n",
      "[404/1762] D loss: 1.4794, G loss: 1.1703\n",
      "[484/1762] D loss: 1.6254, G loss: 0.5193\n",
      "[564/1762] D loss: 1.4677, G loss: 1.0745\n",
      "[644/1762] D loss: 1.4291, G loss: 0.6860\n",
      "[724/1762] D loss: 1.3984, G loss: 0.8144\n",
      "[804/1762] D loss: 2.0640, G loss: 1.7621\n",
      "[884/1762] D loss: 1.4851, G loss: 0.7191\n",
      "[964/1762] D loss: 1.6354, G loss: 0.3343\n",
      "[1044/1762] D loss: 0.5212, G loss: 1.0390\n",
      "[1124/1762] D loss: 1.3850, G loss: 0.7262\n",
      "[1204/1762] D loss: 1.3986, G loss: 0.8596\n",
      "[1284/1762] D loss: 1.4767, G loss: 0.8757\n",
      "[1364/1762] D loss: 0.0558, G loss: 3.2137\n",
      "[1444/1762] D loss: 0.2068, G loss: 2.2334\n",
      "[1524/1762] D loss: 0.3616, G loss: 1.2544\n",
      "[1604/1762] D loss: 1.4315, G loss: 0.8021\n",
      "[1684/1762] D loss: 1.3939, G loss: 0.7729\n",
      "[1762/1762] D loss: 1.4073, G loss: 0.8621\n",
      "train error: \n",
      " D loss: 1.372685, G loss: 0.581384, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.359783, G loss: 0.585034, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4301, G loss: 0.7401\n",
      "[84/1762] D loss: 0.2412, G loss: 1.8440\n",
      "[164/1762] D loss: 1.5699, G loss: 1.0994\n",
      "[244/1762] D loss: 1.4005, G loss: 0.7464\n",
      "[324/1762] D loss: 1.4853, G loss: 1.1001\n",
      "[404/1762] D loss: 1.4156, G loss: 0.8231\n",
      "[484/1762] D loss: 1.3975, G loss: 0.7125\n",
      "[564/1762] D loss: 1.3954, G loss: 0.7716\n",
      "[644/1762] D loss: 1.4220, G loss: 0.8115\n",
      "[724/1762] D loss: 0.2560, G loss: 1.4829\n",
      "[804/1762] D loss: 1.4117, G loss: 0.5075\n",
      "[884/1762] D loss: 1.3033, G loss: 1.0684\n",
      "[964/1762] D loss: 1.4128, G loss: 0.6731\n",
      "[1044/1762] D loss: 1.4053, G loss: 0.6902\n",
      "[1124/1762] D loss: 1.5149, G loss: 0.9329\n",
      "[1204/1762] D loss: 0.2560, G loss: 1.4130\n",
      "[1284/1762] D loss: 1.3935, G loss: 0.6808\n",
      "[1364/1762] D loss: 1.4125, G loss: 0.5753\n",
      "[1444/1762] D loss: 0.2410, G loss: 1.7706\n",
      "[1524/1762] D loss: 1.4233, G loss: 0.8364\n",
      "[1604/1762] D loss: 1.4140, G loss: 0.7927\n",
      "[1684/1762] D loss: 1.3955, G loss: 0.7290\n",
      "[1762/1762] D loss: 0.0206, G loss: 4.4787\n",
      "train error: \n",
      " D loss: 1.588761, G loss: 0.341109, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.571102, G loss: 0.352966, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1084, G loss: 3.0833\n",
      "[84/1762] D loss: 0.1293, G loss: 2.1640\n",
      "[164/1762] D loss: 1.4080, G loss: 0.5309\n",
      "[244/1762] D loss: 1.4309, G loss: 0.5967\n",
      "[324/1762] D loss: 1.4516, G loss: 0.5630\n",
      "[404/1762] D loss: 1.4699, G loss: 0.8776\n",
      "[484/1762] D loss: 0.2059, G loss: 1.7116\n",
      "[564/1762] D loss: 1.3962, G loss: 0.6453\n",
      "[644/1762] D loss: 0.1162, G loss: 2.4565\n",
      "[724/1762] D loss: 0.2612, G loss: 1.7159\n",
      "[804/1762] D loss: 1.4070, G loss: 0.7554\n",
      "[884/1762] D loss: 1.4152, G loss: 0.5696\n",
      "[964/1762] D loss: 1.3871, G loss: 0.7677\n",
      "[1044/1762] D loss: 1.3991, G loss: 0.6989\n",
      "[1124/1762] D loss: 1.4389, G loss: 0.9418\n",
      "[1204/1762] D loss: 1.3913, G loss: 0.6818\n",
      "[1284/1762] D loss: 1.4068, G loss: 0.7307\n",
      "[1364/1762] D loss: 1.3975, G loss: 0.7873\n",
      "[1444/1762] D loss: 0.1644, G loss: 2.1033\n",
      "[1524/1762] D loss: 1.3909, G loss: 0.6584\n",
      "[1604/1762] D loss: 1.4397, G loss: 0.5556\n",
      "[1684/1762] D loss: 1.2845, G loss: 1.0928\n",
      "[1762/1762] D loss: 0.0372, G loss: 3.9117\n",
      "train error: \n",
      " D loss: 1.888425, G loss: 0.221940, D accuracy: 50.6%, cell accuracy: 99.8%, board accuracy: 83.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.868750, G loss: 0.229142, D accuracy: 50.8%, cell accuracy: 99.8%, board accuracy: 81.4% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9311, G loss: 1.0418\n",
      "[84/1762] D loss: 1.0673, G loss: 2.0049\n",
      "[164/1762] D loss: 1.4115, G loss: 0.6135\n",
      "[244/1762] D loss: 1.1345, G loss: 0.9459\n",
      "[324/1762] D loss: 1.4137, G loss: 0.6756\n",
      "[404/1762] D loss: 1.5342, G loss: 0.9512\n",
      "[484/1762] D loss: 1.1980, G loss: 1.0301\n",
      "[564/1762] D loss: 1.4833, G loss: 1.1440\n",
      "[644/1762] D loss: 1.4612, G loss: 0.8332\n",
      "[724/1762] D loss: 0.1864, G loss: 1.9448\n",
      "[804/1762] D loss: 1.4828, G loss: 0.9633\n",
      "[884/1762] D loss: 1.3850, G loss: 0.7320\n",
      "[964/1762] D loss: 0.1474, G loss: 1.9017\n",
      "[1044/1762] D loss: 0.1570, G loss: 2.1453\n",
      "[1124/1762] D loss: 1.4063, G loss: 0.7557\n",
      "[1204/1762] D loss: 0.3159, G loss: 1.6502\n",
      "[1284/1762] D loss: 1.4179, G loss: 0.8519\n",
      "[1364/1762] D loss: 1.4270, G loss: 0.8005\n",
      "[1444/1762] D loss: 1.4206, G loss: 0.5767\n",
      "[1524/1762] D loss: 1.4563, G loss: 0.9983\n",
      "[1604/1762] D loss: 1.4292, G loss: 0.8656\n",
      "[1684/1762] D loss: 1.3967, G loss: 0.6883\n",
      "[1762/1762] D loss: 0.0465, G loss: 3.4071\n",
      "train error: \n",
      " D loss: 1.465607, G loss: 0.444277, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.450471, G loss: 0.456913, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4073, G loss: 0.7540\n",
      "[84/1762] D loss: 1.4280, G loss: 0.8408\n",
      "[164/1762] D loss: 1.3894, G loss: 0.6663\n",
      "[244/1762] D loss: 1.3973, G loss: 0.6643\n",
      "[324/1762] D loss: 1.5043, G loss: 0.9849\n",
      "[404/1762] D loss: 1.3944, G loss: 0.7322\n",
      "[484/1762] D loss: 1.4101, G loss: 0.5288\n",
      "[564/1762] D loss: 0.2055, G loss: 1.9075\n",
      "[644/1762] D loss: 0.2512, G loss: 1.8755\n",
      "[724/1762] D loss: 1.5976, G loss: 1.0619\n",
      "[804/1762] D loss: 1.4265, G loss: 0.5734\n",
      "[884/1762] D loss: 0.1000, G loss: 2.5121\n",
      "[964/1762] D loss: 1.4171, G loss: 0.6201\n",
      "[1044/1762] D loss: 1.4576, G loss: 0.8512\n",
      "[1124/1762] D loss: 1.4163, G loss: 0.7687\n",
      "[1204/1762] D loss: 1.7183, G loss: 1.1973\n",
      "[1284/1762] D loss: 1.5412, G loss: 0.4113\n",
      "[1364/1762] D loss: 0.1378, G loss: 2.3453\n",
      "[1444/1762] D loss: 1.4023, G loss: 1.0307\n",
      "[1524/1762] D loss: 1.4036, G loss: 0.5149\n",
      "[1604/1762] D loss: 1.3936, G loss: 0.7013\n",
      "[1684/1762] D loss: 0.1907, G loss: 1.9500\n",
      "[1762/1762] D loss: 1.0819, G loss: 0.7566\n",
      "train error: \n",
      " D loss: 1.524268, G loss: 0.395510, D accuracy: 53.0%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.503267, G loss: 0.410484, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5485, G loss: 0.4688\n",
      "[84/1762] D loss: 1.4023, G loss: 0.8061\n",
      "[164/1762] D loss: 1.3975, G loss: 0.7568\n",
      "[244/1762] D loss: 1.3889, G loss: 0.7684\n",
      "[324/1762] D loss: 0.2389, G loss: 1.6406\n",
      "[404/1762] D loss: 1.2587, G loss: 0.7934\n",
      "[484/1762] D loss: 1.4072, G loss: 0.6372\n",
      "[564/1762] D loss: 0.1176, G loss: 2.3452\n",
      "[644/1762] D loss: 1.3869, G loss: 0.6130\n",
      "[724/1762] D loss: 0.1460, G loss: 2.1803\n",
      "[804/1762] D loss: 0.2170, G loss: 1.8530\n",
      "[884/1762] D loss: 1.7055, G loss: 1.2414\n",
      "[964/1762] D loss: 1.4855, G loss: 0.4831\n",
      "[1044/1762] D loss: 1.4744, G loss: 0.5295\n",
      "[1124/1762] D loss: 1.8942, G loss: 0.2421\n",
      "[1204/1762] D loss: 1.1553, G loss: 0.9233\n",
      "[1284/1762] D loss: 1.2014, G loss: 1.1488\n",
      "[1364/1762] D loss: 1.4273, G loss: 0.8116\n",
      "[1444/1762] D loss: 0.1256, G loss: 2.1995\n",
      "[1524/1762] D loss: 0.2896, G loss: 1.5184\n",
      "[1604/1762] D loss: 1.4343, G loss: 0.6326\n",
      "[1684/1762] D loss: 0.1906, G loss: 2.0096\n",
      "[1762/1762] D loss: 1.4214, G loss: 0.5988\n",
      "train error: \n",
      " D loss: 1.542520, G loss: 0.385749, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.512493, G loss: 0.416628, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4034, G loss: 0.6905\n",
      "[84/1762] D loss: 1.3140, G loss: 0.8474\n",
      "[164/1762] D loss: 1.4292, G loss: 0.7726\n",
      "[244/1762] D loss: 0.2700, G loss: 1.5856\n",
      "[324/1762] D loss: 1.4027, G loss: 0.6889\n",
      "[404/1762] D loss: 0.1260, G loss: 2.4972\n",
      "[484/1762] D loss: 1.5550, G loss: 0.3408\n",
      "[564/1762] D loss: 1.4941, G loss: 0.9868\n",
      "[644/1762] D loss: 1.6018, G loss: 0.4340\n",
      "[724/1762] D loss: 1.4813, G loss: 1.1737\n",
      "[804/1762] D loss: 1.4916, G loss: 1.0428\n",
      "[884/1762] D loss: 1.4330, G loss: 0.7994\n",
      "[964/1762] D loss: 1.3935, G loss: 0.6693\n",
      "[1044/1762] D loss: 1.3861, G loss: 0.6549\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.7190\n",
      "[1204/1762] D loss: 0.2234, G loss: 1.8817\n",
      "[1284/1762] D loss: 0.1120, G loss: 2.2483\n",
      "[1364/1762] D loss: 1.3898, G loss: 0.7365\n",
      "[1444/1762] D loss: 1.5855, G loss: 1.1172\n",
      "[1524/1762] D loss: 1.4025, G loss: 0.5848\n",
      "[1604/1762] D loss: 1.4271, G loss: 0.8805\n",
      "[1684/1762] D loss: 1.3972, G loss: 0.8627\n",
      "[1762/1762] D loss: 1.3888, G loss: 0.7015\n",
      "train error: \n",
      " D loss: 1.423103, G loss: 0.510902, D accuracy: 52.7%, cell accuracy: 99.9%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.417925, G loss: 0.516391, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0962, G loss: 2.5724\n",
      "[84/1762] D loss: 1.4016, G loss: 0.6207\n",
      "[164/1762] D loss: 1.3993, G loss: 0.6105\n",
      "[244/1762] D loss: 0.0130, G loss: 4.8016\n",
      "[324/1762] D loss: 1.3943, G loss: 0.6609\n",
      "[404/1762] D loss: 1.4298, G loss: 0.9106\n",
      "[484/1762] D loss: 1.4205, G loss: 0.5408\n",
      "[564/1762] D loss: 1.5017, G loss: 0.9283\n",
      "[644/1762] D loss: 1.1369, G loss: 1.0206\n",
      "[724/1762] D loss: 1.2096, G loss: 1.2067\n",
      "[804/1762] D loss: 1.6859, G loss: 1.2593\n",
      "[884/1762] D loss: 1.4388, G loss: 0.5368\n",
      "[964/1762] D loss: 1.4018, G loss: 0.8557\n",
      "[1044/1762] D loss: 1.3825, G loss: 0.4965\n",
      "[1124/1762] D loss: 1.4027, G loss: 0.6996\n",
      "[1204/1762] D loss: 0.3213, G loss: 1.4564\n",
      "[1284/1762] D loss: 1.3993, G loss: 0.6813\n",
      "[1364/1762] D loss: 0.2778, G loss: 1.6367\n",
      "[1444/1762] D loss: 1.4097, G loss: 0.8951\n",
      "[1524/1762] D loss: 0.1744, G loss: 1.9998\n",
      "[1604/1762] D loss: 0.1925, G loss: 1.8557\n",
      "[1684/1762] D loss: 1.4026, G loss: 0.7165\n",
      "[1762/1762] D loss: 1.5365, G loss: 1.0277\n",
      "train error: \n",
      " D loss: 1.451933, G loss: 0.819813, D accuracy: 50.6%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.461457, G loss: 0.836194, D accuracy: 50.6%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3801, G loss: 0.7096\n",
      "[84/1762] D loss: 1.4404, G loss: 0.9519\n",
      "[164/1762] D loss: 1.1448, G loss: 1.1871\n",
      "[244/1762] D loss: 1.4842, G loss: 0.8417\n",
      "[324/1762] D loss: 1.4126, G loss: 0.6468\n",
      "[404/1762] D loss: 1.4082, G loss: 0.7686\n",
      "[484/1762] D loss: 0.0222, G loss: 4.1372\n",
      "[564/1762] D loss: 0.1741, G loss: 1.9687\n",
      "[644/1762] D loss: 1.3991, G loss: 0.6366\n",
      "[724/1762] D loss: 0.2821, G loss: 1.5908\n",
      "[804/1762] D loss: 0.0155, G loss: 4.7422\n",
      "[884/1762] D loss: 1.2094, G loss: 0.6732\n",
      "[964/1762] D loss: 1.4339, G loss: 0.6100\n",
      "[1044/1762] D loss: 0.0158, G loss: 4.4808\n",
      "[1124/1762] D loss: 0.1682, G loss: 1.9480\n",
      "[1204/1762] D loss: 0.0640, G loss: 2.8688\n",
      "[1284/1762] D loss: 1.4741, G loss: 0.5949\n",
      "[1364/1762] D loss: 1.6177, G loss: 1.2288\n",
      "[1444/1762] D loss: 1.3978, G loss: 0.7211\n",
      "[1524/1762] D loss: 0.2408, G loss: 1.7335\n",
      "[1604/1762] D loss: 1.4057, G loss: 0.8383\n",
      "[1684/1762] D loss: 1.4367, G loss: 0.5206\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.7063\n",
      "train error: \n",
      " D loss: 1.398817, G loss: 0.759899, D accuracy: 51.7%, cell accuracy: 99.8%, board accuracy: 88.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.395919, G loss: 0.755977, D accuracy: 52.2%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5046, G loss: 0.8574\n",
      "[84/1762] D loss: 0.6870, G loss: 0.9294\n",
      "[164/1762] D loss: 1.3759, G loss: 0.7058\n",
      "[244/1762] D loss: 0.1769, G loss: 2.1033\n",
      "[324/1762] D loss: 0.1098, G loss: 2.1813\n",
      "[404/1762] D loss: 1.1973, G loss: 0.8485\n",
      "[484/1762] D loss: 0.1404, G loss: 2.3029\n",
      "[564/1762] D loss: 1.4358, G loss: 0.4580\n",
      "[644/1762] D loss: 1.3979, G loss: 0.6913\n",
      "[724/1762] D loss: 0.1251, G loss: 2.2498\n",
      "[804/1762] D loss: 1.4845, G loss: 0.4317\n",
      "[884/1762] D loss: 0.1852, G loss: 2.0807\n",
      "[964/1762] D loss: 1.4045, G loss: 0.6241\n",
      "[1044/1762] D loss: 1.3899, G loss: 0.7277\n",
      "[1124/1762] D loss: 1.3978, G loss: 0.7226\n",
      "[1204/1762] D loss: 1.3962, G loss: 0.6484\n",
      "[1284/1762] D loss: 1.4516, G loss: 0.9029\n",
      "[1364/1762] D loss: 1.4119, G loss: 0.6751\n",
      "[1444/1762] D loss: 1.4288, G loss: 0.7641\n",
      "[1524/1762] D loss: 1.4150, G loss: 0.9022\n",
      "[1604/1762] D loss: 1.4484, G loss: 0.5058\n",
      "[1684/1762] D loss: 1.4487, G loss: 1.0193\n",
      "[1762/1762] D loss: 1.4032, G loss: 0.5383\n",
      "train error: \n",
      " D loss: 1.511308, G loss: 0.453567, D accuracy: 51.2%, cell accuracy: 99.9%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.517962, G loss: 0.457750, D accuracy: 51.7%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2260, G loss: 1.6253\n",
      "[84/1762] D loss: 1.3922, G loss: 0.6865\n",
      "[164/1762] D loss: 0.1367, G loss: 2.2283\n",
      "[244/1762] D loss: 1.4313, G loss: 0.8859\n",
      "[324/1762] D loss: 1.4009, G loss: 0.7128\n",
      "[404/1762] D loss: 1.4101, G loss: 0.9111\n",
      "[484/1762] D loss: 1.4402, G loss: 0.8362\n",
      "[564/1762] D loss: 1.3634, G loss: 0.8757\n",
      "[644/1762] D loss: 1.3893, G loss: 0.6074\n",
      "[724/1762] D loss: 1.4327, G loss: 0.9696\n",
      "[804/1762] D loss: 0.0951, G loss: 2.5848\n",
      "[884/1762] D loss: 1.4010, G loss: 0.6533\n",
      "[964/1762] D loss: 0.1974, G loss: 1.9808\n",
      "[1044/1762] D loss: 1.4322, G loss: 0.8923\n",
      "[1124/1762] D loss: 1.4657, G loss: 0.9206\n",
      "[1204/1762] D loss: 1.4080, G loss: 0.6321\n",
      "[1284/1762] D loss: 1.3957, G loss: 0.6648\n",
      "[1364/1762] D loss: 0.1000, G loss: 2.3475\n",
      "[1444/1762] D loss: 1.3963, G loss: 0.6958\n",
      "[1524/1762] D loss: 1.4865, G loss: 0.5986\n",
      "[1604/1762] D loss: 0.6973, G loss: 2.1132\n",
      "[1684/1762] D loss: 1.6793, G loss: 0.3571\n",
      "[1762/1762] D loss: 1.4172, G loss: 0.5334\n",
      "train error: \n",
      " D loss: 1.729919, G loss: 0.498789, D accuracy: 49.2%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.793391, G loss: 0.525576, D accuracy: 49.2%, cell accuracy: 99.7%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5376, G loss: 0.4372\n",
      "[84/1762] D loss: 0.2674, G loss: 1.6803\n",
      "[164/1762] D loss: 1.4294, G loss: 0.5117\n",
      "[244/1762] D loss: 1.4335, G loss: 0.7743\n",
      "[324/1762] D loss: 0.1439, G loss: 2.4071\n",
      "[404/1762] D loss: 1.4277, G loss: 0.7008\n",
      "[484/1762] D loss: 1.3888, G loss: 0.6748\n",
      "[564/1762] D loss: 1.3962, G loss: 0.7189\n",
      "[644/1762] D loss: 1.4182, G loss: 0.8980\n",
      "[724/1762] D loss: 1.4418, G loss: 0.8310\n",
      "[804/1762] D loss: 1.3875, G loss: 0.7145\n",
      "[884/1762] D loss: 1.3911, G loss: 0.6121\n",
      "[964/1762] D loss: 1.4106, G loss: 0.7752\n",
      "[1044/1762] D loss: 1.3887, G loss: 0.7102\n",
      "[1124/1762] D loss: 0.0015, G loss: 8.0660\n",
      "[1204/1762] D loss: 1.4223, G loss: 0.6517\n",
      "[1284/1762] D loss: 0.0996, G loss: 2.6628\n",
      "[1364/1762] D loss: 1.3909, G loss: 0.7285\n",
      "[1444/1762] D loss: 1.3940, G loss: 0.8453\n",
      "[1524/1762] D loss: 1.4578, G loss: 0.8023\n",
      "[1604/1762] D loss: 1.3964, G loss: 0.6342\n",
      "[1684/1762] D loss: 0.0406, G loss: 3.8454\n",
      "[1762/1762] D loss: 1.3974, G loss: 0.6900\n",
      "train error: \n",
      " D loss: 1.502822, G loss: 0.689216, D accuracy: 50.4%, cell accuracy: 99.8%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.494713, G loss: 0.731265, D accuracy: 50.6%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4506, G loss: 0.7700\n",
      "[84/1762] D loss: 1.4305, G loss: 0.6119\n",
      "[164/1762] D loss: 1.3908, G loss: 0.6874\n",
      "[244/1762] D loss: 0.1909, G loss: 1.9342\n",
      "[324/1762] D loss: 1.3947, G loss: 0.7459\n",
      "[404/1762] D loss: 1.4054, G loss: 0.8273\n",
      "[484/1762] D loss: 1.3934, G loss: 0.6102\n",
      "[564/1762] D loss: 1.4055, G loss: 0.8816\n",
      "[644/1762] D loss: 1.4008, G loss: 0.7241\n",
      "[724/1762] D loss: 0.2286, G loss: 1.6767\n",
      "[804/1762] D loss: 1.3885, G loss: 0.6069\n",
      "[884/1762] D loss: 1.4127, G loss: 0.5940\n",
      "[964/1762] D loss: 1.5017, G loss: 1.0001\n",
      "[1044/1762] D loss: 1.4093, G loss: 0.6241\n",
      "[1124/1762] D loss: 1.4018, G loss: 0.8026\n",
      "[1204/1762] D loss: 1.3917, G loss: 0.6021\n",
      "[1284/1762] D loss: 1.4058, G loss: 0.7764\n",
      "[1364/1762] D loss: 1.3847, G loss: 0.5270\n",
      "[1444/1762] D loss: 1.3948, G loss: 0.7179\n",
      "[1524/1762] D loss: 1.3932, G loss: 0.6837\n",
      "[1604/1762] D loss: 1.4149, G loss: 0.6122\n",
      "[1684/1762] D loss: 1.4659, G loss: 0.9128\n",
      "[1762/1762] D loss: 1.4229, G loss: 0.5833\n",
      "train error: \n",
      " D loss: 1.640461, G loss: 0.390058, D accuracy: 50.9%, cell accuracy: 99.9%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.646161, G loss: 0.409591, D accuracy: 51.2%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4508, G loss: 0.5633\n",
      "[84/1762] D loss: 1.4047, G loss: 0.7734\n",
      "[164/1762] D loss: 1.4007, G loss: 0.6311\n",
      "[244/1762] D loss: 0.0851, G loss: 2.7336\n",
      "[324/1762] D loss: 1.4031, G loss: 0.5717\n",
      "[404/1762] D loss: 1.4598, G loss: 0.9364\n",
      "[484/1762] D loss: 0.2759, G loss: 1.5408\n",
      "[564/1762] D loss: 1.3943, G loss: 0.8140\n",
      "[644/1762] D loss: 0.1235, G loss: 2.1628\n",
      "[724/1762] D loss: 0.1538, G loss: 2.1050\n",
      "[804/1762] D loss: 1.4061, G loss: 0.8753\n",
      "[884/1762] D loss: 0.1262, G loss: 2.2048\n",
      "[964/1762] D loss: 0.0961, G loss: 2.6896\n",
      "[1044/1762] D loss: 1.3924, G loss: 0.6154\n",
      "[1124/1762] D loss: 1.4019, G loss: 0.6414\n",
      "[1204/1762] D loss: 1.3930, G loss: 0.7273\n",
      "[1284/1762] D loss: 1.4758, G loss: 0.9061\n",
      "[1364/1762] D loss: 1.3914, G loss: 0.7409\n",
      "[1444/1762] D loss: 1.3973, G loss: 0.7493\n",
      "[1524/1762] D loss: 1.4265, G loss: 0.8984\n",
      "[1604/1762] D loss: 1.4276, G loss: 0.5425\n",
      "[1684/1762] D loss: 1.3893, G loss: 0.7045\n",
      "[1762/1762] D loss: 1.4397, G loss: 0.9915\n",
      "train error: \n",
      " D loss: 1.604632, G loss: 0.948929, D accuracy: 50.6%, cell accuracy: 99.9%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.649424, G loss: 0.976655, D accuracy: 50.6%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5615, G loss: 1.0800\n",
      "[84/1762] D loss: 1.3933, G loss: 0.7422\n",
      "[164/1762] D loss: 1.4370, G loss: 0.8201\n",
      "[244/1762] D loss: 1.4100, G loss: 0.7702\n",
      "[324/1762] D loss: 1.4437, G loss: 0.5713\n",
      "[404/1762] D loss: 1.4238, G loss: 0.5799\n",
      "[484/1762] D loss: 1.5247, G loss: 1.0297\n",
      "[564/1762] D loss: 0.0773, G loss: 2.7988\n",
      "[644/1762] D loss: 1.4409, G loss: 0.5414\n",
      "[724/1762] D loss: 1.4348, G loss: 0.9360\n",
      "[804/1762] D loss: 1.4017, G loss: 0.6086\n",
      "[884/1762] D loss: 1.4005, G loss: 0.7199\n",
      "[964/1762] D loss: 1.4052, G loss: 0.7770\n",
      "[1044/1762] D loss: 1.3945, G loss: 0.7264\n",
      "[1124/1762] D loss: 1.3848, G loss: 0.6506\n",
      "[1204/1762] D loss: 1.4407, G loss: 0.5807\n",
      "[1284/1762] D loss: 1.4416, G loss: 0.8612\n",
      "[1364/1762] D loss: 1.4409, G loss: 0.7561\n",
      "[1444/1762] D loss: 1.4047, G loss: 0.8893\n",
      "[1524/1762] D loss: 1.4319, G loss: 0.8033\n",
      "[1604/1762] D loss: 0.1156, G loss: 2.7384\n",
      "[1684/1762] D loss: 1.3205, G loss: 0.7329\n",
      "[1762/1762] D loss: 1.7345, G loss: 0.6614\n",
      "train error: \n",
      " D loss: 1.733009, G loss: 1.656854, D accuracy: 50.6%, cell accuracy: 99.7%, board accuracy: 80.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.770456, G loss: 1.713229, D accuracy: 50.7%, cell accuracy: 99.7%, board accuracy: 76.8% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1844, G loss: 0.7313\n",
      "[84/1762] D loss: 1.5073, G loss: 0.5202\n",
      "[164/1762] D loss: 0.1423, G loss: 1.8932\n",
      "[244/1762] D loss: 1.4211, G loss: 0.8627\n",
      "[324/1762] D loss: 1.3644, G loss: 2.0120\n",
      "[404/1762] D loss: 1.3782, G loss: 0.8842\n",
      "[484/1762] D loss: 1.6818, G loss: 1.3691\n",
      "[564/1762] D loss: 1.4357, G loss: 0.5500\n",
      "[644/1762] D loss: 1.2737, G loss: 1.1960\n",
      "[724/1762] D loss: 1.4522, G loss: 0.6770\n",
      "[804/1762] D loss: 1.4268, G loss: 0.5717\n",
      "[884/1762] D loss: 1.4536, G loss: 0.5552\n",
      "[964/1762] D loss: 1.3911, G loss: 0.7989\n",
      "[1044/1762] D loss: 1.4904, G loss: 0.6472\n",
      "[1124/1762] D loss: 1.4067, G loss: 0.7428\n",
      "[1204/1762] D loss: 0.1240, G loss: 2.5579\n",
      "[1284/1762] D loss: 1.4026, G loss: 0.7899\n",
      "[1364/1762] D loss: 1.1958, G loss: 0.8659\n",
      "[1444/1762] D loss: 0.0863, G loss: 2.6510\n",
      "[1524/1762] D loss: 0.0309, G loss: 4.1744\n",
      "[1604/1762] D loss: 1.4113, G loss: 0.7966\n",
      "[1684/1762] D loss: 1.4551, G loss: 0.5666\n",
      "[1762/1762] D loss: 1.4159, G loss: 0.8154\n",
      "train error: \n",
      " D loss: 1.487257, G loss: 0.465950, D accuracy: 51.4%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.478877, G loss: 0.477298, D accuracy: 52.4%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4429, G loss: 0.8954\n",
      "[84/1762] D loss: 0.1168, G loss: 2.2968\n",
      "[164/1762] D loss: 1.3887, G loss: 0.7646\n",
      "[244/1762] D loss: 1.4105, G loss: 0.5212\n",
      "[324/1762] D loss: 1.3951, G loss: 0.6727\n",
      "[404/1762] D loss: 1.4201, G loss: 0.5782\n",
      "[484/1762] D loss: 0.0728, G loss: 2.7027\n",
      "[564/1762] D loss: 1.4338, G loss: 0.7947\n",
      "[644/1762] D loss: 1.3950, G loss: 0.7680\n",
      "[724/1762] D loss: 0.1211, G loss: 2.3006\n",
      "[804/1762] D loss: 1.4521, G loss: 0.5613\n",
      "[884/1762] D loss: 0.1104, G loss: 2.2447\n",
      "[964/1762] D loss: 1.4305, G loss: 0.8273\n",
      "[1044/1762] D loss: 0.0723, G loss: 2.8742\n",
      "[1124/1762] D loss: 1.4212, G loss: 0.6038\n",
      "[1204/1762] D loss: 1.4556, G loss: 0.9955\n",
      "[1284/1762] D loss: 1.4396, G loss: 0.9583\n",
      "[1364/1762] D loss: 1.4516, G loss: 0.9363\n",
      "[1444/1762] D loss: 0.1275, G loss: 3.6521\n",
      "[1524/1762] D loss: 1.4165, G loss: 0.8225\n",
      "[1604/1762] D loss: 1.0691, G loss: 0.7753\n",
      "[1684/1762] D loss: 1.6860, G loss: 0.9810\n",
      "[1762/1762] D loss: 1.4306, G loss: 0.7707\n",
      "train error: \n",
      " D loss: 1.862562, G loss: 1.439765, D accuracy: 50.6%, cell accuracy: 99.9%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.907200, G loss: 1.475725, D accuracy: 50.6%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0745, G loss: 3.8935\n",
      "[84/1762] D loss: 1.4480, G loss: 0.7341\n",
      "[164/1762] D loss: 1.4183, G loss: 0.9779\n",
      "[244/1762] D loss: 0.1376, G loss: 1.9863\n",
      "[324/1762] D loss: 1.4002, G loss: 0.7619\n",
      "[404/1762] D loss: 1.4014, G loss: 0.7546\n",
      "[484/1762] D loss: 0.0863, G loss: 2.7125\n",
      "[564/1762] D loss: 0.0920, G loss: 2.4807\n",
      "[644/1762] D loss: 1.4825, G loss: 0.9552\n",
      "[724/1762] D loss: 0.1328, G loss: 2.3994\n",
      "[804/1762] D loss: 1.4026, G loss: 0.6024\n",
      "[884/1762] D loss: 1.4409, G loss: 0.5576\n",
      "[964/1762] D loss: 1.4290, G loss: 0.7846\n",
      "[1044/1762] D loss: 1.4505, G loss: 0.5356\n",
      "[1124/1762] D loss: 1.5818, G loss: 1.2405\n",
      "[1204/1762] D loss: 1.4069, G loss: 0.6050\n",
      "[1284/1762] D loss: 1.3978, G loss: 0.6807\n",
      "[1364/1762] D loss: 0.1273, G loss: 2.5374\n",
      "[1444/1762] D loss: 1.4363, G loss: 0.7295\n",
      "[1524/1762] D loss: 1.4165, G loss: 0.5337\n",
      "[1604/1762] D loss: 1.4319, G loss: 0.9403\n",
      "[1684/1762] D loss: 1.4247, G loss: 0.8151\n",
      "[1762/1762] D loss: 1.5531, G loss: 1.0863\n",
      "train error: \n",
      " D loss: 1.492682, G loss: 0.575943, D accuracy: 50.5%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.497185, G loss: 0.585639, D accuracy: 50.7%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0775, G loss: 2.6616\n",
      "[84/1762] D loss: 1.4515, G loss: 0.5167\n",
      "[164/1762] D loss: 1.4392, G loss: 0.8291\n",
      "[244/1762] D loss: 0.1154, G loss: 2.2763\n",
      "[324/1762] D loss: 1.4147, G loss: 0.6221\n",
      "[404/1762] D loss: 1.3907, G loss: 0.7509\n",
      "[484/1762] D loss: 1.3968, G loss: 0.6349\n",
      "[564/1762] D loss: 0.0051, G loss: 5.4799\n",
      "[644/1762] D loss: 1.4207, G loss: 0.8817\n",
      "[724/1762] D loss: 1.4171, G loss: 0.7628\n",
      "[804/1762] D loss: 0.1347, G loss: 2.2906\n",
      "[884/1762] D loss: 1.5280, G loss: 0.8898\n",
      "[964/1762] D loss: 1.4648, G loss: 0.4904\n",
      "[1044/1762] D loss: 0.0839, G loss: 2.9614\n",
      "[1124/1762] D loss: 0.2535, G loss: 1.6185\n",
      "[1204/1762] D loss: 1.5554, G loss: 1.1738\n",
      "[1284/1762] D loss: 1.4531, G loss: 0.7121\n",
      "[1364/1762] D loss: 1.5167, G loss: 0.7271\n",
      "[1444/1762] D loss: 0.9366, G loss: 1.2176\n",
      "[1524/1762] D loss: 1.3383, G loss: 2.0905\n",
      "[1604/1762] D loss: 0.4189, G loss: 1.2183\n",
      "[1684/1762] D loss: 0.1653, G loss: 2.1281\n",
      "[1762/1762] D loss: 1.3994, G loss: 0.7719\n",
      "train error: \n",
      " D loss: 1.573485, G loss: 0.534875, D accuracy: 50.9%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.578490, G loss: 0.564246, D accuracy: 51.2%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4059, G loss: 0.8061\n",
      "[84/1762] D loss: 0.3588, G loss: 1.4206\n",
      "[164/1762] D loss: 1.4168, G loss: 0.5497\n",
      "[244/1762] D loss: 1.4234, G loss: 0.8759\n",
      "[324/1762] D loss: 1.4014, G loss: 0.6579\n",
      "[404/1762] D loss: 1.0077, G loss: 1.3616\n",
      "[484/1762] D loss: 1.4396, G loss: 0.8013\n",
      "[564/1762] D loss: 1.3905, G loss: 0.7248\n",
      "[644/1762] D loss: 1.4079, G loss: 0.6143\n",
      "[724/1762] D loss: 1.6199, G loss: 1.1124\n",
      "[804/1762] D loss: 1.3962, G loss: 0.4931\n",
      "[884/1762] D loss: 1.4233, G loss: 0.5186\n",
      "[964/1762] D loss: 0.1535, G loss: 2.1270\n",
      "[1044/1762] D loss: 0.0803, G loss: 2.7678\n",
      "[1124/1762] D loss: 0.8972, G loss: 1.9503\n",
      "[1204/1762] D loss: 0.1410, G loss: 2.2439\n",
      "[1284/1762] D loss: 0.1474, G loss: 2.1523\n",
      "[1364/1762] D loss: 1.3911, G loss: 0.7100\n",
      "[1444/1762] D loss: 0.0121, G loss: 4.5525\n",
      "[1524/1762] D loss: 1.3916, G loss: 0.7222\n",
      "[1604/1762] D loss: 0.1409, G loss: 2.2498\n",
      "[1684/1762] D loss: 1.5448, G loss: 1.0689\n",
      "[1762/1762] D loss: 1.4303, G loss: 0.5260\n",
      "train error: \n",
      " D loss: 2.045932, G loss: 0.188872, D accuracy: 49.1%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 2.041187, G loss: 0.192659, D accuracy: 49.0%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1781, G loss: 1.9240\n",
      "[84/1762] D loss: 1.3996, G loss: 0.6249\n",
      "[164/1762] D loss: 1.3950, G loss: 0.7861\n",
      "[244/1762] D loss: 1.3906, G loss: 0.7695\n",
      "[324/1762] D loss: 1.2945, G loss: 0.9320\n",
      "[404/1762] D loss: 1.4393, G loss: 0.4669\n",
      "[484/1762] D loss: 0.1361, G loss: 2.3451\n",
      "[564/1762] D loss: 0.0072, G loss: 5.1737\n",
      "[644/1762] D loss: 1.4688, G loss: 0.6001\n",
      "[724/1762] D loss: 1.4223, G loss: 0.8078\n",
      "[804/1762] D loss: 0.1459, G loss: 1.9302\n",
      "[884/1762] D loss: 0.1511, G loss: 1.9744\n",
      "[964/1762] D loss: 1.4469, G loss: 0.8908\n",
      "[1044/1762] D loss: 1.4025, G loss: 0.5997\n",
      "[1124/1762] D loss: 1.4167, G loss: 0.5789\n",
      "[1204/1762] D loss: 1.3888, G loss: 0.8922\n",
      "[1284/1762] D loss: 1.1851, G loss: 1.1479\n",
      "[1364/1762] D loss: 1.3947, G loss: 0.7457\n",
      "[1444/1762] D loss: 1.4015, G loss: 0.6072\n",
      "[1524/1762] D loss: 1.4233, G loss: 0.7654\n",
      "[1604/1762] D loss: 1.3947, G loss: 0.6963\n",
      "[1684/1762] D loss: 0.1251, G loss: 2.3694\n",
      "[1762/1762] D loss: 1.3982, G loss: 0.7205\n",
      "train error: \n",
      " D loss: 1.591250, G loss: 0.435758, D accuracy: 50.8%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.600760, G loss: 0.442272, D accuracy: 50.7%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3924, G loss: 0.5749\n",
      "[84/1762] D loss: 0.1495, G loss: 2.1258\n",
      "[164/1762] D loss: 1.4087, G loss: 0.5938\n",
      "[244/1762] D loss: 1.3901, G loss: 0.6298\n",
      "[324/1762] D loss: 0.0949, G loss: 2.7038\n",
      "[404/1762] D loss: 1.4150, G loss: 0.6847\n",
      "[484/1762] D loss: 1.6064, G loss: 0.9612\n",
      "[564/1762] D loss: 0.2232, G loss: 1.8271\n",
      "[644/1762] D loss: 0.0061, G loss: 5.4321\n",
      "[724/1762] D loss: 0.0883, G loss: 2.4602\n",
      "[804/1762] D loss: 1.4120, G loss: 0.5979\n",
      "[884/1762] D loss: 1.4139, G loss: 0.7451\n",
      "[964/1762] D loss: 0.1421, G loss: 2.0413\n",
      "[1044/1762] D loss: 0.0844, G loss: 2.6570\n",
      "[1124/1762] D loss: 1.4253, G loss: 0.8691\n",
      "[1204/1762] D loss: 0.0667, G loss: 2.8196\n",
      "[1284/1762] D loss: 1.3962, G loss: 0.5672\n",
      "[1364/1762] D loss: 1.4060, G loss: 0.8997\n",
      "[1444/1762] D loss: 1.3974, G loss: 0.6378\n",
      "[1524/1762] D loss: 1.4373, G loss: 0.8123\n",
      "[1604/1762] D loss: 1.4082, G loss: 0.6770\n",
      "[1684/1762] D loss: 1.4030, G loss: 0.7341\n",
      "[1762/1762] D loss: 1.3895, G loss: 0.6339\n",
      "train error: \n",
      " D loss: 2.412826, G loss: 0.128429, D accuracy: 49.9%, cell accuracy: 99.8%, board accuracy: 90.6% \n",
      "\n",
      "test error: \n",
      " D loss: 2.374452, G loss: 0.149480, D accuracy: 50.3%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3125, G loss: 0.6561\n",
      "[84/1762] D loss: 1.4129, G loss: 0.8401\n",
      "[164/1762] D loss: 1.0973, G loss: 1.7507\n",
      "[244/1762] D loss: 1.4170, G loss: 0.5716\n",
      "[324/1762] D loss: 1.4114, G loss: 0.8711\n",
      "[404/1762] D loss: 1.3982, G loss: 0.7458\n",
      "[484/1762] D loss: 0.1244, G loss: 2.0928\n",
      "[564/1762] D loss: 1.5123, G loss: 0.4404\n",
      "[644/1762] D loss: 0.0698, G loss: 2.8064\n",
      "[724/1762] D loss: 1.3954, G loss: 0.5798\n",
      "[804/1762] D loss: 1.4247, G loss: 0.7334\n",
      "[884/1762] D loss: 1.3880, G loss: 0.7217\n",
      "[964/1762] D loss: 1.3950, G loss: 0.6391\n",
      "[1044/1762] D loss: 0.1469, G loss: 2.1687\n",
      "[1124/1762] D loss: 1.3035, G loss: 0.9334\n",
      "[1204/1762] D loss: 1.4345, G loss: 0.5745\n",
      "[1284/1762] D loss: 0.1194, G loss: 2.4069\n",
      "[1364/1762] D loss: 1.3970, G loss: 0.6617\n",
      "[1444/1762] D loss: 1.4431, G loss: 0.5394\n",
      "[1524/1762] D loss: 1.3953, G loss: 0.6549\n",
      "[1604/1762] D loss: 1.4076, G loss: 0.8265\n",
      "[1684/1762] D loss: 1.3938, G loss: 0.6181\n",
      "[1762/1762] D loss: 1.4417, G loss: 0.8617\n",
      "train error: \n",
      " D loss: 1.444615, G loss: 0.821042, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.435590, G loss: 0.850262, D accuracy: 53.8%, cell accuracy: 99.7%, board accuracy: 84.1% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3999, G loss: 0.6743\n",
      "[84/1762] D loss: 1.3925, G loss: 0.6773\n",
      "[164/1762] D loss: 1.3929, G loss: 0.7451\n",
      "[244/1762] D loss: 1.3961, G loss: 0.6897\n",
      "[324/1762] D loss: 0.1567, G loss: 1.9726\n",
      "[404/1762] D loss: 1.3942, G loss: 0.6569\n",
      "[484/1762] D loss: 0.0932, G loss: 2.4982\n",
      "[564/1762] D loss: 1.4014, G loss: 0.7584\n",
      "[644/1762] D loss: 0.0892, G loss: 2.5725\n",
      "[724/1762] D loss: 1.3960, G loss: 0.6461\n",
      "[804/1762] D loss: 1.2098, G loss: 1.1507\n",
      "[884/1762] D loss: 1.4262, G loss: 0.7841\n",
      "[964/1762] D loss: 1.4377, G loss: 0.5839\n",
      "[1044/1762] D loss: 0.1335, G loss: 2.3252\n",
      "[1124/1762] D loss: 1.3948, G loss: 0.9295\n",
      "[1204/1762] D loss: 1.4415, G loss: 0.6125\n",
      "[1284/1762] D loss: 0.3744, G loss: 1.4555\n",
      "[1364/1762] D loss: 0.0973, G loss: 2.2811\n",
      "[1444/1762] D loss: 1.4354, G loss: 0.5839\n",
      "[1524/1762] D loss: 0.0478, G loss: 3.2520\n",
      "[1604/1762] D loss: 1.4341, G loss: 0.7237\n",
      "[1684/1762] D loss: 1.4154, G loss: 0.5853\n",
      "[1762/1762] D loss: 1.4018, G loss: 0.6268\n",
      "train error: \n",
      " D loss: 1.579048, G loss: 0.409260, D accuracy: 51.2%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.563741, G loss: 0.424967, D accuracy: 52.2%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3873, G loss: 0.7350\n",
      "[84/1762] D loss: 1.4122, G loss: 0.6024\n",
      "[164/1762] D loss: 0.1153, G loss: 2.3085\n",
      "[244/1762] D loss: 0.1104, G loss: 2.3048\n",
      "[324/1762] D loss: 1.3906, G loss: 0.7006\n",
      "[404/1762] D loss: 1.4881, G loss: 0.9410\n",
      "[484/1762] D loss: 1.4295, G loss: 0.6328\n",
      "[564/1762] D loss: 1.4370, G loss: 0.7668\n",
      "[644/1762] D loss: 0.1173, G loss: 2.3730\n",
      "[724/1762] D loss: 1.4228, G loss: 0.9618\n",
      "[804/1762] D loss: 1.4026, G loss: 0.7332\n",
      "[884/1762] D loss: 1.4067, G loss: 0.8786\n",
      "[964/1762] D loss: 0.0938, G loss: 2.4786\n",
      "[1044/1762] D loss: 1.4938, G loss: 0.4730\n",
      "[1124/1762] D loss: 0.0917, G loss: 2.5784\n",
      "[1204/1762] D loss: 1.3990, G loss: 0.7729\n",
      "[1284/1762] D loss: 1.4554, G loss: 0.5217\n",
      "[1364/1762] D loss: 0.0412, G loss: 3.7676\n",
      "[1444/1762] D loss: 1.4405, G loss: 0.8765\n",
      "[1524/1762] D loss: 1.4192, G loss: 0.6036\n",
      "[1604/1762] D loss: 1.4069, G loss: 0.6591\n",
      "[1684/1762] D loss: 1.3931, G loss: 0.6506\n",
      "[1762/1762] D loss: 1.4239, G loss: 0.5468\n",
      "train error: \n",
      " D loss: 1.449376, G loss: 0.522525, D accuracy: 52.1%, cell accuracy: 99.8%, board accuracy: 91.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.434857, G loss: 0.550991, D accuracy: 53.0%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9695, G loss: 1.8197\n",
      "[84/1762] D loss: 1.3974, G loss: 0.6076\n",
      "[164/1762] D loss: 2.0615, G loss: 0.4757\n",
      "[244/1762] D loss: 1.4365, G loss: 0.6401\n",
      "[324/1762] D loss: 0.0481, G loss: 3.6536\n",
      "[404/1762] D loss: 1.4007, G loss: 0.5459\n",
      "[484/1762] D loss: 1.4436, G loss: 0.9071\n",
      "[564/1762] D loss: 0.0914, G loss: 2.5886\n",
      "[644/1762] D loss: 1.4294, G loss: 0.8376\n",
      "[724/1762] D loss: 1.3204, G loss: 0.8227\n",
      "[804/1762] D loss: 1.4032, G loss: 0.8949\n",
      "[884/1762] D loss: 0.1702, G loss: 1.8604\n",
      "[964/1762] D loss: 1.3901, G loss: 0.7745\n",
      "[1044/1762] D loss: 1.4022, G loss: 0.6031\n",
      "[1124/1762] D loss: 1.3984, G loss: 0.7752\n",
      "[1204/1762] D loss: 0.0961, G loss: 2.4225\n",
      "[1284/1762] D loss: 0.0607, G loss: 2.9671\n",
      "[1364/1762] D loss: 1.4192, G loss: 0.7186\n",
      "[1444/1762] D loss: 1.4057, G loss: 0.6112\n",
      "[1524/1762] D loss: 1.4049, G loss: 0.7404\n",
      "[1604/1762] D loss: 1.3897, G loss: 0.6550\n",
      "[1684/1762] D loss: 1.4082, G loss: 0.8416\n",
      "[1762/1762] D loss: 1.3890, G loss: 0.7149\n",
      "train error: \n",
      " D loss: 1.526914, G loss: 0.409173, D accuracy: 51.8%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.509732, G loss: 0.426241, D accuracy: 52.8%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4326, G loss: 0.8315\n",
      "[84/1762] D loss: 0.1222, G loss: 2.2787\n",
      "[164/1762] D loss: 1.3988, G loss: 0.6198\n",
      "[244/1762] D loss: 1.4000, G loss: 0.7710\n",
      "[324/1762] D loss: 0.0692, G loss: 2.8791\n",
      "[404/1762] D loss: 1.4244, G loss: 0.7936\n",
      "[484/1762] D loss: 1.3945, G loss: 0.6704\n",
      "[564/1762] D loss: 0.0887, G loss: 2.5071\n",
      "[644/1762] D loss: 0.0890, G loss: 2.7353\n",
      "[724/1762] D loss: 1.3880, G loss: 0.6846\n",
      "[804/1762] D loss: 0.0699, G loss: 2.9095\n",
      "[884/1762] D loss: 0.0860, G loss: 2.5817\n",
      "[964/1762] D loss: 0.0628, G loss: 2.9624\n",
      "[1044/1762] D loss: 0.0080, G loss: 5.3422\n",
      "[1124/1762] D loss: 1.4097, G loss: 0.5926\n",
      "[1204/1762] D loss: 1.3899, G loss: 0.7061\n",
      "[1284/1762] D loss: 1.4574, G loss: 0.5276\n",
      "[1364/1762] D loss: 1.1399, G loss: 1.0573\n",
      "[1444/1762] D loss: 1.4587, G loss: 0.9556\n",
      "[1524/1762] D loss: 1.4539, G loss: 0.9053\n",
      "[1604/1762] D loss: 1.4401, G loss: 0.5448\n",
      "[1684/1762] D loss: 0.0770, G loss: 2.6399\n",
      "[1762/1762] D loss: 0.0118, G loss: 4.7736\n",
      "train error: \n",
      " D loss: 2.570435, G loss: 0.123489, D accuracy: 50.9%, cell accuracy: 99.7%, board accuracy: 85.1% \n",
      "\n",
      "test error: \n",
      " D loss: 2.527702, G loss: 0.143524, D accuracy: 51.5%, cell accuracy: 99.7%, board accuracy: 83.9% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0108, G loss: 1.3273\n",
      "[84/1762] D loss: 1.4087, G loss: 0.6548\n",
      "[164/1762] D loss: 1.4288, G loss: 0.8396\n",
      "[244/1762] D loss: 1.4463, G loss: 0.5997\n",
      "[324/1762] D loss: 1.1958, G loss: 1.6058\n",
      "[404/1762] D loss: 1.4450, G loss: 1.0148\n",
      "[484/1762] D loss: 1.3959, G loss: 0.5462\n",
      "[564/1762] D loss: 1.3988, G loss: 0.8381\n",
      "[644/1762] D loss: 1.4633, G loss: 0.7891\n",
      "[724/1762] D loss: 1.4841, G loss: 0.9448\n",
      "[804/1762] D loss: 1.4215, G loss: 0.7935\n",
      "[884/1762] D loss: 1.3924, G loss: 0.6353\n",
      "[964/1762] D loss: 1.3860, G loss: 0.6982\n",
      "[1044/1762] D loss: 1.3941, G loss: 0.7284\n",
      "[1124/1762] D loss: 1.3947, G loss: 0.7303\n",
      "[1204/1762] D loss: 1.3966, G loss: 0.6609\n",
      "[1284/1762] D loss: 1.3885, G loss: 0.6129\n",
      "[1364/1762] D loss: 1.4034, G loss: 0.7875\n",
      "[1444/1762] D loss: 0.0856, G loss: 2.7220\n",
      "[1524/1762] D loss: 1.3990, G loss: 0.5949\n",
      "[1604/1762] D loss: 0.1045, G loss: 2.3925\n",
      "[1684/1762] D loss: 1.4297, G loss: 0.5563\n",
      "[1762/1762] D loss: 1.4189, G loss: 0.4421\n",
      "train error: \n",
      " D loss: 1.613692, G loss: 0.350013, D accuracy: 52.3%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.607688, G loss: 0.357054, D accuracy: 53.1%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.6156, G loss: 0.3567\n",
      "[84/1762] D loss: 1.2897, G loss: 3.3224\n",
      "[164/1762] D loss: 0.1427, G loss: 2.2922\n",
      "[244/1762] D loss: 1.4518, G loss: 0.8981\n",
      "[324/1762] D loss: 1.3907, G loss: 0.6846\n",
      "[404/1762] D loss: 0.0767, G loss: 2.7486\n",
      "[484/1762] D loss: 1.4029, G loss: 0.7199\n",
      "[564/1762] D loss: 0.1200, G loss: 2.4789\n",
      "[644/1762] D loss: 1.4007, G loss: 0.7000\n",
      "[724/1762] D loss: 1.4087, G loss: 0.5678\n",
      "[804/1762] D loss: 1.4298, G loss: 1.0722\n",
      "[884/1762] D loss: 1.3944, G loss: 0.7083\n",
      "[964/1762] D loss: 1.4312, G loss: 0.8515\n",
      "[1044/1762] D loss: 1.3978, G loss: 0.7216\n",
      "[1124/1762] D loss: 1.3907, G loss: 0.6291\n",
      "[1204/1762] D loss: 0.1062, G loss: 2.5936\n",
      "[1284/1762] D loss: 1.3944, G loss: 0.6654\n",
      "[1364/1762] D loss: 1.3954, G loss: 0.8041\n",
      "[1444/1762] D loss: 1.3978, G loss: 0.6800\n",
      "[1524/1762] D loss: 1.5044, G loss: 0.9015\n",
      "[1604/1762] D loss: 1.5306, G loss: 0.4046\n",
      "[1684/1762] D loss: 1.4804, G loss: 1.0153\n",
      "[1762/1762] D loss: 1.4060, G loss: 0.6228\n",
      "train error: \n",
      " D loss: 1.482172, G loss: 0.523409, D accuracy: 51.0%, cell accuracy: 99.8%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.489283, G loss: 0.535352, D accuracy: 51.4%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4017, G loss: 0.6164\n",
      "[84/1762] D loss: 1.4013, G loss: 0.6250\n",
      "[164/1762] D loss: 1.3968, G loss: 0.5526\n",
      "[244/1762] D loss: 1.4254, G loss: 0.9252\n",
      "[324/1762] D loss: 1.1112, G loss: 1.4277\n",
      "[404/1762] D loss: 1.3378, G loss: 0.8349\n",
      "[484/1762] D loss: 1.5387, G loss: 0.9141\n",
      "[564/1762] D loss: 0.1223, G loss: 2.2812\n",
      "[644/1762] D loss: 1.4280, G loss: 0.6625\n",
      "[724/1762] D loss: 1.8893, G loss: 0.7670\n",
      "[804/1762] D loss: 1.4222, G loss: 0.5829\n",
      "[884/1762] D loss: 0.0787, G loss: 2.6487\n",
      "[964/1762] D loss: 1.3982, G loss: 0.6588\n",
      "[1044/1762] D loss: 1.3733, G loss: 0.6996\n",
      "[1124/1762] D loss: 1.4372, G loss: 0.5198\n",
      "[1204/1762] D loss: 0.1340, G loss: 2.3180\n",
      "[1284/1762] D loss: 1.4102, G loss: 0.8287\n",
      "[1364/1762] D loss: 0.0908, G loss: 2.6529\n",
      "[1444/1762] D loss: 0.1228, G loss: 2.1363\n",
      "[1524/1762] D loss: 0.0934, G loss: 2.3763\n",
      "[1604/1762] D loss: 0.0700, G loss: 2.8636\n",
      "[1684/1762] D loss: 1.4634, G loss: 0.4676\n",
      "[1762/1762] D loss: 1.3983, G loss: 0.8104\n",
      "train error: \n",
      " D loss: 2.266358, G loss: 0.149600, D accuracy: 50.7%, cell accuracy: 99.8%, board accuracy: 91.2% \n",
      "\n",
      "test error: \n",
      " D loss: 2.242445, G loss: 0.149880, D accuracy: 50.6%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1059, G loss: 2.4559\n",
      "[84/1762] D loss: 1.4999, G loss: 1.0196\n",
      "[164/1762] D loss: 1.4237, G loss: 0.6667\n",
      "[244/1762] D loss: 1.4671, G loss: 0.5013\n",
      "[324/1762] D loss: 1.3835, G loss: 0.6789\n",
      "[404/1762] D loss: 0.0577, G loss: 2.9640\n",
      "[484/1762] D loss: 1.3896, G loss: 0.6535\n",
      "[564/1762] D loss: 0.1013, G loss: 2.5049\n",
      "[644/1762] D loss: 1.3984, G loss: 0.6626\n",
      "[724/1762] D loss: 1.4004, G loss: 0.6320\n",
      "[804/1762] D loss: 1.4079, G loss: 0.7928\n",
      "[884/1762] D loss: 1.4100, G loss: 0.8292\n",
      "[964/1762] D loss: 0.0769, G loss: 2.7870\n",
      "[1044/1762] D loss: 1.3723, G loss: 0.6677\n",
      "[1124/1762] D loss: 1.4177, G loss: 0.9029\n",
      "[1204/1762] D loss: 0.0735, G loss: 2.7858\n",
      "[1284/1762] D loss: 0.0914, G loss: 2.6623\n",
      "[1364/1762] D loss: 1.3903, G loss: 0.6275\n",
      "[1444/1762] D loss: 1.3949, G loss: 0.7299\n",
      "[1524/1762] D loss: 1.2117, G loss: 1.5575\n",
      "[1604/1762] D loss: 0.1067, G loss: 2.2852\n",
      "[1684/1762] D loss: 1.4076, G loss: 0.6519\n",
      "[1762/1762] D loss: 1.4201, G loss: 0.7960\n",
      "train error: \n",
      " D loss: 1.507705, G loss: 0.477165, D accuracy: 50.1%, cell accuracy: 99.8%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.504052, G loss: 0.494879, D accuracy: 50.0%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1883, G loss: 2.0698\n",
      "[84/1762] D loss: 1.5098, G loss: 1.0557\n",
      "[164/1762] D loss: 1.4039, G loss: 0.7336\n",
      "[244/1762] D loss: 1.4227, G loss: 0.6863\n",
      "[324/1762] D loss: 0.0694, G loss: 2.7722\n",
      "[404/1762] D loss: 1.3952, G loss: 0.6145\n",
      "[484/1762] D loss: 0.1004, G loss: 2.4828\n",
      "[564/1762] D loss: 1.3923, G loss: 0.7080\n",
      "[644/1762] D loss: 1.3992, G loss: 0.5295\n",
      "[724/1762] D loss: 0.0457, G loss: 3.3113\n",
      "[804/1762] D loss: 1.4068, G loss: 0.6337\n",
      "[884/1762] D loss: 1.3877, G loss: 0.7063\n",
      "[964/1762] D loss: 1.4093, G loss: 0.6396\n",
      "[1044/1762] D loss: 0.1047, G loss: 2.4845\n",
      "[1124/1762] D loss: 0.0786, G loss: 2.9218\n",
      "[1204/1762] D loss: 1.2802, G loss: 0.7832\n",
      "[1284/1762] D loss: 1.4345, G loss: 0.9220\n",
      "[1364/1762] D loss: 1.3891, G loss: 0.7982\n",
      "[1444/1762] D loss: 1.4535, G loss: 0.8692\n",
      "[1524/1762] D loss: 1.3925, G loss: 0.7334\n",
      "[1604/1762] D loss: 1.3951, G loss: 0.6482\n",
      "[1684/1762] D loss: 1.3918, G loss: 0.7555\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.6892\n",
      "train error: \n",
      " D loss: 1.652934, G loss: 0.351236, D accuracy: 51.5%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.645515, G loss: 0.362885, D accuracy: 51.7%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0523, G loss: 3.1053\n",
      "[84/1762] D loss: 1.5139, G loss: 0.5103\n",
      "[164/1762] D loss: 0.0574, G loss: 3.3414\n",
      "[244/1762] D loss: 1.4094, G loss: 0.5848\n",
      "[324/1762] D loss: 1.4032, G loss: 0.7656\n",
      "[404/1762] D loss: 1.4353, G loss: 0.5253\n",
      "[484/1762] D loss: 0.0725, G loss: 2.6800\n",
      "[564/1762] D loss: 1.3980, G loss: 0.7800\n",
      "[644/1762] D loss: 0.0833, G loss: 2.5917\n",
      "[724/1762] D loss: 1.4066, G loss: 0.6268\n",
      "[804/1762] D loss: 0.0563, G loss: 2.9898\n",
      "[884/1762] D loss: 1.3965, G loss: 0.6852\n",
      "[964/1762] D loss: 1.4001, G loss: 0.6272\n",
      "[1044/1762] D loss: 1.6499, G loss: 1.3008\n",
      "[1124/1762] D loss: 1.0225, G loss: 1.2946\n",
      "[1204/1762] D loss: 1.4594, G loss: 0.4847\n",
      "[1284/1762] D loss: 1.4552, G loss: 0.5798\n",
      "[1364/1762] D loss: 1.4132, G loss: 0.7462\n",
      "[1444/1762] D loss: 1.4511, G loss: 0.7547\n",
      "[1524/1762] D loss: 0.0843, G loss: 2.8216\n",
      "[1604/1762] D loss: 1.5202, G loss: 0.8023\n",
      "[1684/1762] D loss: 1.4036, G loss: 0.8227\n",
      "[1762/1762] D loss: 1.4273, G loss: 0.8398\n",
      "train error: \n",
      " D loss: 1.632176, G loss: 0.476965, D accuracy: 50.7%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.637217, G loss: 0.502783, D accuracy: 51.1%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4285, G loss: 0.7478\n",
      "[84/1762] D loss: 1.4501, G loss: 0.5850\n",
      "[164/1762] D loss: 1.3928, G loss: 0.6450\n",
      "[244/1762] D loss: 0.0865, G loss: 2.5782\n",
      "[324/1762] D loss: 1.3909, G loss: 0.7371\n",
      "[404/1762] D loss: 0.0778, G loss: 2.7557\n",
      "[484/1762] D loss: 1.4324, G loss: 0.5148\n",
      "[564/1762] D loss: 0.1082, G loss: 2.6080\n",
      "[644/1762] D loss: 1.4055, G loss: 0.6622\n",
      "[724/1762] D loss: 0.0620, G loss: 2.9933\n",
      "[804/1762] D loss: 1.3954, G loss: 0.7573\n",
      "[884/1762] D loss: 0.0900, G loss: 2.6087\n",
      "[964/1762] D loss: 0.0781, G loss: 2.8084\n",
      "[1044/1762] D loss: 0.0770, G loss: 2.6151\n",
      "[1124/1762] D loss: 0.0027, G loss: 6.2252\n",
      "[1204/1762] D loss: 1.4047, G loss: 0.7834\n",
      "[1284/1762] D loss: 1.3900, G loss: 0.6406\n",
      "[1364/1762] D loss: 1.3946, G loss: 0.7714\n",
      "[1444/1762] D loss: 1.3914, G loss: 0.7263\n",
      "[1524/1762] D loss: 0.0034, G loss: 5.7626\n",
      "[1604/1762] D loss: 0.0442, G loss: 3.4783\n",
      "[1684/1762] D loss: 1.3913, G loss: 0.6596\n",
      "[1762/1762] D loss: 1.4279, G loss: 0.7860\n",
      "train error: \n",
      " D loss: 1.588900, G loss: 0.544386, D accuracy: 50.8%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.618076, G loss: 0.552772, D accuracy: 50.8%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3869, G loss: 0.6048\n",
      "[84/1762] D loss: 1.3969, G loss: 0.5975\n",
      "[164/1762] D loss: 1.4116, G loss: 0.8366\n",
      "[244/1762] D loss: 1.3971, G loss: 0.6743\n",
      "[324/1762] D loss: 1.4277, G loss: 0.8280\n",
      "[404/1762] D loss: 1.4370, G loss: 0.4699\n",
      "[484/1762] D loss: 1.4266, G loss: 0.9727\n",
      "[564/1762] D loss: 0.0546, G loss: 2.7429\n",
      "[644/1762] D loss: 0.0018, G loss: 6.7493\n",
      "[724/1762] D loss: 1.4209, G loss: 0.5307\n",
      "[804/1762] D loss: 1.3965, G loss: 0.8316\n",
      "[884/1762] D loss: 1.3974, G loss: 0.5656\n",
      "[964/1762] D loss: 0.0661, G loss: 3.0223\n",
      "[1044/1762] D loss: 1.3959, G loss: 0.7545\n",
      "[1124/1762] D loss: 1.4050, G loss: 0.5954\n",
      "[1204/1762] D loss: 1.3903, G loss: 0.7239\n",
      "[1284/1762] D loss: 1.4005, G loss: 0.9817\n",
      "[1364/1762] D loss: 1.4630, G loss: 0.5278\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6458\n",
      "[1524/1762] D loss: 1.4399, G loss: 0.5510\n",
      "[1604/1762] D loss: 0.0625, G loss: 2.9571\n",
      "[1684/1762] D loss: 0.0363, G loss: 3.4769\n",
      "[1762/1762] D loss: 1.3925, G loss: 0.7204\n",
      "train error: \n",
      " D loss: 1.744911, G loss: 0.307708, D accuracy: 48.3%, cell accuracy: 99.9%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.740587, G loss: 0.309956, D accuracy: 47.8%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4015, G loss: 0.7180\n",
      "[84/1762] D loss: 1.4036, G loss: 0.8308\n",
      "[164/1762] D loss: 0.8538, G loss: 2.7972\n",
      "[244/1762] D loss: 1.4490, G loss: 0.6420\n",
      "[324/1762] D loss: 1.3876, G loss: 0.6195\n",
      "[404/1762] D loss: 1.4350, G loss: 0.9652\n",
      "[484/1762] D loss: 1.4269, G loss: 0.8309\n",
      "[564/1762] D loss: 1.4262, G loss: 0.9390\n",
      "[644/1762] D loss: 0.7830, G loss: 2.6834\n",
      "[724/1762] D loss: 0.0717, G loss: 2.9086\n",
      "[804/1762] D loss: 0.0478, G loss: 3.1496\n",
      "[884/1762] D loss: 1.3928, G loss: 0.6386\n",
      "[964/1762] D loss: 0.0706, G loss: 2.8191\n",
      "[1044/1762] D loss: 1.3968, G loss: 0.6356\n",
      "[1124/1762] D loss: 1.3944, G loss: 0.7682\n",
      "[1204/1762] D loss: 1.4061, G loss: 0.6380\n",
      "[1284/1762] D loss: 1.3873, G loss: 0.6534\n",
      "[1364/1762] D loss: 1.3981, G loss: 0.5686\n",
      "[1444/1762] D loss: 1.4021, G loss: 0.8108\n",
      "[1524/1762] D loss: 0.0639, G loss: 2.8516\n",
      "[1604/1762] D loss: 0.0588, G loss: 3.0216\n",
      "[1684/1762] D loss: 1.4503, G loss: 0.8553\n",
      "[1762/1762] D loss: 1.3870, G loss: 0.7502\n",
      "train error: \n",
      " D loss: 2.619632, G loss: 0.092152, D accuracy: 49.9%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 2.601868, G loss: 0.096142, D accuracy: 49.9%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3888, G loss: 0.7231\n",
      "[84/1762] D loss: 1.4127, G loss: 0.5622\n",
      "[164/1762] D loss: 1.4276, G loss: 0.6543\n",
      "[244/1762] D loss: 1.4904, G loss: 0.5607\n",
      "[324/1762] D loss: 0.0467, G loss: 3.1603\n",
      "[404/1762] D loss: 0.0462, G loss: 3.5331\n",
      "[484/1762] D loss: 1.4056, G loss: 0.5216\n",
      "[564/1762] D loss: 1.3990, G loss: 0.7351\n",
      "[644/1762] D loss: 1.3993, G loss: 0.7174\n",
      "[724/1762] D loss: 1.3928, G loss: 0.6770\n",
      "[804/1762] D loss: 1.3978, G loss: 0.6923\n",
      "[884/1762] D loss: 0.2603, G loss: 2.2946\n",
      "[964/1762] D loss: 1.3943, G loss: 0.8024\n",
      "[1044/1762] D loss: 1.5337, G loss: 0.4685\n",
      "[1124/1762] D loss: 0.0171, G loss: 4.4947\n",
      "[1204/1762] D loss: 1.3930, G loss: 0.4163\n",
      "[1284/1762] D loss: 1.5633, G loss: 0.5332\n",
      "[1364/1762] D loss: 1.6516, G loss: 1.1142\n",
      "[1444/1762] D loss: 1.3991, G loss: 0.8844\n",
      "[1524/1762] D loss: 1.4019, G loss: 0.5846\n",
      "[1604/1762] D loss: 1.4078, G loss: 0.7540\n",
      "[1684/1762] D loss: 1.4225, G loss: 0.8132\n",
      "[1762/1762] D loss: 1.3880, G loss: 0.6521\n",
      "train error: \n",
      " D loss: 1.755958, G loss: 0.258512, D accuracy: 49.7%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.744266, G loss: 0.265643, D accuracy: 49.5%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3886, G loss: 0.6150\n",
      "[84/1762] D loss: 1.4171, G loss: 0.5894\n",
      "[164/1762] D loss: 1.3929, G loss: 0.7260\n",
      "[244/1762] D loss: 1.4497, G loss: 0.8474\n",
      "[324/1762] D loss: 1.4438, G loss: 0.5128\n",
      "[404/1762] D loss: 1.4013, G loss: 0.6878\n",
      "[484/1762] D loss: 1.4095, G loss: 0.6646\n",
      "[564/1762] D loss: 1.3938, G loss: 0.5615\n",
      "[644/1762] D loss: 1.4005, G loss: 0.6937\n",
      "[724/1762] D loss: 1.3881, G loss: 0.6473\n",
      "[804/1762] D loss: 1.4141, G loss: 0.7226\n",
      "[884/1762] D loss: 1.4016, G loss: 0.5992\n",
      "[964/1762] D loss: 1.3925, G loss: 0.7701\n",
      "[1044/1762] D loss: 1.4048, G loss: 0.7541\n",
      "[1124/1762] D loss: 0.0028, G loss: 5.9945\n",
      "[1204/1762] D loss: 1.3922, G loss: 0.7262\n",
      "[1284/1762] D loss: 0.0768, G loss: 2.6386\n",
      "[1364/1762] D loss: 0.0642, G loss: 2.7498\n",
      "[1444/1762] D loss: 0.0399, G loss: 3.4181\n",
      "[1524/1762] D loss: 1.4603, G loss: 0.3654\n",
      "[1604/1762] D loss: 0.0929, G loss: 2.6883\n",
      "[1684/1762] D loss: 0.0427, G loss: 3.3221\n",
      "[1762/1762] D loss: 1.3913, G loss: 0.6976\n",
      "train error: \n",
      " D loss: 1.623172, G loss: 0.327976, D accuracy: 50.7%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.605691, G loss: 0.338197, D accuracy: 50.8%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3885, G loss: 0.7079\n",
      "[84/1762] D loss: 1.4006, G loss: 0.6537\n",
      "[164/1762] D loss: 1.3994, G loss: 0.7862\n",
      "[244/1762] D loss: 1.3946, G loss: 0.6322\n",
      "[324/1762] D loss: 1.3923, G loss: 0.6122\n",
      "[404/1762] D loss: 1.4099, G loss: 0.7739\n",
      "[484/1762] D loss: 1.3875, G loss: 0.7392\n",
      "[564/1762] D loss: 1.3896, G loss: 0.6473\n",
      "[644/1762] D loss: 1.3917, G loss: 0.7321\n",
      "[724/1762] D loss: 1.3946, G loss: 0.6502\n",
      "[804/1762] D loss: 1.3914, G loss: 0.6636\n",
      "[884/1762] D loss: 0.0781, G loss: 2.6565\n",
      "[964/1762] D loss: 1.4725, G loss: 1.0630\n",
      "[1044/1762] D loss: 1.4149, G loss: 0.5560\n",
      "[1124/1762] D loss: 1.3130, G loss: 1.4477\n",
      "[1204/1762] D loss: 1.4248, G loss: 0.8070\n",
      "[1284/1762] D loss: 1.4176, G loss: 0.9074\n",
      "[1364/1762] D loss: 1.3946, G loss: 0.5322\n",
      "[1444/1762] D loss: 0.0691, G loss: 2.8617\n",
      "[1524/1762] D loss: 1.4107, G loss: 0.5915\n",
      "[1604/1762] D loss: 1.3953, G loss: 0.7292\n",
      "[1684/1762] D loss: 0.0844, G loss: 2.6552\n",
      "[1762/1762] D loss: 0.0022, G loss: 6.2616\n",
      "train error: \n",
      " D loss: 2.931081, G loss: 0.073655, D accuracy: 50.2%, cell accuracy: 99.8%, board accuracy: 90.6% \n",
      "\n",
      "test error: \n",
      " D loss: 2.907244, G loss: 0.082818, D accuracy: 50.6%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3993, G loss: 0.6494\n",
      "[84/1762] D loss: 1.4216, G loss: 0.5484\n",
      "[164/1762] D loss: 1.4146, G loss: 0.9687\n",
      "[244/1762] D loss: 1.4391, G loss: 0.8733\n",
      "[324/1762] D loss: 0.0796, G loss: 2.6774\n",
      "[404/1762] D loss: 1.4149, G loss: 0.8542\n",
      "[484/1762] D loss: 1.4751, G loss: 0.5610\n",
      "[564/1762] D loss: 1.3932, G loss: 0.7455\n",
      "[644/1762] D loss: 0.0616, G loss: 2.9658\n",
      "[724/1762] D loss: 1.3955, G loss: 0.5846\n",
      "[804/1762] D loss: 1.4164, G loss: 0.8735\n",
      "[884/1762] D loss: 1.4045, G loss: 0.7863\n",
      "[964/1762] D loss: 1.4475, G loss: 0.4972\n",
      "[1044/1762] D loss: 0.0610, G loss: 3.1071\n",
      "[1124/1762] D loss: 0.0669, G loss: 2.8722\n",
      "[1204/1762] D loss: 1.3208, G loss: 0.7348\n",
      "[1284/1762] D loss: 0.9941, G loss: 2.2566\n",
      "[1364/1762] D loss: 1.4087, G loss: 0.8079\n",
      "[1444/1762] D loss: 0.0716, G loss: 2.7387\n",
      "[1524/1762] D loss: 1.3724, G loss: 0.7551\n",
      "[1604/1762] D loss: 0.0026, G loss: 6.3510\n",
      "[1684/1762] D loss: 1.3854, G loss: 0.6865\n",
      "[1762/1762] D loss: 1.3876, G loss: 0.6229\n",
      "train error: \n",
      " D loss: 1.434341, G loss: 0.570146, D accuracy: 51.1%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.433982, G loss: 0.581706, D accuracy: 51.4%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0783, G loss: 2.5957\n",
      "[84/1762] D loss: 1.3878, G loss: 0.6781\n",
      "[164/1762] D loss: 1.3874, G loss: 0.6755\n",
      "[244/1762] D loss: 1.3874, G loss: 0.7015\n",
      "[324/1762] D loss: 1.3899, G loss: 0.7390\n",
      "[404/1762] D loss: 1.3914, G loss: 0.7460\n",
      "[484/1762] D loss: 1.3884, G loss: 0.7040\n",
      "[564/1762] D loss: 1.3891, G loss: 0.7529\n",
      "[644/1762] D loss: 1.3901, G loss: 0.6638\n",
      "[724/1762] D loss: 1.3938, G loss: 0.6648\n",
      "[804/1762] D loss: 1.4039, G loss: 0.7920\n",
      "[884/1762] D loss: 0.0651, G loss: 2.8099\n",
      "[964/1762] D loss: 1.4015, G loss: 0.7586\n",
      "[1044/1762] D loss: 1.3921, G loss: 0.7201\n",
      "[1124/1762] D loss: 0.0600, G loss: 2.7474\n",
      "[1204/1762] D loss: 1.6339, G loss: 0.8324\n",
      "[1284/1762] D loss: 1.8070, G loss: 1.3590\n",
      "[1364/1762] D loss: 1.5238, G loss: 0.3637\n",
      "[1444/1762] D loss: 1.5948, G loss: 1.1699\n",
      "[1524/1762] D loss: 0.0541, G loss: 2.8599\n",
      "[1604/1762] D loss: 1.5052, G loss: 0.9919\n",
      "[1684/1762] D loss: 1.3739, G loss: 0.7477\n",
      "[1762/1762] D loss: 1.4087, G loss: 0.8699\n",
      "train error: \n",
      " D loss: 1.506287, G loss: 0.704178, D accuracy: 51.0%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.513636, G loss: 0.710766, D accuracy: 51.6%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4221, G loss: 0.8486\n",
      "[84/1762] D loss: 1.4456, G loss: 0.5282\n",
      "[164/1762] D loss: 1.4120, G loss: 0.8221\n",
      "[244/1762] D loss: 1.3877, G loss: 0.6660\n",
      "[324/1762] D loss: 1.3956, G loss: 0.5814\n",
      "[404/1762] D loss: 0.0821, G loss: 2.5683\n",
      "[484/1762] D loss: 1.4226, G loss: 0.8710\n",
      "[564/1762] D loss: 1.4021, G loss: 0.6255\n",
      "[644/1762] D loss: 1.3881, G loss: 0.6489\n",
      "[724/1762] D loss: 1.3885, G loss: 0.7427\n",
      "[804/1762] D loss: 1.3876, G loss: 0.6913\n",
      "[884/1762] D loss: 0.0639, G loss: 2.9149\n",
      "[964/1762] D loss: 1.3884, G loss: 0.7195\n",
      "[1044/1762] D loss: 1.3944, G loss: 0.6884\n",
      "[1124/1762] D loss: 1.3984, G loss: 0.7836\n",
      "[1204/1762] D loss: 1.4607, G loss: 0.9947\n",
      "[1284/1762] D loss: 1.3991, G loss: 0.7498\n",
      "[1364/1762] D loss: 0.0605, G loss: 2.9505\n",
      "[1444/1762] D loss: 1.4510, G loss: 0.5626\n",
      "[1524/1762] D loss: 0.0589, G loss: 3.0208\n",
      "[1604/1762] D loss: 1.3939, G loss: 0.6970\n",
      "[1684/1762] D loss: 1.4011, G loss: 0.7020\n",
      "[1762/1762] D loss: 1.4038, G loss: 0.6275\n",
      "train error: \n",
      " D loss: 1.505261, G loss: 0.583199, D accuracy: 50.9%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.526165, G loss: 0.588602, D accuracy: 51.4%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3964, G loss: 0.6982\n",
      "[84/1762] D loss: 0.0803, G loss: 2.4997\n",
      "[164/1762] D loss: 0.0571, G loss: 3.0856\n",
      "[244/1762] D loss: 0.0414, G loss: 3.2707\n",
      "[324/1762] D loss: 1.3891, G loss: 0.7426\n",
      "[404/1762] D loss: 1.3906, G loss: 0.7199\n",
      "[484/1762] D loss: 0.0149, G loss: 4.1824\n",
      "[564/1762] D loss: 1.4053, G loss: 0.6874\n",
      "[644/1762] D loss: 1.3240, G loss: 1.6627\n",
      "[724/1762] D loss: 1.4244, G loss: 2.0026\n",
      "[804/1762] D loss: 1.3984, G loss: 0.6692\n",
      "[884/1762] D loss: 1.1350, G loss: 1.4469\n",
      "[964/1762] D loss: 1.4230, G loss: 0.7892\n",
      "[1044/1762] D loss: 1.4452, G loss: 0.6843\n",
      "[1124/1762] D loss: 0.1460, G loss: 2.2116\n",
      "[1204/1762] D loss: 0.0055, G loss: 5.5057\n",
      "[1284/1762] D loss: 1.3894, G loss: 0.5022\n",
      "[1364/1762] D loss: 1.5071, G loss: 0.4808\n",
      "[1444/1762] D loss: 1.4338, G loss: 0.9863\n",
      "[1524/1762] D loss: 1.3928, G loss: 0.5913\n",
      "[1604/1762] D loss: 1.3896, G loss: 0.7522\n",
      "[1684/1762] D loss: 1.4232, G loss: 0.8713\n",
      "[1762/1762] D loss: 1.4495, G loss: 0.9013\n",
      "train error: \n",
      " D loss: 1.333828, G loss: 0.713797, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.314032, G loss: 0.733958, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0496, G loss: 3.0973\n",
      "[84/1762] D loss: 1.3869, G loss: 0.6854\n",
      "[164/1762] D loss: 1.3845, G loss: 0.7798\n",
      "[244/1762] D loss: 1.3873, G loss: 0.7105\n",
      "[324/1762] D loss: 0.0932, G loss: 2.6493\n",
      "[404/1762] D loss: 0.0839, G loss: 2.5607\n",
      "[484/1762] D loss: 1.3916, G loss: 0.6196\n",
      "[564/1762] D loss: 1.3503, G loss: 0.9431\n",
      "[644/1762] D loss: 0.1226, G loss: 2.1313\n",
      "[724/1762] D loss: 1.3941, G loss: 0.7653\n",
      "[804/1762] D loss: 0.0744, G loss: 2.7801\n",
      "[884/1762] D loss: 0.0822, G loss: 2.7427\n",
      "[964/1762] D loss: 1.4115, G loss: 0.7610\n",
      "[1044/1762] D loss: 1.4259, G loss: 0.9082\n",
      "[1124/1762] D loss: 1.4118, G loss: 0.7753\n",
      "[1204/1762] D loss: 1.4079, G loss: 0.7651\n",
      "[1284/1762] D loss: 1.3975, G loss: 0.7814\n",
      "[1364/1762] D loss: 1.3992, G loss: 0.8274\n",
      "[1444/1762] D loss: 1.4008, G loss: 0.6977\n",
      "[1524/1762] D loss: 0.1062, G loss: 2.5634\n",
      "[1604/1762] D loss: 1.3963, G loss: 0.6914\n",
      "[1684/1762] D loss: 1.0725, G loss: 3.0412\n",
      "[1762/1762] D loss: 1.3910, G loss: 0.6835\n",
      "train error: \n",
      " D loss: 1.423832, G loss: 0.557117, D accuracy: 52.4%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.416167, G loss: 0.551831, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0690, G loss: 2.8586\n",
      "[84/1762] D loss: 0.8501, G loss: 1.1544\n",
      "[164/1762] D loss: 0.0436, G loss: 3.5039\n",
      "[244/1762] D loss: 1.0753, G loss: 0.9228\n",
      "[324/1762] D loss: 1.6228, G loss: 0.3690\n",
      "[404/1762] D loss: 1.3948, G loss: 0.7689\n",
      "[484/1762] D loss: 1.4014, G loss: 0.7263\n",
      "[564/1762] D loss: 1.4127, G loss: 0.6786\n",
      "[644/1762] D loss: 1.6156, G loss: 1.0141\n",
      "[724/1762] D loss: 1.3949, G loss: 0.6749\n",
      "[804/1762] D loss: 1.4196, G loss: 0.5417\n",
      "[884/1762] D loss: 1.4006, G loss: 0.8038\n",
      "[964/1762] D loss: 0.0812, G loss: 2.6997\n",
      "[1044/1762] D loss: 1.1898, G loss: 0.9470\n",
      "[1124/1762] D loss: 0.0697, G loss: 2.8563\n",
      "[1204/1762] D loss: 1.3888, G loss: 0.6598\n",
      "[1284/1762] D loss: 0.0905, G loss: 2.6853\n",
      "[1364/1762] D loss: 1.3995, G loss: 0.6833\n",
      "[1444/1762] D loss: 1.3922, G loss: 0.7087\n",
      "[1524/1762] D loss: 1.4281, G loss: 0.8202\n",
      "[1604/1762] D loss: 1.4133, G loss: 0.8088\n",
      "[1684/1762] D loss: 1.3954, G loss: 0.6626\n",
      "[1762/1762] D loss: 1.3941, G loss: 0.6509\n",
      "train error: \n",
      " D loss: 1.916270, G loss: 0.205613, D accuracy: 49.5%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.907564, G loss: 0.208702, D accuracy: 49.4%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0540, G loss: 3.2069\n",
      "[84/1762] D loss: 1.3928, G loss: 0.6388\n",
      "[164/1762] D loss: 0.0582, G loss: 2.9024\n",
      "[244/1762] D loss: 1.4702, G loss: 0.8516\n",
      "[324/1762] D loss: 0.0026, G loss: 6.2970\n",
      "[404/1762] D loss: 1.3884, G loss: 0.7961\n",
      "[484/1762] D loss: 0.0452, G loss: 3.3791\n",
      "[564/1762] D loss: 1.3905, G loss: 0.7455\n",
      "[644/1762] D loss: 1.3921, G loss: 0.6593\n",
      "[724/1762] D loss: 1.3935, G loss: 0.8084\n",
      "[804/1762] D loss: 0.0504, G loss: 3.0716\n",
      "[884/1762] D loss: 0.0741, G loss: 2.7953\n",
      "[964/1762] D loss: 1.3913, G loss: 0.6316\n",
      "[1044/1762] D loss: 1.4096, G loss: 0.7747\n",
      "[1124/1762] D loss: 1.4494, G loss: 0.8760\n",
      "[1204/1762] D loss: 1.4040, G loss: 0.6540\n",
      "[1284/1762] D loss: 1.4200, G loss: 0.7477\n",
      "[1364/1762] D loss: 1.4038, G loss: 0.8398\n",
      "[1444/1762] D loss: 0.0476, G loss: 3.2059\n",
      "[1524/1762] D loss: 0.0690, G loss: 2.7524\n",
      "[1604/1762] D loss: 1.3891, G loss: 0.7549\n",
      "[1684/1762] D loss: 0.0692, G loss: 2.8797\n",
      "[1762/1762] D loss: 1.4006, G loss: 0.7223\n",
      "train error: \n",
      " D loss: 1.569056, G loss: 0.414111, D accuracy: 52.0%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.559017, G loss: 0.430687, D accuracy: 53.0%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3901, G loss: 0.6214\n",
      "[84/1762] D loss: 0.0506, G loss: 3.0609\n",
      "[164/1762] D loss: 0.7868, G loss: 2.5986\n",
      "[244/1762] D loss: 1.5507, G loss: 0.9865\n",
      "[324/1762] D loss: 1.8427, G loss: 0.3890\n",
      "[404/1762] D loss: 0.1471, G loss: 2.4726\n",
      "[484/1762] D loss: 1.4763, G loss: 0.6281\n",
      "[564/1762] D loss: 1.7829, G loss: 1.1586\n",
      "[644/1762] D loss: 1.5527, G loss: 0.3877\n",
      "[724/1762] D loss: 1.4016, G loss: 0.8351\n",
      "[804/1762] D loss: 0.0651, G loss: 2.7732\n",
      "[884/1762] D loss: 1.3971, G loss: 0.8326\n",
      "[964/1762] D loss: 0.1119, G loss: 2.5019\n",
      "[1044/1762] D loss: 1.3870, G loss: 0.8155\n",
      "[1124/1762] D loss: 1.4012, G loss: 0.5790\n",
      "[1204/1762] D loss: 1.3950, G loss: 0.6236\n",
      "[1284/1762] D loss: 1.4145, G loss: 0.5987\n",
      "[1364/1762] D loss: 1.4074, G loss: 0.7994\n",
      "[1444/1762] D loss: 1.4287, G loss: 0.5590\n",
      "[1524/1762] D loss: 1.3955, G loss: 0.8103\n",
      "[1604/1762] D loss: 1.4117, G loss: 0.7726\n",
      "[1684/1762] D loss: 0.0538, G loss: 3.0929\n",
      "[1762/1762] D loss: 1.3904, G loss: 0.6947\n",
      "train error: \n",
      " D loss: 2.186328, G loss: 0.154482, D accuracy: 50.1%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 2.171928, G loss: 0.171365, D accuracy: 50.2%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3867, G loss: 0.6695\n",
      "[84/1762] D loss: 0.0665, G loss: 2.9644\n",
      "[164/1762] D loss: 1.4007, G loss: 0.7608\n",
      "[244/1762] D loss: 1.3911, G loss: 0.7304\n",
      "[324/1762] D loss: 1.4000, G loss: 0.7417\n",
      "[404/1762] D loss: 1.4064, G loss: 0.7211\n",
      "[484/1762] D loss: 1.4298, G loss: 0.8494\n",
      "[564/1762] D loss: 1.3939, G loss: 0.6859\n",
      "[644/1762] D loss: 1.4363, G loss: 0.8843\n",
      "[724/1762] D loss: 0.0880, G loss: 2.6132\n",
      "[804/1762] D loss: 0.0599, G loss: 3.0239\n",
      "[884/1762] D loss: 1.3867, G loss: 0.7126\n",
      "[964/1762] D loss: 0.0638, G loss: 2.8515\n",
      "[1044/1762] D loss: 1.3861, G loss: 0.6401\n",
      "[1124/1762] D loss: 1.3902, G loss: 0.7633\n",
      "[1204/1762] D loss: 0.0635, G loss: 2.9413\n",
      "[1284/1762] D loss: 0.0030, G loss: 6.0658\n",
      "[1364/1762] D loss: 1.4191, G loss: 0.6396\n",
      "[1444/1762] D loss: 0.0519, G loss: 3.1067\n",
      "[1524/1762] D loss: 1.3944, G loss: 0.6396\n",
      "[1604/1762] D loss: 1.3998, G loss: 0.6462\n",
      "[1684/1762] D loss: 1.3883, G loss: 0.6631\n",
      "[1762/1762] D loss: 1.3928, G loss: 0.7708\n",
      "train error: \n",
      " D loss: 1.614393, G loss: 1.012399, D accuracy: 50.6%, cell accuracy: 99.9%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.621020, G loss: 1.029293, D accuracy: 50.6%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4142, G loss: 0.8537\n",
      "[84/1762] D loss: 1.4273, G loss: 0.7399\n",
      "[164/1762] D loss: 1.4226, G loss: 0.5000\n",
      "[244/1762] D loss: 1.4312, G loss: 0.6286\n",
      "[324/1762] D loss: 1.4143, G loss: 0.8962\n",
      "[404/1762] D loss: 0.0939, G loss: 2.6955\n",
      "[484/1762] D loss: 1.4869, G loss: 1.0064\n",
      "[564/1762] D loss: 1.4183, G loss: 0.7112\n",
      "[644/1762] D loss: 1.4050, G loss: 0.5876\n",
      "[724/1762] D loss: 1.4538, G loss: 0.9427\n",
      "[804/1762] D loss: 1.3880, G loss: 0.6774\n",
      "[884/1762] D loss: 0.0982, G loss: 2.5167\n",
      "[964/1762] D loss: 1.3945, G loss: 0.6887\n",
      "[1044/1762] D loss: 1.3915, G loss: 0.6397\n",
      "[1124/1762] D loss: 0.0668, G loss: 2.8642\n",
      "[1204/1762] D loss: 1.3925, G loss: 0.8275\n",
      "[1284/1762] D loss: 0.0775, G loss: 2.7047\n",
      "[1364/1762] D loss: 1.4115, G loss: 0.8234\n",
      "[1444/1762] D loss: 1.5072, G loss: 0.4724\n",
      "[1524/1762] D loss: 1.5913, G loss: 1.0648\n",
      "[1604/1762] D loss: 1.4183, G loss: 0.6037\n",
      "[1684/1762] D loss: 1.3989, G loss: 0.7478\n",
      "[1762/1762] D loss: 1.3879, G loss: 0.6735\n",
      "train error: \n",
      " D loss: 1.596163, G loss: 0.445432, D accuracy: 51.0%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.590419, G loss: 0.459122, D accuracy: 51.5%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3927, G loss: 0.6226\n",
      "[84/1762] D loss: 0.0777, G loss: 2.6866\n",
      "[164/1762] D loss: 1.3972, G loss: 0.7058\n",
      "[244/1762] D loss: 0.0495, G loss: 3.0754\n",
      "[324/1762] D loss: 1.3909, G loss: 0.7783\n",
      "[404/1762] D loss: 0.0351, G loss: 3.6375\n",
      "[484/1762] D loss: 1.3978, G loss: 0.6772\n",
      "[564/1762] D loss: 1.4116, G loss: 0.8003\n",
      "[644/1762] D loss: 1.3927, G loss: 0.7432\n",
      "[724/1762] D loss: 1.3938, G loss: 0.7426\n",
      "[804/1762] D loss: 1.3992, G loss: 0.5462\n",
      "[884/1762] D loss: 1.4272, G loss: 0.5683\n",
      "[964/1762] D loss: 1.4087, G loss: 0.7469\n",
      "[1044/1762] D loss: 1.3993, G loss: 0.7798\n",
      "[1124/1762] D loss: 0.0518, G loss: 3.0200\n",
      "[1204/1762] D loss: 1.3933, G loss: 0.5772\n",
      "[1284/1762] D loss: 0.0412, G loss: 3.3087\n",
      "[1364/1762] D loss: 0.0500, G loss: 2.9762\n",
      "[1444/1762] D loss: 1.3895, G loss: 0.7210\n",
      "[1524/1762] D loss: 1.3948, G loss: 0.7902\n",
      "[1604/1762] D loss: 0.0639, G loss: 2.7630\n",
      "[1684/1762] D loss: 1.3904, G loss: 0.6696\n",
      "[1762/1762] D loss: 1.3887, G loss: 0.7077\n",
      "train error: \n",
      " D loss: 1.674043, G loss: 0.419042, D accuracy: 50.5%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.674735, G loss: 0.431531, D accuracy: 50.6%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3931, G loss: 0.6539\n",
      "[84/1762] D loss: 1.4024, G loss: 0.6917\n",
      "[164/1762] D loss: 1.3923, G loss: 0.6224\n",
      "[244/1762] D loss: 1.5383, G loss: 1.1457\n",
      "[324/1762] D loss: 1.4666, G loss: 0.4500\n",
      "[404/1762] D loss: 1.3902, G loss: 0.7624\n",
      "[484/1762] D loss: 1.3884, G loss: 0.6573\n",
      "[564/1762] D loss: 1.4014, G loss: 0.8114\n",
      "[644/1762] D loss: 1.2940, G loss: 0.7675\n",
      "[724/1762] D loss: 1.4097, G loss: 0.5203\n",
      "[804/1762] D loss: 1.3268, G loss: 2.3964\n",
      "[884/1762] D loss: 1.4527, G loss: 0.6323\n",
      "[964/1762] D loss: 1.4787, G loss: 0.4277\n",
      "[1044/1762] D loss: 1.4414, G loss: 0.5963\n",
      "[1124/1762] D loss: 1.3948, G loss: 0.7889\n",
      "[1204/1762] D loss: 1.3957, G loss: 0.7405\n",
      "[1284/1762] D loss: 0.0040, G loss: 5.8038\n",
      "[1364/1762] D loss: 1.0642, G loss: 1.4191\n",
      "[1444/1762] D loss: 1.3994, G loss: 0.6167\n",
      "[1524/1762] D loss: 1.4469, G loss: 0.5005\n",
      "[1604/1762] D loss: 1.4386, G loss: 0.5671\n",
      "[1684/1762] D loss: 0.0727, G loss: 2.7619\n",
      "[1762/1762] D loss: 1.3958, G loss: 0.6585\n",
      "train error: \n",
      " D loss: 1.536500, G loss: 0.739455, D accuracy: 50.8%, cell accuracy: 99.9%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.542171, G loss: 0.748072, D accuracy: 51.0%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4040, G loss: 0.6670\n",
      "[84/1762] D loss: 1.3998, G loss: 0.7540\n",
      "[164/1762] D loss: 1.3900, G loss: 0.6980\n",
      "[244/1762] D loss: 1.3866, G loss: 0.6699\n",
      "[324/1762] D loss: 1.4086, G loss: 0.7982\n",
      "[404/1762] D loss: 1.4069, G loss: 0.8213\n",
      "[484/1762] D loss: 1.3930, G loss: 0.6465\n",
      "[564/1762] D loss: 1.4704, G loss: 0.9408\n",
      "[644/1762] D loss: 1.4383, G loss: 0.5515\n",
      "[724/1762] D loss: 0.0222, G loss: 4.1144\n",
      "[804/1762] D loss: 0.0791, G loss: 2.8393\n",
      "[884/1762] D loss: 1.3901, G loss: 0.6918\n",
      "[964/1762] D loss: 0.0867, G loss: 2.5031\n",
      "[1044/1762] D loss: 1.4409, G loss: 0.8200\n",
      "[1124/1762] D loss: 1.5239, G loss: 0.9088\n",
      "[1204/1762] D loss: 1.4093, G loss: 0.6460\n",
      "[1284/1762] D loss: 1.3954, G loss: 0.6295\n",
      "[1364/1762] D loss: 0.0987, G loss: 2.3825\n",
      "[1444/1762] D loss: 1.5590, G loss: 0.5854\n",
      "[1524/1762] D loss: 1.0416, G loss: 1.2971\n",
      "[1604/1762] D loss: 1.4324, G loss: 0.4964\n",
      "[1684/1762] D loss: 0.1285, G loss: 2.5914\n",
      "[1762/1762] D loss: 1.4147, G loss: 0.7502\n",
      "train error: \n",
      " D loss: 1.496953, G loss: 0.558280, D accuracy: 52.3%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.469194, G loss: 0.598867, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0733, G loss: 2.6823\n",
      "[84/1762] D loss: 1.4562, G loss: 0.5679\n",
      "[164/1762] D loss: 1.3847, G loss: 5.0378\n",
      "[244/1762] D loss: 1.4046, G loss: 0.6802\n",
      "[324/1762] D loss: 1.4298, G loss: 0.8395\n",
      "[404/1762] D loss: 1.4600, G loss: 0.5353\n",
      "[484/1762] D loss: 0.0337, G loss: 3.5567\n",
      "[564/1762] D loss: 0.0995, G loss: 2.1730\n",
      "[644/1762] D loss: 1.3938, G loss: 0.9150\n",
      "[724/1762] D loss: 1.4712, G loss: 0.7808\n",
      "[804/1762] D loss: 1.4040, G loss: 0.7466\n",
      "[884/1762] D loss: 1.6073, G loss: 1.1176\n",
      "[964/1762] D loss: 1.4198, G loss: 0.5340\n",
      "[1044/1762] D loss: 1.4088, G loss: 0.6227\n",
      "[1124/1762] D loss: 1.3891, G loss: 0.7060\n",
      "[1204/1762] D loss: 1.3936, G loss: 0.7198\n",
      "[1284/1762] D loss: 1.3976, G loss: 0.7907\n",
      "[1364/1762] D loss: 0.0599, G loss: 3.1659\n",
      "[1444/1762] D loss: 1.4055, G loss: 0.7818\n",
      "[1524/1762] D loss: 1.3922, G loss: 0.6340\n",
      "[1604/1762] D loss: 0.0682, G loss: 2.7816\n",
      "[1684/1762] D loss: 1.4038, G loss: 0.7088\n",
      "[1762/1762] D loss: 1.3923, G loss: 0.7890\n",
      "train error: \n",
      " D loss: 1.952476, G loss: 0.217340, D accuracy: 49.2%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.935864, G loss: 0.226301, D accuracy: 49.4%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0706, G loss: 2.8384\n",
      "[84/1762] D loss: 1.3919, G loss: 0.6581\n",
      "[164/1762] D loss: 1.3978, G loss: 0.7267\n",
      "[244/1762] D loss: 1.5208, G loss: 0.4309\n",
      "[324/1762] D loss: 1.5827, G loss: 1.1416\n",
      "[404/1762] D loss: 1.4037, G loss: 0.5809\n",
      "[484/1762] D loss: 1.3891, G loss: 0.7067\n",
      "[564/1762] D loss: 1.4067, G loss: 0.7994\n",
      "[644/1762] D loss: 1.3959, G loss: 0.5665\n",
      "[724/1762] D loss: 1.3375, G loss: 0.8002\n",
      "[804/1762] D loss: 1.4710, G loss: 0.9665\n",
      "[884/1762] D loss: 0.0783, G loss: 2.6389\n",
      "[964/1762] D loss: 1.3899, G loss: 0.7228\n",
      "[1044/1762] D loss: 1.3903, G loss: 0.6852\n",
      "[1124/1762] D loss: 1.3931, G loss: 0.7446\n",
      "[1204/1762] D loss: 0.0673, G loss: 2.8924\n",
      "[1284/1762] D loss: 1.4006, G loss: 0.6059\n",
      "[1364/1762] D loss: 1.3906, G loss: 0.6460\n",
      "[1444/1762] D loss: 1.4107, G loss: 0.8412\n",
      "[1524/1762] D loss: 1.3892, G loss: 0.7035\n",
      "[1604/1762] D loss: 1.4106, G loss: 0.8049\n",
      "[1684/1762] D loss: 1.4240, G loss: 0.6029\n",
      "[1762/1762] D loss: 1.4448, G loss: 0.6005\n",
      "train error: \n",
      " D loss: 1.987045, G loss: 0.231534, D accuracy: 49.3%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.960056, G loss: 0.239834, D accuracy: 49.2%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0711, G loss: 3.0561\n",
      "[84/1762] D loss: 0.0514, G loss: 2.9976\n",
      "[164/1762] D loss: 1.4189, G loss: 0.5761\n",
      "[244/1762] D loss: 0.0028, G loss: 6.0271\n",
      "[324/1762] D loss: 0.1204, G loss: 2.2423\n",
      "[404/1762] D loss: 1.3915, G loss: 0.7241\n",
      "[484/1762] D loss: 1.3944, G loss: 0.6200\n",
      "[564/1762] D loss: 1.3939, G loss: 0.7262\n",
      "[644/1762] D loss: 1.4101, G loss: 0.6225\n",
      "[724/1762] D loss: 1.3960, G loss: 0.7637\n",
      "[804/1762] D loss: 1.4395, G loss: 0.8286\n",
      "[884/1762] D loss: 1.4579, G loss: 0.9781\n",
      "[964/1762] D loss: 1.3884, G loss: 0.6967\n",
      "[1044/1762] D loss: 1.4131, G loss: 0.6266\n",
      "[1124/1762] D loss: 1.3966, G loss: 0.8024\n",
      "[1204/1762] D loss: 1.4354, G loss: 0.9159\n",
      "[1284/1762] D loss: 1.3923, G loss: 0.5687\n",
      "[1364/1762] D loss: 1.3929, G loss: 0.7431\n",
      "[1444/1762] D loss: 1.3989, G loss: 0.6261\n",
      "[1524/1762] D loss: 1.4014, G loss: 0.7316\n",
      "[1604/1762] D loss: 1.3973, G loss: 0.6881\n",
      "[1684/1762] D loss: 1.3913, G loss: 0.6865\n",
      "[1762/1762] D loss: 1.3975, G loss: 0.6270\n",
      "train error: \n",
      " D loss: 1.615231, G loss: 0.660323, D accuracy: 50.4%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.650983, G loss: 0.672718, D accuracy: 50.6%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3966, G loss: 0.7592\n",
      "[84/1762] D loss: 1.3975, G loss: 0.7340\n",
      "[164/1762] D loss: 0.0148, G loss: 4.3882\n",
      "[244/1762] D loss: 1.4079, G loss: 0.6138\n",
      "[324/1762] D loss: 1.3943, G loss: 0.7727\n",
      "[404/1762] D loss: 1.4003, G loss: 0.7113\n",
      "[484/1762] D loss: 1.4123, G loss: 0.8342\n",
      "[564/1762] D loss: 1.3932, G loss: 0.6547\n",
      "[644/1762] D loss: 0.0481, G loss: 3.0252\n",
      "[724/1762] D loss: 1.3972, G loss: 0.7458\n",
      "[804/1762] D loss: 1.3994, G loss: 0.6226\n",
      "[884/1762] D loss: 1.4142, G loss: 0.9253\n",
      "[964/1762] D loss: 1.3908, G loss: 0.7207\n",
      "[1044/1762] D loss: 1.3969, G loss: 0.5690\n",
      "[1124/1762] D loss: 0.0513, G loss: 3.1937\n",
      "[1204/1762] D loss: 1.3924, G loss: 0.7208\n",
      "[1284/1762] D loss: 1.4592, G loss: 0.7999\n",
      "[1364/1762] D loss: 0.0380, G loss: 3.3698\n",
      "[1444/1762] D loss: 1.4040, G loss: 0.8151\n",
      "[1524/1762] D loss: 0.0524, G loss: 3.2489\n",
      "[1604/1762] D loss: 1.3883, G loss: 0.6329\n",
      "[1684/1762] D loss: 1.4298, G loss: 0.4267\n",
      "[1762/1762] D loss: 1.4489, G loss: 0.9340\n",
      "train error: \n",
      " D loss: 1.948070, G loss: 0.257269, D accuracy: 47.8%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.957335, G loss: 0.266936, D accuracy: 47.2%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0426, G loss: 3.2767\n",
      "[84/1762] D loss: 1.4160, G loss: 0.5604\n",
      "[164/1762] D loss: 1.4018, G loss: 0.7326\n",
      "[244/1762] D loss: 1.3950, G loss: 0.7033\n",
      "[324/1762] D loss: 1.3944, G loss: 0.6866\n",
      "[404/1762] D loss: 1.3877, G loss: 0.6856\n",
      "[484/1762] D loss: 0.0641, G loss: 2.8364\n",
      "[564/1762] D loss: 1.4896, G loss: 0.4955\n",
      "[644/1762] D loss: 1.3974, G loss: 0.5776\n",
      "[724/1762] D loss: 1.3963, G loss: 0.7495\n",
      "[804/1762] D loss: 0.0438, G loss: 3.1172\n",
      "[884/1762] D loss: 1.3930, G loss: 0.6701\n",
      "[964/1762] D loss: 1.4104, G loss: 0.7750\n",
      "[1044/1762] D loss: 0.5684, G loss: 2.2814\n",
      "[1124/1762] D loss: 1.4018, G loss: 0.8703\n",
      "[1204/1762] D loss: 1.3957, G loss: 0.6250\n",
      "[1284/1762] D loss: 1.5809, G loss: 0.4063\n",
      "[1364/1762] D loss: 0.0696, G loss: 2.9411\n",
      "[1444/1762] D loss: 0.0604, G loss: 2.9291\n",
      "[1524/1762] D loss: 1.3961, G loss: 0.6767\n",
      "[1604/1762] D loss: 0.0601, G loss: 2.9593\n",
      "[1684/1762] D loss: 1.3880, G loss: 0.7132\n",
      "[1762/1762] D loss: 1.3904, G loss: 0.7512\n",
      "train error: \n",
      " D loss: 2.115257, G loss: 0.219978, D accuracy: 47.4%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 2.147565, G loss: 0.223352, D accuracy: 46.6%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0769, G loss: 3.0258\n",
      "[84/1762] D loss: 1.4402, G loss: 0.5842\n",
      "[164/1762] D loss: 0.0447, G loss: 3.1690\n",
      "[244/1762] D loss: 1.3928, G loss: 0.7709\n",
      "[324/1762] D loss: 1.3916, G loss: 0.7651\n",
      "[404/1762] D loss: 1.3940, G loss: 0.6601\n",
      "[484/1762] D loss: 1.3969, G loss: 0.7611\n",
      "[564/1762] D loss: 0.0423, G loss: 3.3115\n",
      "[644/1762] D loss: 1.3886, G loss: 0.7469\n",
      "[724/1762] D loss: 1.4108, G loss: 0.7939\n",
      "[804/1762] D loss: 1.3933, G loss: 0.7547\n",
      "[884/1762] D loss: 0.0483, G loss: 3.2309\n",
      "[964/1762] D loss: 1.4209, G loss: 0.5434\n",
      "[1044/1762] D loss: 1.3947, G loss: 0.7653\n",
      "[1124/1762] D loss: 1.3919, G loss: 0.8275\n",
      "[1204/1762] D loss: 1.4715, G loss: 0.4688\n",
      "[1284/1762] D loss: 1.4000, G loss: 0.7955\n",
      "[1364/1762] D loss: 0.0580, G loss: 2.9991\n",
      "[1444/1762] D loss: 0.0548, G loss: 2.8728\n",
      "[1524/1762] D loss: 1.4021, G loss: 0.7559\n",
      "[1604/1762] D loss: 1.4181, G loss: 0.6237\n",
      "[1684/1762] D loss: 1.3932, G loss: 0.5788\n",
      "[1762/1762] D loss: 1.4010, G loss: 0.6201\n",
      "train error: \n",
      " D loss: 1.730432, G loss: 0.483479, D accuracy: 49.6%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.770871, G loss: 0.519354, D accuracy: 49.0%, cell accuracy: 99.7%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4345, G loss: 0.5690\n",
      "[84/1762] D loss: 1.3973, G loss: 0.5802\n",
      "[164/1762] D loss: 0.0014, G loss: 7.7610\n",
      "[244/1762] D loss: 1.4541, G loss: 0.8338\n",
      "[324/1762] D loss: 0.0766, G loss: 2.6946\n",
      "[404/1762] D loss: 1.4005, G loss: 0.8086\n",
      "[484/1762] D loss: 1.3908, G loss: 0.8306\n",
      "[564/1762] D loss: 1.4601, G loss: 0.5342\n",
      "[644/1762] D loss: 1.4035, G loss: 0.5930\n",
      "[724/1762] D loss: 1.3951, G loss: 0.8269\n",
      "[804/1762] D loss: 1.4033, G loss: 0.8588\n",
      "[884/1762] D loss: 1.6196, G loss: 0.9702\n",
      "[964/1762] D loss: 1.3665, G loss: 0.9978\n",
      "[1044/1762] D loss: 1.5103, G loss: 1.1150\n",
      "[1124/1762] D loss: 1.4226, G loss: 0.7212\n",
      "[1204/1762] D loss: 1.4338, G loss: 0.5160\n",
      "[1284/1762] D loss: 1.4015, G loss: 0.7715\n",
      "[1364/1762] D loss: 0.0546, G loss: 3.1713\n",
      "[1444/1762] D loss: 1.4455, G loss: 0.8523\n",
      "[1524/1762] D loss: 0.0399, G loss: 3.3416\n",
      "[1604/1762] D loss: 1.4224, G loss: 0.8033\n",
      "[1684/1762] D loss: 0.0922, G loss: 2.6538\n",
      "[1762/1762] D loss: 1.3895, G loss: 0.6702\n",
      "train error: \n",
      " D loss: 1.830326, G loss: 0.627824, D accuracy: 49.8%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.928546, G loss: 0.638676, D accuracy: 50.0%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4084, G loss: 0.7592\n",
      "[84/1762] D loss: 1.4154, G loss: 0.8205\n",
      "[164/1762] D loss: 0.0860, G loss: 2.7172\n",
      "[244/1762] D loss: 1.4023, G loss: 0.7521\n",
      "[324/1762] D loss: 0.0689, G loss: 2.7423\n",
      "[404/1762] D loss: 1.3890, G loss: 0.9126\n",
      "[484/1762] D loss: 1.4055, G loss: 0.5702\n",
      "[564/1762] D loss: 1.4608, G loss: 0.5812\n",
      "[644/1762] D loss: 1.4013, G loss: 0.7887\n",
      "[724/1762] D loss: 1.4366, G loss: 0.6609\n",
      "[804/1762] D loss: 0.0770, G loss: 2.7409\n",
      "[884/1762] D loss: 1.4655, G loss: 0.9399\n",
      "[964/1762] D loss: 1.4018, G loss: 0.6471\n",
      "[1044/1762] D loss: 1.4271, G loss: 0.5248\n",
      "[1124/1762] D loss: 1.4041, G loss: 0.6051\n",
      "[1204/1762] D loss: 0.0810, G loss: 3.0749\n",
      "[1284/1762] D loss: 1.4104, G loss: 0.8476\n",
      "[1364/1762] D loss: 1.4187, G loss: 0.5533\n",
      "[1444/1762] D loss: 1.4027, G loss: 0.6055\n",
      "[1524/1762] D loss: 1.4027, G loss: 0.7500\n",
      "[1604/1762] D loss: 1.3867, G loss: 0.6968\n",
      "[1684/1762] D loss: 1.3895, G loss: 0.6920\n",
      "[1762/1762] D loss: 1.3878, G loss: 0.6878\n",
      "train error: \n",
      " D loss: 1.857048, G loss: 0.296628, D accuracy: 47.8%, cell accuracy: 99.9%, board accuracy: 92.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.863755, G loss: 0.301962, D accuracy: 46.8%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3845, G loss: 0.6315\n",
      "[84/1762] D loss: 1.3935, G loss: 0.8048\n",
      "[164/1762] D loss: 1.4083, G loss: 0.7872\n",
      "[244/1762] D loss: 1.3928, G loss: 0.6715\n",
      "[324/1762] D loss: 1.3963, G loss: 0.6934\n",
      "[404/1762] D loss: 0.0688, G loss: 3.4957\n",
      "[484/1762] D loss: 1.4369, G loss: 0.5034\n",
      "[564/1762] D loss: 1.3989, G loss: 0.8546\n",
      "[644/1762] D loss: 0.0610, G loss: 3.5124\n",
      "[724/1762] D loss: 1.3868, G loss: 0.6878\n",
      "[804/1762] D loss: 0.1045, G loss: 3.1811\n",
      "[884/1762] D loss: 1.3892, G loss: 0.7179\n",
      "[964/1762] D loss: 1.4340, G loss: 0.4487\n",
      "[1044/1762] D loss: 1.4480, G loss: 0.8550\n",
      "[1124/1762] D loss: 1.5437, G loss: 0.4507\n",
      "[1204/1762] D loss: 1.4063, G loss: 0.6546\n",
      "[1284/1762] D loss: 1.4034, G loss: 0.6523\n",
      "[1364/1762] D loss: 1.4040, G loss: 0.8091\n",
      "[1444/1762] D loss: 1.4003, G loss: 0.6474\n",
      "[1524/1762] D loss: 1.3959, G loss: 0.5656\n",
      "[1604/1762] D loss: 1.3946, G loss: 0.8060\n",
      "[1684/1762] D loss: 0.0571, G loss: 3.0682\n",
      "[1762/1762] D loss: 0.0031, G loss: 6.0077\n",
      "train error: \n",
      " D loss: 2.233894, G loss: 0.228561, D accuracy: 50.7%, cell accuracy: 99.8%, board accuracy: 90.6% \n",
      "\n",
      "test error: \n",
      " D loss: 2.197701, G loss: 0.285649, D accuracy: 51.2%, cell accuracy: 99.7%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4170, G loss: 0.7752\n",
      "[84/1762] D loss: 1.4142, G loss: 0.6889\n",
      "[164/1762] D loss: 0.0410, G loss: 3.2047\n",
      "[244/1762] D loss: 1.3887, G loss: 0.6429\n",
      "[324/1762] D loss: 1.4011, G loss: 0.6491\n",
      "[404/1762] D loss: 1.3995, G loss: 0.6071\n",
      "[484/1762] D loss: 0.0852, G loss: 2.6391\n",
      "[564/1762] D loss: 1.3966, G loss: 0.6117\n",
      "[644/1762] D loss: 1.4110, G loss: 0.7085\n",
      "[724/1762] D loss: 0.0632, G loss: 2.9042\n",
      "[804/1762] D loss: 1.3956, G loss: 0.6580\n",
      "[884/1762] D loss: 1.3833, G loss: 0.7229\n",
      "[964/1762] D loss: 1.3977, G loss: 0.6605\n",
      "[1044/1762] D loss: 1.4033, G loss: 0.7764\n",
      "[1124/1762] D loss: 1.3877, G loss: 0.7381\n",
      "[1204/1762] D loss: 1.3884, G loss: 0.7283\n",
      "[1284/1762] D loss: 1.3954, G loss: 0.6738\n",
      "[1364/1762] D loss: 1.4282, G loss: 0.6744\n",
      "[1444/1762] D loss: 0.0409, G loss: 3.4063\n",
      "[1524/1762] D loss: 1.3984, G loss: 0.7383\n",
      "[1604/1762] D loss: 1.4228, G loss: 0.7513\n",
      "[1684/1762] D loss: 0.0331, G loss: 3.6558\n",
      "[1762/1762] D loss: 1.3940, G loss: 0.7506\n",
      "train error: \n",
      " D loss: 1.644505, G loss: 0.624157, D accuracy: 50.8%, cell accuracy: 99.8%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.666972, G loss: 0.632938, D accuracy: 51.4%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4046, G loss: 0.6398\n",
      "[84/1762] D loss: 1.4036, G loss: 0.7598\n",
      "[164/1762] D loss: 0.0531, G loss: 3.1096\n",
      "[244/1762] D loss: 1.4006, G loss: 0.8095\n",
      "[324/1762] D loss: 1.4084, G loss: 0.6610\n",
      "[404/1762] D loss: 1.3919, G loss: 0.7268\n",
      "[484/1762] D loss: 0.1091, G loss: 2.8456\n",
      "[564/1762] D loss: 1.3990, G loss: 0.6947\n",
      "[644/1762] D loss: 1.3946, G loss: 0.6850\n",
      "[724/1762] D loss: 1.4015, G loss: 0.6026\n",
      "[804/1762] D loss: 1.3936, G loss: 0.7164\n",
      "[884/1762] D loss: 0.1014, G loss: 2.6452\n",
      "[964/1762] D loss: 1.6248, G loss: 0.8825\n",
      "[1044/1762] D loss: 1.4835, G loss: 0.9639\n",
      "[1124/1762] D loss: 1.4421, G loss: 0.5994\n",
      "[1204/1762] D loss: 1.4005, G loss: 0.6172\n",
      "[1284/1762] D loss: 1.4204, G loss: 0.8205\n",
      "[1364/1762] D loss: 1.3891, G loss: 0.6935\n",
      "[1444/1762] D loss: 1.2610, G loss: 1.2575\n",
      "[1524/1762] D loss: 1.3823, G loss: 0.7108\n",
      "[1604/1762] D loss: 0.0462, G loss: 3.1822\n",
      "[1684/1762] D loss: 0.0702, G loss: 2.7464\n",
      "[1762/1762] D loss: 1.4074, G loss: 0.7894\n",
      "train error: \n",
      " D loss: 1.781472, G loss: 0.662854, D accuracy: 49.9%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.860946, G loss: 0.675419, D accuracy: 50.0%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4476, G loss: 0.7808\n",
      "[84/1762] D loss: 1.3882, G loss: 0.7734\n",
      "[164/1762] D loss: 1.3951, G loss: 0.6696\n",
      "[244/1762] D loss: 1.3888, G loss: 0.7802\n",
      "[324/1762] D loss: 0.0690, G loss: 2.6932\n",
      "[404/1762] D loss: 1.4236, G loss: 0.8886\n",
      "[484/1762] D loss: 1.3902, G loss: 0.7060\n",
      "[564/1762] D loss: 1.3606, G loss: 0.7301\n",
      "[644/1762] D loss: 1.3866, G loss: 0.6024\n",
      "[724/1762] D loss: 1.4461, G loss: 0.9891\n",
      "[804/1762] D loss: 1.4507, G loss: 0.5845\n",
      "[884/1762] D loss: 0.0490, G loss: 3.1770\n",
      "[964/1762] D loss: 1.3998, G loss: 0.8121\n",
      "[1044/1762] D loss: 1.3916, G loss: 0.6082\n",
      "[1124/1762] D loss: 0.1242, G loss: 2.5712\n",
      "[1204/1762] D loss: 0.0790, G loss: 2.4844\n",
      "[1284/1762] D loss: 1.4566, G loss: 0.6165\n",
      "[1364/1762] D loss: 1.4517, G loss: 0.9102\n",
      "[1444/1762] D loss: 1.3958, G loss: 0.6585\n",
      "[1524/1762] D loss: 1.4016, G loss: 0.7045\n",
      "[1604/1762] D loss: 1.3921, G loss: 0.6217\n",
      "[1684/1762] D loss: 1.3877, G loss: 0.7904\n",
      "[1762/1762] D loss: 1.4016, G loss: 0.6223\n",
      "train error: \n",
      " D loss: 1.634034, G loss: 0.598908, D accuracy: 51.4%, cell accuracy: 99.8%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.669556, G loss: 0.603487, D accuracy: 51.5%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3892, G loss: 0.7011\n",
      "[84/1762] D loss: 1.4170, G loss: 0.8173\n",
      "[164/1762] D loss: 1.4086, G loss: 0.5591\n",
      "[244/1762] D loss: 1.4186, G loss: 0.8119\n",
      "[324/1762] D loss: 1.3743, G loss: 0.8179\n",
      "[404/1762] D loss: 1.3963, G loss: 0.7355\n",
      "[484/1762] D loss: 0.0591, G loss: 2.9123\n",
      "[564/1762] D loss: 1.4433, G loss: 0.9357\n",
      "[644/1762] D loss: 0.0629, G loss: 3.1278\n",
      "[724/1762] D loss: 1.4022, G loss: 0.8237\n",
      "[804/1762] D loss: 0.0592, G loss: 2.9514\n",
      "[884/1762] D loss: 0.0408, G loss: 3.2349\n",
      "[964/1762] D loss: 1.3944, G loss: 0.7303\n",
      "[1044/1762] D loss: 1.4003, G loss: 0.8251\n",
      "[1124/1762] D loss: 1.4079, G loss: 0.6706\n",
      "[1204/1762] D loss: 0.0441, G loss: 3.1939\n",
      "[1284/1762] D loss: 1.4288, G loss: 0.8531\n",
      "[1364/1762] D loss: 0.0656, G loss: 2.9168\n",
      "[1444/1762] D loss: 0.0494, G loss: 3.1442\n",
      "[1524/1762] D loss: 1.3894, G loss: 0.7190\n",
      "[1604/1762] D loss: 1.3978, G loss: 0.7565\n",
      "[1684/1762] D loss: 1.4060, G loss: 0.7666\n",
      "[1762/1762] D loss: 1.3941, G loss: 0.7350\n",
      "train error: \n",
      " D loss: 1.753748, G loss: 0.475465, D accuracy: 50.3%, cell accuracy: 99.9%, board accuracy: 92.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.799229, G loss: 0.480569, D accuracy: 50.7%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3897, G loss: 0.6756\n",
      "[84/1762] D loss: 1.3977, G loss: 0.6794\n",
      "[164/1762] D loss: 1.4831, G loss: 1.0150\n",
      "[244/1762] D loss: 1.3915, G loss: 0.7415\n",
      "[324/1762] D loss: 0.0659, G loss: 2.8719\n",
      "[404/1762] D loss: 0.0676, G loss: 2.8327\n",
      "[484/1762] D loss: 1.3927, G loss: 0.6543\n",
      "[564/1762] D loss: 1.3918, G loss: 0.7537\n",
      "[644/1762] D loss: 1.3979, G loss: 0.6364\n",
      "[724/1762] D loss: 1.3938, G loss: 0.6781\n",
      "[804/1762] D loss: 1.3946, G loss: 0.7001\n",
      "[884/1762] D loss: 1.3787, G loss: 0.7963\n",
      "[964/1762] D loss: 1.3948, G loss: 0.7028\n",
      "[1044/1762] D loss: 0.0640, G loss: 2.8612\n",
      "[1124/1762] D loss: 1.3950, G loss: 0.7315\n",
      "[1204/1762] D loss: 1.3961, G loss: 0.6518\n",
      "[1284/1762] D loss: 1.3876, G loss: 0.6560\n",
      "[1364/1762] D loss: 1.3969, G loss: 0.7596\n",
      "[1444/1762] D loss: 1.3965, G loss: 0.8514\n",
      "[1524/1762] D loss: 1.4157, G loss: 0.8091\n",
      "[1604/1762] D loss: 1.4099, G loss: 0.7089\n",
      "[1684/1762] D loss: 1.3865, G loss: 0.7594\n",
      "[1762/1762] D loss: 1.3877, G loss: 0.7612\n",
      "train error: \n",
      " D loss: 1.683382, G loss: 0.808130, D accuracy: 50.0%, cell accuracy: 99.9%, board accuracy: 92.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.745643, G loss: 0.827910, D accuracy: 50.2%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3874, G loss: 0.7566\n",
      "[84/1762] D loss: 0.0417, G loss: 3.2770\n",
      "[164/1762] D loss: 1.4119, G loss: 0.6868\n",
      "[244/1762] D loss: 1.4844, G loss: 0.9360\n",
      "[324/1762] D loss: 1.4009, G loss: 0.6877\n",
      "[404/1762] D loss: 1.4205, G loss: 0.5304\n",
      "[484/1762] D loss: 1.3858, G loss: 0.7132\n",
      "[564/1762] D loss: 1.3997, G loss: 0.6707\n",
      "[644/1762] D loss: 1.3910, G loss: 0.6711\n",
      "[724/1762] D loss: 1.3993, G loss: 0.6740\n",
      "[804/1762] D loss: 1.3987, G loss: 0.7128\n",
      "[884/1762] D loss: 0.0509, G loss: 2.9419\n",
      "[964/1762] D loss: 1.4257, G loss: 0.6388\n",
      "[1044/1762] D loss: 1.3902, G loss: 0.6481\n",
      "[1124/1762] D loss: 1.3918, G loss: 0.6540\n",
      "[1204/1762] D loss: 1.3940, G loss: 0.6165\n",
      "[1284/1762] D loss: 1.4140, G loss: 0.6437\n",
      "[1364/1762] D loss: 1.4248, G loss: 0.9267\n",
      "[1444/1762] D loss: 1.3996, G loss: 0.5922\n",
      "[1524/1762] D loss: 1.3987, G loss: 0.6362\n",
      "[1604/1762] D loss: 1.3995, G loss: 0.7799\n",
      "[1684/1762] D loss: 1.4510, G loss: 0.4886\n",
      "[1762/1762] D loss: 1.5691, G loss: 0.9372\n",
      "train error: \n",
      " D loss: 1.698480, G loss: 0.490682, D accuracy: 48.5%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.765197, G loss: 0.485854, D accuracy: 47.6%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4040, G loss: 0.5412\n",
      "[84/1762] D loss: 0.0407, G loss: 3.3632\n",
      "[164/1762] D loss: 1.3935, G loss: 0.7827\n",
      "[244/1762] D loss: 1.3885, G loss: 0.6397\n",
      "[324/1762] D loss: 1.3183, G loss: 0.9285\n",
      "[404/1762] D loss: 1.4381, G loss: 0.8808\n",
      "[484/1762] D loss: 1.4047, G loss: 0.7385\n",
      "[564/1762] D loss: 1.3874, G loss: 0.7458\n",
      "[644/1762] D loss: 0.0426, G loss: 3.2034\n",
      "[724/1762] D loss: 1.4091, G loss: 0.8379\n",
      "[804/1762] D loss: 1.3897, G loss: 0.6755\n",
      "[884/1762] D loss: 1.3834, G loss: 0.7332\n",
      "[964/1762] D loss: 1.4679, G loss: 0.4774\n",
      "[1044/1762] D loss: 1.4133, G loss: 0.7902\n",
      "[1124/1762] D loss: 1.4335, G loss: 0.9617\n",
      "[1204/1762] D loss: 1.3964, G loss: 0.6139\n",
      "[1284/1762] D loss: 1.4219, G loss: 0.5713\n",
      "[1364/1762] D loss: 1.4025, G loss: 0.7944\n",
      "[1444/1762] D loss: 1.3892, G loss: 0.7235\n",
      "[1524/1762] D loss: 1.3905, G loss: 0.7091\n",
      "[1604/1762] D loss: 1.3883, G loss: 0.6886\n",
      "[1684/1762] D loss: 1.3913, G loss: 0.6785\n",
      "[1762/1762] D loss: 1.4428, G loss: 0.5452\n",
      "train error: \n",
      " D loss: 2.422095, G loss: 0.168739, D accuracy: 49.1%, cell accuracy: 99.8%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 2.435651, G loss: 0.173058, D accuracy: 48.0%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4029, G loss: 0.6571\n",
      "[84/1762] D loss: 1.3932, G loss: 0.6370\n",
      "[164/1762] D loss: 1.3939, G loss: 0.8443\n",
      "[244/1762] D loss: 0.0535, G loss: 2.8995\n",
      "[324/1762] D loss: 1.3922, G loss: 0.8210\n",
      "[404/1762] D loss: 0.0842, G loss: 3.2942\n",
      "[484/1762] D loss: 1.4224, G loss: 0.8053\n",
      "[564/1762] D loss: 1.4047, G loss: 0.6325\n",
      "[644/1762] D loss: 1.4038, G loss: 0.7047\n",
      "[724/1762] D loss: 1.3942, G loss: 0.7503\n",
      "[804/1762] D loss: 0.0019, G loss: 6.5774\n",
      "[884/1762] D loss: 1.4192, G loss: 0.6651\n",
      "[964/1762] D loss: 1.4039, G loss: 0.5835\n",
      "[1044/1762] D loss: 0.0430, G loss: 3.3388\n",
      "[1124/1762] D loss: 1.3934, G loss: 0.6166\n",
      "[1204/1762] D loss: 0.0467, G loss: 3.1185\n",
      "[1284/1762] D loss: 0.1573, G loss: 2.4456\n",
      "[1364/1762] D loss: 1.4110, G loss: 0.8132\n",
      "[1444/1762] D loss: 1.4637, G loss: 0.4832\n",
      "[1524/1762] D loss: 1.1321, G loss: 1.2182\n",
      "[1604/1762] D loss: 1.3972, G loss: 0.7245\n",
      "[1684/1762] D loss: 0.0683, G loss: 2.7447\n",
      "[1762/1762] D loss: 1.3992, G loss: 0.8079\n",
      "train error: \n",
      " D loss: 1.878960, G loss: 0.282477, D accuracy: 48.6%, cell accuracy: 99.8%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.881103, G loss: 0.302460, D accuracy: 48.0%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4089, G loss: 0.7896\n",
      "[84/1762] D loss: 1.3943, G loss: 0.7197\n",
      "[164/1762] D loss: 0.0021, G loss: 6.2342\n",
      "[244/1762] D loss: 1.3965, G loss: 0.6505\n",
      "[324/1762] D loss: 1.3942, G loss: 0.6865\n",
      "[404/1762] D loss: 1.3836, G loss: 0.7588\n",
      "[484/1762] D loss: 1.3953, G loss: 0.7127\n",
      "[564/1762] D loss: 1.4990, G loss: 0.9506\n",
      "[644/1762] D loss: 1.3887, G loss: 0.7838\n",
      "[724/1762] D loss: 1.2230, G loss: 0.9166\n",
      "[804/1762] D loss: 0.0604, G loss: 2.6988\n",
      "[884/1762] D loss: 1.3955, G loss: 0.6966\n",
      "[964/1762] D loss: 1.3969, G loss: 0.6798\n",
      "[1044/1762] D loss: 0.1635, G loss: 1.9607\n",
      "[1124/1762] D loss: 0.1229, G loss: 2.2561\n",
      "[1204/1762] D loss: 1.4548, G loss: 0.8392\n",
      "[1284/1762] D loss: 0.0479, G loss: 3.2133\n",
      "[1364/1762] D loss: 0.0582, G loss: 2.8783\n",
      "[1444/1762] D loss: 1.3957, G loss: 0.8258\n",
      "[1524/1762] D loss: 0.0692, G loss: 2.6626\n",
      "[1604/1762] D loss: 1.4809, G loss: 0.7553\n",
      "[1684/1762] D loss: 0.0503, G loss: 3.7050\n",
      "[1762/1762] D loss: 1.3876, G loss: 0.6247\n",
      "train error: \n",
      " D loss: 1.604150, G loss: 0.691553, D accuracy: 50.4%, cell accuracy: 99.8%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.630857, G loss: 0.729736, D accuracy: 50.8%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4037, G loss: 0.7157\n",
      "[84/1762] D loss: 0.1581, G loss: 2.6774\n",
      "[164/1762] D loss: 1.4041, G loss: 0.7182\n",
      "[244/1762] D loss: 1.4158, G loss: 0.8357\n",
      "[324/1762] D loss: 1.4310, G loss: 0.4329\n",
      "[404/1762] D loss: 1.4122, G loss: 0.7831\n",
      "[484/1762] D loss: 1.4158, G loss: 0.6431\n",
      "[564/1762] D loss: 0.0020, G loss: 6.5063\n",
      "[644/1762] D loss: 1.4092, G loss: 0.7319\n",
      "[724/1762] D loss: 1.4465, G loss: 0.5154\n",
      "[804/1762] D loss: 0.1107, G loss: 2.7139\n",
      "[884/1762] D loss: 1.3894, G loss: 0.5935\n",
      "[964/1762] D loss: 1.3901, G loss: 0.7408\n",
      "[1044/1762] D loss: 1.3878, G loss: 0.7101\n",
      "[1124/1762] D loss: 1.3876, G loss: 0.6925\n",
      "[1204/1762] D loss: 1.3882, G loss: 0.7100\n",
      "[1284/1762] D loss: 0.0561, G loss: 3.0593\n",
      "[1364/1762] D loss: 1.4038, G loss: 0.8020\n",
      "[1444/1762] D loss: 1.4295, G loss: 0.8995\n",
      "[1524/1762] D loss: 1.3935, G loss: 0.7114\n",
      "[1604/1762] D loss: 1.3944, G loss: 0.7154\n",
      "[1684/1762] D loss: 1.3885, G loss: 0.6530\n",
      "[1762/1762] D loss: 1.3878, G loss: 0.7209\n",
      "train error: \n",
      " D loss: 1.864182, G loss: 0.307710, D accuracy: 47.8%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.888900, G loss: 0.298493, D accuracy: 46.9%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0464, G loss: 3.1366\n",
      "[84/1762] D loss: 1.3871, G loss: 0.7241\n",
      "[164/1762] D loss: 0.0468, G loss: 3.1779\n",
      "[244/1762] D loss: 0.0011, G loss: 6.9775\n",
      "[324/1762] D loss: 0.0551, G loss: 3.0715\n",
      "[404/1762] D loss: 1.3925, G loss: 0.6196\n",
      "[484/1762] D loss: 0.0309, G loss: 3.6811\n",
      "[564/1762] D loss: 0.0537, G loss: 2.8834\n",
      "[644/1762] D loss: 1.4346, G loss: 0.9111\n",
      "[724/1762] D loss: 1.3917, G loss: 0.6795\n",
      "[804/1762] D loss: 0.0445, G loss: 3.2186\n",
      "[884/1762] D loss: 0.0324, G loss: 3.5003\n",
      "[964/1762] D loss: 0.0349, G loss: 3.6556\n",
      "[1044/1762] D loss: 0.0301, G loss: 4.0171\n",
      "[1124/1762] D loss: 1.3914, G loss: 0.6747\n",
      "[1204/1762] D loss: 0.0344, G loss: 3.3499\n",
      "[1284/1762] D loss: 0.0374, G loss: 3.4980\n",
      "[1364/1762] D loss: 1.4022, G loss: 0.7760\n",
      "[1444/1762] D loss: 0.0370, G loss: 3.5061\n",
      "[1524/1762] D loss: 1.3817, G loss: 0.6684\n",
      "[1604/1762] D loss: 1.3890, G loss: 0.6123\n",
      "[1684/1762] D loss: 1.3981, G loss: 0.6899\n",
      "[1762/1762] D loss: 1.4086, G loss: 0.5620\n",
      "train error: \n",
      " D loss: 2.508442, G loss: 0.143625, D accuracy: 48.6%, cell accuracy: 99.8%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 2.516297, G loss: 0.146704, D accuracy: 47.7%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3893, G loss: 0.6422\n",
      "[84/1762] D loss: 1.4256, G loss: 0.7488\n",
      "[164/1762] D loss: 1.4360, G loss: 0.6691\n",
      "[244/1762] D loss: 1.4783, G loss: 0.4517\n",
      "[324/1762] D loss: 0.0292, G loss: 3.6948\n",
      "[404/1762] D loss: 1.3967, G loss: 0.6392\n",
      "[484/1762] D loss: 0.0451, G loss: 3.1266\n",
      "[564/1762] D loss: 1.3907, G loss: 0.6920\n",
      "[644/1762] D loss: 1.3897, G loss: 0.6880\n",
      "[724/1762] D loss: 0.0018, G loss: 6.5199\n",
      "[804/1762] D loss: 1.3894, G loss: 0.7429\n",
      "[884/1762] D loss: 1.3879, G loss: 0.6786\n",
      "[964/1762] D loss: 0.0032, G loss: 5.9918\n",
      "[1044/1762] D loss: 1.4106, G loss: 0.7953\n",
      "[1124/1762] D loss: 1.3914, G loss: 0.7401\n",
      "[1204/1762] D loss: 1.3882, G loss: 0.7348\n",
      "[1284/1762] D loss: 1.3866, G loss: 0.6978\n",
      "[1364/1762] D loss: 1.3874, G loss: 0.6324\n",
      "[1444/1762] D loss: 1.3878, G loss: 0.7288\n",
      "[1524/1762] D loss: 1.4140, G loss: 0.7049\n",
      "[1604/1762] D loss: 1.4419, G loss: 0.5009\n",
      "[1684/1762] D loss: 1.0729, G loss: 1.3897\n",
      "[1762/1762] D loss: 1.4387, G loss: 0.8971\n",
      "train error: \n",
      " D loss: 2.058097, G loss: 0.370696, D accuracy: 50.6%, cell accuracy: 99.8%, board accuracy: 90.8% \n",
      "\n",
      "test error: \n",
      " D loss: 2.123321, G loss: 0.392515, D accuracy: 50.6%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5981, G loss: 0.9466\n",
      "[84/1762] D loss: 1.3892, G loss: 0.9357\n",
      "[164/1762] D loss: 1.4748, G loss: 0.4382\n",
      "[244/1762] D loss: 1.4123, G loss: 0.8086\n",
      "[324/1762] D loss: 1.4228, G loss: 0.5568\n",
      "[404/1762] D loss: 0.0524, G loss: 3.1967\n",
      "[484/1762] D loss: 1.3568, G loss: 0.6674\n",
      "[564/1762] D loss: 1.3906, G loss: 0.7287\n",
      "[644/1762] D loss: 1.4029, G loss: 0.6762\n",
      "[724/1762] D loss: 1.3929, G loss: 0.6237\n",
      "[804/1762] D loss: 1.4183, G loss: 0.8362\n",
      "[884/1762] D loss: 0.0512, G loss: 3.0561\n",
      "[964/1762] D loss: 1.3927, G loss: 0.7292\n",
      "[1044/1762] D loss: 1.3882, G loss: 0.6844\n",
      "[1124/1762] D loss: 1.6067, G loss: 1.0366\n",
      "[1204/1762] D loss: 1.4778, G loss: 0.4598\n",
      "[1284/1762] D loss: 1.4592, G loss: 1.0195\n",
      "[1364/1762] D loss: 1.4871, G loss: 0.9901\n",
      "[1444/1762] D loss: 1.4133, G loss: 0.7239\n",
      "[1524/1762] D loss: 1.4846, G loss: 1.1141\n",
      "[1604/1762] D loss: 1.6967, G loss: 0.6647\n",
      "[1684/1762] D loss: 0.0017, G loss: 7.6931\n",
      "[1762/1762] D loss: 1.3945, G loss: 0.6900\n",
      "train error: \n",
      " D loss: 1.948349, G loss: 0.268453, D accuracy: 51.6%, cell accuracy: 99.8%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.918382, G loss: 0.278437, D accuracy: 52.2%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1502, G loss: 2.9376\n",
      "[84/1762] D loss: 1.4426, G loss: 0.5035\n",
      "[164/1762] D loss: 1.3896, G loss: 0.7588\n",
      "[244/1762] D loss: 1.4537, G loss: 0.9107\n",
      "[324/1762] D loss: 1.3982, G loss: 0.6775\n",
      "[404/1762] D loss: 1.3882, G loss: 0.6786\n",
      "[484/1762] D loss: 0.0489, G loss: 3.1869\n",
      "[564/1762] D loss: 1.3893, G loss: 0.6633\n",
      "[644/1762] D loss: 0.0038, G loss: 5.6472\n",
      "[724/1762] D loss: 1.3900, G loss: 0.6714\n",
      "[804/1762] D loss: 1.4004, G loss: 0.6463\n",
      "[884/1762] D loss: 0.0411, G loss: 3.3413\n",
      "[964/1762] D loss: 1.3929, G loss: 0.7167\n",
      "[1044/1762] D loss: 1.3938, G loss: 0.7011\n",
      "[1124/1762] D loss: 1.3901, G loss: 0.7063\n",
      "[1204/1762] D loss: 1.4143, G loss: 0.8389\n",
      "[1284/1762] D loss: 1.4113, G loss: 0.5937\n",
      "[1364/1762] D loss: 1.4069, G loss: 0.6149\n",
      "[1444/1762] D loss: 1.4753, G loss: 0.5200\n",
      "[1524/1762] D loss: 1.3907, G loss: 0.6084\n",
      "[1604/1762] D loss: 1.3929, G loss: 0.7199\n",
      "[1684/1762] D loss: 1.4685, G loss: 0.5534\n",
      "[1762/1762] D loss: 0.0019, G loss: 6.3816\n",
      "train error: \n",
      " D loss: 3.178800, G loss: 0.067692, D accuracy: 49.9%, cell accuracy: 99.8%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 3.145153, G loss: 0.078920, D accuracy: 50.0%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0060, G loss: 5.3368\n",
      "[84/1762] D loss: 1.4164, G loss: 0.5171\n",
      "[164/1762] D loss: 1.4008, G loss: 0.7844\n",
      "[244/1762] D loss: 0.0550, G loss: 2.9063\n",
      "[324/1762] D loss: 1.3893, G loss: 0.7170\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6844\n",
      "[484/1762] D loss: 1.3885, G loss: 0.6580\n",
      "[564/1762] D loss: 0.0345, G loss: 3.4076\n",
      "[644/1762] D loss: 1.3964, G loss: 0.7500\n",
      "[724/1762] D loss: 1.3995, G loss: 0.6193\n",
      "[804/1762] D loss: 1.4148, G loss: 0.7730\n",
      "[884/1762] D loss: 1.4047, G loss: 0.8955\n",
      "[964/1762] D loss: 1.3904, G loss: 0.7014\n",
      "[1044/1762] D loss: 0.0015, G loss: 6.6428\n",
      "[1124/1762] D loss: 1.4083, G loss: 0.5890\n",
      "[1204/1762] D loss: 1.3969, G loss: 0.7164\n",
      "[1284/1762] D loss: 1.3913, G loss: 0.6714\n",
      "[1364/1762] D loss: 0.0437, G loss: 3.2261\n",
      "[1444/1762] D loss: 0.0381, G loss: 3.8360\n",
      "[1524/1762] D loss: 0.0282, G loss: 3.7203\n",
      "[1604/1762] D loss: 1.3939, G loss: 0.7512\n",
      "[1684/1762] D loss: 1.3972, G loss: 0.7620\n",
      "[1762/1762] D loss: 1.3858, G loss: 0.6114\n",
      "train error: \n",
      " D loss: 1.869148, G loss: 0.394056, D accuracy: 49.9%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.914890, G loss: 0.411628, D accuracy: 50.1%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4100, G loss: 0.5486\n",
      "[84/1762] D loss: 1.4719, G loss: 0.9712\n",
      "[164/1762] D loss: 0.0352, G loss: 3.4825\n",
      "[244/1762] D loss: 1.4020, G loss: 0.7566\n",
      "[324/1762] D loss: 1.3982, G loss: 0.5945\n",
      "[404/1762] D loss: 1.3911, G loss: 0.6229\n",
      "[484/1762] D loss: 1.4238, G loss: 0.6562\n",
      "[564/1762] D loss: 0.0321, G loss: 3.5679\n",
      "[644/1762] D loss: 0.0285, G loss: 3.7716\n",
      "[724/1762] D loss: 0.0224, G loss: 3.9075\n",
      "[804/1762] D loss: 1.3932, G loss: 0.6581\n",
      "[884/1762] D loss: 1.4535, G loss: 1.0744\n",
      "[964/1762] D loss: 1.4290, G loss: 0.6720\n",
      "[1044/1762] D loss: 1.3998, G loss: 0.6599\n",
      "[1124/1762] D loss: 0.0335, G loss: 3.6400\n",
      "[1204/1762] D loss: 1.4200, G loss: 0.5869\n",
      "[1284/1762] D loss: 1.3947, G loss: 0.6532\n",
      "[1364/1762] D loss: 1.3958, G loss: 0.8020\n",
      "[1444/1762] D loss: 1.3963, G loss: 0.7586\n",
      "[1524/1762] D loss: 1.4113, G loss: 0.5732\n",
      "[1604/1762] D loss: 1.4346, G loss: 0.8389\n",
      "[1684/1762] D loss: 1.3966, G loss: 0.7803\n",
      "[1762/1762] D loss: 1.3870, G loss: 0.6933\n",
      "train error: \n",
      " D loss: 2.409287, G loss: 0.140868, D accuracy: 47.5%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 2.439284, G loss: 0.143467, D accuracy: 46.7%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3990, G loss: 0.6069\n",
      "[84/1762] D loss: 1.3968, G loss: 0.6685\n",
      "[164/1762] D loss: 1.3888, G loss: 0.6766\n",
      "[244/1762] D loss: 0.0348, G loss: 3.4371\n",
      "[324/1762] D loss: 1.3912, G loss: 0.7093\n",
      "[404/1762] D loss: 1.3910, G loss: 0.8245\n",
      "[484/1762] D loss: 0.0345, G loss: 3.5043\n",
      "[564/1762] D loss: 1.3943, G loss: 0.6334\n",
      "[644/1762] D loss: 1.4002, G loss: 0.8248\n",
      "[724/1762] D loss: 1.4159, G loss: 0.5208\n",
      "[804/1762] D loss: 0.0011, G loss: 6.7776\n",
      "[884/1762] D loss: 1.4047, G loss: 0.8117\n",
      "[964/1762] D loss: 1.5035, G loss: 0.9742\n",
      "[1044/1762] D loss: 1.4833, G loss: 0.5315\n",
      "[1124/1762] D loss: 1.4034, G loss: 0.7306\n",
      "[1204/1762] D loss: 1.3900, G loss: 0.7095\n",
      "[1284/1762] D loss: 1.3914, G loss: 0.6475\n",
      "[1364/1762] D loss: 1.3876, G loss: 0.7970\n",
      "[1444/1762] D loss: 1.4041, G loss: 0.5632\n",
      "[1524/1762] D loss: 1.3940, G loss: 0.7460\n",
      "[1604/1762] D loss: 1.4050, G loss: 0.5961\n",
      "[1684/1762] D loss: 1.3889, G loss: 0.6242\n",
      "[1762/1762] D loss: 0.0012, G loss: 6.7928\n",
      "train error: \n",
      " D loss: 3.256860, G loss: 0.051574, D accuracy: 47.4%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 3.266524, G loss: 0.053906, D accuracy: 46.6%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0305, G loss: 3.6389\n",
      "[84/1762] D loss: 0.0422, G loss: 3.2843\n",
      "[164/1762] D loss: 1.3878, G loss: 0.6650\n",
      "[244/1762] D loss: 1.3885, G loss: 0.7455\n",
      "[324/1762] D loss: 1.3926, G loss: 0.7198\n",
      "[404/1762] D loss: 0.0309, G loss: 3.6947\n",
      "[484/1762] D loss: 1.3875, G loss: 0.6701\n",
      "[564/1762] D loss: 0.0009, G loss: 7.8220\n",
      "[644/1762] D loss: 0.0600, G loss: 3.5895\n",
      "[724/1762] D loss: 1.3936, G loss: 0.6499\n",
      "[804/1762] D loss: 1.4041, G loss: 0.8300\n",
      "[884/1762] D loss: 1.4005, G loss: 0.7804\n",
      "[964/1762] D loss: 1.3888, G loss: 0.7121\n",
      "[1044/1762] D loss: 1.3957, G loss: 0.6539\n",
      "[1124/1762] D loss: 1.3877, G loss: 0.6551\n",
      "[1204/1762] D loss: 1.3868, G loss: 0.6928\n",
      "[1284/1762] D loss: 1.3891, G loss: 0.7352\n",
      "[1364/1762] D loss: 1.3912, G loss: 0.7044\n",
      "[1444/1762] D loss: 1.2905, G loss: 0.9251\n",
      "[1524/1762] D loss: 1.3919, G loss: 0.7739\n",
      "[1604/1762] D loss: 1.3930, G loss: 0.6496\n",
      "[1684/1762] D loss: 1.3988, G loss: 0.6471\n",
      "[1762/1762] D loss: 0.0007, G loss: 7.4138\n",
      "train error: \n",
      " D loss: 3.729315, G loss: 0.036775, D accuracy: 48.6%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 3.715187, G loss: 0.034619, D accuracy: 48.2%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3884, G loss: 0.6442\n",
      "[84/1762] D loss: 1.4148, G loss: 0.8656\n",
      "[164/1762] D loss: 0.0319, G loss: 3.5042\n",
      "[244/1762] D loss: 0.0294, G loss: 3.5152\n",
      "[324/1762] D loss: 1.3744, G loss: 0.6663\n",
      "[404/1762] D loss: 1.3828, G loss: 0.7035\n",
      "[484/1762] D loss: 1.4723, G loss: 0.8379\n",
      "[564/1762] D loss: 1.4117, G loss: 0.5720\n",
      "[644/1762] D loss: 1.3970, G loss: 0.6586\n",
      "[724/1762] D loss: 1.4089, G loss: 0.6621\n",
      "[804/1762] D loss: 0.0481, G loss: 4.3831\n",
      "[884/1762] D loss: 1.4685, G loss: 0.5556\n",
      "[964/1762] D loss: 1.4245, G loss: 0.7328\n",
      "[1044/1762] D loss: 1.4075, G loss: 0.5943\n",
      "[1124/1762] D loss: 0.1523, G loss: 2.8368\n",
      "[1204/1762] D loss: 1.3974, G loss: 0.4983\n",
      "[1284/1762] D loss: 1.4179, G loss: 0.8417\n",
      "[1364/1762] D loss: 0.0287, G loss: 3.5004\n",
      "[1444/1762] D loss: 1.3996, G loss: 0.7535\n",
      "[1524/1762] D loss: 1.4073, G loss: 0.8347\n",
      "[1604/1762] D loss: 1.3901, G loss: 0.6380\n",
      "[1684/1762] D loss: 0.0323, G loss: 3.5798\n",
      "[1762/1762] D loss: 0.0011, G loss: 6.9958\n",
      "train error: \n",
      " D loss: 2.772666, G loss: 0.149747, D accuracy: 50.0%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "test error: \n",
      " D loss: 2.746931, G loss: 0.177318, D accuracy: 49.8%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0151, G loss: 4.8393\n",
      "[84/1762] D loss: 1.5756, G loss: 0.3656\n",
      "[164/1762] D loss: 0.9793, G loss: 2.5104\n",
      "[244/1762] D loss: 1.4023, G loss: 0.8394\n",
      "[324/1762] D loss: 1.4191, G loss: 1.9684\n",
      "[404/1762] D loss: 1.6209, G loss: 0.8243\n",
      "[484/1762] D loss: 1.4009, G loss: 0.8889\n",
      "[564/1762] D loss: 0.0935, G loss: 2.5291\n",
      "[644/1762] D loss: 1.4360, G loss: 0.6422\n",
      "[724/1762] D loss: 1.3971, G loss: 0.6559\n",
      "[804/1762] D loss: 1.4036, G loss: 0.7693\n",
      "[884/1762] D loss: 1.4092, G loss: 0.5836\n",
      "[964/1762] D loss: 0.0671, G loss: 2.8548\n",
      "[1044/1762] D loss: 1.3944, G loss: 0.6411\n",
      "[1124/1762] D loss: 1.4046, G loss: 0.5991\n",
      "[1204/1762] D loss: 1.3984, G loss: 0.7956\n",
      "[1284/1762] D loss: 1.3983, G loss: 0.6817\n",
      "[1364/1762] D loss: 1.3970, G loss: 0.6247\n",
      "[1444/1762] D loss: 1.0125, G loss: 1.5367\n",
      "[1524/1762] D loss: 0.0556, G loss: 3.1006\n",
      "[1604/1762] D loss: 1.4031, G loss: 0.6045\n",
      "[1684/1762] D loss: 1.3973, G loss: 0.6485\n",
      "[1762/1762] D loss: 1.4182, G loss: 0.8018\n",
      "train error: \n",
      " D loss: 1.518583, G loss: 0.899692, D accuracy: 47.6%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.537456, G loss: 0.906287, D accuracy: 48.5%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4530, G loss: 0.5338\n",
      "[84/1762] D loss: 1.4226, G loss: 0.5624\n",
      "[164/1762] D loss: 0.0104, G loss: 4.9409\n",
      "[244/1762] D loss: 1.6654, G loss: 0.6382\n",
      "[324/1762] D loss: 0.0387, G loss: 3.4993\n",
      "[404/1762] D loss: 1.4450, G loss: 0.4831\n",
      "[484/1762] D loss: 0.1649, G loss: 2.1306\n",
      "[564/1762] D loss: 1.4951, G loss: 0.3928\n",
      "[644/1762] D loss: 1.4212, G loss: 0.7401\n",
      "[724/1762] D loss: 1.3953, G loss: 0.6202\n",
      "[804/1762] D loss: 1.3729, G loss: 0.7091\n",
      "[884/1762] D loss: 1.4795, G loss: 1.0211\n",
      "[964/1762] D loss: 1.3720, G loss: 0.6104\n",
      "[1044/1762] D loss: 0.0755, G loss: 2.9048\n",
      "[1124/1762] D loss: 1.3930, G loss: 0.7244\n",
      "[1204/1762] D loss: 1.4118, G loss: 0.7606\n",
      "[1284/1762] D loss: 0.0403, G loss: 4.8716\n",
      "[1364/1762] D loss: 1.5099, G loss: 1.0105\n",
      "[1444/1762] D loss: 1.3943, G loss: 0.7329\n",
      "[1524/1762] D loss: 1.4979, G loss: 0.9611\n",
      "[1604/1762] D loss: 1.4490, G loss: 0.5793\n",
      "[1684/1762] D loss: 1.4150, G loss: 0.7269\n",
      "[1762/1762] D loss: 1.3947, G loss: 0.6232\n",
      "train error: \n",
      " D loss: 1.771023, G loss: 0.437292, D accuracy: 48.0%, cell accuracy: 99.9%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.797994, G loss: 0.452429, D accuracy: 47.8%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4065, G loss: 0.6479\n",
      "[84/1762] D loss: 0.0495, G loss: 3.1534\n",
      "[164/1762] D loss: 1.3861, G loss: 0.6603\n",
      "[244/1762] D loss: 1.4415, G loss: 0.5415\n",
      "[324/1762] D loss: 1.3928, G loss: 0.6429\n",
      "[404/1762] D loss: 1.4198, G loss: 0.8892\n",
      "[484/1762] D loss: 0.0005, G loss: 8.2591\n",
      "[564/1762] D loss: 1.3981, G loss: 0.6869\n",
      "[644/1762] D loss: 1.4192, G loss: 0.6004\n",
      "[724/1762] D loss: 1.3877, G loss: 0.6989\n",
      "[804/1762] D loss: 1.3962, G loss: 0.6937\n",
      "[884/1762] D loss: 1.3876, G loss: 0.6772\n",
      "[964/1762] D loss: 1.3866, G loss: 0.6716\n",
      "[1044/1762] D loss: 0.0275, G loss: 3.7598\n",
      "[1124/1762] D loss: 1.3957, G loss: 0.7715\n",
      "[1204/1762] D loss: 0.0294, G loss: 3.5772\n",
      "[1284/1762] D loss: 1.3925, G loss: 0.6822\n",
      "[1364/1762] D loss: 0.0008, G loss: 8.1591\n",
      "[1444/1762] D loss: 0.0225, G loss: 4.0604\n",
      "[1524/1762] D loss: 0.0311, G loss: 3.8537\n",
      "[1604/1762] D loss: 0.0090, G loss: 4.9721\n",
      "[1684/1762] D loss: 1.3869, G loss: 0.6724\n",
      "[1762/1762] D loss: 1.3961, G loss: 0.7915\n",
      "train error: \n",
      " D loss: 1.914114, G loss: 0.664520, D accuracy: 49.1%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 2.001600, G loss: 0.662177, D accuracy: 49.5%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3875, G loss: 0.6541\n",
      "[84/1762] D loss: 1.3878, G loss: 0.6841\n",
      "[164/1762] D loss: 1.3975, G loss: 0.7074\n",
      "[244/1762] D loss: 1.3938, G loss: 0.6339\n",
      "[324/1762] D loss: 1.4012, G loss: 0.5808\n",
      "[404/1762] D loss: 0.0220, G loss: 4.0918\n",
      "[484/1762] D loss: 1.3887, G loss: 0.7311\n",
      "[564/1762] D loss: 1.3862, G loss: 0.7342\n",
      "[644/1762] D loss: 0.0180, G loss: 4.2176\n",
      "[724/1762] D loss: 1.4028, G loss: 0.6311\n",
      "[804/1762] D loss: 0.0364, G loss: 3.5380\n",
      "[884/1762] D loss: 0.0251, G loss: 3.8526\n",
      "[964/1762] D loss: 1.4145, G loss: 0.8343\n",
      "[1044/1762] D loss: 1.3997, G loss: 0.7913\n",
      "[1124/1762] D loss: 1.3934, G loss: 0.6443\n",
      "[1204/1762] D loss: 1.3880, G loss: 0.7346\n",
      "[1284/1762] D loss: 0.0176, G loss: 4.3742\n",
      "[1364/1762] D loss: 0.0160, G loss: 4.5617\n",
      "[1444/1762] D loss: 1.3875, G loss: 0.6962\n",
      "[1524/1762] D loss: 1.3962, G loss: 0.6997\n",
      "[1604/1762] D loss: 1.5183, G loss: 1.0241\n",
      "[1684/1762] D loss: 1.3909, G loss: 0.6278\n",
      "[1762/1762] D loss: 1.3877, G loss: 0.6802\n",
      "train error: \n",
      " D loss: 2.173570, G loss: 0.242877, D accuracy: 46.8%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 2.216407, G loss: 0.253804, D accuracy: 46.1%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3910, G loss: 0.6684\n",
      "[84/1762] D loss: 1.3869, G loss: 0.6572\n",
      "[164/1762] D loss: 0.0826, G loss: 3.8002\n",
      "[244/1762] D loss: 1.3899, G loss: 0.6799\n",
      "[324/1762] D loss: 0.0149, G loss: 4.4671\n",
      "[404/1762] D loss: 1.3861, G loss: 0.6661\n",
      "[484/1762] D loss: 0.0133, G loss: 4.7297\n",
      "[564/1762] D loss: 1.3926, G loss: 0.7308\n",
      "[644/1762] D loss: 0.0008, G loss: 8.4660\n",
      "[724/1762] D loss: 1.3881, G loss: 0.7257\n",
      "[804/1762] D loss: 1.3967, G loss: 0.7254\n",
      "[884/1762] D loss: 1.3876, G loss: 0.6900\n",
      "[964/1762] D loss: 0.0164, G loss: 4.1174\n",
      "[1044/1762] D loss: 1.3873, G loss: 0.7019\n",
      "[1124/1762] D loss: 1.4160, G loss: 0.5476\n",
      "[1204/1762] D loss: 1.3826, G loss: 0.7352\n",
      "[1284/1762] D loss: 1.3911, G loss: 0.6498\n",
      "[1364/1762] D loss: 0.0696, G loss: 3.8895\n",
      "[1444/1762] D loss: 0.0234, G loss: 3.9329\n",
      "[1524/1762] D loss: 1.3962, G loss: 0.7674\n",
      "[1604/1762] D loss: 1.3968, G loss: 0.6907\n",
      "[1684/1762] D loss: 0.0003, G loss: 9.5488\n",
      "[1762/1762] D loss: 1.3991, G loss: 0.6399\n",
      "train error: \n",
      " D loss: 2.523850, G loss: 0.744902, D accuracy: 49.4%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 2.768234, G loss: 0.738041, D accuracy: 49.7%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0132, G loss: 4.6450\n",
      "[84/1762] D loss: 0.0108, G loss: 4.6269\n",
      "[164/1762] D loss: 1.3907, G loss: 0.6828\n",
      "[244/1762] D loss: 1.3906, G loss: 0.7108\n",
      "[324/1762] D loss: 1.3985, G loss: 0.7254\n",
      "[404/1762] D loss: 1.3803, G loss: 0.7073\n",
      "[484/1762] D loss: 1.3864, G loss: 0.7118\n",
      "[564/1762] D loss: 1.3896, G loss: 0.6640\n",
      "[644/1762] D loss: 1.3909, G loss: 0.7334\n",
      "[724/1762] D loss: 0.0030, G loss: 7.9234\n",
      "[804/1762] D loss: 0.0109, G loss: 4.7496\n",
      "[884/1762] D loss: 1.4021, G loss: 0.7801\n",
      "[964/1762] D loss: 1.3802, G loss: 0.7048\n",
      "[1044/1762] D loss: 1.3866, G loss: 0.6650\n",
      "[1124/1762] D loss: 1.3886, G loss: 0.7288\n",
      "[1204/1762] D loss: 1.3915, G loss: 0.7117\n",
      "[1284/1762] D loss: 1.3871, G loss: 0.5518\n",
      "[1364/1762] D loss: 1.3983, G loss: 0.6056\n",
      "[1444/1762] D loss: 1.3932, G loss: 0.7944\n",
      "[1524/1762] D loss: 1.4005, G loss: 0.7975\n",
      "[1604/1762] D loss: 1.3935, G loss: 0.7035\n",
      "[1684/1762] D loss: 1.4020, G loss: 0.7880\n",
      "[1762/1762] D loss: 1.3861, G loss: 0.6729\n",
      "train error: \n",
      " D loss: 2.849137, G loss: 0.202754, D accuracy: 46.7%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 3.031094, G loss: 0.204947, D accuracy: 45.6%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3937, G loss: 0.7143\n",
      "[84/1762] D loss: 0.0101, G loss: 4.7239\n",
      "[164/1762] D loss: 1.3923, G loss: 0.7102\n",
      "[244/1762] D loss: 1.3889, G loss: 0.7044\n",
      "[324/1762] D loss: 1.3966, G loss: 0.6786\n",
      "[404/1762] D loss: 1.3916, G loss: 0.6600\n",
      "[484/1762] D loss: 0.0155, G loss: 4.4182\n",
      "[564/1762] D loss: 0.0005, G loss: 10.2736\n",
      "[644/1762] D loss: 1.3894, G loss: 0.7546\n",
      "[724/1762] D loss: 1.3874, G loss: 0.7057\n",
      "[804/1762] D loss: 1.3897, G loss: 0.7356\n",
      "[884/1762] D loss: 0.0441, G loss: 3.2155\n",
      "[964/1762] D loss: 1.3940, G loss: 0.6586\n",
      "[1044/1762] D loss: 1.3912, G loss: 0.7717\n",
      "[1124/1762] D loss: 1.3853, G loss: 0.7061\n",
      "[1204/1762] D loss: 0.0066, G loss: 5.5003\n",
      "[1284/1762] D loss: 1.3897, G loss: 0.7537\n",
      "[1364/1762] D loss: 1.3930, G loss: 0.6838\n",
      "[1444/1762] D loss: 0.0088, G loss: 5.3800\n",
      "[1524/1762] D loss: 0.0113, G loss: 4.7933\n",
      "[1604/1762] D loss: 1.4064, G loss: 0.7147\n",
      "[1684/1762] D loss: 0.1269, G loss: 3.3262\n",
      "[1762/1762] D loss: 1.4074, G loss: 0.7237\n",
      "train error: \n",
      " D loss: 2.879123, G loss: 0.880082, D accuracy: 49.7%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "test error: \n",
      " D loss: 3.211137, G loss: 0.861054, D accuracy: 49.3%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0188, G loss: 4.9726\n",
      "[84/1762] D loss: 1.3929, G loss: 0.6607\n",
      "[164/1762] D loss: 0.0329, G loss: 5.5965\n",
      "[244/1762] D loss: 1.3942, G loss: 0.6652\n",
      "[324/1762] D loss: 1.3865, G loss: 0.6994\n",
      "[404/1762] D loss: 0.0069, G loss: 5.2256\n",
      "[484/1762] D loss: 1.3870, G loss: 0.6750\n",
      "[564/1762] D loss: 0.0089, G loss: 5.1266\n",
      "[644/1762] D loss: 0.0097, G loss: 5.2989\n",
      "[724/1762] D loss: 1.4142, G loss: 0.6103\n",
      "[804/1762] D loss: 1.3863, G loss: 0.6921\n",
      "[884/1762] D loss: 0.0002, G loss: 14.7322\n",
      "[964/1762] D loss: 1.4825, G loss: 0.4947\n",
      "[1044/1762] D loss: 1.4811, G loss: 0.9861\n",
      "[1124/1762] D loss: 1.3941, G loss: 0.6634\n",
      "[1204/1762] D loss: 1.4101, G loss: 0.8915\n",
      "[1284/1762] D loss: 1.3891, G loss: 0.7275\n",
      "[1364/1762] D loss: 1.3916, G loss: 0.6883\n",
      "[1444/1762] D loss: 1.3872, G loss: 0.7095\n",
      "[1524/1762] D loss: 1.4055, G loss: 0.7683\n",
      "[1604/1762] D loss: 1.3892, G loss: 0.7012\n",
      "[1684/1762] D loss: 1.3910, G loss: 0.7229\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.7150\n",
      "train error: \n",
      " D loss: 3.347227, G loss: 0.119323, D accuracy: 46.5%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 3.527464, G loss: 0.133096, D accuracy: 45.6%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0006, G loss: 11.9303\n",
      "[84/1762] D loss: 1.4290, G loss: 0.5568\n",
      "[164/1762] D loss: 1.4035, G loss: 0.6148\n",
      "[244/1762] D loss: 1.3927, G loss: 0.7872\n",
      "[324/1762] D loss: 1.3925, G loss: 0.6143\n",
      "[404/1762] D loss: 0.0247, G loss: 4.1971\n",
      "[484/1762] D loss: 0.0141, G loss: 4.6204\n",
      "[564/1762] D loss: 1.3953, G loss: 0.7693\n",
      "[644/1762] D loss: 1.3890, G loss: 0.6958\n",
      "[724/1762] D loss: 1.3883, G loss: 0.7247\n",
      "[804/1762] D loss: 1.3896, G loss: 0.7165\n",
      "[884/1762] D loss: 1.3957, G loss: 0.6560\n",
      "[964/1762] D loss: 0.0083, G loss: 5.1254\n",
      "[1044/1762] D loss: 1.3912, G loss: 0.7091\n",
      "[1124/1762] D loss: 1.3961, G loss: 0.6428\n",
      "[1204/1762] D loss: 1.3842, G loss: 0.6718\n",
      "[1284/1762] D loss: 1.3900, G loss: 0.6575\n",
      "[1364/1762] D loss: 1.3907, G loss: 0.7047\n",
      "[1444/1762] D loss: 1.3646, G loss: 0.6698\n",
      "[1524/1762] D loss: 1.3940, G loss: 0.5899\n",
      "[1604/1762] D loss: 1.4262, G loss: 0.6202\n",
      "[1684/1762] D loss: 1.4118, G loss: 0.6690\n",
      "[1762/1762] D loss: 1.4186, G loss: 0.9344\n",
      "train error: \n",
      " D loss: 2.689805, G loss: 0.649932, D accuracy: 47.8%, cell accuracy: 99.9%, board accuracy: 92.8% \n",
      "\n",
      "test error: \n",
      " D loss: 2.968289, G loss: 0.636604, D accuracy: 47.0%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4445, G loss: 0.8486\n",
      "[84/1762] D loss: 1.4247, G loss: 0.5253\n",
      "[164/1762] D loss: 1.3948, G loss: 0.7946\n",
      "[244/1762] D loss: 1.4128, G loss: 0.8661\n",
      "[324/1762] D loss: 1.4495, G loss: 0.4265\n",
      "[404/1762] D loss: 1.3953, G loss: 0.6469\n",
      "[484/1762] D loss: 0.0097, G loss: 4.6535\n",
      "[564/1762] D loss: 0.0186, G loss: 4.3136\n",
      "[644/1762] D loss: 0.0209, G loss: 4.5931\n",
      "[724/1762] D loss: 1.3966, G loss: 0.7324\n",
      "[804/1762] D loss: 1.3900, G loss: 0.6794\n",
      "[884/1762] D loss: 1.4024, G loss: 0.6636\n",
      "[964/1762] D loss: 0.0137, G loss: 4.8322\n",
      "[1044/1762] D loss: 1.3869, G loss: 0.6684\n",
      "[1124/1762] D loss: 1.3900, G loss: 0.7106\n",
      "[1204/1762] D loss: 1.3876, G loss: 0.6898\n",
      "[1284/1762] D loss: 1.3996, G loss: 0.7415\n",
      "[1364/1762] D loss: 1.3898, G loss: 0.6527\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6656\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.6948\n",
      "[1604/1762] D loss: 1.3889, G loss: 0.7839\n",
      "[1684/1762] D loss: 1.4021, G loss: 0.5775\n",
      "[1762/1762] D loss: 1.4107, G loss: 0.5596\n",
      "train error: \n",
      " D loss: 3.142063, G loss: 0.463478, D accuracy: 47.9%, cell accuracy: 99.8%, board accuracy: 91.0% \n",
      "\n",
      "test error: \n",
      " D loss: 3.509038, G loss: 0.479300, D accuracy: 46.9%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4361, G loss: 0.5222\n",
      "[84/1762] D loss: 1.3942, G loss: 0.6878\n",
      "[164/1762] D loss: 1.3948, G loss: 0.6543\n",
      "[244/1762] D loss: 0.0077, G loss: 6.1531\n",
      "[324/1762] D loss: 1.4439, G loss: 0.9171\n",
      "[404/1762] D loss: 1.4114, G loss: 0.5371\n",
      "[484/1762] D loss: 0.0109, G loss: 5.1531\n",
      "[564/1762] D loss: 0.0076, G loss: 5.3184\n",
      "[644/1762] D loss: 1.3901, G loss: 0.6174\n",
      "[724/1762] D loss: 1.3890, G loss: 0.7070\n",
      "[804/1762] D loss: 0.0054, G loss: 8.5447\n",
      "[884/1762] D loss: 1.3901, G loss: 0.7213\n",
      "[964/1762] D loss: 1.5128, G loss: 0.3775\n",
      "[1044/1762] D loss: 1.4159, G loss: 0.6123\n",
      "[1124/1762] D loss: 1.3894, G loss: 0.7052\n",
      "[1204/1762] D loss: 1.3886, G loss: 0.7351\n",
      "[1284/1762] D loss: 1.3801, G loss: 0.7940\n",
      "[1364/1762] D loss: 1.3892, G loss: 0.7029\n",
      "[1444/1762] D loss: 0.0109, G loss: 5.0811\n",
      "[1524/1762] D loss: 1.3964, G loss: 0.7590\n",
      "[1604/1762] D loss: 1.4035, G loss: 0.6941\n",
      "[1684/1762] D loss: 1.3996, G loss: 0.5597\n",
      "[1762/1762] D loss: 1.3942, G loss: 0.6814\n",
      "train error: \n",
      " D loss: 3.094426, G loss: 0.346957, D accuracy: 46.8%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 3.432144, G loss: 0.335206, D accuracy: 45.5%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3902, G loss: 0.7691\n",
      "[84/1762] D loss: 1.3988, G loss: 0.7884\n",
      "[164/1762] D loss: 1.3866, G loss: 0.6698\n",
      "[244/1762] D loss: 1.3844, G loss: 0.7095\n",
      "[324/1762] D loss: 0.0235, G loss: 6.1423\n",
      "[404/1762] D loss: 1.3963, G loss: 0.8350\n",
      "[484/1762] D loss: 1.3879, G loss: 0.6440\n",
      "[564/1762] D loss: 1.4001, G loss: 0.6480\n",
      "[644/1762] D loss: 1.3873, G loss: 0.8098\n",
      "[724/1762] D loss: 1.4170, G loss: 0.6039\n",
      "[804/1762] D loss: 0.2086, G loss: 2.1159\n",
      "[884/1762] D loss: 1.4125, G loss: 0.7515\n",
      "[964/1762] D loss: 0.0350, G loss: 3.9418\n",
      "[1044/1762] D loss: 1.3950, G loss: 0.6735\n",
      "[1124/1762] D loss: 1.3908, G loss: 0.7653\n",
      "[1204/1762] D loss: 1.3891, G loss: 0.7185\n",
      "[1284/1762] D loss: 1.4004, G loss: 0.5526\n",
      "[1364/1762] D loss: 0.0099, G loss: 5.1529\n",
      "[1444/1762] D loss: 1.4168, G loss: 0.5948\n",
      "[1524/1762] D loss: 1.6974, G loss: 0.8570\n",
      "[1604/1762] D loss: 1.0384, G loss: 2.3745\n",
      "[1684/1762] D loss: 0.0115, G loss: 10.7093\n",
      "[1762/1762] D loss: 0.5176, G loss: 6.8000\n",
      "train error: \n",
      " D loss: 0.520118, G loss: 11.006404, D accuracy: 87.0%, cell accuracy: 95.4%, board accuracy: 1.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.528524, G loss: 11.015910, D accuracy: 88.0%, cell accuracy: 95.4%, board accuracy: 1.6% \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0131, G loss: 10.2286\n",
      "[84/1762] D loss: 1.6303, G loss: 1.4196\n",
      "[164/1762] D loss: 1.5218, G loss: 0.8387\n",
      "[244/1762] D loss: 1.5784, G loss: 1.1076\n",
      "[324/1762] D loss: 1.4085, G loss: 0.6502\n",
      "[404/1762] D loss: 1.4341, G loss: 0.7036\n",
      "[484/1762] D loss: 1.2473, G loss: 0.7902\n",
      "[564/1762] D loss: 1.3897, G loss: 0.6936\n",
      "[644/1762] D loss: 1.3977, G loss: 0.7115\n",
      "[724/1762] D loss: 1.0762, G loss: 0.8146\n",
      "[804/1762] D loss: 1.3885, G loss: 0.6829\n",
      "[884/1762] D loss: 1.3918, G loss: 0.6807\n",
      "[964/1762] D loss: 1.3957, G loss: 0.7103\n",
      "[1044/1762] D loss: 0.8384, G loss: 1.0960\n",
      "[1124/1762] D loss: 1.4074, G loss: 0.8336\n",
      "[1204/1762] D loss: 1.3929, G loss: 0.7242\n",
      "[1284/1762] D loss: 1.4843, G loss: 0.9057\n",
      "[1364/1762] D loss: 1.4002, G loss: 0.6788\n",
      "[1444/1762] D loss: 0.4165, G loss: 1.9192\n",
      "[1524/1762] D loss: 1.3963, G loss: 0.7773\n",
      "[1604/1762] D loss: 1.3883, G loss: 0.7289\n",
      "[1684/1762] D loss: 1.4111, G loss: 0.5570\n",
      "[1762/1762] D loss: 1.4197, G loss: 0.8468\n",
      "train error: \n",
      " D loss: 1.383967, G loss: 0.700119, D accuracy: 51.7%, cell accuracy: 99.8%, board accuracy: 91.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.371971, G loss: 0.708775, D accuracy: 52.4%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3924, G loss: 0.7140\n",
      "[84/1762] D loss: 1.3954, G loss: 0.5648\n",
      "[164/1762] D loss: 1.4105, G loss: 0.5645\n",
      "[244/1762] D loss: 1.4324, G loss: 0.5941\n",
      "[324/1762] D loss: 1.3887, G loss: 0.6636\n",
      "[404/1762] D loss: 1.5593, G loss: 0.3793\n",
      "[484/1762] D loss: 1.3985, G loss: 0.6307\n",
      "[564/1762] D loss: 1.3963, G loss: 0.9055\n",
      "[644/1762] D loss: 0.0630, G loss: 2.9954\n",
      "[724/1762] D loss: 1.3880, G loss: 0.6857\n",
      "[804/1762] D loss: 1.3972, G loss: 0.6709\n",
      "[884/1762] D loss: 1.3956, G loss: 0.5795\n",
      "[964/1762] D loss: 1.2629, G loss: 1.0296\n",
      "[1044/1762] D loss: 1.4021, G loss: 0.7647\n",
      "[1124/1762] D loss: 1.4046, G loss: 0.6286\n",
      "[1204/1762] D loss: 0.3111, G loss: 1.4721\n",
      "[1284/1762] D loss: 1.4698, G loss: 0.6934\n",
      "[1364/1762] D loss: 2.0172, G loss: 0.5605\n",
      "[1444/1762] D loss: 1.5073, G loss: 0.4648\n",
      "[1524/1762] D loss: 1.4936, G loss: 0.5468\n",
      "[1604/1762] D loss: 1.0214, G loss: 1.0694\n",
      "[1684/1762] D loss: 0.4202, G loss: 1.6380\n",
      "[1762/1762] D loss: 0.2732, G loss: 2.1435\n",
      "train error: \n",
      " D loss: 1.342339, G loss: 0.685187, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.329677, G loss: 0.680977, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8907, G loss: 1.1677\n",
      "[84/1762] D loss: 1.3936, G loss: 0.7424\n",
      "[164/1762] D loss: 1.3865, G loss: 0.6739\n",
      "[244/1762] D loss: 1.3906, G loss: 0.6259\n",
      "[324/1762] D loss: 1.3953, G loss: 0.7546\n",
      "[404/1762] D loss: 1.3384, G loss: 0.7425\n",
      "[484/1762] D loss: 1.4053, G loss: 0.8747\n",
      "[564/1762] D loss: 1.3915, G loss: 0.7280\n",
      "[644/1762] D loss: 1.3974, G loss: 0.7542\n",
      "[724/1762] D loss: 1.4107, G loss: 0.7832\n",
      "[804/1762] D loss: 1.4028, G loss: 0.7975\n",
      "[884/1762] D loss: 1.7124, G loss: 1.6484\n",
      "[964/1762] D loss: 1.1355, G loss: 0.8230\n",
      "[1044/1762] D loss: 2.2738, G loss: 1.0220\n",
      "[1124/1762] D loss: 1.2845, G loss: 0.9492\n",
      "[1204/1762] D loss: 1.4071, G loss: 0.7308\n",
      "[1284/1762] D loss: 1.3943, G loss: 0.7661\n",
      "[1364/1762] D loss: 1.3880, G loss: 0.8497\n",
      "[1444/1762] D loss: 1.4089, G loss: 0.9160\n",
      "[1524/1762] D loss: 1.2209, G loss: 1.1284\n",
      "[1604/1762] D loss: 0.6818, G loss: 1.2398\n",
      "[1684/1762] D loss: 1.7536, G loss: 1.4851\n",
      "[1762/1762] D loss: 2.5750, G loss: 0.1498\n",
      "train error: \n",
      " D loss: 1.469671, G loss: 0.901965, D accuracy: 50.5%, cell accuracy: 99.8%, board accuracy: 85.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.471757, G loss: 0.910101, D accuracy: 50.5%, cell accuracy: 99.7%, board accuracy: 83.2% \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.9542, G loss: 1.6336\n",
      "[84/1762] D loss: 2.1935, G loss: 0.4378\n",
      "[164/1762] D loss: 1.4160, G loss: 0.5728\n",
      "[244/1762] D loss: 1.3002, G loss: 0.8449\n",
      "[324/1762] D loss: 1.4073, G loss: 0.6357\n",
      "[404/1762] D loss: 1.4704, G loss: 0.6172\n",
      "[484/1762] D loss: 1.4306, G loss: 0.6676\n",
      "[564/1762] D loss: 1.4347, G loss: 0.5661\n",
      "[644/1762] D loss: 1.0162, G loss: 1.0694\n",
      "[724/1762] D loss: 1.3872, G loss: 0.6468\n",
      "[804/1762] D loss: 1.3929, G loss: 0.6281\n",
      "[884/1762] D loss: 1.3538, G loss: 0.7258\n",
      "[964/1762] D loss: 1.3911, G loss: 0.7294\n",
      "[1044/1762] D loss: 1.3908, G loss: 0.6465\n",
      "[1124/1762] D loss: 1.3840, G loss: 0.6441\n",
      "[1204/1762] D loss: 1.3045, G loss: 0.7625\n",
      "[1284/1762] D loss: 1.3902, G loss: 0.6245\n",
      "[1364/1762] D loss: 1.3927, G loss: 0.6824\n",
      "[1444/1762] D loss: 1.3427, G loss: 1.0341\n",
      "[1524/1762] D loss: 1.4032, G loss: 0.8103\n",
      "[1604/1762] D loss: 1.3994, G loss: 0.7256\n",
      "[1684/1762] D loss: 1.2792, G loss: 0.7141\n",
      "[1762/1762] D loss: 1.4080, G loss: 0.5557\n",
      "train error: \n",
      " D loss: 1.341642, G loss: 0.857542, D accuracy: 54.2%, cell accuracy: 99.7%, board accuracy: 85.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.334762, G loss: 0.886026, D accuracy: 54.3%, cell accuracy: 99.7%, board accuracy: 82.0% \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3947, G loss: 0.6092\n",
      "[84/1762] D loss: 1.2140, G loss: 0.9060\n",
      "[164/1762] D loss: 1.2173, G loss: 0.8537\n",
      "[244/1762] D loss: 1.3850, G loss: 0.6795\n",
      "[324/1762] D loss: 1.3935, G loss: 0.7256\n",
      "[404/1762] D loss: 1.3864, G loss: 0.7045\n",
      "[484/1762] D loss: 1.3882, G loss: 0.6991\n",
      "[564/1762] D loss: 1.4024, G loss: 0.5931\n",
      "[644/1762] D loss: 1.3920, G loss: 0.7205\n",
      "[724/1762] D loss: 1.3880, G loss: 0.6639\n",
      "[804/1762] D loss: 1.3930, G loss: 0.7561\n",
      "[884/1762] D loss: 1.3897, G loss: 0.6425\n",
      "[964/1762] D loss: 1.3892, G loss: 0.7522\n",
      "[1044/1762] D loss: 1.2462, G loss: 0.8401\n",
      "[1124/1762] D loss: 1.3866, G loss: 0.6995\n",
      "[1204/1762] D loss: 1.3879, G loss: 0.6597\n",
      "[1284/1762] D loss: 1.4176, G loss: 0.5702\n",
      "[1364/1762] D loss: 1.3889, G loss: 0.6773\n",
      "[1444/1762] D loss: 1.3898, G loss: 0.6738\n",
      "[1524/1762] D loss: 1.5681, G loss: 0.6587\n",
      "[1604/1762] D loss: 0.9939, G loss: 1.0903\n",
      "[1684/1762] D loss: 1.1113, G loss: 2.1463\n",
      "[1762/1762] D loss: 1.3430, G loss: 0.7491\n",
      "train error: \n",
      " D loss: 1.347169, G loss: 0.737102, D accuracy: 52.5%, cell accuracy: 99.9%, board accuracy: 91.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.337889, G loss: 0.751257, D accuracy: 53.1%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3889, G loss: 0.6725\n",
      "[84/1762] D loss: 1.3906, G loss: 0.7170\n",
      "[164/1762] D loss: 0.9688, G loss: 1.0306\n",
      "[244/1762] D loss: 1.1951, G loss: 1.1286\n",
      "[324/1762] D loss: 1.1017, G loss: 0.7644\n",
      "[404/1762] D loss: 1.3870, G loss: 0.6740\n",
      "[484/1762] D loss: 1.0226, G loss: 1.0313\n",
      "[564/1762] D loss: 1.3976, G loss: 0.8026\n",
      "[644/1762] D loss: 1.3970, G loss: 0.5927\n",
      "[724/1762] D loss: 1.3939, G loss: 0.6297\n",
      "[804/1762] D loss: 1.1427, G loss: 1.0623\n",
      "[884/1762] D loss: 1.0208, G loss: 1.1057\n",
      "[964/1762] D loss: 1.4744, G loss: 0.6434\n",
      "[1044/1762] D loss: 1.3879, G loss: 0.6387\n",
      "[1124/1762] D loss: 1.4030, G loss: 0.8012\n",
      "[1204/1762] D loss: 1.3956, G loss: 0.6176\n",
      "[1284/1762] D loss: 1.3974, G loss: 0.6308\n",
      "[1364/1762] D loss: 1.4396, G loss: 0.6172\n",
      "[1444/1762] D loss: 1.3899, G loss: 0.7287\n",
      "[1524/1762] D loss: 1.3880, G loss: 0.6496\n",
      "[1604/1762] D loss: 1.3898, G loss: 0.7248\n",
      "[1684/1762] D loss: 1.4291, G loss: 0.5425\n",
      "[1762/1762] D loss: 1.5486, G loss: 0.4918\n",
      "train error: \n",
      " D loss: 1.359637, G loss: 0.631098, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.350743, G loss: 0.653324, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5375, G loss: 0.8508\n",
      "[84/1762] D loss: 1.3296, G loss: 0.6972\n",
      "[164/1762] D loss: 1.4326, G loss: 0.7916\n",
      "[244/1762] D loss: 1.3859, G loss: 0.7130\n",
      "[324/1762] D loss: 1.3874, G loss: 0.6695\n",
      "[404/1762] D loss: 1.7096, G loss: 0.5941\n",
      "[484/1762] D loss: 1.3920, G loss: 0.7911\n",
      "[564/1762] D loss: 1.3946, G loss: 0.6428\n",
      "[644/1762] D loss: 1.3357, G loss: 0.9717\n",
      "[724/1762] D loss: 1.3059, G loss: 1.2011\n",
      "[804/1762] D loss: 1.3895, G loss: 0.6541\n",
      "[884/1762] D loss: 1.3607, G loss: 0.6731\n",
      "[964/1762] D loss: 1.4081, G loss: 0.5868\n",
      "[1044/1762] D loss: 1.3894, G loss: 0.7421\n",
      "[1124/1762] D loss: 1.3976, G loss: 0.5837\n",
      "[1204/1762] D loss: 1.4013, G loss: 0.8015\n",
      "[1284/1762] D loss: 1.3890, G loss: 0.7133\n",
      "[1364/1762] D loss: 1.4972, G loss: 0.8933\n",
      "[1444/1762] D loss: 1.3886, G loss: 0.6648\n",
      "[1524/1762] D loss: 1.3896, G loss: 0.6592\n",
      "[1604/1762] D loss: 1.3923, G loss: 0.6273\n",
      "[1684/1762] D loss: 1.3481, G loss: 0.8572\n",
      "[1762/1762] D loss: 1.3908, G loss: 0.7348\n",
      "train error: \n",
      " D loss: 1.359765, G loss: 0.768131, D accuracy: 52.7%, cell accuracy: 99.9%, board accuracy: 90.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.350884, G loss: 0.786715, D accuracy: 52.8%, cell accuracy: 99.9%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3872, G loss: 0.6758\n",
      "[84/1762] D loss: 1.3871, G loss: 0.6687\n",
      "[164/1762] D loss: 1.4053, G loss: 0.5894\n",
      "[244/1762] D loss: 1.3970, G loss: 0.7388\n",
      "[324/1762] D loss: 1.3183, G loss: 0.7297\n",
      "[404/1762] D loss: 1.4103, G loss: 0.5869\n",
      "[484/1762] D loss: 1.4018, G loss: 0.8239\n",
      "[564/1762] D loss: 1.1090, G loss: 0.7592\n",
      "[644/1762] D loss: 1.3916, G loss: 0.6676\n",
      "[724/1762] D loss: 1.4006, G loss: 0.5809\n",
      "[804/1762] D loss: 1.4024, G loss: 0.6237\n",
      "[884/1762] D loss: 1.3879, G loss: 0.7539\n",
      "[964/1762] D loss: 1.3767, G loss: 0.7093\n",
      "[1044/1762] D loss: 1.1988, G loss: 1.1128\n",
      "[1124/1762] D loss: 1.3966, G loss: 0.6485\n",
      "[1204/1762] D loss: 1.3905, G loss: 0.7013\n",
      "[1284/1762] D loss: 1.3889, G loss: 0.7051\n",
      "[1364/1762] D loss: 1.3968, G loss: 0.6441\n",
      "[1444/1762] D loss: 1.3874, G loss: 0.6984\n",
      "[1524/1762] D loss: 1.3927, G loss: 0.7788\n",
      "[1604/1762] D loss: 1.3987, G loss: 0.7754\n",
      "[1684/1762] D loss: 1.4412, G loss: 0.9178\n",
      "[1762/1762] D loss: 0.8643, G loss: 1.0429\n",
      "train error: \n",
      " D loss: 1.366134, G loss: 0.807762, D accuracy: 52.4%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.357437, G loss: 0.819288, D accuracy: 52.6%, cell accuracy: 99.9%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3082, G loss: 0.9203\n",
      "[84/1762] D loss: 1.3946, G loss: 0.6235\n",
      "[164/1762] D loss: 1.1454, G loss: 0.8840\n",
      "[244/1762] D loss: 1.4152, G loss: 0.8680\n",
      "[324/1762] D loss: 1.3885, G loss: 0.7148\n",
      "[404/1762] D loss: 1.3908, G loss: 0.6430\n",
      "[484/1762] D loss: 1.3746, G loss: 0.8281\n",
      "[564/1762] D loss: 1.3890, G loss: 0.6550\n",
      "[644/1762] D loss: 1.4998, G loss: 0.9832\n",
      "[724/1762] D loss: 1.0336, G loss: 1.1271\n",
      "[804/1762] D loss: 1.3956, G loss: 0.7722\n",
      "[884/1762] D loss: 1.3889, G loss: 0.6996\n",
      "[964/1762] D loss: 1.3951, G loss: 0.6078\n",
      "[1044/1762] D loss: 1.3977, G loss: 0.7601\n",
      "[1124/1762] D loss: 1.3899, G loss: 0.6482\n",
      "[1204/1762] D loss: 1.3368, G loss: 1.0119\n",
      "[1284/1762] D loss: 1.3956, G loss: 0.6666\n",
      "[1364/1762] D loss: 1.4768, G loss: 0.4659\n",
      "[1444/1762] D loss: 0.8643, G loss: 0.9074\n",
      "[1524/1762] D loss: 1.4139, G loss: 0.7555\n",
      "[1604/1762] D loss: 1.8300, G loss: 0.6508\n",
      "[1684/1762] D loss: 1.3881, G loss: 0.6547\n",
      "[1762/1762] D loss: 0.9320, G loss: 0.6774\n",
      "train error: \n",
      " D loss: 1.432736, G loss: 0.498164, D accuracy: 52.1%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.428593, G loss: 0.510949, D accuracy: 52.8%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4867, G loss: 0.7009\n",
      "[84/1762] D loss: 1.3970, G loss: 0.7765\n",
      "[164/1762] D loss: 1.3985, G loss: 0.6138\n",
      "[244/1762] D loss: 0.9894, G loss: 0.9121\n",
      "[324/1762] D loss: 1.3962, G loss: 0.6224\n",
      "[404/1762] D loss: 0.7231, G loss: 1.2592\n",
      "[484/1762] D loss: 0.4996, G loss: 1.3343\n",
      "[564/1762] D loss: 1.4034, G loss: 0.7979\n",
      "[644/1762] D loss: 1.3983, G loss: 0.5771\n",
      "[724/1762] D loss: 0.5405, G loss: 1.5808\n",
      "[804/1762] D loss: 1.3962, G loss: 0.5765\n",
      "[884/1762] D loss: 1.4398, G loss: 0.9089\n",
      "[964/1762] D loss: 1.4002, G loss: 0.6135\n",
      "[1044/1762] D loss: 0.2932, G loss: 1.8052\n",
      "[1124/1762] D loss: 1.4021, G loss: 0.7509\n",
      "[1204/1762] D loss: 1.3960, G loss: 0.7888\n",
      "[1284/1762] D loss: 1.4826, G loss: 0.4745\n",
      "[1364/1762] D loss: 0.2061, G loss: 1.9960\n",
      "[1444/1762] D loss: 1.5050, G loss: 0.9296\n",
      "[1524/1762] D loss: 1.3866, G loss: 0.6131\n",
      "[1604/1762] D loss: 0.1908, G loss: 2.0375\n",
      "[1684/1762] D loss: 0.3432, G loss: 1.4968\n",
      "[1762/1762] D loss: 0.6595, G loss: 4.3080\n",
      "train error: \n",
      " D loss: 1.206400, G loss: 1.121122, D accuracy: 63.4%, cell accuracy: 99.6%, board accuracy: 65.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.211579, G loss: 1.077593, D accuracy: 63.5%, cell accuracy: 99.6%, board accuracy: 67.5% \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1234, G loss: 2.1929\n",
      "[84/1762] D loss: 1.5731, G loss: 0.9885\n",
      "[164/1762] D loss: 1.2665, G loss: 0.8335\n",
      "[244/1762] D loss: 1.4014, G loss: 0.9131\n",
      "[324/1762] D loss: 1.3925, G loss: 0.6474\n",
      "[404/1762] D loss: 1.4074, G loss: 0.7117\n",
      "[484/1762] D loss: 1.4030, G loss: 0.9849\n",
      "[564/1762] D loss: 0.2932, G loss: 1.6948\n",
      "[644/1762] D loss: 1.4320, G loss: 0.8701\n",
      "[724/1762] D loss: 0.2049, G loss: 1.7577\n",
      "[804/1762] D loss: 1.4020, G loss: 0.6818\n",
      "[884/1762] D loss: 1.3950, G loss: 0.7012\n",
      "[964/1762] D loss: 1.3969, G loss: 0.6689\n",
      "[1044/1762] D loss: 1.0711, G loss: 1.2677\n",
      "[1124/1762] D loss: 1.4662, G loss: 1.0253\n",
      "[1204/1762] D loss: 1.3897, G loss: 0.6078\n",
      "[1284/1762] D loss: 1.4013, G loss: 0.6614\n",
      "[1364/1762] D loss: 1.3892, G loss: 0.6790\n",
      "[1444/1762] D loss: 0.1533, G loss: 2.2286\n",
      "[1524/1762] D loss: 1.3909, G loss: 0.6761\n",
      "[1604/1762] D loss: 1.4801, G loss: 0.9169\n",
      "[1684/1762] D loss: 0.1671, G loss: 2.8241\n",
      "[1762/1762] D loss: 1.4013, G loss: 0.8246\n",
      "train error: \n",
      " D loss: 1.391564, G loss: 0.677065, D accuracy: 52.5%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.373914, G loss: 0.694516, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4067, G loss: 0.8041\n",
      "[84/1762] D loss: 1.3938, G loss: 0.7175\n",
      "[164/1762] D loss: 1.6138, G loss: 0.3936\n",
      "[244/1762] D loss: 1.4041, G loss: 0.8194\n",
      "[324/1762] D loss: 0.1357, G loss: 2.1607\n",
      "[404/1762] D loss: 1.3938, G loss: 0.5801\n",
      "[484/1762] D loss: 1.3894, G loss: 0.6805\n",
      "[564/1762] D loss: 1.4105, G loss: 0.5198\n",
      "[644/1762] D loss: 1.3931, G loss: 0.7816\n",
      "[724/1762] D loss: 1.4533, G loss: 0.8681\n",
      "[804/1762] D loss: 1.4115, G loss: 0.7975\n",
      "[884/1762] D loss: 0.0688, G loss: 2.9552\n",
      "[964/1762] D loss: 1.4027, G loss: 0.7638\n",
      "[1044/1762] D loss: 1.4171, G loss: 0.8198\n",
      "[1124/1762] D loss: 1.4264, G loss: 0.6046\n",
      "[1204/1762] D loss: 1.5056, G loss: 1.0366\n",
      "[1284/1762] D loss: 1.5372, G loss: 0.7876\n",
      "[1364/1762] D loss: 0.1045, G loss: 2.5907\n",
      "[1444/1762] D loss: 1.3938, G loss: 0.7607\n",
      "[1524/1762] D loss: 0.0645, G loss: 3.0072\n",
      "[1604/1762] D loss: 0.0432, G loss: 3.8474\n",
      "[1684/1762] D loss: 1.4146, G loss: 0.8262\n",
      "[1762/1762] D loss: 1.4500, G loss: 0.7964\n",
      "train error: \n",
      " D loss: 1.695634, G loss: 0.553739, D accuracy: 50.1%, cell accuracy: 99.9%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.744735, G loss: 0.583573, D accuracy: 50.1%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3953, G loss: 0.5589\n",
      "[84/1762] D loss: 1.4954, G loss: 0.5010\n",
      "[164/1762] D loss: 1.4272, G loss: 0.8646\n",
      "[244/1762] D loss: 1.5311, G loss: 0.4102\n",
      "[324/1762] D loss: 0.0080, G loss: 5.5588\n",
      "[404/1762] D loss: 0.1206, G loss: 2.4633\n",
      "[484/1762] D loss: 1.4054, G loss: 0.8307\n",
      "[564/1762] D loss: 1.3954, G loss: 0.6996\n",
      "[644/1762] D loss: 1.4024, G loss: 0.6289\n",
      "[724/1762] D loss: 1.3889, G loss: 0.6916\n",
      "[804/1762] D loss: 1.4263, G loss: 0.9000\n",
      "[884/1762] D loss: 1.3932, G loss: 0.7161\n",
      "[964/1762] D loss: 1.4168, G loss: 0.7448\n",
      "[1044/1762] D loss: 1.4032, G loss: 0.6270\n",
      "[1124/1762] D loss: 1.3881, G loss: 0.6740\n",
      "[1204/1762] D loss: 1.4065, G loss: 0.8105\n",
      "[1284/1762] D loss: 0.1028, G loss: 2.4502\n",
      "[1364/1762] D loss: 0.0711, G loss: 2.9451\n",
      "[1444/1762] D loss: 1.5993, G loss: 1.0182\n",
      "[1524/1762] D loss: 1.4288, G loss: 0.5817\n",
      "[1604/1762] D loss: 0.0686, G loss: 2.7364\n",
      "[1684/1762] D loss: 1.3894, G loss: 0.7217\n",
      "[1762/1762] D loss: 1.4092, G loss: 0.8324\n",
      "train error: \n",
      " D loss: 1.823545, G loss: 0.277844, D accuracy: 48.7%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.812467, G loss: 0.311136, D accuracy: 48.0%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0040, G loss: 7.6628\n",
      "[84/1762] D loss: 0.0900, G loss: 2.6342\n",
      "[164/1762] D loss: 0.0802, G loss: 2.5382\n",
      "[244/1762] D loss: 1.3906, G loss: 0.7186\n",
      "[324/1762] D loss: 1.4588, G loss: 0.8669\n",
      "[404/1762] D loss: 1.4084, G loss: 0.6188\n",
      "[484/1762] D loss: 1.3934, G loss: 0.8069\n",
      "[564/1762] D loss: 1.4006, G loss: 0.8037\n",
      "[644/1762] D loss: 0.0982, G loss: 2.7832\n",
      "[724/1762] D loss: 0.0948, G loss: 2.3742\n",
      "[804/1762] D loss: 1.3911, G loss: 0.6548\n",
      "[884/1762] D loss: 1.4391, G loss: 0.8703\n",
      "[964/1762] D loss: 0.7347, G loss: 4.7323\n",
      "[1044/1762] D loss: 1.4098, G loss: 0.4655\n",
      "[1124/1762] D loss: 1.3958, G loss: 0.7322\n",
      "[1204/1762] D loss: 1.3905, G loss: 0.6441\n",
      "[1284/1762] D loss: 0.0011, G loss: 7.8666\n",
      "[1364/1762] D loss: 1.3866, G loss: 0.6724\n",
      "[1444/1762] D loss: 1.4142, G loss: 0.8225\n",
      "[1524/1762] D loss: 1.4099, G loss: 0.5678\n",
      "[1604/1762] D loss: 0.0652, G loss: 2.9067\n",
      "[1684/1762] D loss: 0.0392, G loss: 3.4875\n",
      "[1762/1762] D loss: 1.4615, G loss: 0.8581\n",
      "train error: \n",
      " D loss: 1.995042, G loss: 0.561851, D accuracy: 50.4%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 2.130607, G loss: 0.576743, D accuracy: 50.2%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3906, G loss: 0.6175\n",
      "[84/1762] D loss: 1.5506, G loss: 0.8335\n",
      "[164/1762] D loss: 0.1096, G loss: 2.4316\n",
      "[244/1762] D loss: 1.3975, G loss: 0.6636\n",
      "[324/1762] D loss: 1.4324, G loss: 0.8551\n",
      "[404/1762] D loss: 1.4158, G loss: 0.6148\n",
      "[484/1762] D loss: 1.4491, G loss: 0.9699\n",
      "[564/1762] D loss: 1.3976, G loss: 0.6116\n",
      "[644/1762] D loss: 1.3905, G loss: 0.6610\n",
      "[724/1762] D loss: 0.0106, G loss: 5.0474\n",
      "[804/1762] D loss: 1.4300, G loss: 0.5385\n",
      "[884/1762] D loss: 1.3962, G loss: 0.7210\n",
      "[964/1762] D loss: 1.4327, G loss: 0.8657\n",
      "[1044/1762] D loss: 1.4029, G loss: 0.7183\n",
      "[1124/1762] D loss: 0.9789, G loss: 4.7197\n",
      "[1204/1762] D loss: 0.2005, G loss: 1.6690\n",
      "[1284/1762] D loss: 0.2100, G loss: 2.0981\n",
      "[1364/1762] D loss: 1.4250, G loss: 0.8696\n",
      "[1444/1762] D loss: 0.0222, G loss: 4.4332\n",
      "[1524/1762] D loss: 1.3898, G loss: 0.6866\n",
      "[1604/1762] D loss: 1.4073, G loss: 0.8290\n",
      "[1684/1762] D loss: 1.3954, G loss: 0.6196\n",
      "[1762/1762] D loss: 1.4210, G loss: 0.7279\n",
      "train error: \n",
      " D loss: 2.231736, G loss: 0.523379, D accuracy: 51.2%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "test error: \n",
      " D loss: 2.398977, G loss: 0.597296, D accuracy: 49.8%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.6841, G loss: 0.8565\n",
      "[84/1762] D loss: 1.4488, G loss: 0.5941\n",
      "[164/1762] D loss: 0.0372, G loss: 4.0297\n",
      "[244/1762] D loss: 1.4089, G loss: 0.7309\n",
      "[324/1762] D loss: 1.4002, G loss: 0.7178\n",
      "[404/1762] D loss: 1.2930, G loss: 0.9381\n",
      "[484/1762] D loss: 0.0017, G loss: 9.1859\n",
      "[564/1762] D loss: 1.3938, G loss: 0.7375\n",
      "[644/1762] D loss: 1.4061, G loss: 0.7201\n",
      "[724/1762] D loss: 1.3893, G loss: 0.7100\n",
      "[804/1762] D loss: 1.4200, G loss: 0.8202\n",
      "[884/1762] D loss: 1.3920, G loss: 0.6827\n",
      "[964/1762] D loss: 1.3964, G loss: 0.7035\n",
      "[1044/1762] D loss: 1.3264, G loss: 1.5077\n",
      "[1124/1762] D loss: 1.4981, G loss: 0.4426\n",
      "[1204/1762] D loss: 1.3936, G loss: 0.8415\n",
      "[1284/1762] D loss: 1.4735, G loss: 0.4701\n",
      "[1364/1762] D loss: 1.4205, G loss: 0.5867\n",
      "[1444/1762] D loss: 0.1107, G loss: 2.6553\n",
      "[1524/1762] D loss: 1.4083, G loss: 0.6547\n",
      "[1604/1762] D loss: 1.4247, G loss: 0.7844\n",
      "[1684/1762] D loss: 1.4671, G loss: 0.4647\n",
      "[1762/1762] D loss: 1.3186, G loss: 1.5185\n",
      "train error: \n",
      " D loss: 2.263727, G loss: 0.367210, D accuracy: 49.2%, cell accuracy: 99.8%, board accuracy: 91.2% \n",
      "\n",
      "test error: \n",
      " D loss: 2.376615, G loss: 0.377172, D accuracy: 48.8%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3969, G loss: 0.6664\n",
      "[84/1762] D loss: 1.4034, G loss: 0.5735\n",
      "[164/1762] D loss: 0.0532, G loss: 3.4387\n",
      "[244/1762] D loss: 0.0195, G loss: 4.4500\n",
      "[324/1762] D loss: 1.4415, G loss: 0.5190\n",
      "[404/1762] D loss: 0.0514, G loss: 2.8260\n",
      "[484/1762] D loss: 1.2443, G loss: 1.0916\n",
      "[564/1762] D loss: 1.3986, G loss: 0.6588\n",
      "[644/1762] D loss: 1.3896, G loss: 0.7128\n",
      "[724/1762] D loss: 0.0142, G loss: 4.8830\n",
      "[804/1762] D loss: 1.3883, G loss: 0.7359\n",
      "[884/1762] D loss: 0.0402, G loss: 3.4841\n",
      "[964/1762] D loss: 1.3929, G loss: 0.6805\n",
      "[1044/1762] D loss: 1.3943, G loss: 0.6421\n",
      "[1124/1762] D loss: 1.3966, G loss: 0.7252\n",
      "[1204/1762] D loss: 0.0270, G loss: 3.7828\n",
      "[1284/1762] D loss: 1.3972, G loss: 0.7515\n",
      "[1364/1762] D loss: 0.0007, G loss: 11.2030\n",
      "[1444/1762] D loss: 1.3872, G loss: 0.7419\n",
      "[1524/1762] D loss: 1.4134, G loss: 0.7975\n",
      "[1604/1762] D loss: 1.3932, G loss: 0.7186\n",
      "[1684/1762] D loss: 1.3931, G loss: 0.6979\n",
      "[1762/1762] D loss: 1.3856, G loss: 0.6415\n",
      "train error: \n",
      " D loss: 2.588290, G loss: 0.530445, D accuracy: 50.7%, cell accuracy: 99.8%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 2.841456, G loss: 0.543400, D accuracy: 50.8%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3901, G loss: 0.6198\n",
      "[84/1762] D loss: 1.4024, G loss: 0.8265\n",
      "[164/1762] D loss: 0.0225, G loss: 4.4517\n",
      "[244/1762] D loss: 1.3940, G loss: 0.6247\n",
      "[324/1762] D loss: 1.3931, G loss: 0.6382\n",
      "[404/1762] D loss: 0.0007, G loss: 11.9024\n",
      "[484/1762] D loss: 1.4253, G loss: 0.5461\n",
      "[564/1762] D loss: 1.3964, G loss: 0.8173\n",
      "[644/1762] D loss: 1.3889, G loss: 0.6958\n",
      "[724/1762] D loss: 1.4076, G loss: 0.5919\n",
      "[804/1762] D loss: 0.0169, G loss: 4.6014\n",
      "[884/1762] D loss: 1.3711, G loss: 0.6906\n",
      "[964/1762] D loss: 1.3517, G loss: 0.8458\n",
      "[1044/1762] D loss: 0.0164, G loss: 4.8817\n",
      "[1124/1762] D loss: 1.3875, G loss: 0.7014\n",
      "[1204/1762] D loss: 1.3867, G loss: 0.6849\n",
      "[1284/1762] D loss: 1.4470, G loss: 0.5676\n",
      "[1364/1762] D loss: 1.3776, G loss: 0.7257\n",
      "[1444/1762] D loss: 1.4062, G loss: 0.5839\n",
      "[1524/1762] D loss: 1.3892, G loss: 0.7416\n",
      "[1604/1762] D loss: 1.3954, G loss: 0.7687\n",
      "[1684/1762] D loss: 1.4077, G loss: 0.8789\n",
      "[1762/1762] D loss: 1.4072, G loss: 0.8258\n",
      "train error: \n",
      " D loss: 2.759989, G loss: 0.339776, D accuracy: 46.7%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 3.011017, G loss: 0.358655, D accuracy: 46.0%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0132, G loss: 4.8605\n",
      "[84/1762] D loss: 0.0124, G loss: 4.9995\n",
      "[164/1762] D loss: 1.3876, G loss: 0.6846\n",
      "[244/1762] D loss: 0.0500, G loss: 5.4147\n",
      "[324/1762] D loss: 0.0087, G loss: 5.5964\n",
      "[404/1762] D loss: 1.3920, G loss: 0.6509\n",
      "[484/1762] D loss: 0.0513, G loss: 5.1533\n",
      "[564/1762] D loss: 1.3881, G loss: 0.6914\n",
      "[644/1762] D loss: 1.3925, G loss: 0.6928\n",
      "[724/1762] D loss: 1.3913, G loss: 0.7247\n",
      "[804/1762] D loss: 1.4035, G loss: 0.8079\n",
      "[884/1762] D loss: 1.3896, G loss: 0.6664\n",
      "[964/1762] D loss: 0.0108, G loss: 4.8336\n",
      "[1044/1762] D loss: 1.3883, G loss: 0.7516\n",
      "[1124/1762] D loss: 0.0071, G loss: 5.2033\n",
      "[1204/1762] D loss: 1.4158, G loss: 0.8593\n",
      "[1284/1762] D loss: 1.3930, G loss: 0.6242\n",
      "[1364/1762] D loss: 1.3966, G loss: 0.5777\n",
      "[1444/1762] D loss: 1.3885, G loss: 0.6711\n",
      "[1524/1762] D loss: 1.4020, G loss: 0.6434\n",
      "[1604/1762] D loss: 1.3895, G loss: 0.7063\n",
      "[1684/1762] D loss: 1.3914, G loss: 0.7209\n",
      "[1762/1762] D loss: 1.3920, G loss: 0.6457\n",
      "train error: \n",
      " D loss: 2.979967, G loss: 0.545345, D accuracy: 47.6%, cell accuracy: 99.9%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 3.329727, G loss: 0.577815, D accuracy: 47.4%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3915, G loss: 0.6382\n",
      "[84/1762] D loss: 1.3937, G loss: 0.7459\n",
      "[164/1762] D loss: 0.0170, G loss: 4.2255\n",
      "[244/1762] D loss: 1.4168, G loss: 0.5206\n",
      "[324/1762] D loss: 1.3958, G loss: 0.8112\n",
      "[404/1762] D loss: 1.5236, G loss: 0.7821\n",
      "[484/1762] D loss: 1.3919, G loss: 0.6736\n",
      "[564/1762] D loss: 0.0118, G loss: 4.8264\n",
      "[644/1762] D loss: 1.3912, G loss: 0.7527\n",
      "[724/1762] D loss: 1.1637, G loss: 1.9219\n",
      "[804/1762] D loss: 1.4127, G loss: 0.6073\n",
      "[884/1762] D loss: 1.3893, G loss: 0.7612\n",
      "[964/1762] D loss: 1.3922, G loss: 0.6639\n",
      "[1044/1762] D loss: 1.3912, G loss: 0.6769\n",
      "[1124/1762] D loss: 1.4291, G loss: 0.7652\n",
      "[1204/1762] D loss: 0.0075, G loss: 5.4824\n",
      "[1284/1762] D loss: 1.3877, G loss: 0.7048\n",
      "[1364/1762] D loss: 1.4020, G loss: 0.7334\n",
      "[1444/1762] D loss: 1.3896, G loss: 0.7261\n",
      "[1524/1762] D loss: 1.3952, G loss: 0.7306\n",
      "[1604/1762] D loss: 1.3979, G loss: 0.6337\n",
      "[1684/1762] D loss: 1.4029, G loss: 0.6552\n",
      "[1762/1762] D loss: 1.3875, G loss: 0.6786\n",
      "train error: \n",
      " D loss: 3.313506, G loss: 0.161322, D accuracy: 46.7%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 3.575900, G loss: 0.178586, D accuracy: 45.9%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4086, G loss: 0.6213\n",
      "[84/1762] D loss: 1.3937, G loss: 0.7494\n",
      "[164/1762] D loss: 1.4019, G loss: 0.6620\n",
      "[244/1762] D loss: 1.4066, G loss: 0.5829\n",
      "[324/1762] D loss: 0.0093, G loss: 5.4162\n",
      "[404/1762] D loss: 0.0014, G loss: 13.4386\n",
      "[484/1762] D loss: 1.3971, G loss: 0.5848\n",
      "[564/1762] D loss: 0.0127, G loss: 4.9874\n",
      "[644/1762] D loss: 0.0090, G loss: 5.4666\n",
      "[724/1762] D loss: 1.3972, G loss: 0.6956\n",
      "[804/1762] D loss: 1.4007, G loss: 0.8218\n",
      "[884/1762] D loss: 1.3852, G loss: 0.6876\n",
      "[964/1762] D loss: 0.0109, G loss: 4.9981\n",
      "[1044/1762] D loss: 0.0073, G loss: 6.0461\n",
      "[1124/1762] D loss: 1.3891, G loss: 0.7024\n",
      "[1204/1762] D loss: 0.0134, G loss: 4.7691\n",
      "[1284/1762] D loss: 1.3870, G loss: 0.6926\n",
      "[1364/1762] D loss: 1.2845, G loss: 0.9061\n",
      "[1444/1762] D loss: 1.4404, G loss: 0.8621\n",
      "[1524/1762] D loss: 1.3932, G loss: 0.7390\n",
      "[1604/1762] D loss: 0.0247, G loss: 3.9517\n",
      "[1684/1762] D loss: 0.0150, G loss: 4.9063\n",
      "[1762/1762] D loss: 1.4151, G loss: 0.5740\n",
      "train error: \n",
      " D loss: 3.390189, G loss: 0.211987, D accuracy: 46.7%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 3.725365, G loss: 0.245986, D accuracy: 45.8%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3942, G loss: 0.6812\n",
      "[84/1762] D loss: 1.3906, G loss: 0.7555\n",
      "[164/1762] D loss: 1.3895, G loss: 0.7384\n",
      "[244/1762] D loss: 0.0067, G loss: 5.7638\n",
      "[324/1762] D loss: 0.0109, G loss: 5.0187\n",
      "[404/1762] D loss: 1.3903, G loss: 0.7138\n",
      "[484/1762] D loss: 0.0096, G loss: 5.3396\n",
      "[564/1762] D loss: 1.3908, G loss: 0.7570\n",
      "[644/1762] D loss: 0.0079, G loss: 6.1128\n",
      "[724/1762] D loss: 0.0095, G loss: 5.0492\n",
      "[804/1762] D loss: 1.3879, G loss: 0.6778\n",
      "[884/1762] D loss: 1.3882, G loss: 0.6496\n",
      "[964/1762] D loss: 1.3966, G loss: 0.7966\n",
      "[1044/1762] D loss: 1.3889, G loss: 0.7223\n",
      "[1124/1762] D loss: 1.3882, G loss: 0.6433\n",
      "[1204/1762] D loss: 0.0062, G loss: 5.6704\n",
      "[1284/1762] D loss: 0.0044, G loss: 6.3683\n",
      "[1364/1762] D loss: 1.4031, G loss: 0.5723\n",
      "[1444/1762] D loss: 1.3885, G loss: 0.6755\n",
      "[1524/1762] D loss: 1.3882, G loss: 0.6626\n",
      "[1604/1762] D loss: 1.4059, G loss: 0.5481\n",
      "[1684/1762] D loss: 0.0037, G loss: 6.5365\n",
      "[1762/1762] D loss: 1.4071, G loss: 0.6854\n",
      "train error: \n",
      " D loss: 3.631124, G loss: 0.230241, D accuracy: 46.9%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 4.022813, G loss: 0.232596, D accuracy: 45.8%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0078, G loss: 4.7779\n",
      "[84/1762] D loss: 1.3904, G loss: 0.6897\n",
      "[164/1762] D loss: 1.3878, G loss: 0.7246\n",
      "[244/1762] D loss: 1.3973, G loss: 0.7820\n",
      "[324/1762] D loss: 1.3868, G loss: 0.6862\n",
      "[404/1762] D loss: 0.0076, G loss: 5.6564\n",
      "[484/1762] D loss: 1.3883, G loss: 0.6863\n",
      "[564/1762] D loss: 0.0072, G loss: 6.3290\n",
      "[644/1762] D loss: 1.3902, G loss: 0.7148\n",
      "[724/1762] D loss: 1.3887, G loss: 0.6876\n",
      "[804/1762] D loss: 1.3892, G loss: 0.6946\n",
      "[884/1762] D loss: 1.3892, G loss: 0.7284\n",
      "[964/1762] D loss: 1.3895, G loss: 0.7176\n",
      "[1044/1762] D loss: 0.0143, G loss: 4.6921\n",
      "[1124/1762] D loss: 1.3927, G loss: 0.6690\n",
      "[1204/1762] D loss: 0.0073, G loss: 6.1286\n",
      "[1284/1762] D loss: 1.3911, G loss: 0.6152\n",
      "[1364/1762] D loss: 0.0219, G loss: 5.2102\n",
      "[1444/1762] D loss: 1.4199, G loss: 0.8429\n",
      "[1524/1762] D loss: 1.4027, G loss: 0.7291\n",
      "[1604/1762] D loss: 1.4472, G loss: 0.6456\n",
      "[1684/1762] D loss: 0.0010, G loss: 11.9762\n",
      "[1762/1762] D loss: 1.3912, G loss: 0.6827\n",
      "train error: \n",
      " D loss: 3.497202, G loss: 0.338995, D accuracy: 47.4%, cell accuracy: 99.8%, board accuracy: 90.8% \n",
      "\n",
      "test error: \n",
      " D loss: 3.891185, G loss: 0.390787, D accuracy: 46.7%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4159, G loss: 0.7963\n",
      "[84/1762] D loss: 1.4067, G loss: 0.7314\n",
      "[164/1762] D loss: 1.3420, G loss: 1.1079\n",
      "[244/1762] D loss: 1.1787, G loss: 0.7159\n",
      "[324/1762] D loss: 1.3914, G loss: 0.6518\n",
      "[404/1762] D loss: 0.0099, G loss: 14.5676\n",
      "[484/1762] D loss: 1.4480, G loss: 0.9324\n",
      "[564/1762] D loss: 1.1237, G loss: 0.7283\n",
      "[644/1762] D loss: 0.5194, G loss: 1.9663\n",
      "[724/1762] D loss: 1.1429, G loss: 0.8642\n",
      "[804/1762] D loss: 1.4282, G loss: 0.6328\n",
      "[884/1762] D loss: 1.3860, G loss: 0.7204\n",
      "[964/1762] D loss: 1.2657, G loss: 0.9751\n",
      "[1044/1762] D loss: 1.4025, G loss: 0.5684\n",
      "[1124/1762] D loss: 0.2630, G loss: 1.9370\n",
      "[1204/1762] D loss: 1.3891, G loss: 0.6910\n",
      "[1284/1762] D loss: 1.3147, G loss: 0.7175\n",
      "[1364/1762] D loss: 0.1459, G loss: 2.2294\n",
      "[1444/1762] D loss: 0.1167, G loss: 2.4271\n",
      "[1524/1762] D loss: 0.1582, G loss: 2.2277\n",
      "[1604/1762] D loss: 1.4139, G loss: 0.7599\n",
      "[1684/1762] D loss: 1.4032, G loss: 0.7800\n",
      "[1762/1762] D loss: 0.0126, G loss: 5.7495\n",
      "train error: \n",
      " D loss: 2.039648, G loss: 0.227997, D accuracy: 47.9%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 2.024043, G loss: 0.238501, D accuracy: 47.7%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3910, G loss: 0.6994\n",
      "[84/1762] D loss: 0.1138, G loss: 2.3231\n",
      "[164/1762] D loss: 0.1480, G loss: 2.2498\n",
      "[244/1762] D loss: 1.3894, G loss: 0.5620\n",
      "[324/1762] D loss: 1.4000, G loss: 0.6097\n",
      "[404/1762] D loss: 1.3899, G loss: 0.6971\n",
      "[484/1762] D loss: 1.4000, G loss: 0.7555\n",
      "[564/1762] D loss: 1.4107, G loss: 0.8049\n",
      "[644/1762] D loss: 1.3971, G loss: 0.6265\n",
      "[724/1762] D loss: 1.4506, G loss: 0.9730\n",
      "[804/1762] D loss: 1.3952, G loss: 0.6243\n",
      "[884/1762] D loss: 1.4517, G loss: 0.5381\n",
      "[964/1762] D loss: 1.3869, G loss: 0.7208\n",
      "[1044/1762] D loss: 1.3909, G loss: 0.6454\n",
      "[1124/1762] D loss: 1.3894, G loss: 0.6973\n",
      "[1204/1762] D loss: 0.1232, G loss: 2.2795\n",
      "[1284/1762] D loss: 1.3901, G loss: 0.6759\n",
      "[1364/1762] D loss: 1.4000, G loss: 0.7112\n",
      "[1444/1762] D loss: 1.4185, G loss: 0.8304\n",
      "[1524/1762] D loss: 1.3970, G loss: 0.6347\n",
      "[1604/1762] D loss: 1.4030, G loss: 0.5361\n",
      "[1684/1762] D loss: 0.0741, G loss: 3.1086\n",
      "[1762/1762] D loss: 1.3939, G loss: 0.7337\n",
      "train error: \n",
      " D loss: 2.473598, G loss: 0.676870, D accuracy: 51.6%, cell accuracy: 99.8%, board accuracy: 90.8% \n",
      "\n",
      "test error: \n",
      " D loss: 2.675934, G loss: 0.695647, D accuracy: 51.7%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3923, G loss: 0.6801\n",
      "[84/1762] D loss: 0.0003, G loss: 13.5228\n",
      "[164/1762] D loss: 0.0557, G loss: 3.5437\n",
      "[244/1762] D loss: 1.3416, G loss: 0.8465\n",
      "[324/1762] D loss: 1.3885, G loss: 0.7108\n",
      "[404/1762] D loss: 0.1219, G loss: 2.6320\n",
      "[484/1762] D loss: 0.0023, G loss: 9.9900\n",
      "[564/1762] D loss: 0.1401, G loss: 2.6201\n",
      "[644/1762] D loss: 1.3964, G loss: 0.7004\n",
      "[724/1762] D loss: 0.1282, G loss: 2.7515\n",
      "[804/1762] D loss: 1.4275, G loss: 0.8415\n",
      "[884/1762] D loss: 1.3819, G loss: 0.7729\n",
      "[964/1762] D loss: 0.2661, G loss: 1.4734\n",
      "[1044/1762] D loss: 1.4065, G loss: 0.6630\n",
      "[1124/1762] D loss: 0.0222, G loss: 5.2482\n",
      "[1204/1762] D loss: 1.3971, G loss: 0.7237\n",
      "[1284/1762] D loss: 0.1021, G loss: 4.0778\n",
      "[1364/1762] D loss: 1.3916, G loss: 0.6543\n",
      "[1444/1762] D loss: 1.4001, G loss: 0.8330\n",
      "[1524/1762] D loss: 1.3947, G loss: 0.6851\n",
      "[1604/1762] D loss: 1.5150, G loss: 1.0936\n",
      "[1684/1762] D loss: 1.4494, G loss: 0.5678\n",
      "[1762/1762] D loss: 1.4218, G loss: 0.6672\n",
      "train error: \n",
      " D loss: 1.416585, G loss: 0.894171, D accuracy: 52.0%, cell accuracy: 99.8%, board accuracy: 90.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.407035, G loss: 0.877859, D accuracy: 52.5%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3995, G loss: 0.7745\n",
      "[84/1762] D loss: 1.4085, G loss: 0.7533\n",
      "[164/1762] D loss: 1.3881, G loss: 0.6479\n",
      "[244/1762] D loss: 0.1043, G loss: 4.7573\n",
      "[324/1762] D loss: 0.0081, G loss: 6.4566\n",
      "[404/1762] D loss: 1.3875, G loss: 0.7810\n",
      "[484/1762] D loss: 1.4604, G loss: 0.5617\n",
      "[564/1762] D loss: 1.5471, G loss: 0.4838\n",
      "[644/1762] D loss: 0.0669, G loss: 3.0211\n",
      "[724/1762] D loss: 0.0162, G loss: 5.5309\n",
      "[804/1762] D loss: 1.4100, G loss: 0.8451\n",
      "[884/1762] D loss: 1.4319, G loss: 0.6644\n",
      "[964/1762] D loss: 1.3894, G loss: 0.6412\n",
      "[1044/1762] D loss: 1.3934, G loss: 0.7703\n",
      "[1124/1762] D loss: 1.4108, G loss: 0.7089\n",
      "[1204/1762] D loss: 1.3959, G loss: 0.7286\n",
      "[1284/1762] D loss: 1.4024, G loss: 0.7713\n",
      "[1364/1762] D loss: 1.3777, G loss: 0.8605\n",
      "[1444/1762] D loss: 1.4113, G loss: 0.5873\n",
      "[1524/1762] D loss: 0.0890, G loss: 5.4604\n",
      "[1604/1762] D loss: 1.3946, G loss: 0.7704\n",
      "[1684/1762] D loss: 0.0662, G loss: 6.1203\n",
      "[1762/1762] D loss: 1.4009, G loss: 0.6061\n",
      "train error: \n",
      " D loss: 1.943348, G loss: 0.698835, D accuracy: 49.1%, cell accuracy: 99.9%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.972531, G loss: 0.687863, D accuracy: 49.0%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4000, G loss: 0.6255\n",
      "[84/1762] D loss: 1.3975, G loss: 0.7397\n",
      "[164/1762] D loss: 0.0036, G loss: 6.7451\n",
      "[244/1762] D loss: 1.5086, G loss: 0.4740\n",
      "[324/1762] D loss: 1.3953, G loss: 0.7541\n",
      "[404/1762] D loss: 1.4111, G loss: 0.8094\n",
      "[484/1762] D loss: 1.3880, G loss: 0.6838\n",
      "[564/1762] D loss: 0.0103, G loss: 5.3392\n",
      "[644/1762] D loss: 1.3958, G loss: 0.8253\n",
      "[724/1762] D loss: 0.8488, G loss: 2.9742\n",
      "[804/1762] D loss: 0.0272, G loss: 3.9937\n",
      "[884/1762] D loss: 1.4647, G loss: 0.9044\n",
      "[964/1762] D loss: 1.3895, G loss: 0.7513\n",
      "[1044/1762] D loss: 0.0060, G loss: 5.9529\n",
      "[1124/1762] D loss: 1.3964, G loss: 0.7249\n",
      "[1204/1762] D loss: 1.5377, G loss: 0.3402\n",
      "[1284/1762] D loss: 1.3972, G loss: 0.6107\n",
      "[1364/1762] D loss: 0.0638, G loss: 3.7010\n",
      "[1444/1762] D loss: 0.0130, G loss: 6.0272\n",
      "[1524/1762] D loss: 1.3922, G loss: 0.6628\n",
      "[1604/1762] D loss: 0.0013, G loss: 15.0918\n",
      "[1684/1762] D loss: 1.3902, G loss: 0.7351\n",
      "[1762/1762] D loss: 1.3940, G loss: 0.7657\n",
      "train error: \n",
      " D loss: 2.342015, G loss: 0.597105, D accuracy: 46.9%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 2.503942, G loss: 0.584847, D accuracy: 46.4%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4050, G loss: 0.7507\n",
      "[84/1762] D loss: 1.4025, G loss: 0.7628\n",
      "[164/1762] D loss: 0.0155, G loss: 6.1260\n",
      "[244/1762] D loss: 1.3883, G loss: 0.7163\n",
      "[324/1762] D loss: 0.0037, G loss: 6.6525\n",
      "[404/1762] D loss: 0.0052, G loss: 5.8059\n",
      "[484/1762] D loss: 1.3910, G loss: 0.6622\n",
      "[564/1762] D loss: 1.4191, G loss: 0.7835\n",
      "[644/1762] D loss: 1.3932, G loss: 0.5914\n",
      "[724/1762] D loss: 1.3443, G loss: 0.7150\n",
      "[804/1762] D loss: 1.3886, G loss: 0.6627\n",
      "[884/1762] D loss: 1.3880, G loss: 0.7106\n",
      "[964/1762] D loss: 0.0083, G loss: 6.4347\n",
      "[1044/1762] D loss: 1.3867, G loss: 0.6902\n",
      "[1124/1762] D loss: 1.3867, G loss: 0.7027\n",
      "[1204/1762] D loss: 0.0124, G loss: 6.4730\n",
      "[1284/1762] D loss: 1.3874, G loss: 0.7278\n",
      "[1364/1762] D loss: 0.0023, G loss: 7.0028\n",
      "[1444/1762] D loss: 1.3928, G loss: 0.6312\n",
      "[1524/1762] D loss: 1.3893, G loss: 0.6627\n",
      "[1604/1762] D loss: 1.3950, G loss: 0.6591\n",
      "[1684/1762] D loss: 0.0009, G loss: 16.7342\n",
      "[1762/1762] D loss: 1.3892, G loss: 0.7221\n",
      "train error: \n",
      " D loss: 2.631568, G loss: 0.283645, D accuracy: 46.5%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 2.796784, G loss: 0.314450, D accuracy: 45.7%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3878, G loss: 0.7235\n",
      "[84/1762] D loss: 1.3867, G loss: 0.7087\n",
      "[164/1762] D loss: 1.3869, G loss: 0.6669\n",
      "[244/1762] D loss: 1.3879, G loss: 0.7116\n",
      "[324/1762] D loss: 0.0029, G loss: 10.7133\n",
      "[404/1762] D loss: 1.4206, G loss: 0.8730\n",
      "[484/1762] D loss: 1.3909, G loss: 0.6559\n",
      "[564/1762] D loss: 1.4501, G loss: 0.9337\n",
      "[644/1762] D loss: 1.4246, G loss: 0.8003\n",
      "[724/1762] D loss: 1.3924, G loss: 0.5775\n",
      "[804/1762] D loss: 1.3894, G loss: 0.6463\n",
      "[884/1762] D loss: 1.3975, G loss: 0.6339\n",
      "[964/1762] D loss: 1.3885, G loss: 0.6772\n",
      "[1044/1762] D loss: 1.3866, G loss: 0.6983\n",
      "[1124/1762] D loss: 1.3992, G loss: 0.8067\n",
      "[1204/1762] D loss: 1.3898, G loss: 0.7914\n",
      "[1284/1762] D loss: 0.0011, G loss: 15.4216\n",
      "[1364/1762] D loss: 1.3880, G loss: 0.7104\n",
      "[1444/1762] D loss: 1.3946, G loss: 0.7436\n",
      "[1524/1762] D loss: 1.3878, G loss: 0.6597\n",
      "[1604/1762] D loss: 0.0079, G loss: 6.4828\n",
      "[1684/1762] D loss: 1.3921, G loss: 0.7580\n",
      "[1762/1762] D loss: 1.3870, G loss: 0.7140\n",
      "train error: \n",
      " D loss: 2.618279, G loss: 0.380442, D accuracy: 46.5%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 2.822131, G loss: 0.396159, D accuracy: 45.6%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0070, G loss: 6.2652\n",
      "[84/1762] D loss: 1.3867, G loss: 0.6714\n",
      "[164/1762] D loss: 1.3870, G loss: 0.6902\n",
      "[244/1762] D loss: 0.0053, G loss: 6.6170\n",
      "[324/1762] D loss: 0.0057, G loss: 6.5746\n",
      "[404/1762] D loss: 1.3878, G loss: 0.7316\n",
      "[484/1762] D loss: 0.0002, G loss: 14.5673\n",
      "[564/1762] D loss: 1.3906, G loss: 0.6606\n",
      "[644/1762] D loss: 0.0096, G loss: 6.2723\n",
      "[724/1762] D loss: 1.5527, G loss: 0.3381\n",
      "[804/1762] D loss: 1.3952, G loss: 0.7495\n",
      "[884/1762] D loss: 0.0726, G loss: 3.1116\n",
      "[964/1762] D loss: 1.3968, G loss: 0.6773\n",
      "[1044/1762] D loss: 1.3905, G loss: 0.6771\n",
      "[1124/1762] D loss: 1.3890, G loss: 0.7521\n",
      "[1204/1762] D loss: 1.3828, G loss: 0.7066\n",
      "[1284/1762] D loss: 1.3890, G loss: 0.6319\n",
      "[1364/1762] D loss: 1.3981, G loss: 0.7152\n",
      "[1444/1762] D loss: 1.3857, G loss: 0.7244\n",
      "[1524/1762] D loss: 1.3878, G loss: 0.7198\n",
      "[1604/1762] D loss: 0.0054, G loss: 6.2312\n",
      "[1684/1762] D loss: 0.3240, G loss: 1.5539\n",
      "[1762/1762] D loss: 1.3966, G loss: 0.7226\n",
      "train error: \n",
      " D loss: 2.646107, G loss: 0.559452, D accuracy: 46.9%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 2.881543, G loss: 0.550191, D accuracy: 46.0%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3944, G loss: 0.5827\n",
      "[84/1762] D loss: 1.3892, G loss: 0.7321\n",
      "[164/1762] D loss: 1.3977, G loss: 0.7760\n",
      "[244/1762] D loss: 1.3882, G loss: 0.7203\n",
      "[324/1762] D loss: 1.4054, G loss: 0.5516\n",
      "[404/1762] D loss: 0.0294, G loss: 5.2347\n",
      "[484/1762] D loss: 1.3591, G loss: 0.9398\n",
      "[564/1762] D loss: 1.3993, G loss: 0.6313\n",
      "[644/1762] D loss: 1.4007, G loss: 0.6758\n",
      "[724/1762] D loss: 1.4725, G loss: 0.6019\n",
      "[804/1762] D loss: 1.4046, G loss: 0.5851\n",
      "[884/1762] D loss: 0.0313, G loss: 5.3843\n",
      "[964/1762] D loss: 1.3828, G loss: 0.7129\n",
      "[1044/1762] D loss: 0.0045, G loss: 5.6834\n",
      "[1124/1762] D loss: 1.3929, G loss: 0.6937\n",
      "[1204/1762] D loss: 0.0156, G loss: 6.3374\n",
      "[1284/1762] D loss: 0.0087, G loss: 6.3751\n",
      "[1364/1762] D loss: 0.0105, G loss: 5.6676\n",
      "[1444/1762] D loss: 1.4050, G loss: 0.7478\n",
      "[1524/1762] D loss: 1.3899, G loss: 0.6476\n",
      "[1604/1762] D loss: 1.4181, G loss: 0.5330\n",
      "[1684/1762] D loss: 0.0421, G loss: 5.3103\n",
      "[1762/1762] D loss: 1.3881, G loss: 0.7330\n",
      "train error: \n",
      " D loss: 2.343540, G loss: 0.465522, D accuracy: 47.1%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 2.457870, G loss: 0.488316, D accuracy: 46.4%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3901, G loss: 0.6898\n",
      "[84/1762] D loss: 0.0193, G loss: 6.4931\n",
      "[164/1762] D loss: 1.3883, G loss: 0.6345\n",
      "[244/1762] D loss: 1.3903, G loss: 0.6632\n",
      "[324/1762] D loss: 1.3877, G loss: 0.7160\n",
      "[404/1762] D loss: 1.3933, G loss: 0.6784\n",
      "[484/1762] D loss: 0.0029, G loss: 6.8404\n",
      "[564/1762] D loss: 1.3896, G loss: 0.6623\n",
      "[644/1762] D loss: 0.0003, G loss: 12.0977\n",
      "[724/1762] D loss: 1.1891, G loss: 0.8422\n",
      "[804/1762] D loss: 1.3947, G loss: 0.6751\n",
      "[884/1762] D loss: 1.3871, G loss: 0.6970\n",
      "[964/1762] D loss: 1.3990, G loss: 0.5841\n",
      "[1044/1762] D loss: 0.0198, G loss: 6.1966\n",
      "[1124/1762] D loss: 1.3947, G loss: 0.7669\n",
      "[1204/1762] D loss: 1.7654, G loss: 0.3241\n",
      "[1284/1762] D loss: 1.4172, G loss: 0.6334\n",
      "[1364/1762] D loss: 1.4442, G loss: 0.9073\n",
      "[1444/1762] D loss: 0.0331, G loss: 5.3871\n",
      "[1524/1762] D loss: 0.0176, G loss: 4.6572\n",
      "[1604/1762] D loss: 1.3976, G loss: 0.7108\n",
      "[1684/1762] D loss: 0.0068, G loss: 5.7137\n",
      "[1762/1762] D loss: 1.3918, G loss: 0.7606\n",
      "train error: \n",
      " D loss: 2.845699, G loss: 0.576643, D accuracy: 47.4%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 3.155345, G loss: 0.543406, D accuracy: 46.2%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4510, G loss: 0.7510\n",
      "[84/1762] D loss: 1.3921, G loss: 0.7091\n",
      "[164/1762] D loss: 1.3875, G loss: 0.6627\n",
      "[244/1762] D loss: 0.0102, G loss: 5.3483\n",
      "[324/1762] D loss: 1.3901, G loss: 0.6698\n",
      "[404/1762] D loss: 1.3857, G loss: 0.7387\n",
      "[484/1762] D loss: 1.3837, G loss: 0.6963\n",
      "[564/1762] D loss: 1.3873, G loss: 0.7237\n",
      "[644/1762] D loss: 1.4311, G loss: 0.9317\n",
      "[724/1762] D loss: 0.0103, G loss: 5.2399\n",
      "[804/1762] D loss: 1.3904, G loss: 0.6766\n",
      "[884/1762] D loss: 1.3862, G loss: 0.6796\n",
      "[964/1762] D loss: 1.4005, G loss: 0.5616\n",
      "[1044/1762] D loss: 1.3911, G loss: 0.7514\n",
      "[1124/1762] D loss: 1.3897, G loss: 0.6394\n",
      "[1204/1762] D loss: 1.3890, G loss: 0.7196\n",
      "[1284/1762] D loss: 1.4184, G loss: 0.5741\n",
      "[1364/1762] D loss: 0.0060, G loss: 5.6118\n",
      "[1444/1762] D loss: 1.3878, G loss: 0.6797\n",
      "[1524/1762] D loss: 1.3868, G loss: 0.6894\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6767\n",
      "[1684/1762] D loss: 0.0083, G loss: 7.0643\n",
      "[1762/1762] D loss: 1.4319, G loss: 0.6918\n",
      "train error: \n",
      " D loss: 3.067124, G loss: 0.334342, D accuracy: 46.6%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 3.393335, G loss: 0.348203, D accuracy: 45.7%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3875, G loss: 0.6565\n",
      "[84/1762] D loss: 0.0008, G loss: 12.5253\n",
      "[164/1762] D loss: 1.3929, G loss: 0.6815\n",
      "[244/1762] D loss: 0.0046, G loss: 6.3348\n",
      "[324/1762] D loss: 1.3955, G loss: 0.7578\n",
      "[404/1762] D loss: 1.3891, G loss: 0.6676\n",
      "[484/1762] D loss: 1.3910, G loss: 0.7698\n",
      "[564/1762] D loss: 1.3894, G loss: 0.7314\n",
      "[644/1762] D loss: 0.0030, G loss: 6.6993\n",
      "[724/1762] D loss: 1.3917, G loss: 0.6941\n",
      "[804/1762] D loss: 1.3893, G loss: 0.6920\n",
      "[884/1762] D loss: 1.3872, G loss: 0.7244\n",
      "[964/1762] D loss: 0.0056, G loss: 6.3638\n",
      "[1044/1762] D loss: 1.3916, G loss: 0.6559\n",
      "[1124/1762] D loss: 0.0059, G loss: 5.7724\n",
      "[1204/1762] D loss: 1.3872, G loss: 0.6873\n",
      "[1284/1762] D loss: 1.3876, G loss: 0.6863\n",
      "[1364/1762] D loss: 1.3918, G loss: 0.7513\n",
      "[1444/1762] D loss: 0.0084, G loss: 6.2584\n",
      "[1524/1762] D loss: 1.3874, G loss: 0.6605\n",
      "[1604/1762] D loss: 0.0065, G loss: 5.6316\n",
      "[1684/1762] D loss: 1.3912, G loss: 0.7419\n",
      "[1762/1762] D loss: 1.3895, G loss: 0.6991\n",
      "train error: \n",
      " D loss: 3.395331, G loss: 0.115648, D accuracy: 47.1%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 3.618390, G loss: 0.113502, D accuracy: 46.1%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3871, G loss: 0.6918\n",
      "[84/1762] D loss: 1.3885, G loss: 0.7372\n",
      "[164/1762] D loss: 0.0011, G loss: 14.8141\n",
      "[244/1762] D loss: 1.3871, G loss: 0.6922\n",
      "[324/1762] D loss: 1.3920, G loss: 0.6081\n",
      "[404/1762] D loss: 0.0123, G loss: 4.8657\n",
      "[484/1762] D loss: 0.0247, G loss: 4.1441\n",
      "[564/1762] D loss: 0.0144, G loss: 5.1744\n",
      "[644/1762] D loss: 1.3897, G loss: 0.6964\n",
      "[724/1762] D loss: 1.3884, G loss: 0.6785\n",
      "[804/1762] D loss: 1.3876, G loss: 0.6506\n",
      "[884/1762] D loss: 1.3950, G loss: 0.6274\n",
      "[964/1762] D loss: 0.0037, G loss: 6.8071\n",
      "[1044/1762] D loss: 1.3865, G loss: 0.7075\n",
      "[1124/1762] D loss: 1.3695, G loss: 0.6719\n",
      "[1204/1762] D loss: 1.3910, G loss: 0.6658\n",
      "[1284/1762] D loss: 1.3945, G loss: 0.7640\n",
      "[1364/1762] D loss: 1.3893, G loss: 0.6989\n",
      "[1444/1762] D loss: 1.3880, G loss: 0.7535\n",
      "[1524/1762] D loss: 1.3926, G loss: 0.6334\n",
      "[1604/1762] D loss: 0.0009, G loss: 17.7674\n",
      "[1684/1762] D loss: 1.3916, G loss: 0.6382\n",
      "[1762/1762] D loss: 1.3898, G loss: 0.6874\n",
      "train error: \n",
      " D loss: 3.341291, G loss: 0.413361, D accuracy: 46.7%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 3.805565, G loss: 0.387364, D accuracy: 45.5%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0065, G loss: 6.2112\n",
      "[84/1762] D loss: 0.0027, G loss: 6.8103\n",
      "[164/1762] D loss: 1.3892, G loss: 0.7012\n",
      "[244/1762] D loss: 1.3868, G loss: 0.7022\n",
      "[324/1762] D loss: 1.3888, G loss: 0.7071\n",
      "[404/1762] D loss: 0.0027, G loss: 6.6706\n",
      "[484/1762] D loss: 1.4005, G loss: 0.6291\n",
      "[564/1762] D loss: 0.0060, G loss: 6.7682\n",
      "[644/1762] D loss: 0.0052, G loss: 6.0887\n",
      "[724/1762] D loss: 0.0039, G loss: 6.4035\n",
      "[804/1762] D loss: 1.3960, G loss: 0.7841\n",
      "[884/1762] D loss: 1.3889, G loss: 0.7160\n",
      "[964/1762] D loss: 1.3873, G loss: 0.7034\n",
      "[1044/1762] D loss: 1.3883, G loss: 0.6707\n",
      "[1124/1762] D loss: 1.3878, G loss: 0.7149\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.7056\n",
      "[1284/1762] D loss: 1.3882, G loss: 0.6418\n",
      "[1364/1762] D loss: 1.4076, G loss: 0.5682\n",
      "[1444/1762] D loss: 1.3929, G loss: 0.6150\n",
      "[1524/1762] D loss: 0.0088, G loss: 5.4742\n",
      "[1604/1762] D loss: 0.0147, G loss: 4.7707\n",
      "[1684/1762] D loss: 1.3872, G loss: 0.6748\n",
      "[1762/1762] D loss: 1.4824, G loss: 0.6654\n",
      "train error: \n",
      " D loss: 3.439852, G loss: 0.358114, D accuracy: 46.8%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 3.906325, G loss: 0.353563, D accuracy: 45.9%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3923, G loss: 0.5513\n",
      "[84/1762] D loss: 1.3868, G loss: 0.7673\n",
      "[164/1762] D loss: 0.0061, G loss: 5.4753\n",
      "[244/1762] D loss: 1.3962, G loss: 0.7262\n",
      "[324/1762] D loss: 0.0114, G loss: 4.8335\n",
      "[404/1762] D loss: 1.4107, G loss: 1.3074\n",
      "[484/1762] D loss: 1.3951, G loss: 0.5969\n",
      "[564/1762] D loss: 1.3985, G loss: 0.5356\n",
      "[644/1762] D loss: 1.1998, G loss: 3.0106\n",
      "[724/1762] D loss: 0.0330, G loss: 4.7148\n",
      "[804/1762] D loss: 0.0092, G loss: 6.8315\n",
      "[884/1762] D loss: 1.4153, G loss: 0.6861\n",
      "[964/1762] D loss: 1.3956, G loss: 0.6172\n",
      "[1044/1762] D loss: 1.3997, G loss: 0.6927\n",
      "[1124/1762] D loss: 0.0013, G loss: 15.4749\n",
      "[1204/1762] D loss: 1.3897, G loss: 0.6604\n",
      "[1284/1762] D loss: 1.1968, G loss: 2.7997\n",
      "[1364/1762] D loss: 1.3876, G loss: 0.6737\n",
      "[1444/1762] D loss: 1.3972, G loss: 0.7746\n",
      "[1524/1762] D loss: 1.3913, G loss: 0.7660\n",
      "[1604/1762] D loss: 1.3996, G loss: 0.6519\n",
      "[1684/1762] D loss: 1.5676, G loss: 1.1121\n",
      "[1762/1762] D loss: 0.0011, G loss: 9.9500\n",
      "train error: \n",
      " D loss: 3.452318, G loss: 0.073308, D accuracy: 47.1%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 3.545106, G loss: 0.067518, D accuracy: 46.0%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0056, G loss: 8.2238\n",
      "[84/1762] D loss: 1.3903, G loss: 0.6314\n",
      "[164/1762] D loss: 1.3960, G loss: 0.6029\n",
      "[244/1762] D loss: 1.3869, G loss: 0.7007\n",
      "[324/1762] D loss: 0.0020, G loss: 18.0904\n",
      "[404/1762] D loss: 0.0116, G loss: 5.1003\n",
      "[484/1762] D loss: 0.0010, G loss: 18.6598\n",
      "[564/1762] D loss: 1.3871, G loss: 0.7221\n",
      "[644/1762] D loss: 1.3825, G loss: 1.1916\n",
      "[724/1762] D loss: 1.4025, G loss: 0.7858\n",
      "[804/1762] D loss: 1.3920, G loss: 0.7275\n",
      "[884/1762] D loss: 1.3915, G loss: 0.7442\n",
      "[964/1762] D loss: 1.4232, G loss: 0.5547\n",
      "[1044/1762] D loss: 1.4313, G loss: 0.5577\n",
      "[1124/1762] D loss: 1.3960, G loss: 0.7845\n",
      "[1204/1762] D loss: 1.4364, G loss: 0.7866\n",
      "[1284/1762] D loss: 1.4067, G loss: 0.7256\n",
      "[1364/1762] D loss: 1.4009, G loss: 0.7699\n",
      "[1444/1762] D loss: 1.4129, G loss: 0.5656\n",
      "[1524/1762] D loss: 1.4067, G loss: 0.7249\n",
      "[1604/1762] D loss: 1.4211, G loss: 0.9104\n",
      "[1684/1762] D loss: 1.3891, G loss: 0.7375\n",
      "[1762/1762] D loss: 1.4053, G loss: 0.8071\n",
      "train error: \n",
      " D loss: 3.707172, G loss: 0.480201, D accuracy: 47.4%, cell accuracy: 99.8%, board accuracy: 91.9% \n",
      "\n",
      "test error: \n",
      " D loss: 4.269659, G loss: 0.493482, D accuracy: 46.7%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0113, G loss: 6.2992\n",
      "[84/1762] D loss: 1.4867, G loss: 0.9903\n",
      "[164/1762] D loss: 1.3995, G loss: 0.8042\n",
      "[244/1762] D loss: 1.3890, G loss: 0.7298\n",
      "[324/1762] D loss: 1.4158, G loss: 0.5775\n",
      "[404/1762] D loss: 1.2208, G loss: 2.8227\n",
      "[484/1762] D loss: 1.3925, G loss: 0.6279\n",
      "[564/1762] D loss: 1.3971, G loss: 0.6918\n",
      "[644/1762] D loss: 1.3883, G loss: 0.6765\n",
      "[724/1762] D loss: 0.0496, G loss: 4.1297\n",
      "[804/1762] D loss: 1.3918, G loss: 0.6347\n",
      "[884/1762] D loss: 0.0048, G loss: 11.5730\n",
      "[964/1762] D loss: 1.3870, G loss: 0.6708\n",
      "[1044/1762] D loss: 0.0188, G loss: 5.0310\n",
      "[1124/1762] D loss: 1.3873, G loss: 0.6952\n",
      "[1204/1762] D loss: 1.3961, G loss: 0.7857\n",
      "[1284/1762] D loss: 1.3874, G loss: 0.7118\n",
      "[1364/1762] D loss: 1.3871, G loss: 0.6992\n",
      "[1444/1762] D loss: 1.3881, G loss: 0.7366\n",
      "[1524/1762] D loss: 0.0018, G loss: 12.8976\n",
      "[1604/1762] D loss: 1.3867, G loss: 0.6959\n",
      "[1684/1762] D loss: 1.5156, G loss: 0.4188\n",
      "[1762/1762] D loss: 1.3859, G loss: 0.7308\n",
      "train error: \n",
      " D loss: 2.399684, G loss: 1.244787, D accuracy: 46.2%, cell accuracy: 99.5%, board accuracy: 78.6% \n",
      "\n",
      "test error: \n",
      " D loss: 2.541051, G loss: 1.225226, D accuracy: 45.6%, cell accuracy: 99.4%, board accuracy: 75.5% \n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9229, G loss: 2.0281\n",
      "[84/1762] D loss: 1.4163, G loss: 0.8243\n",
      "[164/1762] D loss: 1.1604, G loss: 1.1890\n",
      "[244/1762] D loss: 1.3910, G loss: 0.7037\n",
      "[324/1762] D loss: 0.0144, G loss: 4.8208\n",
      "[404/1762] D loss: 1.3990, G loss: 0.6668\n",
      "[484/1762] D loss: 0.0723, G loss: 7.7732\n",
      "[564/1762] D loss: 1.4097, G loss: 0.5882\n",
      "[644/1762] D loss: 1.3990, G loss: 0.6394\n",
      "[724/1762] D loss: 1.3947, G loss: 0.6911\n",
      "[804/1762] D loss: 1.3940, G loss: 0.7887\n",
      "[884/1762] D loss: 0.0082, G loss: 17.3094\n",
      "[964/1762] D loss: 1.3882, G loss: 0.6600\n",
      "[1044/1762] D loss: 1.3925, G loss: 0.7369\n",
      "[1124/1762] D loss: 1.3903, G loss: 0.6420\n",
      "[1204/1762] D loss: 1.6017, G loss: 1.0022\n",
      "[1284/1762] D loss: 1.3896, G loss: 0.8117\n",
      "[1364/1762] D loss: 1.4145, G loss: 0.8333\n",
      "[1444/1762] D loss: 1.3975, G loss: 0.6511\n",
      "[1524/1762] D loss: 0.2895, G loss: 1.4527\n",
      "[1604/1762] D loss: 1.3927, G loss: 0.6159\n",
      "[1684/1762] D loss: 1.3898, G loss: 0.7957\n",
      "[1762/1762] D loss: 1.4061, G loss: 0.9577\n",
      "train error: \n",
      " D loss: 2.157037, G loss: 0.409083, D accuracy: 47.8%, cell accuracy: 99.9%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 2.278804, G loss: 0.406910, D accuracy: 46.7%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2256, G loss: 1.3883\n",
      "[84/1762] D loss: 0.0336, G loss: 3.9655\n",
      "[164/1762] D loss: 0.2351, G loss: 1.6514\n",
      "[244/1762] D loss: 1.4275, G loss: 0.8693\n",
      "[324/1762] D loss: 1.4379, G loss: 0.8279\n",
      "[404/1762] D loss: 1.3927, G loss: 0.7298\n",
      "[484/1762] D loss: 1.3961, G loss: 0.7093\n",
      "[564/1762] D loss: 0.0070, G loss: 10.7019\n",
      "[644/1762] D loss: 0.0030, G loss: 6.6914\n",
      "[724/1762] D loss: 1.3894, G loss: 0.7022\n",
      "[804/1762] D loss: 1.3880, G loss: 0.6866\n",
      "[884/1762] D loss: 1.3927, G loss: 0.6432\n",
      "[964/1762] D loss: 1.4628, G loss: 0.4985\n",
      "[1044/1762] D loss: 1.3935, G loss: 0.6862\n",
      "[1124/1762] D loss: 1.3920, G loss: 0.7451\n",
      "[1204/1762] D loss: 0.9540, G loss: 3.0582\n",
      "[1284/1762] D loss: 1.3893, G loss: 0.6635\n",
      "[1364/1762] D loss: 1.4326, G loss: 0.5353\n",
      "[1444/1762] D loss: 1.3862, G loss: 0.7250\n",
      "[1524/1762] D loss: 1.3884, G loss: 0.6751\n",
      "[1604/1762] D loss: 1.3890, G loss: 0.7010\n",
      "[1684/1762] D loss: 0.0028, G loss: 7.4935\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.7172\n",
      "train error: \n",
      " D loss: 3.788914, G loss: 0.258953, D accuracy: 47.5%, cell accuracy: 99.8%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 4.271000, G loss: 0.277862, D accuracy: 47.0%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3929, G loss: 0.7523\n",
      "[84/1762] D loss: 1.3869, G loss: 0.6840\n",
      "[164/1762] D loss: 1.3986, G loss: 0.7878\n",
      "[244/1762] D loss: 1.4076, G loss: 0.8275\n",
      "[324/1762] D loss: 1.3902, G loss: 0.7229\n",
      "[404/1762] D loss: 1.4091, G loss: 0.5846\n",
      "[484/1762] D loss: 1.3862, G loss: 0.7042\n",
      "[564/1762] D loss: 1.3865, G loss: 0.6873\n",
      "[644/1762] D loss: 1.3883, G loss: 0.7205\n",
      "[724/1762] D loss: 1.3864, G loss: 0.7100\n",
      "[804/1762] D loss: 1.3886, G loss: 0.7146\n",
      "[884/1762] D loss: 1.3902, G loss: 0.7190\n",
      "[964/1762] D loss: 0.0034, G loss: 7.3798\n",
      "[1044/1762] D loss: 0.0075, G loss: 5.4358\n",
      "[1124/1762] D loss: 0.0128, G loss: 7.6474\n",
      "[1204/1762] D loss: 1.3898, G loss: 0.8295\n",
      "[1284/1762] D loss: 0.7599, G loss: 4.3573\n",
      "[1364/1762] D loss: 1.3978, G loss: 0.7745\n",
      "[1444/1762] D loss: 1.3873, G loss: 0.6680\n",
      "[1524/1762] D loss: 0.0032, G loss: 6.7444\n",
      "[1604/1762] D loss: 1.3880, G loss: 0.6677\n",
      "[1684/1762] D loss: 1.3879, G loss: 0.6995\n",
      "[1762/1762] D loss: 1.3897, G loss: 0.7469\n",
      "train error: \n",
      " D loss: 4.166199, G loss: 0.132876, D accuracy: 46.5%, cell accuracy: 99.9%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 4.632694, G loss: 0.159933, D accuracy: 45.7%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3916, G loss: 0.6224\n",
      "[84/1762] D loss: 1.3870, G loss: 0.6769\n",
      "[164/1762] D loss: 0.0023, G loss: 7.6759\n",
      "[244/1762] D loss: 1.4202, G loss: 0.5232\n",
      "[324/1762] D loss: 0.0220, G loss: 4.9331\n",
      "[404/1762] D loss: 0.0051, G loss: 6.4020\n",
      "[484/1762] D loss: 1.3871, G loss: 0.6898\n",
      "[564/1762] D loss: 0.0007, G loss: 18.5147\n",
      "[644/1762] D loss: 1.3874, G loss: 0.6797\n",
      "[724/1762] D loss: 1.3925, G loss: 0.6430\n",
      "[804/1762] D loss: 0.0036, G loss: 8.2553\n",
      "[884/1762] D loss: 1.3876, G loss: 0.6903\n",
      "[964/1762] D loss: 1.3880, G loss: 0.7323\n",
      "[1044/1762] D loss: 1.3882, G loss: 0.7230\n",
      "[1124/1762] D loss: 0.0050, G loss: 5.9097\n",
      "[1204/1762] D loss: 1.3913, G loss: 0.7790\n",
      "[1284/1762] D loss: 1.4012, G loss: 0.7240\n",
      "[1364/1762] D loss: 1.3973, G loss: 0.7895\n",
      "[1444/1762] D loss: 0.0032, G loss: 8.2037\n",
      "[1524/1762] D loss: 1.3935, G loss: 0.6393\n",
      "[1604/1762] D loss: 1.3896, G loss: 0.7088\n",
      "[1684/1762] D loss: 0.0011, G loss: 18.1424\n",
      "[1762/1762] D loss: 1.3970, G loss: 0.7996\n",
      "train error: \n",
      " D loss: 4.294372, G loss: 0.419829, D accuracy: 47.0%, cell accuracy: 99.9%, board accuracy: 92.8% \n",
      "\n",
      "test error: \n",
      " D loss: 5.037087, G loss: 0.383817, D accuracy: 45.8%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0011, G loss: 19.6496\n",
      "[84/1762] D loss: 0.0014, G loss: 16.5670\n",
      "[164/1762] D loss: 1.4332, G loss: 0.4860\n",
      "[244/1762] D loss: 0.0256, G loss: 4.4095\n",
      "[324/1762] D loss: 0.0138, G loss: 5.1698\n",
      "[404/1762] D loss: 1.3963, G loss: 0.6454\n",
      "[484/1762] D loss: 0.0068, G loss: 5.9099\n",
      "[564/1762] D loss: 1.3965, G loss: 0.6154\n",
      "[644/1762] D loss: 0.0035, G loss: 7.6199\n",
      "[724/1762] D loss: 0.0042, G loss: 7.1708\n",
      "[804/1762] D loss: 1.3875, G loss: 0.7025\n",
      "[884/1762] D loss: 1.4134, G loss: 0.8390\n",
      "[964/1762] D loss: 1.3876, G loss: 0.6934\n",
      "[1044/1762] D loss: 1.3887, G loss: 0.6760\n",
      "[1124/1762] D loss: 1.3895, G loss: 0.7471\n",
      "[1204/1762] D loss: 0.0048, G loss: 7.4327\n",
      "[1284/1762] D loss: 1.3961, G loss: 0.6598\n",
      "[1364/1762] D loss: 1.3919, G loss: 0.7473\n",
      "[1444/1762] D loss: 1.3909, G loss: 0.7075\n",
      "[1524/1762] D loss: 0.0103, G loss: 6.5142\n",
      "[1604/1762] D loss: 1.4210, G loss: 0.5257\n",
      "[1684/1762] D loss: 1.3951, G loss: 0.6057\n",
      "[1762/1762] D loss: 1.3908, G loss: 0.6365\n",
      "train error: \n",
      " D loss: 4.406107, G loss: 0.248628, D accuracy: 46.6%, cell accuracy: 99.9%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 5.074277, G loss: 0.271071, D accuracy: 45.7%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3974, G loss: 0.6128\n",
      "[84/1762] D loss: 1.3497, G loss: 0.5999\n",
      "[164/1762] D loss: 1.3993, G loss: 0.6331\n",
      "[244/1762] D loss: 1.4241, G loss: 0.5721\n",
      "[324/1762] D loss: 0.0067, G loss: 6.3772\n",
      "[404/1762] D loss: 1.3994, G loss: 0.5627\n",
      "[484/1762] D loss: 1.4042, G loss: 0.5979\n",
      "[564/1762] D loss: 1.3886, G loss: 0.6601\n",
      "[644/1762] D loss: 0.0054, G loss: 6.7501\n",
      "[724/1762] D loss: 1.3910, G loss: 0.7333\n",
      "[804/1762] D loss: 0.0037, G loss: 7.5406\n",
      "[884/1762] D loss: 1.1425, G loss: 2.0695\n",
      "[964/1762] D loss: 1.4103, G loss: 0.7783\n",
      "[1044/1762] D loss: 1.4074, G loss: 0.7348\n",
      "[1124/1762] D loss: 1.3924, G loss: 0.7465\n",
      "[1204/1762] D loss: 1.3883, G loss: 0.6688\n",
      "[1284/1762] D loss: 0.0017, G loss: 17.6626\n",
      "[1364/1762] D loss: 1.3921, G loss: 0.6419\n",
      "[1444/1762] D loss: 0.0024, G loss: 23.5223\n",
      "[1524/1762] D loss: 1.3890, G loss: 0.7287\n",
      "[1604/1762] D loss: 1.3878, G loss: 0.7109\n",
      "[1684/1762] D loss: 1.3877, G loss: 0.6890\n",
      "[1762/1762] D loss: 1.3880, G loss: 0.7310\n",
      "train error: \n",
      " D loss: 4.158741, G loss: 0.568275, D accuracy: 47.1%, cell accuracy: 99.8%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 4.855099, G loss: 0.565233, D accuracy: 46.2%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0168, G loss: 5.4196\n",
      "[84/1762] D loss: 1.3917, G loss: 0.6500\n",
      "[164/1762] D loss: 1.3865, G loss: 0.6697\n",
      "[244/1762] D loss: 0.0110, G loss: 6.4394\n",
      "[324/1762] D loss: 0.0067, G loss: 6.8929\n",
      "[404/1762] D loss: 1.3905, G loss: 0.7263\n",
      "[484/1762] D loss: 1.3868, G loss: 0.6945\n",
      "[564/1762] D loss: 0.0130, G loss: 5.3554\n",
      "[644/1762] D loss: 0.0447, G loss: 4.4085\n",
      "[724/1762] D loss: 1.3878, G loss: 0.7920\n",
      "[804/1762] D loss: 1.3880, G loss: 0.7162\n",
      "[884/1762] D loss: 1.3900, G loss: 0.6729\n",
      "[964/1762] D loss: 1.4057, G loss: 0.5959\n",
      "[1044/1762] D loss: 0.0239, G loss: 4.5705\n",
      "[1124/1762] D loss: 0.0299, G loss: 4.5451\n",
      "[1204/1762] D loss: 0.0281, G loss: 5.3719\n",
      "[1284/1762] D loss: 1.3933, G loss: 0.6624\n",
      "[1364/1762] D loss: 0.0025, G loss: 10.8969\n",
      "[1444/1762] D loss: 1.3884, G loss: 0.6825\n",
      "[1524/1762] D loss: 1.4152, G loss: 0.5437\n",
      "[1604/1762] D loss: 1.3554, G loss: 1.5090\n",
      "[1684/1762] D loss: 0.0103, G loss: 6.9043\n",
      "[1762/1762] D loss: 1.3968, G loss: 0.7328\n",
      "train error: \n",
      " D loss: 3.732010, G loss: 0.209952, D accuracy: 46.8%, cell accuracy: 99.8%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 4.165655, G loss: 0.214385, D accuracy: 46.1%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3874, G loss: 0.6746\n",
      "[84/1762] D loss: 1.4435, G loss: 0.5257\n",
      "[164/1762] D loss: 1.2749, G loss: 0.9498\n",
      "[244/1762] D loss: 1.3957, G loss: 0.7182\n",
      "[324/1762] D loss: 1.3879, G loss: 0.7140\n",
      "[404/1762] D loss: 1.4044, G loss: 0.8726\n",
      "[484/1762] D loss: 1.3963, G loss: 0.7934\n",
      "[564/1762] D loss: 1.3931, G loss: 0.7566\n",
      "[644/1762] D loss: 0.0014, G loss: 20.4529\n",
      "[724/1762] D loss: 1.3910, G loss: 0.6234\n",
      "[804/1762] D loss: 1.3894, G loss: 0.6616\n",
      "[884/1762] D loss: 0.0044, G loss: 8.0137\n",
      "[964/1762] D loss: 1.3879, G loss: 0.7181\n",
      "[1044/1762] D loss: 1.3887, G loss: 0.7407\n",
      "[1124/1762] D loss: 0.0176, G loss: 6.9912\n",
      "[1204/1762] D loss: 1.3938, G loss: 0.6283\n",
      "[1284/1762] D loss: 1.3889, G loss: 0.6536\n",
      "[1364/1762] D loss: 0.0074, G loss: 6.0683\n",
      "[1444/1762] D loss: 1.3869, G loss: 0.6933\n",
      "[1524/1762] D loss: 0.0010, G loss: 20.9516\n",
      "[1604/1762] D loss: 1.3883, G loss: 0.7198\n",
      "[1684/1762] D loss: 1.3894, G loss: 0.7458\n",
      "[1762/1762] D loss: 1.3993, G loss: 0.7747\n",
      "train error: \n",
      " D loss: 4.517173, G loss: 0.323112, D accuracy: 46.9%, cell accuracy: 99.8%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 5.241688, G loss: 0.327624, D accuracy: 46.0%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3894, G loss: 0.6882\n",
      "[84/1762] D loss: 1.3985, G loss: 0.5964\n",
      "[164/1762] D loss: 1.3907, G loss: 0.6521\n",
      "[244/1762] D loss: 1.3871, G loss: 0.7172\n",
      "[324/1762] D loss: 1.3883, G loss: 0.6444\n",
      "[404/1762] D loss: 1.3892, G loss: 0.7571\n",
      "[484/1762] D loss: 0.0068, G loss: 6.8823\n",
      "[564/1762] D loss: 1.3868, G loss: 0.6853\n",
      "[644/1762] D loss: 0.0012, G loss: 21.4625\n",
      "[724/1762] D loss: 1.3901, G loss: 0.6442\n",
      "[804/1762] D loss: 1.3877, G loss: 0.6892\n",
      "[884/1762] D loss: 1.3873, G loss: 0.6923\n",
      "[964/1762] D loss: 1.3868, G loss: 0.6856\n",
      "[1044/1762] D loss: 1.3817, G loss: 0.6847\n",
      "[1124/1762] D loss: 1.3878, G loss: 0.6575\n",
      "[1204/1762] D loss: 1.3862, G loss: 0.6939\n",
      "[1284/1762] D loss: 1.3912, G loss: 0.7261\n",
      "[1364/1762] D loss: 1.3870, G loss: 0.7387\n",
      "[1444/1762] D loss: 0.0036, G loss: 6.8668\n",
      "[1524/1762] D loss: 1.3888, G loss: 0.6479\n",
      "[1604/1762] D loss: 1.3867, G loss: 0.7042\n",
      "[1684/1762] D loss: 0.0056, G loss: 8.9876\n",
      "[1762/1762] D loss: 0.0004, G loss: 18.6914\n",
      "train error: \n",
      " D loss: 4.637711, G loss: 0.069724, D accuracy: 47.2%, cell accuracy: 99.8%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 4.995942, G loss: 0.081199, D accuracy: 46.2%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5270, G loss: 0.3393\n",
      "[84/1762] D loss: 1.3883, G loss: 0.7089\n",
      "[164/1762] D loss: 1.4462, G loss: 0.5072\n",
      "[244/1762] D loss: 0.0195, G loss: 6.1833\n",
      "[324/1762] D loss: 0.0186, G loss: 5.8160\n",
      "[404/1762] D loss: 1.3945, G loss: 0.6478\n",
      "[484/1762] D loss: 0.0207, G loss: 5.2735\n",
      "[564/1762] D loss: 1.3904, G loss: 0.6441\n",
      "[644/1762] D loss: 0.0062, G loss: 8.3878\n",
      "[724/1762] D loss: 1.4023, G loss: 0.7921\n",
      "[804/1762] D loss: 0.0098, G loss: 4.8426\n",
      "[884/1762] D loss: 1.3920, G loss: 0.6823\n",
      "[964/1762] D loss: 1.4024, G loss: 0.7940\n",
      "[1044/1762] D loss: 0.0069, G loss: 6.3483\n",
      "[1124/1762] D loss: 1.4112, G loss: 0.5792\n",
      "[1204/1762] D loss: 1.3906, G loss: 0.7660\n",
      "[1284/1762] D loss: 1.3889, G loss: 0.7000\n",
      "[1364/1762] D loss: 0.0056, G loss: 10.7154\n",
      "[1444/1762] D loss: 1.4066, G loss: 0.5564\n",
      "[1524/1762] D loss: 1.3927, G loss: 0.6590\n",
      "[1604/1762] D loss: 0.0020, G loss: 17.8514\n",
      "[1684/1762] D loss: 1.3913, G loss: 0.7578\n",
      "[1762/1762] D loss: 1.4249, G loss: 0.5107\n",
      "train error: \n",
      " D loss: 4.983682, G loss: 0.539249, D accuracy: 47.3%, cell accuracy: 99.8%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 5.895438, G loss: 0.501001, D accuracy: 46.4%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4545, G loss: 0.4819\n",
      "[84/1762] D loss: 0.0291, G loss: 5.0224\n",
      "[164/1762] D loss: 0.0084, G loss: 6.4122\n",
      "[244/1762] D loss: 0.0093, G loss: 11.9247\n",
      "[324/1762] D loss: 0.0099, G loss: 8.1089\n",
      "[404/1762] D loss: 0.0136, G loss: 8.0021\n",
      "[484/1762] D loss: 0.0150, G loss: 5.3086\n",
      "[564/1762] D loss: 0.0249, G loss: 4.1634\n",
      "[644/1762] D loss: 1.4079, G loss: 0.5476\n",
      "[724/1762] D loss: 0.0185, G loss: 4.6031\n",
      "[804/1762] D loss: 1.3911, G loss: 0.6960\n",
      "[884/1762] D loss: 0.0097, G loss: 12.4199\n",
      "[964/1762] D loss: 0.0026, G loss: 24.2092\n",
      "[1044/1762] D loss: 1.3919, G loss: 0.6532\n",
      "[1124/1762] D loss: 1.3872, G loss: 0.6787\n",
      "[1204/1762] D loss: 1.3893, G loss: 0.7233\n",
      "[1284/1762] D loss: 0.0021, G loss: 11.1318\n",
      "[1364/1762] D loss: 0.0058, G loss: 7.2632\n",
      "[1444/1762] D loss: 1.3870, G loss: 0.7177\n",
      "[1524/1762] D loss: 1.3929, G loss: 0.7936\n",
      "[1604/1762] D loss: 1.3938, G loss: 0.6087\n",
      "[1684/1762] D loss: 1.3390, G loss: 0.6814\n",
      "[1762/1762] D loss: 1.3908, G loss: 0.6851\n",
      "train error: \n",
      " D loss: 5.076502, G loss: 0.240098, D accuracy: 46.9%, cell accuracy: 99.8%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 5.827285, G loss: 0.266996, D accuracy: 46.1%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3853, G loss: 0.6940\n",
      "[84/1762] D loss: 1.3895, G loss: 0.6965\n",
      "[164/1762] D loss: 1.3129, G loss: 0.7629\n",
      "[244/1762] D loss: 1.3908, G loss: 0.7501\n",
      "[324/1762] D loss: 1.3914, G loss: 0.7654\n",
      "[404/1762] D loss: 1.3870, G loss: 0.7281\n",
      "[484/1762] D loss: 1.3879, G loss: 0.7069\n",
      "[564/1762] D loss: 1.3904, G loss: 0.7423\n",
      "[644/1762] D loss: 1.3890, G loss: 0.7361\n",
      "[724/1762] D loss: 1.3876, G loss: 0.6934\n",
      "[804/1762] D loss: 1.3868, G loss: 0.6655\n",
      "[884/1762] D loss: 1.3898, G loss: 0.7333\n",
      "[964/1762] D loss: 1.3900, G loss: 0.7397\n",
      "[1044/1762] D loss: 0.0055, G loss: 7.2980\n",
      "[1124/1762] D loss: 1.3866, G loss: 0.7107\n",
      "[1204/1762] D loss: 1.3875, G loss: 0.6962\n",
      "[1284/1762] D loss: 1.3851, G loss: 0.7469\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6994\n",
      "[1444/1762] D loss: 1.3874, G loss: 0.6885\n",
      "[1524/1762] D loss: 1.3890, G loss: 0.7172\n",
      "[1604/1762] D loss: 1.3868, G loss: 0.6480\n",
      "[1684/1762] D loss: 1.3913, G loss: 0.7358\n",
      "[1762/1762] D loss: 1.3882, G loss: 0.6975\n",
      "train error: \n",
      " D loss: 5.085119, G loss: 0.098531, D accuracy: 46.5%, cell accuracy: 99.8%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 5.667647, G loss: 0.098148, D accuracy: 45.5%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3857, G loss: 0.6879\n",
      "[84/1762] D loss: 1.3867, G loss: 0.7371\n",
      "[164/1762] D loss: 0.0066, G loss: 9.0798\n",
      "[244/1762] D loss: 0.0064, G loss: 11.0407\n",
      "[324/1762] D loss: 0.0062, G loss: 6.2287\n",
      "[404/1762] D loss: 1.3878, G loss: 0.6545\n",
      "[484/1762] D loss: 0.0018, G loss: 20.5022\n",
      "[564/1762] D loss: 1.3798, G loss: 0.7248\n",
      "[644/1762] D loss: 1.3869, G loss: 0.6916\n",
      "[724/1762] D loss: 1.3879, G loss: 0.6805\n",
      "[804/1762] D loss: 1.3975, G loss: 0.5872\n",
      "[884/1762] D loss: 1.3862, G loss: 0.6810\n",
      "[964/1762] D loss: 1.3887, G loss: 0.7375\n",
      "[1044/1762] D loss: 0.0035, G loss: 9.0648\n",
      "[1124/1762] D loss: 1.3876, G loss: 0.6965\n",
      "[1204/1762] D loss: 1.3867, G loss: 0.6823\n",
      "[1284/1762] D loss: 1.3867, G loss: 0.6622\n",
      "[1364/1762] D loss: 1.3873, G loss: 0.7173\n",
      "[1444/1762] D loss: 1.3869, G loss: 0.7028\n",
      "[1524/1762] D loss: 1.3865, G loss: 0.6878\n",
      "[1604/1762] D loss: 0.0019, G loss: 8.9059\n",
      "[1684/1762] D loss: 1.3872, G loss: 0.7101\n",
      "[1762/1762] D loss: 1.3912, G loss: 0.7464\n",
      "train error: \n",
      " D loss: 7.270929, G loss: 0.422935, D accuracy: 46.9%, cell accuracy: 99.8%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 8.687530, G loss: 0.417685, D accuracy: 45.8%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3871, G loss: 0.7108\n",
      "[84/1762] D loss: 1.3839, G loss: 0.7341\n",
      "[164/1762] D loss: 1.3832, G loss: 0.7127\n",
      "[244/1762] D loss: 1.4143, G loss: 0.5390\n",
      "[324/1762] D loss: 1.3880, G loss: 0.6767\n",
      "[404/1762] D loss: 1.3848, G loss: 0.6964\n",
      "[484/1762] D loss: 0.0022, G loss: 7.2544\n",
      "[564/1762] D loss: 1.3862, G loss: 0.6617\n",
      "[644/1762] D loss: 1.4146, G loss: 0.8410\n",
      "[724/1762] D loss: 1.3887, G loss: 0.5967\n",
      "[804/1762] D loss: 1.3883, G loss: 0.6973\n",
      "[884/1762] D loss: 1.3906, G loss: 0.6720\n",
      "[964/1762] D loss: 1.3894, G loss: 0.6819\n",
      "[1044/1762] D loss: 1.3873, G loss: 0.6698\n",
      "[1124/1762] D loss: 1.3922, G loss: 0.6553\n",
      "[1204/1762] D loss: 1.3896, G loss: 0.7519\n",
      "[1284/1762] D loss: 1.3886, G loss: 0.7065\n",
      "[1364/1762] D loss: 1.3892, G loss: 0.6843\n",
      "[1444/1762] D loss: 1.3892, G loss: 0.6636\n",
      "[1524/1762] D loss: 1.3868, G loss: 0.6839\n",
      "[1604/1762] D loss: 1.3902, G loss: 0.6806\n",
      "[1684/1762] D loss: 0.0007, G loss: 26.0785\n",
      "[1762/1762] D loss: 1.3920, G loss: 0.6396\n",
      "train error: \n",
      " D loss: 8.589031, G loss: 0.715515, D accuracy: 49.4%, cell accuracy: 99.8%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 10.376600, G loss: 0.969197, D accuracy: 50.0%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0267, G loss: 7.4555\n",
      "[84/1762] D loss: 1.4057, G loss: 0.6665\n",
      "[164/1762] D loss: 1.3882, G loss: 0.6706\n",
      "[244/1762] D loss: 1.4009, G loss: 0.6986\n",
      "[324/1762] D loss: 1.4257, G loss: 0.5665\n",
      "[404/1762] D loss: 1.3980, G loss: 0.6013\n",
      "[484/1762] D loss: 1.3852, G loss: 0.6745\n",
      "[564/1762] D loss: 1.3922, G loss: 0.6162\n",
      "[644/1762] D loss: 1.4021, G loss: 0.5992\n",
      "[724/1762] D loss: 1.3891, G loss: 0.6792\n",
      "[804/1762] D loss: 1.3897, G loss: 0.6670\n",
      "[884/1762] D loss: 1.3979, G loss: 0.5869\n",
      "[964/1762] D loss: 1.3939, G loss: 0.6096\n",
      "[1044/1762] D loss: 1.3917, G loss: 0.7677\n",
      "[1124/1762] D loss: 0.0058, G loss: 7.2082\n",
      "[1204/1762] D loss: 0.0094, G loss: 10.5102\n",
      "[1284/1762] D loss: 0.0061, G loss: 6.2778\n",
      "[1364/1762] D loss: 1.3829, G loss: 0.7201\n",
      "[1444/1762] D loss: 0.0087, G loss: 7.2132\n",
      "[1524/1762] D loss: 1.3956, G loss: 0.7873\n",
      "[1604/1762] D loss: 0.0085, G loss: 6.4240\n",
      "[1684/1762] D loss: 1.3844, G loss: 0.6680\n",
      "[1762/1762] D loss: 1.3874, G loss: 0.7046\n",
      "train error: \n",
      " D loss: 6.367306, G loss: 0.108490, D accuracy: 46.5%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 7.317415, G loss: 0.107642, D accuracy: 45.5%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3894, G loss: 0.6510\n",
      "[84/1762] D loss: 0.0067, G loss: 7.0194\n",
      "[164/1762] D loss: 0.0013, G loss: 22.6751\n",
      "[244/1762] D loss: 1.3885, G loss: 0.7312\n",
      "[324/1762] D loss: 1.3878, G loss: 0.6994\n",
      "[404/1762] D loss: 1.3872, G loss: 0.7169\n",
      "[484/1762] D loss: 1.3851, G loss: 0.7078\n",
      "[564/1762] D loss: 1.3898, G loss: 0.6668\n",
      "[644/1762] D loss: 1.3874, G loss: 0.6669\n",
      "[724/1762] D loss: 1.3878, G loss: 0.6833\n",
      "[804/1762] D loss: 0.0032, G loss: 7.4978\n",
      "[884/1762] D loss: 0.0065, G loss: 4.4292\n",
      "[964/1762] D loss: 1.3875, G loss: 0.6585\n",
      "[1044/1762] D loss: 0.0449, G loss: 4.0537\n",
      "[1124/1762] D loss: 1.3981, G loss: 0.6305\n",
      "[1204/1762] D loss: 1.3909, G loss: 0.7620\n",
      "[1284/1762] D loss: 0.0525, G loss: 3.9219\n",
      "[1364/1762] D loss: 1.4014, G loss: 0.6256\n",
      "[1444/1762] D loss: 1.3942, G loss: 0.7763\n",
      "[1524/1762] D loss: 1.3886, G loss: 0.6901\n",
      "[1604/1762] D loss: 1.5330, G loss: 0.4346\n",
      "[1684/1762] D loss: 1.3983, G loss: 0.6528\n",
      "[1762/1762] D loss: 1.3875, G loss: 0.6879\n",
      "train error: \n",
      " D loss: 5.667716, G loss: 0.329638, D accuracy: 47.1%, cell accuracy: 99.8%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 6.616885, G loss: 0.334172, D accuracy: 45.9%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3935, G loss: 0.6407\n",
      "[84/1762] D loss: 1.4501, G loss: 0.9186\n",
      "[164/1762] D loss: 1.4386, G loss: 0.5192\n",
      "[244/1762] D loss: 1.3899, G loss: 0.6658\n",
      "[324/1762] D loss: 1.2932, G loss: 0.7329\n",
      "[404/1762] D loss: 1.3738, G loss: 0.7251\n",
      "[484/1762] D loss: 1.3776, G loss: 0.6677\n",
      "[564/1762] D loss: 0.1749, G loss: 3.6150\n",
      "[644/1762] D loss: 1.4102, G loss: 0.5862\n",
      "[724/1762] D loss: 0.1597, G loss: 2.0622\n",
      "[804/1762] D loss: 1.2312, G loss: 1.4268\n",
      "[884/1762] D loss: 0.0800, G loss: 4.2903\n",
      "[964/1762] D loss: 1.5057, G loss: 0.9943\n",
      "[1044/1762] D loss: 1.4680, G loss: 0.9622\n",
      "[1124/1762] D loss: 1.3661, G loss: 0.6972\n",
      "[1204/1762] D loss: 1.3886, G loss: 0.6875\n",
      "[1284/1762] D loss: 1.3899, G loss: 0.7654\n",
      "[1364/1762] D loss: 1.3897, G loss: 0.7083\n",
      "[1444/1762] D loss: 1.3944, G loss: 0.6387\n",
      "[1524/1762] D loss: 1.3826, G loss: 0.6609\n",
      "[1604/1762] D loss: 1.4021, G loss: 0.6002\n",
      "[1684/1762] D loss: 1.3951, G loss: 0.7638\n",
      "[1762/1762] D loss: 1.3958, G loss: 0.6225\n",
      "train error: \n",
      " D loss: 6.961566, G loss: 0.201465, D accuracy: 46.7%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 8.144579, G loss: 0.199742, D accuracy: 45.7%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3856, G loss: 0.6998\n",
      "[84/1762] D loss: 0.0511, G loss: 3.1362\n",
      "[164/1762] D loss: 1.3990, G loss: 0.7720\n",
      "[244/1762] D loss: 1.4000, G loss: 0.7351\n",
      "[324/1762] D loss: 1.4039, G loss: 0.6169\n",
      "[404/1762] D loss: 1.3913, G loss: 0.8015\n",
      "[484/1762] D loss: 1.3935, G loss: 0.6199\n",
      "[564/1762] D loss: 0.0004, G loss: 13.4428\n",
      "[644/1762] D loss: 1.3867, G loss: 0.6766\n",
      "[724/1762] D loss: 1.3923, G loss: 0.6420\n",
      "[804/1762] D loss: 1.4771, G loss: 0.8998\n",
      "[884/1762] D loss: 1.4047, G loss: 0.5818\n",
      "[964/1762] D loss: 1.3895, G loss: 0.7523\n",
      "[1044/1762] D loss: 0.0373, G loss: 3.4593\n",
      "[1124/1762] D loss: 1.3879, G loss: 0.7119\n",
      "[1204/1762] D loss: 1.3878, G loss: 0.7211\n",
      "[1284/1762] D loss: 1.3838, G loss: 0.6827\n",
      "[1364/1762] D loss: 1.3961, G loss: 0.7339\n",
      "[1444/1762] D loss: 1.3877, G loss: 0.6743\n",
      "[1524/1762] D loss: 0.0226, G loss: 4.0581\n",
      "[1604/1762] D loss: 0.0334, G loss: 3.4015\n",
      "[1684/1762] D loss: 1.3879, G loss: 0.6719\n",
      "[1762/1762] D loss: 0.0001, G loss: 13.7678\n",
      "train error: \n",
      " D loss: 6.407866, G loss: 0.002978, D accuracy: 47.8%, cell accuracy: 99.8%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 6.382202, G loss: 0.003036, D accuracy: 47.7%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4113, G loss: 0.5711\n",
      "[84/1762] D loss: 1.3875, G loss: 0.7268\n",
      "[164/1762] D loss: 1.3874, G loss: 0.6946\n",
      "[244/1762] D loss: 1.3895, G loss: 0.6681\n",
      "[324/1762] D loss: 0.0312, G loss: 3.7166\n",
      "[404/1762] D loss: 1.3866, G loss: 1.0611\n",
      "[484/1762] D loss: 0.8348, G loss: 2.3049\n",
      "[564/1762] D loss: 1.3833, G loss: 0.8487\n",
      "[644/1762] D loss: 1.2192, G loss: 0.8769\n",
      "[724/1762] D loss: 0.2242, G loss: 1.9052\n",
      "[804/1762] D loss: 1.3927, G loss: 0.7078\n",
      "[884/1762] D loss: 1.4541, G loss: 0.5276\n",
      "[964/1762] D loss: 1.4002, G loss: 0.7776\n",
      "[1044/1762] D loss: 1.3896, G loss: 0.7879\n",
      "[1124/1762] D loss: 0.0301, G loss: 3.7809\n",
      "[1204/1762] D loss: 1.4030, G loss: 0.7888\n",
      "[1284/1762] D loss: 1.4226, G loss: 0.8136\n",
      "[1364/1762] D loss: 1.3871, G loss: 0.6887\n",
      "[1444/1762] D loss: 1.3858, G loss: 0.7177\n",
      "[1524/1762] D loss: 1.3848, G loss: 0.7163\n",
      "[1604/1762] D loss: 1.4224, G loss: 0.5170\n",
      "[1684/1762] D loss: 1.4016, G loss: 0.6077\n",
      "[1762/1762] D loss: 1.4358, G loss: 0.8288\n",
      "train error: \n",
      " D loss: 6.880175, G loss: 0.022368, D accuracy: 46.6%, cell accuracy: 99.8%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 7.443056, G loss: 0.024064, D accuracy: 45.7%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3869, G loss: 0.6745\n",
      "[84/1762] D loss: 1.3971, G loss: 0.7142\n",
      "[164/1762] D loss: 1.3974, G loss: 0.6709\n",
      "[244/1762] D loss: 1.3723, G loss: 0.6069\n",
      "[324/1762] D loss: 1.3889, G loss: 0.6566\n",
      "[404/1762] D loss: 1.3885, G loss: 0.7061\n",
      "[484/1762] D loss: 1.4259, G loss: 0.5542\n",
      "[564/1762] D loss: 1.3884, G loss: 0.7341\n",
      "[644/1762] D loss: 0.0281, G loss: 3.7771\n",
      "[724/1762] D loss: 1.3875, G loss: 0.6394\n",
      "[804/1762] D loss: 1.3891, G loss: 0.6942\n",
      "[884/1762] D loss: 1.4091, G loss: 0.7440\n",
      "[964/1762] D loss: 1.3931, G loss: 0.7429\n",
      "[1044/1762] D loss: 1.3844, G loss: 0.6867\n",
      "[1124/1762] D loss: 0.0275, G loss: 3.7876\n",
      "[1204/1762] D loss: 1.3890, G loss: 0.7297\n",
      "[1284/1762] D loss: 1.3846, G loss: 0.7025\n",
      "[1364/1762] D loss: 1.3860, G loss: 0.6326\n",
      "[1444/1762] D loss: 1.3919, G loss: 0.6428\n",
      "[1524/1762] D loss: 1.3950, G loss: 0.6382\n",
      "[1604/1762] D loss: 1.3854, G loss: 0.6820\n",
      "[1684/1762] D loss: 1.3884, G loss: 0.6652\n",
      "[1762/1762] D loss: 1.3890, G loss: 0.7107\n",
      "train error: \n",
      " D loss: 8.262374, G loss: 0.086809, D accuracy: 46.7%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 9.596446, G loss: 0.077723, D accuracy: 45.6%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3985, G loss: 0.7579\n",
      "[84/1762] D loss: 1.3866, G loss: 0.6992\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6849\n",
      "[244/1762] D loss: 0.0231, G loss: 3.9726\n",
      "[324/1762] D loss: 1.3892, G loss: 0.6629\n",
      "[404/1762] D loss: 1.3911, G loss: 0.7861\n",
      "[484/1762] D loss: 0.0180, G loss: 3.9446\n",
      "[564/1762] D loss: 1.3915, G loss: 0.6835\n",
      "[644/1762] D loss: 1.4123, G loss: 0.7471\n",
      "[724/1762] D loss: 1.3873, G loss: 0.6431\n",
      "[804/1762] D loss: 1.3920, G loss: 0.6848\n",
      "[884/1762] D loss: 1.3861, G loss: 0.6926\n",
      "[964/1762] D loss: 1.3884, G loss: 0.6597\n",
      "[1044/1762] D loss: 1.3987, G loss: 0.6358\n",
      "[1124/1762] D loss: 1.3875, G loss: 0.6720\n",
      "[1204/1762] D loss: 1.3876, G loss: 0.7020\n",
      "[1284/1762] D loss: 1.3903, G loss: 0.7685\n",
      "[1364/1762] D loss: 1.3928, G loss: 0.6992\n",
      "[1444/1762] D loss: 1.3869, G loss: 0.7059\n",
      "[1524/1762] D loss: 0.0625, G loss: 3.8651\n",
      "[1604/1762] D loss: 1.3877, G loss: 0.6671\n",
      "[1684/1762] D loss: 1.3899, G loss: 0.6366\n",
      "[1762/1762] D loss: 1.3911, G loss: 0.7040\n",
      "train error: \n",
      " D loss: 7.713459, G loss: 0.048382, D accuracy: 46.7%, cell accuracy: 99.8%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 8.690787, G loss: 0.047275, D accuracy: 45.8%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0221, G loss: 3.8037\n",
      "[84/1762] D loss: 1.3868, G loss: 0.6912\n",
      "[164/1762] D loss: 1.3916, G loss: 0.7354\n",
      "[244/1762] D loss: 1.4193, G loss: 0.8372\n",
      "[324/1762] D loss: 1.3909, G loss: 0.6771\n",
      "[404/1762] D loss: 1.3927, G loss: 0.7223\n",
      "[484/1762] D loss: 1.3916, G loss: 0.6832\n",
      "[564/1762] D loss: 1.3868, G loss: 0.7105\n",
      "[644/1762] D loss: 1.3957, G loss: 0.6179\n",
      "[724/1762] D loss: 1.3901, G loss: 0.7262\n",
      "[804/1762] D loss: 1.4269, G loss: 0.5610\n",
      "[884/1762] D loss: 1.3866, G loss: 0.6987\n",
      "[964/1762] D loss: 1.3815, G loss: 0.7033\n",
      "[1044/1762] D loss: 1.3888, G loss: 0.6854\n",
      "[1124/1762] D loss: 1.4318, G loss: 0.5703\n",
      "[1204/1762] D loss: 1.4176, G loss: 0.5972\n",
      "[1284/1762] D loss: 1.4048, G loss: 0.7575\n",
      "[1364/1762] D loss: 1.3841, G loss: 0.6827\n",
      "[1444/1762] D loss: 1.3978, G loss: 0.7532\n",
      "[1524/1762] D loss: 0.0430, G loss: 6.0687\n",
      "[1604/1762] D loss: 1.3916, G loss: 0.7322\n",
      "[1684/1762] D loss: 0.0002, G loss: 14.4978\n",
      "[1762/1762] D loss: 1.4117, G loss: 0.6252\n",
      "train error: \n",
      " D loss: 8.011738, G loss: 0.091616, D accuracy: 46.7%, cell accuracy: 99.9%, board accuracy: 92.8% \n",
      "\n",
      "test error: \n",
      " D loss: 9.312200, G loss: 0.085483, D accuracy: 45.5%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3883, G loss: 0.7004\n",
      "[84/1762] D loss: 1.3874, G loss: 0.6894\n",
      "[164/1762] D loss: 1.3954, G loss: 0.7802\n",
      "[244/1762] D loss: 1.4494, G loss: 0.9635\n",
      "[324/1762] D loss: 1.4053, G loss: 0.7745\n",
      "[404/1762] D loss: 1.4010, G loss: 0.7888\n",
      "[484/1762] D loss: 1.3874, G loss: 0.7281\n",
      "[564/1762] D loss: 1.3865, G loss: 0.6614\n",
      "[644/1762] D loss: 1.3903, G loss: 0.7381\n",
      "[724/1762] D loss: 0.0080, G loss: 5.0756\n",
      "[804/1762] D loss: 1.3867, G loss: 0.7012\n",
      "[884/1762] D loss: 1.4681, G loss: 0.4821\n",
      "[964/1762] D loss: 1.4003, G loss: 0.7823\n",
      "[1044/1762] D loss: 1.3956, G loss: 0.6626\n",
      "[1124/1762] D loss: 1.3982, G loss: 0.5781\n",
      "[1204/1762] D loss: 1.3857, G loss: 0.6620\n",
      "[1284/1762] D loss: 0.0169, G loss: 5.1201\n",
      "[1364/1762] D loss: 1.3914, G loss: 0.6945\n",
      "[1444/1762] D loss: 1.3940, G loss: 0.6206\n",
      "[1524/1762] D loss: 1.3923, G loss: 0.6180\n",
      "[1604/1762] D loss: 0.0166, G loss: 4.2733\n",
      "[1684/1762] D loss: 1.3935, G loss: 0.6413\n",
      "[1762/1762] D loss: 1.3944, G loss: 0.6475\n",
      "train error: \n",
      " D loss: 8.183688, G loss: 0.174827, D accuracy: 46.9%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 9.613687, G loss: 0.207136, D accuracy: 45.8%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0117, G loss: 4.8320\n",
      "[84/1762] D loss: 1.3875, G loss: 0.7321\n",
      "[164/1762] D loss: 1.3897, G loss: 0.6562\n",
      "[244/1762] D loss: 1.3972, G loss: 0.7709\n",
      "[324/1762] D loss: 1.3932, G loss: 0.7740\n",
      "[404/1762] D loss: 1.3936, G loss: 0.7876\n",
      "[484/1762] D loss: 1.4892, G loss: 1.0264\n",
      "[564/1762] D loss: 0.0150, G loss: 4.3980\n",
      "[644/1762] D loss: 0.0073, G loss: 5.1502\n",
      "[724/1762] D loss: 1.3921, G loss: 0.7174\n",
      "[804/1762] D loss: 1.3946, G loss: 0.6751\n",
      "[884/1762] D loss: 0.0192, G loss: 3.9261\n",
      "[964/1762] D loss: 0.0003, G loss: 16.1007\n",
      "[1044/1762] D loss: 1.3974, G loss: 0.7466\n",
      "[1124/1762] D loss: 0.0095, G loss: 5.5347\n",
      "[1204/1762] D loss: 1.3870, G loss: 0.6768\n",
      "[1284/1762] D loss: 0.0067, G loss: 5.2105\n",
      "[1364/1762] D loss: 1.3885, G loss: 0.7290\n",
      "[1444/1762] D loss: 1.3976, G loss: 0.8197\n",
      "[1524/1762] D loss: 1.3848, G loss: 0.7403\n",
      "[1604/1762] D loss: 1.3935, G loss: 0.5995\n",
      "[1684/1762] D loss: 1.3889, G loss: 0.7191\n",
      "[1762/1762] D loss: 1.3872, G loss: 0.7437\n",
      "train error: \n",
      " D loss: 10.243903, G loss: 0.583914, D accuracy: 47.6%, cell accuracy: 99.8%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 12.390136, G loss: 0.707152, D accuracy: 46.7%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4072, G loss: 0.7616\n",
      "[84/1762] D loss: 0.0190, G loss: 4.0050\n",
      "[164/1762] D loss: 0.0046, G loss: 16.0667\n",
      "[244/1762] D loss: 1.3866, G loss: 0.6452\n",
      "[324/1762] D loss: 0.0137, G loss: 4.5540\n",
      "[404/1762] D loss: 1.4204, G loss: 0.8347\n",
      "[484/1762] D loss: 0.0984, G loss: 4.6062\n",
      "[564/1762] D loss: 0.0075, G loss: 5.0215\n",
      "[644/1762] D loss: 1.3914, G loss: 0.7746\n",
      "[724/1762] D loss: 1.3915, G loss: 0.6431\n",
      "[804/1762] D loss: 0.0069, G loss: 5.5487\n",
      "[884/1762] D loss: 1.4236, G loss: 0.7572\n",
      "[964/1762] D loss: 1.3936, G loss: 0.7660\n",
      "[1044/1762] D loss: 1.3912, G loss: 0.7013\n",
      "[1124/1762] D loss: 0.0003, G loss: 19.5725\n",
      "[1204/1762] D loss: 1.3917, G loss: 0.6655\n",
      "[1284/1762] D loss: 1.3915, G loss: 0.7210\n",
      "[1364/1762] D loss: 1.3877, G loss: 0.6709\n",
      "[1444/1762] D loss: 1.3872, G loss: 0.6982\n",
      "[1524/1762] D loss: 1.3891, G loss: 0.7322\n",
      "[1604/1762] D loss: 0.0074, G loss: 5.1160\n",
      "[1684/1762] D loss: 1.3815, G loss: 0.6879\n",
      "[1762/1762] D loss: 1.2403, G loss: 1.0721\n",
      "train error: \n",
      " D loss: 1.341888, G loss: 1.318700, D accuracy: 69.3%, cell accuracy: 98.9%, board accuracy: 31.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.378051, G loss: 1.412103, D accuracy: 69.1%, cell accuracy: 98.9%, board accuracy: 33.0% \n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.4492, G loss: 1.4342\n",
      "[84/1762] D loss: 1.0458, G loss: 1.6607\n",
      "[164/1762] D loss: 0.4922, G loss: 1.8653\n",
      "[244/1762] D loss: 0.2564, G loss: 3.3268\n",
      "[324/1762] D loss: 1.4154, G loss: 0.6256\n",
      "[404/1762] D loss: 1.1678, G loss: 0.8893\n",
      "[484/1762] D loss: 1.3918, G loss: 0.6871\n",
      "[564/1762] D loss: 1.3943, G loss: 0.7397\n",
      "[644/1762] D loss: 1.3952, G loss: 0.6152\n",
      "[724/1762] D loss: 1.3889, G loss: 0.7252\n",
      "[804/1762] D loss: 1.4003, G loss: 0.7204\n",
      "[884/1762] D loss: 1.4012, G loss: 0.5469\n",
      "[964/1762] D loss: 0.4072, G loss: 1.3997\n",
      "[1044/1762] D loss: 1.4323, G loss: 0.8737\n",
      "[1124/1762] D loss: 1.3872, G loss: 0.7234\n",
      "[1204/1762] D loss: 1.3936, G loss: 0.6531\n",
      "[1284/1762] D loss: 1.3938, G loss: 0.6843\n",
      "[1364/1762] D loss: 1.4216, G loss: 0.7661\n",
      "[1444/1762] D loss: 1.4079, G loss: 0.7829\n",
      "[1524/1762] D loss: 1.3894, G loss: 0.7218\n",
      "[1604/1762] D loss: 1.3586, G loss: 0.8139\n",
      "[1684/1762] D loss: 1.3908, G loss: 0.7061\n",
      "[1762/1762] D loss: 1.4099, G loss: 1.5308\n",
      "train error: \n",
      " D loss: 2.594386, G loss: 0.309474, D accuracy: 51.9%, cell accuracy: 99.9%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 2.558598, G loss: 0.388082, D accuracy: 51.9%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3044, G loss: 2.0789\n",
      "[84/1762] D loss: 1.4019, G loss: 0.6806\n",
      "[164/1762] D loss: 0.4493, G loss: 1.4027\n",
      "[244/1762] D loss: 1.3986, G loss: 0.6171\n",
      "[324/1762] D loss: 0.1976, G loss: 4.8712\n",
      "[404/1762] D loss: 0.1958, G loss: 2.0972\n",
      "[484/1762] D loss: 1.0321, G loss: 1.9239\n",
      "[564/1762] D loss: 1.4007, G loss: 0.5827\n",
      "[644/1762] D loss: 1.3966, G loss: 0.6542\n",
      "[724/1762] D loss: 1.4080, G loss: 0.7922\n",
      "[804/1762] D loss: 1.3986, G loss: 0.7700\n",
      "[884/1762] D loss: 1.4018, G loss: 0.7623\n",
      "[964/1762] D loss: 1.4116, G loss: 0.7031\n",
      "[1044/1762] D loss: 1.4197, G loss: 0.5226\n",
      "[1124/1762] D loss: 1.4056, G loss: 0.7412\n",
      "[1204/1762] D loss: 1.4197, G loss: 0.7641\n",
      "[1284/1762] D loss: 1.3881, G loss: 0.7009\n",
      "[1364/1762] D loss: 1.4246, G loss: 0.7200\n",
      "[1444/1762] D loss: 1.3880, G loss: 0.6999\n",
      "[1524/1762] D loss: 1.4015, G loss: 0.5865\n",
      "[1604/1762] D loss: 1.3896, G loss: 0.6287\n",
      "[1684/1762] D loss: 1.1343, G loss: 1.8529\n",
      "[1762/1762] D loss: 1.4611, G loss: 0.4924\n",
      "train error: \n",
      " D loss: 1.480681, G loss: 1.218533, D accuracy: 53.1%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.489641, G loss: 1.291078, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1474, G loss: 2.3619\n",
      "[84/1762] D loss: 1.3996, G loss: 0.6060\n",
      "[164/1762] D loss: 1.3912, G loss: 0.7467\n",
      "[244/1762] D loss: 1.3964, G loss: 0.6788\n",
      "[324/1762] D loss: 1.3890, G loss: 0.6266\n",
      "[404/1762] D loss: 1.3864, G loss: 0.7247\n",
      "[484/1762] D loss: 1.4253, G loss: 0.9145\n",
      "[564/1762] D loss: 1.3886, G loss: 0.7354\n",
      "[644/1762] D loss: 1.3878, G loss: 0.7124\n",
      "[724/1762] D loss: 1.3907, G loss: 0.7398\n",
      "[804/1762] D loss: 0.3289, G loss: 2.1693\n",
      "[884/1762] D loss: 1.4072, G loss: 0.8037\n",
      "[964/1762] D loss: 1.4007, G loss: 0.8133\n",
      "[1044/1762] D loss: 0.4740, G loss: 1.1979\n",
      "[1124/1762] D loss: 0.3371, G loss: 1.6833\n",
      "[1204/1762] D loss: 1.3838, G loss: 0.7100\n",
      "[1284/1762] D loss: 0.1820, G loss: 2.0526\n",
      "[1364/1762] D loss: 1.3979, G loss: 0.6210\n",
      "[1444/1762] D loss: 1.3939, G loss: 0.6386\n",
      "[1524/1762] D loss: 0.1406, G loss: 2.7846\n",
      "[1604/1762] D loss: 1.3846, G loss: 0.7457\n",
      "[1684/1762] D loss: 1.3842, G loss: 0.6551\n",
      "[1762/1762] D loss: 1.3893, G loss: 0.7534\n",
      "train error: \n",
      " D loss: 1.925152, G loss: 0.383975, D accuracy: 48.1%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.920502, G loss: 0.380673, D accuracy: 48.1%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4122, G loss: 0.8464\n",
      "[84/1762] D loss: 0.1018, G loss: 2.8932\n",
      "[164/1762] D loss: 1.4003, G loss: 0.7866\n",
      "[244/1762] D loss: 1.3959, G loss: 0.6699\n",
      "[324/1762] D loss: 1.3864, G loss: 0.6780\n",
      "[404/1762] D loss: 1.3910, G loss: 0.7142\n",
      "[484/1762] D loss: 0.0229, G loss: 4.7156\n",
      "[564/1762] D loss: 1.4035, G loss: 0.6291\n",
      "[644/1762] D loss: 1.3911, G loss: 0.6542\n",
      "[724/1762] D loss: 0.0117, G loss: 20.3496\n",
      "[804/1762] D loss: 0.0170, G loss: 5.0633\n",
      "[884/1762] D loss: 1.4806, G loss: 0.7582\n",
      "[964/1762] D loss: 1.4167, G loss: 0.6537\n",
      "[1044/1762] D loss: 0.6157, G loss: 2.1596\n",
      "[1124/1762] D loss: 1.0389, G loss: 2.0075\n",
      "[1204/1762] D loss: 1.4258, G loss: 0.7909\n",
      "[1284/1762] D loss: 1.3943, G loss: 0.7729\n",
      "[1364/1762] D loss: 0.6682, G loss: 1.6677\n",
      "[1444/1762] D loss: 1.4071, G loss: 0.7962\n",
      "[1524/1762] D loss: 0.5174, G loss: 2.6884\n",
      "[1604/1762] D loss: 1.3962, G loss: 0.7445\n",
      "[1684/1762] D loss: 0.3943, G loss: 2.2627\n",
      "[1762/1762] D loss: 1.3950, G loss: 0.6749\n",
      "train error: \n",
      " D loss: 1.543011, G loss: 0.621176, D accuracy: 51.6%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.522969, G loss: 0.678270, D accuracy: 52.6%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3785, G loss: 1.2180\n",
      "[84/1762] D loss: 1.4242, G loss: 0.8388\n",
      "[164/1762] D loss: 1.4082, G loss: 0.8175\n",
      "[244/1762] D loss: 0.5050, G loss: 2.0038\n",
      "[324/1762] D loss: 1.7291, G loss: 2.1511\n",
      "[404/1762] D loss: 1.3902, G loss: 0.6728\n",
      "[484/1762] D loss: 1.3866, G loss: 0.6949\n",
      "[564/1762] D loss: 1.4001, G loss: 0.6005\n",
      "[644/1762] D loss: 1.3999, G loss: 0.6018\n",
      "[724/1762] D loss: 1.4010, G loss: 0.6671\n",
      "[804/1762] D loss: 1.4206, G loss: 0.5483\n",
      "[884/1762] D loss: 1.3893, G loss: 0.6420\n",
      "[964/1762] D loss: 1.3882, G loss: 0.7128\n",
      "[1044/1762] D loss: 1.3932, G loss: 0.7049\n",
      "[1124/1762] D loss: 1.3921, G loss: 0.6764\n",
      "[1204/1762] D loss: 1.3773, G loss: 0.7043\n",
      "[1284/1762] D loss: 0.4248, G loss: 1.7354\n",
      "[1364/1762] D loss: 1.4072, G loss: 0.7791\n",
      "[1444/1762] D loss: 1.4060, G loss: 0.8283\n",
      "[1524/1762] D loss: 0.2210, G loss: 2.1700\n",
      "[1604/1762] D loss: 0.3515, G loss: 1.8583\n",
      "[1684/1762] D loss: 1.4007, G loss: 0.7551\n",
      "[1762/1762] D loss: 1.3899, G loss: 0.6301\n",
      "train error: \n",
      " D loss: 1.344103, G loss: 0.770689, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.313551, G loss: 0.743927, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4702, G loss: 0.3179\n",
      "[84/1762] D loss: 1.3965, G loss: 0.8075\n",
      "[164/1762] D loss: 1.5737, G loss: 1.5470\n",
      "[244/1762] D loss: 0.4464, G loss: 1.7097\n",
      "[324/1762] D loss: 1.4103, G loss: 0.5563\n",
      "[404/1762] D loss: 1.4175, G loss: 0.7993\n",
      "[484/1762] D loss: 0.2878, G loss: 1.9622\n",
      "[564/1762] D loss: 0.7378, G loss: 1.6446\n",
      "[644/1762] D loss: 1.3908, G loss: 0.7127\n",
      "[724/1762] D loss: 0.4335, G loss: 1.4916\n",
      "[804/1762] D loss: 1.4987, G loss: 1.6456\n",
      "[884/1762] D loss: 1.4128, G loss: 0.6630\n",
      "[964/1762] D loss: 0.5912, G loss: 0.9963\n",
      "[1044/1762] D loss: 0.1739, G loss: 7.3242\n",
      "[1124/1762] D loss: 1.4181, G loss: 0.7535\n",
      "[1204/1762] D loss: 1.4128, G loss: 0.5480\n",
      "[1284/1762] D loss: 2.8821, G loss: 0.1673\n",
      "[1364/1762] D loss: 1.3983, G loss: 0.6363\n",
      "[1444/1762] D loss: 1.9943, G loss: 1.7924\n",
      "[1524/1762] D loss: 1.3873, G loss: 0.6214\n",
      "[1604/1762] D loss: 1.4068, G loss: 0.6174\n",
      "[1684/1762] D loss: 1.3874, G loss: 0.6913\n",
      "[1762/1762] D loss: 1.4291, G loss: 0.5154\n",
      "train error: \n",
      " D loss: 1.485410, G loss: 1.301670, D accuracy: 54.2%, cell accuracy: 99.9%, board accuracy: 90.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.455219, G loss: 1.645650, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8565, G loss: 1.6972\n",
      "[84/1762] D loss: 1.4008, G loss: 0.6011\n",
      "[164/1762] D loss: 1.4753, G loss: 0.4509\n",
      "[244/1762] D loss: 1.3982, G loss: 0.6206\n",
      "[324/1762] D loss: 1.3879, G loss: 0.6961\n",
      "[404/1762] D loss: 1.4294, G loss: 0.8327\n",
      "[484/1762] D loss: 1.3828, G loss: 0.7458\n",
      "[564/1762] D loss: 1.3961, G loss: 0.6031\n",
      "[644/1762] D loss: 1.4171, G loss: 0.5402\n",
      "[724/1762] D loss: 0.5104, G loss: 2.8597\n",
      "[804/1762] D loss: 1.3988, G loss: 0.7512\n",
      "[884/1762] D loss: 1.4293, G loss: 0.7121\n",
      "[964/1762] D loss: 1.4081, G loss: 0.6490\n",
      "[1044/1762] D loss: 1.5017, G loss: 0.9218\n",
      "[1124/1762] D loss: 0.6526, G loss: 1.6679\n",
      "[1204/1762] D loss: 1.4596, G loss: 0.9816\n",
      "[1284/1762] D loss: 1.3993, G loss: 0.6701\n",
      "[1364/1762] D loss: 1.3916, G loss: 0.7683\n",
      "[1444/1762] D loss: 1.4185, G loss: 0.8070\n",
      "[1524/1762] D loss: 1.3997, G loss: 0.5621\n",
      "[1604/1762] D loss: 1.3958, G loss: 0.7613\n",
      "[1684/1762] D loss: 1.4269, G loss: 0.5455\n",
      "[1762/1762] D loss: 1.0512, G loss: 3.3733\n",
      "train error: \n",
      " D loss: 1.383316, G loss: 1.054988, D accuracy: 51.4%, cell accuracy: 99.9%, board accuracy: 90.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.372003, G loss: 1.108168, D accuracy: 50.9%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3881, G loss: 0.6798\n",
      "[84/1762] D loss: 1.3696, G loss: 1.5466\n",
      "[164/1762] D loss: 1.4129, G loss: 0.5797\n",
      "[244/1762] D loss: 1.4302, G loss: 0.5316\n",
      "[324/1762] D loss: 1.4053, G loss: 0.5924\n",
      "[404/1762] D loss: 1.3886, G loss: 0.6719\n",
      "[484/1762] D loss: 1.4511, G loss: 0.6160\n",
      "[564/1762] D loss: 1.3509, G loss: 0.5753\n",
      "[644/1762] D loss: 1.4310, G loss: 0.5398\n",
      "[724/1762] D loss: 1.0562, G loss: 1.4417\n",
      "[804/1762] D loss: 1.3901, G loss: 0.6952\n",
      "[884/1762] D loss: 1.3930, G loss: 0.6292\n",
      "[964/1762] D loss: 1.4060, G loss: 0.5582\n",
      "[1044/1762] D loss: 1.3709, G loss: 0.6680\n",
      "[1124/1762] D loss: 1.4449, G loss: 0.5091\n",
      "[1204/1762] D loss: 1.3551, G loss: 0.6404\n",
      "[1284/1762] D loss: 1.4111, G loss: 0.5565\n",
      "[1364/1762] D loss: 1.1593, G loss: 0.6848\n",
      "[1444/1762] D loss: 1.3961, G loss: 0.6323\n",
      "[1524/1762] D loss: 1.4007, G loss: 0.6062\n",
      "[1604/1762] D loss: 1.4034, G loss: 0.8117\n",
      "[1684/1762] D loss: 0.8111, G loss: 1.1739\n",
      "[1762/1762] D loss: 0.1904, G loss: 10.9687\n",
      "train error: \n",
      " D loss: 1.437651, G loss: 1.002448, D accuracy: 51.9%, cell accuracy: 99.9%, board accuracy: 93.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.411282, G loss: 1.036504, D accuracy: 52.7%, cell accuracy: 99.9%, board accuracy: 91.4% \n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4302, G loss: 0.6566\n",
      "[84/1762] D loss: 0.3523, G loss: 3.5430\n",
      "[164/1762] D loss: 1.3934, G loss: 0.6285\n",
      "[244/1762] D loss: 0.4061, G loss: 3.7347\n",
      "[324/1762] D loss: 1.4762, G loss: 0.4068\n",
      "[404/1762] D loss: 1.3952, G loss: 0.7061\n",
      "[484/1762] D loss: 1.3951, G loss: 0.7111\n",
      "[564/1762] D loss: 1.3884, G loss: 0.6572\n",
      "[644/1762] D loss: 1.3900, G loss: 0.6364\n",
      "[724/1762] D loss: 1.1059, G loss: 1.1217\n",
      "[804/1762] D loss: 1.3594, G loss: 0.6621\n",
      "[884/1762] D loss: 0.8866, G loss: 2.3018\n",
      "[964/1762] D loss: 1.3978, G loss: 0.7286\n",
      "[1044/1762] D loss: 0.9313, G loss: 3.9325\n",
      "[1124/1762] D loss: 1.1903, G loss: 1.2763\n",
      "[1204/1762] D loss: 0.8635, G loss: 1.5650\n",
      "[1284/1762] D loss: 1.3906, G loss: 0.7122\n",
      "[1364/1762] D loss: 0.8047, G loss: 1.7504\n",
      "[1444/1762] D loss: 1.3950, G loss: 0.7104\n",
      "[1524/1762] D loss: 0.7227, G loss: 1.1279\n",
      "[1604/1762] D loss: 1.3986, G loss: 0.6788\n",
      "[1684/1762] D loss: 1.3894, G loss: 0.7047\n",
      "[1762/1762] D loss: 1.3970, G loss: 0.7592\n",
      "train error: \n",
      " D loss: 1.350447, G loss: 0.942184, D accuracy: 53.2%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.315351, G loss: 0.977305, D accuracy: 54.5%, cell accuracy: 99.9%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8214, G loss: 1.4723\n",
      "[84/1762] D loss: 1.4130, G loss: 0.8350\n",
      "[164/1762] D loss: 1.3939, G loss: 0.6687\n",
      "[244/1762] D loss: 1.1547, G loss: 1.0432\n",
      "[324/1762] D loss: 1.4124, G loss: 0.8720\n",
      "[404/1762] D loss: 1.3912, G loss: 0.7472\n",
      "[484/1762] D loss: 1.4178, G loss: 0.8541\n",
      "[564/1762] D loss: 1.3889, G loss: 0.6291\n",
      "[644/1762] D loss: 1.3883, G loss: 0.7194\n",
      "[724/1762] D loss: 0.9796, G loss: 1.5991\n",
      "[804/1762] D loss: 1.4021, G loss: 0.6455\n",
      "[884/1762] D loss: 1.7170, G loss: 1.2798\n",
      "[964/1762] D loss: 1.3919, G loss: 0.6501\n",
      "[1044/1762] D loss: 1.4262, G loss: 0.9780\n",
      "[1124/1762] D loss: 1.5476, G loss: 1.1131\n",
      "[1204/1762] D loss: 1.6092, G loss: 0.4949\n",
      "[1284/1762] D loss: 1.3939, G loss: 0.6143\n",
      "[1364/1762] D loss: 1.3993, G loss: 0.6441\n",
      "[1444/1762] D loss: 1.3891, G loss: 0.7406\n",
      "[1524/1762] D loss: 1.4142, G loss: 0.5669\n",
      "[1604/1762] D loss: 1.4238, G loss: 0.7884\n",
      "[1684/1762] D loss: 1.4030, G loss: 0.7154\n",
      "[1762/1762] D loss: 1.3868, G loss: 0.6889\n",
      "train error: \n",
      " D loss: 1.664759, G loss: 0.522576, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.620914, G loss: 0.604276, D accuracy: 54.4%, cell accuracy: 99.9%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3965, G loss: 0.7035\n",
      "[84/1762] D loss: 1.5036, G loss: 0.3998\n",
      "[164/1762] D loss: 1.3960, G loss: 0.7743\n",
      "[244/1762] D loss: 1.3889, G loss: 0.7081\n",
      "[324/1762] D loss: 1.3897, G loss: 0.6899\n",
      "[404/1762] D loss: 0.6558, G loss: 0.9420\n",
      "[484/1762] D loss: 1.4948, G loss: 1.3220\n",
      "[564/1762] D loss: 1.4059, G loss: 0.5693\n",
      "[644/1762] D loss: 1.3953, G loss: 0.7257\n",
      "[724/1762] D loss: 1.4076, G loss: 0.5952\n",
      "[804/1762] D loss: 1.0519, G loss: 1.4874\n",
      "[884/1762] D loss: 1.3953, G loss: 0.6372\n",
      "[964/1762] D loss: 1.4144, G loss: 0.5493\n",
      "[1044/1762] D loss: 1.3890, G loss: 0.6814\n",
      "[1124/1762] D loss: 1.3963, G loss: 0.7519\n",
      "[1204/1762] D loss: 0.6196, G loss: 1.1546\n",
      "[1284/1762] D loss: 1.3911, G loss: 0.6851\n",
      "[1364/1762] D loss: 1.3994, G loss: 0.6355\n",
      "[1444/1762] D loss: 1.3904, G loss: 0.6268\n",
      "[1524/1762] D loss: 1.6245, G loss: 1.0082\n",
      "[1604/1762] D loss: 0.9052, G loss: 0.8397\n",
      "[1684/1762] D loss: 1.3917, G loss: 0.7044\n",
      "[1762/1762] D loss: 1.3938, G loss: 0.7575\n",
      "train error: \n",
      " D loss: 1.405557, G loss: 0.558224, D accuracy: 53.0%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.386541, G loss: 0.537995, D accuracy: 54.3%, cell accuracy: 99.9%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3913, G loss: 0.6955\n",
      "[84/1762] D loss: 1.4110, G loss: 0.6337\n",
      "[164/1762] D loss: 1.4259, G loss: 0.5442\n",
      "[244/1762] D loss: 0.4139, G loss: 3.4991\n",
      "[324/1762] D loss: 0.9080, G loss: 0.9175\n",
      "[404/1762] D loss: 0.5124, G loss: 1.3115\n",
      "[484/1762] D loss: 1.3947, G loss: 0.6217\n",
      "[564/1762] D loss: 1.7121, G loss: 1.4523\n",
      "[644/1762] D loss: 1.3930, G loss: 0.7076\n",
      "[724/1762] D loss: 1.4085, G loss: 0.5619\n",
      "[804/1762] D loss: 1.4173, G loss: 0.7311\n",
      "[884/1762] D loss: 1.4212, G loss: 0.6037\n",
      "[964/1762] D loss: 1.3913, G loss: 0.6754\n",
      "[1044/1762] D loss: 1.4280, G loss: 0.5379\n",
      "[1124/1762] D loss: 0.9481, G loss: 1.0876\n",
      "[1204/1762] D loss: 0.4400, G loss: 1.3343\n",
      "[1284/1762] D loss: 1.4023, G loss: 0.7158\n",
      "[1364/1762] D loss: 0.3482, G loss: 1.7423\n",
      "[1444/1762] D loss: 1.3985, G loss: 0.7719\n",
      "[1524/1762] D loss: 1.3992, G loss: 0.7118\n",
      "[1604/1762] D loss: 1.3878, G loss: 0.6927\n",
      "[1684/1762] D loss: 1.3997, G loss: 0.6771\n",
      "[1762/1762] D loss: 1.3905, G loss: 0.7308\n",
      "train error: \n",
      " D loss: 1.589553, G loss: 1.469840, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 91.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.543684, G loss: 1.618473, D accuracy: 54.9%, cell accuracy: 99.9%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3900, G loss: 0.7486\n",
      "[84/1762] D loss: 1.4338, G loss: 0.7285\n",
      "[164/1762] D loss: 0.6348, G loss: 2.4406\n",
      "[244/1762] D loss: 1.4162, G loss: 0.5939\n",
      "[324/1762] D loss: 0.4700, G loss: 1.9978\n",
      "[404/1762] D loss: 1.4020, G loss: 0.6291\n",
      "[484/1762] D loss: 1.4052, G loss: 0.6001\n",
      "[564/1762] D loss: 1.0362, G loss: 2.3820\n",
      "[644/1762] D loss: 1.4151, G loss: 0.5949\n",
      "[724/1762] D loss: 0.7081, G loss: 1.0638\n",
      "[804/1762] D loss: 1.3889, G loss: 0.7363\n",
      "[884/1762] D loss: 1.3920, G loss: 0.6618\n",
      "[964/1762] D loss: 1.4285, G loss: 0.8798\n",
      "[1044/1762] D loss: 1.5550, G loss: 1.2309\n",
      "[1124/1762] D loss: 0.5494, G loss: 1.1895\n",
      "[1204/1762] D loss: 1.3920, G loss: 0.6788\n",
      "[1284/1762] D loss: 1.4507, G loss: 0.5420\n",
      "[1364/1762] D loss: 1.4074, G loss: 0.5764\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6062\n",
      "[1524/1762] D loss: 1.3986, G loss: 0.7296\n",
      "[1604/1762] D loss: 0.6065, G loss: 1.9120\n",
      "[1684/1762] D loss: 0.2363, G loss: 1.8781\n",
      "[1762/1762] D loss: 1.3918, G loss: 0.6165\n",
      "train error: \n",
      " D loss: 1.445262, G loss: 1.154024, D accuracy: 52.5%, cell accuracy: 99.9%, board accuracy: 93.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.414507, G loss: 1.136156, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4030, G loss: 0.5784\n",
      "[84/1762] D loss: 1.4047, G loss: 0.5976\n",
      "[164/1762] D loss: 1.3956, G loss: 0.7051\n",
      "[244/1762] D loss: 1.3972, G loss: 0.5838\n",
      "[324/1762] D loss: 0.1863, G loss: 1.9324\n",
      "[404/1762] D loss: 1.4002, G loss: 0.7706\n",
      "[484/1762] D loss: 1.3968, G loss: 0.6819\n",
      "[564/1762] D loss: 1.4878, G loss: 0.9463\n",
      "[644/1762] D loss: 1.3950, G loss: 0.6378\n",
      "[724/1762] D loss: 1.4030, G loss: 0.7345\n",
      "[804/1762] D loss: 1.3928, G loss: 0.6576\n",
      "[884/1762] D loss: 0.3194, G loss: 1.4271\n",
      "[964/1762] D loss: 1.3919, G loss: 0.6982\n",
      "[1044/1762] D loss: 1.5124, G loss: 0.3887\n",
      "[1124/1762] D loss: 1.4352, G loss: 0.5535\n",
      "[1204/1762] D loss: 1.4203, G loss: 0.8080\n",
      "[1284/1762] D loss: 1.3929, G loss: 0.6649\n",
      "[1364/1762] D loss: 0.3884, G loss: 1.4219\n",
      "[1444/1762] D loss: 1.4029, G loss: 0.6099\n",
      "[1524/1762] D loss: 0.2473, G loss: 2.6747\n",
      "[1604/1762] D loss: 1.4460, G loss: 0.8045\n",
      "[1684/1762] D loss: 1.4513, G loss: 1.7969\n",
      "[1762/1762] D loss: 1.4013, G loss: 0.6950\n",
      "train error: \n",
      " D loss: 2.031178, G loss: 0.717312, D accuracy: 51.3%, cell accuracy: 99.9%, board accuracy: 85.9% \n",
      "\n",
      "test error: \n",
      " D loss: 2.200770, G loss: 0.734660, D accuracy: 51.7%, cell accuracy: 99.8%, board accuracy: 84.8% \n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3791, G loss: 0.6884\n",
      "[84/1762] D loss: 1.5991, G loss: 0.4956\n",
      "[164/1762] D loss: 1.3896, G loss: 0.7935\n",
      "[244/1762] D loss: 1.3916, G loss: 0.8460\n",
      "[324/1762] D loss: 1.4348, G loss: 0.8724\n",
      "[404/1762] D loss: 1.3904, G loss: 0.7262\n",
      "[484/1762] D loss: 1.1483, G loss: 0.9726\n",
      "[564/1762] D loss: 1.4170, G loss: 0.8349\n",
      "[644/1762] D loss: 1.3992, G loss: 0.5778\n",
      "[724/1762] D loss: 1.3998, G loss: 0.5821\n",
      "[804/1762] D loss: 1.4761, G loss: 0.4486\n",
      "[884/1762] D loss: 0.8317, G loss: 0.9198\n",
      "[964/1762] D loss: 1.4249, G loss: 0.9141\n",
      "[1044/1762] D loss: 1.4207, G loss: 0.6776\n",
      "[1124/1762] D loss: 0.6738, G loss: 3.0975\n",
      "[1204/1762] D loss: 1.4114, G loss: 0.7653\n",
      "[1284/1762] D loss: 1.3978, G loss: 0.6060\n",
      "[1364/1762] D loss: 1.3976, G loss: 0.6269\n",
      "[1444/1762] D loss: 1.3928, G loss: 0.7148\n",
      "[1524/1762] D loss: 1.3921, G loss: 0.5989\n",
      "[1604/1762] D loss: 0.3333, G loss: 1.6724\n",
      "[1684/1762] D loss: 1.3835, G loss: 0.6883\n",
      "[1762/1762] D loss: 1.3968, G loss: 0.6840\n",
      "train error: \n",
      " D loss: 1.604537, G loss: 0.767097, D accuracy: 48.8%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.602008, G loss: 0.787896, D accuracy: 51.7%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8802, G loss: 2.5704\n",
      "[84/1762] D loss: 1.3913, G loss: 0.6846\n",
      "[164/1762] D loss: 1.4010, G loss: 0.7075\n",
      "[244/1762] D loss: 0.4009, G loss: 1.7945\n",
      "[324/1762] D loss: 0.7541, G loss: 2.1930\n",
      "[404/1762] D loss: 1.4135, G loss: 0.5891\n",
      "[484/1762] D loss: 1.3967, G loss: 0.6862\n",
      "[564/1762] D loss: 1.4113, G loss: 0.8005\n",
      "[644/1762] D loss: 0.3821, G loss: 1.5711\n",
      "[724/1762] D loss: 0.3474, G loss: 2.6825\n",
      "[804/1762] D loss: 1.2394, G loss: 1.7052\n",
      "[884/1762] D loss: 1.4298, G loss: 0.4454\n",
      "[964/1762] D loss: 1.3835, G loss: 0.6271\n",
      "[1044/1762] D loss: 1.4018, G loss: 0.5716\n",
      "[1124/1762] D loss: 1.3817, G loss: 0.6706\n",
      "[1204/1762] D loss: 1.4185, G loss: 0.5255\n",
      "[1284/1762] D loss: 1.3933, G loss: 0.5572\n",
      "[1364/1762] D loss: 1.4615, G loss: 0.4978\n",
      "[1444/1762] D loss: 1.4304, G loss: 2.4189\n",
      "[1524/1762] D loss: 1.4014, G loss: 0.6133\n",
      "[1604/1762] D loss: 1.4487, G loss: 0.5047\n",
      "[1684/1762] D loss: 1.3896, G loss: 0.7186\n",
      "[1762/1762] D loss: 1.3998, G loss: 0.6350\n",
      "train error: \n",
      " D loss: 1.653186, G loss: 0.708359, D accuracy: 51.3%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.628913, G loss: 0.769815, D accuracy: 51.9%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3923, G loss: 0.7477\n",
      "[84/1762] D loss: 0.1722, G loss: 2.4630\n",
      "[164/1762] D loss: 1.3924, G loss: 0.7191\n",
      "[244/1762] D loss: 1.3958, G loss: 0.6230\n",
      "[324/1762] D loss: 1.3855, G loss: 0.7179\n",
      "[404/1762] D loss: 0.2008, G loss: 2.7117\n",
      "[484/1762] D loss: 1.3944, G loss: 0.7787\n",
      "[564/1762] D loss: 0.2034, G loss: 2.2445\n",
      "[644/1762] D loss: 1.4021, G loss: 0.6109\n",
      "[724/1762] D loss: 1.1531, G loss: 0.8885\n",
      "[804/1762] D loss: 0.1597, G loss: 3.0024\n",
      "[884/1762] D loss: 0.2219, G loss: 2.6294\n",
      "[964/1762] D loss: 0.5666, G loss: 3.5073\n",
      "[1044/1762] D loss: 0.1341, G loss: 3.6688\n",
      "[1124/1762] D loss: 0.2559, G loss: 1.8576\n",
      "[1204/1762] D loss: 0.1225, G loss: 2.6975\n",
      "[1284/1762] D loss: 0.4076, G loss: 1.3791\n",
      "[1364/1762] D loss: 0.8500, G loss: 1.4974\n",
      "[1444/1762] D loss: 0.5586, G loss: 1.6773\n",
      "[1524/1762] D loss: 1.5020, G loss: 1.0115\n",
      "[1604/1762] D loss: 0.1857, G loss: 3.0463\n",
      "[1684/1762] D loss: 1.4185, G loss: 0.5512\n",
      "[1762/1762] D loss: 1.3953, G loss: 0.7518\n",
      "train error: \n",
      " D loss: 1.874901, G loss: 1.002152, D accuracy: 50.8%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.856996, G loss: 1.093326, D accuracy: 51.8%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3969, G loss: 0.6097\n",
      "[84/1762] D loss: 1.4048, G loss: 0.5972\n",
      "[164/1762] D loss: 0.2649, G loss: 1.7590\n",
      "[244/1762] D loss: 1.0448, G loss: 2.6681\n",
      "[324/1762] D loss: 1.4422, G loss: 0.5073\n",
      "[404/1762] D loss: 1.4159, G loss: 0.5632\n",
      "[484/1762] D loss: 1.3952, G loss: 0.6798\n",
      "[564/1762] D loss: 1.4062, G loss: 0.8489\n",
      "[644/1762] D loss: 1.4067, G loss: 0.6288\n",
      "[724/1762] D loss: 0.0223, G loss: 4.9633\n",
      "[804/1762] D loss: 0.2115, G loss: 2.6331\n",
      "[884/1762] D loss: 1.4070, G loss: 0.8441\n",
      "[964/1762] D loss: 1.3952, G loss: 0.7532\n",
      "[1044/1762] D loss: 0.0109, G loss: 10.9128\n",
      "[1124/1762] D loss: 1.3954, G loss: 0.6329\n",
      "[1204/1762] D loss: 1.4468, G loss: 0.9565\n",
      "[1284/1762] D loss: 1.3995, G loss: 0.7481\n",
      "[1364/1762] D loss: 1.3895, G loss: 0.7697\n",
      "[1444/1762] D loss: 1.3990, G loss: 0.7053\n",
      "[1524/1762] D loss: 1.3933, G loss: 0.6907\n",
      "[1604/1762] D loss: 1.3923, G loss: 0.7670\n",
      "[1684/1762] D loss: 1.3949, G loss: 0.7446\n",
      "[1762/1762] D loss: 1.3870, G loss: 0.6534\n",
      "train error: \n",
      " D loss: 2.816163, G loss: 0.525824, D accuracy: 50.3%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 2.975065, G loss: 0.580098, D accuracy: 50.7%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0300, G loss: 4.5596\n",
      "[84/1762] D loss: 1.3935, G loss: 0.6985\n",
      "[164/1762] D loss: 1.3871, G loss: 0.7153\n",
      "[244/1762] D loss: 1.4062, G loss: 0.5901\n",
      "[324/1762] D loss: 1.4028, G loss: 0.6951\n",
      "[404/1762] D loss: 1.3990, G loss: 0.6444\n",
      "[484/1762] D loss: 1.3934, G loss: 0.6401\n",
      "[564/1762] D loss: 1.3873, G loss: 0.7278\n",
      "[644/1762] D loss: 1.4100, G loss: 0.8361\n",
      "[724/1762] D loss: 1.3913, G loss: 0.6406\n",
      "[804/1762] D loss: 1.3894, G loss: 0.7474\n",
      "[884/1762] D loss: 0.0514, G loss: 6.2565\n",
      "[964/1762] D loss: 1.4048, G loss: 0.6106\n",
      "[1044/1762] D loss: 1.3920, G loss: 0.6990\n",
      "[1124/1762] D loss: 0.0146, G loss: 4.9905\n",
      "[1204/1762] D loss: 1.4264, G loss: 0.5443\n",
      "[1284/1762] D loss: 1.3871, G loss: 0.7214\n",
      "[1364/1762] D loss: 0.0084, G loss: 5.7649\n",
      "[1444/1762] D loss: 1.4061, G loss: 0.5990\n",
      "[1524/1762] D loss: 1.4033, G loss: 0.7940\n",
      "[1604/1762] D loss: 1.4043, G loss: 0.7532\n",
      "[1684/1762] D loss: 1.6347, G loss: 0.8547\n",
      "[1762/1762] D loss: 1.3901, G loss: 0.6598\n",
      "train error: \n",
      " D loss: 2.697730, G loss: 0.738323, D accuracy: 50.2%, cell accuracy: 99.8%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 2.887258, G loss: 0.833562, D accuracy: 50.6%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4099, G loss: 0.7672\n",
      "[84/1762] D loss: 1.3923, G loss: 0.6406\n",
      "[164/1762] D loss: 0.0240, G loss: 4.0300\n",
      "[244/1762] D loss: 1.3907, G loss: 0.6656\n",
      "[324/1762] D loss: 1.3923, G loss: 0.6627\n",
      "[404/1762] D loss: 1.4506, G loss: 0.8223\n",
      "[484/1762] D loss: 1.3972, G loss: 0.7476\n",
      "[564/1762] D loss: 1.3917, G loss: 0.7406\n",
      "[644/1762] D loss: 1.3910, G loss: 0.6668\n",
      "[724/1762] D loss: 1.4259, G loss: 0.5812\n",
      "[804/1762] D loss: 1.3886, G loss: 0.6613\n",
      "[884/1762] D loss: 1.4440, G loss: 0.7583\n",
      "[964/1762] D loss: 0.0236, G loss: 4.1425\n",
      "[1044/1762] D loss: 1.3889, G loss: 0.7893\n",
      "[1124/1762] D loss: 1.3894, G loss: 0.7646\n",
      "[1204/1762] D loss: 0.0250, G loss: 4.9348\n",
      "[1284/1762] D loss: 1.3891, G loss: 0.7769\n",
      "[1364/1762] D loss: 1.4489, G loss: 0.8066\n",
      "[1444/1762] D loss: 0.0369, G loss: 3.6874\n",
      "[1524/1762] D loss: 1.3920, G loss: 0.7270\n",
      "[1604/1762] D loss: 0.0149, G loss: 4.4170\n",
      "[1684/1762] D loss: 1.3958, G loss: 0.6931\n",
      "[1762/1762] D loss: 1.4011, G loss: 0.5521\n",
      "train error: \n",
      " D loss: 3.195139, G loss: 0.430488, D accuracy: 50.2%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 3.400201, G loss: 0.488351, D accuracy: 50.6%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3611, G loss: 0.6161\n",
      "[84/1762] D loss: 0.0223, G loss: 4.0343\n",
      "[164/1762] D loss: 1.3984, G loss: 0.7374\n",
      "[244/1762] D loss: 1.3872, G loss: 0.6682\n",
      "[324/1762] D loss: 0.0100, G loss: 4.9721\n",
      "[404/1762] D loss: 1.3868, G loss: 0.7058\n",
      "[484/1762] D loss: 1.3934, G loss: 0.7241\n",
      "[564/1762] D loss: 1.3893, G loss: 0.6834\n",
      "[644/1762] D loss: 1.3876, G loss: 0.6932\n",
      "[724/1762] D loss: 0.0052, G loss: 5.9259\n",
      "[804/1762] D loss: 1.3901, G loss: 0.7400\n",
      "[884/1762] D loss: 1.3882, G loss: 0.6666\n",
      "[964/1762] D loss: 1.3913, G loss: 0.6096\n",
      "[1044/1762] D loss: 1.3767, G loss: 0.6261\n",
      "[1124/1762] D loss: 1.4025, G loss: 0.7378\n",
      "[1204/1762] D loss: 1.3882, G loss: 0.6525\n",
      "[1284/1762] D loss: 1.3887, G loss: 0.7287\n",
      "[1364/1762] D loss: 0.2139, G loss: 3.6903\n",
      "[1444/1762] D loss: 1.3936, G loss: 0.7381\n",
      "[1524/1762] D loss: 1.3946, G loss: 0.7227\n",
      "[1604/1762] D loss: 0.0083, G loss: 8.0903\n",
      "[1684/1762] D loss: 0.0065, G loss: 6.0385\n",
      "[1762/1762] D loss: 1.3859, G loss: 0.6961\n",
      "train error: \n",
      " D loss: 3.401363, G loss: 0.426241, D accuracy: 50.2%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 3.629391, G loss: 0.502248, D accuracy: 50.6%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0064, G loss: 6.5119\n",
      "[84/1762] D loss: 1.3899, G loss: 0.7312\n",
      "[164/1762] D loss: 1.3922, G loss: 0.7476\n",
      "[244/1762] D loss: 1.3918, G loss: 0.6344\n",
      "[324/1762] D loss: 1.3896, G loss: 0.6907\n",
      "[404/1762] D loss: 1.3867, G loss: 0.7161\n",
      "[484/1762] D loss: 1.3880, G loss: 0.6965\n",
      "[564/1762] D loss: 1.3868, G loss: 0.7141\n",
      "[644/1762] D loss: 0.0017, G loss: 7.9563\n",
      "[724/1762] D loss: 1.3920, G loss: 0.6233\n",
      "[804/1762] D loss: 1.3959, G loss: 0.6046\n",
      "[884/1762] D loss: 1.3946, G loss: 0.6573\n",
      "[964/1762] D loss: 0.0024, G loss: 7.1916\n",
      "[1044/1762] D loss: 0.0149, G loss: 5.2743\n",
      "[1124/1762] D loss: 1.3914, G loss: 0.6438\n",
      "[1204/1762] D loss: 1.4160, G loss: 0.8292\n",
      "[1284/1762] D loss: 0.0052, G loss: 5.6829\n",
      "[1364/1762] D loss: 1.3898, G loss: 0.6493\n",
      "[1444/1762] D loss: 0.0030, G loss: 7.6976\n",
      "[1524/1762] D loss: 1.3870, G loss: 0.6688\n",
      "[1604/1762] D loss: 0.0003, G loss: 15.2988\n",
      "[1684/1762] D loss: 1.3937, G loss: 0.6410\n",
      "[1762/1762] D loss: 1.3929, G loss: 0.7292\n",
      "train error: \n",
      " D loss: 4.377910, G loss: 0.769789, D accuracy: 50.1%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 4.997326, G loss: 0.850594, D accuracy: 50.2%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0019, G loss: 7.0209\n",
      "[84/1762] D loss: 1.3897, G loss: 0.7275\n",
      "[164/1762] D loss: 1.3903, G loss: 0.7292\n",
      "[244/1762] D loss: 1.3867, G loss: 0.7291\n",
      "[324/1762] D loss: 1.3914, G loss: 0.6472\n",
      "[404/1762] D loss: 0.0006, G loss: 15.7866\n",
      "[484/1762] D loss: 0.0021, G loss: 7.7266\n",
      "[564/1762] D loss: 1.3868, G loss: 0.6594\n",
      "[644/1762] D loss: 0.0012, G loss: 7.9889\n",
      "[724/1762] D loss: 1.3899, G loss: 0.6615\n",
      "[804/1762] D loss: 1.3892, G loss: 0.6105\n",
      "[884/1762] D loss: 0.0063, G loss: 5.9598\n",
      "[964/1762] D loss: 1.4073, G loss: 0.7196\n",
      "[1044/1762] D loss: 1.3872, G loss: 0.6962\n",
      "[1124/1762] D loss: 1.3942, G loss: 0.7716\n",
      "[1204/1762] D loss: 1.3880, G loss: 0.6927\n",
      "[1284/1762] D loss: 1.3885, G loss: 0.7046\n",
      "[1364/1762] D loss: 1.3925, G loss: 0.7617\n",
      "[1444/1762] D loss: 1.3950, G loss: 0.7592\n",
      "[1524/1762] D loss: 1.3909, G loss: 0.6643\n",
      "[1604/1762] D loss: 1.3861, G loss: 0.7136\n",
      "[1684/1762] D loss: 1.3898, G loss: 0.7665\n",
      "[1762/1762] D loss: 1.4023, G loss: 0.6806\n",
      "train error: \n",
      " D loss: 3.597913, G loss: 0.662518, D accuracy: 50.0%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 3.990352, G loss: 0.763695, D accuracy: 50.2%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3919, G loss: 0.6171\n",
      "[84/1762] D loss: 1.2931, G loss: 0.6952\n",
      "[164/1762] D loss: 0.6447, G loss: 1.6372\n",
      "[244/1762] D loss: 0.2600, G loss: 2.4599\n",
      "[324/1762] D loss: 0.2000, G loss: 2.6398\n",
      "[404/1762] D loss: 0.6539, G loss: 2.4374\n",
      "[484/1762] D loss: 1.1224, G loss: 1.6196\n",
      "[564/1762] D loss: 0.7313, G loss: 1.4710\n",
      "[644/1762] D loss: 0.8160, G loss: 1.4113\n",
      "[724/1762] D loss: 1.1737, G loss: 0.9964\n",
      "[804/1762] D loss: 0.7432, G loss: 1.0232\n",
      "[884/1762] D loss: 0.9416, G loss: 1.6604\n",
      "[964/1762] D loss: 1.0588, G loss: 3.1215\n",
      "[1044/1762] D loss: 0.8588, G loss: 2.4503\n",
      "[1124/1762] D loss: 1.3308, G loss: 1.0682\n",
      "[1204/1762] D loss: 1.0300, G loss: 1.6989\n",
      "[1284/1762] D loss: 0.9274, G loss: 0.4434\n",
      "[1364/1762] D loss: 1.0972, G loss: 1.0758\n",
      "[1444/1762] D loss: 1.2577, G loss: 0.7983\n",
      "[1524/1762] D loss: 1.2789, G loss: 1.2931\n",
      "[1604/1762] D loss: 1.4370, G loss: 0.7139\n",
      "[1684/1762] D loss: 1.1351, G loss: 1.0185\n",
      "[1762/1762] D loss: 1.2791, G loss: 0.6848\n",
      "train error: \n",
      " D loss: 1.150165, G loss: 0.726609, D accuracy: 71.6%, cell accuracy: 98.5%, board accuracy: 1.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.144180, G loss: 0.740424, D accuracy: 71.7%, cell accuracy: 98.4%, board accuracy: 1.8% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1124, G loss: 1.1247\n",
      "[84/1762] D loss: 1.2167, G loss: 1.0316\n",
      "[164/1762] D loss: 1.2075, G loss: 1.3601\n",
      "[244/1762] D loss: 1.0876, G loss: 0.9656\n",
      "[324/1762] D loss: 1.2262, G loss: 1.4984\n",
      "[404/1762] D loss: 1.1899, G loss: 1.1210\n",
      "[484/1762] D loss: 1.1839, G loss: 1.4279\n",
      "[564/1762] D loss: 1.4083, G loss: 1.4861\n",
      "[644/1762] D loss: 1.2586, G loss: 1.0159\n",
      "[724/1762] D loss: 1.3810, G loss: 0.8673\n",
      "[804/1762] D loss: 1.3011, G loss: 0.5429\n",
      "[884/1762] D loss: 1.3109, G loss: 1.0618\n",
      "[964/1762] D loss: 1.3055, G loss: 0.7483\n",
      "[1044/1762] D loss: 1.3943, G loss: 0.7653\n",
      "[1124/1762] D loss: 1.3383, G loss: 0.5378\n",
      "[1204/1762] D loss: 1.1514, G loss: 1.0792\n",
      "[1284/1762] D loss: 1.3276, G loss: 1.1488\n",
      "[1364/1762] D loss: 1.3428, G loss: 0.7612\n",
      "[1444/1762] D loss: 1.3704, G loss: 0.7090\n",
      "[1524/1762] D loss: 1.3605, G loss: 0.6760\n",
      "[1604/1762] D loss: 1.3505, G loss: 0.8012\n",
      "[1684/1762] D loss: 1.2915, G loss: 0.8252\n",
      "[1762/1762] D loss: 1.3643, G loss: 0.6774\n",
      "train error: \n",
      " D loss: 1.338718, G loss: 0.654952, D accuracy: 59.0%, cell accuracy: 99.6%, board accuracy: 71.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.335554, G loss: 0.656530, D accuracy: 58.1%, cell accuracy: 99.6%, board accuracy: 67.5% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3632, G loss: 0.6774\n",
      "[84/1762] D loss: 1.3523, G loss: 0.8426\n",
      "[164/1762] D loss: 1.3754, G loss: 0.6472\n",
      "[244/1762] D loss: 1.3691, G loss: 0.8350\n",
      "[324/1762] D loss: 1.2268, G loss: 1.1018\n",
      "[404/1762] D loss: 1.3791, G loss: 0.7060\n",
      "[484/1762] D loss: 1.3439, G loss: 0.7273\n",
      "[564/1762] D loss: 1.3130, G loss: 0.8564\n",
      "[644/1762] D loss: 1.2288, G loss: 0.7759\n",
      "[724/1762] D loss: 1.2807, G loss: 1.0448\n",
      "[804/1762] D loss: 1.4532, G loss: 0.5280\n",
      "[884/1762] D loss: 1.3606, G loss: 0.9142\n",
      "[964/1762] D loss: 1.3310, G loss: 0.6128\n",
      "[1044/1762] D loss: 1.3733, G loss: 0.6792\n",
      "[1124/1762] D loss: 1.3683, G loss: 0.6588\n",
      "[1204/1762] D loss: 1.3103, G loss: 0.6943\n",
      "[1284/1762] D loss: 1.3763, G loss: 0.6532\n",
      "[1364/1762] D loss: 1.4468, G loss: 0.5871\n",
      "[1444/1762] D loss: 1.4023, G loss: 0.7366\n",
      "[1524/1762] D loss: 1.3217, G loss: 0.7134\n",
      "[1604/1762] D loss: 1.3754, G loss: 0.7831\n",
      "[1684/1762] D loss: 1.3801, G loss: 0.5290\n",
      "[1762/1762] D loss: 1.3773, G loss: 0.6605\n",
      "train error: \n",
      " D loss: 1.344381, G loss: 0.681117, D accuracy: 56.8%, cell accuracy: 99.7%, board accuracy: 76.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.335552, G loss: 0.688070, D accuracy: 57.2%, cell accuracy: 99.6%, board accuracy: 72.5% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3953, G loss: 0.5770\n",
      "[84/1762] D loss: 1.3028, G loss: 0.6162\n",
      "[164/1762] D loss: 1.4265, G loss: 0.8441\n",
      "[244/1762] D loss: 1.4022, G loss: 0.6252\n",
      "[324/1762] D loss: 1.2313, G loss: 0.6548\n",
      "[404/1762] D loss: 1.3200, G loss: 0.7188\n",
      "[484/1762] D loss: 1.3819, G loss: 0.7621\n",
      "[564/1762] D loss: 1.2741, G loss: 0.9380\n",
      "[644/1762] D loss: 1.2705, G loss: 0.6374\n",
      "[724/1762] D loss: 1.3822, G loss: 0.5575\n",
      "[804/1762] D loss: 1.3999, G loss: 0.4778\n",
      "[884/1762] D loss: 1.2587, G loss: 0.6494\n",
      "[964/1762] D loss: 1.2383, G loss: 1.0172\n",
      "[1044/1762] D loss: 1.4392, G loss: 0.8215\n",
      "[1124/1762] D loss: 1.3272, G loss: 0.7723\n",
      "[1204/1762] D loss: 1.3942, G loss: 0.7171\n",
      "[1284/1762] D loss: 1.3679, G loss: 0.7161\n",
      "[1364/1762] D loss: 1.1973, G loss: 0.8918\n",
      "[1444/1762] D loss: 1.2848, G loss: 0.7324\n",
      "[1524/1762] D loss: 1.2901, G loss: 0.9147\n",
      "[1604/1762] D loss: 1.3700, G loss: 0.5375\n",
      "[1684/1762] D loss: 1.3055, G loss: 0.7666\n",
      "[1762/1762] D loss: 1.2521, G loss: 0.8167\n",
      "train error: \n",
      " D loss: 1.313173, G loss: 0.808537, D accuracy: 60.4%, cell accuracy: 99.6%, board accuracy: 61.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.302736, G loss: 0.805152, D accuracy: 62.2%, cell accuracy: 99.5%, board accuracy: 58.6% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3050, G loss: 0.8375\n",
      "[84/1762] D loss: 1.3774, G loss: 0.7069\n",
      "[164/1762] D loss: 1.3635, G loss: 0.5535\n",
      "[244/1762] D loss: 1.3311, G loss: 0.8118\n",
      "[324/1762] D loss: 1.3205, G loss: 0.6974\n",
      "[404/1762] D loss: 1.3151, G loss: 0.7132\n",
      "[484/1762] D loss: 1.4461, G loss: 0.3983\n",
      "[564/1762] D loss: 1.3677, G loss: 0.7041\n",
      "[644/1762] D loss: 1.1085, G loss: 0.9567\n",
      "[724/1762] D loss: 1.4117, G loss: 0.6782\n",
      "[804/1762] D loss: 1.3910, G loss: 0.6681\n",
      "[884/1762] D loss: 1.3903, G loss: 0.7523\n",
      "[964/1762] D loss: 1.3552, G loss: 0.8983\n",
      "[1044/1762] D loss: 1.3481, G loss: 0.6965\n",
      "[1124/1762] D loss: 1.4637, G loss: 0.9718\n",
      "[1204/1762] D loss: 1.2710, G loss: 0.7175\n",
      "[1284/1762] D loss: 1.3592, G loss: 0.8302\n",
      "[1364/1762] D loss: 1.3691, G loss: 0.6055\n",
      "[1444/1762] D loss: 1.3994, G loss: 0.6731\n",
      "[1524/1762] D loss: 1.3885, G loss: 0.8110\n",
      "[1604/1762] D loss: 1.4286, G loss: 0.9507\n",
      "[1684/1762] D loss: 1.3584, G loss: 0.6529\n",
      "[1762/1762] D loss: 1.3769, G loss: 0.6506\n",
      "train error: \n",
      " D loss: 1.323707, G loss: 0.758758, D accuracy: 56.0%, cell accuracy: 99.8%, board accuracy: 83.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.309753, G loss: 0.764556, D accuracy: 56.4%, cell accuracy: 99.7%, board accuracy: 81.4% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4507, G loss: 0.6589\n",
      "[84/1762] D loss: 1.2210, G loss: 0.7573\n",
      "[164/1762] D loss: 1.2272, G loss: 0.7920\n",
      "[244/1762] D loss: 1.1848, G loss: 0.9211\n",
      "[324/1762] D loss: 1.3740, G loss: 0.8045\n",
      "[404/1762] D loss: 1.3850, G loss: 0.7209\n",
      "[484/1762] D loss: 1.3891, G loss: 0.7193\n",
      "[564/1762] D loss: 0.9563, G loss: 1.1829\n",
      "[644/1762] D loss: 1.3022, G loss: 0.9367\n",
      "[724/1762] D loss: 1.4092, G loss: 0.7041\n",
      "[804/1762] D loss: 1.3783, G loss: 0.6058\n",
      "[884/1762] D loss: 1.3895, G loss: 0.5579\n",
      "[964/1762] D loss: 1.3655, G loss: 0.5658\n",
      "[1044/1762] D loss: 1.3395, G loss: 0.8027\n",
      "[1124/1762] D loss: 1.3461, G loss: 0.7330\n",
      "[1204/1762] D loss: 1.1374, G loss: 0.8195\n",
      "[1284/1762] D loss: 1.3472, G loss: 1.1053\n",
      "[1364/1762] D loss: 0.8440, G loss: 0.7324\n",
      "[1444/1762] D loss: 1.5901, G loss: 0.4590\n",
      "[1524/1762] D loss: 1.5235, G loss: 0.4462\n",
      "[1604/1762] D loss: 1.3929, G loss: 0.6103\n",
      "[1684/1762] D loss: 1.4012, G loss: 0.7416\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6562\n",
      "train error: \n",
      " D loss: 1.391098, G loss: 0.661244, D accuracy: 50.5%, cell accuracy: 99.7%, board accuracy: 79.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.394080, G loss: 0.655892, D accuracy: 50.0%, cell accuracy: 99.7%, board accuracy: 76.1% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4070, G loss: 0.6330\n",
      "[84/1762] D loss: 1.3866, G loss: 0.7200\n",
      "[164/1762] D loss: 1.3979, G loss: 0.8520\n",
      "[244/1762] D loss: 1.3631, G loss: 0.6863\n",
      "[324/1762] D loss: 1.3865, G loss: 0.7241\n",
      "[404/1762] D loss: 1.3868, G loss: 0.7564\n",
      "[484/1762] D loss: 1.3793, G loss: 0.7268\n",
      "[564/1762] D loss: 1.3891, G loss: 0.7475\n",
      "[644/1762] D loss: 1.3874, G loss: 0.6978\n",
      "[724/1762] D loss: 1.3635, G loss: 0.7421\n",
      "[804/1762] D loss: 1.3895, G loss: 0.6974\n",
      "[884/1762] D loss: 1.3230, G loss: 0.7190\n",
      "[964/1762] D loss: 1.3880, G loss: 0.7461\n",
      "[1044/1762] D loss: 1.3768, G loss: 0.6721\n",
      "[1124/1762] D loss: 1.4078, G loss: 0.5748\n",
      "[1204/1762] D loss: 1.2836, G loss: 0.7400\n",
      "[1284/1762] D loss: 1.3878, G loss: 0.6950\n",
      "[1364/1762] D loss: 1.3500, G loss: 0.6630\n",
      "[1444/1762] D loss: 1.3933, G loss: 0.7129\n",
      "[1524/1762] D loss: 1.4013, G loss: 0.6889\n",
      "[1604/1762] D loss: 1.2843, G loss: 0.6488\n",
      "[1684/1762] D loss: 1.4410, G loss: 0.5701\n",
      "[1762/1762] D loss: 1.1164, G loss: 0.9517\n",
      "train error: \n",
      " D loss: 1.349337, G loss: 0.755121, D accuracy: 52.7%, cell accuracy: 99.5%, board accuracy: 42.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.339556, G loss: 0.753467, D accuracy: 54.1%, cell accuracy: 99.5%, board accuracy: 48.9% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3823, G loss: 0.8818\n",
      "[84/1762] D loss: 1.3912, G loss: 0.5627\n",
      "[164/1762] D loss: 1.4160, G loss: 0.6749\n",
      "[244/1762] D loss: 1.5099, G loss: 0.6966\n",
      "[324/1762] D loss: 1.3859, G loss: 0.7100\n",
      "[404/1762] D loss: 1.0124, G loss: 1.0245\n",
      "[484/1762] D loss: 1.3919, G loss: 0.6702\n",
      "[564/1762] D loss: 1.3841, G loss: 0.7642\n",
      "[644/1762] D loss: 1.4272, G loss: 0.8531\n",
      "[724/1762] D loss: 1.3893, G loss: 0.6278\n",
      "[804/1762] D loss: 1.3843, G loss: 0.6495\n",
      "[884/1762] D loss: 1.3952, G loss: 0.6844\n",
      "[964/1762] D loss: 1.3991, G loss: 0.7469\n",
      "[1044/1762] D loss: 1.3734, G loss: 0.6921\n",
      "[1124/1762] D loss: 1.4025, G loss: 0.6662\n",
      "[1204/1762] D loss: 1.3967, G loss: 0.5891\n",
      "[1284/1762] D loss: 1.4772, G loss: 0.8086\n",
      "[1364/1762] D loss: 1.4747, G loss: 0.7044\n",
      "[1444/1762] D loss: 1.3879, G loss: 0.7423\n",
      "[1524/1762] D loss: 1.3332, G loss: 0.6679\n",
      "[1604/1762] D loss: 1.3944, G loss: 0.6994\n",
      "[1684/1762] D loss: 1.3896, G loss: 0.6539\n",
      "[1762/1762] D loss: 1.3887, G loss: 0.7453\n",
      "train error: \n",
      " D loss: 1.358231, G loss: 0.736754, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.352834, G loss: 0.740325, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 84.8% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3021, G loss: 0.8589\n",
      "[84/1762] D loss: 1.5471, G loss: 0.5841\n",
      "[164/1762] D loss: 1.3950, G loss: 0.7796\n",
      "[244/1762] D loss: 1.3872, G loss: 0.6284\n",
      "[324/1762] D loss: 1.3881, G loss: 0.7737\n",
      "[404/1762] D loss: 1.3415, G loss: 0.6106\n",
      "[484/1762] D loss: 1.4123, G loss: 0.7876\n",
      "[564/1762] D loss: 1.3910, G loss: 0.7619\n",
      "[644/1762] D loss: 1.3864, G loss: 0.7343\n",
      "[724/1762] D loss: 1.3834, G loss: 0.6769\n",
      "[804/1762] D loss: 1.3869, G loss: 0.6769\n",
      "[884/1762] D loss: 1.3937, G loss: 0.7914\n",
      "[964/1762] D loss: 1.3933, G loss: 0.6494\n",
      "[1044/1762] D loss: 1.3911, G loss: 0.7000\n",
      "[1124/1762] D loss: 1.3412, G loss: 0.8153\n",
      "[1204/1762] D loss: 1.3884, G loss: 0.6835\n",
      "[1284/1762] D loss: 1.4217, G loss: 0.6080\n",
      "[1364/1762] D loss: 1.3041, G loss: 0.6963\n",
      "[1444/1762] D loss: 1.4068, G loss: 0.5876\n",
      "[1524/1762] D loss: 1.3855, G loss: 0.7494\n",
      "[1604/1762] D loss: 1.2753, G loss: 0.8141\n",
      "[1684/1762] D loss: 1.3882, G loss: 0.7567\n",
      "[1762/1762] D loss: 1.4155, G loss: 0.5788\n",
      "train error: \n",
      " D loss: 1.352045, G loss: 0.665356, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 89.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.344339, G loss: 0.666001, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3760, G loss: 0.7074\n",
      "[84/1762] D loss: 1.3886, G loss: 0.6978\n",
      "[164/1762] D loss: 1.2404, G loss: 0.7038\n",
      "[244/1762] D loss: 1.2809, G loss: 0.5773\n",
      "[324/1762] D loss: 1.3920, G loss: 0.7582\n",
      "[404/1762] D loss: 1.2147, G loss: 0.7340\n",
      "[484/1762] D loss: 1.3945, G loss: 0.7177\n",
      "[564/1762] D loss: 1.3960, G loss: 0.6728\n",
      "[644/1762] D loss: 1.3841, G loss: 0.6329\n",
      "[724/1762] D loss: 1.1703, G loss: 0.8357\n",
      "[804/1762] D loss: 1.3896, G loss: 0.6828\n",
      "[884/1762] D loss: 1.3911, G loss: 0.6763\n",
      "[964/1762] D loss: 1.3950, G loss: 0.7163\n",
      "[1044/1762] D loss: 1.4286, G loss: 0.8822\n",
      "[1124/1762] D loss: 1.3904, G loss: 0.8794\n",
      "[1204/1762] D loss: 1.4125, G loss: 0.8597\n",
      "[1284/1762] D loss: 1.3995, G loss: 0.5551\n",
      "[1364/1762] D loss: 1.1920, G loss: 0.7851\n",
      "[1444/1762] D loss: 1.3800, G loss: 0.7894\n",
      "[1524/1762] D loss: 1.4140, G loss: 0.7400\n",
      "[1604/1762] D loss: 0.7823, G loss: 1.3789\n",
      "[1684/1762] D loss: 1.1114, G loss: 1.4341\n",
      "[1762/1762] D loss: 1.6876, G loss: 0.4465\n",
      "train error: \n",
      " D loss: 1.426615, G loss: 0.674763, D accuracy: 51.8%, cell accuracy: 98.5%, board accuracy: 2.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.429931, G loss: 0.650682, D accuracy: 51.2%, cell accuracy: 98.5%, board accuracy: 3.4% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3203, G loss: 0.6281\n",
      "[84/1762] D loss: 1.3147, G loss: 0.7823\n",
      "[164/1762] D loss: 1.0021, G loss: 1.4501\n",
      "[244/1762] D loss: 0.8003, G loss: 1.3471\n",
      "[324/1762] D loss: 1.3696, G loss: 1.2403\n",
      "[404/1762] D loss: 1.2438, G loss: 0.7127\n",
      "[484/1762] D loss: 1.2795, G loss: 0.8688\n",
      "[564/1762] D loss: 1.3512, G loss: 0.6161\n",
      "[644/1762] D loss: 1.3921, G loss: 0.6291\n",
      "[724/1762] D loss: 1.4424, G loss: 0.5691\n",
      "[804/1762] D loss: 1.2797, G loss: 0.6995\n",
      "[884/1762] D loss: 1.2851, G loss: 0.7057\n",
      "[964/1762] D loss: 1.3823, G loss: 0.5877\n",
      "[1044/1762] D loss: 1.3641, G loss: 0.7002\n",
      "[1124/1762] D loss: 1.2200, G loss: 0.7992\n",
      "[1204/1762] D loss: 1.0559, G loss: 0.8304\n",
      "[1284/1762] D loss: 1.2318, G loss: 0.7225\n",
      "[1364/1762] D loss: 1.3908, G loss: 0.7748\n",
      "[1444/1762] D loss: 1.3465, G loss: 0.7648\n",
      "[1524/1762] D loss: 1.4309, G loss: 0.5084\n",
      "[1604/1762] D loss: 1.2811, G loss: 0.7037\n",
      "[1684/1762] D loss: 1.4559, G loss: 0.6255\n",
      "[1762/1762] D loss: 1.3862, G loss: 0.7582\n",
      "train error: \n",
      " D loss: 1.314448, G loss: 0.887688, D accuracy: 56.3%, cell accuracy: 99.7%, board accuracy: 71.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.306706, G loss: 0.892028, D accuracy: 56.0%, cell accuracy: 99.7%, board accuracy: 68.9% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3959, G loss: 0.7652\n",
      "[84/1762] D loss: 1.3369, G loss: 0.7319\n",
      "[164/1762] D loss: 1.3703, G loss: 0.6875\n",
      "[244/1762] D loss: 1.1773, G loss: 0.7438\n",
      "[324/1762] D loss: 1.3800, G loss: 0.6003\n",
      "[404/1762] D loss: 1.3867, G loss: 0.6874\n",
      "[484/1762] D loss: 1.4110, G loss: 0.7999\n",
      "[564/1762] D loss: 1.3719, G loss: 0.7213\n",
      "[644/1762] D loss: 1.3797, G loss: 0.6996\n",
      "[724/1762] D loss: 1.3698, G loss: 0.7307\n",
      "[804/1762] D loss: 1.4198, G loss: 0.8089\n",
      "[884/1762] D loss: 1.3925, G loss: 0.7885\n",
      "[964/1762] D loss: 1.4207, G loss: 0.8098\n",
      "[1044/1762] D loss: 1.1165, G loss: 0.8966\n",
      "[1124/1762] D loss: 1.3702, G loss: 0.7164\n",
      "[1204/1762] D loss: 1.4128, G loss: 0.8514\n",
      "[1284/1762] D loss: 1.3921, G loss: 0.7633\n",
      "[1364/1762] D loss: 1.3909, G loss: 0.6402\n",
      "[1444/1762] D loss: 1.4070, G loss: 0.7919\n",
      "[1524/1762] D loss: 1.3906, G loss: 0.6765\n",
      "[1604/1762] D loss: 1.1827, G loss: 0.7736\n",
      "[1684/1762] D loss: 0.9281, G loss: 1.0031\n",
      "[1762/1762] D loss: 1.3977, G loss: 0.7379\n",
      "train error: \n",
      " D loss: 1.320809, G loss: 0.775803, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 87.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.303302, G loss: 0.785576, D accuracy: 55.1%, cell accuracy: 99.7%, board accuracy: 83.4% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3891, G loss: 0.6638\n",
      "[84/1762] D loss: 1.1630, G loss: 0.8051\n",
      "[164/1762] D loss: 1.4001, G loss: 0.6755\n",
      "[244/1762] D loss: 1.1905, G loss: 0.6220\n",
      "[324/1762] D loss: 1.4299, G loss: 0.6134\n",
      "[404/1762] D loss: 1.4313, G loss: 0.7737\n",
      "[484/1762] D loss: 1.3891, G loss: 0.7263\n",
      "[564/1762] D loss: 1.1710, G loss: 0.7585\n",
      "[644/1762] D loss: 1.4034, G loss: 0.7864\n",
      "[724/1762] D loss: 1.1123, G loss: 1.0458\n",
      "[804/1762] D loss: 1.1386, G loss: 0.9846\n",
      "[884/1762] D loss: 1.1498, G loss: 0.8228\n",
      "[964/1762] D loss: 1.3885, G loss: 0.6907\n",
      "[1044/1762] D loss: 1.3865, G loss: 0.6872\n",
      "[1124/1762] D loss: 1.3993, G loss: 0.5767\n",
      "[1204/1762] D loss: 1.3954, G loss: 0.7251\n",
      "[1284/1762] D loss: 1.3721, G loss: 0.7673\n",
      "[1364/1762] D loss: 1.4506, G loss: 0.9105\n",
      "[1444/1762] D loss: 1.3938, G loss: 0.7654\n",
      "[1524/1762] D loss: 1.3705, G loss: 0.8214\n",
      "[1604/1762] D loss: 1.1723, G loss: 0.7747\n",
      "[1684/1762] D loss: 1.4058, G loss: 0.6009\n",
      "[1762/1762] D loss: 1.4272, G loss: 0.9732\n",
      "train error: \n",
      " D loss: 1.358524, G loss: 0.939324, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 87.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.337133, G loss: 0.947733, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 83.4% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4133, G loss: 0.8881\n",
      "[84/1762] D loss: 1.3886, G loss: 0.7383\n",
      "[164/1762] D loss: 1.3920, G loss: 0.6912\n",
      "[244/1762] D loss: 1.3958, G loss: 0.6911\n",
      "[324/1762] D loss: 1.1468, G loss: 0.8802\n",
      "[404/1762] D loss: 1.3858, G loss: 0.6956\n",
      "[484/1762] D loss: 2.4842, G loss: 0.8123\n",
      "[564/1762] D loss: 1.3941, G loss: 0.6219\n",
      "[644/1762] D loss: 1.3874, G loss: 0.7387\n",
      "[724/1762] D loss: 1.3840, G loss: 0.6718\n",
      "[804/1762] D loss: 1.3848, G loss: 0.6801\n",
      "[884/1762] D loss: 1.3861, G loss: 0.7021\n",
      "[964/1762] D loss: 1.3694, G loss: 0.6813\n",
      "[1044/1762] D loss: 1.3866, G loss: 0.7026\n",
      "[1124/1762] D loss: 1.3868, G loss: 0.6983\n",
      "[1204/1762] D loss: 1.2320, G loss: 0.6894\n",
      "[1284/1762] D loss: 1.3869, G loss: 0.7115\n",
      "[1364/1762] D loss: 1.3871, G loss: 0.6650\n",
      "[1444/1762] D loss: 1.3862, G loss: 0.6875\n",
      "[1524/1762] D loss: 1.3861, G loss: 0.6831\n",
      "[1604/1762] D loss: 1.3874, G loss: 0.6997\n",
      "[1684/1762] D loss: 1.3647, G loss: 0.7177\n",
      "[1762/1762] D loss: 1.3908, G loss: 0.7624\n",
      "train error: \n",
      " D loss: 1.342859, G loss: 0.762539, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 87.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.330499, G loss: 0.763235, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 85.0% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2172, G loss: 0.7957\n",
      "[84/1762] D loss: 1.3941, G loss: 0.7416\n",
      "[164/1762] D loss: 1.3914, G loss: 0.6657\n",
      "[244/1762] D loss: 1.3924, G loss: 0.6232\n",
      "[324/1762] D loss: 1.2528, G loss: 0.7411\n",
      "[404/1762] D loss: 1.3582, G loss: 0.7133\n",
      "[484/1762] D loss: 1.1807, G loss: 0.7954\n",
      "[564/1762] D loss: 1.3876, G loss: 0.7465\n",
      "[644/1762] D loss: 1.3579, G loss: 0.7476\n",
      "[724/1762] D loss: 1.1341, G loss: 0.9361\n",
      "[804/1762] D loss: 1.4313, G loss: 0.6735\n",
      "[884/1762] D loss: 1.3871, G loss: 0.7269\n",
      "[964/1762] D loss: 1.3515, G loss: 0.7749\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.7390\n",
      "[1124/1762] D loss: 1.3994, G loss: 0.7905\n",
      "[1204/1762] D loss: 1.1435, G loss: 0.9154\n",
      "[1284/1762] D loss: 1.3824, G loss: 0.6699\n",
      "[1364/1762] D loss: 1.3384, G loss: 0.7906\n",
      "[1444/1762] D loss: 1.4137, G loss: 0.7226\n",
      "[1524/1762] D loss: 1.3489, G loss: 0.5477\n",
      "[1604/1762] D loss: 1.4167, G loss: 0.7128\n",
      "[1684/1762] D loss: 1.2748, G loss: 0.5903\n",
      "[1762/1762] D loss: 1.3628, G loss: 0.6789\n",
      "train error: \n",
      " D loss: 1.359094, G loss: 0.711151, D accuracy: 55.7%, cell accuracy: 99.3%, board accuracy: 27.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.361522, G loss: 0.708319, D accuracy: 56.8%, cell accuracy: 99.3%, board accuracy: 29.8% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3843, G loss: 0.6814\n",
      "[84/1762] D loss: 1.2500, G loss: 0.7352\n",
      "[164/1762] D loss: 1.3908, G loss: 0.7453\n",
      "[244/1762] D loss: 1.3815, G loss: 0.7893\n",
      "[324/1762] D loss: 1.3795, G loss: 0.7909\n",
      "[404/1762] D loss: 1.3894, G loss: 0.7172\n",
      "[484/1762] D loss: 1.3867, G loss: 0.6838\n",
      "[564/1762] D loss: 1.3854, G loss: 0.7118\n",
      "[644/1762] D loss: 1.3965, G loss: 0.6806\n",
      "[724/1762] D loss: 1.4069, G loss: 0.8310\n",
      "[804/1762] D loss: 1.3817, G loss: 0.6635\n",
      "[884/1762] D loss: 1.3909, G loss: 0.7676\n",
      "[964/1762] D loss: 1.3463, G loss: 0.6618\n",
      "[1044/1762] D loss: 1.1581, G loss: 0.7750\n",
      "[1124/1762] D loss: 1.3986, G loss: 0.7820\n",
      "[1204/1762] D loss: 1.1090, G loss: 0.9378\n",
      "[1284/1762] D loss: 1.4000, G loss: 0.5712\n",
      "[1364/1762] D loss: 1.3915, G loss: 0.6275\n",
      "[1444/1762] D loss: 1.3856, G loss: 0.6467\n",
      "[1524/1762] D loss: 1.2725, G loss: 0.6944\n",
      "[1604/1762] D loss: 1.4565, G loss: 0.6327\n",
      "[1684/1762] D loss: 1.3435, G loss: 0.7837\n",
      "[1762/1762] D loss: 1.0844, G loss: 0.7313\n",
      "train error: \n",
      " D loss: 1.344285, G loss: 0.737143, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 82.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.335128, G loss: 0.739639, D accuracy: 56.2%, cell accuracy: 99.7%, board accuracy: 78.0% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3909, G loss: 0.7641\n",
      "[84/1762] D loss: 1.3737, G loss: 0.7841\n",
      "[164/1762] D loss: 1.2300, G loss: 0.7053\n",
      "[244/1762] D loss: 1.3858, G loss: 0.7036\n",
      "[324/1762] D loss: 1.3868, G loss: 0.7058\n",
      "[404/1762] D loss: 1.3924, G loss: 0.6616\n",
      "[484/1762] D loss: 1.3725, G loss: 0.6556\n",
      "[564/1762] D loss: 1.3902, G loss: 0.7640\n",
      "[644/1762] D loss: 1.1617, G loss: 0.8153\n",
      "[724/1762] D loss: 1.3893, G loss: 0.7446\n",
      "[804/1762] D loss: 1.3877, G loss: 0.6535\n",
      "[884/1762] D loss: 1.3947, G loss: 0.7609\n",
      "[964/1762] D loss: 1.1402, G loss: 0.9290\n",
      "[1044/1762] D loss: 1.3901, G loss: 0.6603\n",
      "[1124/1762] D loss: 1.1109, G loss: 0.8999\n",
      "[1204/1762] D loss: 1.3908, G loss: 0.6713\n",
      "[1284/1762] D loss: 1.3804, G loss: 0.8111\n",
      "[1364/1762] D loss: 1.3751, G loss: 0.9502\n",
      "[1444/1762] D loss: 1.1496, G loss: 0.9095\n",
      "[1524/1762] D loss: 1.1374, G loss: 0.7734\n",
      "[1604/1762] D loss: 1.2746, G loss: 0.6330\n",
      "[1684/1762] D loss: 0.8290, G loss: 1.4475\n",
      "[1762/1762] D loss: 1.0330, G loss: 2.5542\n",
      "train error: \n",
      " D loss: 2.273511, G loss: 2.399729, D accuracy: 52.8%, cell accuracy: 98.8%, board accuracy: 20.7% \n",
      "\n",
      "test error: \n",
      " D loss: 2.249704, G loss: 2.424011, D accuracy: 53.2%, cell accuracy: 98.7%, board accuracy: 18.4% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.8957, G loss: 2.6243\n",
      "[84/1762] D loss: 1.3953, G loss: 0.6983\n",
      "[164/1762] D loss: 1.3947, G loss: 0.7908\n",
      "[244/1762] D loss: 1.2904, G loss: 0.8319\n",
      "[324/1762] D loss: 1.3692, G loss: 0.7736\n",
      "[404/1762] D loss: 1.4064, G loss: 0.7586\n",
      "[484/1762] D loss: 1.3889, G loss: 0.7495\n",
      "[564/1762] D loss: 1.3845, G loss: 0.7341\n",
      "[644/1762] D loss: 1.3904, G loss: 0.7660\n",
      "[724/1762] D loss: 1.3878, G loss: 0.7205\n",
      "[804/1762] D loss: 1.2236, G loss: 0.7149\n",
      "[884/1762] D loss: 1.3909, G loss: 0.7628\n",
      "[964/1762] D loss: 1.3790, G loss: 0.7128\n",
      "[1044/1762] D loss: 1.3836, G loss: 0.7432\n",
      "[1124/1762] D loss: 1.3872, G loss: 0.7297\n",
      "[1204/1762] D loss: 1.3763, G loss: 0.7298\n",
      "[1284/1762] D loss: 1.3937, G loss: 0.7387\n",
      "[1364/1762] D loss: 1.3839, G loss: 0.7458\n",
      "[1444/1762] D loss: 1.3881, G loss: 0.7308\n",
      "[1524/1762] D loss: 1.3868, G loss: 0.7026\n",
      "[1604/1762] D loss: 1.3905, G loss: 0.7442\n",
      "[1684/1762] D loss: 1.3875, G loss: 0.7120\n",
      "[1762/1762] D loss: 1.0262, G loss: 0.7528\n",
      "train error: \n",
      " D loss: 1.336801, G loss: 0.728796, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 80.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.324419, G loss: 0.728068, D accuracy: 55.3%, cell accuracy: 99.7%, board accuracy: 76.4% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3860, G loss: 0.7279\n",
      "[84/1762] D loss: 1.3871, G loss: 0.7128\n",
      "[164/1762] D loss: 1.3883, G loss: 0.7079\n",
      "[244/1762] D loss: 1.2538, G loss: 0.7163\n",
      "[324/1762] D loss: 1.3885, G loss: 0.7346\n",
      "[404/1762] D loss: 1.2039, G loss: 0.7280\n",
      "[484/1762] D loss: 1.3871, G loss: 0.7078\n",
      "[564/1762] D loss: 1.1995, G loss: 0.7316\n",
      "[644/1762] D loss: 1.3844, G loss: 0.7529\n",
      "[724/1762] D loss: 1.3943, G loss: 0.7777\n",
      "[804/1762] D loss: 1.3894, G loss: 0.7243\n",
      "[884/1762] D loss: 1.3938, G loss: 0.7439\n",
      "[964/1762] D loss: 1.1786, G loss: 0.8390\n",
      "[1044/1762] D loss: 1.3270, G loss: 0.7787\n",
      "[1124/1762] D loss: 1.0123, G loss: 0.7316\n",
      "[1204/1762] D loss: 1.3886, G loss: 0.6914\n",
      "[1284/1762] D loss: 1.3834, G loss: 0.7170\n",
      "[1364/1762] D loss: 1.3938, G loss: 0.7697\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.7098\n",
      "[1524/1762] D loss: 1.1791, G loss: 0.7674\n",
      "[1604/1762] D loss: 1.3891, G loss: 0.7370\n",
      "[1684/1762] D loss: 1.1610, G loss: 0.7986\n",
      "[1762/1762] D loss: 1.3874, G loss: 0.7068\n",
      "train error: \n",
      " D loss: 1.321172, G loss: 0.740892, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 86.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.302621, G loss: 0.739296, D accuracy: 55.7%, cell accuracy: 99.8%, board accuracy: 82.5% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3644, G loss: 0.7069\n",
      "[84/1762] D loss: 1.3820, G loss: 0.7041\n",
      "[164/1762] D loss: 1.3946, G loss: 0.7601\n",
      "[244/1762] D loss: 1.3946, G loss: 0.7312\n",
      "[324/1762] D loss: 1.3882, G loss: 0.7072\n",
      "[404/1762] D loss: 1.1476, G loss: 1.0355\n",
      "[484/1762] D loss: 1.4206, G loss: 0.7262\n",
      "[564/1762] D loss: 1.1586, G loss: 0.8895\n",
      "[644/1762] D loss: 1.3959, G loss: 0.7009\n",
      "[724/1762] D loss: 1.3062, G loss: 0.7096\n",
      "[804/1762] D loss: 1.2522, G loss: 0.7094\n",
      "[884/1762] D loss: 0.8453, G loss: 1.2730\n",
      "[964/1762] D loss: 1.4405, G loss: 0.6725\n",
      "[1044/1762] D loss: 1.3566, G loss: 0.5479\n",
      "[1124/1762] D loss: 1.0824, G loss: 1.0486\n",
      "[1204/1762] D loss: 1.0748, G loss: 0.9221\n",
      "[1284/1762] D loss: 1.4267, G loss: 0.8728\n",
      "[1364/1762] D loss: 1.1189, G loss: 0.8800\n",
      "[1444/1762] D loss: 1.3881, G loss: 0.7253\n",
      "[1524/1762] D loss: 1.3868, G loss: 0.7891\n",
      "[1604/1762] D loss: 1.3901, G loss: 0.6127\n",
      "[1684/1762] D loss: 1.3936, G loss: 0.8255\n",
      "[1762/1762] D loss: 1.5335, G loss: 0.9695\n",
      "train error: \n",
      " D loss: 1.262297, G loss: 0.931068, D accuracy: 62.7%, cell accuracy: 99.5%, board accuracy: 61.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.249132, G loss: 0.910567, D accuracy: 63.1%, cell accuracy: 99.4%, board accuracy: 58.9% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1001, G loss: 1.1473\n",
      "[84/1762] D loss: 1.5623, G loss: 0.9974\n",
      "[164/1762] D loss: 1.3891, G loss: 0.6231\n",
      "[244/1762] D loss: 1.3738, G loss: 0.7858\n",
      "[324/1762] D loss: 1.1824, G loss: 0.7040\n",
      "[404/1762] D loss: 1.3936, G loss: 0.7548\n",
      "[484/1762] D loss: 1.3152, G loss: 0.7986\n",
      "[564/1762] D loss: 1.3869, G loss: 0.6902\n",
      "[644/1762] D loss: 1.1594, G loss: 0.8090\n",
      "[724/1762] D loss: 1.4097, G loss: 0.7337\n",
      "[804/1762] D loss: 1.4105, G loss: 0.7644\n",
      "[884/1762] D loss: 1.3698, G loss: 0.6181\n",
      "[964/1762] D loss: 1.4012, G loss: 0.6312\n",
      "[1044/1762] D loss: 1.3886, G loss: 0.6870\n",
      "[1124/1762] D loss: 1.4016, G loss: 0.7654\n",
      "[1204/1762] D loss: 1.3696, G loss: 0.9164\n",
      "[1284/1762] D loss: 1.1485, G loss: 0.8712\n",
      "[1364/1762] D loss: 1.0585, G loss: 0.9508\n",
      "[1444/1762] D loss: 1.3973, G loss: 0.7933\n",
      "[1524/1762] D loss: 1.2498, G loss: 0.8523\n",
      "[1604/1762] D loss: 1.5500, G loss: 0.7902\n",
      "[1684/1762] D loss: 1.4326, G loss: 0.9625\n",
      "[1762/1762] D loss: 1.4368, G loss: 0.5753\n",
      "train error: \n",
      " D loss: 1.287313, G loss: 0.710011, D accuracy: 57.7%, cell accuracy: 99.7%, board accuracy: 78.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.253053, G loss: 0.751786, D accuracy: 59.4%, cell accuracy: 99.6%, board accuracy: 75.0% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4087, G loss: 0.6409\n",
      "[84/1762] D loss: 1.0884, G loss: 1.1891\n",
      "[164/1762] D loss: 1.3464, G loss: 0.6755\n",
      "[244/1762] D loss: 1.0537, G loss: 1.0533\n",
      "[324/1762] D loss: 1.4174, G loss: 0.6938\n",
      "[404/1762] D loss: 1.4040, G loss: 0.8370\n",
      "[484/1762] D loss: 1.4023, G loss: 0.6980\n",
      "[564/1762] D loss: 1.4046, G loss: 0.8118\n",
      "[644/1762] D loss: 1.1009, G loss: 1.0814\n",
      "[724/1762] D loss: 1.0691, G loss: 1.1728\n",
      "[804/1762] D loss: 1.1199, G loss: 0.8141\n",
      "[884/1762] D loss: 1.3789, G loss: 0.9462\n",
      "[964/1762] D loss: 1.0723, G loss: 1.1189\n",
      "[1044/1762] D loss: 1.2747, G loss: 1.1363\n",
      "[1124/1762] D loss: 1.4009, G loss: 0.7399\n",
      "[1204/1762] D loss: 1.0507, G loss: 1.3732\n",
      "[1284/1762] D loss: 1.4688, G loss: 0.5237\n",
      "[1364/1762] D loss: 1.0993, G loss: 1.4142\n",
      "[1444/1762] D loss: 1.3145, G loss: 0.7354\n",
      "[1524/1762] D loss: 1.0761, G loss: 1.0484\n",
      "[1604/1762] D loss: 1.3910, G loss: 0.6217\n",
      "[1684/1762] D loss: 1.1317, G loss: 0.8662\n",
      "[1762/1762] D loss: 1.3995, G loss: 0.6115\n",
      "train error: \n",
      " D loss: 1.339063, G loss: 0.653751, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 90.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.312402, G loss: 0.681963, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4377, G loss: 0.5484\n",
      "[84/1762] D loss: 1.0668, G loss: 0.9926\n",
      "[164/1762] D loss: 1.3877, G loss: 0.7038\n",
      "[244/1762] D loss: 1.3886, G loss: 0.6605\n",
      "[324/1762] D loss: 1.2351, G loss: 0.9948\n",
      "[404/1762] D loss: 1.3703, G loss: 0.6939\n",
      "[484/1762] D loss: 1.3878, G loss: 0.7167\n",
      "[564/1762] D loss: 1.3425, G loss: 0.7820\n",
      "[644/1762] D loss: 1.3873, G loss: 0.7140\n",
      "[724/1762] D loss: 1.0575, G loss: 1.0380\n",
      "[804/1762] D loss: 1.3644, G loss: 0.8559\n",
      "[884/1762] D loss: 1.1038, G loss: 0.8189\n",
      "[964/1762] D loss: 1.3420, G loss: 0.9491\n",
      "[1044/1762] D loss: 1.4087, G loss: 0.7493\n",
      "[1124/1762] D loss: 1.3879, G loss: 0.7232\n",
      "[1204/1762] D loss: 1.3282, G loss: 0.6881\n",
      "[1284/1762] D loss: 2.1577, G loss: 0.8168\n",
      "[1364/1762] D loss: 1.3934, G loss: 0.6874\n",
      "[1444/1762] D loss: 1.3936, G loss: 0.7466\n",
      "[1524/1762] D loss: 1.3897, G loss: 0.7045\n",
      "[1604/1762] D loss: 1.3905, G loss: 0.7383\n",
      "[1684/1762] D loss: 1.3862, G loss: 0.6941\n",
      "[1762/1762] D loss: 1.3926, G loss: 0.6767\n",
      "train error: \n",
      " D loss: 1.303373, G loss: 0.766834, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 81.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.278514, G loss: 0.791390, D accuracy: 55.1%, cell accuracy: 99.7%, board accuracy: 76.6% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3886, G loss: 0.6956\n",
      "[84/1762] D loss: 1.3875, G loss: 0.6623\n",
      "[164/1762] D loss: 1.3923, G loss: 0.7148\n",
      "[244/1762] D loss: 1.0669, G loss: 1.1411\n",
      "[324/1762] D loss: 1.3683, G loss: 0.7176\n",
      "[404/1762] D loss: 1.0532, G loss: 1.3434\n",
      "[484/1762] D loss: 0.7986, G loss: 1.3175\n",
      "[564/1762] D loss: 1.1015, G loss: 0.9286\n",
      "[644/1762] D loss: 1.0845, G loss: 0.9676\n",
      "[724/1762] D loss: 1.3935, G loss: 0.6634\n",
      "[804/1762] D loss: 1.3900, G loss: 0.6083\n",
      "[884/1762] D loss: 1.2647, G loss: 0.8925\n",
      "[964/1762] D loss: 1.2906, G loss: 0.9143\n",
      "[1044/1762] D loss: 1.3774, G loss: 0.6655\n",
      "[1124/1762] D loss: 0.9109, G loss: 1.3592\n",
      "[1204/1762] D loss: 1.0860, G loss: 0.9938\n",
      "[1284/1762] D loss: 1.3881, G loss: 0.6801\n",
      "[1364/1762] D loss: 1.0688, G loss: 1.1130\n",
      "[1444/1762] D loss: 1.3907, G loss: 0.7089\n",
      "[1524/1762] D loss: 1.4121, G loss: 0.8377\n",
      "[1604/1762] D loss: 1.0492, G loss: 1.3850\n",
      "[1684/1762] D loss: 0.9862, G loss: 1.4750\n",
      "[1762/1762] D loss: 1.2286, G loss: 0.6536\n",
      "train error: \n",
      " D loss: 1.293382, G loss: 0.755439, D accuracy: 57.7%, cell accuracy: 99.6%, board accuracy: 78.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.257720, G loss: 0.811222, D accuracy: 58.6%, cell accuracy: 99.5%, board accuracy: 76.4% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4113, G loss: 0.6837\n",
      "[84/1762] D loss: 1.3816, G loss: 0.7100\n",
      "[164/1762] D loss: 1.4069, G loss: 0.7760\n",
      "[244/1762] D loss: 1.4022, G loss: 0.5999\n",
      "[324/1762] D loss: 1.3877, G loss: 0.7213\n",
      "[404/1762] D loss: 1.3931, G loss: 0.7941\n",
      "[484/1762] D loss: 1.1382, G loss: 1.0280\n",
      "[564/1762] D loss: 1.3906, G loss: 0.6546\n",
      "[644/1762] D loss: 1.3952, G loss: 0.6985\n",
      "[724/1762] D loss: 1.3186, G loss: 0.9600\n",
      "[804/1762] D loss: 1.3248, G loss: 0.7579\n",
      "[884/1762] D loss: 1.3905, G loss: 0.7013\n",
      "[964/1762] D loss: 1.4455, G loss: 0.8558\n",
      "[1044/1762] D loss: 1.3937, G loss: 0.7557\n",
      "[1124/1762] D loss: 1.0543, G loss: 1.3697\n",
      "[1204/1762] D loss: 1.3870, G loss: 0.7135\n",
      "[1284/1762] D loss: 1.3869, G loss: 0.7064\n",
      "[1364/1762] D loss: 1.3909, G loss: 0.6969\n",
      "[1444/1762] D loss: 1.3894, G loss: 0.6509\n",
      "[1524/1762] D loss: 0.7422, G loss: 1.9151\n",
      "[1604/1762] D loss: 1.3337, G loss: 0.8162\n",
      "[1684/1762] D loss: 1.1760, G loss: 0.9790\n",
      "[1762/1762] D loss: 1.3924, G loss: 0.6544\n",
      "train error: \n",
      " D loss: 1.291843, G loss: 0.865363, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 89.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.261878, G loss: 0.938061, D accuracy: 55.6%, cell accuracy: 99.7%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3407, G loss: 0.7549\n",
      "[84/1762] D loss: 1.0570, G loss: 1.3422\n",
      "[164/1762] D loss: 1.3876, G loss: 0.7131\n",
      "[244/1762] D loss: 1.0492, G loss: 1.3242\n",
      "[324/1762] D loss: 1.3903, G loss: 0.7111\n",
      "[404/1762] D loss: 0.6289, G loss: 2.3712\n",
      "[484/1762] D loss: 1.3881, G loss: 0.7004\n",
      "[564/1762] D loss: 1.3950, G loss: 0.5972\n",
      "[644/1762] D loss: 1.3996, G loss: 0.5820\n",
      "[724/1762] D loss: 1.3888, G loss: 0.7485\n",
      "[804/1762] D loss: 1.3459, G loss: 0.8885\n",
      "[884/1762] D loss: 1.3107, G loss: 0.7906\n",
      "[964/1762] D loss: 1.4356, G loss: 0.5536\n",
      "[1044/1762] D loss: 1.0859, G loss: 1.2092\n",
      "[1124/1762] D loss: 1.0484, G loss: 1.6939\n",
      "[1204/1762] D loss: 1.3305, G loss: 0.8083\n",
      "[1284/1762] D loss: 1.3887, G loss: 0.6488\n",
      "[1364/1762] D loss: 1.3872, G loss: 0.7049\n",
      "[1444/1762] D loss: 1.0460, G loss: 1.5673\n",
      "[1524/1762] D loss: 1.3908, G loss: 0.6810\n",
      "[1604/1762] D loss: 1.0455, G loss: 1.5358\n",
      "[1684/1762] D loss: 1.3866, G loss: 0.6934\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.7009\n",
      "train error: \n",
      " D loss: 1.288213, G loss: 0.943194, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 88.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.257504, G loss: 1.036149, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0485, G loss: 1.3473\n",
      "[84/1762] D loss: 1.3872, G loss: 0.7340\n",
      "[164/1762] D loss: 1.0991, G loss: 0.9447\n",
      "[244/1762] D loss: 1.3885, G loss: 0.6975\n",
      "[324/1762] D loss: 1.3878, G loss: 0.6845\n",
      "[404/1762] D loss: 1.3852, G loss: 0.7042\n",
      "[484/1762] D loss: 1.3892, G loss: 0.7133\n",
      "[564/1762] D loss: 1.3974, G loss: 0.6401\n",
      "[644/1762] D loss: 1.3881, G loss: 0.6427\n",
      "[724/1762] D loss: 1.2999, G loss: 0.6419\n",
      "[804/1762] D loss: 1.4096, G loss: 0.6271\n",
      "[884/1762] D loss: 1.0722, G loss: 1.3497\n",
      "[964/1762] D loss: 1.3944, G loss: 0.6607\n",
      "[1044/1762] D loss: 1.3935, G loss: 0.6439\n",
      "[1124/1762] D loss: 0.7154, G loss: 2.4324\n",
      "[1204/1762] D loss: 1.3998, G loss: 0.7328\n",
      "[1284/1762] D loss: 1.3920, G loss: 0.6638\n",
      "[1364/1762] D loss: 1.0499, G loss: 1.3637\n",
      "[1444/1762] D loss: 1.3543, G loss: 0.7868\n",
      "[1524/1762] D loss: 1.4293, G loss: 0.5186\n",
      "[1604/1762] D loss: 1.3911, G loss: 0.6934\n",
      "[1684/1762] D loss: 1.0462, G loss: 1.4528\n",
      "[1762/1762] D loss: 1.3969, G loss: 0.5809\n",
      "train error: \n",
      " D loss: 1.283326, G loss: 0.923837, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 89.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.258814, G loss: 0.976389, D accuracy: 55.6%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0436, G loss: 1.6516\n",
      "[84/1762] D loss: 1.1795, G loss: 0.8269\n",
      "[164/1762] D loss: 1.3758, G loss: 0.6540\n",
      "[244/1762] D loss: 1.0368, G loss: 1.7039\n",
      "[324/1762] D loss: 1.3506, G loss: 0.6988\n",
      "[404/1762] D loss: 1.0426, G loss: 1.9372\n",
      "[484/1762] D loss: 1.0440, G loss: 1.6336\n",
      "[564/1762] D loss: 1.0469, G loss: 1.6937\n",
      "[644/1762] D loss: 1.3866, G loss: 0.7125\n",
      "[724/1762] D loss: 1.0397, G loss: 1.9908\n",
      "[804/1762] D loss: 1.3893, G loss: 0.6985\n",
      "[884/1762] D loss: 1.3921, G loss: 0.7194\n",
      "[964/1762] D loss: 1.3870, G loss: 0.6773\n",
      "[1044/1762] D loss: 1.0518, G loss: 1.0494\n",
      "[1124/1762] D loss: 1.3981, G loss: 0.6696\n",
      "[1204/1762] D loss: 1.3352, G loss: 0.7459\n",
      "[1284/1762] D loss: 1.0185, G loss: 1.9779\n",
      "[1364/1762] D loss: 1.1452, G loss: 1.1811\n",
      "[1444/1762] D loss: 1.0531, G loss: 1.4476\n",
      "[1524/1762] D loss: 1.2220, G loss: 0.7448\n",
      "[1604/1762] D loss: 1.3896, G loss: 0.6568\n",
      "[1684/1762] D loss: 1.3522, G loss: 0.6891\n",
      "[1762/1762] D loss: 1.3892, G loss: 0.7442\n",
      "train error: \n",
      " D loss: 1.302322, G loss: 0.877747, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 87.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.277062, G loss: 0.927237, D accuracy: 54.9%, cell accuracy: 99.7%, board accuracy: 84.1% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7992, G loss: 1.7001\n",
      "[84/1762] D loss: 1.4284, G loss: 0.7394\n",
      "[164/1762] D loss: 1.3864, G loss: 0.7761\n",
      "[244/1762] D loss: 1.0925, G loss: 1.0276\n",
      "[324/1762] D loss: 1.0845, G loss: 0.9932\n",
      "[404/1762] D loss: 1.0530, G loss: 1.2347\n",
      "[484/1762] D loss: 1.3869, G loss: 0.7140\n",
      "[564/1762] D loss: 1.0467, G loss: 1.5238\n",
      "[644/1762] D loss: 1.3874, G loss: 0.7045\n",
      "[724/1762] D loss: 1.3872, G loss: 0.6794\n",
      "[804/1762] D loss: 1.3868, G loss: 0.7041\n",
      "[884/1762] D loss: 1.3884, G loss: 0.7035\n",
      "[964/1762] D loss: 1.3882, G loss: 0.6890\n",
      "[1044/1762] D loss: 1.3415, G loss: 0.7590\n",
      "[1124/1762] D loss: 1.4156, G loss: 0.5797\n",
      "[1204/1762] D loss: 1.4526, G loss: 0.7687\n",
      "[1284/1762] D loss: 1.3893, G loss: 0.6640\n",
      "[1364/1762] D loss: 1.3908, G loss: 0.7132\n",
      "[1444/1762] D loss: 1.3870, G loss: 0.6940\n",
      "[1524/1762] D loss: 1.2753, G loss: 0.9360\n",
      "[1604/1762] D loss: 1.3874, G loss: 0.6994\n",
      "[1684/1762] D loss: 1.2099, G loss: 1.3648\n",
      "[1762/1762] D loss: 1.3897, G loss: 0.7301\n",
      "train error: \n",
      " D loss: 1.284284, G loss: 0.990578, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 89.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.263895, G loss: 1.109267, D accuracy: 55.1%, cell accuracy: 99.7%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2353, G loss: 0.8519\n",
      "[84/1762] D loss: 1.3908, G loss: 0.7344\n",
      "[164/1762] D loss: 1.3883, G loss: 0.6308\n",
      "[244/1762] D loss: 1.3808, G loss: 0.6825\n",
      "[324/1762] D loss: 1.3898, G loss: 0.6538\n",
      "[404/1762] D loss: 1.5382, G loss: 0.7481\n",
      "[484/1762] D loss: 1.3915, G loss: 0.7324\n",
      "[564/1762] D loss: 0.6308, G loss: 2.6217\n",
      "[644/1762] D loss: 1.3891, G loss: 0.7474\n",
      "[724/1762] D loss: 1.3849, G loss: 0.6816\n",
      "[804/1762] D loss: 1.3873, G loss: 0.6922\n",
      "[884/1762] D loss: 1.3465, G loss: 0.7408\n",
      "[964/1762] D loss: 1.3911, G loss: 0.7004\n",
      "[1044/1762] D loss: 1.3426, G loss: 0.7368\n",
      "[1124/1762] D loss: 1.3893, G loss: 0.6639\n",
      "[1204/1762] D loss: 1.3725, G loss: 0.6910\n",
      "[1284/1762] D loss: 1.3362, G loss: 0.8417\n",
      "[1364/1762] D loss: 1.3913, G loss: 0.6873\n",
      "[1444/1762] D loss: 1.0430, G loss: 1.6560\n",
      "[1524/1762] D loss: 1.0433, G loss: 1.7534\n",
      "[1604/1762] D loss: 1.3905, G loss: 0.6629\n",
      "[1684/1762] D loss: 1.3869, G loss: 0.7031\n",
      "[1762/1762] D loss: 1.3914, G loss: 0.6478\n",
      "train error: \n",
      " D loss: 1.285191, G loss: 0.972251, D accuracy: 54.4%, cell accuracy: 99.9%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.259712, G loss: 1.040496, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3920, G loss: 0.6553\n",
      "[84/1762] D loss: 1.3914, G loss: 0.6768\n",
      "[164/1762] D loss: 1.3921, G loss: 0.7006\n",
      "[244/1762] D loss: 1.0393, G loss: 1.2630\n",
      "[324/1762] D loss: 1.0486, G loss: 1.4267\n",
      "[404/1762] D loss: 0.7037, G loss: 2.4136\n",
      "[484/1762] D loss: 1.3874, G loss: 0.6984\n",
      "[564/1762] D loss: 1.3867, G loss: 0.6811\n",
      "[644/1762] D loss: 1.3873, G loss: 0.7063\n",
      "[724/1762] D loss: 0.9540, G loss: 2.0737\n",
      "[804/1762] D loss: 1.0552, G loss: 1.9968\n",
      "[884/1762] D loss: 1.3902, G loss: 0.6325\n",
      "[964/1762] D loss: 1.3875, G loss: 0.6621\n",
      "[1044/1762] D loss: 1.0535, G loss: 1.2816\n",
      "[1124/1762] D loss: 1.3866, G loss: 0.7077\n",
      "[1204/1762] D loss: 1.3871, G loss: 0.6790\n",
      "[1284/1762] D loss: 1.0464, G loss: 1.5282\n",
      "[1364/1762] D loss: 1.2408, G loss: 1.0634\n",
      "[1444/1762] D loss: 1.3872, G loss: 0.6987\n",
      "[1524/1762] D loss: 1.0455, G loss: 1.6180\n",
      "[1604/1762] D loss: 1.2134, G loss: 1.9879\n",
      "[1684/1762] D loss: 0.8671, G loss: 3.1179\n",
      "[1762/1762] D loss: 1.3879, G loss: 0.6711\n",
      "train error: \n",
      " D loss: 1.281774, G loss: 0.935940, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 90.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.261413, G loss: 1.012413, D accuracy: 55.3%, cell accuracy: 99.7%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0449, G loss: 1.6996\n",
      "[84/1762] D loss: 1.3893, G loss: 0.7269\n",
      "[164/1762] D loss: 1.3835, G loss: 0.7228\n",
      "[244/1762] D loss: 1.3869, G loss: 0.7120\n",
      "[324/1762] D loss: 1.3888, G loss: 0.6543\n",
      "[404/1762] D loss: 1.3957, G loss: 0.6511\n",
      "[484/1762] D loss: 1.0745, G loss: 1.0635\n",
      "[564/1762] D loss: 1.3868, G loss: 0.7057\n",
      "[644/1762] D loss: 1.3874, G loss: 0.7218\n",
      "[724/1762] D loss: 1.3874, G loss: 0.6705\n",
      "[804/1762] D loss: 1.3877, G loss: 0.7075\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6917\n",
      "[964/1762] D loss: 0.7008, G loss: 2.5301\n",
      "[1044/1762] D loss: 1.3865, G loss: 0.7063\n",
      "[1124/1762] D loss: 1.3866, G loss: 0.6945\n",
      "[1204/1762] D loss: 1.3880, G loss: 0.6749\n",
      "[1284/1762] D loss: 1.2239, G loss: 1.2767\n",
      "[1364/1762] D loss: 1.3869, G loss: 0.6972\n",
      "[1444/1762] D loss: 1.0417, G loss: 1.7664\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.6922\n",
      "[1604/1762] D loss: 1.0394, G loss: 1.8219\n",
      "[1684/1762] D loss: 1.3919, G loss: 0.7017\n",
      "[1762/1762] D loss: 1.1533, G loss: 1.6995\n",
      "train error: \n",
      " D loss: 1.276455, G loss: 1.572156, D accuracy: 56.0%, cell accuracy: 99.7%, board accuracy: 80.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.228315, G loss: 1.720741, D accuracy: 57.8%, cell accuracy: 99.5%, board accuracy: 77.0% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1366, G loss: 1.0556\n",
      "[84/1762] D loss: 0.5135, G loss: 5.1863\n",
      "[164/1762] D loss: 1.0149, G loss: 2.6561\n",
      "[244/1762] D loss: 1.0794, G loss: 1.2474\n",
      "[324/1762] D loss: 1.4062, G loss: 0.7266\n",
      "[404/1762] D loss: 1.3870, G loss: 0.7015\n",
      "[484/1762] D loss: 1.3874, G loss: 0.6742\n",
      "[564/1762] D loss: 1.3992, G loss: 0.6080\n",
      "[644/1762] D loss: 1.0456, G loss: 1.5241\n",
      "[724/1762] D loss: 1.3892, G loss: 0.6699\n",
      "[804/1762] D loss: 1.3875, G loss: 0.7093\n",
      "[884/1762] D loss: 1.0438, G loss: 1.8486\n",
      "[964/1762] D loss: 1.3996, G loss: 0.6915\n",
      "[1044/1762] D loss: 1.0443, G loss: 1.7026\n",
      "[1124/1762] D loss: 1.3837, G loss: 0.6778\n",
      "[1204/1762] D loss: 1.3649, G loss: 0.6972\n",
      "[1284/1762] D loss: 0.8673, G loss: 2.6749\n",
      "[1364/1762] D loss: 1.3874, G loss: 0.6757\n",
      "[1444/1762] D loss: 1.3880, G loss: 0.6749\n",
      "[1524/1762] D loss: 1.4019, G loss: 0.6844\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6800\n",
      "[1684/1762] D loss: 1.3871, G loss: 0.6908\n",
      "[1762/1762] D loss: 1.3869, G loss: 0.7335\n",
      "train error: \n",
      " D loss: 1.346846, G loss: 1.342666, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.332037, G loss: 1.500132, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2329, G loss: 2.5919\n",
      "[84/1762] D loss: 1.3940, G loss: 0.6745\n",
      "[164/1762] D loss: 1.3867, G loss: 0.6847\n",
      "[244/1762] D loss: 1.3869, G loss: 0.6956\n",
      "[324/1762] D loss: 1.0413, G loss: 1.9460\n",
      "[404/1762] D loss: 1.3867, G loss: 0.6910\n",
      "[484/1762] D loss: 1.3874, G loss: 0.6648\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6830\n",
      "[644/1762] D loss: 1.0424, G loss: 2.1570\n",
      "[724/1762] D loss: 1.3872, G loss: 0.6922\n",
      "[804/1762] D loss: 1.3902, G loss: 0.6372\n",
      "[884/1762] D loss: 1.3885, G loss: 0.7290\n",
      "[964/1762] D loss: 1.0435, G loss: 1.6160\n",
      "[1044/1762] D loss: 1.3876, G loss: 0.6754\n",
      "[1124/1762] D loss: 1.3876, G loss: 0.6703\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6898\n",
      "[1284/1762] D loss: 1.3867, G loss: 0.6815\n",
      "[1364/1762] D loss: 1.3880, G loss: 0.7208\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6890\n",
      "[1524/1762] D loss: 1.3829, G loss: 0.7093\n",
      "[1604/1762] D loss: 1.3874, G loss: 0.7100\n",
      "[1684/1762] D loss: 1.0408, G loss: 2.0219\n",
      "[1762/1762] D loss: 1.3868, G loss: 0.7014\n",
      "train error: \n",
      " D loss: 1.286066, G loss: 1.144433, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.256879, G loss: 1.277864, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3866, G loss: 0.7014\n",
      "[84/1762] D loss: 1.0402, G loss: 2.4108\n",
      "[164/1762] D loss: 1.3877, G loss: 0.7094\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6985\n",
      "[324/1762] D loss: 1.3868, G loss: 0.6783\n",
      "[404/1762] D loss: 1.3874, G loss: 0.6827\n",
      "[484/1762] D loss: 1.3865, G loss: 0.6998\n",
      "[564/1762] D loss: 1.3880, G loss: 0.6753\n",
      "[644/1762] D loss: 1.0406, G loss: 2.6595\n",
      "[724/1762] D loss: 1.0414, G loss: 2.1247\n",
      "[804/1762] D loss: 1.3884, G loss: 0.7246\n",
      "[884/1762] D loss: 1.3992, G loss: 0.6197\n",
      "[964/1762] D loss: 1.0426, G loss: 2.0994\n",
      "[1044/1762] D loss: 1.3874, G loss: 0.6666\n",
      "[1124/1762] D loss: 1.3885, G loss: 0.7318\n",
      "[1204/1762] D loss: 0.9463, G loss: 3.9212\n",
      "[1284/1762] D loss: 1.0428, G loss: 3.2401\n",
      "[1364/1762] D loss: 1.3875, G loss: 0.6540\n",
      "[1444/1762] D loss: 1.3790, G loss: 0.7323\n",
      "[1524/1762] D loss: 1.3876, G loss: 0.6740\n",
      "[1604/1762] D loss: 1.3660, G loss: 0.6735\n",
      "[1684/1762] D loss: 1.3869, G loss: 0.7076\n",
      "[1762/1762] D loss: 1.3462, G loss: 0.7210\n",
      "train error: \n",
      " D loss: 1.270599, G loss: 1.438191, D accuracy: 55.8%, cell accuracy: 99.6%, board accuracy: 71.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.254211, G loss: 1.715673, D accuracy: 56.4%, cell accuracy: 99.5%, board accuracy: 73.2% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3973, G loss: 0.7094\n",
      "[84/1762] D loss: 1.3874, G loss: 0.6834\n",
      "[164/1762] D loss: 1.2902, G loss: 1.2688\n",
      "[244/1762] D loss: 1.0441, G loss: 2.1483\n",
      "[324/1762] D loss: 1.3851, G loss: 0.6079\n",
      "[404/1762] D loss: 1.2523, G loss: 0.8146\n",
      "[484/1762] D loss: 1.3914, G loss: 0.6767\n",
      "[564/1762] D loss: 0.7056, G loss: 2.3701\n",
      "[644/1762] D loss: 1.3961, G loss: 0.7825\n",
      "[724/1762] D loss: 1.3908, G loss: 0.6752\n",
      "[804/1762] D loss: 1.0473, G loss: 1.4998\n",
      "[884/1762] D loss: 1.0163, G loss: 1.8989\n",
      "[964/1762] D loss: 1.3866, G loss: 0.6719\n",
      "[1044/1762] D loss: 1.0405, G loss: 2.2547\n",
      "[1124/1762] D loss: 1.3868, G loss: 0.6938\n",
      "[1204/1762] D loss: 1.3870, G loss: 0.6910\n",
      "[1284/1762] D loss: 1.0407, G loss: 2.1624\n",
      "[1364/1762] D loss: 1.2175, G loss: 1.2233\n",
      "[1444/1762] D loss: 1.3908, G loss: 0.6372\n",
      "[1524/1762] D loss: 1.3525, G loss: 0.6534\n",
      "[1604/1762] D loss: 1.3139, G loss: 0.7790\n",
      "[1684/1762] D loss: 1.0448, G loss: 1.9310\n",
      "[1762/1762] D loss: 1.3918, G loss: 0.6933\n",
      "train error: \n",
      " D loss: 1.285228, G loss: 1.045271, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 89.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.250226, G loss: 1.202485, D accuracy: 55.8%, cell accuracy: 99.7%, board accuracy: 85.0% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3900, G loss: 0.6959\n",
      "[84/1762] D loss: 1.3879, G loss: 0.7200\n",
      "[164/1762] D loss: 1.0479, G loss: 1.5077\n",
      "[244/1762] D loss: 1.3874, G loss: 0.6711\n",
      "[324/1762] D loss: 1.0431, G loss: 1.9520\n",
      "[404/1762] D loss: 1.0539, G loss: 1.2332\n",
      "[484/1762] D loss: 1.3881, G loss: 0.6475\n",
      "[564/1762] D loss: 1.0404, G loss: 2.4957\n",
      "[644/1762] D loss: 0.9890, G loss: 1.6553\n",
      "[724/1762] D loss: 1.0370, G loss: 2.0394\n",
      "[804/1762] D loss: 1.3973, G loss: 0.7479\n",
      "[884/1762] D loss: 1.3892, G loss: 0.6637\n",
      "[964/1762] D loss: 1.3866, G loss: 0.6858\n",
      "[1044/1762] D loss: 1.3897, G loss: 0.6567\n",
      "[1124/1762] D loss: 1.3867, G loss: 0.7048\n",
      "[1204/1762] D loss: 1.3883, G loss: 0.6588\n",
      "[1284/1762] D loss: 1.3869, G loss: 0.6797\n",
      "[1364/1762] D loss: 1.3881, G loss: 0.6895\n",
      "[1444/1762] D loss: 1.3866, G loss: 0.7012\n",
      "[1524/1762] D loss: 1.3887, G loss: 0.7008\n",
      "[1604/1762] D loss: 1.3539, G loss: 0.7179\n",
      "[1684/1762] D loss: 1.3880, G loss: 0.7035\n",
      "[1762/1762] D loss: 1.3871, G loss: 0.6863\n",
      "train error: \n",
      " D loss: 1.267662, G loss: 1.106001, D accuracy: 56.3%, cell accuracy: 99.8%, board accuracy: 86.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.224803, G loss: 1.293412, D accuracy: 58.6%, cell accuracy: 99.7%, board accuracy: 81.6% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3883, G loss: 0.6627\n",
      "[84/1762] D loss: 1.4318, G loss: 0.7508\n",
      "[164/1762] D loss: 1.3870, G loss: 0.6680\n",
      "[244/1762] D loss: 1.3881, G loss: 0.6819\n",
      "[324/1762] D loss: 1.3871, G loss: 0.6840\n",
      "[404/1762] D loss: 0.9082, G loss: 2.1472\n",
      "[484/1762] D loss: 1.3911, G loss: 0.6903\n",
      "[564/1762] D loss: 1.3878, G loss: 0.6673\n",
      "[644/1762] D loss: 1.3880, G loss: 0.6621\n",
      "[724/1762] D loss: 1.0406, G loss: 2.0270\n",
      "[804/1762] D loss: 1.0418, G loss: 1.7568\n",
      "[884/1762] D loss: 0.6956, G loss: 3.1016\n",
      "[964/1762] D loss: 1.3864, G loss: 0.7017\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.6962\n",
      "[1124/1762] D loss: 1.3869, G loss: 0.6807\n",
      "[1204/1762] D loss: 1.3881, G loss: 0.6680\n",
      "[1284/1762] D loss: 1.0386, G loss: 1.6809\n",
      "[1364/1762] D loss: 1.3871, G loss: 0.7062\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6936\n",
      "[1524/1762] D loss: 1.0417, G loss: 1.8949\n",
      "[1604/1762] D loss: 1.3865, G loss: 0.7056\n",
      "[1684/1762] D loss: 0.6957, G loss: 3.0479\n",
      "[1762/1762] D loss: 1.3870, G loss: 0.6892\n",
      "train error: \n",
      " D loss: 1.284078, G loss: 1.056757, D accuracy: 54.0%, cell accuracy: 99.9%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.256212, G loss: 1.143353, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2266, G loss: 1.3225\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6918\n",
      "[164/1762] D loss: 1.3867, G loss: 0.6946\n",
      "[244/1762] D loss: 1.3864, G loss: 0.6827\n",
      "[324/1762] D loss: 1.3865, G loss: 0.6909\n",
      "[404/1762] D loss: 1.0409, G loss: 1.9523\n",
      "[484/1762] D loss: 1.0403, G loss: 2.0923\n",
      "[564/1762] D loss: 1.3878, G loss: 0.7275\n",
      "[644/1762] D loss: 1.3864, G loss: 0.7093\n",
      "[724/1762] D loss: 1.2144, G loss: 2.7643\n",
      "[804/1762] D loss: 1.3868, G loss: 0.6982\n",
      "[884/1762] D loss: 1.0447, G loss: 1.9477\n",
      "[964/1762] D loss: 1.3920, G loss: 0.6566\n",
      "[1044/1762] D loss: 1.3902, G loss: 0.6511\n",
      "[1124/1762] D loss: 1.3879, G loss: 0.6901\n",
      "[1204/1762] D loss: 1.3355, G loss: 0.7220\n",
      "[1284/1762] D loss: 1.0441, G loss: 1.9720\n",
      "[1364/1762] D loss: 1.3928, G loss: 0.6700\n",
      "[1444/1762] D loss: 1.3887, G loss: 0.6515\n",
      "[1524/1762] D loss: 1.3880, G loss: 0.7112\n",
      "[1604/1762] D loss: 1.3868, G loss: 0.6792\n",
      "[1684/1762] D loss: 1.3876, G loss: 0.6804\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.7069\n",
      "train error: \n",
      " D loss: 1.280956, G loss: 1.176184, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.250769, G loss: 1.307073, D accuracy: 56.1%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3876, G loss: 0.6676\n",
      "[84/1762] D loss: 1.2065, G loss: 2.3320\n",
      "[164/1762] D loss: 1.1449, G loss: 2.9017\n",
      "[244/1762] D loss: 1.2542, G loss: 1.0422\n",
      "[324/1762] D loss: 1.0469, G loss: 1.7194\n",
      "[404/1762] D loss: 1.0444, G loss: 1.7521\n",
      "[484/1762] D loss: 1.3889, G loss: 0.6543\n",
      "[564/1762] D loss: 1.3866, G loss: 0.6820\n",
      "[644/1762] D loss: 1.3885, G loss: 0.6885\n",
      "[724/1762] D loss: 1.0847, G loss: 3.2478\n",
      "[804/1762] D loss: 1.3752, G loss: 0.5263\n",
      "[884/1762] D loss: 1.3931, G loss: 0.7031\n",
      "[964/1762] D loss: 1.0436, G loss: 1.9990\n",
      "[1044/1762] D loss: 1.3878, G loss: 0.6894\n",
      "[1124/1762] D loss: 1.3891, G loss: 0.6847\n",
      "[1204/1762] D loss: 1.3888, G loss: 0.6580\n",
      "[1284/1762] D loss: 1.3898, G loss: 0.6633\n",
      "[1364/1762] D loss: 1.1067, G loss: 1.7510\n",
      "[1444/1762] D loss: 0.9905, G loss: 1.7894\n",
      "[1524/1762] D loss: 0.7022, G loss: 2.4021\n",
      "[1604/1762] D loss: 1.3874, G loss: 0.6835\n",
      "[1684/1762] D loss: 1.2410, G loss: 1.0891\n",
      "[1762/1762] D loss: 0.6965, G loss: 2.8772\n",
      "train error: \n",
      " D loss: 1.282672, G loss: 1.030157, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 85.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.257573, G loss: 1.109295, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0423, G loss: 1.7075\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6997\n",
      "[164/1762] D loss: 1.0412, G loss: 2.2503\n",
      "[244/1762] D loss: 1.3899, G loss: 0.6792\n",
      "[324/1762] D loss: 1.3865, G loss: 0.6922\n",
      "[404/1762] D loss: 1.3877, G loss: 0.6816\n",
      "[484/1762] D loss: 1.3870, G loss: 0.7033\n",
      "[564/1762] D loss: 1.3885, G loss: 0.6859\n",
      "[644/1762] D loss: 1.0406, G loss: 2.0403\n",
      "[724/1762] D loss: 1.3867, G loss: 0.7095\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6968\n",
      "[884/1762] D loss: 1.3868, G loss: 0.7095\n",
      "[964/1762] D loss: 1.3865, G loss: 0.6908\n",
      "[1044/1762] D loss: 1.3862, G loss: 0.6889\n",
      "[1124/1762] D loss: 1.3867, G loss: 0.6999\n",
      "[1204/1762] D loss: 1.3886, G loss: 0.6654\n",
      "[1284/1762] D loss: 1.3867, G loss: 0.7026\n",
      "[1364/1762] D loss: 1.3874, G loss: 0.7052\n",
      "[1444/1762] D loss: 1.0414, G loss: 1.8344\n",
      "[1524/1762] D loss: 1.2300, G loss: 1.5948\n",
      "[1604/1762] D loss: 1.0398, G loss: 2.4374\n",
      "[1684/1762] D loss: 1.0414, G loss: 1.9376\n",
      "[1762/1762] D loss: 1.3866, G loss: 0.6793\n",
      "train error: \n",
      " D loss: 1.286323, G loss: 1.076049, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.255541, G loss: 1.219249, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0406, G loss: 1.9410\n",
      "[84/1762] D loss: 1.3867, G loss: 0.7092\n",
      "[164/1762] D loss: 1.3864, G loss: 0.6885\n",
      "[244/1762] D loss: 1.3867, G loss: 0.6932\n",
      "[324/1762] D loss: 1.3864, G loss: 0.7024\n",
      "[404/1762] D loss: 1.3868, G loss: 0.6870\n",
      "[484/1762] D loss: 1.3864, G loss: 0.6920\n",
      "[564/1762] D loss: 1.0406, G loss: 2.0259\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6959\n",
      "[724/1762] D loss: 1.0403, G loss: 2.0564\n",
      "[804/1762] D loss: 1.0404, G loss: 2.3256\n",
      "[884/1762] D loss: 1.0402, G loss: 2.1079\n",
      "[964/1762] D loss: 1.3865, G loss: 0.6995\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.6851\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.7038\n",
      "[1204/1762] D loss: 1.3943, G loss: 0.6144\n",
      "[1284/1762] D loss: 1.0461, G loss: 1.8782\n",
      "[1364/1762] D loss: 1.2148, G loss: 1.3098\n",
      "[1444/1762] D loss: 1.3869, G loss: 0.6839\n",
      "[1524/1762] D loss: 1.2122, G loss: 3.1814\n",
      "[1604/1762] D loss: 1.3885, G loss: 0.7402\n",
      "[1684/1762] D loss: 1.3891, G loss: 0.6560\n",
      "[1762/1762] D loss: 1.3871, G loss: 0.6917\n",
      "train error: \n",
      " D loss: 1.277738, G loss: 1.125521, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 90.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.253489, G loss: 1.202625, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3873, G loss: 0.6719\n",
      "[84/1762] D loss: 1.3878, G loss: 0.6843\n",
      "[164/1762] D loss: 1.0408, G loss: 2.0874\n",
      "[244/1762] D loss: 1.0405, G loss: 2.1039\n",
      "[324/1762] D loss: 1.3874, G loss: 0.6959\n",
      "[404/1762] D loss: 1.3867, G loss: 0.6823\n",
      "[484/1762] D loss: 1.3901, G loss: 0.6691\n",
      "[564/1762] D loss: 1.3870, G loss: 0.6826\n",
      "[644/1762] D loss: 1.0403, G loss: 2.1578\n",
      "[724/1762] D loss: 1.3870, G loss: 0.6716\n",
      "[804/1762] D loss: 1.0421, G loss: 2.1752\n",
      "[884/1762] D loss: 1.3873, G loss: 0.6948\n",
      "[964/1762] D loss: 1.3869, G loss: 0.6717\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.6902\n",
      "[1124/1762] D loss: 1.3883, G loss: 0.6670\n",
      "[1204/1762] D loss: 1.3867, G loss: 0.6907\n",
      "[1284/1762] D loss: 1.0433, G loss: 2.2030\n",
      "[1364/1762] D loss: 1.3877, G loss: 0.6954\n",
      "[1444/1762] D loss: 1.3868, G loss: 0.6853\n",
      "[1524/1762] D loss: 1.0402, G loss: 2.1537\n",
      "[1604/1762] D loss: 1.3951, G loss: 0.6546\n",
      "[1684/1762] D loss: 1.0401, G loss: 2.2086\n",
      "[1762/1762] D loss: 1.3869, G loss: 0.7145\n",
      "train error: \n",
      " D loss: 1.277167, G loss: 1.201582, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.244897, G loss: 1.398978, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3280, G loss: 0.7862\n",
      "[84/1762] D loss: 1.3866, G loss: 0.7004\n",
      "[164/1762] D loss: 1.3865, G loss: 0.6812\n",
      "[244/1762] D loss: 1.0401, G loss: 2.2732\n",
      "[324/1762] D loss: 1.3868, G loss: 0.6982\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6848\n",
      "[484/1762] D loss: 1.3865, G loss: 0.6787\n",
      "[564/1762] D loss: 1.3863, G loss: 0.6946\n",
      "[644/1762] D loss: 1.3869, G loss: 0.6903\n",
      "[724/1762] D loss: 1.3871, G loss: 0.6701\n",
      "[804/1762] D loss: 1.3865, G loss: 0.6999\n",
      "[884/1762] D loss: 1.3877, G loss: 0.6661\n",
      "[964/1762] D loss: 1.3864, G loss: 0.6915\n",
      "[1044/1762] D loss: 1.3872, G loss: 0.6820\n",
      "[1124/1762] D loss: 1.0409, G loss: 1.9352\n",
      "[1204/1762] D loss: 1.3867, G loss: 0.6925\n",
      "[1284/1762] D loss: 1.1984, G loss: 3.1986\n",
      "[1364/1762] D loss: 1.3269, G loss: 0.7856\n",
      "[1444/1762] D loss: 0.6965, G loss: 3.0795\n",
      "[1524/1762] D loss: 1.3869, G loss: 0.7138\n",
      "[1604/1762] D loss: 1.3854, G loss: 0.7206\n",
      "[1684/1762] D loss: 1.3867, G loss: 0.6775\n",
      "[1762/1762] D loss: 1.3876, G loss: 0.7161\n",
      "train error: \n",
      " D loss: 1.278052, G loss: 1.237091, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.248281, G loss: 1.405748, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1845, G loss: 5.9143\n",
      "[84/1762] D loss: 1.2084, G loss: 1.6199\n",
      "[164/1762] D loss: 1.2019, G loss: 5.5186\n",
      "[244/1762] D loss: 1.4287, G loss: 0.6470\n",
      "[324/1762] D loss: 1.3902, G loss: 0.7025\n",
      "[404/1762] D loss: 1.3897, G loss: 0.6424\n",
      "[484/1762] D loss: 1.0443, G loss: 1.9706\n",
      "[564/1762] D loss: 1.3887, G loss: 0.7112\n",
      "[644/1762] D loss: 1.0403, G loss: 2.2470\n",
      "[724/1762] D loss: 1.3865, G loss: 0.6942\n",
      "[804/1762] D loss: 1.3866, G loss: 0.6904\n",
      "[884/1762] D loss: 0.9830, G loss: 2.3538\n",
      "[964/1762] D loss: 1.3873, G loss: 0.6865\n",
      "[1044/1762] D loss: 1.3865, G loss: 0.6853\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.7014\n",
      "[1204/1762] D loss: 1.3877, G loss: 0.6697\n",
      "[1284/1762] D loss: 1.3877, G loss: 0.6829\n",
      "[1364/1762] D loss: 1.3909, G loss: 0.7148\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.6879\n",
      "[1524/1762] D loss: 1.3878, G loss: 0.6828\n",
      "[1604/1762] D loss: 1.0405, G loss: 2.0930\n",
      "[1684/1762] D loss: 1.3872, G loss: 0.6749\n",
      "[1762/1762] D loss: 0.6942, G loss: 3.7209\n",
      "train error: \n",
      " D loss: 1.281673, G loss: 1.166918, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.249312, G loss: 1.323619, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0404, G loss: 2.1749\n",
      "[84/1762] D loss: 1.3866, G loss: 0.6907\n",
      "[164/1762] D loss: 1.3867, G loss: 0.7045\n",
      "[244/1762] D loss: 1.3869, G loss: 0.6807\n",
      "[324/1762] D loss: 1.0400, G loss: 2.2863\n",
      "[404/1762] D loss: 1.3840, G loss: 0.7036\n",
      "[484/1762] D loss: 1.3862, G loss: 0.6981\n",
      "[564/1762] D loss: 1.3863, G loss: 0.6884\n",
      "[644/1762] D loss: 1.0407, G loss: 2.2084\n",
      "[724/1762] D loss: 1.3864, G loss: 0.7033\n",
      "[804/1762] D loss: 1.3866, G loss: 0.6982\n",
      "[884/1762] D loss: 1.3872, G loss: 0.6715\n",
      "[964/1762] D loss: 1.3866, G loss: 0.6870\n",
      "[1044/1762] D loss: 1.3865, G loss: 0.7087\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.6967\n",
      "[1204/1762] D loss: 1.0399, G loss: 2.4285\n",
      "[1284/1762] D loss: 1.3924, G loss: 0.7213\n",
      "[1364/1762] D loss: 1.0404, G loss: 2.1635\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6955\n",
      "[1524/1762] D loss: 1.0405, G loss: 2.1513\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.7015\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.6965\n",
      "[1762/1762] D loss: 0.6937, G loss: 3.7838\n",
      "train error: \n",
      " D loss: 1.285119, G loss: 1.154711, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.257275, G loss: 1.278749, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6946\n",
      "[84/1762] D loss: 1.3866, G loss: 0.6802\n",
      "[164/1762] D loss: 1.3864, G loss: 0.6907\n",
      "[244/1762] D loss: 1.0401, G loss: 2.2467\n",
      "[324/1762] D loss: 1.3865, G loss: 0.6961\n",
      "[404/1762] D loss: 0.6938, G loss: 3.7960\n",
      "[484/1762] D loss: 1.3865, G loss: 0.6890\n",
      "[564/1762] D loss: 1.0404, G loss: 2.2578\n",
      "[644/1762] D loss: 1.0399, G loss: 2.3380\n",
      "[724/1762] D loss: 0.6937, G loss: 4.0402\n",
      "[804/1762] D loss: 1.3852, G loss: 0.6740\n",
      "[884/1762] D loss: 0.8788, G loss: 3.2469\n",
      "[964/1762] D loss: 1.3869, G loss: 0.6859\n",
      "[1044/1762] D loss: 1.4004, G loss: 0.6386\n",
      "[1124/1762] D loss: 1.3871, G loss: 0.6684\n",
      "[1204/1762] D loss: 1.3855, G loss: 0.6899\n",
      "[1284/1762] D loss: 1.0410, G loss: 1.8877\n",
      "[1364/1762] D loss: 1.3859, G loss: 0.6975\n",
      "[1444/1762] D loss: 1.3803, G loss: 0.7592\n",
      "[1524/1762] D loss: 1.3894, G loss: 0.7076\n",
      "[1604/1762] D loss: 1.3903, G loss: 0.7124\n",
      "[1684/1762] D loss: 1.3923, G loss: 0.6318\n",
      "[1762/1762] D loss: 0.6945, G loss: 3.7867\n",
      "train error: \n",
      " D loss: 1.271605, G loss: 1.362691, D accuracy: 56.0%, cell accuracy: 99.7%, board accuracy: 86.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.238132, G loss: 1.567264, D accuracy: 57.5%, cell accuracy: 99.7%, board accuracy: 83.4% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3877, G loss: 0.6683\n",
      "[84/1762] D loss: 1.3815, G loss: 0.6735\n",
      "[164/1762] D loss: 1.3873, G loss: 0.7067\n",
      "[244/1762] D loss: 1.3879, G loss: 0.7006\n",
      "[324/1762] D loss: 1.3880, G loss: 0.7131\n",
      "[404/1762] D loss: 1.3910, G loss: 0.6285\n",
      "[484/1762] D loss: 1.3860, G loss: 0.6740\n",
      "[564/1762] D loss: 1.0465, G loss: 1.5633\n",
      "[644/1762] D loss: 1.3871, G loss: 0.6621\n",
      "[724/1762] D loss: 1.0451, G loss: 1.7596\n",
      "[804/1762] D loss: 1.0417, G loss: 1.7574\n",
      "[884/1762] D loss: 1.3869, G loss: 0.7116\n",
      "[964/1762] D loss: 1.3871, G loss: 0.7122\n",
      "[1044/1762] D loss: 1.0429, G loss: 1.7425\n",
      "[1124/1762] D loss: 1.3872, G loss: 0.6919\n",
      "[1204/1762] D loss: 1.0408, G loss: 1.9344\n",
      "[1284/1762] D loss: 1.2138, G loss: 1.9011\n",
      "[1364/1762] D loss: 1.3882, G loss: 0.6599\n",
      "[1444/1762] D loss: 1.3862, G loss: 0.6920\n",
      "[1524/1762] D loss: 1.3890, G loss: 0.6470\n",
      "[1604/1762] D loss: 1.3870, G loss: 0.6951\n",
      "[1684/1762] D loss: 1.3887, G loss: 0.6781\n",
      "[1762/1762] D loss: 1.3886, G loss: 0.7244\n",
      "train error: \n",
      " D loss: 1.278318, G loss: 1.279138, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 90.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.250988, G loss: 1.405889, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3957, G loss: 0.7551\n",
      "[84/1762] D loss: 1.3874, G loss: 0.7242\n",
      "[164/1762] D loss: 1.3874, G loss: 0.6878\n",
      "[244/1762] D loss: 1.3869, G loss: 0.7093\n",
      "[324/1762] D loss: 1.0407, G loss: 2.2942\n",
      "[404/1762] D loss: 1.3944, G loss: 0.6755\n",
      "[484/1762] D loss: 1.3865, G loss: 0.6881\n",
      "[564/1762] D loss: 1.0411, G loss: 2.1834\n",
      "[644/1762] D loss: 1.3867, G loss: 0.6955\n",
      "[724/1762] D loss: 1.3866, G loss: 0.6975\n",
      "[804/1762] D loss: 1.3863, G loss: 0.6873\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6929\n",
      "[964/1762] D loss: 1.3868, G loss: 0.7083\n",
      "[1044/1762] D loss: 1.3873, G loss: 0.7071\n",
      "[1124/1762] D loss: 1.3894, G loss: 0.7185\n",
      "[1204/1762] D loss: 1.3871, G loss: 0.6899\n",
      "[1284/1762] D loss: 1.3866, G loss: 0.6842\n",
      "[1364/1762] D loss: 1.3858, G loss: 0.7008\n",
      "[1444/1762] D loss: 1.3872, G loss: 0.6816\n",
      "[1524/1762] D loss: 1.2508, G loss: 1.2220\n",
      "[1604/1762] D loss: 1.3854, G loss: 0.7116\n",
      "[1684/1762] D loss: 1.3841, G loss: 0.6133\n",
      "[1762/1762] D loss: 1.4408, G loss: 0.4929\n",
      "train error: \n",
      " D loss: 1.223904, G loss: 1.253686, D accuracy: 61.1%, cell accuracy: 99.6%, board accuracy: 59.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.193999, G loss: 1.322282, D accuracy: 62.5%, cell accuracy: 99.5%, board accuracy: 58.9% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2384, G loss: 0.8164\n",
      "[84/1762] D loss: 1.3921, G loss: 0.6860\n",
      "[164/1762] D loss: 1.0394, G loss: 1.3688\n",
      "[244/1762] D loss: 1.0410, G loss: 2.0127\n",
      "[324/1762] D loss: 1.3214, G loss: 0.7501\n",
      "[404/1762] D loss: 1.3444, G loss: 0.7100\n",
      "[484/1762] D loss: 1.3887, G loss: 0.6988\n",
      "[564/1762] D loss: 1.3627, G loss: 0.7688\n",
      "[644/1762] D loss: 1.3532, G loss: 0.6511\n",
      "[724/1762] D loss: 1.3871, G loss: 0.7101\n",
      "[804/1762] D loss: 1.0618, G loss: 1.5599\n",
      "[884/1762] D loss: 1.3623, G loss: 0.7020\n",
      "[964/1762] D loss: 1.3507, G loss: 1.0907\n",
      "[1044/1762] D loss: 0.9313, G loss: 4.1504\n",
      "[1124/1762] D loss: 0.8975, G loss: 1.0057\n",
      "[1204/1762] D loss: 0.9089, G loss: 4.9183\n",
      "[1284/1762] D loss: 1.1740, G loss: 4.1813\n",
      "[1364/1762] D loss: 1.2899, G loss: 1.5142\n",
      "[1444/1762] D loss: 1.4097, G loss: 0.7629\n",
      "[1524/1762] D loss: 1.3894, G loss: 0.6883\n",
      "[1604/1762] D loss: 1.3865, G loss: 0.6973\n",
      "[1684/1762] D loss: 1.3957, G loss: 0.6530\n",
      "[1762/1762] D loss: 1.3910, G loss: 0.7067\n",
      "train error: \n",
      " D loss: 1.289462, G loss: 1.258198, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.259757, G loss: 1.436722, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0430, G loss: 2.9400\n",
      "[84/1762] D loss: 1.3865, G loss: 0.6939\n",
      "[164/1762] D loss: 1.0417, G loss: 2.4082\n",
      "[244/1762] D loss: 1.3973, G loss: 0.6162\n",
      "[324/1762] D loss: 1.3988, G loss: 0.6153\n",
      "[404/1762] D loss: 1.3905, G loss: 0.6323\n",
      "[484/1762] D loss: 1.3888, G loss: 0.6545\n",
      "[564/1762] D loss: 1.3861, G loss: 0.7069\n",
      "[644/1762] D loss: 1.3872, G loss: 0.6991\n",
      "[724/1762] D loss: 1.0406, G loss: 2.2798\n",
      "[804/1762] D loss: 1.0409, G loss: 2.2504\n",
      "[884/1762] D loss: 1.3871, G loss: 0.7116\n",
      "[964/1762] D loss: 1.0439, G loss: 2.1912\n",
      "[1044/1762] D loss: 0.6952, G loss: 3.8841\n",
      "[1124/1762] D loss: 1.0403, G loss: 2.2620\n",
      "[1204/1762] D loss: 1.0437, G loss: 2.3121\n",
      "[1284/1762] D loss: 1.2989, G loss: 0.7824\n",
      "[1364/1762] D loss: 1.2798, G loss: 1.1177\n",
      "[1444/1762] D loss: 1.3724, G loss: 0.7264\n",
      "[1524/1762] D loss: 1.3878, G loss: 0.6787\n",
      "[1604/1762] D loss: 1.0427, G loss: 2.3539\n",
      "[1684/1762] D loss: 1.3831, G loss: 0.7105\n",
      "[1762/1762] D loss: 1.3896, G loss: 0.7325\n",
      "train error: \n",
      " D loss: 1.286274, G loss: 1.249520, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.255237, G loss: 1.415052, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3871, G loss: 0.6912\n",
      "[84/1762] D loss: 1.3876, G loss: 0.7155\n",
      "[164/1762] D loss: 1.0401, G loss: 2.3731\n",
      "[244/1762] D loss: 1.3882, G loss: 0.6905\n",
      "[324/1762] D loss: 1.0417, G loss: 2.3265\n",
      "[404/1762] D loss: 1.3894, G loss: 0.6592\n",
      "[484/1762] D loss: 1.0519, G loss: 2.4208\n",
      "[564/1762] D loss: 1.3865, G loss: 0.6892\n",
      "[644/1762] D loss: 1.3873, G loss: 0.6823\n",
      "[724/1762] D loss: 1.3885, G loss: 0.6812\n",
      "[804/1762] D loss: 1.3875, G loss: 0.6723\n",
      "[884/1762] D loss: 1.3866, G loss: 0.6999\n",
      "[964/1762] D loss: 0.8438, G loss: 3.8856\n",
      "[1044/1762] D loss: 1.3867, G loss: 0.6940\n",
      "[1124/1762] D loss: 0.6938, G loss: 3.9121\n",
      "[1204/1762] D loss: 1.3555, G loss: 0.7128\n",
      "[1284/1762] D loss: 1.3868, G loss: 0.7065\n",
      "[1364/1762] D loss: 1.3879, G loss: 0.6518\n",
      "[1444/1762] D loss: 1.3872, G loss: 0.6873\n",
      "[1524/1762] D loss: 1.0411, G loss: 2.2713\n",
      "[1604/1762] D loss: 1.0450, G loss: 2.2545\n",
      "[1684/1762] D loss: 1.3862, G loss: 0.6853\n",
      "[1762/1762] D loss: 1.3974, G loss: 0.6854\n",
      "train error: \n",
      " D loss: 1.287963, G loss: 1.179653, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.260446, G loss: 1.310652, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6897\n",
      "[84/1762] D loss: 1.3881, G loss: 0.6628\n",
      "[164/1762] D loss: 1.3839, G loss: 0.6733\n",
      "[244/1762] D loss: 1.3876, G loss: 0.6757\n",
      "[324/1762] D loss: 1.0411, G loss: 2.4425\n",
      "[404/1762] D loss: 1.3873, G loss: 0.6739\n",
      "[484/1762] D loss: 1.3875, G loss: 0.7020\n",
      "[564/1762] D loss: 1.3872, G loss: 0.6836\n",
      "[644/1762] D loss: 1.3892, G loss: 0.7363\n",
      "[724/1762] D loss: 1.0583, G loss: 2.5569\n",
      "[804/1762] D loss: 1.0412, G loss: 3.9902\n",
      "[884/1762] D loss: 1.3931, G loss: 0.6390\n",
      "[964/1762] D loss: 1.3910, G loss: 0.6797\n",
      "[1044/1762] D loss: 1.3898, G loss: 0.6844\n",
      "[1124/1762] D loss: 0.9052, G loss: 2.4771\n",
      "[1204/1762] D loss: 1.4848, G loss: 0.4630\n",
      "[1284/1762] D loss: 1.2413, G loss: 0.9661\n",
      "[1364/1762] D loss: 1.3815, G loss: 0.6810\n",
      "[1444/1762] D loss: 1.2190, G loss: 2.8398\n",
      "[1524/1762] D loss: 1.3903, G loss: 0.7182\n",
      "[1604/1762] D loss: 1.3880, G loss: 0.6769\n",
      "[1684/1762] D loss: 1.3876, G loss: 0.7042\n",
      "[1762/1762] D loss: 1.3868, G loss: 0.6870\n",
      "train error: \n",
      " D loss: 1.284521, G loss: 1.222556, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.257546, G loss: 1.385681, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0402, G loss: 2.4782\n",
      "[84/1762] D loss: 1.3889, G loss: 0.7198\n",
      "[164/1762] D loss: 1.3879, G loss: 0.7017\n",
      "[244/1762] D loss: 1.3882, G loss: 0.6632\n",
      "[324/1762] D loss: 1.0403, G loss: 2.4806\n",
      "[404/1762] D loss: 0.6981, G loss: 3.4662\n",
      "[484/1762] D loss: 1.3867, G loss: 0.7106\n",
      "[564/1762] D loss: 1.0401, G loss: 2.7605\n",
      "[644/1762] D loss: 1.3870, G loss: 0.6743\n",
      "[724/1762] D loss: 1.3887, G loss: 0.7392\n",
      "[804/1762] D loss: 1.0504, G loss: 1.3813\n",
      "[884/1762] D loss: 1.3868, G loss: 0.6963\n",
      "[964/1762] D loss: 1.3867, G loss: 0.6978\n",
      "[1044/1762] D loss: 1.3885, G loss: 0.7423\n",
      "[1124/1762] D loss: 1.3876, G loss: 0.6756\n",
      "[1204/1762] D loss: 1.0398, G loss: 2.5947\n",
      "[1284/1762] D loss: 1.3868, G loss: 0.7067\n",
      "[1364/1762] D loss: 1.3867, G loss: 0.6975\n",
      "[1444/1762] D loss: 1.0412, G loss: 2.5745\n",
      "[1524/1762] D loss: 1.3878, G loss: 0.6671\n",
      "[1604/1762] D loss: 1.0403, G loss: 2.5663\n",
      "[1684/1762] D loss: 1.3868, G loss: 0.6890\n",
      "[1762/1762] D loss: 1.3878, G loss: 0.6597\n",
      "train error: \n",
      " D loss: 1.286432, G loss: 1.214142, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.256658, G loss: 1.373360, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0403, G loss: 2.4661\n",
      "[84/1762] D loss: 1.3876, G loss: 0.6936\n",
      "[164/1762] D loss: 1.0398, G loss: 2.4616\n",
      "[244/1762] D loss: 1.3867, G loss: 0.6936\n",
      "[324/1762] D loss: 1.0400, G loss: 2.5342\n",
      "[404/1762] D loss: 1.3571, G loss: 0.7732\n",
      "[484/1762] D loss: 1.3882, G loss: 0.6736\n",
      "[564/1762] D loss: 1.3881, G loss: 0.6510\n",
      "[644/1762] D loss: 1.0400, G loss: 2.6035\n",
      "[724/1762] D loss: 1.3865, G loss: 0.6721\n",
      "[804/1762] D loss: 1.3869, G loss: 0.6984\n",
      "[884/1762] D loss: 1.2026, G loss: 1.2972\n",
      "[964/1762] D loss: 1.3871, G loss: 0.7049\n",
      "[1044/1762] D loss: 1.3872, G loss: 0.6744\n",
      "[1124/1762] D loss: 1.0431, G loss: 3.6159\n",
      "[1204/1762] D loss: 1.3915, G loss: 0.7529\n",
      "[1284/1762] D loss: 1.3875, G loss: 0.7044\n",
      "[1364/1762] D loss: 1.0460, G loss: 2.4512\n",
      "[1444/1762] D loss: 1.0573, G loss: 2.7436\n",
      "[1524/1762] D loss: 1.3917, G loss: 0.6482\n",
      "[1604/1762] D loss: 1.2107, G loss: 3.3556\n",
      "[1684/1762] D loss: 1.0411, G loss: 2.7185\n",
      "[1762/1762] D loss: 1.3876, G loss: 0.6730\n",
      "train error: \n",
      " D loss: 1.281719, G loss: 1.272661, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 89.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.254861, G loss: 1.476512, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3894, G loss: 0.7143\n",
      "[84/1762] D loss: 1.3878, G loss: 0.7313\n",
      "[164/1762] D loss: 1.3877, G loss: 0.6742\n",
      "[244/1762] D loss: 1.0450, G loss: 2.6060\n",
      "[324/1762] D loss: 1.3866, G loss: 0.6959\n",
      "[404/1762] D loss: 0.6954, G loss: 4.0772\n",
      "[484/1762] D loss: 1.0509, G loss: 7.4552\n",
      "[564/1762] D loss: 1.0331, G loss: 2.4657\n",
      "[644/1762] D loss: 1.3866, G loss: 0.6864\n",
      "[724/1762] D loss: 1.3614, G loss: 0.6987\n",
      "[804/1762] D loss: 1.3979, G loss: 0.6950\n",
      "[884/1762] D loss: 0.8641, G loss: 3.8999\n",
      "[964/1762] D loss: 1.1945, G loss: 2.3739\n",
      "[1044/1762] D loss: 1.3883, G loss: 0.7303\n",
      "[1124/1762] D loss: 1.0424, G loss: 2.3950\n",
      "[1204/1762] D loss: 1.3874, G loss: 0.7194\n",
      "[1284/1762] D loss: 1.3868, G loss: 0.7056\n",
      "[1364/1762] D loss: 1.3871, G loss: 0.6864\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.6940\n",
      "[1524/1762] D loss: 1.0377, G loss: 2.6216\n",
      "[1604/1762] D loss: 1.0396, G loss: 2.6779\n",
      "[1684/1762] D loss: 0.6936, G loss: 4.6033\n",
      "[1762/1762] D loss: 1.3870, G loss: 0.7113\n",
      "train error: \n",
      " D loss: 1.283890, G loss: 1.286520, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 89.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.254695, G loss: 1.430708, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3868, G loss: 0.6916\n",
      "[84/1762] D loss: 1.1903, G loss: 2.5549\n",
      "[164/1762] D loss: 1.3865, G loss: 0.7068\n",
      "[244/1762] D loss: 1.0409, G loss: 2.6046\n",
      "[324/1762] D loss: 1.3873, G loss: 0.7199\n",
      "[404/1762] D loss: 1.0399, G loss: 2.5791\n",
      "[484/1762] D loss: 1.0401, G loss: 2.5858\n",
      "[564/1762] D loss: 1.3868, G loss: 0.6964\n",
      "[644/1762] D loss: 1.3852, G loss: 0.7042\n",
      "[724/1762] D loss: 1.3870, G loss: 0.6801\n",
      "[804/1762] D loss: 1.3865, G loss: 0.6900\n",
      "[884/1762] D loss: 1.3869, G loss: 0.6713\n",
      "[964/1762] D loss: 1.3866, G loss: 0.7023\n",
      "[1044/1762] D loss: 1.0397, G loss: 2.6466\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.6901\n",
      "[1204/1762] D loss: 1.3866, G loss: 0.6879\n",
      "[1284/1762] D loss: 0.6933, G loss: 4.4842\n",
      "[1364/1762] D loss: 1.3875, G loss: 0.6626\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6952\n",
      "[1524/1762] D loss: 1.3866, G loss: 0.7071\n",
      "[1604/1762] D loss: 1.3796, G loss: 0.6797\n",
      "[1684/1762] D loss: 1.0400, G loss: 2.6025\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6953\n",
      "train error: \n",
      " D loss: 1.284499, G loss: 1.269219, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.255566, G loss: 1.480996, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3870, G loss: 0.7133\n",
      "[84/1762] D loss: 1.0403, G loss: 2.5685\n",
      "[164/1762] D loss: 1.3864, G loss: 0.6913\n",
      "[244/1762] D loss: 1.3864, G loss: 0.7005\n",
      "[324/1762] D loss: 1.0106, G loss: 2.6692\n",
      "[404/1762] D loss: 1.3860, G loss: 0.6859\n",
      "[484/1762] D loss: 1.2023, G loss: 2.6537\n",
      "[564/1762] D loss: 1.3880, G loss: 0.6518\n",
      "[644/1762] D loss: 1.0409, G loss: 2.6116\n",
      "[724/1762] D loss: 1.0399, G loss: 2.4259\n",
      "[804/1762] D loss: 1.3877, G loss: 0.6683\n",
      "[884/1762] D loss: 0.8940, G loss: 3.4834\n",
      "[964/1762] D loss: 1.0424, G loss: 2.8085\n",
      "[1044/1762] D loss: 1.3871, G loss: 0.6795\n",
      "[1124/1762] D loss: 1.0400, G loss: 2.6818\n",
      "[1204/1762] D loss: 1.3895, G loss: 0.7340\n",
      "[1284/1762] D loss: 1.3884, G loss: 0.6795\n",
      "[1364/1762] D loss: 1.3867, G loss: 0.6862\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6887\n",
      "[1524/1762] D loss: 0.8562, G loss: 3.2464\n",
      "[1604/1762] D loss: 1.3902, G loss: 0.6573\n",
      "[1684/1762] D loss: 1.3858, G loss: 0.6790\n",
      "[1762/1762] D loss: 1.4381, G loss: 0.7584\n",
      "train error: \n",
      " D loss: 1.285760, G loss: 1.306736, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.257225, G loss: 1.538087, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0405, G loss: 2.4214\n",
      "[84/1762] D loss: 1.3868, G loss: 0.6929\n",
      "[164/1762] D loss: 1.0404, G loss: 2.3773\n",
      "[244/1762] D loss: 1.3893, G loss: 0.6632\n",
      "[324/1762] D loss: 1.3875, G loss: 0.6601\n",
      "[404/1762] D loss: 1.3891, G loss: 0.6833\n",
      "[484/1762] D loss: 1.3866, G loss: 0.7057\n",
      "[564/1762] D loss: 1.0403, G loss: 2.4869\n",
      "[644/1762] D loss: 1.0399, G loss: 2.4614\n",
      "[724/1762] D loss: 1.0400, G loss: 2.4494\n",
      "[804/1762] D loss: 1.3868, G loss: 0.6775\n",
      "[884/1762] D loss: 1.3878, G loss: 0.6602\n",
      "[964/1762] D loss: 1.2368, G loss: 1.1221\n",
      "[1044/1762] D loss: 1.3885, G loss: 0.6851\n",
      "[1124/1762] D loss: 1.0403, G loss: 2.4731\n",
      "[1204/1762] D loss: 1.3866, G loss: 0.6823\n",
      "[1284/1762] D loss: 1.3871, G loss: 0.6659\n",
      "[1364/1762] D loss: 1.3862, G loss: 0.6843\n",
      "[1444/1762] D loss: 1.0402, G loss: 2.4439\n",
      "[1524/1762] D loss: 1.3870, G loss: 0.6791\n",
      "[1604/1762] D loss: 1.3859, G loss: 0.6856\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.6888\n",
      "[1762/1762] D loss: 1.3855, G loss: 0.6875\n",
      "train error: \n",
      " D loss: 1.285280, G loss: 1.303854, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 89.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.256475, G loss: 1.520097, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0406, G loss: 2.0999\n",
      "[84/1762] D loss: 0.3468, G loss: 7.0514\n",
      "[164/1762] D loss: 1.3869, G loss: 0.6779\n",
      "[244/1762] D loss: 1.0433, G loss: 2.6177\n",
      "[324/1762] D loss: 1.0411, G loss: 2.5016\n",
      "[404/1762] D loss: 1.0403, G loss: 2.5071\n",
      "[484/1762] D loss: 1.2478, G loss: 3.2032\n",
      "[564/1762] D loss: 1.3870, G loss: 0.6849\n",
      "[644/1762] D loss: 1.3880, G loss: 0.7381\n",
      "[724/1762] D loss: 1.0623, G loss: 2.9302\n",
      "[804/1762] D loss: 1.3911, G loss: 0.7284\n",
      "[884/1762] D loss: 1.3866, G loss: 0.6956\n",
      "[964/1762] D loss: 1.3870, G loss: 0.6911\n",
      "[1044/1762] D loss: 1.3869, G loss: 0.6960\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.6859\n",
      "[1204/1762] D loss: 1.3872, G loss: 0.6884\n",
      "[1284/1762] D loss: 1.3869, G loss: 0.7049\n",
      "[1364/1762] D loss: 1.3902, G loss: 0.6493\n",
      "[1444/1762] D loss: 1.3868, G loss: 0.6786\n",
      "[1524/1762] D loss: 1.3875, G loss: 0.6657\n",
      "[1604/1762] D loss: 1.0402, G loss: 2.3170\n",
      "[1684/1762] D loss: 1.3870, G loss: 0.6897\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6931\n",
      "train error: \n",
      " D loss: 1.280827, G loss: 1.183626, D accuracy: 54.4%, cell accuracy: 99.9%, board accuracy: 90.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.256132, G loss: 1.298911, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3876, G loss: 0.6892\n",
      "[84/1762] D loss: 0.8490, G loss: 3.4772\n",
      "[164/1762] D loss: 1.3868, G loss: 0.6902\n",
      "[244/1762] D loss: 1.3868, G loss: 0.6792\n",
      "[324/1762] D loss: 1.3882, G loss: 0.6600\n",
      "[404/1762] D loss: 1.0404, G loss: 2.3500\n",
      "[484/1762] D loss: 1.0403, G loss: 2.3570\n",
      "[564/1762] D loss: 1.3933, G loss: 0.6724\n",
      "[644/1762] D loss: 1.3867, G loss: 0.6968\n",
      "[724/1762] D loss: 1.3862, G loss: 0.6935\n",
      "[804/1762] D loss: 1.3858, G loss: 0.7006\n",
      "[884/1762] D loss: 1.0402, G loss: 2.6457\n",
      "[964/1762] D loss: 1.3874, G loss: 0.6973\n",
      "[1044/1762] D loss: 1.2094, G loss: 4.0377\n",
      "[1124/1762] D loss: 1.0405, G loss: 2.3577\n",
      "[1204/1762] D loss: 1.3868, G loss: 0.6893\n",
      "[1284/1762] D loss: 1.0400, G loss: 2.3841\n",
      "[1364/1762] D loss: 1.3865, G loss: 0.6977\n",
      "[1444/1762] D loss: 1.0406, G loss: 2.3574\n",
      "[1524/1762] D loss: 1.3865, G loss: 0.7058\n",
      "[1604/1762] D loss: 1.0403, G loss: 2.3132\n",
      "[1684/1762] D loss: 1.0402, G loss: 2.2701\n",
      "[1762/1762] D loss: 1.3869, G loss: 0.6918\n",
      "train error: \n",
      " D loss: 1.286833, G loss: 1.154180, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.257852, G loss: 1.362987, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3866, G loss: 0.6806\n",
      "[84/1762] D loss: 1.0399, G loss: 2.3476\n",
      "[164/1762] D loss: 1.3876, G loss: 0.6838\n",
      "[244/1762] D loss: 1.3865, G loss: 0.6931\n",
      "[324/1762] D loss: 1.2207, G loss: 2.4921\n",
      "[404/1762] D loss: 1.0421, G loss: 2.5513\n",
      "[484/1762] D loss: 1.4190, G loss: 0.7511\n",
      "[564/1762] D loss: 1.3901, G loss: 0.6475\n",
      "[644/1762] D loss: 1.0344, G loss: 2.2619\n",
      "[724/1762] D loss: 1.3328, G loss: 0.9836\n",
      "[804/1762] D loss: 1.3896, G loss: 0.6822\n",
      "[884/1762] D loss: 1.3957, G loss: 0.6821\n",
      "[964/1762] D loss: 1.3883, G loss: 0.7112\n",
      "[1044/1762] D loss: 1.3889, G loss: 0.6651\n",
      "[1124/1762] D loss: 1.3879, G loss: 0.6701\n",
      "[1204/1762] D loss: 1.3861, G loss: 0.7042\n",
      "[1284/1762] D loss: 1.0412, G loss: 2.2626\n",
      "[1364/1762] D loss: 0.9255, G loss: 2.6115\n",
      "[1444/1762] D loss: 1.0439, G loss: 1.5213\n",
      "[1524/1762] D loss: 1.0475, G loss: 1.4617\n",
      "[1604/1762] D loss: 1.3893, G loss: 0.7014\n",
      "[1684/1762] D loss: 1.0439, G loss: 1.6387\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6938\n",
      "train error: \n",
      " D loss: 1.288174, G loss: 0.989215, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.259373, G loss: 1.074539, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3868, G loss: 0.6818\n",
      "[84/1762] D loss: 1.3866, G loss: 0.6970\n",
      "[164/1762] D loss: 1.3860, G loss: 0.6846\n",
      "[244/1762] D loss: 1.3874, G loss: 0.6839\n",
      "[324/1762] D loss: 1.3869, G loss: 0.7002\n",
      "[404/1762] D loss: 1.0415, G loss: 1.8458\n",
      "[484/1762] D loss: 1.0410, G loss: 1.9097\n",
      "[564/1762] D loss: 1.3821, G loss: 0.6824\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6929\n",
      "[724/1762] D loss: 1.0415, G loss: 2.1123\n",
      "[804/1762] D loss: 1.3876, G loss: 0.7143\n",
      "[884/1762] D loss: 1.3873, G loss: 0.6675\n",
      "[964/1762] D loss: 1.0404, G loss: 2.1061\n",
      "[1044/1762] D loss: 1.3868, G loss: 0.6837\n",
      "[1124/1762] D loss: 1.3876, G loss: 0.6884\n",
      "[1204/1762] D loss: 1.3868, G loss: 0.6827\n",
      "[1284/1762] D loss: 1.0403, G loss: 2.1010\n",
      "[1364/1762] D loss: 1.3871, G loss: 0.6871\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6932\n",
      "[1524/1762] D loss: 1.3869, G loss: 0.6982\n",
      "[1604/1762] D loss: 1.0402, G loss: 2.2625\n",
      "[1684/1762] D loss: 1.0261, G loss: 3.6843\n",
      "[1762/1762] D loss: 1.3857, G loss: 0.7115\n",
      "train error: \n",
      " D loss: 1.284924, G loss: 1.157765, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 91.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.256165, G loss: 1.289921, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0401, G loss: 2.1900\n",
      "[84/1762] D loss: 1.0445, G loss: 2.2103\n",
      "[164/1762] D loss: 1.3868, G loss: 0.6902\n",
      "[244/1762] D loss: 1.0400, G loss: 2.3068\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6919\n",
      "[404/1762] D loss: 1.0399, G loss: 2.3248\n",
      "[484/1762] D loss: 1.3871, G loss: 0.6917\n",
      "[564/1762] D loss: 1.3867, G loss: 0.6830\n",
      "[644/1762] D loss: 1.3862, G loss: 0.6988\n",
      "[724/1762] D loss: 0.3472, G loss: 5.7033\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6943\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6856\n",
      "[964/1762] D loss: 1.0399, G loss: 2.4318\n",
      "[1044/1762] D loss: 1.3865, G loss: 0.6853\n",
      "[1124/1762] D loss: 1.0399, G loss: 2.5460\n",
      "[1204/1762] D loss: 1.0400, G loss: 2.3161\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6832\n",
      "[1364/1762] D loss: 1.0378, G loss: 2.2103\n",
      "[1444/1762] D loss: 1.3866, G loss: 0.6893\n",
      "[1524/1762] D loss: 1.3875, G loss: 0.6754\n",
      "[1604/1762] D loss: 1.3866, G loss: 0.6786\n",
      "[1684/1762] D loss: 1.3948, G loss: 0.8232\n",
      "[1762/1762] D loss: 0.6974, G loss: 2.7494\n",
      "train error: \n",
      " D loss: 1.287381, G loss: 1.012194, D accuracy: 54.0%, cell accuracy: 99.9%, board accuracy: 91.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.255359, G loss: 1.104686, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3865, G loss: 0.6886\n",
      "[84/1762] D loss: 1.3869, G loss: 0.6661\n",
      "[164/1762] D loss: 1.3869, G loss: 0.6781\n",
      "[244/1762] D loss: 1.3875, G loss: 0.6617\n",
      "[324/1762] D loss: 1.3868, G loss: 0.6936\n",
      "[404/1762] D loss: 1.0413, G loss: 1.8827\n",
      "[484/1762] D loss: 1.3889, G loss: 0.6507\n",
      "[564/1762] D loss: 1.3867, G loss: 0.6985\n",
      "[644/1762] D loss: 1.0416, G loss: 2.0272\n",
      "[724/1762] D loss: 1.3870, G loss: 0.7725\n",
      "[804/1762] D loss: 1.3827, G loss: 0.6571\n",
      "[884/1762] D loss: 1.3866, G loss: 0.6768\n",
      "[964/1762] D loss: 1.3893, G loss: 0.6555\n",
      "[1044/1762] D loss: 1.3780, G loss: 0.6882\n",
      "[1124/1762] D loss: 1.0404, G loss: 1.9916\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6908\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6917\n",
      "[1364/1762] D loss: 1.3871, G loss: 0.6714\n",
      "[1444/1762] D loss: 1.3868, G loss: 0.7061\n",
      "[1524/1762] D loss: 1.3862, G loss: 0.7097\n",
      "[1604/1762] D loss: 1.3865, G loss: 0.7049\n",
      "[1684/1762] D loss: 1.3865, G loss: 0.6955\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.7169\n",
      "train error: \n",
      " D loss: 1.285576, G loss: 1.108712, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 91.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.257220, G loss: 1.230240, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0480, G loss: 2.0664\n",
      "[84/1762] D loss: 1.3856, G loss: 0.7092\n",
      "[164/1762] D loss: 1.3866, G loss: 0.7005\n",
      "[244/1762] D loss: 1.0406, G loss: 2.1176\n",
      "[324/1762] D loss: 1.3866, G loss: 0.7108\n",
      "[404/1762] D loss: 1.0402, G loss: 2.1654\n",
      "[484/1762] D loss: 1.3867, G loss: 0.6928\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6941\n",
      "[644/1762] D loss: 1.3866, G loss: 0.7050\n",
      "[724/1762] D loss: 1.3867, G loss: 0.6880\n",
      "[804/1762] D loss: 1.3865, G loss: 0.6918\n",
      "[884/1762] D loss: 1.3872, G loss: 0.6721\n",
      "[964/1762] D loss: 1.3867, G loss: 0.6880\n",
      "[1044/1762] D loss: 1.3871, G loss: 0.6895\n",
      "[1124/1762] D loss: 1.0404, G loss: 2.2011\n",
      "[1204/1762] D loss: 1.0403, G loss: 2.2158\n",
      "[1284/1762] D loss: 1.3865, G loss: 0.6988\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6886\n",
      "[1444/1762] D loss: 0.6937, G loss: 3.7724\n",
      "[1524/1762] D loss: 1.3944, G loss: 0.6884\n",
      "[1604/1762] D loss: 1.3551, G loss: 0.7282\n",
      "[1684/1762] D loss: 1.3944, G loss: 0.6917\n",
      "[1762/1762] D loss: 1.3875, G loss: 0.7246\n",
      "train error: \n",
      " D loss: 1.284459, G loss: 1.191986, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 90.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.256060, G loss: 1.327289, D accuracy: 55.7%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0406, G loss: 2.5268\n",
      "[84/1762] D loss: 1.0346, G loss: 2.5450\n",
      "[164/1762] D loss: 1.3308, G loss: 0.7487\n",
      "[244/1762] D loss: 1.3879, G loss: 0.7269\n",
      "[324/1762] D loss: 1.0403, G loss: 2.4814\n",
      "[404/1762] D loss: 1.0396, G loss: 2.9759\n",
      "[484/1762] D loss: 1.3868, G loss: 0.7031\n",
      "[564/1762] D loss: 1.3883, G loss: 0.7207\n",
      "[644/1762] D loss: 1.3871, G loss: 0.6783\n",
      "[724/1762] D loss: 1.3865, G loss: 0.6945\n",
      "[804/1762] D loss: 1.0405, G loss: 2.8432\n",
      "[884/1762] D loss: 1.3866, G loss: 0.6850\n",
      "[964/1762] D loss: 1.3866, G loss: 0.6953\n",
      "[1044/1762] D loss: 1.3865, G loss: 0.7008\n",
      "[1124/1762] D loss: 1.0398, G loss: 2.8103\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6940\n",
      "[1284/1762] D loss: 1.3866, G loss: 0.7007\n",
      "[1364/1762] D loss: 1.3879, G loss: 0.7085\n",
      "[1444/1762] D loss: 0.6937, G loss: 5.3477\n",
      "[1524/1762] D loss: 1.3865, G loss: 0.6924\n",
      "[1604/1762] D loss: 1.3865, G loss: 0.6974\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.6975\n",
      "[1762/1762] D loss: 1.3861, G loss: 0.7116\n",
      "train error: \n",
      " D loss: 1.282896, G loss: 1.362427, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.254013, G loss: 1.557853, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0399, G loss: 2.8469\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6970\n",
      "[164/1762] D loss: 1.3864, G loss: 0.6928\n",
      "[244/1762] D loss: 1.3867, G loss: 0.6738\n",
      "[324/1762] D loss: 1.3859, G loss: 0.6955\n",
      "[404/1762] D loss: 1.0412, G loss: 2.8135\n",
      "[484/1762] D loss: 1.0408, G loss: 2.7965\n",
      "[564/1762] D loss: 1.3867, G loss: 0.6991\n",
      "[644/1762] D loss: 1.3868, G loss: 0.7081\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6918\n",
      "[804/1762] D loss: 1.3865, G loss: 0.6907\n",
      "[884/1762] D loss: 1.3865, G loss: 0.6976\n",
      "[964/1762] D loss: 1.3861, G loss: 0.6888\n",
      "[1044/1762] D loss: 1.0399, G loss: 2.6629\n",
      "[1124/1762] D loss: 0.6958, G loss: 4.7628\n",
      "[1204/1762] D loss: 1.3896, G loss: 0.6626\n",
      "[1284/1762] D loss: 1.2361, G loss: 1.2172\n",
      "[1364/1762] D loss: 1.3854, G loss: 0.7385\n",
      "[1444/1762] D loss: 1.4113, G loss: 0.6066\n",
      "[1524/1762] D loss: 1.3145, G loss: 0.8086\n",
      "[1604/1762] D loss: 0.9548, G loss: 2.2237\n",
      "[1684/1762] D loss: 1.3879, G loss: 0.6792\n",
      "[1762/1762] D loss: 1.4086, G loss: 0.6052\n",
      "train error: \n",
      " D loss: 1.286243, G loss: 1.276433, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 91.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.253273, G loss: 1.378995, D accuracy: 55.8%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3926, G loss: 0.6724\n",
      "[84/1762] D loss: 1.0402, G loss: 2.2588\n",
      "[164/1762] D loss: 1.3897, G loss: 0.6260\n",
      "[244/1762] D loss: 1.0406, G loss: 2.2769\n",
      "[324/1762] D loss: 1.3869, G loss: 0.6850\n",
      "[404/1762] D loss: 1.3807, G loss: 0.6955\n",
      "[484/1762] D loss: 1.3868, G loss: 0.6865\n",
      "[564/1762] D loss: 1.3882, G loss: 0.7126\n",
      "[644/1762] D loss: 1.3879, G loss: 0.6832\n",
      "[724/1762] D loss: 0.6970, G loss: 3.5716\n",
      "[804/1762] D loss: 1.3714, G loss: 0.7423\n",
      "[884/1762] D loss: 1.3884, G loss: 0.6571\n",
      "[964/1762] D loss: 1.3869, G loss: 0.7148\n",
      "[1044/1762] D loss: 1.0399, G loss: 2.1680\n",
      "[1124/1762] D loss: 1.3866, G loss: 0.6906\n",
      "[1204/1762] D loss: 1.0401, G loss: 2.1827\n",
      "[1284/1762] D loss: 1.3874, G loss: 0.6838\n",
      "[1364/1762] D loss: 1.3867, G loss: 0.7071\n",
      "[1444/1762] D loss: 1.0410, G loss: 2.2170\n",
      "[1524/1762] D loss: 1.3871, G loss: 0.7016\n",
      "[1604/1762] D loss: 1.0409, G loss: 2.3000\n",
      "[1684/1762] D loss: 1.3866, G loss: 0.6873\n",
      "[1762/1762] D loss: 0.6932, G loss: 6.7182\n",
      "train error: \n",
      " D loss: 1.269136, G loss: 1.213850, D accuracy: 57.9%, cell accuracy: 99.8%, board accuracy: 88.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.237075, G loss: 1.415057, D accuracy: 59.7%, cell accuracy: 99.8%, board accuracy: 85.0% \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0299, G loss: 2.3274\n",
      "[84/1762] D loss: 1.3856, G loss: 0.6497\n",
      "[164/1762] D loss: 1.3876, G loss: 0.6589\n",
      "[244/1762] D loss: 1.0416, G loss: 2.4092\n",
      "[324/1762] D loss: 1.0402, G loss: 2.3644\n",
      "[404/1762] D loss: 1.3868, G loss: 0.7119\n",
      "[484/1762] D loss: 1.3866, G loss: 0.6898\n",
      "[564/1762] D loss: 1.3872, G loss: 0.7017\n",
      "[644/1762] D loss: 1.0403, G loss: 2.3812\n",
      "[724/1762] D loss: 1.0422, G loss: 2.4869\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6944\n",
      "[884/1762] D loss: 1.3867, G loss: 0.6821\n",
      "[964/1762] D loss: 1.3872, G loss: 0.6886\n",
      "[1044/1762] D loss: 1.0401, G loss: 2.4202\n",
      "[1124/1762] D loss: 1.0399, G loss: 2.4134\n",
      "[1204/1762] D loss: 1.3867, G loss: 0.6860\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6919\n",
      "[1364/1762] D loss: 1.0402, G loss: 2.4437\n",
      "[1444/1762] D loss: 1.0401, G loss: 2.4521\n",
      "[1524/1762] D loss: 1.3868, G loss: 0.7152\n",
      "[1604/1762] D loss: 1.3870, G loss: 0.7042\n",
      "[1684/1762] D loss: 1.0399, G loss: 2.4511\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6957\n",
      "train error: \n",
      " D loss: 1.274661, G loss: 1.315604, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.242865, G loss: 1.533007, D accuracy: 55.7%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2134, G loss: 2.9289\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6989\n",
      "[164/1762] D loss: 1.0399, G loss: 2.4572\n",
      "[244/1762] D loss: 1.3865, G loss: 0.6833\n",
      "[324/1762] D loss: 1.3880, G loss: 0.6846\n",
      "[404/1762] D loss: 1.3865, G loss: 0.7003\n",
      "[484/1762] D loss: 1.3872, G loss: 0.7125\n",
      "[564/1762] D loss: 1.3798, G loss: 0.6940\n",
      "[644/1762] D loss: 1.3908, G loss: 0.6601\n",
      "[724/1762] D loss: 1.3909, G loss: 0.7244\n",
      "[804/1762] D loss: 1.3874, G loss: 0.6831\n",
      "[884/1762] D loss: 1.0399, G loss: 2.4938\n",
      "[964/1762] D loss: 1.3867, G loss: 0.6942\n",
      "[1044/1762] D loss: 1.3868, G loss: 0.6824\n",
      "[1124/1762] D loss: 1.3871, G loss: 0.6768\n",
      "[1204/1762] D loss: 1.3865, G loss: 0.6968\n",
      "[1284/1762] D loss: 1.0401, G loss: 2.5406\n",
      "[1364/1762] D loss: 1.3867, G loss: 0.6975\n",
      "[1444/1762] D loss: 1.0398, G loss: 2.5441\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.6947\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6865\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.7025\n",
      "[1762/1762] D loss: 0.6934, G loss: 4.3830\n",
      "train error: \n",
      " D loss: 1.284361, G loss: 1.251979, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.253940, G loss: 1.431229, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3874, G loss: 0.6780\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6910\n",
      "[164/1762] D loss: 1.0399, G loss: 2.5385\n",
      "[244/1762] D loss: 1.3865, G loss: 0.6887\n",
      "[324/1762] D loss: 1.3867, G loss: 0.6771\n",
      "[404/1762] D loss: 1.3872, G loss: 0.6865\n",
      "[484/1762] D loss: 1.0401, G loss: 2.5296\n",
      "[564/1762] D loss: 1.0401, G loss: 2.5609\n",
      "[644/1762] D loss: 1.0399, G loss: 2.5378\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6946\n",
      "[804/1762] D loss: 1.3867, G loss: 0.6764\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6994\n",
      "[964/1762] D loss: 1.0417, G loss: 2.5994\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6959\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.7027\n",
      "[1204/1762] D loss: 1.3874, G loss: 0.6693\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6869\n",
      "[1364/1762] D loss: 1.3866, G loss: 0.7027\n",
      "[1444/1762] D loss: 0.6933, G loss: 4.5006\n",
      "[1524/1762] D loss: 1.0398, G loss: 2.6136\n",
      "[1604/1762] D loss: 1.0398, G loss: 2.6265\n",
      "[1684/1762] D loss: 1.0401, G loss: 2.6246\n",
      "[1762/1762] D loss: 1.4615, G loss: 0.6674\n",
      "train error: \n",
      " D loss: 1.284351, G loss: 1.259074, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.256355, G loss: 1.422769, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3883, G loss: 0.6350\n",
      "[84/1762] D loss: 1.3879, G loss: 0.7205\n",
      "[164/1762] D loss: 0.6939, G loss: 3.7365\n",
      "[244/1762] D loss: 1.0403, G loss: 2.2262\n",
      "[324/1762] D loss: 1.1821, G loss: 5.2345\n",
      "[404/1762] D loss: 1.3866, G loss: 0.6778\n",
      "[484/1762] D loss: 0.6939, G loss: 3.9001\n",
      "[564/1762] D loss: 1.3843, G loss: 0.6709\n",
      "[644/1762] D loss: 1.0401, G loss: 2.3402\n",
      "[724/1762] D loss: 1.3865, G loss: 0.6996\n",
      "[804/1762] D loss: 1.3872, G loss: 0.6730\n",
      "[884/1762] D loss: 1.3868, G loss: 0.6777\n",
      "[964/1762] D loss: 1.3864, G loss: 0.6980\n",
      "[1044/1762] D loss: 1.3868, G loss: 0.6887\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.6845\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6964\n",
      "[1284/1762] D loss: 1.3870, G loss: 0.6868\n",
      "[1364/1762] D loss: 1.3871, G loss: 0.7257\n",
      "[1444/1762] D loss: 1.3017, G loss: 1.6458\n",
      "[1524/1762] D loss: 1.0440, G loss: 2.3888\n",
      "[1604/1762] D loss: 1.3876, G loss: 0.6867\n",
      "[1684/1762] D loss: 1.3871, G loss: 0.7126\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.6994\n",
      "train error: \n",
      " D loss: 1.281583, G loss: 1.209996, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.253823, G loss: 1.320042, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6834\n",
      "[84/1762] D loss: 1.0401, G loss: 2.3016\n",
      "[164/1762] D loss: 1.3867, G loss: 0.6824\n",
      "[244/1762] D loss: 1.3885, G loss: 0.6558\n",
      "[324/1762] D loss: 1.3873, G loss: 0.7009\n",
      "[404/1762] D loss: 1.3864, G loss: 0.7017\n",
      "[484/1762] D loss: 1.0400, G loss: 2.2302\n",
      "[564/1762] D loss: 1.1972, G loss: 2.3874\n",
      "[644/1762] D loss: 1.3864, G loss: 0.6952\n",
      "[724/1762] D loss: 1.3865, G loss: 0.6808\n",
      "[804/1762] D loss: 1.3868, G loss: 0.6763\n",
      "[884/1762] D loss: 1.3864, G loss: 0.7007\n",
      "[964/1762] D loss: 1.3868, G loss: 0.6954\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.6875\n",
      "[1124/1762] D loss: 1.0401, G loss: 2.3699\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6926\n",
      "[1284/1762] D loss: 1.0401, G loss: 2.2772\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6893\n",
      "[1444/1762] D loss: 1.0404, G loss: 2.3561\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.6840\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6912\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.6958\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6689\n",
      "train error: \n",
      " D loss: 1.284450, G loss: 1.214977, D accuracy: 54.0%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.255007, G loss: 1.362048, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6864\n",
      "[84/1762] D loss: 1.3865, G loss: 0.6842\n",
      "[164/1762] D loss: 1.3865, G loss: 0.7073\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6891\n",
      "[324/1762] D loss: 1.3865, G loss: 0.6917\n",
      "[404/1762] D loss: 1.1995, G loss: 2.4587\n",
      "[484/1762] D loss: 1.3870, G loss: 0.6927\n",
      "[564/1762] D loss: 1.0400, G loss: 2.4356\n",
      "[644/1762] D loss: 1.0398, G loss: 2.4399\n",
      "[724/1762] D loss: 1.3868, G loss: 0.6822\n",
      "[804/1762] D loss: 1.3863, G loss: 0.6913\n",
      "[884/1762] D loss: 1.0398, G loss: 2.4784\n",
      "[964/1762] D loss: 1.3867, G loss: 0.6832\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6906\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6949\n",
      "[1204/1762] D loss: 1.3865, G loss: 0.6943\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6962\n",
      "[1364/1762] D loss: 1.0402, G loss: 2.5092\n",
      "[1444/1762] D loss: 1.3868, G loss: 0.6849\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.6900\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6850\n",
      "[1684/1762] D loss: 1.3869, G loss: 0.6808\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6948\n",
      "train error: \n",
      " D loss: 1.284750, G loss: 1.237657, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.255458, G loss: 1.401874, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6855\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6932\n",
      "[164/1762] D loss: 1.3865, G loss: 0.6957\n",
      "[244/1762] D loss: 1.3877, G loss: 0.6422\n",
      "[324/1762] D loss: 0.6925, G loss: 5.0615\n",
      "[404/1762] D loss: 1.3942, G loss: 0.6150\n",
      "[484/1762] D loss: 1.3868, G loss: 0.7024\n",
      "[564/1762] D loss: 1.3867, G loss: 0.7085\n",
      "[644/1762] D loss: 1.3866, G loss: 0.6846\n",
      "[724/1762] D loss: 1.3865, G loss: 0.6849\n",
      "[804/1762] D loss: 1.0398, G loss: 2.5967\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6920\n",
      "[964/1762] D loss: 1.3868, G loss: 0.6763\n",
      "[1044/1762] D loss: 1.0399, G loss: 2.6166\n",
      "[1124/1762] D loss: 1.3862, G loss: 0.6845\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6936\n",
      "[1284/1762] D loss: 1.3862, G loss: 0.6975\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6976\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.7003\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.6925\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6917\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6976\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.7004\n",
      "train error: \n",
      " D loss: 1.284611, G loss: 1.274856, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.255342, G loss: 1.446363, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.7035\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6846\n",
      "[164/1762] D loss: 1.0399, G loss: 2.6566\n",
      "[244/1762] D loss: 1.3874, G loss: 0.6778\n",
      "[324/1762] D loss: 0.6933, G loss: 4.5431\n",
      "[404/1762] D loss: 1.3865, G loss: 0.6872\n",
      "[484/1762] D loss: 1.0398, G loss: 2.6213\n",
      "[564/1762] D loss: 1.3863, G loss: 0.6959\n",
      "[644/1762] D loss: 1.0398, G loss: 2.6278\n",
      "[724/1762] D loss: 0.6932, G loss: 4.6046\n",
      "[804/1762] D loss: 0.8445, G loss: 4.6261\n",
      "[884/1762] D loss: 1.3871, G loss: 0.6869\n",
      "[964/1762] D loss: 1.0401, G loss: 2.6499\n",
      "[1044/1762] D loss: 1.3866, G loss: 0.6780\n",
      "[1124/1762] D loss: 1.3879, G loss: 0.6693\n",
      "[1204/1762] D loss: 1.3793, G loss: 0.6942\n",
      "[1284/1762] D loss: 1.1892, G loss: 2.6540\n",
      "[1364/1762] D loss: 1.3865, G loss: 0.6983\n",
      "[1444/1762] D loss: 1.3874, G loss: 0.6757\n",
      "[1524/1762] D loss: 1.0400, G loss: 2.6836\n",
      "[1604/1762] D loss: 1.0398, G loss: 2.6769\n",
      "[1684/1762] D loss: 1.3866, G loss: 0.7054\n",
      "[1762/1762] D loss: 1.0169, G loss: 4.7039\n",
      "train error: \n",
      " D loss: 1.283743, G loss: 1.295283, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.255322, G loss: 1.469674, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3868, G loss: 0.6686\n",
      "[84/1762] D loss: 1.3868, G loss: 0.7059\n",
      "[164/1762] D loss: 1.1960, G loss: 2.6991\n",
      "[244/1762] D loss: 1.0398, G loss: 2.7180\n",
      "[324/1762] D loss: 1.3864, G loss: 0.6983\n",
      "[404/1762] D loss: 1.3864, G loss: 0.7025\n",
      "[484/1762] D loss: 1.3863, G loss: 0.7004\n",
      "[564/1762] D loss: 1.3899, G loss: 0.6766\n",
      "[644/1762] D loss: 1.3644, G loss: 0.7711\n",
      "[724/1762] D loss: 1.3866, G loss: 0.6520\n",
      "[804/1762] D loss: 1.3896, G loss: 0.7550\n",
      "[884/1762] D loss: 1.3875, G loss: 0.6972\n",
      "[964/1762] D loss: 1.3898, G loss: 0.6499\n",
      "[1044/1762] D loss: 1.0408, G loss: 2.7981\n",
      "[1124/1762] D loss: 1.3919, G loss: 0.6497\n",
      "[1204/1762] D loss: 1.3876, G loss: 0.6624\n",
      "[1284/1762] D loss: 1.3876, G loss: 0.7180\n",
      "[1364/1762] D loss: 1.3799, G loss: 0.7063\n",
      "[1444/1762] D loss: 1.3866, G loss: 0.6903\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.6907\n",
      "[1604/1762] D loss: 1.3850, G loss: 0.6869\n",
      "[1684/1762] D loss: 1.0398, G loss: 2.5819\n",
      "[1762/1762] D loss: 1.3868, G loss: 0.6798\n",
      "train error: \n",
      " D loss: 1.285176, G loss: 1.187517, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.255628, G loss: 1.342026, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3871, G loss: 0.6868\n",
      "[84/1762] D loss: 0.6936, G loss: 4.0990\n",
      "[164/1762] D loss: 1.3862, G loss: 0.6918\n",
      "[244/1762] D loss: 1.3856, G loss: 0.6996\n",
      "[324/1762] D loss: 1.3874, G loss: 0.6757\n",
      "[404/1762] D loss: 1.0406, G loss: 2.5067\n",
      "[484/1762] D loss: 1.3868, G loss: 0.6968\n",
      "[564/1762] D loss: 1.2225, G loss: 2.9311\n",
      "[644/1762] D loss: 1.3871, G loss: 0.6827\n",
      "[724/1762] D loss: 1.0405, G loss: 2.6745\n",
      "[804/1762] D loss: 1.0399, G loss: 2.4442\n",
      "[884/1762] D loss: 1.0402, G loss: 2.6641\n",
      "[964/1762] D loss: 1.3863, G loss: 0.6917\n",
      "[1044/1762] D loss: 1.3878, G loss: 0.6804\n",
      "[1124/1762] D loss: 1.0400, G loss: 2.6089\n",
      "[1204/1762] D loss: 1.0398, G loss: 2.6120\n",
      "[1284/1762] D loss: 1.3865, G loss: 0.7098\n",
      "[1364/1762] D loss: 1.0401, G loss: 2.6706\n",
      "[1444/1762] D loss: 1.3859, G loss: 0.6879\n",
      "[1524/1762] D loss: 1.0404, G loss: 2.5774\n",
      "[1604/1762] D loss: 1.3886, G loss: 0.6729\n",
      "[1684/1762] D loss: 1.3876, G loss: 0.6774\n",
      "[1762/1762] D loss: 1.3862, G loss: 0.6917\n",
      "train error: \n",
      " D loss: 1.283326, G loss: 1.296447, D accuracy: 54.2%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.255352, G loss: 1.470607, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6935, G loss: 4.7828\n",
      "[84/1762] D loss: 1.3874, G loss: 0.6988\n",
      "[164/1762] D loss: 1.3875, G loss: 0.6791\n",
      "[244/1762] D loss: 0.6936, G loss: 4.3798\n",
      "[324/1762] D loss: 1.3868, G loss: 0.6723\n",
      "[404/1762] D loss: 1.0401, G loss: 2.5241\n",
      "[484/1762] D loss: 1.0400, G loss: 2.5089\n",
      "[564/1762] D loss: 1.3862, G loss: 0.6940\n",
      "[644/1762] D loss: 1.0398, G loss: 2.5905\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6825\n",
      "[804/1762] D loss: 1.3868, G loss: 0.6908\n",
      "[884/1762] D loss: 1.0398, G loss: 2.6570\n",
      "[964/1762] D loss: 0.8399, G loss: 4.6409\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.6787\n",
      "[1124/1762] D loss: 1.3868, G loss: 0.6828\n",
      "[1204/1762] D loss: 1.1705, G loss: 3.2245\n",
      "[1284/1762] D loss: 1.3866, G loss: 0.7014\n",
      "[1364/1762] D loss: 1.3895, G loss: 0.6596\n",
      "[1444/1762] D loss: 1.0436, G loss: 2.9238\n",
      "[1524/1762] D loss: 1.0404, G loss: 2.7529\n",
      "[1604/1762] D loss: 1.0399, G loss: 2.6913\n",
      "[1684/1762] D loss: 1.3862, G loss: 0.6838\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6900\n",
      "train error: \n",
      " D loss: 1.284746, G loss: 1.315499, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.255078, G loss: 1.508092, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3865, G loss: 0.7001\n",
      "[84/1762] D loss: 1.3866, G loss: 0.6824\n",
      "[164/1762] D loss: 1.3865, G loss: 0.6764\n",
      "[244/1762] D loss: 1.2055, G loss: 3.5149\n",
      "[324/1762] D loss: 1.3869, G loss: 0.6680\n",
      "[404/1762] D loss: 1.0398, G loss: 2.9524\n",
      "[484/1762] D loss: 1.3857, G loss: 0.6783\n",
      "[564/1762] D loss: 1.3871, G loss: 0.6974\n",
      "[644/1762] D loss: 1.0371, G loss: 2.8914\n",
      "[724/1762] D loss: 1.0404, G loss: 2.9897\n",
      "[804/1762] D loss: 1.3864, G loss: 0.7016\n",
      "[884/1762] D loss: 1.0301, G loss: 3.0422\n",
      "[964/1762] D loss: 0.8193, G loss: 5.2485\n",
      "[1044/1762] D loss: 1.3827, G loss: 0.7005\n",
      "[1124/1762] D loss: 1.3871, G loss: 0.6670\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6701\n",
      "[1284/1762] D loss: 0.6932, G loss: 5.3352\n",
      "[1364/1762] D loss: 1.3944, G loss: 0.6163\n",
      "[1444/1762] D loss: 1.3976, G loss: 0.6227\n",
      "[1524/1762] D loss: 1.2389, G loss: 2.3073\n",
      "[1604/1762] D loss: 1.3537, G loss: 0.6139\n",
      "[1684/1762] D loss: 1.3302, G loss: 0.7393\n",
      "[1762/1762] D loss: 1.3707, G loss: 0.7070\n",
      "train error: \n",
      " D loss: 1.228006, G loss: 1.106874, D accuracy: 70.6%, cell accuracy: 99.5%, board accuracy: 35.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.201812, G loss: 1.224636, D accuracy: 69.7%, cell accuracy: 99.5%, board accuracy: 34.5% \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3466, G loss: 0.6815\n",
      "[84/1762] D loss: 1.3948, G loss: 0.7556\n",
      "[164/1762] D loss: 1.3907, G loss: 0.6651\n",
      "[244/1762] D loss: 1.0095, G loss: 2.2514\n",
      "[324/1762] D loss: 1.3814, G loss: 0.7020\n",
      "[404/1762] D loss: 1.3546, G loss: 0.7755\n",
      "[484/1762] D loss: 1.3878, G loss: 0.7260\n",
      "[564/1762] D loss: 1.3875, G loss: 0.6669\n",
      "[644/1762] D loss: 1.0202, G loss: 2.2776\n",
      "[724/1762] D loss: 1.3898, G loss: 0.6443\n",
      "[804/1762] D loss: 1.3936, G loss: 0.7114\n",
      "[884/1762] D loss: 1.3888, G loss: 0.6741\n",
      "[964/1762] D loss: 1.3875, G loss: 0.6976\n",
      "[1044/1762] D loss: 1.0402, G loss: 2.3119\n",
      "[1124/1762] D loss: 1.3866, G loss: 0.6869\n",
      "[1204/1762] D loss: 1.3867, G loss: 0.6971\n",
      "[1284/1762] D loss: 1.3782, G loss: 0.6899\n",
      "[1364/1762] D loss: 1.0375, G loss: 2.4388\n",
      "[1444/1762] D loss: 1.3852, G loss: 0.6964\n",
      "[1524/1762] D loss: 1.3856, G loss: 0.6708\n",
      "[1604/1762] D loss: 1.0387, G loss: 2.4922\n",
      "[1684/1762] D loss: 1.0401, G loss: 2.5042\n",
      "[1762/1762] D loss: 1.3348, G loss: 0.7499\n",
      "train error: \n",
      " D loss: 1.283503, G loss: 1.243083, D accuracy: 54.3%, cell accuracy: 99.9%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.256540, G loss: 1.408395, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0402, G loss: 2.5432\n",
      "[84/1762] D loss: 1.3868, G loss: 0.6710\n",
      "[164/1762] D loss: 1.0314, G loss: 2.6612\n",
      "[244/1762] D loss: 1.3858, G loss: 0.6732\n",
      "[324/1762] D loss: 1.3736, G loss: 0.7069\n",
      "[404/1762] D loss: 1.3845, G loss: 0.6976\n",
      "[484/1762] D loss: 1.3920, G loss: 0.6579\n",
      "[564/1762] D loss: 1.0403, G loss: 2.7630\n",
      "[644/1762] D loss: 1.0401, G loss: 2.7423\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6657\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6985\n",
      "[884/1762] D loss: 1.0386, G loss: 2.7354\n",
      "[964/1762] D loss: 1.3866, G loss: 0.6867\n",
      "[1044/1762] D loss: 1.3855, G loss: 0.6863\n",
      "[1124/1762] D loss: 1.0420, G loss: 2.8423\n",
      "[1204/1762] D loss: 1.3875, G loss: 0.7135\n",
      "[1284/1762] D loss: 1.3858, G loss: 0.6951\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6967\n",
      "[1444/1762] D loss: 1.3794, G loss: 0.6904\n",
      "[1524/1762] D loss: 1.0400, G loss: 2.7474\n",
      "[1604/1762] D loss: 1.3889, G loss: 0.6797\n",
      "[1684/1762] D loss: 1.3868, G loss: 0.7034\n",
      "[1762/1762] D loss: 0.6932, G loss: 4.9619\n",
      "train error: \n",
      " D loss: 1.284468, G loss: 1.345358, D accuracy: 54.1%, cell accuracy: 99.9%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.255785, G loss: 1.517576, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3857, G loss: 0.7085\n",
      "[84/1762] D loss: 1.0394, G loss: 2.8245\n",
      "[164/1762] D loss: 1.3862, G loss: 0.6928\n",
      "[244/1762] D loss: 1.3442, G loss: 0.6943\n",
      "[324/1762] D loss: 1.0403, G loss: 2.7644\n",
      "[404/1762] D loss: 1.3863, G loss: 0.6912\n",
      "[484/1762] D loss: 1.3864, G loss: 0.6975\n",
      "[564/1762] D loss: 1.3868, G loss: 0.7003\n",
      "[644/1762] D loss: 1.3866, G loss: 0.6870\n",
      "[724/1762] D loss: 1.3871, G loss: 0.6841\n",
      "[804/1762] D loss: 1.3872, G loss: 0.7018\n",
      "[884/1762] D loss: 1.3868, G loss: 0.6952\n",
      "[964/1762] D loss: 1.3868, G loss: 0.6785\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6827\n",
      "[1124/1762] D loss: 1.0396, G loss: 3.0872\n",
      "[1204/1762] D loss: 1.3927, G loss: 0.7766\n",
      "[1284/1762] D loss: 1.0402, G loss: 2.4609\n",
      "[1364/1762] D loss: 1.3695, G loss: 0.7142\n",
      "[1444/1762] D loss: 0.6936, G loss: 4.3096\n",
      "[1524/1762] D loss: 1.3878, G loss: 0.6772\n",
      "[1604/1762] D loss: 1.0404, G loss: 2.5164\n",
      "[1684/1762] D loss: 1.3889, G loss: 0.6770\n",
      "[1762/1762] D loss: 1.3869, G loss: 0.6913\n",
      "train error: \n",
      " D loss: 1.280060, G loss: 1.291087, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 90.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.253791, G loss: 1.462413, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3873, G loss: 0.7129\n",
      "[84/1762] D loss: 1.0401, G loss: 2.5753\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6928\n",
      "[244/1762] D loss: 1.3824, G loss: 0.6759\n",
      "[324/1762] D loss: 1.1811, G loss: 3.9215\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6940\n",
      "[484/1762] D loss: 1.3845, G loss: 0.6892\n",
      "[564/1762] D loss: 1.3877, G loss: 0.6572\n",
      "[644/1762] D loss: 1.3884, G loss: 0.6549\n",
      "[724/1762] D loss: 1.3866, G loss: 0.7021\n",
      "[804/1762] D loss: 1.3887, G loss: 0.7791\n",
      "[884/1762] D loss: 1.3058, G loss: 0.8289\n",
      "[964/1762] D loss: 1.3859, G loss: 0.6683\n",
      "[1044/1762] D loss: 1.0401, G loss: 2.2003\n",
      "[1124/1762] D loss: 1.3867, G loss: 0.7045\n",
      "[1204/1762] D loss: 1.3630, G loss: 0.7199\n",
      "[1284/1762] D loss: 1.3735, G loss: 0.6961\n",
      "[1364/1762] D loss: 1.3871, G loss: 0.7084\n",
      "[1444/1762] D loss: 1.3862, G loss: 0.6885\n",
      "[1524/1762] D loss: 1.3867, G loss: 0.7046\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6810\n",
      "[1684/1762] D loss: 1.3877, G loss: 0.6764\n",
      "[1762/1762] D loss: 1.3916, G loss: 0.6506\n",
      "train error: \n",
      " D loss: 1.274211, G loss: 1.326524, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 90.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.239945, G loss: 1.543535, D accuracy: 55.6%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0395, G loss: 6.0763\n",
      "[84/1762] D loss: 1.3891, G loss: 0.6573\n",
      "[164/1762] D loss: 1.3865, G loss: 0.6869\n",
      "[244/1762] D loss: 1.3870, G loss: 0.6947\n",
      "[324/1762] D loss: 1.3883, G loss: 0.6867\n",
      "[404/1762] D loss: 1.0415, G loss: 2.5666\n",
      "[484/1762] D loss: 1.3878, G loss: 0.6758\n",
      "[564/1762] D loss: 1.3896, G loss: 0.7300\n",
      "[644/1762] D loss: 1.3869, G loss: 0.6881\n",
      "[724/1762] D loss: 1.3865, G loss: 0.6812\n",
      "[804/1762] D loss: 1.3892, G loss: 0.6648\n",
      "[884/1762] D loss: 1.3868, G loss: 0.7126\n",
      "[964/1762] D loss: 1.3864, G loss: 0.6984\n",
      "[1044/1762] D loss: 1.3911, G loss: 0.7259\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6957\n",
      "[1204/1762] D loss: 1.0399, G loss: 2.5127\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6952\n",
      "[1364/1762] D loss: 1.3865, G loss: 0.6847\n",
      "[1444/1762] D loss: 1.3867, G loss: 0.7082\n",
      "[1524/1762] D loss: 1.3867, G loss: 0.6947\n",
      "[1604/1762] D loss: 1.0399, G loss: 2.5626\n",
      "[1684/1762] D loss: 1.3881, G loss: 0.7034\n",
      "[1762/1762] D loss: 0.6933, G loss: 4.4053\n",
      "train error: \n",
      " D loss: 1.283771, G loss: 1.263416, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.257317, G loss: 1.408457, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3866, G loss: 0.7042\n",
      "[84/1762] D loss: 1.3867, G loss: 0.7109\n",
      "[164/1762] D loss: 0.6935, G loss: 4.4969\n",
      "[244/1762] D loss: 1.3870, G loss: 0.6821\n",
      "[324/1762] D loss: 1.3865, G loss: 0.6951\n",
      "[404/1762] D loss: 1.0398, G loss: 2.5963\n",
      "[484/1762] D loss: 1.3864, G loss: 0.6955\n",
      "[564/1762] D loss: 1.3863, G loss: 0.6931\n",
      "[644/1762] D loss: 1.3866, G loss: 0.6979\n",
      "[724/1762] D loss: 1.0398, G loss: 2.7054\n",
      "[804/1762] D loss: 1.0402, G loss: 2.8034\n",
      "[884/1762] D loss: 1.3869, G loss: 0.6823\n",
      "[964/1762] D loss: 1.3915, G loss: 0.7081\n",
      "[1044/1762] D loss: 1.3877, G loss: 0.6998\n",
      "[1124/1762] D loss: 1.0399, G loss: 2.7181\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6868\n",
      "[1284/1762] D loss: 1.2531, G loss: 1.5468\n",
      "[1364/1762] D loss: 1.3889, G loss: 0.6769\n",
      "[1444/1762] D loss: 1.3869, G loss: 0.6782\n",
      "[1524/1762] D loss: 1.3872, G loss: 0.7072\n",
      "[1604/1762] D loss: 1.3894, G loss: 0.6864\n",
      "[1684/1762] D loss: 1.0398, G loss: 2.8408\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.7041\n",
      "train error: \n",
      " D loss: 1.277767, G loss: 1.357211, D accuracy: 55.8%, cell accuracy: 99.8%, board accuracy: 88.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.251252, G loss: 1.533247, D accuracy: 56.4%, cell accuracy: 99.8%, board accuracy: 85.9% \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6933, G loss: 4.9535\n",
      "[84/1762] D loss: 1.3753, G loss: 0.6662\n",
      "[164/1762] D loss: 1.3830, G loss: 0.6806\n",
      "[244/1762] D loss: 1.3869, G loss: 0.6963\n",
      "[324/1762] D loss: 1.0406, G loss: 2.7563\n",
      "[404/1762] D loss: 1.3926, G loss: 0.6474\n",
      "[484/1762] D loss: 1.3867, G loss: 0.6763\n",
      "[564/1762] D loss: 1.3881, G loss: 0.6608\n",
      "[644/1762] D loss: 1.3874, G loss: 0.7036\n",
      "[724/1762] D loss: 1.1602, G loss: 2.7404\n",
      "[804/1762] D loss: 1.3867, G loss: 0.6982\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6932\n",
      "[964/1762] D loss: 1.3872, G loss: 0.6986\n",
      "[1044/1762] D loss: 1.3865, G loss: 0.6918\n",
      "[1124/1762] D loss: 1.3866, G loss: 0.6904\n",
      "[1204/1762] D loss: 1.0417, G loss: 2.7472\n",
      "[1284/1762] D loss: 1.3856, G loss: 0.6960\n",
      "[1364/1762] D loss: 1.0399, G loss: 2.7319\n",
      "[1444/1762] D loss: 1.3870, G loss: 0.6778\n",
      "[1524/1762] D loss: 1.3886, G loss: 0.7024\n",
      "[1604/1762] D loss: 1.3869, G loss: 0.6805\n",
      "[1684/1762] D loss: 1.1877, G loss: 1.1980\n",
      "[1762/1762] D loss: 1.3107, G loss: 0.6218\n",
      "train error: \n",
      " D loss: 1.300323, G loss: 0.985641, D accuracy: 55.4%, cell accuracy: 99.8%, board accuracy: 82.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.267745, G loss: 1.195115, D accuracy: 56.7%, cell accuracy: 99.7%, board accuracy: 79.5% \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4199, G loss: 0.5431\n",
      "[84/1762] D loss: 1.3881, G loss: 0.6476\n",
      "[164/1762] D loss: 1.3929, G loss: 0.6821\n",
      "[244/1762] D loss: 1.3867, G loss: 0.6827\n",
      "[324/1762] D loss: 1.0397, G loss: 3.1852\n",
      "[404/1762] D loss: 1.3868, G loss: 0.6859\n",
      "[484/1762] D loss: 1.3864, G loss: 0.6977\n",
      "[564/1762] D loss: 1.3884, G loss: 0.7161\n",
      "[644/1762] D loss: 0.6937, G loss: 6.8666\n",
      "[724/1762] D loss: 1.3869, G loss: 0.6727\n",
      "[804/1762] D loss: 1.3873, G loss: 0.6906\n",
      "[884/1762] D loss: 1.3883, G loss: 0.6535\n",
      "[964/1762] D loss: 1.0402, G loss: 2.4942\n",
      "[1044/1762] D loss: 1.3845, G loss: 0.6933\n",
      "[1124/1762] D loss: 1.3914, G loss: 0.6380\n",
      "[1204/1762] D loss: 1.3885, G loss: 0.6782\n",
      "[1284/1762] D loss: 1.3877, G loss: 0.6716\n",
      "[1364/1762] D loss: 1.3065, G loss: 0.7755\n",
      "[1444/1762] D loss: 1.4394, G loss: 0.6228\n",
      "[1524/1762] D loss: 1.3882, G loss: 0.7169\n",
      "[1604/1762] D loss: 1.3896, G loss: 0.7130\n",
      "[1684/1762] D loss: 0.6934, G loss: 4.9185\n",
      "[1762/1762] D loss: 1.3868, G loss: 0.6931\n",
      "train error: \n",
      " D loss: 1.281220, G loss: 1.337701, D accuracy: 54.4%, cell accuracy: 99.9%, board accuracy: 90.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.249156, G loss: 1.520769, D accuracy: 55.8%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3866, G loss: 0.6839\n",
      "[84/1762] D loss: 1.0399, G loss: 2.6571\n",
      "[164/1762] D loss: 1.3865, G loss: 0.7025\n",
      "[244/1762] D loss: 1.3869, G loss: 0.7031\n",
      "[324/1762] D loss: 1.3868, G loss: 0.7069\n",
      "[404/1762] D loss: 1.3855, G loss: 0.6846\n",
      "[484/1762] D loss: 1.3865, G loss: 0.6882\n",
      "[564/1762] D loss: 1.3868, G loss: 0.7106\n",
      "[644/1762] D loss: 1.3867, G loss: 0.6743\n",
      "[724/1762] D loss: 1.3868, G loss: 0.6889\n",
      "[804/1762] D loss: 1.3868, G loss: 0.6751\n",
      "[884/1762] D loss: 1.3886, G loss: 0.6770\n",
      "[964/1762] D loss: 1.3874, G loss: 0.6725\n",
      "[1044/1762] D loss: 1.3887, G loss: 0.6701\n",
      "[1124/1762] D loss: 1.0404, G loss: 2.5515\n",
      "[1204/1762] D loss: 1.3867, G loss: 0.6762\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6999\n",
      "[1364/1762] D loss: 1.0398, G loss: 2.6519\n",
      "[1444/1762] D loss: 1.3831, G loss: 0.6775\n",
      "[1524/1762] D loss: 1.3416, G loss: 0.7486\n",
      "[1604/1762] D loss: 1.3873, G loss: 0.7005\n",
      "[1684/1762] D loss: 1.4030, G loss: 0.5847\n",
      "[1762/1762] D loss: 1.3882, G loss: 0.6538\n",
      "train error: \n",
      " D loss: 1.287779, G loss: 1.202292, D accuracy: 54.1%, cell accuracy: 99.9%, board accuracy: 90.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.260339, G loss: 1.366530, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3891, G loss: 0.6794\n",
      "[84/1762] D loss: 1.0403, G loss: 2.6786\n",
      "[164/1762] D loss: 1.3870, G loss: 0.6813\n",
      "[244/1762] D loss: 1.2989, G loss: 0.7832\n",
      "[324/1762] D loss: 1.2392, G loss: 1.0059\n",
      "[404/1762] D loss: 1.4017, G loss: 0.6200\n",
      "[484/1762] D loss: 0.8010, G loss: 5.2802\n",
      "[564/1762] D loss: 1.0458, G loss: 3.1286\n",
      "[644/1762] D loss: 1.3890, G loss: 0.6968\n",
      "[724/1762] D loss: 1.3770, G loss: 0.6678\n",
      "[804/1762] D loss: 1.3888, G loss: 0.6492\n",
      "[884/1762] D loss: 1.3883, G loss: 0.6775\n",
      "[964/1762] D loss: 1.3919, G loss: 0.6768\n",
      "[1044/1762] D loss: 1.3904, G loss: 0.6666\n",
      "[1124/1762] D loss: 1.3896, G loss: 0.6507\n",
      "[1204/1762] D loss: 1.3874, G loss: 0.7067\n",
      "[1284/1762] D loss: 1.3879, G loss: 0.6913\n",
      "[1364/1762] D loss: 1.3870, G loss: 0.6972\n",
      "[1444/1762] D loss: 1.0411, G loss: 3.0650\n",
      "[1524/1762] D loss: 1.3866, G loss: 0.6934\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6893\n",
      "[1684/1762] D loss: 1.0398, G loss: 3.0796\n",
      "[1762/1762] D loss: 1.3868, G loss: 0.6735\n",
      "train error: \n",
      " D loss: 1.284265, G loss: 1.408179, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.255134, G loss: 1.631524, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3865, G loss: 0.6962\n",
      "[84/1762] D loss: 1.3867, G loss: 0.7069\n",
      "[164/1762] D loss: 1.3865, G loss: 0.6873\n",
      "[244/1762] D loss: 1.3864, G loss: 0.6920\n",
      "[324/1762] D loss: 1.3885, G loss: 0.7280\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6891\n",
      "[484/1762] D loss: 1.0399, G loss: 3.0622\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6953\n",
      "[644/1762] D loss: 1.3864, G loss: 0.6884\n",
      "[724/1762] D loss: 1.3865, G loss: 0.6986\n",
      "[804/1762] D loss: 1.3867, G loss: 0.7004\n",
      "[884/1762] D loss: 1.3871, G loss: 0.6971\n",
      "[964/1762] D loss: 1.3864, G loss: 0.6915\n",
      "[1044/1762] D loss: 1.3860, G loss: 0.6964\n",
      "[1124/1762] D loss: 1.3867, G loss: 0.7068\n",
      "[1204/1762] D loss: 1.3867, G loss: 0.7081\n",
      "[1284/1762] D loss: 1.3865, G loss: 0.6889\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6979\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6850\n",
      "[1524/1762] D loss: 1.3867, G loss: 0.7006\n",
      "[1604/1762] D loss: 1.3866, G loss: 0.7017\n",
      "[1684/1762] D loss: 1.3879, G loss: 0.6513\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.6898\n",
      "train error: \n",
      " D loss: 1.284449, G loss: 1.408030, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.255517, G loss: 1.619995, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6989\n",
      "[84/1762] D loss: 1.3921, G loss: 0.6515\n",
      "[164/1762] D loss: 1.3867, G loss: 0.6824\n",
      "[244/1762] D loss: 1.3877, G loss: 0.7177\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6956\n",
      "[404/1762] D loss: 1.3865, G loss: 0.6856\n",
      "[484/1762] D loss: 1.3864, G loss: 0.7018\n",
      "[564/1762] D loss: 1.3866, G loss: 0.6805\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6934\n",
      "[724/1762] D loss: 1.3868, G loss: 0.6818\n",
      "[804/1762] D loss: 1.3938, G loss: 0.6533\n",
      "[884/1762] D loss: 1.0401, G loss: 3.1180\n",
      "[964/1762] D loss: 1.0400, G loss: 3.1551\n",
      "[1044/1762] D loss: 1.0398, G loss: 3.1609\n",
      "[1124/1762] D loss: 1.3875, G loss: 0.6798\n",
      "[1204/1762] D loss: 1.3868, G loss: 0.7023\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6962\n",
      "[1364/1762] D loss: 0.3466, G loss: 7.6502\n",
      "[1444/1762] D loss: 1.3874, G loss: 0.7006\n",
      "[1524/1762] D loss: 1.3865, G loss: 0.6881\n",
      "[1604/1762] D loss: 1.3871, G loss: 0.7150\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6922\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6969\n",
      "train error: \n",
      " D loss: 1.280638, G loss: 1.751249, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.254009, G loss: 1.994725, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0399, G loss: 3.0872\n",
      "[84/1762] D loss: 1.0399, G loss: 3.0815\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6880\n",
      "[244/1762] D loss: 1.3867, G loss: 0.6935\n",
      "[324/1762] D loss: 1.3866, G loss: 0.6849\n",
      "[404/1762] D loss: 1.3865, G loss: 0.6787\n",
      "[484/1762] D loss: 1.3867, G loss: 0.6952\n",
      "[564/1762] D loss: 1.0245, G loss: 3.1157\n",
      "[644/1762] D loss: 1.0398, G loss: 3.0888\n",
      "[724/1762] D loss: 1.3879, G loss: 0.6727\n",
      "[804/1762] D loss: 1.3866, G loss: 0.6817\n",
      "[884/1762] D loss: 1.3880, G loss: 0.7100\n",
      "[964/1762] D loss: 1.3864, G loss: 0.6843\n",
      "[1044/1762] D loss: 1.3885, G loss: 0.6815\n",
      "[1124/1762] D loss: 1.3882, G loss: 0.7199\n",
      "[1204/1762] D loss: 1.3865, G loss: 0.6937\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6855\n",
      "[1364/1762] D loss: 1.3588, G loss: 0.5725\n",
      "[1444/1762] D loss: 1.0459, G loss: 2.3876\n",
      "[1524/1762] D loss: 1.3872, G loss: 0.6724\n",
      "[1604/1762] D loss: 1.0358, G loss: 2.4676\n",
      "[1684/1762] D loss: 1.0427, G loss: 2.4014\n",
      "[1762/1762] D loss: 1.3897, G loss: 0.6428\n",
      "train error: \n",
      " D loss: 1.281527, G loss: 1.209612, D accuracy: 55.4%, cell accuracy: 99.8%, board accuracy: 87.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.244992, G loss: 1.423269, D accuracy: 56.9%, cell accuracy: 99.8%, board accuracy: 84.8% \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3927, G loss: 0.6311\n",
      "[84/1762] D loss: 1.3081, G loss: 0.8657\n",
      "[164/1762] D loss: 1.3880, G loss: 0.6802\n",
      "[244/1762] D loss: 1.3896, G loss: 0.6871\n",
      "[324/1762] D loss: 1.3878, G loss: 0.6965\n",
      "[404/1762] D loss: 1.3865, G loss: 0.7042\n",
      "[484/1762] D loss: 1.0401, G loss: 2.3430\n",
      "[564/1762] D loss: 1.0400, G loss: 2.4435\n",
      "[644/1762] D loss: 1.3882, G loss: 0.6943\n",
      "[724/1762] D loss: 1.3869, G loss: 0.7061\n",
      "[804/1762] D loss: 1.3862, G loss: 0.6900\n",
      "[884/1762] D loss: 1.3871, G loss: 0.7124\n",
      "[964/1762] D loss: 1.0435, G loss: 2.6187\n",
      "[1044/1762] D loss: 1.3868, G loss: 0.6993\n",
      "[1124/1762] D loss: 1.0419, G loss: 2.9327\n",
      "[1204/1762] D loss: 1.3878, G loss: 0.6979\n",
      "[1284/1762] D loss: 1.3876, G loss: 0.7247\n",
      "[1364/1762] D loss: 1.3868, G loss: 0.6887\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6942\n",
      "[1524/1762] D loss: 1.3877, G loss: 0.6788\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6892\n",
      "[1684/1762] D loss: 1.3867, G loss: 0.6847\n",
      "[1762/1762] D loss: 1.3866, G loss: 0.6851\n",
      "train error: \n",
      " D loss: 1.287910, G loss: 1.320294, D accuracy: 54.1%, cell accuracy: 99.9%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.253903, G loss: 1.456169, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0401, G loss: 2.4043\n",
      "[84/1762] D loss: 1.3866, G loss: 0.6945\n",
      "[164/1762] D loss: 1.0401, G loss: 2.6451\n",
      "[244/1762] D loss: 1.3873, G loss: 0.6823\n",
      "[324/1762] D loss: 1.3866, G loss: 0.6884\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6852\n",
      "[484/1762] D loss: 1.3865, G loss: 0.6873\n",
      "[564/1762] D loss: 1.3873, G loss: 0.6856\n",
      "[644/1762] D loss: 1.3872, G loss: 0.6672\n",
      "[724/1762] D loss: 1.3867, G loss: 0.7059\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6989\n",
      "[884/1762] D loss: 1.3873, G loss: 0.6872\n",
      "[964/1762] D loss: 1.0403, G loss: 2.6553\n",
      "[1044/1762] D loss: 1.0402, G loss: 2.6633\n",
      "[1124/1762] D loss: 1.3876, G loss: 0.7205\n",
      "[1204/1762] D loss: 1.3866, G loss: 0.7039\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6847\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6987\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.6935\n",
      "[1524/1762] D loss: 1.3871, G loss: 0.7006\n",
      "[1604/1762] D loss: 1.0397, G loss: 2.6900\n",
      "[1684/1762] D loss: 1.3869, G loss: 0.7143\n",
      "[1762/1762] D loss: 0.6943, G loss: 4.6739\n",
      "train error: \n",
      " D loss: 1.290134, G loss: 1.302144, D accuracy: 54.0%, cell accuracy: 99.9%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.255109, G loss: 1.459582, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3868, G loss: 0.6742\n",
      "[84/1762] D loss: 1.0399, G loss: 2.6933\n",
      "[164/1762] D loss: 1.3871, G loss: 0.7105\n",
      "[244/1762] D loss: 1.0399, G loss: 2.6938\n",
      "[324/1762] D loss: 1.0411, G loss: 2.7404\n",
      "[404/1762] D loss: 1.3866, G loss: 0.6828\n",
      "[484/1762] D loss: 1.3872, G loss: 0.6706\n",
      "[564/1762] D loss: 1.3866, G loss: 0.6880\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6909\n",
      "[724/1762] D loss: 1.3869, G loss: 0.7064\n",
      "[804/1762] D loss: 1.0400, G loss: 2.6990\n",
      "[884/1762] D loss: 1.3868, G loss: 0.6883\n",
      "[964/1762] D loss: 1.0401, G loss: 2.7195\n",
      "[1044/1762] D loss: 1.0405, G loss: 2.6944\n",
      "[1124/1762] D loss: 1.0400, G loss: 2.7417\n",
      "[1204/1762] D loss: 1.3890, G loss: 0.6490\n",
      "[1284/1762] D loss: 1.0409, G loss: 2.4884\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.7025\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6833\n",
      "[1524/1762] D loss: 1.3867, G loss: 0.6968\n",
      "[1604/1762] D loss: 1.3867, G loss: 0.6870\n",
      "[1684/1762] D loss: 1.3884, G loss: 0.6610\n",
      "[1762/1762] D loss: 1.3969, G loss: 0.6418\n",
      "train error: \n",
      " D loss: 1.289558, G loss: 1.302093, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.263479, G loss: 1.494941, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3870, G loss: 0.7056\n",
      "[84/1762] D loss: 1.3904, G loss: 0.6704\n",
      "[164/1762] D loss: 1.0969, G loss: 2.4704\n",
      "[244/1762] D loss: 1.0399, G loss: 2.5019\n",
      "[324/1762] D loss: 1.3868, G loss: 0.6817\n",
      "[404/1762] D loss: 1.3871, G loss: 0.6905\n",
      "[484/1762] D loss: 1.3874, G loss: 0.6855\n",
      "[564/1762] D loss: 1.3866, G loss: 0.6808\n",
      "[644/1762] D loss: 1.0399, G loss: 2.5516\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6893\n",
      "[804/1762] D loss: 1.3869, G loss: 0.6800\n",
      "[884/1762] D loss: 1.3867, G loss: 0.7065\n",
      "[964/1762] D loss: 1.3702, G loss: 0.7187\n",
      "[1044/1762] D loss: 1.3867, G loss: 0.6753\n",
      "[1124/1762] D loss: 1.3867, G loss: 0.7122\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6921\n",
      "[1284/1762] D loss: 1.0401, G loss: 2.7918\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6991\n",
      "[1444/1762] D loss: 1.0420, G loss: 2.7752\n",
      "[1524/1762] D loss: 1.3866, G loss: 0.6970\n",
      "[1604/1762] D loss: 1.3865, G loss: 0.6830\n",
      "[1684/1762] D loss: 1.3867, G loss: 0.7086\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.6823\n",
      "train error: \n",
      " D loss: 1.293220, G loss: 1.302493, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 90.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.253132, G loss: 1.503519, D accuracy: 55.8%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0401, G loss: 2.7930\n",
      "[84/1762] D loss: 1.3673, G loss: 0.6853\n",
      "[164/1762] D loss: 1.3869, G loss: 0.7119\n",
      "[244/1762] D loss: 1.3862, G loss: 0.6881\n",
      "[324/1762] D loss: 1.0408, G loss: 2.7952\n",
      "[404/1762] D loss: 1.3870, G loss: 0.6816\n",
      "[484/1762] D loss: 1.3862, G loss: 0.6975\n",
      "[564/1762] D loss: 1.3865, G loss: 0.6959\n",
      "[644/1762] D loss: 1.0398, G loss: 2.7992\n",
      "[724/1762] D loss: 1.3860, G loss: 0.6906\n",
      "[804/1762] D loss: 0.6932, G loss: 4.9151\n",
      "[884/1762] D loss: 1.0414, G loss: 1.8698\n",
      "[964/1762] D loss: 1.3860, G loss: 0.6917\n",
      "[1044/1762] D loss: 1.3859, G loss: 0.7004\n",
      "[1124/1762] D loss: 1.0399, G loss: 2.8143\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6986\n",
      "[1284/1762] D loss: 1.3862, G loss: 0.6902\n",
      "[1364/1762] D loss: 1.1398, G loss: 2.9978\n",
      "[1444/1762] D loss: 1.3870, G loss: 0.6945\n",
      "[1524/1762] D loss: 1.3878, G loss: 0.6984\n",
      "[1604/1762] D loss: 1.3871, G loss: 0.7011\n",
      "[1684/1762] D loss: 1.0456, G loss: 2.7188\n",
      "[1762/1762] D loss: 1.3866, G loss: 0.6943\n",
      "train error: \n",
      " D loss: 1.287503, G loss: 1.260805, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 91.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.257844, G loss: 1.431753, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3866, G loss: 0.7140\n",
      "[84/1762] D loss: 1.0907, G loss: 2.5730\n",
      "[164/1762] D loss: 1.3860, G loss: 0.6865\n",
      "[244/1762] D loss: 1.0401, G loss: 2.5562\n",
      "[324/1762] D loss: 1.3869, G loss: 0.7168\n",
      "[404/1762] D loss: 1.3868, G loss: 0.6837\n",
      "[484/1762] D loss: 1.3860, G loss: 0.6875\n",
      "[564/1762] D loss: 1.8872, G loss: 0.5407\n",
      "[644/1762] D loss: 1.3865, G loss: 0.6857\n",
      "[724/1762] D loss: 1.0461, G loss: 2.6372\n",
      "[804/1762] D loss: 1.3862, G loss: 0.7009\n",
      "[884/1762] D loss: 1.3861, G loss: 0.6901\n",
      "[964/1762] D loss: 1.3860, G loss: 0.6988\n",
      "[1044/1762] D loss: 1.3880, G loss: 0.7350\n",
      "[1124/1762] D loss: 0.6937, G loss: 4.3753\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6992\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6894\n",
      "[1364/1762] D loss: 1.0420, G loss: 2.5634\n",
      "[1444/1762] D loss: 1.3873, G loss: 0.6655\n",
      "[1524/1762] D loss: 1.0411, G loss: 2.5504\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6984\n",
      "[1684/1762] D loss: 1.3865, G loss: 0.6827\n",
      "[1762/1762] D loss: 1.3862, G loss: 0.6962\n",
      "train error: \n",
      " D loss: 1.285455, G loss: 1.243888, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.257579, G loss: 1.410892, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3868, G loss: 0.6995\n",
      "[84/1762] D loss: 1.3865, G loss: 0.6914\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6932\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6976\n",
      "[324/1762] D loss: 1.3858, G loss: 0.6828\n",
      "[404/1762] D loss: 1.3868, G loss: 0.7087\n",
      "[484/1762] D loss: 1.0399, G loss: 2.4945\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6970\n",
      "[644/1762] D loss: 1.0403, G loss: 2.4635\n",
      "[724/1762] D loss: 1.3862, G loss: 0.6935\n",
      "[804/1762] D loss: 1.3866, G loss: 0.6855\n",
      "[884/1762] D loss: 1.3864, G loss: 0.7009\n",
      "[964/1762] D loss: 1.3806, G loss: 0.6799\n",
      "[1044/1762] D loss: 1.9385, G loss: 0.5484\n",
      "[1124/1762] D loss: 1.3866, G loss: 0.6742\n",
      "[1204/1762] D loss: 1.3867, G loss: 0.6947\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.7019\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6947\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6970\n",
      "[1524/1762] D loss: 1.3867, G loss: 0.7044\n",
      "[1604/1762] D loss: 1.3867, G loss: 0.7030\n",
      "[1684/1762] D loss: 1.0405, G loss: 2.4876\n",
      "[1762/1762] D loss: 1.3829, G loss: 0.6705\n",
      "train error: \n",
      " D loss: 1.285515, G loss: 1.230612, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.256119, G loss: 1.379146, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7055, G loss: 4.3003\n",
      "[84/1762] D loss: 1.3866, G loss: 0.6759\n",
      "[164/1762] D loss: 1.0399, G loss: 2.5122\n",
      "[244/1762] D loss: 1.3884, G loss: 0.7376\n",
      "[324/1762] D loss: 0.6947, G loss: 4.4735\n",
      "[404/1762] D loss: 1.0399, G loss: 2.5475\n",
      "[484/1762] D loss: 1.3865, G loss: 0.6864\n",
      "[564/1762] D loss: 0.6951, G loss: 4.4340\n",
      "[644/1762] D loss: 1.3866, G loss: 0.6840\n",
      "[724/1762] D loss: 1.0405, G loss: 2.5707\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6836\n",
      "[884/1762] D loss: 1.0399, G loss: 2.7388\n",
      "[964/1762] D loss: 1.3863, G loss: 0.6835\n",
      "[1044/1762] D loss: 1.3866, G loss: 0.6718\n",
      "[1124/1762] D loss: 1.0415, G loss: 2.6975\n",
      "[1204/1762] D loss: 1.2102, G loss: 32.4448\n",
      "[1284/1762] D loss: 1.3903, G loss: 0.7195\n",
      "[1364/1762] D loss: 1.3602, G loss: 0.7374\n",
      "[1444/1762] D loss: 1.3915, G loss: 0.6554\n",
      "[1524/1762] D loss: 1.3884, G loss: 0.7089\n",
      "[1604/1762] D loss: 1.3879, G loss: 0.7379\n",
      "[1684/1762] D loss: 1.3865, G loss: 0.6962\n",
      "[1762/1762] D loss: 1.3870, G loss: 0.6691\n",
      "train error: \n",
      " D loss: 1.284382, G loss: 1.314285, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.256866, G loss: 1.592920, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0411, G loss: 2.7268\n",
      "[84/1762] D loss: 1.0418, G loss: 2.6409\n",
      "[164/1762] D loss: 1.3866, G loss: 0.6964\n",
      "[244/1762] D loss: 1.3868, G loss: 0.6887\n",
      "[324/1762] D loss: 1.3864, G loss: 0.7004\n",
      "[404/1762] D loss: 1.3866, G loss: 0.7034\n",
      "[484/1762] D loss: 1.3887, G loss: 0.6429\n",
      "[564/1762] D loss: 1.3866, G loss: 0.7049\n",
      "[644/1762] D loss: 1.0400, G loss: 2.6427\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6893\n",
      "[804/1762] D loss: 1.3866, G loss: 0.6769\n",
      "[884/1762] D loss: 1.3839, G loss: 0.7502\n",
      "[964/1762] D loss: 1.3897, G loss: 0.7061\n",
      "[1044/1762] D loss: 1.3876, G loss: 0.7260\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.7083\n",
      "[1204/1762] D loss: 1.3872, G loss: 0.6755\n",
      "[1284/1762] D loss: 1.3873, G loss: 0.7028\n",
      "[1364/1762] D loss: 1.0413, G loss: 2.3324\n",
      "[1444/1762] D loss: 1.3867, G loss: 0.6795\n",
      "[1524/1762] D loss: 1.3871, G loss: 0.7163\n",
      "[1604/1762] D loss: 1.3873, G loss: 0.7161\n",
      "[1684/1762] D loss: 1.3867, G loss: 0.6828\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6982\n",
      "train error: \n",
      " D loss: 1.285725, G loss: 1.183862, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.257964, G loss: 1.338961, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0421, G loss: 2.3741\n",
      "[84/1762] D loss: 1.3865, G loss: 0.6985\n",
      "[164/1762] D loss: 1.3853, G loss: 0.6997\n",
      "[244/1762] D loss: 1.3866, G loss: 0.7020\n",
      "[324/1762] D loss: 1.3864, G loss: 0.6930\n",
      "[404/1762] D loss: 1.3871, G loss: 0.7151\n",
      "[484/1762] D loss: 0.9901, G loss: 2.7283\n",
      "[564/1762] D loss: 1.3913, G loss: 0.6238\n",
      "[644/1762] D loss: 1.3906, G loss: 0.7054\n",
      "[724/1762] D loss: 1.3874, G loss: 0.7205\n",
      "[804/1762] D loss: 1.3845, G loss: 0.6932\n",
      "[884/1762] D loss: 1.3868, G loss: 0.6803\n",
      "[964/1762] D loss: 1.3866, G loss: 0.7044\n",
      "[1044/1762] D loss: 1.3871, G loss: 0.6794\n",
      "[1124/1762] D loss: 1.3880, G loss: 0.6910\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6981\n",
      "[1284/1762] D loss: 1.3867, G loss: 0.6849\n",
      "[1364/1762] D loss: 1.3870, G loss: 0.6919\n",
      "[1444/1762] D loss: 1.0446, G loss: 1.5975\n",
      "[1524/1762] D loss: 0.6945, G loss: 4.9021\n",
      "[1604/1762] D loss: 1.0901, G loss: 2.6517\n",
      "[1684/1762] D loss: 1.3914, G loss: 0.7374\n",
      "[1762/1762] D loss: 1.3869, G loss: 0.7189\n",
      "train error: \n",
      " D loss: 1.287102, G loss: 1.238333, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.258898, G loss: 1.449721, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3880, G loss: 0.7248\n",
      "[84/1762] D loss: 1.3870, G loss: 0.7085\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6988\n",
      "[244/1762] D loss: 1.3868, G loss: 0.7076\n",
      "[324/1762] D loss: 1.3876, G loss: 0.7218\n",
      "[404/1762] D loss: 1.3878, G loss: 0.6938\n",
      "[484/1762] D loss: 1.3880, G loss: 0.6650\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6779\n",
      "[644/1762] D loss: 1.3883, G loss: 0.7230\n",
      "[724/1762] D loss: 0.6782, G loss: 4.6270\n",
      "[804/1762] D loss: 1.0386, G loss: 2.7066\n",
      "[884/1762] D loss: 1.3861, G loss: 0.7000\n",
      "[964/1762] D loss: 1.3865, G loss: 0.6817\n",
      "[1044/1762] D loss: 1.0442, G loss: 2.4828\n",
      "[1124/1762] D loss: 1.0395, G loss: 2.7087\n",
      "[1204/1762] D loss: 1.3874, G loss: 0.7033\n",
      "[1284/1762] D loss: 1.3883, G loss: 0.6661\n",
      "[1364/1762] D loss: 1.3873, G loss: 0.6904\n",
      "[1444/1762] D loss: 1.3861, G loss: 0.6916\n",
      "[1524/1762] D loss: 1.3868, G loss: 0.7167\n",
      "[1604/1762] D loss: 1.3932, G loss: 0.6603\n",
      "[1684/1762] D loss: 1.3911, G loss: 0.6382\n",
      "[1762/1762] D loss: 1.3843, G loss: 0.6876\n",
      "train error: \n",
      " D loss: 1.250837, G loss: 1.580148, D accuracy: 56.7%, cell accuracy: 99.8%, board accuracy: 87.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.234176, G loss: 1.762923, D accuracy: 57.3%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3858, G loss: 0.6772\n",
      "[84/1762] D loss: 0.7418, G loss: 3.6286\n",
      "[164/1762] D loss: 1.3882, G loss: 0.7025\n",
      "[244/1762] D loss: 1.3873, G loss: 0.6882\n",
      "[324/1762] D loss: 1.3873, G loss: 0.6664\n",
      "[404/1762] D loss: 1.0406, G loss: 2.9597\n",
      "[484/1762] D loss: 1.3860, G loss: 0.6846\n",
      "[564/1762] D loss: 1.0412, G loss: 3.2414\n",
      "[644/1762] D loss: 1.3851, G loss: 0.7100\n",
      "[724/1762] D loss: 1.3868, G loss: 0.6943\n",
      "[804/1762] D loss: 1.3881, G loss: 0.6707\n",
      "[884/1762] D loss: 1.0402, G loss: 2.7598\n",
      "[964/1762] D loss: 1.3863, G loss: 0.6999\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.6908\n",
      "[1124/1762] D loss: 1.3884, G loss: 0.6934\n",
      "[1204/1762] D loss: 1.3692, G loss: 0.7175\n",
      "[1284/1762] D loss: 1.3862, G loss: 0.6939\n",
      "[1364/1762] D loss: 1.3809, G loss: 0.7050\n",
      "[1444/1762] D loss: 1.0400, G loss: 2.8183\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.6843\n",
      "[1604/1762] D loss: 1.3866, G loss: 0.6844\n",
      "[1684/1762] D loss: 1.0394, G loss: 2.7767\n",
      "[1762/1762] D loss: 1.3874, G loss: 0.6642\n",
      "train error: \n",
      " D loss: 1.284363, G loss: 1.321238, D accuracy: 54.1%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.262715, G loss: 1.497428, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3866, G loss: 0.6906\n",
      "[84/1762] D loss: 1.3869, G loss: 0.6765\n",
      "[164/1762] D loss: 1.3867, G loss: 0.6987\n",
      "[244/1762] D loss: 1.0398, G loss: 2.7667\n",
      "[324/1762] D loss: 1.3865, G loss: 0.7014\n",
      "[404/1762] D loss: 1.3871, G loss: 0.6911\n",
      "[484/1762] D loss: 1.3864, G loss: 0.6910\n",
      "[564/1762] D loss: 1.3869, G loss: 0.6922\n",
      "[644/1762] D loss: 1.3870, G loss: 0.6750\n",
      "[724/1762] D loss: 1.3871, G loss: 0.6733\n",
      "[804/1762] D loss: 1.0060, G loss: 1.5199\n",
      "[884/1762] D loss: 1.6716, G loss: 0.4842\n",
      "[964/1762] D loss: 1.3973, G loss: 0.6253\n",
      "[1044/1762] D loss: 1.4070, G loss: 0.6053\n",
      "[1124/1762] D loss: 1.3952, G loss: 0.7236\n",
      "[1204/1762] D loss: 1.4000, G loss: 0.6881\n",
      "[1284/1762] D loss: 1.3869, G loss: 0.6871\n",
      "[1364/1762] D loss: 1.0521, G loss: 1.3798\n",
      "[1444/1762] D loss: 1.3901, G loss: 0.7137\n",
      "[1524/1762] D loss: 1.3877, G loss: 0.6670\n",
      "[1604/1762] D loss: 1.3865, G loss: 0.7071\n",
      "[1684/1762] D loss: 1.3873, G loss: 0.7014\n",
      "[1762/1762] D loss: 1.4197, G loss: 0.6072\n",
      "train error: \n",
      " D loss: 1.290021, G loss: 1.073632, D accuracy: 53.2%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.265856, G loss: 1.189316, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3871, G loss: 0.6956\n",
      "[84/1762] D loss: 1.3931, G loss: 0.6527\n",
      "[164/1762] D loss: 1.3879, G loss: 0.7022\n",
      "[244/1762] D loss: 1.3868, G loss: 0.6933\n",
      "[324/1762] D loss: 1.3867, G loss: 0.6817\n",
      "[404/1762] D loss: 1.3880, G loss: 0.6785\n",
      "[484/1762] D loss: 1.3867, G loss: 0.6994\n",
      "[564/1762] D loss: 1.0501, G loss: 1.7451\n",
      "[644/1762] D loss: 1.0440, G loss: 1.8695\n",
      "[724/1762] D loss: 1.0418, G loss: 1.9900\n",
      "[804/1762] D loss: 1.0415, G loss: 2.2017\n",
      "[884/1762] D loss: 1.0989, G loss: 2.0244\n",
      "[964/1762] D loss: 1.3871, G loss: 0.7049\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.7026\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.6845\n",
      "[1204/1762] D loss: 1.3861, G loss: 0.6793\n",
      "[1284/1762] D loss: 1.3869, G loss: 0.7047\n",
      "[1364/1762] D loss: 1.3774, G loss: 0.7346\n",
      "[1444/1762] D loss: 1.1248, G loss: 0.8108\n",
      "[1524/1762] D loss: 1.2687, G loss: 0.8819\n",
      "[1604/1762] D loss: 1.3754, G loss: 0.6023\n",
      "[1684/1762] D loss: 1.1837, G loss: 1.0775\n",
      "[1762/1762] D loss: 1.1228, G loss: 0.9105\n",
      "train error: \n",
      " D loss: 1.238711, G loss: 0.977594, D accuracy: 58.1%, cell accuracy: 99.7%, board accuracy: 82.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.224110, G loss: 1.011101, D accuracy: 59.1%, cell accuracy: 99.6%, board accuracy: 80.0% \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5955, G loss: 2.7704\n",
      "[84/1762] D loss: 1.3822, G loss: 0.6337\n",
      "[164/1762] D loss: 1.3521, G loss: 0.6122\n",
      "[244/1762] D loss: 1.3890, G loss: 0.6692\n",
      "[324/1762] D loss: 1.0365, G loss: 2.0168\n",
      "[404/1762] D loss: 1.3904, G loss: 0.6853\n",
      "[484/1762] D loss: 1.2335, G loss: 1.3245\n",
      "[564/1762] D loss: 1.4253, G loss: 0.5855\n",
      "[644/1762] D loss: 1.3867, G loss: 0.6787\n",
      "[724/1762] D loss: 1.3875, G loss: 0.6610\n",
      "[804/1762] D loss: 1.3909, G loss: 0.7465\n",
      "[884/1762] D loss: 1.3899, G loss: 0.6538\n",
      "[964/1762] D loss: 1.0444, G loss: 1.5346\n",
      "[1044/1762] D loss: 1.3871, G loss: 0.7023\n",
      "[1124/1762] D loss: 1.3882, G loss: 0.6636\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6919\n",
      "[1284/1762] D loss: 1.3859, G loss: 0.6824\n",
      "[1364/1762] D loss: 1.3876, G loss: 0.6706\n",
      "[1444/1762] D loss: 1.0600, G loss: 1.2103\n",
      "[1524/1762] D loss: 1.0626, G loss: 1.1639\n",
      "[1604/1762] D loss: 1.3908, G loss: 0.7381\n",
      "[1684/1762] D loss: 1.3771, G loss: 0.6954\n",
      "[1762/1762] D loss: 1.3908, G loss: 0.6587\n",
      "train error: \n",
      " D loss: 1.402503, G loss: 0.782792, D accuracy: 52.9%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.448356, G loss: 0.716587, D accuracy: 52.3%, cell accuracy: 99.7%, board accuracy: 84.8% \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3872, G loss: 0.6823\n",
      "[84/1762] D loss: 1.5362, G loss: 0.6385\n",
      "[164/1762] D loss: 1.4157, G loss: 0.6521\n",
      "[244/1762] D loss: 1.4090, G loss: 0.6526\n",
      "[324/1762] D loss: 1.3614, G loss: 0.6994\n",
      "[404/1762] D loss: 1.3847, G loss: 0.6928\n",
      "[484/1762] D loss: 1.0509, G loss: 1.4942\n",
      "[564/1762] D loss: 1.0566, G loss: 1.6234\n",
      "[644/1762] D loss: 1.3867, G loss: 0.7217\n",
      "[724/1762] D loss: 1.2240, G loss: 1.0489\n",
      "[804/1762] D loss: 1.2299, G loss: 0.7345\n",
      "[884/1762] D loss: 1.3869, G loss: 0.6918\n",
      "[964/1762] D loss: 1.2139, G loss: 1.2161\n",
      "[1044/1762] D loss: 1.1504, G loss: 1.1065\n",
      "[1124/1762] D loss: 1.1197, G loss: 0.9548\n",
      "[1204/1762] D loss: 1.3950, G loss: 0.6940\n",
      "[1284/1762] D loss: 1.3890, G loss: 0.7468\n",
      "[1364/1762] D loss: 1.1045, G loss: 0.8854\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6993\n",
      "[1524/1762] D loss: 1.3867, G loss: 0.6953\n",
      "[1604/1762] D loss: 1.3874, G loss: 0.6889\n",
      "[1684/1762] D loss: 1.3875, G loss: 0.7177\n",
      "[1762/1762] D loss: 1.3666, G loss: 0.7897\n",
      "train error: \n",
      " D loss: 1.292773, G loss: 0.891789, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 89.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.277623, G loss: 0.906922, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2386, G loss: 1.0162\n",
      "[84/1762] D loss: 1.3904, G loss: 0.7571\n",
      "[164/1762] D loss: 1.0581, G loss: 1.5929\n",
      "[244/1762] D loss: 1.3868, G loss: 0.6980\n",
      "[324/1762] D loss: 1.3873, G loss: 0.6844\n",
      "[404/1762] D loss: 1.0442, G loss: 1.6564\n",
      "[484/1762] D loss: 1.0420, G loss: 1.8294\n",
      "[564/1762] D loss: 1.3865, G loss: 0.7181\n",
      "[644/1762] D loss: 1.3873, G loss: 0.7108\n",
      "[724/1762] D loss: 1.3868, G loss: 0.7053\n",
      "[804/1762] D loss: 1.4054, G loss: 0.6510\n",
      "[884/1762] D loss: 1.3880, G loss: 0.6712\n",
      "[964/1762] D loss: 1.3866, G loss: 0.6796\n",
      "[1044/1762] D loss: 1.0443, G loss: 1.8568\n",
      "[1124/1762] D loss: 1.3889, G loss: 0.7196\n",
      "[1204/1762] D loss: 1.3878, G loss: 0.7216\n",
      "[1284/1762] D loss: 1.3862, G loss: 0.6900\n",
      "[1364/1762] D loss: 1.3871, G loss: 0.6742\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.7049\n",
      "[1524/1762] D loss: 1.3710, G loss: 0.7346\n",
      "[1604/1762] D loss: 1.0414, G loss: 2.2956\n",
      "[1684/1762] D loss: 1.3877, G loss: 0.7026\n",
      "[1762/1762] D loss: 1.3975, G loss: 0.7116\n",
      "train error: \n",
      " D loss: 1.287042, G loss: 1.138583, D accuracy: 54.0%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.263833, G loss: 1.249829, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3699, G loss: 0.6995\n",
      "[84/1762] D loss: 1.3869, G loss: 0.6931\n",
      "[164/1762] D loss: 1.0346, G loss: 2.1602\n",
      "[244/1762] D loss: 1.3483, G loss: 0.7444\n",
      "[324/1762] D loss: 1.3904, G loss: 0.7197\n",
      "[404/1762] D loss: 1.4119, G loss: 0.5611\n",
      "[484/1762] D loss: 1.4073, G loss: 0.7370\n",
      "[564/1762] D loss: 1.3875, G loss: 0.6780\n",
      "[644/1762] D loss: 1.0416, G loss: 4.3902\n",
      "[724/1762] D loss: 1.3884, G loss: 0.6533\n",
      "[804/1762] D loss: 1.3321, G loss: 0.7349\n",
      "[884/1762] D loss: 1.3890, G loss: 0.6703\n",
      "[964/1762] D loss: 1.3891, G loss: 0.6949\n",
      "[1044/1762] D loss: 1.3883, G loss: 0.6758\n",
      "[1124/1762] D loss: 1.3894, G loss: 0.6444\n",
      "[1204/1762] D loss: 1.3878, G loss: 0.7018\n",
      "[1284/1762] D loss: 1.4029, G loss: 0.6320\n",
      "[1364/1762] D loss: 1.3964, G loss: 0.6039\n",
      "[1444/1762] D loss: 1.0470, G loss: 2.1867\n",
      "[1524/1762] D loss: 1.3824, G loss: 0.7192\n",
      "[1604/1762] D loss: 1.3625, G loss: 0.7181\n",
      "[1684/1762] D loss: 1.3856, G loss: 0.7045\n",
      "[1762/1762] D loss: 1.4009, G loss: 0.6992\n",
      "train error: \n",
      " D loss: 1.281490, G loss: 1.209391, D accuracy: 54.6%, cell accuracy: 99.9%, board accuracy: 90.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.257388, G loss: 1.329368, D accuracy: 55.6%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3884, G loss: 0.7199\n",
      "[84/1762] D loss: 1.3869, G loss: 0.7196\n",
      "[164/1762] D loss: 1.3869, G loss: 0.6737\n",
      "[244/1762] D loss: 1.3887, G loss: 0.7074\n",
      "[324/1762] D loss: 1.0429, G loss: 2.2871\n",
      "[404/1762] D loss: 1.0406, G loss: 2.3077\n",
      "[484/1762] D loss: 1.3852, G loss: 0.6958\n",
      "[564/1762] D loss: 1.3908, G loss: 0.6832\n",
      "[644/1762] D loss: 1.3874, G loss: 0.6845\n",
      "[724/1762] D loss: 1.3901, G loss: 0.6514\n",
      "[804/1762] D loss: 1.3864, G loss: 0.7057\n",
      "[884/1762] D loss: 1.0401, G loss: 2.3502\n",
      "[964/1762] D loss: 0.8173, G loss: 4.2475\n",
      "[1044/1762] D loss: 1.3874, G loss: 0.7210\n",
      "[1124/1762] D loss: 1.3869, G loss: 0.6747\n",
      "[1204/1762] D loss: 1.3873, G loss: 0.6979\n",
      "[1284/1762] D loss: 1.3895, G loss: 0.6686\n",
      "[1364/1762] D loss: 1.0400, G loss: 2.3587\n",
      "[1444/1762] D loss: 1.3869, G loss: 0.7059\n",
      "[1524/1762] D loss: 1.3876, G loss: 0.6704\n",
      "[1604/1762] D loss: 1.0451, G loss: 2.4464\n",
      "[1684/1762] D loss: 1.3862, G loss: 0.6888\n",
      "[1762/1762] D loss: 1.3862, G loss: 0.6944\n",
      "train error: \n",
      " D loss: 1.284342, G loss: 1.238961, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.263008, G loss: 1.377372, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3880, G loss: 0.6778\n",
      "[84/1762] D loss: 1.3869, G loss: 0.7049\n",
      "[164/1762] D loss: 1.3865, G loss: 0.6913\n",
      "[244/1762] D loss: 1.0430, G loss: 2.5297\n",
      "[324/1762] D loss: 1.0425, G loss: 2.8812\n",
      "[404/1762] D loss: 1.3830, G loss: 0.6721\n",
      "[484/1762] D loss: 1.3492, G loss: 0.6748\n",
      "[564/1762] D loss: 1.3916, G loss: 0.7540\n",
      "[644/1762] D loss: 1.3806, G loss: 0.6890\n",
      "[724/1762] D loss: 1.3911, G loss: 0.7365\n",
      "[804/1762] D loss: 1.3861, G loss: 0.7163\n",
      "[884/1762] D loss: 1.1975, G loss: 1.4030\n",
      "[964/1762] D loss: 1.4031, G loss: 0.8102\n",
      "[1044/1762] D loss: 1.3905, G loss: 0.7210\n",
      "[1124/1762] D loss: 1.1673, G loss: 0.8649\n",
      "[1204/1762] D loss: 1.3833, G loss: 0.7014\n",
      "[1284/1762] D loss: 1.3748, G loss: 0.7258\n",
      "[1364/1762] D loss: 1.0877, G loss: 0.9537\n",
      "[1444/1762] D loss: 1.2025, G loss: 1.3907\n",
      "[1524/1762] D loss: 1.2252, G loss: 1.1687\n",
      "[1604/1762] D loss: 0.7058, G loss: 3.8963\n",
      "[1684/1762] D loss: 1.3967, G loss: 0.6852\n",
      "[1762/1762] D loss: 1.3869, G loss: 0.6954\n",
      "train error: \n",
      " D loss: 1.294588, G loss: 1.001766, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.279587, G loss: 1.126155, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3886, G loss: 0.6668\n",
      "[84/1762] D loss: 1.3876, G loss: 0.6946\n",
      "[164/1762] D loss: 1.0414, G loss: 2.0178\n",
      "[244/1762] D loss: 1.3845, G loss: 0.7121\n",
      "[324/1762] D loss: 1.3869, G loss: 0.6935\n",
      "[404/1762] D loss: 1.3882, G loss: 0.6734\n",
      "[484/1762] D loss: 1.3877, G loss: 0.7141\n",
      "[564/1762] D loss: 1.3880, G loss: 0.6961\n",
      "[644/1762] D loss: 1.3878, G loss: 0.6567\n",
      "[724/1762] D loss: 1.2174, G loss: 1.4877\n",
      "[804/1762] D loss: 1.0956, G loss: 0.8994\n",
      "[884/1762] D loss: 1.3929, G loss: 0.6419\n",
      "[964/1762] D loss: 1.3874, G loss: 0.6786\n",
      "[1044/1762] D loss: 1.3798, G loss: 0.6913\n",
      "[1124/1762] D loss: 1.3875, G loss: 0.6854\n",
      "[1204/1762] D loss: 1.3883, G loss: 0.7141\n",
      "[1284/1762] D loss: 1.0489, G loss: 2.3811\n",
      "[1364/1762] D loss: 1.0623, G loss: 2.1099\n",
      "[1444/1762] D loss: 1.0418, G loss: 1.9342\n",
      "[1524/1762] D loss: 1.4066, G loss: 0.5852\n",
      "[1604/1762] D loss: 1.3876, G loss: 0.6636\n",
      "[1684/1762] D loss: 1.3860, G loss: 0.6991\n",
      "[1762/1762] D loss: 1.3871, G loss: 0.6848\n",
      "train error: \n",
      " D loss: 1.278100, G loss: 1.059924, D accuracy: 54.9%, cell accuracy: 99.7%, board accuracy: 88.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.264198, G loss: 1.067510, D accuracy: 56.0%, cell accuracy: 99.6%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4017, G loss: 0.7707\n",
      "[84/1762] D loss: 1.3878, G loss: 0.6733\n",
      "[164/1762] D loss: 1.0975, G loss: 1.0868\n",
      "[244/1762] D loss: 1.3084, G loss: 0.8026\n",
      "[324/1762] D loss: 1.3881, G loss: 0.6915\n",
      "[404/1762] D loss: 1.3871, G loss: 0.6917\n",
      "[484/1762] D loss: 1.3898, G loss: 0.6715\n",
      "[564/1762] D loss: 0.7351, G loss: 1.6303\n",
      "[644/1762] D loss: 1.3889, G loss: 0.7379\n",
      "[724/1762] D loss: 1.3865, G loss: 0.6822\n",
      "[804/1762] D loss: 1.3870, G loss: 0.6971\n",
      "[884/1762] D loss: 1.3869, G loss: 0.7056\n",
      "[964/1762] D loss: 1.3867, G loss: 0.6968\n",
      "[1044/1762] D loss: 1.3865, G loss: 0.6830\n",
      "[1124/1762] D loss: 1.3885, G loss: 0.7121\n",
      "[1204/1762] D loss: 1.0726, G loss: 1.0406\n",
      "[1284/1762] D loss: 1.3916, G loss: 0.6847\n",
      "[1364/1762] D loss: 1.2413, G loss: 0.8513\n",
      "[1444/1762] D loss: 1.3896, G loss: 0.7044\n",
      "[1524/1762] D loss: 1.3872, G loss: 0.6794\n",
      "[1604/1762] D loss: 1.3887, G loss: 0.7083\n",
      "[1684/1762] D loss: 1.3865, G loss: 0.6832\n",
      "[1762/1762] D loss: 1.3897, G loss: 0.7556\n",
      "train error: \n",
      " D loss: 1.297700, G loss: 0.885316, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.292516, G loss: 0.895989, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0770, G loss: 1.0349\n",
      "[84/1762] D loss: 1.3899, G loss: 0.6732\n",
      "[164/1762] D loss: 1.3869, G loss: 0.6790\n",
      "[244/1762] D loss: 1.3871, G loss: 0.6823\n",
      "[324/1762] D loss: 1.3905, G loss: 0.7562\n",
      "[404/1762] D loss: 1.3878, G loss: 0.7270\n",
      "[484/1762] D loss: 1.0844, G loss: 0.9755\n",
      "[564/1762] D loss: 1.3866, G loss: 0.6939\n",
      "[644/1762] D loss: 1.3790, G loss: 0.7065\n",
      "[724/1762] D loss: 1.3202, G loss: 0.8118\n",
      "[804/1762] D loss: 1.3890, G loss: 0.6755\n",
      "[884/1762] D loss: 1.0581, G loss: 1.1962\n",
      "[964/1762] D loss: 1.3870, G loss: 0.6908\n",
      "[1044/1762] D loss: 1.2087, G loss: 1.6016\n",
      "[1124/1762] D loss: 1.3869, G loss: 0.6773\n",
      "[1204/1762] D loss: 1.3904, G loss: 0.6362\n",
      "[1284/1762] D loss: 1.3868, G loss: 0.6948\n",
      "[1364/1762] D loss: 1.3866, G loss: 0.7108\n",
      "[1444/1762] D loss: 1.0711, G loss: 1.0655\n",
      "[1524/1762] D loss: 1.3890, G loss: 0.6648\n",
      "[1604/1762] D loss: 1.3873, G loss: 0.7083\n",
      "[1684/1762] D loss: 1.0668, G loss: 1.0891\n",
      "[1762/1762] D loss: 1.3890, G loss: 0.6540\n",
      "train error: \n",
      " D loss: 1.299844, G loss: 0.851470, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.288416, G loss: 0.880529, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3874, G loss: 0.6782\n",
      "[84/1762] D loss: 1.3854, G loss: 0.7039\n",
      "[164/1762] D loss: 1.3867, G loss: 0.6899\n",
      "[244/1762] D loss: 1.0654, G loss: 1.0806\n",
      "[324/1762] D loss: 1.3866, G loss: 0.7114\n",
      "[404/1762] D loss: 1.0848, G loss: 1.0451\n",
      "[484/1762] D loss: 1.3873, G loss: 0.7155\n",
      "[564/1762] D loss: 1.3871, G loss: 0.7003\n",
      "[644/1762] D loss: 1.3877, G loss: 0.6735\n",
      "[724/1762] D loss: 1.3878, G loss: 0.7176\n",
      "[804/1762] D loss: 1.0619, G loss: 1.1105\n",
      "[884/1762] D loss: 1.3868, G loss: 0.6930\n",
      "[964/1762] D loss: 1.3868, G loss: 0.7148\n",
      "[1044/1762] D loss: 1.2445, G loss: 1.0726\n",
      "[1124/1762] D loss: 1.0350, G loss: 1.0627\n",
      "[1204/1762] D loss: 0.7510, G loss: 1.4773\n",
      "[1284/1762] D loss: 1.3865, G loss: 0.7036\n",
      "[1364/1762] D loss: 1.3848, G loss: 0.6933\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.6834\n",
      "[1524/1762] D loss: 1.3868, G loss: 0.6775\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6869\n",
      "[1684/1762] D loss: 1.3862, G loss: 0.6940\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6900\n",
      "train error: \n",
      " D loss: 1.308037, G loss: 0.938205, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 93.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.304966, G loss: 1.001207, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6849\n",
      "[84/1762] D loss: 2.0249, G loss: 1.3793\n",
      "[164/1762] D loss: 1.3878, G loss: 0.6833\n",
      "[244/1762] D loss: 1.3880, G loss: 0.7288\n",
      "[324/1762] D loss: 1.0899, G loss: 0.9537\n",
      "[404/1762] D loss: 1.3868, G loss: 0.6942\n",
      "[484/1762] D loss: 1.0791, G loss: 0.9911\n",
      "[564/1762] D loss: 1.3866, G loss: 0.7097\n",
      "[644/1762] D loss: 1.3869, G loss: 0.7046\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6916\n",
      "[804/1762] D loss: 1.3873, G loss: 0.7084\n",
      "[884/1762] D loss: 1.3870, G loss: 0.6931\n",
      "[964/1762] D loss: 1.0558, G loss: 1.2573\n",
      "[1044/1762] D loss: 1.0588, G loss: 1.1970\n",
      "[1124/1762] D loss: 1.3874, G loss: 0.6891\n",
      "[1204/1762] D loss: 1.3866, G loss: 0.6831\n",
      "[1284/1762] D loss: 0.7130, G loss: 2.0509\n",
      "[1364/1762] D loss: 1.3865, G loss: 0.7083\n",
      "[1444/1762] D loss: 1.3878, G loss: 0.7195\n",
      "[1524/1762] D loss: 1.0505, G loss: 1.3385\n",
      "[1604/1762] D loss: 1.3872, G loss: 0.6786\n",
      "[1684/1762] D loss: 1.3866, G loss: 0.6849\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.7000\n",
      "train error: \n",
      " D loss: 1.303993, G loss: 0.867245, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.294275, G loss: 0.950525, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3840, G loss: 0.6845\n",
      "[84/1762] D loss: 1.3867, G loss: 0.6735\n",
      "[164/1762] D loss: 1.3867, G loss: 0.6863\n",
      "[244/1762] D loss: 1.3871, G loss: 0.6791\n",
      "[324/1762] D loss: 1.3832, G loss: 0.6999\n",
      "[404/1762] D loss: 1.3866, G loss: 0.7072\n",
      "[484/1762] D loss: 1.3864, G loss: 0.6980\n",
      "[564/1762] D loss: 1.0768, G loss: 1.1655\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6960\n",
      "[724/1762] D loss: 1.0617, G loss: 1.1345\n",
      "[804/1762] D loss: 1.3866, G loss: 0.7116\n",
      "[884/1762] D loss: 1.3865, G loss: 0.6808\n",
      "[964/1762] D loss: 1.3863, G loss: 0.6999\n",
      "[1044/1762] D loss: 1.4338, G loss: 1.7234\n",
      "[1124/1762] D loss: 1.3871, G loss: 0.6871\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.7023\n",
      "[1284/1762] D loss: 1.3880, G loss: 0.7038\n",
      "[1364/1762] D loss: 1.3860, G loss: 0.6638\n",
      "[1444/1762] D loss: 1.3868, G loss: 0.6915\n",
      "[1524/1762] D loss: 1.3873, G loss: 0.7270\n",
      "[1604/1762] D loss: 1.0750, G loss: 1.0563\n",
      "[1684/1762] D loss: 1.3876, G loss: 0.7247\n",
      "[1762/1762] D loss: 1.3866, G loss: 0.6727\n",
      "train error: \n",
      " D loss: 1.305761, G loss: 0.815598, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.299418, G loss: 0.868410, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3875, G loss: 0.6602\n",
      "[84/1762] D loss: 1.3875, G loss: 0.6689\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6901\n",
      "[244/1762] D loss: 1.3866, G loss: 0.6887\n",
      "[324/1762] D loss: 1.3866, G loss: 0.7036\n",
      "[404/1762] D loss: 1.3867, G loss: 0.7065\n",
      "[484/1762] D loss: 1.3866, G loss: 0.6795\n",
      "[564/1762] D loss: 1.0803, G loss: 1.0107\n",
      "[644/1762] D loss: 1.0682, G loss: 1.0908\n",
      "[724/1762] D loss: 1.3864, G loss: 0.7079\n",
      "[804/1762] D loss: 1.0561, G loss: 1.2197\n",
      "[884/1762] D loss: 1.3865, G loss: 0.7015\n",
      "[964/1762] D loss: 1.3865, G loss: 0.7067\n",
      "[1044/1762] D loss: 1.3871, G loss: 0.6780\n",
      "[1124/1762] D loss: 1.3891, G loss: 0.6532\n",
      "[1204/1762] D loss: 1.0509, G loss: 1.3081\n",
      "[1284/1762] D loss: 1.3928, G loss: 0.6394\n",
      "[1364/1762] D loss: 1.3865, G loss: 0.6894\n",
      "[1444/1762] D loss: 1.0337, G loss: 1.4579\n",
      "[1524/1762] D loss: 1.0433, G loss: 1.6462\n",
      "[1604/1762] D loss: 1.3867, G loss: 0.6346\n",
      "[1684/1762] D loss: 1.0560, G loss: 1.2336\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6902\n",
      "train error: \n",
      " D loss: 1.304724, G loss: 0.823275, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.294215, G loss: 0.867867, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3875, G loss: 0.6724\n",
      "[84/1762] D loss: 1.3867, G loss: 0.6819\n",
      "[164/1762] D loss: 1.3870, G loss: 0.6997\n",
      "[244/1762] D loss: 1.0744, G loss: 1.0352\n",
      "[324/1762] D loss: 1.3869, G loss: 0.7141\n",
      "[404/1762] D loss: 1.3865, G loss: 0.6941\n",
      "[484/1762] D loss: 1.3866, G loss: 0.6950\n",
      "[564/1762] D loss: 1.3863, G loss: 0.6900\n",
      "[644/1762] D loss: 1.3868, G loss: 0.7076\n",
      "[724/1762] D loss: 1.3872, G loss: 0.6759\n",
      "[804/1762] D loss: 1.3869, G loss: 0.7098\n",
      "[884/1762] D loss: 1.3874, G loss: 0.7063\n",
      "[964/1762] D loss: 1.0796, G loss: 0.9963\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.6831\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.6893\n",
      "[1204/1762] D loss: 1.3867, G loss: 0.6833\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.7037\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6961\n",
      "[1444/1762] D loss: 1.3868, G loss: 0.6993\n",
      "[1524/1762] D loss: 1.3865, G loss: 0.6836\n",
      "[1604/1762] D loss: 1.0681, G loss: 1.0790\n",
      "[1684/1762] D loss: 1.3884, G loss: 0.6828\n",
      "[1762/1762] D loss: 1.3873, G loss: 0.6818\n",
      "train error: \n",
      " D loss: 1.298913, G loss: 0.933570, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.289218, G loss: 1.040418, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6955\n",
      "[84/1762] D loss: 1.3866, G loss: 0.7037\n",
      "[164/1762] D loss: 1.6819, G loss: 1.1311\n",
      "[244/1762] D loss: 1.3864, G loss: 0.7013\n",
      "[324/1762] D loss: 1.0671, G loss: 1.1381\n",
      "[404/1762] D loss: 1.0577, G loss: 1.2029\n",
      "[484/1762] D loss: 1.0545, G loss: 1.2492\n",
      "[564/1762] D loss: 1.7235, G loss: 1.2023\n",
      "[644/1762] D loss: 1.3866, G loss: 0.6977\n",
      "[724/1762] D loss: 1.3866, G loss: 0.6975\n",
      "[804/1762] D loss: 1.3864, G loss: 0.7022\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6895\n",
      "[964/1762] D loss: 1.3869, G loss: 0.6731\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.6824\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.6912\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6932\n",
      "[1284/1762] D loss: 1.2050, G loss: 1.3296\n",
      "[1364/1762] D loss: 1.0709, G loss: 1.2157\n",
      "[1444/1762] D loss: 1.0772, G loss: 1.1425\n",
      "[1524/1762] D loss: 1.2031, G loss: 1.1746\n",
      "[1604/1762] D loss: 1.3894, G loss: 0.6555\n",
      "[1684/1762] D loss: 1.3930, G loss: 0.6601\n",
      "[1762/1762] D loss: 1.3869, G loss: 0.6919\n",
      "train error: \n",
      " D loss: 1.297920, G loss: 0.906408, D accuracy: 53.9%, cell accuracy: 99.7%, board accuracy: 89.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.285643, G loss: 0.979842, D accuracy: 55.1%, cell accuracy: 99.6%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3907, G loss: 0.6582\n",
      "[84/1762] D loss: 1.0512, G loss: 1.3842\n",
      "[164/1762] D loss: 1.3957, G loss: 0.7369\n",
      "[244/1762] D loss: 1.1664, G loss: 0.7239\n",
      "[324/1762] D loss: 1.3925, G loss: 0.7530\n",
      "[404/1762] D loss: 1.3862, G loss: 0.6843\n",
      "[484/1762] D loss: 1.3869, G loss: 0.7138\n",
      "[564/1762] D loss: 1.3866, G loss: 0.6856\n",
      "[644/1762] D loss: 1.3755, G loss: 0.7018\n",
      "[724/1762] D loss: 1.3884, G loss: 0.6622\n",
      "[804/1762] D loss: 1.3866, G loss: 0.6906\n",
      "[884/1762] D loss: 1.3867, G loss: 0.6843\n",
      "[964/1762] D loss: 1.3864, G loss: 0.6943\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.6895\n",
      "[1124/1762] D loss: 1.0720, G loss: 1.0550\n",
      "[1204/1762] D loss: 1.3868, G loss: 0.6963\n",
      "[1284/1762] D loss: 1.3870, G loss: 0.7018\n",
      "[1364/1762] D loss: 0.7197, G loss: 1.9083\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6888\n",
      "[1524/1762] D loss: 0.7187, G loss: 1.8271\n",
      "[1604/1762] D loss: 1.0517, G loss: 1.3054\n",
      "[1684/1762] D loss: 1.0499, G loss: 1.3426\n",
      "[1762/1762] D loss: 0.7113, G loss: 2.0208\n",
      "train error: \n",
      " D loss: 1.301202, G loss: 0.898741, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.293014, G loss: 0.963055, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3872, G loss: 0.6924\n",
      "[84/1762] D loss: 1.3865, G loss: 0.6822\n",
      "[164/1762] D loss: 1.0617, G loss: 1.2170\n",
      "[244/1762] D loss: 1.0497, G loss: 1.3067\n",
      "[324/1762] D loss: 1.3865, G loss: 0.6949\n",
      "[404/1762] D loss: 1.3866, G loss: 0.6909\n",
      "[484/1762] D loss: 1.0642, G loss: 1.3112\n",
      "[564/1762] D loss: 1.0490, G loss: 1.3513\n",
      "[644/1762] D loss: 1.0477, G loss: 1.3953\n",
      "[724/1762] D loss: 1.3865, G loss: 0.6931\n",
      "[804/1762] D loss: 1.3866, G loss: 0.6917\n",
      "[884/1762] D loss: 1.3862, G loss: 0.6897\n",
      "[964/1762] D loss: 1.3864, G loss: 0.6937\n",
      "[1044/1762] D loss: 1.3913, G loss: 0.7303\n",
      "[1124/1762] D loss: 1.3949, G loss: 0.7861\n",
      "[1204/1762] D loss: 1.3895, G loss: 0.6549\n",
      "[1284/1762] D loss: 1.3874, G loss: 0.7008\n",
      "[1364/1762] D loss: 0.9046, G loss: 4.9533\n",
      "[1444/1762] D loss: 1.3869, G loss: 0.6983\n",
      "[1524/1762] D loss: 1.3865, G loss: 0.7010\n",
      "[1604/1762] D loss: 1.3878, G loss: 0.6753\n",
      "[1684/1762] D loss: 1.3873, G loss: 0.7014\n",
      "[1762/1762] D loss: 1.3879, G loss: 0.6571\n",
      "train error: \n",
      " D loss: 1.284855, G loss: 1.151694, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.260588, G loss: 1.281322, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3858, G loss: 0.6682\n",
      "[84/1762] D loss: 1.3868, G loss: 0.7059\n",
      "[164/1762] D loss: 1.3865, G loss: 0.6860\n",
      "[244/1762] D loss: 1.3870, G loss: 0.6862\n",
      "[324/1762] D loss: 1.3867, G loss: 0.7007\n",
      "[404/1762] D loss: 1.3873, G loss: 0.6747\n",
      "[484/1762] D loss: 1.3866, G loss: 0.6810\n",
      "[564/1762] D loss: 1.3873, G loss: 0.7118\n",
      "[644/1762] D loss: 1.3876, G loss: 0.6678\n",
      "[724/1762] D loss: 1.3871, G loss: 0.6994\n",
      "[804/1762] D loss: 1.2147, G loss: 1.2897\n",
      "[884/1762] D loss: 1.3869, G loss: 0.7101\n",
      "[964/1762] D loss: 1.3869, G loss: 0.6949\n",
      "[1044/1762] D loss: 1.3874, G loss: 0.6722\n",
      "[1124/1762] D loss: 1.0400, G loss: 2.3953\n",
      "[1204/1762] D loss: 1.3865, G loss: 0.6954\n",
      "[1284/1762] D loss: 1.0392, G loss: 2.4319\n",
      "[1364/1762] D loss: 1.3942, G loss: 0.6223\n",
      "[1444/1762] D loss: 1.3879, G loss: 0.7216\n",
      "[1524/1762] D loss: 1.3885, G loss: 0.6608\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6898\n",
      "[1684/1762] D loss: 1.3865, G loss: 0.6922\n",
      "[1762/1762] D loss: 0.6949, G loss: 4.1142\n",
      "train error: \n",
      " D loss: 1.282815, G loss: 1.205535, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.256493, G loss: 1.356344, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3865, G loss: 0.6878\n",
      "[84/1762] D loss: 1.3866, G loss: 0.6784\n",
      "[164/1762] D loss: 1.3866, G loss: 0.6794\n",
      "[244/1762] D loss: 1.3870, G loss: 0.6944\n",
      "[324/1762] D loss: 1.3874, G loss: 0.7001\n",
      "[404/1762] D loss: 1.0399, G loss: 2.4378\n",
      "[484/1762] D loss: 1.0401, G loss: 2.4345\n",
      "[564/1762] D loss: 1.0401, G loss: 2.4223\n",
      "[644/1762] D loss: 1.3864, G loss: 0.6916\n",
      "[724/1762] D loss: 1.0404, G loss: 2.4278\n",
      "[804/1762] D loss: 1.3867, G loss: 0.6821\n",
      "[884/1762] D loss: 1.0427, G loss: 2.4632\n",
      "[964/1762] D loss: 1.3873, G loss: 0.6779\n",
      "[1044/1762] D loss: 1.3868, G loss: 0.6918\n",
      "[1124/1762] D loss: 1.0407, G loss: 2.4836\n",
      "[1204/1762] D loss: 1.0400, G loss: 2.5019\n",
      "[1284/1762] D loss: 1.3894, G loss: 0.6871\n",
      "[1364/1762] D loss: 1.3866, G loss: 0.6975\n",
      "[1444/1762] D loss: 1.3866, G loss: 0.7022\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.6887\n",
      "[1604/1762] D loss: 1.3875, G loss: 0.6668\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6894\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6934\n",
      "train error: \n",
      " D loss: 1.282364, G loss: 1.252617, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.256957, G loss: 1.416448, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6945\n",
      "[84/1762] D loss: 1.3868, G loss: 0.6732\n",
      "[164/1762] D loss: 1.0401, G loss: 2.5554\n",
      "[244/1762] D loss: 1.3861, G loss: 0.6972\n",
      "[324/1762] D loss: 1.3864, G loss: 0.6920\n",
      "[404/1762] D loss: 1.3864, G loss: 0.7050\n",
      "[484/1762] D loss: 1.3864, G loss: 0.6908\n",
      "[564/1762] D loss: 1.3869, G loss: 0.7120\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6900\n",
      "[724/1762] D loss: 1.3866, G loss: 0.7064\n",
      "[804/1762] D loss: 1.3863, G loss: 0.6909\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6965\n",
      "[964/1762] D loss: 1.3870, G loss: 0.6987\n",
      "[1044/1762] D loss: 1.3993, G loss: 0.6260\n",
      "[1124/1762] D loss: 1.3897, G loss: 0.7545\n",
      "[1204/1762] D loss: 1.0422, G loss: 2.5643\n",
      "[1284/1762] D loss: 1.3866, G loss: 0.6970\n",
      "[1364/1762] D loss: 1.3873, G loss: 0.6905\n",
      "[1444/1762] D loss: 1.0400, G loss: 2.6314\n",
      "[1524/1762] D loss: 1.0407, G loss: 2.6673\n",
      "[1604/1762] D loss: 1.3871, G loss: 0.7016\n",
      "[1684/1762] D loss: 1.3869, G loss: 0.6937\n",
      "[1762/1762] D loss: 1.3921, G loss: 0.6529\n",
      "train error: \n",
      " D loss: 1.281657, G loss: 1.288705, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.258202, G loss: 1.441342, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0400, G loss: 2.6070\n",
      "[84/1762] D loss: 1.3708, G loss: 0.7240\n",
      "[164/1762] D loss: 1.3891, G loss: 0.6781\n",
      "[244/1762] D loss: 0.7056, G loss: 4.5959\n",
      "[324/1762] D loss: 1.3917, G loss: 0.6351\n",
      "[404/1762] D loss: 1.3867, G loss: 0.6705\n",
      "[484/1762] D loss: 1.3883, G loss: 0.7058\n",
      "[564/1762] D loss: 1.3879, G loss: 0.6796\n",
      "[644/1762] D loss: 1.0415, G loss: 2.1666\n",
      "[724/1762] D loss: 1.3888, G loss: 0.6537\n",
      "[804/1762] D loss: 1.3866, G loss: 0.7053\n",
      "[884/1762] D loss: 1.0474, G loss: 2.2370\n",
      "[964/1762] D loss: 1.0412, G loss: 2.2689\n",
      "[1044/1762] D loss: 1.3876, G loss: 0.6717\n",
      "[1124/1762] D loss: 1.3870, G loss: 0.6777\n",
      "[1204/1762] D loss: 1.3870, G loss: 0.7076\n",
      "[1284/1762] D loss: 1.3865, G loss: 0.7040\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6972\n",
      "[1444/1762] D loss: 1.3875, G loss: 0.7041\n",
      "[1524/1762] D loss: 1.3868, G loss: 0.7042\n",
      "[1604/1762] D loss: 1.3870, G loss: 0.7088\n",
      "[1684/1762] D loss: 1.3866, G loss: 0.6835\n",
      "[1762/1762] D loss: 1.3875, G loss: 0.6753\n",
      "train error: \n",
      " D loss: 1.281656, G loss: 1.177494, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.255206, G loss: 1.312967, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0407, G loss: 2.2760\n",
      "[84/1762] D loss: 1.3866, G loss: 0.6831\n",
      "[164/1762] D loss: 1.3868, G loss: 0.7055\n",
      "[244/1762] D loss: 1.3865, G loss: 0.6928\n",
      "[324/1762] D loss: 1.0368, G loss: 2.3179\n",
      "[404/1762] D loss: 1.0400, G loss: 2.3236\n",
      "[484/1762] D loss: 1.3865, G loss: 0.6922\n",
      "[564/1762] D loss: 1.3868, G loss: 0.6995\n",
      "[644/1762] D loss: 1.3864, G loss: 0.6920\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6977\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6938\n",
      "[884/1762] D loss: 1.3865, G loss: 0.6926\n",
      "[964/1762] D loss: 1.3864, G loss: 0.6821\n",
      "[1044/1762] D loss: 1.3867, G loss: 0.6803\n",
      "[1124/1762] D loss: 1.3869, G loss: 0.6877\n",
      "[1204/1762] D loss: 1.3866, G loss: 0.6932\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.7023\n",
      "[1364/1762] D loss: 1.3867, G loss: 0.7031\n",
      "[1444/1762] D loss: 1.3866, G loss: 0.7040\n",
      "[1524/1762] D loss: 1.0400, G loss: 2.4360\n",
      "[1604/1762] D loss: 1.0444, G loss: 2.4357\n",
      "[1684/1762] D loss: 1.3876, G loss: 0.7089\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6884\n",
      "train error: \n",
      " D loss: 1.282227, G loss: 1.219342, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.254828, G loss: 1.373955, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6885\n",
      "[84/1762] D loss: 1.3866, G loss: 0.7023\n",
      "[164/1762] D loss: 1.3867, G loss: 0.7014\n",
      "[244/1762] D loss: 1.0401, G loss: 2.4784\n",
      "[324/1762] D loss: 1.3864, G loss: 0.6864\n",
      "[404/1762] D loss: 1.0399, G loss: 2.4795\n",
      "[484/1762] D loss: 1.3864, G loss: 0.6892\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6907\n",
      "[644/1762] D loss: 1.3864, G loss: 0.6933\n",
      "[724/1762] D loss: 1.3866, G loss: 0.6906\n",
      "[804/1762] D loss: 1.3863, G loss: 0.6918\n",
      "[884/1762] D loss: 1.0399, G loss: 2.5189\n",
      "[964/1762] D loss: 1.3872, G loss: 0.7119\n",
      "[1044/1762] D loss: 0.6936, G loss: 4.3506\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.6849\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6911\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6978\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6932\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6941\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.6963\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6952\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6973\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.7026\n",
      "train error: \n",
      " D loss: 1.282095, G loss: 1.249462, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.254791, G loss: 1.412832, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3865, G loss: 0.6824\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6881\n",
      "[164/1762] D loss: 1.3864, G loss: 0.6886\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6961\n",
      "[324/1762] D loss: 1.3864, G loss: 0.6926\n",
      "[404/1762] D loss: 1.3865, G loss: 0.6880\n",
      "[484/1762] D loss: 1.3864, G loss: 0.6844\n",
      "[564/1762] D loss: 1.3865, G loss: 0.6926\n",
      "[644/1762] D loss: 1.3867, G loss: 0.6813\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6866\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6982\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6906\n",
      "[964/1762] D loss: 1.0398, G loss: 2.6080\n",
      "[1044/1762] D loss: 1.3865, G loss: 0.7004\n",
      "[1124/1762] D loss: 1.0399, G loss: 2.6067\n",
      "[1204/1762] D loss: 1.0398, G loss: 2.6129\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6852\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6854\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.7018\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.6950\n",
      "[1604/1762] D loss: 0.6974, G loss: 4.5770\n",
      "[1684/1762] D loss: 1.3867, G loss: 0.7099\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6928\n",
      "train error: \n",
      " D loss: 1.281997, G loss: 1.280205, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.254909, G loss: 1.451659, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6866\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6955\n",
      "[164/1762] D loss: 1.3864, G loss: 0.6887\n",
      "[244/1762] D loss: 0.6933, G loss: 4.6172\n",
      "[324/1762] D loss: 1.3864, G loss: 0.6927\n",
      "[404/1762] D loss: 1.3863, G loss: 0.6902\n",
      "[484/1762] D loss: 1.0398, G loss: 2.6678\n",
      "[564/1762] D loss: 1.0400, G loss: 2.6614\n",
      "[644/1762] D loss: 1.3867, G loss: 0.7002\n",
      "[724/1762] D loss: 1.0398, G loss: 2.6761\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6983\n",
      "[884/1762] D loss: 1.3867, G loss: 0.6981\n",
      "[964/1762] D loss: 1.3883, G loss: 0.6824\n",
      "[1044/1762] D loss: 1.3865, G loss: 0.6899\n",
      "[1124/1762] D loss: 1.0398, G loss: 2.6966\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6936\n",
      "[1284/1762] D loss: 0.6933, G loss: 4.7363\n",
      "[1364/1762] D loss: 1.3867, G loss: 0.7060\n",
      "[1444/1762] D loss: 1.0426, G loss: 2.7109\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.6977\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6955\n",
      "[1684/1762] D loss: 1.0414, G loss: 2.7244\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6915\n",
      "train error: \n",
      " D loss: 1.281188, G loss: 1.314322, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.254937, G loss: 1.487190, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6960\n",
      "[84/1762] D loss: 1.3865, G loss: 0.6904\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6934\n",
      "[244/1762] D loss: 1.3865, G loss: 0.6832\n",
      "[324/1762] D loss: 1.0397, G loss: 2.7457\n",
      "[404/1762] D loss: 1.3866, G loss: 0.6920\n",
      "[484/1762] D loss: 1.3864, G loss: 0.6948\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6908\n",
      "[644/1762] D loss: 1.0398, G loss: 2.7179\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6830\n",
      "[804/1762] D loss: 1.0398, G loss: 2.7258\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6972\n",
      "[964/1762] D loss: 1.3864, G loss: 0.6929\n",
      "[1044/1762] D loss: 1.0411, G loss: 2.7326\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.6880\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6978\n",
      "[1284/1762] D loss: 1.0421, G loss: 2.7580\n",
      "[1364/1762] D loss: 1.0399, G loss: 2.7692\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6882\n",
      "[1524/1762] D loss: 1.3870, G loss: 0.6813\n",
      "[1604/1762] D loss: 1.3865, G loss: 0.6921\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6909\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.7001\n",
      "train error: \n",
      " D loss: 1.281977, G loss: 1.317403, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.254930, G loss: 1.500396, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0399, G loss: 2.7726\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6945\n",
      "[164/1762] D loss: 1.3864, G loss: 0.6971\n",
      "[244/1762] D loss: 1.0398, G loss: 2.7929\n",
      "[324/1762] D loss: 1.3865, G loss: 0.6968\n",
      "[404/1762] D loss: 1.0402, G loss: 2.8062\n",
      "[484/1762] D loss: 1.3864, G loss: 0.6952\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6973\n",
      "[644/1762] D loss: 1.3865, G loss: 0.6801\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6860\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6965\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6873\n",
      "[964/1762] D loss: 1.3865, G loss: 0.6863\n",
      "[1044/1762] D loss: 1.3866, G loss: 0.6992\n",
      "[1124/1762] D loss: 0.6937, G loss: 4.6401\n",
      "[1204/1762] D loss: 1.0398, G loss: 2.6651\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6924\n",
      "[1364/1762] D loss: 1.3868, G loss: 0.7105\n",
      "[1444/1762] D loss: 1.0409, G loss: 2.6961\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.6905\n",
      "[1604/1762] D loss: 1.3866, G loss: 0.6944\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.6888\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6961\n",
      "train error: \n",
      " D loss: 1.281970, G loss: 1.310187, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.254926, G loss: 1.486868, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3865, G loss: 0.7033\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6963\n",
      "[164/1762] D loss: 1.3864, G loss: 0.6855\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6948\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6904\n",
      "[404/1762] D loss: 1.3865, G loss: 0.6897\n",
      "[484/1762] D loss: 1.3864, G loss: 0.6971\n",
      "[564/1762] D loss: 1.0398, G loss: 2.7593\n",
      "[644/1762] D loss: 1.3864, G loss: 0.6965\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6916\n",
      "[804/1762] D loss: 1.3865, G loss: 0.7017\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6887\n",
      "[964/1762] D loss: 1.3869, G loss: 0.7063\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.6947\n",
      "[1124/1762] D loss: 1.0398, G loss: 2.7793\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6981\n",
      "[1284/1762] D loss: 1.0404, G loss: 2.7964\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6851\n",
      "[1444/1762] D loss: 1.0398, G loss: 2.8069\n",
      "[1524/1762] D loss: 1.0398, G loss: 2.7973\n",
      "[1604/1762] D loss: 1.0398, G loss: 2.8011\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6961\n",
      "[1762/1762] D loss: 0.6932, G loss: 4.9352\n",
      "train error: \n",
      " D loss: 1.281931, G loss: 1.328543, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.255755, G loss: 1.514170, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6903\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6871\n",
      "[164/1762] D loss: 1.3863, G loss: 0.7013\n",
      "[244/1762] D loss: 1.0398, G loss: 2.8346\n",
      "[324/1762] D loss: 1.0398, G loss: 2.8447\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6907\n",
      "[484/1762] D loss: 1.3863, G loss: 0.7009\n",
      "[564/1762] D loss: 1.0399, G loss: 2.8485\n",
      "[644/1762] D loss: 1.3858, G loss: 0.6995\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6929\n",
      "[804/1762] D loss: 1.3863, G loss: 0.6936\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6928\n",
      "[964/1762] D loss: 1.3859, G loss: 0.6938\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6934\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6943\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6846\n",
      "[1284/1762] D loss: 1.3868, G loss: 0.6963\n",
      "[1364/1762] D loss: 1.0398, G loss: 2.8817\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6877\n",
      "[1524/1762] D loss: 1.0407, G loss: 2.8787\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6827\n",
      "[1684/1762] D loss: 1.3867, G loss: 0.6796\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.7093\n",
      "train error: \n",
      " D loss: 1.282018, G loss: 1.360381, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.253154, G loss: 1.557159, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3866, G loss: 0.6930\n",
      "[84/1762] D loss: 1.3866, G loss: 0.7107\n",
      "[164/1762] D loss: 1.3866, G loss: 0.6848\n",
      "[244/1762] D loss: 1.3866, G loss: 0.6955\n",
      "[324/1762] D loss: 1.3864, G loss: 0.6912\n",
      "[404/1762] D loss: 1.0398, G loss: 2.9342\n",
      "[484/1762] D loss: 1.0398, G loss: 2.9365\n",
      "[564/1762] D loss: 1.0398, G loss: 2.9411\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6922\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6830\n",
      "[804/1762] D loss: 1.3863, G loss: 0.6913\n",
      "[884/1762] D loss: 1.0397, G loss: 2.9480\n",
      "[964/1762] D loss: 1.3863, G loss: 0.6892\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.6927\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.6879\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6934\n",
      "[1284/1762] D loss: 1.0398, G loss: 2.9591\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6981\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6853\n",
      "[1524/1762] D loss: 1.0398, G loss: 2.9691\n",
      "[1604/1762] D loss: 1.0398, G loss: 2.9913\n",
      "[1684/1762] D loss: 1.3873, G loss: 0.6841\n",
      "[1762/1762] D loss: 1.3886, G loss: 0.7260\n",
      "train error: \n",
      " D loss: 1.282180, G loss: 1.389859, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.253948, G loss: 1.592000, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3866, G loss: 0.6991\n",
      "[84/1762] D loss: 1.0402, G loss: 2.9612\n",
      "[164/1762] D loss: 1.3865, G loss: 0.7022\n",
      "[244/1762] D loss: 1.3864, G loss: 0.6892\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6959\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6945\n",
      "[484/1762] D loss: 1.3863, G loss: 0.6898\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6919\n",
      "[644/1762] D loss: 1.3864, G loss: 0.6951\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6926\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6885\n",
      "[884/1762] D loss: 1.3865, G loss: 0.7056\n",
      "[964/1762] D loss: 1.3871, G loss: 0.7029\n",
      "[1044/1762] D loss: 1.3865, G loss: 0.6824\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6932\n",
      "[1204/1762] D loss: 0.6932, G loss: 5.3347\n",
      "[1284/1762] D loss: 1.0398, G loss: 3.0241\n",
      "[1364/1762] D loss: 1.3865, G loss: 0.6992\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6922\n",
      "[1524/1762] D loss: 1.0399, G loss: 3.0322\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6912\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6927\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6954\n",
      "train error: \n",
      " D loss: 1.281842, G loss: 1.400557, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.253771, G loss: 1.606301, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0398, G loss: 3.0381\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6962\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6927\n",
      "[244/1762] D loss: 1.0398, G loss: 3.0486\n",
      "[324/1762] D loss: 1.0397, G loss: 3.0569\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6863\n",
      "[484/1762] D loss: 1.3863, G loss: 0.6930\n",
      "[564/1762] D loss: 1.0398, G loss: 3.0631\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6903\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6908\n",
      "[804/1762] D loss: 1.0398, G loss: 3.0723\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6940\n",
      "[964/1762] D loss: 1.3866, G loss: 0.6814\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.6940\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.6965\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6864\n",
      "[1284/1762] D loss: 1.0398, G loss: 3.0761\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6901\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6892\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.6860\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6993\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.6884\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6918\n",
      "train error: \n",
      " D loss: 1.281908, G loss: 1.418826, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.254328, G loss: 1.628898, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6911\n",
      "[84/1762] D loss: 1.0398, G loss: 3.0995\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6925\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6949\n",
      "[324/1762] D loss: 1.3865, G loss: 0.6884\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6903\n",
      "[484/1762] D loss: 1.3864, G loss: 0.6882\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6950\n",
      "[644/1762] D loss: 1.3870, G loss: 0.6926\n",
      "[724/1762] D loss: 1.0399, G loss: 3.1447\n",
      "[804/1762] D loss: 1.0398, G loss: 3.1398\n",
      "[884/1762] D loss: 1.3865, G loss: 0.7024\n",
      "[964/1762] D loss: 1.0402, G loss: 3.1460\n",
      "[1044/1762] D loss: 1.0399, G loss: 3.1401\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6962\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6900\n",
      "[1284/1762] D loss: 1.0398, G loss: 3.1581\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.7036\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6923\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.6921\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.7034\n",
      "[1684/1762] D loss: 1.4217, G loss: 0.7063\n",
      "[1762/1762] D loss: 1.4375, G loss: 0.8034\n",
      "train error: \n",
      " D loss: 1.307008, G loss: 1.333176, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 91.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.268890, G loss: 1.477479, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3918, G loss: 0.6626\n",
      "[84/1762] D loss: 1.3891, G loss: 0.6883\n",
      "[164/1762] D loss: 1.3864, G loss: 0.6891\n",
      "[244/1762] D loss: 1.0401, G loss: 2.3055\n",
      "[324/1762] D loss: 1.3864, G loss: 0.6977\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6976\n",
      "[484/1762] D loss: 1.3846, G loss: 0.7009\n",
      "[564/1762] D loss: 1.3865, G loss: 0.6884\n",
      "[644/1762] D loss: 1.3868, G loss: 0.6905\n",
      "[724/1762] D loss: 1.3850, G loss: 0.6926\n",
      "[804/1762] D loss: 1.0401, G loss: 2.4871\n",
      "[884/1762] D loss: 1.3855, G loss: 0.6845\n",
      "[964/1762] D loss: 1.3867, G loss: 0.7058\n",
      "[1044/1762] D loss: 1.3871, G loss: 0.6675\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.6989\n",
      "[1204/1762] D loss: 1.3866, G loss: 0.7035\n",
      "[1284/1762] D loss: 1.0401, G loss: 2.5124\n",
      "[1364/1762] D loss: 1.3868, G loss: 0.6850\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.7010\n",
      "[1524/1762] D loss: 1.0401, G loss: 2.5995\n",
      "[1604/1762] D loss: 1.0400, G loss: 2.5777\n",
      "[1684/1762] D loss: 1.3865, G loss: 0.6898\n",
      "[1762/1762] D loss: 1.3871, G loss: 0.6870\n",
      "train error: \n",
      " D loss: 1.281880, G loss: 1.284396, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.253414, G loss: 1.456541, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0412, G loss: 2.6335\n",
      "[84/1762] D loss: 1.0401, G loss: 2.6520\n",
      "[164/1762] D loss: 1.3876, G loss: 0.6669\n",
      "[244/1762] D loss: 1.3865, G loss: 0.6824\n",
      "[324/1762] D loss: 1.3873, G loss: 0.6861\n",
      "[404/1762] D loss: 1.3866, G loss: 0.6815\n",
      "[484/1762] D loss: 1.0411, G loss: 2.4854\n",
      "[564/1762] D loss: 1.0401, G loss: 2.5195\n",
      "[644/1762] D loss: 1.3864, G loss: 0.6886\n",
      "[724/1762] D loss: 1.0399, G loss: 2.5313\n",
      "[804/1762] D loss: 1.0400, G loss: 2.5478\n",
      "[884/1762] D loss: 1.0399, G loss: 2.6178\n",
      "[964/1762] D loss: 1.3887, G loss: 0.6589\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.6966\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.6952\n",
      "[1204/1762] D loss: 1.3849, G loss: 0.6831\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6984\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6949\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6853\n",
      "[1524/1762] D loss: 1.3865, G loss: 0.7042\n",
      "[1604/1762] D loss: 1.3865, G loss: 0.6967\n",
      "[1684/1762] D loss: 1.0398, G loss: 2.6978\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.7017\n",
      "train error: \n",
      " D loss: 1.281661, G loss: 1.305599, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.253747, G loss: 1.473785, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0399, G loss: 2.7304\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6950\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6962\n",
      "[244/1762] D loss: 1.0398, G loss: 2.6579\n",
      "[324/1762] D loss: 0.7000, G loss: 4.6101\n",
      "[404/1762] D loss: 1.3847, G loss: 0.6929\n",
      "[484/1762] D loss: 1.3864, G loss: 0.6848\n",
      "[564/1762] D loss: 1.3867, G loss: 0.7002\n",
      "[644/1762] D loss: 1.0395, G loss: 2.6590\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6905\n",
      "[804/1762] D loss: 1.0398, G loss: 2.7547\n",
      "[884/1762] D loss: 1.3865, G loss: 0.6985\n",
      "[964/1762] D loss: 1.3868, G loss: 0.6762\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.6943\n",
      "[1124/1762] D loss: 1.3869, G loss: 0.7113\n",
      "[1204/1762] D loss: 1.3865, G loss: 0.6913\n",
      "[1284/1762] D loss: 1.3865, G loss: 0.7038\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6914\n",
      "[1444/1762] D loss: 1.3874, G loss: 0.6668\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.6935\n",
      "[1604/1762] D loss: 1.3888, G loss: 0.7244\n",
      "[1684/1762] D loss: 1.3871, G loss: 0.7172\n",
      "[1762/1762] D loss: 1.3915, G loss: 0.6367\n",
      "train error: \n",
      " D loss: 1.286945, G loss: 0.902851, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 89.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.259244, G loss: 0.974429, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3904, G loss: 0.6565\n",
      "[84/1762] D loss: 1.3892, G loss: 0.6772\n",
      "[164/1762] D loss: 1.3872, G loss: 0.6743\n",
      "[244/1762] D loss: 1.3912, G loss: 0.6936\n",
      "[324/1762] D loss: 1.0004, G loss: 2.9502\n",
      "[404/1762] D loss: 1.3919, G loss: 0.6757\n",
      "[484/1762] D loss: 1.3875, G loss: 0.7030\n",
      "[564/1762] D loss: 1.3905, G loss: 0.6386\n",
      "[644/1762] D loss: 1.3880, G loss: 0.6441\n",
      "[724/1762] D loss: 1.3866, G loss: 0.6946\n",
      "[804/1762] D loss: 1.0400, G loss: 3.3275\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6878\n",
      "[964/1762] D loss: 1.3866, G loss: 0.7020\n",
      "[1044/1762] D loss: 1.3868, G loss: 0.7005\n",
      "[1124/1762] D loss: 1.0414, G loss: 3.3262\n",
      "[1204/1762] D loss: 1.0401, G loss: 3.2596\n",
      "[1284/1762] D loss: 1.3870, G loss: 0.6709\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6965\n",
      "[1444/1762] D loss: 1.0044, G loss: 3.4102\n",
      "[1524/1762] D loss: 1.3851, G loss: 0.7044\n",
      "[1604/1762] D loss: 1.3855, G loss: 0.7000\n",
      "[1684/1762] D loss: 1.3887, G loss: 0.6638\n",
      "[1762/1762] D loss: 1.4036, G loss: 0.5886\n",
      "train error: \n",
      " D loss: 1.273664, G loss: 1.642886, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 89.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.245524, G loss: 1.917615, D accuracy: 55.8%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3922, G loss: 0.6472\n",
      "[84/1762] D loss: 1.3892, G loss: 0.7002\n",
      "[164/1762] D loss: 1.0404, G loss: 3.2396\n",
      "[244/1762] D loss: 1.0418, G loss: 3.3926\n",
      "[324/1762] D loss: 1.3841, G loss: 0.7202\n",
      "[404/1762] D loss: 1.3861, G loss: 0.6836\n",
      "[484/1762] D loss: 1.3865, G loss: 0.6824\n",
      "[564/1762] D loss: 1.3879, G loss: 0.6635\n",
      "[644/1762] D loss: 1.3875, G loss: 0.7092\n",
      "[724/1762] D loss: 1.0410, G loss: 2.9638\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6922\n",
      "[884/1762] D loss: 1.3588, G loss: 0.7370\n",
      "[964/1762] D loss: 1.0345, G loss: 3.0700\n",
      "[1044/1762] D loss: 1.3867, G loss: 0.7007\n",
      "[1124/1762] D loss: 1.3938, G loss: 0.7006\n",
      "[1204/1762] D loss: 1.0401, G loss: 3.0385\n",
      "[1284/1762] D loss: 1.0402, G loss: 3.0623\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6863\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.6860\n",
      "[1524/1762] D loss: 1.3838, G loss: 0.6875\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6806\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.6998\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6973\n",
      "train error: \n",
      " D loss: 1.283571, G loss: 1.421843, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.255373, G loss: 1.594889, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0398, G loss: 3.0720\n",
      "[84/1762] D loss: 1.3865, G loss: 0.6888\n",
      "[164/1762] D loss: 1.0410, G loss: 1.8523\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6929\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6916\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6880\n",
      "[484/1762] D loss: 1.2097, G loss: 13.2746\n",
      "[564/1762] D loss: 1.0405, G loss: 3.1278\n",
      "[644/1762] D loss: 1.3864, G loss: 0.6899\n",
      "[724/1762] D loss: 1.3869, G loss: 0.7115\n",
      "[804/1762] D loss: 1.0398, G loss: 3.1545\n",
      "[884/1762] D loss: 1.0407, G loss: 3.1745\n",
      "[964/1762] D loss: 1.3868, G loss: 0.6753\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.7000\n",
      "[1124/1762] D loss: 0.6932, G loss: 5.7077\n",
      "[1204/1762] D loss: 1.3873, G loss: 0.6670\n",
      "[1284/1762] D loss: 0.8808, G loss: 4.2558\n",
      "[1364/1762] D loss: 1.3878, G loss: 0.6703\n",
      "[1444/1762] D loss: 1.3868, G loss: 0.7046\n",
      "[1524/1762] D loss: 1.3865, G loss: 0.6886\n",
      "[1604/1762] D loss: 0.6945, G loss: 5.7680\n",
      "[1684/1762] D loss: 0.6933, G loss: 5.7770\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.7003\n",
      "train error: \n",
      " D loss: 1.282367, G loss: 1.470994, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.254311, G loss: 1.687226, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6898\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6937\n",
      "[164/1762] D loss: 1.3869, G loss: 0.6741\n",
      "[244/1762] D loss: 1.3869, G loss: 0.7140\n",
      "[324/1762] D loss: 1.3866, G loss: 0.7094\n",
      "[404/1762] D loss: 1.3865, G loss: 0.6852\n",
      "[484/1762] D loss: 1.3871, G loss: 0.6827\n",
      "[564/1762] D loss: 1.3865, G loss: 0.7024\n",
      "[644/1762] D loss: 1.3864, G loss: 0.6954\n",
      "[724/1762] D loss: 1.3865, G loss: 0.6946\n",
      "[804/1762] D loss: 1.3865, G loss: 0.6983\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6971\n",
      "[964/1762] D loss: 1.0398, G loss: 3.2372\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.6922\n",
      "[1124/1762] D loss: 1.0398, G loss: 3.2414\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6974\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6917\n",
      "[1364/1762] D loss: 1.0398, G loss: 3.2391\n",
      "[1444/1762] D loss: 1.3867, G loss: 0.6775\n",
      "[1524/1762] D loss: 1.3865, G loss: 0.6941\n",
      "[1604/1762] D loss: 1.3865, G loss: 0.6849\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.6966\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6975\n",
      "train error: \n",
      " D loss: 1.281181, G loss: 1.482058, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.253262, G loss: 1.688674, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6870\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6906\n",
      "[164/1762] D loss: 1.3865, G loss: 0.6996\n",
      "[244/1762] D loss: 0.6932, G loss: 5.7960\n",
      "[324/1762] D loss: 1.3865, G loss: 0.6993\n",
      "[404/1762] D loss: 1.0398, G loss: 3.2437\n",
      "[484/1762] D loss: 1.3856, G loss: 0.7181\n",
      "[564/1762] D loss: 1.0421, G loss: 3.2070\n",
      "[644/1762] D loss: 1.3864, G loss: 0.6992\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6911\n",
      "[804/1762] D loss: 1.3863, G loss: 0.6905\n",
      "[884/1762] D loss: 1.3867, G loss: 0.6854\n",
      "[964/1762] D loss: 1.3866, G loss: 0.6960\n",
      "[1044/1762] D loss: 1.0398, G loss: 4.3223\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6903\n",
      "[1204/1762] D loss: 1.3865, G loss: 0.6818\n",
      "[1284/1762] D loss: 1.0397, G loss: 3.2180\n",
      "[1364/1762] D loss: 0.6933, G loss: 5.7425\n",
      "[1444/1762] D loss: 1.3868, G loss: 0.6871\n",
      "[1524/1762] D loss: 1.3869, G loss: 0.6807\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6921\n",
      "[1684/1762] D loss: 1.0397, G loss: 3.2194\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.6827\n",
      "train error: \n",
      " D loss: 1.283093, G loss: 1.464033, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.252321, G loss: 1.679392, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3870, G loss: 0.7086\n",
      "[84/1762] D loss: 1.0401, G loss: 3.2293\n",
      "[164/1762] D loss: 1.3864, G loss: 0.6945\n",
      "[244/1762] D loss: 1.0405, G loss: 3.2103\n",
      "[324/1762] D loss: 1.3865, G loss: 0.6985\n",
      "[404/1762] D loss: 0.6933, G loss: 5.8016\n",
      "[484/1762] D loss: 1.3875, G loss: 0.7327\n",
      "[564/1762] D loss: 1.3868, G loss: 0.6716\n",
      "[644/1762] D loss: 1.0398, G loss: 3.1884\n",
      "[724/1762] D loss: 1.3871, G loss: 0.7002\n",
      "[804/1762] D loss: 0.6933, G loss: 5.6050\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6945\n",
      "[964/1762] D loss: 1.3868, G loss: 0.6792\n",
      "[1044/1762] D loss: 1.3872, G loss: 0.6844\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.6905\n",
      "[1204/1762] D loss: 1.3858, G loss: 0.6817\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6958\n",
      "[1364/1762] D loss: 1.3866, G loss: 0.6810\n",
      "[1444/1762] D loss: 1.3833, G loss: 0.6901\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.6949\n",
      "[1604/1762] D loss: 1.3865, G loss: 0.6943\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6993\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6969\n",
      "train error: \n",
      " D loss: 1.280385, G loss: 1.474229, D accuracy: 54.1%, cell accuracy: 99.9%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.252116, G loss: 1.682557, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6948\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6894\n",
      "[164/1762] D loss: 1.3864, G loss: 0.6874\n",
      "[244/1762] D loss: 1.3817, G loss: 0.6977\n",
      "[324/1762] D loss: 1.3868, G loss: 0.6720\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6904\n",
      "[484/1762] D loss: 1.0399, G loss: 3.0649\n",
      "[564/1762] D loss: 1.3865, G loss: 0.7040\n",
      "[644/1762] D loss: 1.0398, G loss: 3.0871\n",
      "[724/1762] D loss: 1.3867, G loss: 0.7103\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6996\n",
      "[884/1762] D loss: 1.0402, G loss: 3.0923\n",
      "[964/1762] D loss: 1.3867, G loss: 0.6877\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.7016\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6912\n",
      "[1204/1762] D loss: 1.0399, G loss: 3.1046\n",
      "[1284/1762] D loss: 1.0398, G loss: 3.1029\n",
      "[1364/1762] D loss: 1.0397, G loss: 3.1053\n",
      "[1444/1762] D loss: 1.0398, G loss: 3.1254\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.6864\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6937\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.6872\n",
      "[1762/1762] D loss: 1.3866, G loss: 0.6791\n",
      "train error: \n",
      " D loss: 1.282763, G loss: 1.441497, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.251926, G loss: 1.741288, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6957\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6929\n",
      "[164/1762] D loss: 1.3864, G loss: 0.6970\n",
      "[244/1762] D loss: 1.5930, G loss: 1.1372\n",
      "[324/1762] D loss: 1.3867, G loss: 0.6871\n",
      "[404/1762] D loss: 1.3883, G loss: 0.7392\n",
      "[484/1762] D loss: 1.4362, G loss: 0.6727\n",
      "[564/1762] D loss: 1.3865, G loss: 0.6780\n",
      "[644/1762] D loss: 1.3895, G loss: 0.7366\n",
      "[724/1762] D loss: 1.1907, G loss: 2.0668\n",
      "[804/1762] D loss: 1.3870, G loss: 0.7021\n",
      "[884/1762] D loss: 1.3874, G loss: 0.7124\n",
      "[964/1762] D loss: 1.0400, G loss: 2.6320\n",
      "[1044/1762] D loss: 1.0405, G loss: 2.6334\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.6923\n",
      "[1204/1762] D loss: 1.0401, G loss: 2.6873\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6919\n",
      "[1364/1762] D loss: 1.3872, G loss: 0.6883\n",
      "[1444/1762] D loss: 1.0407, G loss: 2.6752\n",
      "[1524/1762] D loss: 1.3868, G loss: 0.6903\n",
      "[1604/1762] D loss: 1.0646, G loss: 2.6870\n",
      "[1684/1762] D loss: 1.3865, G loss: 0.7022\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6868\n",
      "train error: \n",
      " D loss: 1.288534, G loss: 1.199643, D accuracy: 55.2%, cell accuracy: 99.7%, board accuracy: 79.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.260093, G loss: 1.393558, D accuracy: 56.1%, cell accuracy: 99.6%, board accuracy: 75.2% \n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2779, G loss: 0.6439\n",
      "[84/1762] D loss: 0.9911, G loss: 3.0637\n",
      "[164/1762] D loss: 1.3956, G loss: 0.5791\n",
      "[244/1762] D loss: 1.3977, G loss: 0.7457\n",
      "[324/1762] D loss: 1.3875, G loss: 0.6658\n",
      "[404/1762] D loss: 1.3895, G loss: 0.6991\n",
      "[484/1762] D loss: 1.3851, G loss: 0.7073\n",
      "[564/1762] D loss: 1.0397, G loss: 2.6649\n",
      "[644/1762] D loss: 0.6899, G loss: 5.3834\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6962\n",
      "[804/1762] D loss: 1.3866, G loss: 0.6848\n",
      "[884/1762] D loss: 1.3869, G loss: 0.7086\n",
      "[964/1762] D loss: 1.0407, G loss: 3.0666\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.6923\n",
      "[1124/1762] D loss: 1.3869, G loss: 0.7146\n",
      "[1204/1762] D loss: 1.3872, G loss: 0.6615\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6975\n",
      "[1364/1762] D loss: 1.3805, G loss: 0.7087\n",
      "[1444/1762] D loss: 1.3791, G loss: 0.7040\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.6989\n",
      "[1604/1762] D loss: 1.3870, G loss: 0.6728\n",
      "[1684/1762] D loss: 1.3859, G loss: 0.6890\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.6860\n",
      "train error: \n",
      " D loss: 1.285178, G loss: 1.429600, D accuracy: 54.0%, cell accuracy: 99.9%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.253534, G loss: 1.660100, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0422, G loss: 3.1588\n",
      "[84/1762] D loss: 1.3870, G loss: 0.6792\n",
      "[164/1762] D loss: 1.3868, G loss: 0.6828\n",
      "[244/1762] D loss: 1.3881, G loss: 0.7104\n",
      "[324/1762] D loss: 1.3862, G loss: 0.6836\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6841\n",
      "[484/1762] D loss: 1.3863, G loss: 0.6940\n",
      "[564/1762] D loss: 1.3869, G loss: 0.6971\n",
      "[644/1762] D loss: 1.3864, G loss: 0.7038\n",
      "[724/1762] D loss: 1.0402, G loss: 3.1578\n",
      "[804/1762] D loss: 1.3865, G loss: 0.6824\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6851\n",
      "[964/1762] D loss: 1.3867, G loss: 0.6775\n",
      "[1044/1762] D loss: 1.3884, G loss: 0.7235\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.6908\n",
      "[1204/1762] D loss: 1.3865, G loss: 0.6895\n",
      "[1284/1762] D loss: 1.3867, G loss: 0.6764\n",
      "[1364/1762] D loss: 1.3888, G loss: 0.6548\n",
      "[1444/1762] D loss: 0.6940, G loss: 4.9473\n",
      "[1524/1762] D loss: 1.0407, G loss: 2.8673\n",
      "[1604/1762] D loss: 1.0360, G loss: 2.8028\n",
      "[1684/1762] D loss: 1.3867, G loss: 0.6951\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6892\n",
      "train error: \n",
      " D loss: 1.283250, G loss: 1.341244, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.254774, G loss: 1.532441, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3865, G loss: 0.6909\n",
      "[84/1762] D loss: 1.3872, G loss: 0.6646\n",
      "[164/1762] D loss: 1.3869, G loss: 0.7121\n",
      "[244/1762] D loss: 1.3866, G loss: 0.6988\n",
      "[324/1762] D loss: 1.0398, G loss: 2.8126\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6961\n",
      "[484/1762] D loss: 1.0399, G loss: 2.8001\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6856\n",
      "[644/1762] D loss: 1.0398, G loss: 2.8075\n",
      "[724/1762] D loss: 1.3865, G loss: 0.7038\n",
      "[804/1762] D loss: 1.0401, G loss: 2.7948\n",
      "[884/1762] D loss: 1.3865, G loss: 0.6970\n",
      "[964/1762] D loss: 1.3868, G loss: 0.6847\n",
      "[1044/1762] D loss: 1.3937, G loss: 0.7078\n",
      "[1124/1762] D loss: 1.3869, G loss: 0.7108\n",
      "[1204/1762] D loss: 1.0398, G loss: 2.9941\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6900\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6928\n",
      "[1444/1762] D loss: 1.0397, G loss: 2.9990\n",
      "[1524/1762] D loss: 0.6935, G loss: 5.3075\n",
      "[1604/1762] D loss: 1.3862, G loss: 0.6929\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.6920\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6923\n",
      "train error: \n",
      " D loss: 1.281742, G loss: 1.379828, D accuracy: 54.0%, cell accuracy: 99.9%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.251197, G loss: 1.598402, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6985\n",
      "[84/1762] D loss: 1.3859, G loss: 0.6955\n",
      "[164/1762] D loss: 1.0399, G loss: 3.0057\n",
      "[244/1762] D loss: 1.0421, G loss: 2.9927\n",
      "[324/1762] D loss: 1.0398, G loss: 2.9779\n",
      "[404/1762] D loss: 1.0399, G loss: 2.9990\n",
      "[484/1762] D loss: 1.3863, G loss: 0.6898\n",
      "[564/1762] D loss: 1.3863, G loss: 0.6950\n",
      "[644/1762] D loss: 1.0397, G loss: 2.9784\n",
      "[724/1762] D loss: 1.0398, G loss: 2.9871\n",
      "[804/1762] D loss: 0.6936, G loss: 5.2703\n",
      "[884/1762] D loss: 1.3867, G loss: 0.7010\n",
      "[964/1762] D loss: 1.0400, G loss: 2.9946\n",
      "[1044/1762] D loss: 1.3869, G loss: 0.7023\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.6850\n",
      "[1204/1762] D loss: 1.0397, G loss: 2.9883\n",
      "[1284/1762] D loss: 1.0398, G loss: 2.9871\n",
      "[1364/1762] D loss: 1.0400, G loss: 2.9847\n",
      "[1444/1762] D loss: 1.0398, G loss: 2.9900\n",
      "[1524/1762] D loss: 1.0397, G loss: 2.9938\n",
      "[1604/1762] D loss: 0.6932, G loss: 5.2958\n",
      "[1684/1762] D loss: 1.0411, G loss: 2.9918\n",
      "[1762/1762] D loss: 1.3870, G loss: 0.7155\n",
      "train error: \n",
      " D loss: 1.298161, G loss: 1.372719, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.252310, G loss: 1.586806, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6926\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6988\n",
      "[164/1762] D loss: 1.3866, G loss: 0.6989\n",
      "[244/1762] D loss: 1.3799, G loss: 0.7047\n",
      "[324/1762] D loss: 1.5693, G loss: 1.0176\n",
      "[404/1762] D loss: 1.1270, G loss: 0.9576\n",
      "[484/1762] D loss: 1.0995, G loss: 0.9216\n",
      "[564/1762] D loss: 1.3950, G loss: 0.6329\n",
      "[644/1762] D loss: 1.3932, G loss: 0.6413\n",
      "[724/1762] D loss: 1.3900, G loss: 0.6583\n",
      "[804/1762] D loss: 1.0432, G loss: 1.7399\n",
      "[884/1762] D loss: 1.3878, G loss: 0.6905\n",
      "[964/1762] D loss: 1.3914, G loss: 0.7425\n",
      "[1044/1762] D loss: 1.1074, G loss: 0.9426\n",
      "[1124/1762] D loss: 1.3869, G loss: 0.6870\n",
      "[1204/1762] D loss: 1.3881, G loss: 0.7205\n",
      "[1284/1762] D loss: 1.3884, G loss: 0.6786\n",
      "[1364/1762] D loss: 1.1037, G loss: 1.0456\n",
      "[1444/1762] D loss: 1.3874, G loss: 0.7163\n",
      "[1524/1762] D loss: 1.7280, G loss: 1.0083\n",
      "[1604/1762] D loss: 1.3845, G loss: 0.6799\n",
      "[1684/1762] D loss: 1.3867, G loss: 0.6992\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.6763\n",
      "train error: \n",
      " D loss: 1.300825, G loss: 0.810111, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 91.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.283018, G loss: 0.847941, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3875, G loss: 0.6978\n",
      "[84/1762] D loss: 1.3866, G loss: 0.6861\n",
      "[164/1762] D loss: 1.3868, G loss: 0.6959\n",
      "[244/1762] D loss: 1.0649, G loss: 1.1169\n",
      "[324/1762] D loss: 1.3867, G loss: 0.6815\n",
      "[404/1762] D loss: 1.3875, G loss: 0.6703\n",
      "[484/1762] D loss: 1.1079, G loss: 0.9093\n",
      "[564/1762] D loss: 1.0880, G loss: 0.9271\n",
      "[644/1762] D loss: 1.3864, G loss: 0.6949\n",
      "[724/1762] D loss: 1.3866, G loss: 0.6964\n",
      "[804/1762] D loss: 1.3867, G loss: 0.6792\n",
      "[884/1762] D loss: 1.3868, G loss: 0.7135\n",
      "[964/1762] D loss: 1.3866, G loss: 0.6977\n",
      "[1044/1762] D loss: 1.3875, G loss: 0.6713\n",
      "[1124/1762] D loss: 1.3868, G loss: 0.6805\n",
      "[1204/1762] D loss: 1.3878, G loss: 0.6624\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6863\n",
      "[1364/1762] D loss: 1.3868, G loss: 0.7055\n",
      "[1444/1762] D loss: 1.0495, G loss: 1.3386\n",
      "[1524/1762] D loss: 1.3819, G loss: 0.6847\n",
      "[1604/1762] D loss: 1.3866, G loss: 0.6837\n",
      "[1684/1762] D loss: 1.0572, G loss: 1.1758\n",
      "[1762/1762] D loss: 1.3890, G loss: 0.7199\n",
      "train error: \n",
      " D loss: 1.302664, G loss: 0.860325, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.289577, G loss: 0.902196, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3866, G loss: 0.6998\n",
      "[84/1762] D loss: 1.3899, G loss: 0.6324\n",
      "[164/1762] D loss: 1.3875, G loss: 0.7209\n",
      "[244/1762] D loss: 1.0594, G loss: 1.1687\n",
      "[324/1762] D loss: 1.0567, G loss: 1.1987\n",
      "[404/1762] D loss: 1.3873, G loss: 0.7036\n",
      "[484/1762] D loss: 1.3865, G loss: 0.6863\n",
      "[564/1762] D loss: 1.3868, G loss: 0.6944\n",
      "[644/1762] D loss: 1.3864, G loss: 0.7002\n",
      "[724/1762] D loss: 1.3879, G loss: 0.6925\n",
      "[804/1762] D loss: 1.3863, G loss: 0.7013\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6917\n",
      "[964/1762] D loss: 1.3865, G loss: 0.7027\n",
      "[1044/1762] D loss: 1.3877, G loss: 0.6761\n",
      "[1124/1762] D loss: 1.3901, G loss: 0.6414\n",
      "[1204/1762] D loss: 1.3886, G loss: 0.6908\n",
      "[1284/1762] D loss: 1.3981, G loss: 0.7504\n",
      "[1364/1762] D loss: 1.3812, G loss: 0.7262\n",
      "[1444/1762] D loss: 1.6223, G loss: 1.2354\n",
      "[1524/1762] D loss: 1.0549, G loss: 1.2080\n",
      "[1604/1762] D loss: 1.3491, G loss: 0.7834\n",
      "[1684/1762] D loss: 1.3879, G loss: 0.6794\n",
      "[1762/1762] D loss: 0.7482, G loss: 1.4696\n",
      "train error: \n",
      " D loss: 1.300837, G loss: 0.781627, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.280739, G loss: 0.815481, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3872, G loss: 0.6695\n",
      "[84/1762] D loss: 1.3866, G loss: 0.7041\n",
      "[164/1762] D loss: 1.3870, G loss: 0.6788\n",
      "[244/1762] D loss: 1.3865, G loss: 0.6808\n",
      "[324/1762] D loss: 1.3873, G loss: 0.6668\n",
      "[404/1762] D loss: 1.3867, G loss: 0.7019\n",
      "[484/1762] D loss: 1.0681, G loss: 1.1041\n",
      "[564/1762] D loss: 1.3865, G loss: 0.7060\n",
      "[644/1762] D loss: 1.3875, G loss: 0.6872\n",
      "[724/1762] D loss: 1.4931, G loss: 0.9446\n",
      "[804/1762] D loss: 1.3835, G loss: 0.7200\n",
      "[884/1762] D loss: 1.3873, G loss: 0.7093\n",
      "[964/1762] D loss: 1.3863, G loss: 0.7004\n",
      "[1044/1762] D loss: 1.3873, G loss: 0.6769\n",
      "[1124/1762] D loss: 1.0655, G loss: 1.1940\n",
      "[1204/1762] D loss: 1.3869, G loss: 0.6843\n",
      "[1284/1762] D loss: 1.3871, G loss: 0.6909\n",
      "[1364/1762] D loss: 1.3868, G loss: 0.7156\n",
      "[1444/1762] D loss: 1.3853, G loss: 0.6843\n",
      "[1524/1762] D loss: 1.3866, G loss: 0.6779\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6906\n",
      "[1684/1762] D loss: 1.3868, G loss: 0.6945\n",
      "[1762/1762] D loss: 0.6980, G loss: 2.6707\n",
      "train error: \n",
      " D loss: 1.304499, G loss: 0.811408, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.290432, G loss: 0.842046, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3865, G loss: 0.6819\n",
      "[84/1762] D loss: 1.3840, G loss: 0.7013\n",
      "[164/1762] D loss: 1.3883, G loss: 0.6977\n",
      "[244/1762] D loss: 1.3872, G loss: 0.6764\n",
      "[324/1762] D loss: 1.3865, G loss: 0.6874\n",
      "[404/1762] D loss: 1.0724, G loss: 1.0821\n",
      "[484/1762] D loss: 1.3864, G loss: 0.6890\n",
      "[564/1762] D loss: 1.3835, G loss: 0.7210\n",
      "[644/1762] D loss: 1.3864, G loss: 0.6959\n",
      "[724/1762] D loss: 1.3865, G loss: 0.6860\n",
      "[804/1762] D loss: 1.0578, G loss: 1.1865\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6790\n",
      "[964/1762] D loss: 1.3866, G loss: 0.7051\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.7015\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.6922\n",
      "[1204/1762] D loss: 0.7220, G loss: 1.7968\n",
      "[1284/1762] D loss: 1.3867, G loss: 0.6776\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6874\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.6818\n",
      "[1524/1762] D loss: 1.3871, G loss: 0.6696\n",
      "[1604/1762] D loss: 1.0551, G loss: 1.2075\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6915\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.7162\n",
      "train error: \n",
      " D loss: 1.303465, G loss: 0.823249, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 93.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.288844, G loss: 0.860835, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3877, G loss: 0.6694\n",
      "[84/1762] D loss: 1.3865, G loss: 0.7007\n",
      "[164/1762] D loss: 1.3862, G loss: 0.6957\n",
      "[244/1762] D loss: 1.3862, G loss: 0.6988\n",
      "[324/1762] D loss: 1.7102, G loss: 1.1625\n",
      "[404/1762] D loss: 1.3865, G loss: 0.6883\n",
      "[484/1762] D loss: 1.3864, G loss: 0.6850\n",
      "[564/1762] D loss: 1.0599, G loss: 1.1779\n",
      "[644/1762] D loss: 1.3864, G loss: 0.6827\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6960\n",
      "[804/1762] D loss: 1.3863, G loss: 0.6908\n",
      "[884/1762] D loss: 1.3867, G loss: 0.6949\n",
      "[964/1762] D loss: 1.0700, G loss: 1.0673\n",
      "[1044/1762] D loss: 0.4144, G loss: 2.0212\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.6903\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6988\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6813\n",
      "[1364/1762] D loss: 1.3865, G loss: 0.6947\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6927\n",
      "[1524/1762] D loss: 1.0654, G loss: 1.1181\n",
      "[1604/1762] D loss: 1.3857, G loss: 0.6818\n",
      "[1684/1762] D loss: 1.0482, G loss: 1.4013\n",
      "[1762/1762] D loss: 1.3859, G loss: 0.6830\n",
      "train error: \n",
      " D loss: 1.302482, G loss: 0.856687, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.290171, G loss: 0.898245, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3862, G loss: 0.6948\n",
      "[84/1762] D loss: 1.3865, G loss: 0.6877\n",
      "[164/1762] D loss: 1.3749, G loss: 0.6974\n",
      "[244/1762] D loss: 1.3716, G loss: 0.7028\n",
      "[324/1762] D loss: 1.3863, G loss: 0.7004\n",
      "[404/1762] D loss: 1.3871, G loss: 0.6744\n",
      "[484/1762] D loss: 1.3871, G loss: 0.6896\n",
      "[564/1762] D loss: 1.3882, G loss: 0.6591\n",
      "[644/1762] D loss: 1.3873, G loss: 0.6668\n",
      "[724/1762] D loss: 1.3868, G loss: 0.6920\n",
      "[804/1762] D loss: 1.3857, G loss: 0.6788\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6866\n",
      "[964/1762] D loss: 1.3864, G loss: 0.6853\n",
      "[1044/1762] D loss: 1.3879, G loss: 0.6621\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.6757\n",
      "[1204/1762] D loss: 1.0414, G loss: 1.9041\n",
      "[1284/1762] D loss: 1.3862, G loss: 0.7021\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6856\n",
      "[1444/1762] D loss: 1.3862, G loss: 0.6968\n",
      "[1524/1762] D loss: 1.0339, G loss: 2.0719\n",
      "[1604/1762] D loss: 1.0393, G loss: 2.2906\n",
      "[1684/1762] D loss: 1.3808, G loss: 0.6873\n",
      "[1762/1762] D loss: 0.7024, G loss: 3.1241\n",
      "train error: \n",
      " D loss: 1.309853, G loss: 0.958642, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.289814, G loss: 1.045296, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3995, G loss: 0.6132\n",
      "[84/1762] D loss: 1.3871, G loss: 0.7360\n",
      "[164/1762] D loss: 1.3885, G loss: 0.6497\n",
      "[244/1762] D loss: 1.0428, G loss: 2.0198\n",
      "[324/1762] D loss: 1.3873, G loss: 0.6696\n",
      "[404/1762] D loss: 1.0411, G loss: 1.8645\n",
      "[484/1762] D loss: 1.3871, G loss: 0.6692\n",
      "[564/1762] D loss: 1.2830, G loss: 0.9389\n",
      "[644/1762] D loss: 1.3837, G loss: 0.6726\n",
      "[724/1762] D loss: 1.3882, G loss: 0.6536\n",
      "[804/1762] D loss: 1.3898, G loss: 0.6461\n",
      "[884/1762] D loss: 1.3865, G loss: 0.7036\n",
      "[964/1762] D loss: 1.3872, G loss: 0.6781\n",
      "[1044/1762] D loss: 1.0402, G loss: 2.1467\n",
      "[1124/1762] D loss: 1.3868, G loss: 0.6825\n",
      "[1204/1762] D loss: 1.2803, G loss: 0.9123\n",
      "[1284/1762] D loss: 1.3782, G loss: 0.6582\n",
      "[1364/1762] D loss: 1.0420, G loss: 2.1366\n",
      "[1444/1762] D loss: 1.0405, G loss: 2.2168\n",
      "[1524/1762] D loss: 1.3884, G loss: 0.6573\n",
      "[1604/1762] D loss: 1.0420, G loss: 2.1624\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.6929\n",
      "[1762/1762] D loss: 1.3868, G loss: 0.6719\n",
      "train error: \n",
      " D loss: 1.286949, G loss: 1.134892, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.260440, G loss: 1.276018, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3882, G loss: 0.6608\n",
      "[84/1762] D loss: 1.3879, G loss: 0.7270\n",
      "[164/1762] D loss: 1.0401, G loss: 2.2342\n",
      "[244/1762] D loss: 1.3869, G loss: 0.6930\n",
      "[324/1762] D loss: 1.3863, G loss: 0.7037\n",
      "[404/1762] D loss: 1.3867, G loss: 0.6932\n",
      "[484/1762] D loss: 1.3867, G loss: 0.6855\n",
      "[564/1762] D loss: 1.3866, G loss: 0.7044\n",
      "[644/1762] D loss: 1.3865, G loss: 0.7059\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6930\n",
      "[804/1762] D loss: 1.3863, G loss: 0.6966\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6992\n",
      "[964/1762] D loss: 1.3864, G loss: 0.7017\n",
      "[1044/1762] D loss: 1.3869, G loss: 0.6872\n",
      "[1124/1762] D loss: 1.0399, G loss: 2.4100\n",
      "[1204/1762] D loss: 1.3869, G loss: 0.6856\n",
      "[1284/1762] D loss: 1.0410, G loss: 2.4266\n",
      "[1364/1762] D loss: 1.3869, G loss: 0.7148\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.6809\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.6953\n",
      "[1604/1762] D loss: 1.3870, G loss: 0.6860\n",
      "[1684/1762] D loss: 1.3865, G loss: 0.6982\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6907\n",
      "train error: \n",
      " D loss: 1.285060, G loss: 1.230151, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.257807, G loss: 1.388718, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3872, G loss: 0.6958\n",
      "[84/1762] D loss: 1.3870, G loss: 0.6771\n",
      "[164/1762] D loss: 1.3857, G loss: 0.6831\n",
      "[244/1762] D loss: 1.3865, G loss: 0.6879\n",
      "[324/1762] D loss: 1.3870, G loss: 0.6714\n",
      "[404/1762] D loss: 1.0402, G loss: 2.7236\n",
      "[484/1762] D loss: 1.0397, G loss: 2.7416\n",
      "[564/1762] D loss: 1.3868, G loss: 0.6962\n",
      "[644/1762] D loss: 1.3866, G loss: 0.6877\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6947\n",
      "[804/1762] D loss: 1.3867, G loss: 0.6804\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6961\n",
      "[964/1762] D loss: 1.0400, G loss: 2.7589\n",
      "[1044/1762] D loss: 1.3868, G loss: 0.6797\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6914\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6920\n",
      "[1284/1762] D loss: 1.2948, G loss: 0.9099\n",
      "[1364/1762] D loss: 1.0401, G loss: 2.8609\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.6795\n",
      "[1524/1762] D loss: 0.6932, G loss: 5.1142\n",
      "[1604/1762] D loss: 0.6932, G loss: 5.1468\n",
      "[1684/1762] D loss: 1.1240, G loss: 2.9123\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.6812\n",
      "train error: \n",
      " D loss: 1.282201, G loss: 1.376520, D accuracy: 54.0%, cell accuracy: 99.9%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.254173, G loss: 1.563400, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3874, G loss: 0.6924\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6833\n",
      "[164/1762] D loss: 1.0312, G loss: 2.7955\n",
      "[244/1762] D loss: 1.3865, G loss: 0.7037\n",
      "[324/1762] D loss: 1.2773, G loss: 0.9529\n",
      "[404/1762] D loss: 1.3887, G loss: 0.7176\n",
      "[484/1762] D loss: 1.3863, G loss: 0.6916\n",
      "[564/1762] D loss: 1.3848, G loss: 0.7240\n",
      "[644/1762] D loss: 1.0400, G loss: 3.9573\n",
      "[724/1762] D loss: 1.3750, G loss: 0.7624\n",
      "[804/1762] D loss: 1.9011, G loss: 0.6025\n",
      "[884/1762] D loss: 1.4535, G loss: 0.8337\n",
      "[964/1762] D loss: 1.0596, G loss: 1.2593\n",
      "[1044/1762] D loss: 1.1241, G loss: 0.8642\n",
      "[1124/1762] D loss: 1.3924, G loss: 0.7182\n",
      "[1204/1762] D loss: 1.3871, G loss: 0.6878\n",
      "[1284/1762] D loss: 1.3868, G loss: 0.7138\n",
      "[1364/1762] D loss: 1.3859, G loss: 0.6943\n",
      "[1444/1762] D loss: 1.0660, G loss: 1.1042\n",
      "[1524/1762] D loss: 1.3868, G loss: 0.6986\n",
      "[1604/1762] D loss: 1.3872, G loss: 0.6653\n",
      "[1684/1762] D loss: 1.3866, G loss: 0.6813\n",
      "[1762/1762] D loss: 1.3866, G loss: 0.7117\n",
      "train error: \n",
      " D loss: 1.307448, G loss: 0.826003, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.291587, G loss: 0.857365, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 91.1% \n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3868, G loss: 0.7039\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6906\n",
      "[164/1762] D loss: 1.3873, G loss: 0.6654\n",
      "[244/1762] D loss: 1.3874, G loss: 0.6728\n",
      "[324/1762] D loss: 1.3867, G loss: 0.6792\n",
      "[404/1762] D loss: 1.0689, G loss: 1.1081\n",
      "[484/1762] D loss: 1.3866, G loss: 0.6994\n",
      "[564/1762] D loss: 1.3875, G loss: 0.6549\n",
      "[644/1762] D loss: 1.3872, G loss: 0.7019\n",
      "[724/1762] D loss: 1.3873, G loss: 0.6735\n",
      "[804/1762] D loss: 1.3862, G loss: 0.7150\n",
      "[884/1762] D loss: 1.3861, G loss: 0.6932\n",
      "[964/1762] D loss: 1.3862, G loss: 0.6821\n",
      "[1044/1762] D loss: 1.0625, G loss: 1.1227\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.7041\n",
      "[1204/1762] D loss: 1.0596, G loss: 1.1623\n",
      "[1284/1762] D loss: 1.0588, G loss: 1.1548\n",
      "[1364/1762] D loss: 1.3862, G loss: 0.7015\n",
      "[1444/1762] D loss: 1.0576, G loss: 1.1974\n",
      "[1524/1762] D loss: 1.0538, G loss: 1.2460\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6923\n",
      "[1684/1762] D loss: 1.3777, G loss: 0.6817\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.7112\n",
      "train error: \n",
      " D loss: 1.304499, G loss: 0.866585, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.292656, G loss: 0.884747, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 91.1% \n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3866, G loss: 0.6966\n",
      "[84/1762] D loss: 1.3855, G loss: 0.6869\n",
      "[164/1762] D loss: 1.3864, G loss: 0.6958\n",
      "[244/1762] D loss: 1.0499, G loss: 1.3519\n",
      "[324/1762] D loss: 1.3890, G loss: 0.6594\n",
      "[404/1762] D loss: 1.3862, G loss: 0.6897\n",
      "[484/1762] D loss: 1.0648, G loss: 1.1266\n",
      "[564/1762] D loss: 1.6150, G loss: 1.6116\n",
      "[644/1762] D loss: 1.0736, G loss: 1.0769\n",
      "[724/1762] D loss: 1.0565, G loss: 1.2245\n",
      "[804/1762] D loss: 1.0474, G loss: 1.4035\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6841\n",
      "[964/1762] D loss: 1.3866, G loss: 0.7009\n",
      "[1044/1762] D loss: 1.3867, G loss: 0.7017\n",
      "[1124/1762] D loss: 1.3878, G loss: 0.7355\n",
      "[1204/1762] D loss: 1.3911, G loss: 0.6325\n",
      "[1284/1762] D loss: 1.0645, G loss: 1.0801\n",
      "[1364/1762] D loss: 0.7507, G loss: 1.4699\n",
      "[1444/1762] D loss: 1.3869, G loss: 0.7011\n",
      "[1524/1762] D loss: 1.3867, G loss: 0.6782\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6846\n",
      "[1684/1762] D loss: 1.0757, G loss: 1.0388\n",
      "[1762/1762] D loss: 1.3871, G loss: 0.6665\n",
      "train error: \n",
      " D loss: 1.304995, G loss: 0.841776, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 93.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.292558, G loss: 0.884398, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3868, G loss: 0.7056\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6883\n",
      "[164/1762] D loss: 1.3868, G loss: 0.6888\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6903\n",
      "[324/1762] D loss: 1.3865, G loss: 0.7066\n",
      "[404/1762] D loss: 1.3863, G loss: 0.6922\n",
      "[484/1762] D loss: 1.0655, G loss: 1.1234\n",
      "[564/1762] D loss: 1.3879, G loss: 0.6766\n",
      "[644/1762] D loss: 1.3867, G loss: 0.6953\n",
      "[724/1762] D loss: 1.3865, G loss: 0.6910\n",
      "[804/1762] D loss: 1.0573, G loss: 1.1959\n",
      "[884/1762] D loss: 1.0630, G loss: 1.1328\n",
      "[964/1762] D loss: 1.0577, G loss: 1.1826\n",
      "[1044/1762] D loss: 1.3865, G loss: 0.6945\n",
      "[1124/1762] D loss: 1.3869, G loss: 0.6680\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.7032\n",
      "[1284/1762] D loss: 1.3866, G loss: 0.6857\n",
      "[1364/1762] D loss: 1.3869, G loss: 0.6791\n",
      "[1444/1762] D loss: 1.3853, G loss: 0.6907\n",
      "[1524/1762] D loss: 1.5980, G loss: 1.0120\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.7026\n",
      "[1684/1762] D loss: 1.3857, G loss: 0.6854\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6998\n",
      "train error: \n",
      " D loss: 1.301322, G loss: 0.851317, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.288984, G loss: 0.871628, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 91.1% \n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0619, G loss: 1.1406\n",
      "[84/1762] D loss: 1.3842, G loss: 0.6993\n",
      "[164/1762] D loss: 1.7397, G loss: 1.1268\n",
      "[244/1762] D loss: 1.3867, G loss: 0.7109\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6922\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6912\n",
      "[484/1762] D loss: 1.0683, G loss: 1.0845\n",
      "[564/1762] D loss: 1.3862, G loss: 0.6939\n",
      "[644/1762] D loss: 1.3864, G loss: 0.6920\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6819\n",
      "[804/1762] D loss: 1.3742, G loss: 0.7091\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6853\n",
      "[964/1762] D loss: 1.0639, G loss: 1.1155\n",
      "[1044/1762] D loss: 1.0561, G loss: 1.2070\n",
      "[1124/1762] D loss: 1.3850, G loss: 0.7003\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6942\n",
      "[1284/1762] D loss: 1.0619, G loss: 1.1407\n",
      "[1364/1762] D loss: 0.7297, G loss: 1.6820\n",
      "[1444/1762] D loss: 1.0546, G loss: 1.2399\n",
      "[1524/1762] D loss: 1.3865, G loss: 0.6734\n",
      "[1604/1762] D loss: 1.3869, G loss: 0.6870\n",
      "[1684/1762] D loss: 1.3865, G loss: 0.6798\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.6941\n",
      "train error: \n",
      " D loss: 1.302299, G loss: 0.873815, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.289705, G loss: 0.937434, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3866, G loss: 0.7073\n",
      "[84/1762] D loss: 1.3862, G loss: 0.6872\n",
      "[164/1762] D loss: 1.0457, G loss: 1.4860\n",
      "[244/1762] D loss: 1.3864, G loss: 0.6837\n",
      "[324/1762] D loss: 1.3859, G loss: 0.6976\n",
      "[404/1762] D loss: 2.1112, G loss: 1.5794\n",
      "[484/1762] D loss: 1.3864, G loss: 0.6992\n",
      "[564/1762] D loss: 1.3865, G loss: 0.6765\n",
      "[644/1762] D loss: 1.3866, G loss: 0.6997\n",
      "[724/1762] D loss: 1.3874, G loss: 0.7038\n",
      "[804/1762] D loss: 1.3865, G loss: 0.7056\n",
      "[884/1762] D loss: 1.3850, G loss: 0.7084\n",
      "[964/1762] D loss: 1.3857, G loss: 0.7022\n",
      "[1044/1762] D loss: 1.0703, G loss: 1.0700\n",
      "[1124/1762] D loss: 1.3862, G loss: 0.6999\n",
      "[1204/1762] D loss: 1.3865, G loss: 0.7069\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6916\n",
      "[1364/1762] D loss: 1.3857, G loss: 0.6928\n",
      "[1444/1762] D loss: 1.3902, G loss: 0.7261\n",
      "[1524/1762] D loss: 1.3843, G loss: 0.7039\n",
      "[1604/1762] D loss: 1.0627, G loss: 1.1313\n",
      "[1684/1762] D loss: 1.3871, G loss: 0.6897\n",
      "[1762/1762] D loss: 1.3941, G loss: 0.6647\n",
      "train error: \n",
      " D loss: 1.305171, G loss: 0.845059, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.292969, G loss: 0.904953, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0542, G loss: 1.2397\n",
      "[84/1762] D loss: 1.3882, G loss: 0.7001\n",
      "[164/1762] D loss: 1.0515, G loss: 1.3805\n",
      "[244/1762] D loss: 1.3869, G loss: 0.6938\n",
      "[324/1762] D loss: 1.4059, G loss: 0.6835\n",
      "[404/1762] D loss: 1.3852, G loss: 0.6936\n",
      "[484/1762] D loss: 1.3748, G loss: 0.6908\n",
      "[564/1762] D loss: 1.8498, G loss: 1.3122\n",
      "[644/1762] D loss: 1.3904, G loss: 0.6496\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6984\n",
      "[804/1762] D loss: 1.0696, G loss: 1.0883\n",
      "[884/1762] D loss: 1.3860, G loss: 0.6840\n",
      "[964/1762] D loss: 1.3853, G loss: 0.6751\n",
      "[1044/1762] D loss: 1.3854, G loss: 0.6853\n",
      "[1124/1762] D loss: 1.0682, G loss: 1.0892\n",
      "[1204/1762] D loss: 1.3399, G loss: 0.6963\n",
      "[1284/1762] D loss: 1.3935, G loss: 0.6262\n",
      "[1364/1762] D loss: 1.3870, G loss: 0.6942\n",
      "[1444/1762] D loss: 1.3819, G loss: 0.6730\n",
      "[1524/1762] D loss: 1.3877, G loss: 0.6839\n",
      "[1604/1762] D loss: 1.3865, G loss: 0.7006\n",
      "[1684/1762] D loss: 1.3875, G loss: 0.6685\n",
      "[1762/1762] D loss: 0.7391, G loss: 1.5674\n",
      "train error: \n",
      " D loss: 1.303303, G loss: 0.828131, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.289400, G loss: 0.864203, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3868, G loss: 0.6872\n",
      "[84/1762] D loss: 1.0630, G loss: 1.1538\n",
      "[164/1762] D loss: 1.3878, G loss: 0.6766\n",
      "[244/1762] D loss: 1.3866, G loss: 0.6867\n",
      "[324/1762] D loss: 1.3887, G loss: 0.6543\n",
      "[404/1762] D loss: 1.3867, G loss: 0.6966\n",
      "[484/1762] D loss: 1.2055, G loss: 2.8138\n",
      "[564/1762] D loss: 1.3865, G loss: 0.6903\n",
      "[644/1762] D loss: 1.3865, G loss: 0.6923\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6865\n",
      "[804/1762] D loss: 1.0800, G loss: 0.9858\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6929\n",
      "[964/1762] D loss: 1.3858, G loss: 0.7003\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.6887\n",
      "[1124/1762] D loss: 1.0577, G loss: 1.2015\n",
      "[1204/1762] D loss: 1.0554, G loss: 1.2235\n",
      "[1284/1762] D loss: 1.3869, G loss: 0.7054\n",
      "[1364/1762] D loss: 1.0580, G loss: 1.1861\n",
      "[1444/1762] D loss: 1.3866, G loss: 0.6892\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.6878\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6911\n",
      "[1684/1762] D loss: 1.0633, G loss: 1.1212\n",
      "[1762/1762] D loss: 0.7369, G loss: 1.5913\n",
      "train error: \n",
      " D loss: 1.302414, G loss: 0.822583, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.288089, G loss: 0.860942, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6949\n",
      "[84/1762] D loss: 1.3861, G loss: 0.6856\n",
      "[164/1762] D loss: 1.0603, G loss: 1.1517\n",
      "[244/1762] D loss: 1.3866, G loss: 0.7016\n",
      "[324/1762] D loss: 1.3857, G loss: 0.6987\n",
      "[404/1762] D loss: 1.3867, G loss: 0.6867\n",
      "[484/1762] D loss: 1.3900, G loss: 0.6934\n",
      "[564/1762] D loss: 1.0785, G loss: 1.0480\n",
      "[644/1762] D loss: 1.3872, G loss: 0.7089\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6871\n",
      "[804/1762] D loss: 1.3869, G loss: 0.7046\n",
      "[884/1762] D loss: 1.3864, G loss: 0.7039\n",
      "[964/1762] D loss: 1.0653, G loss: 1.1180\n",
      "[1044/1762] D loss: 1.3872, G loss: 0.6798\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.7006\n",
      "[1204/1762] D loss: 1.0586, G loss: 1.1754\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6909\n",
      "[1364/1762] D loss: 0.3985, G loss: 2.0273\n",
      "[1444/1762] D loss: 1.0614, G loss: 1.1281\n",
      "[1524/1762] D loss: 0.7203, G loss: 1.9267\n",
      "[1604/1762] D loss: 1.3876, G loss: 0.7156\n",
      "[1684/1762] D loss: 1.3873, G loss: 0.6984\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6997\n",
      "train error: \n",
      " D loss: 1.303017, G loss: 0.841308, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 93.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.289472, G loss: 0.887073, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0551, G loss: 1.2407\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6987\n",
      "[164/1762] D loss: 1.3865, G loss: 0.6771\n",
      "[244/1762] D loss: 1.3866, G loss: 0.6926\n",
      "[324/1762] D loss: 1.3864, G loss: 0.7046\n",
      "[404/1762] D loss: 1.3864, G loss: 0.7040\n",
      "[484/1762] D loss: 0.7361, G loss: 1.6116\n",
      "[564/1762] D loss: 1.0564, G loss: 1.2004\n",
      "[644/1762] D loss: 1.3867, G loss: 0.7117\n",
      "[724/1762] D loss: 1.0589, G loss: 1.1701\n",
      "[804/1762] D loss: 1.3862, G loss: 0.7008\n",
      "[884/1762] D loss: 1.3858, G loss: 0.6982\n",
      "[964/1762] D loss: 1.3864, G loss: 0.6854\n",
      "[1044/1762] D loss: 1.3862, G loss: 0.7041\n",
      "[1124/1762] D loss: 1.3866, G loss: 0.6911\n",
      "[1204/1762] D loss: 1.3865, G loss: 0.7081\n",
      "[1284/1762] D loss: 1.0718, G loss: 1.0531\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.7037\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.6897\n",
      "[1524/1762] D loss: 1.3873, G loss: 0.6655\n",
      "[1604/1762] D loss: 1.3867, G loss: 0.6848\n",
      "[1684/1762] D loss: 1.0537, G loss: 1.2608\n",
      "[1762/1762] D loss: 0.7167, G loss: 1.8877\n",
      "train error: \n",
      " D loss: 1.303964, G loss: 0.865643, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 93.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.291464, G loss: 0.919094, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3855, G loss: 0.6913\n",
      "[84/1762] D loss: 1.0499, G loss: 1.3289\n",
      "[164/1762] D loss: 1.0537, G loss: 1.2266\n",
      "[244/1762] D loss: 1.3863, G loss: 0.7175\n",
      "[324/1762] D loss: 1.3867, G loss: 0.7017\n",
      "[404/1762] D loss: 1.3869, G loss: 0.7192\n",
      "[484/1762] D loss: 1.3865, G loss: 0.6799\n",
      "[564/1762] D loss: 1.3864, G loss: 0.7002\n",
      "[644/1762] D loss: 1.3867, G loss: 0.7002\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6987\n",
      "[804/1762] D loss: 1.3865, G loss: 0.6948\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6944\n",
      "[964/1762] D loss: 1.3865, G loss: 0.6877\n",
      "[1044/1762] D loss: 1.3865, G loss: 0.6961\n",
      "[1124/1762] D loss: 1.3868, G loss: 0.6710\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6986\n",
      "[1284/1762] D loss: 1.0641, G loss: 1.1181\n",
      "[1364/1762] D loss: 1.3869, G loss: 0.6731\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6944\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.6952\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6897\n",
      "[1684/1762] D loss: 0.7147, G loss: 1.9433\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6889\n",
      "train error: \n",
      " D loss: 1.304668, G loss: 0.892281, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.293708, G loss: 0.949559, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.7001\n",
      "[84/1762] D loss: 1.3867, G loss: 0.7089\n",
      "[164/1762] D loss: 1.3865, G loss: 0.6879\n",
      "[244/1762] D loss: 1.3870, G loss: 0.6725\n",
      "[324/1762] D loss: 1.3869, G loss: 0.6845\n",
      "[404/1762] D loss: 1.3870, G loss: 0.6831\n",
      "[484/1762] D loss: 1.3866, G loss: 0.6766\n",
      "[564/1762] D loss: 1.0598, G loss: 1.1134\n",
      "[644/1762] D loss: 1.3869, G loss: 0.7120\n",
      "[724/1762] D loss: 1.3865, G loss: 0.6916\n",
      "[804/1762] D loss: 1.0688, G loss: 1.0467\n",
      "[884/1762] D loss: 1.3839, G loss: 0.7034\n",
      "[964/1762] D loss: 1.3973, G loss: 0.7258\n",
      "[1044/1762] D loss: 1.3909, G loss: 0.7110\n",
      "[1124/1762] D loss: 1.3877, G loss: 0.6964\n",
      "[1204/1762] D loss: 1.3871, G loss: 0.6662\n",
      "[1284/1762] D loss: 1.0694, G loss: 1.0899\n",
      "[1364/1762] D loss: 1.3865, G loss: 0.6916\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6942\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.6934\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6909\n",
      "[1684/1762] D loss: 1.0637, G loss: 1.1093\n",
      "[1762/1762] D loss: 1.3866, G loss: 0.7088\n",
      "train error: \n",
      " D loss: 1.292286, G loss: 0.859733, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.276140, G loss: 0.897351, D accuracy: 56.1%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0631, G loss: 1.1215\n",
      "[84/1762] D loss: 1.0612, G loss: 1.1426\n",
      "[164/1762] D loss: 1.3865, G loss: 0.6994\n",
      "[244/1762] D loss: 1.3862, G loss: 0.6894\n",
      "[324/1762] D loss: 1.3866, G loss: 0.7099\n",
      "[404/1762] D loss: 1.3880, G loss: 0.6537\n",
      "[484/1762] D loss: 1.3860, G loss: 0.6885\n",
      "[564/1762] D loss: 1.3866, G loss: 0.6823\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6926\n",
      "[724/1762] D loss: 1.6000, G loss: 1.1805\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6877\n",
      "[884/1762] D loss: 1.0529, G loss: 1.3052\n",
      "[964/1762] D loss: 1.0459, G loss: 1.8579\n",
      "[1044/1762] D loss: 1.3854, G loss: 0.7049\n",
      "[1124/1762] D loss: 1.3872, G loss: 0.7079\n",
      "[1204/1762] D loss: 1.0592, G loss: 1.1765\n",
      "[1284/1762] D loss: 1.3861, G loss: 0.6904\n",
      "[1364/1762] D loss: 1.0532, G loss: 1.2602\n",
      "[1444/1762] D loss: 1.3866, G loss: 0.6915\n",
      "[1524/1762] D loss: 1.0627, G loss: 1.1367\n",
      "[1604/1762] D loss: 1.0614, G loss: 1.1557\n",
      "[1684/1762] D loss: 1.3867, G loss: 0.6878\n",
      "[1762/1762] D loss: 1.3868, G loss: 0.7077\n",
      "train error: \n",
      " D loss: 1.303511, G loss: 0.871093, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.293345, G loss: 0.931156, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0495, G loss: 1.3360\n",
      "[84/1762] D loss: 1.3869, G loss: 0.6865\n",
      "[164/1762] D loss: 0.7109, G loss: 2.0565\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6967\n",
      "[324/1762] D loss: 1.0672, G loss: 1.0963\n",
      "[404/1762] D loss: 1.3870, G loss: 0.7194\n",
      "[484/1762] D loss: 1.3867, G loss: 0.6868\n",
      "[564/1762] D loss: 1.3865, G loss: 0.6986\n",
      "[644/1762] D loss: 1.3879, G loss: 0.7229\n",
      "[724/1762] D loss: 1.3873, G loss: 0.7191\n",
      "[804/1762] D loss: 1.3870, G loss: 0.7092\n",
      "[884/1762] D loss: 1.3868, G loss: 0.6778\n",
      "[964/1762] D loss: 1.3864, G loss: 0.7003\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.7067\n",
      "[1124/1762] D loss: 1.0630, G loss: 1.1339\n",
      "[1204/1762] D loss: 1.3871, G loss: 0.7181\n",
      "[1284/1762] D loss: 1.3862, G loss: 0.6974\n",
      "[1364/1762] D loss: 0.7195, G loss: 1.8477\n",
      "[1444/1762] D loss: 1.3866, G loss: 0.6965\n",
      "[1524/1762] D loss: 1.3865, G loss: 0.6890\n",
      "[1604/1762] D loss: 1.3867, G loss: 0.6937\n",
      "[1684/1762] D loss: 1.0556, G loss: 1.2239\n",
      "[1762/1762] D loss: 1.3876, G loss: 0.6981\n",
      "train error: \n",
      " D loss: 1.303888, G loss: 0.825528, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 93.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.289234, G loss: 0.880359, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 91.1% \n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0570, G loss: 1.1926\n",
      "[84/1762] D loss: 1.3888, G loss: 0.6588\n",
      "[164/1762] D loss: 1.3866, G loss: 0.7065\n",
      "[244/1762] D loss: 1.0707, G loss: 1.0729\n",
      "[324/1762] D loss: 1.3864, G loss: 0.6923\n",
      "[404/1762] D loss: 1.4015, G loss: 0.7519\n",
      "[484/1762] D loss: 1.0511, G loss: 1.3168\n",
      "[564/1762] D loss: 1.0580, G loss: 1.1785\n",
      "[644/1762] D loss: 1.7674, G loss: 1.2185\n",
      "[724/1762] D loss: 1.3866, G loss: 0.7092\n",
      "[804/1762] D loss: 1.0750, G loss: 1.0190\n",
      "[884/1762] D loss: 1.0681, G loss: 1.1205\n",
      "[964/1762] D loss: 1.3866, G loss: 0.6822\n",
      "[1044/1762] D loss: 1.3866, G loss: 0.6940\n",
      "[1124/1762] D loss: 1.3867, G loss: 0.6976\n",
      "[1204/1762] D loss: 1.3868, G loss: 0.7022\n",
      "[1284/1762] D loss: 1.3865, G loss: 0.6865\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6971\n",
      "[1444/1762] D loss: 1.0480, G loss: 1.3874\n",
      "[1524/1762] D loss: 1.3867, G loss: 0.6774\n",
      "[1604/1762] D loss: 1.0497, G loss: 1.3537\n",
      "[1684/1762] D loss: 1.0481, G loss: 1.3961\n",
      "[1762/1762] D loss: 1.3872, G loss: 0.6652\n",
      "train error: \n",
      " D loss: 1.306465, G loss: 0.947014, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.300825, G loss: 1.022502, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3871, G loss: 0.6732\n",
      "[84/1762] D loss: 1.3866, G loss: 0.6776\n",
      "[164/1762] D loss: 1.3868, G loss: 0.6871\n",
      "[244/1762] D loss: 1.3867, G loss: 0.6750\n",
      "[324/1762] D loss: 1.3866, G loss: 0.7046\n",
      "[404/1762] D loss: 1.3863, G loss: 0.6918\n",
      "[484/1762] D loss: 1.3863, G loss: 0.6941\n",
      "[564/1762] D loss: 1.0072, G loss: 1.3683\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6891\n",
      "[724/1762] D loss: 1.0495, G loss: 1.3447\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6918\n",
      "[884/1762] D loss: 1.3844, G loss: 0.7019\n",
      "[964/1762] D loss: 1.3865, G loss: 0.7057\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.6884\n",
      "[1124/1762] D loss: 1.3862, G loss: 0.6897\n",
      "[1204/1762] D loss: 1.0644, G loss: 1.1053\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6869\n",
      "[1364/1762] D loss: 1.3931, G loss: 0.7121\n",
      "[1444/1762] D loss: 1.3866, G loss: 0.6964\n",
      "[1524/1762] D loss: 1.3865, G loss: 0.6898\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6994\n",
      "[1684/1762] D loss: 1.3866, G loss: 0.6787\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6949\n",
      "train error: \n",
      " D loss: 1.302487, G loss: 0.869186, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 93.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.290933, G loss: 0.912741, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7214, G loss: 1.8140\n",
      "[84/1762] D loss: 0.7121, G loss: 2.0179\n",
      "[164/1762] D loss: 1.3868, G loss: 0.6691\n",
      "[244/1762] D loss: 1.3888, G loss: 0.7185\n",
      "[324/1762] D loss: 1.3868, G loss: 0.6835\n",
      "[404/1762] D loss: 1.0443, G loss: 1.5057\n",
      "[484/1762] D loss: 1.3866, G loss: 0.6757\n",
      "[564/1762] D loss: 1.3873, G loss: 0.6864\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6930\n",
      "[724/1762] D loss: 1.2030, G loss: 0.7228\n",
      "[804/1762] D loss: 1.0770, G loss: 1.0227\n",
      "[884/1762] D loss: 1.3866, G loss: 0.6831\n",
      "[964/1762] D loss: 1.3863, G loss: 0.6939\n",
      "[1044/1762] D loss: 1.3865, G loss: 0.6850\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.6995\n",
      "[1204/1762] D loss: 1.0565, G loss: 1.2026\n",
      "[1284/1762] D loss: 1.0595, G loss: 1.1685\n",
      "[1364/1762] D loss: 1.0584, G loss: 1.1828\n",
      "[1444/1762] D loss: 1.3861, G loss: 0.6811\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.6916\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6907\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6869\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6884\n",
      "train error: \n",
      " D loss: 1.304145, G loss: 0.801014, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 93.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.289044, G loss: 0.833887, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6877\n",
      "[84/1762] D loss: 1.0688, G loss: 1.0752\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6901\n",
      "[244/1762] D loss: 1.3865, G loss: 0.6814\n",
      "[324/1762] D loss: 1.3862, G loss: 0.6948\n",
      "[404/1762] D loss: 1.3865, G loss: 0.7017\n",
      "[484/1762] D loss: 1.3865, G loss: 0.6958\n",
      "[564/1762] D loss: 1.3865, G loss: 0.6993\n",
      "[644/1762] D loss: 1.0589, G loss: 1.1823\n",
      "[724/1762] D loss: 1.3866, G loss: 0.6767\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6903\n",
      "[884/1762] D loss: 0.7652, G loss: 1.3573\n",
      "[964/1762] D loss: 0.7496, G loss: 1.4865\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6905\n",
      "[1124/1762] D loss: 1.3862, G loss: 0.6905\n",
      "[1204/1762] D loss: 1.3044, G loss: 1.4495\n",
      "[1284/1762] D loss: 1.3862, G loss: 0.7115\n",
      "[1364/1762] D loss: 1.0751, G loss: 1.0213\n",
      "[1444/1762] D loss: 1.3867, G loss: 0.6775\n",
      "[1524/1762] D loss: 1.3866, G loss: 0.6847\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6919\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.6992\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.6821\n",
      "train error: \n",
      " D loss: 1.311272, G loss: 0.996986, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 93.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.306900, G loss: 1.092687, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6870\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6941\n",
      "[164/1762] D loss: 1.3864, G loss: 0.6947\n",
      "[244/1762] D loss: 1.3862, G loss: 0.6889\n",
      "[324/1762] D loss: 1.3864, G loss: 0.6998\n",
      "[404/1762] D loss: 1.3863, G loss: 0.6912\n",
      "[484/1762] D loss: 1.0612, G loss: 1.1582\n",
      "[564/1762] D loss: 1.3485, G loss: 0.7469\n",
      "[644/1762] D loss: 1.3879, G loss: 0.6779\n",
      "[724/1762] D loss: 1.3865, G loss: 0.6837\n",
      "[804/1762] D loss: 1.0741, G loss: 1.0425\n",
      "[884/1762] D loss: 1.0610, G loss: 1.1379\n",
      "[964/1762] D loss: 1.0566, G loss: 1.2112\n",
      "[1044/1762] D loss: 1.3866, G loss: 0.6796\n",
      "[1124/1762] D loss: 1.0507, G loss: 1.3106\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6881\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6898\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6956\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6985\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.6978\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6997\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6966\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6891\n",
      "train error: \n",
      " D loss: 1.303241, G loss: 0.828490, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 93.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.289874, G loss: 0.868700, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6923\n",
      "[84/1762] D loss: 1.0652, G loss: 1.1036\n",
      "[164/1762] D loss: 1.3863, G loss: 0.7000\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6861\n",
      "[324/1762] D loss: 1.3864, G loss: 0.6892\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6856\n",
      "[484/1762] D loss: 1.0722, G loss: 1.0419\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6937\n",
      "[644/1762] D loss: 1.6349, G loss: 1.0824\n",
      "[724/1762] D loss: 1.3864, G loss: 0.7036\n",
      "[804/1762] D loss: 1.3865, G loss: 0.7049\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6969\n",
      "[964/1762] D loss: 1.3863, G loss: 0.6959\n",
      "[1044/1762] D loss: 1.3865, G loss: 0.6953\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6889\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.7011\n",
      "[1284/1762] D loss: 1.0415, G loss: 1.7702\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6922\n",
      "[1444/1762] D loss: 1.3862, G loss: 0.6900\n",
      "[1524/1762] D loss: 1.3860, G loss: 0.6878\n",
      "[1604/1762] D loss: 1.3862, G loss: 0.6831\n",
      "[1684/1762] D loss: 1.0437, G loss: 1.5749\n",
      "[1762/1762] D loss: 0.6968, G loss: 3.0826\n",
      "train error: \n",
      " D loss: 1.318036, G loss: 1.094745, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.317788, G loss: 1.204229, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 91.1% \n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3869, G loss: 0.6763\n",
      "[84/1762] D loss: 1.3869, G loss: 0.6845\n",
      "[164/1762] D loss: 1.0560, G loss: 1.2232\n",
      "[244/1762] D loss: 1.3869, G loss: 0.6955\n",
      "[324/1762] D loss: 1.3865, G loss: 0.6993\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6817\n",
      "[484/1762] D loss: 1.3865, G loss: 0.6994\n",
      "[564/1762] D loss: 1.3865, G loss: 0.6854\n",
      "[644/1762] D loss: 1.3864, G loss: 0.6913\n",
      "[724/1762] D loss: 1.0847, G loss: 0.9814\n",
      "[804/1762] D loss: 1.0724, G loss: 1.0441\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6911\n",
      "[964/1762] D loss: 1.3865, G loss: 0.7007\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.6896\n",
      "[1124/1762] D loss: 1.0600, G loss: 1.1707\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6978\n",
      "[1284/1762] D loss: 1.0552, G loss: 1.2297\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6900\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6951\n",
      "[1524/1762] D loss: 1.0628, G loss: 1.1245\n",
      "[1604/1762] D loss: 1.3865, G loss: 0.6846\n",
      "[1684/1762] D loss: 1.0475, G loss: 1.3887\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6887\n",
      "train error: \n",
      " D loss: 1.304828, G loss: 0.879299, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 93.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.293622, G loss: 0.939576, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6886\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6873\n",
      "[164/1762] D loss: 1.3867, G loss: 0.7027\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6877\n",
      "[324/1762] D loss: 1.0726, G loss: 1.0414\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6925\n",
      "[484/1762] D loss: 1.3863, G loss: 0.6897\n",
      "[564/1762] D loss: 1.3862, G loss: 0.6948\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6927\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6846\n",
      "[804/1762] D loss: 1.5318, G loss: 0.5931\n",
      "[884/1762] D loss: 1.3867, G loss: 0.6958\n",
      "[964/1762] D loss: 1.3862, G loss: 0.6920\n",
      "[1044/1762] D loss: 1.3867, G loss: 0.7063\n",
      "[1124/1762] D loss: 1.0755, G loss: 1.0291\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.7028\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6805\n",
      "[1364/1762] D loss: 1.3872, G loss: 0.7183\n",
      "[1444/1762] D loss: 1.3866, G loss: 0.6999\n",
      "[1524/1762] D loss: 1.0563, G loss: 1.2078\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.7001\n",
      "[1684/1762] D loss: 1.0514, G loss: 1.2991\n",
      "[1762/1762] D loss: 0.7145, G loss: 1.9384\n",
      "train error: \n",
      " D loss: 1.304925, G loss: 0.878227, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 93.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.292931, G loss: 0.938176, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0513, G loss: 1.2979\n",
      "[84/1762] D loss: 1.8926, G loss: 1.3224\n",
      "[164/1762] D loss: 1.7898, G loss: 1.3021\n",
      "[244/1762] D loss: 1.3863, G loss: 0.7019\n",
      "[324/1762] D loss: 1.0571, G loss: 1.2060\n",
      "[404/1762] D loss: 1.3857, G loss: 0.7138\n",
      "[484/1762] D loss: 1.3818, G loss: 0.6893\n",
      "[564/1762] D loss: 1.3927, G loss: 0.6886\n",
      "[644/1762] D loss: 1.0682, G loss: 1.1684\n",
      "[724/1762] D loss: 0.7465, G loss: 1.5259\n",
      "[804/1762] D loss: 1.0634, G loss: 1.1614\n",
      "[884/1762] D loss: 0.7305, G loss: 1.6603\n",
      "[964/1762] D loss: 1.0571, G loss: 1.2165\n",
      "[1044/1762] D loss: 1.3883, G loss: 0.7192\n",
      "[1124/1762] D loss: 1.0553, G loss: 1.2174\n",
      "[1204/1762] D loss: 1.0564, G loss: 1.2010\n",
      "[1284/1762] D loss: 1.3862, G loss: 0.6898\n",
      "[1364/1762] D loss: 1.3869, G loss: 0.6774\n",
      "[1444/1762] D loss: 1.3861, G loss: 0.7000\n",
      "[1524/1762] D loss: 1.3867, G loss: 0.6999\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6829\n",
      "[1684/1762] D loss: 1.3868, G loss: 0.7078\n",
      "[1762/1762] D loss: 1.3850, G loss: 0.6877\n",
      "train error: \n",
      " D loss: 1.303808, G loss: 0.831288, D accuracy: 53.4%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.289551, G loss: 0.863500, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6956\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6992\n",
      "[164/1762] D loss: 1.3875, G loss: 0.6927\n",
      "[244/1762] D loss: 1.3866, G loss: 0.7052\n",
      "[324/1762] D loss: 1.3869, G loss: 0.7023\n",
      "[404/1762] D loss: 1.3860, G loss: 0.6884\n",
      "[484/1762] D loss: 1.3862, G loss: 0.6973\n",
      "[564/1762] D loss: 1.3849, G loss: 0.6852\n",
      "[644/1762] D loss: 1.3861, G loss: 0.6942\n",
      "[724/1762] D loss: 1.7957, G loss: 1.2397\n",
      "[804/1762] D loss: 1.3870, G loss: 0.7116\n",
      "[884/1762] D loss: 1.0517, G loss: 1.1162\n",
      "[964/1762] D loss: 1.6640, G loss: 1.1214\n",
      "[1044/1762] D loss: 1.3866, G loss: 0.6992\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.6978\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6953\n",
      "[1284/1762] D loss: 1.3865, G loss: 0.7025\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6870\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6884\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.6932\n",
      "[1604/1762] D loss: 1.0607, G loss: 1.1300\n",
      "[1684/1762] D loss: 1.3866, G loss: 0.6987\n",
      "[1762/1762] D loss: 1.3868, G loss: 0.7195\n",
      "train error: \n",
      " D loss: 1.301745, G loss: 0.842129, D accuracy: 54.1%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.287793, G loss: 0.883191, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3862, G loss: 0.7093\n",
      "[84/1762] D loss: 1.3849, G loss: 0.6837\n",
      "[164/1762] D loss: 0.7218, G loss: 1.7788\n",
      "[244/1762] D loss: 1.0542, G loss: 1.2608\n",
      "[324/1762] D loss: 1.3864, G loss: 0.6888\n",
      "[404/1762] D loss: 1.3866, G loss: 0.6835\n",
      "[484/1762] D loss: 1.3907, G loss: 0.7382\n",
      "[564/1762] D loss: 1.3861, G loss: 0.6924\n",
      "[644/1762] D loss: 1.3721, G loss: 0.8018\n",
      "[724/1762] D loss: 1.3871, G loss: 0.7241\n",
      "[804/1762] D loss: 1.3866, G loss: 0.6808\n",
      "[884/1762] D loss: 1.0668, G loss: 1.1276\n",
      "[964/1762] D loss: 1.3866, G loss: 0.7145\n",
      "[1044/1762] D loss: 0.7249, G loss: 1.7736\n",
      "[1124/1762] D loss: 1.3862, G loss: 0.6858\n",
      "[1204/1762] D loss: 1.3872, G loss: 0.6640\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.7035\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6920\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6990\n",
      "[1524/1762] D loss: 1.0608, G loss: 1.1588\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6854\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.7013\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.7019\n",
      "train error: \n",
      " D loss: 1.303333, G loss: 0.823253, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 93.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.288203, G loss: 0.864291, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6981\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6933\n",
      "[164/1762] D loss: 1.7243, G loss: 1.1717\n",
      "[244/1762] D loss: 0.7333, G loss: 1.6308\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6955\n",
      "[404/1762] D loss: 1.3863, G loss: 0.6891\n",
      "[484/1762] D loss: 0.7309, G loss: 1.6654\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6944\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6929\n",
      "[724/1762] D loss: 1.3866, G loss: 0.7068\n",
      "[804/1762] D loss: 0.7176, G loss: 1.8720\n",
      "[884/1762] D loss: 1.0632, G loss: 1.1304\n",
      "[964/1762] D loss: 1.3914, G loss: 0.7381\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.7036\n",
      "[1124/1762] D loss: 1.0622, G loss: 1.1192\n",
      "[1204/1762] D loss: 1.3867, G loss: 0.6905\n",
      "[1284/1762] D loss: 1.0912, G loss: 0.9509\n",
      "[1364/1762] D loss: 1.3878, G loss: 0.7255\n",
      "[1444/1762] D loss: 1.3866, G loss: 0.6767\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.6908\n",
      "[1604/1762] D loss: 1.3862, G loss: 0.6900\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.6894\n",
      "[1762/1762] D loss: 0.7311, G loss: 1.7078\n",
      "train error: \n",
      " D loss: 1.303784, G loss: 0.864128, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.290471, G loss: 0.909430, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0575, G loss: 1.2039\n",
      "[84/1762] D loss: 1.3862, G loss: 0.6899\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6888\n",
      "[244/1762] D loss: 1.3865, G loss: 0.6862\n",
      "[324/1762] D loss: 1.3862, G loss: 0.6927\n",
      "[404/1762] D loss: 1.0525, G loss: 1.2713\n",
      "[484/1762] D loss: 1.3864, G loss: 0.7017\n",
      "[564/1762] D loss: 1.0558, G loss: 1.2058\n",
      "[644/1762] D loss: 1.3871, G loss: 0.6773\n",
      "[724/1762] D loss: 1.3865, G loss: 0.6821\n",
      "[804/1762] D loss: 1.3864, G loss: 0.7007\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6796\n",
      "[964/1762] D loss: 1.3865, G loss: 0.7052\n",
      "[1044/1762] D loss: 1.7385, G loss: 1.1992\n",
      "[1124/1762] D loss: 1.0604, G loss: 1.1541\n",
      "[1204/1762] D loss: 1.0618, G loss: 1.1344\n",
      "[1284/1762] D loss: 1.6711, G loss: 1.1489\n",
      "[1364/1762] D loss: 1.0658, G loss: 1.0969\n",
      "[1444/1762] D loss: 1.3866, G loss: 0.6790\n",
      "[1524/1762] D loss: 0.7294, G loss: 1.7008\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6950\n",
      "[1684/1762] D loss: 1.0594, G loss: 1.1696\n",
      "[1762/1762] D loss: 0.7329, G loss: 1.6076\n",
      "train error: \n",
      " D loss: 1.303197, G loss: 0.820967, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 93.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.291396, G loss: 0.862585, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6914\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6807\n",
      "[164/1762] D loss: 1.7157, G loss: 1.1673\n",
      "[244/1762] D loss: 1.0637, G loss: 1.1232\n",
      "[324/1762] D loss: 1.3036, G loss: 1.4376\n",
      "[404/1762] D loss: 1.0711, G loss: 1.0623\n",
      "[484/1762] D loss: 1.3863, G loss: 0.6950\n",
      "[564/1762] D loss: 1.3869, G loss: 0.7136\n",
      "[644/1762] D loss: 1.0622, G loss: 1.1296\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6923\n",
      "[804/1762] D loss: 1.3865, G loss: 0.6947\n",
      "[884/1762] D loss: 1.7902, G loss: 1.2470\n",
      "[964/1762] D loss: 1.0594, G loss: 1.1608\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6968\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6958\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6928\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6969\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6874\n",
      "[1444/1762] D loss: 1.0619, G loss: 1.1442\n",
      "[1524/1762] D loss: 1.0585, G loss: 1.1798\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6865\n",
      "[1684/1762] D loss: 1.0546, G loss: 1.2435\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6977\n",
      "train error: \n",
      " D loss: 1.303767, G loss: 0.869716, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 93.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.291901, G loss: 0.925795, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0522, G loss: 1.2789\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6933\n",
      "[164/1762] D loss: 1.3867, G loss: 0.7084\n",
      "[244/1762] D loss: 1.3862, G loss: 0.6908\n",
      "[324/1762] D loss: 1.0572, G loss: 1.1950\n",
      "[404/1762] D loss: 1.0582, G loss: 1.1795\n",
      "[484/1762] D loss: 1.3865, G loss: 0.6781\n",
      "[564/1762] D loss: 1.3863, G loss: 0.6948\n",
      "[644/1762] D loss: 1.0591, G loss: 1.1720\n",
      "[724/1762] D loss: 1.0577, G loss: 1.1891\n",
      "[804/1762] D loss: 1.0558, G loss: 1.2306\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6998\n",
      "[964/1762] D loss: 1.3864, G loss: 0.6906\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.6923\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6926\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6913\n",
      "[1284/1762] D loss: 1.3861, G loss: 0.6961\n",
      "[1364/1762] D loss: 1.0546, G loss: 1.2300\n",
      "[1444/1762] D loss: 1.0561, G loss: 1.2110\n",
      "[1524/1762] D loss: 0.7210, G loss: 1.8084\n",
      "[1604/1762] D loss: 1.0553, G loss: 1.2109\n",
      "[1684/1762] D loss: 1.3868, G loss: 0.7222\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6856\n",
      "train error: \n",
      " D loss: 1.303246, G loss: 0.827602, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 93.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.290095, G loss: 0.868908, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6922\n",
      "[84/1762] D loss: 1.0641, G loss: 1.1131\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6959\n",
      "[244/1762] D loss: 1.3864, G loss: 0.6994\n",
      "[324/1762] D loss: 1.0523, G loss: 1.2777\n",
      "[404/1762] D loss: 1.3861, G loss: 0.6902\n",
      "[484/1762] D loss: 1.3862, G loss: 0.6921\n",
      "[564/1762] D loss: 1.3863, G loss: 0.6926\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6927\n",
      "[724/1762] D loss: 1.3866, G loss: 0.6760\n",
      "[804/1762] D loss: 1.3863, G loss: 0.6986\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6894\n",
      "[964/1762] D loss: 1.0580, G loss: 1.1839\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6924\n",
      "[1124/1762] D loss: 1.0616, G loss: 1.1413\n",
      "[1204/1762] D loss: 1.0617, G loss: 1.1361\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6913\n",
      "[1364/1762] D loss: 1.0698, G loss: 1.0615\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6968\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.6909\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6946\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6962\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6950\n",
      "train error: \n",
      " D loss: 1.303145, G loss: 0.831946, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 93.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.289646, G loss: 0.874542, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6922\n",
      "[84/1762] D loss: 1.0589, G loss: 1.1727\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6896\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6906\n",
      "[324/1762] D loss: 1.3863, G loss: 0.7000\n",
      "[404/1762] D loss: 1.0575, G loss: 1.1900\n",
      "[484/1762] D loss: 1.3864, G loss: 0.6880\n",
      "[564/1762] D loss: 1.3863, G loss: 0.6954\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6943\n",
      "[724/1762] D loss: 1.7000, G loss: 1.1529\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6868\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6970\n",
      "[964/1762] D loss: 1.3863, G loss: 0.6949\n",
      "[1044/1762] D loss: 0.7234, G loss: 1.6930\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6922\n",
      "[1204/1762] D loss: 1.0673, G loss: 1.0717\n",
      "[1284/1762] D loss: 1.3857, G loss: 0.6922\n",
      "[1364/1762] D loss: 1.3869, G loss: 0.7175\n",
      "[1444/1762] D loss: 1.0623, G loss: 1.1314\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.6850\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6901\n",
      "[1684/1762] D loss: 1.0521, G loss: 1.2880\n",
      "[1762/1762] D loss: 1.3799, G loss: 0.6840\n",
      "train error: \n",
      " D loss: 1.284673, G loss: 0.929447, D accuracy: 55.8%, cell accuracy: 99.7%, board accuracy: 86.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.270986, G loss: 0.999552, D accuracy: 56.2%, cell accuracy: 99.6%, board accuracy: 85.7% \n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0512, G loss: 1.2991\n",
      "[84/1762] D loss: 1.3893, G loss: 0.6884\n",
      "[164/1762] D loss: 1.3871, G loss: 0.7098\n",
      "[244/1762] D loss: 1.3864, G loss: 0.6926\n",
      "[324/1762] D loss: 1.3865, G loss: 0.6926\n",
      "[404/1762] D loss: 1.3863, G loss: 0.6911\n",
      "[484/1762] D loss: 1.3870, G loss: 0.6994\n",
      "[564/1762] D loss: 1.3885, G loss: 0.6956\n",
      "[644/1762] D loss: 1.3872, G loss: 0.6685\n",
      "[724/1762] D loss: 1.0434, G loss: 1.6660\n",
      "[804/1762] D loss: 1.0407, G loss: 1.9492\n",
      "[884/1762] D loss: 1.0509, G loss: 2.1105\n",
      "[964/1762] D loss: 1.3863, G loss: 0.7006\n",
      "[1044/1762] D loss: 1.3865, G loss: 0.6812\n",
      "[1124/1762] D loss: 1.3866, G loss: 0.6948\n",
      "[1204/1762] D loss: 1.3865, G loss: 0.6805\n",
      "[1284/1762] D loss: 1.3850, G loss: 0.6850\n",
      "[1364/1762] D loss: 1.3870, G loss: 0.7055\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.6875\n",
      "[1524/1762] D loss: 1.0402, G loss: 2.1226\n",
      "[1604/1762] D loss: 1.3874, G loss: 0.6690\n",
      "[1684/1762] D loss: 1.3848, G loss: 0.6842\n",
      "[1762/1762] D loss: 1.3887, G loss: 0.6850\n",
      "train error: \n",
      " D loss: 1.280067, G loss: 1.124452, D accuracy: 54.3%, cell accuracy: 99.9%, board accuracy: 90.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.251450, G loss: 1.244828, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6887\n",
      "[84/1762] D loss: 1.3863, G loss: 0.7015\n",
      "[164/1762] D loss: 1.3862, G loss: 0.6957\n",
      "[244/1762] D loss: 1.3865, G loss: 0.6958\n",
      "[324/1762] D loss: 1.0406, G loss: 2.1550\n",
      "[404/1762] D loss: 1.3868, G loss: 0.6765\n",
      "[484/1762] D loss: 1.3859, G loss: 0.6926\n",
      "[564/1762] D loss: 1.3812, G loss: 0.6982\n",
      "[644/1762] D loss: 1.3865, G loss: 0.6934\n",
      "[724/1762] D loss: 1.0401, G loss: 2.1748\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6840\n",
      "[884/1762] D loss: 1.3862, G loss: 0.7108\n",
      "[964/1762] D loss: 1.3863, G loss: 0.6958\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.7004\n",
      "[1124/1762] D loss: 1.3866, G loss: 0.6823\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6886\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6970\n",
      "[1364/1762] D loss: 1.0400, G loss: 2.3080\n",
      "[1444/1762] D loss: 1.0394, G loss: 2.2611\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.6911\n",
      "[1604/1762] D loss: 0.6936, G loss: 3.8487\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.6977\n",
      "[1762/1762] D loss: 0.6936, G loss: 4.0443\n",
      "train error: \n",
      " D loss: 1.280734, G loss: 1.182611, D accuracy: 54.3%, cell accuracy: 99.9%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.250578, G loss: 1.322727, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3673, G loss: 0.7085\n",
      "[84/1762] D loss: 1.0398, G loss: 2.4410\n",
      "[164/1762] D loss: 1.3864, G loss: 0.7036\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6900\n",
      "[324/1762] D loss: 1.3864, G loss: 0.6966\n",
      "[404/1762] D loss: 1.3797, G loss: 0.6996\n",
      "[484/1762] D loss: 1.3864, G loss: 0.6993\n",
      "[564/1762] D loss: 1.0400, G loss: 2.2377\n",
      "[644/1762] D loss: 1.3940, G loss: 0.7001\n",
      "[724/1762] D loss: 1.4007, G loss: 0.6011\n",
      "[804/1762] D loss: 1.3879, G loss: 0.6943\n",
      "[884/1762] D loss: 1.3845, G loss: 0.7082\n",
      "[964/1762] D loss: 1.3877, G loss: 0.7134\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.6885\n",
      "[1124/1762] D loss: 1.3885, G loss: 0.7090\n",
      "[1204/1762] D loss: 1.0794, G loss: 0.9851\n",
      "[1284/1762] D loss: 1.1017, G loss: 0.8904\n",
      "[1364/1762] D loss: 1.3917, G loss: 0.7161\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6970\n",
      "[1524/1762] D loss: 1.3862, G loss: 0.6902\n",
      "[1604/1762] D loss: 1.3868, G loss: 0.6936\n",
      "[1684/1762] D loss: 1.3872, G loss: 0.6885\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.6888\n",
      "train error: \n",
      " D loss: 1.302761, G loss: 0.807462, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.286259, G loss: 0.842729, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3894, G loss: 0.7518\n",
      "[84/1762] D loss: 1.3457, G loss: 0.7871\n",
      "[164/1762] D loss: 0.8519, G loss: 1.7445\n",
      "[244/1762] D loss: 0.1407, G loss: 3.1045\n",
      "[324/1762] D loss: 0.0840, G loss: 2.3129\n",
      "[404/1762] D loss: 0.3069, G loss: 4.2312\n",
      "[484/1762] D loss: 0.2373, G loss: 4.6070\n",
      "[564/1762] D loss: 0.0600, G loss: 6.1221\n",
      "[644/1762] D loss: 0.0346, G loss: 9.3894\n",
      "[724/1762] D loss: 0.3322, G loss: 2.0293\n",
      "[804/1762] D loss: 0.5653, G loss: 2.4571\n",
      "[884/1762] D loss: 0.3939, G loss: 2.6092\n",
      "[964/1762] D loss: 0.3442, G loss: 5.0408\n",
      "[1044/1762] D loss: 1.2019, G loss: 4.2943\n",
      "[1124/1762] D loss: 0.5665, G loss: 1.7165\n",
      "[1204/1762] D loss: 0.4318, G loss: 2.4357\n",
      "[1284/1762] D loss: 0.9612, G loss: 1.0616\n",
      "[1364/1762] D loss: 0.9074, G loss: 1.6043\n",
      "[1444/1762] D loss: 0.8671, G loss: 1.4245\n",
      "[1524/1762] D loss: 0.6135, G loss: 1.4003\n",
      "[1604/1762] D loss: 1.4467, G loss: 1.7979\n",
      "[1684/1762] D loss: 0.9220, G loss: 1.3992\n",
      "[1762/1762] D loss: 0.8754, G loss: 1.3710\n",
      "train error: \n",
      " D loss: 1.000157, G loss: 2.718427, D accuracy: 77.6%, cell accuracy: 96.2%, board accuracy: 2.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.053389, G loss: 2.337804, D accuracy: 74.8%, cell accuracy: 95.9%, board accuracy: 2.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6094, G loss: 1.5976\n",
      "[84/1762] D loss: 1.0832, G loss: 0.9168\n",
      "[164/1762] D loss: 1.1392, G loss: 0.6166\n",
      "[244/1762] D loss: 0.9515, G loss: 1.0722\n",
      "[324/1762] D loss: 1.2509, G loss: 1.2829\n",
      "[404/1762] D loss: 1.1645, G loss: 1.7872\n",
      "[484/1762] D loss: 1.0781, G loss: 0.7403\n",
      "[564/1762] D loss: 0.9756, G loss: 1.3590\n",
      "[644/1762] D loss: 1.2432, G loss: 0.9100\n",
      "[724/1762] D loss: 0.9896, G loss: 0.6371\n",
      "[804/1762] D loss: 1.5035, G loss: 0.3208\n",
      "[884/1762] D loss: 1.1390, G loss: 0.6865\n",
      "[964/1762] D loss: 1.1363, G loss: 0.8963\n",
      "[1044/1762] D loss: 1.1640, G loss: 1.0100\n",
      "[1124/1762] D loss: 1.4186, G loss: 1.0787\n",
      "[1204/1762] D loss: 1.3801, G loss: 0.5768\n",
      "[1284/1762] D loss: 1.2772, G loss: 0.7612\n",
      "[1364/1762] D loss: 1.3709, G loss: 0.6985\n",
      "[1444/1762] D loss: 1.3252, G loss: 0.7033\n",
      "[1524/1762] D loss: 1.1152, G loss: 1.2663\n",
      "[1604/1762] D loss: 1.2469, G loss: 0.5434\n",
      "[1684/1762] D loss: 1.3340, G loss: 0.7601\n",
      "[1762/1762] D loss: 1.1544, G loss: 0.7420\n",
      "train error: \n",
      " D loss: 1.378505, G loss: 0.557147, D accuracy: 54.9%, cell accuracy: 99.4%, board accuracy: 45.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.375064, G loss: 0.563985, D accuracy: 55.9%, cell accuracy: 99.3%, board accuracy: 37.3% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3435, G loss: 0.5709\n",
      "[84/1762] D loss: 1.3151, G loss: 0.5286\n",
      "[164/1762] D loss: 1.5955, G loss: 0.7605\n",
      "[244/1762] D loss: 1.3498, G loss: 0.7379\n",
      "[324/1762] D loss: 1.3017, G loss: 0.7481\n",
      "[404/1762] D loss: 1.3364, G loss: 0.9533\n",
      "[484/1762] D loss: 1.3976, G loss: 0.5747\n",
      "[564/1762] D loss: 1.2534, G loss: 0.8182\n",
      "[644/1762] D loss: 1.3276, G loss: 0.7404\n",
      "[724/1762] D loss: 1.3477, G loss: 0.7326\n",
      "[804/1762] D loss: 1.1895, G loss: 0.8527\n",
      "[884/1762] D loss: 1.3353, G loss: 0.6422\n",
      "[964/1762] D loss: 1.3785, G loss: 0.7081\n",
      "[1044/1762] D loss: 1.2872, G loss: 0.7831\n",
      "[1124/1762] D loss: 1.2286, G loss: 0.8103\n",
      "[1204/1762] D loss: 1.4010, G loss: 0.7548\n",
      "[1284/1762] D loss: 1.2637, G loss: 0.8754\n",
      "[1364/1762] D loss: 1.3609, G loss: 0.5854\n",
      "[1444/1762] D loss: 1.3173, G loss: 0.8534\n",
      "[1524/1762] D loss: 1.2745, G loss: 0.7405\n",
      "[1604/1762] D loss: 1.2776, G loss: 0.8622\n",
      "[1684/1762] D loss: 1.3321, G loss: 0.7720\n",
      "[1762/1762] D loss: 1.3402, G loss: 0.7003\n",
      "train error: \n",
      " D loss: 1.348337, G loss: 0.773348, D accuracy: 56.7%, cell accuracy: 99.6%, board accuracy: 70.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.348422, G loss: 0.775000, D accuracy: 56.9%, cell accuracy: 99.5%, board accuracy: 67.0% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3324, G loss: 0.7967\n",
      "[84/1762] D loss: 1.3227, G loss: 0.7130\n",
      "[164/1762] D loss: 1.4063, G loss: 0.5832\n",
      "[244/1762] D loss: 1.3716, G loss: 0.8071\n",
      "[324/1762] D loss: 1.2940, G loss: 0.7463\n",
      "[404/1762] D loss: 1.3616, G loss: 0.5023\n",
      "[484/1762] D loss: 1.3706, G loss: 0.7711\n",
      "[564/1762] D loss: 1.3885, G loss: 0.6059\n",
      "[644/1762] D loss: 1.3185, G loss: 0.8628\n",
      "[724/1762] D loss: 1.3748, G loss: 0.7405\n",
      "[804/1762] D loss: 1.4743, G loss: 0.6796\n",
      "[884/1762] D loss: 1.2929, G loss: 0.7120\n",
      "[964/1762] D loss: 1.3262, G loss: 0.6757\n",
      "[1044/1762] D loss: 1.3480, G loss: 0.7127\n",
      "[1124/1762] D loss: 1.4125, G loss: 0.8392\n",
      "[1204/1762] D loss: 1.3881, G loss: 0.4482\n",
      "[1284/1762] D loss: 1.3823, G loss: 0.7658\n",
      "[1364/1762] D loss: 1.4121, G loss: 0.9146\n",
      "[1444/1762] D loss: 1.3860, G loss: 0.7421\n",
      "[1524/1762] D loss: 1.4258, G loss: 0.6261\n",
      "[1604/1762] D loss: 1.3435, G loss: 0.7313\n",
      "[1684/1762] D loss: 1.3010, G loss: 0.8715\n",
      "[1762/1762] D loss: 1.4180, G loss: 0.6278\n",
      "train error: \n",
      " D loss: 1.361505, G loss: 0.606326, D accuracy: 56.0%, cell accuracy: 99.6%, board accuracy: 69.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.360607, G loss: 0.606592, D accuracy: 55.8%, cell accuracy: 99.6%, board accuracy: 65.5% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4211, G loss: 0.6071\n",
      "[84/1762] D loss: 1.3837, G loss: 0.6711\n",
      "[164/1762] D loss: 1.3598, G loss: 0.6619\n",
      "[244/1762] D loss: 1.2524, G loss: 0.8333\n",
      "[324/1762] D loss: 1.3752, G loss: 0.8702\n",
      "[404/1762] D loss: 1.3692, G loss: 0.7728\n",
      "[484/1762] D loss: 1.3637, G loss: 0.6560\n",
      "[564/1762] D loss: 1.3281, G loss: 0.5966\n",
      "[644/1762] D loss: 1.4136, G loss: 0.6489\n",
      "[724/1762] D loss: 1.3854, G loss: 0.7977\n",
      "[804/1762] D loss: 1.2646, G loss: 0.5269\n",
      "[884/1762] D loss: 1.4313, G loss: 0.4893\n",
      "[964/1762] D loss: 1.3155, G loss: 0.6864\n",
      "[1044/1762] D loss: 1.1728, G loss: 0.8686\n",
      "[1124/1762] D loss: 1.1983, G loss: 0.9744\n",
      "[1204/1762] D loss: 1.1623, G loss: 0.9890\n",
      "[1284/1762] D loss: 1.2324, G loss: 1.0921\n",
      "[1364/1762] D loss: 1.3752, G loss: 0.7139\n",
      "[1444/1762] D loss: 1.3955, G loss: 0.7050\n",
      "[1524/1762] D loss: 1.3525, G loss: 0.7004\n",
      "[1604/1762] D loss: 1.2384, G loss: 0.8914\n",
      "[1684/1762] D loss: 1.3901, G loss: 0.7664\n",
      "[1762/1762] D loss: 1.4122, G loss: 0.9461\n",
      "train error: \n",
      " D loss: 1.380655, G loss: 0.987644, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 73.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.374378, G loss: 0.996190, D accuracy: 55.9%, cell accuracy: 99.7%, board accuracy: 69.8% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4493, G loss: 0.8677\n",
      "[84/1762] D loss: 1.0763, G loss: 0.8571\n",
      "[164/1762] D loss: 1.4549, G loss: 0.8698\n",
      "[244/1762] D loss: 1.2581, G loss: 0.8363\n",
      "[324/1762] D loss: 1.4947, G loss: 0.8377\n",
      "[404/1762] D loss: 1.3430, G loss: 0.5694\n",
      "[484/1762] D loss: 1.3888, G loss: 0.6766\n",
      "[564/1762] D loss: 1.1960, G loss: 0.9608\n",
      "[644/1762] D loss: 1.1902, G loss: 1.1877\n",
      "[724/1762] D loss: 1.3744, G loss: 0.6113\n",
      "[804/1762] D loss: 1.3121, G loss: 0.7852\n",
      "[884/1762] D loss: 1.4748, G loss: 0.4415\n",
      "[964/1762] D loss: 1.1988, G loss: 0.9346\n",
      "[1044/1762] D loss: 1.2146, G loss: 0.9324\n",
      "[1124/1762] D loss: 1.4007, G loss: 0.8225\n",
      "[1204/1762] D loss: 1.3840, G loss: 0.7088\n",
      "[1284/1762] D loss: 1.2333, G loss: 0.6404\n",
      "[1364/1762] D loss: 1.3241, G loss: 0.8825\n",
      "[1444/1762] D loss: 1.4081, G loss: 0.6122\n",
      "[1524/1762] D loss: 1.2615, G loss: 1.0617\n",
      "[1604/1762] D loss: 1.4163, G loss: 0.5322\n",
      "[1684/1762] D loss: 1.3899, G loss: 0.6656\n",
      "[1762/1762] D loss: 1.3421, G loss: 0.8447\n",
      "train error: \n",
      " D loss: 1.342393, G loss: 0.772039, D accuracy: 55.7%, cell accuracy: 99.6%, board accuracy: 67.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.335492, G loss: 0.773700, D accuracy: 56.8%, cell accuracy: 99.6%, board accuracy: 64.5% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4121, G loss: 0.7207\n",
      "[84/1762] D loss: 1.2691, G loss: 0.8821\n",
      "[164/1762] D loss: 1.3811, G loss: 0.7440\n",
      "[244/1762] D loss: 1.3378, G loss: 0.7620\n",
      "[324/1762] D loss: 1.4279, G loss: 0.5229\n",
      "[404/1762] D loss: 1.3910, G loss: 0.6388\n",
      "[484/1762] D loss: 1.3015, G loss: 0.8278\n",
      "[564/1762] D loss: 1.3834, G loss: 0.8038\n",
      "[644/1762] D loss: 1.4508, G loss: 0.5780\n",
      "[724/1762] D loss: 1.0350, G loss: 1.3650\n",
      "[804/1762] D loss: 1.5564, G loss: 0.3811\n",
      "[884/1762] D loss: 1.3940, G loss: 0.6863\n",
      "[964/1762] D loss: 1.3905, G loss: 0.6731\n",
      "[1044/1762] D loss: 1.4076, G loss: 0.6696\n",
      "[1124/1762] D loss: 1.2285, G loss: 0.8067\n",
      "[1204/1762] D loss: 1.3972, G loss: 0.5626\n",
      "[1284/1762] D loss: 1.3845, G loss: 0.7573\n",
      "[1364/1762] D loss: 1.3904, G loss: 0.9253\n",
      "[1444/1762] D loss: 1.1919, G loss: 0.8773\n",
      "[1524/1762] D loss: 1.1690, G loss: 0.8682\n",
      "[1604/1762] D loss: 1.4100, G loss: 0.6641\n",
      "[1684/1762] D loss: 1.4005, G loss: 0.7474\n",
      "[1762/1762] D loss: 1.4024, G loss: 0.7612\n",
      "train error: \n",
      " D loss: 1.323092, G loss: 0.847316, D accuracy: 54.5%, cell accuracy: 99.6%, board accuracy: 63.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.307791, G loss: 0.859916, D accuracy: 55.0%, cell accuracy: 99.6%, board accuracy: 60.9% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9439, G loss: 1.0682\n",
      "[84/1762] D loss: 1.0679, G loss: 1.2171\n",
      "[164/1762] D loss: 1.3881, G loss: 0.7305\n",
      "[244/1762] D loss: 1.1929, G loss: 0.6596\n",
      "[324/1762] D loss: 1.4164, G loss: 0.9707\n",
      "[404/1762] D loss: 1.3848, G loss: 0.6433\n",
      "[484/1762] D loss: 1.4050, G loss: 0.6254\n",
      "[564/1762] D loss: 1.4318, G loss: 0.5103\n",
      "[644/1762] D loss: 1.3786, G loss: 0.9065\n",
      "[724/1762] D loss: 1.4320, G loss: 0.5763\n",
      "[804/1762] D loss: 1.1536, G loss: 0.7254\n",
      "[884/1762] D loss: 1.3595, G loss: 0.6571\n",
      "[964/1762] D loss: 1.3725, G loss: 0.7142\n",
      "[1044/1762] D loss: 1.1925, G loss: 1.3498\n",
      "[1124/1762] D loss: 1.2293, G loss: 0.7265\n",
      "[1204/1762] D loss: 1.3828, G loss: 0.7405\n",
      "[1284/1762] D loss: 1.3879, G loss: 0.6911\n",
      "[1364/1762] D loss: 1.3946, G loss: 0.6351\n",
      "[1444/1762] D loss: 1.3904, G loss: 0.6271\n",
      "[1524/1762] D loss: 1.4055, G loss: 0.8355\n",
      "[1604/1762] D loss: 1.3821, G loss: 0.7425\n",
      "[1684/1762] D loss: 1.1376, G loss: 0.9467\n",
      "[1762/1762] D loss: 1.4092, G loss: 0.7594\n",
      "train error: \n",
      " D loss: 1.297445, G loss: 0.782454, D accuracy: 58.0%, cell accuracy: 99.0%, board accuracy: 46.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.279136, G loss: 0.804635, D accuracy: 57.6%, cell accuracy: 98.9%, board accuracy: 45.7% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3726, G loss: 1.0499\n",
      "[84/1762] D loss: 1.3879, G loss: 0.7031\n",
      "[164/1762] D loss: 1.1074, G loss: 1.0687\n",
      "[244/1762] D loss: 1.3761, G loss: 0.6646\n",
      "[324/1762] D loss: 1.1545, G loss: 0.8647\n",
      "[404/1762] D loss: 1.3747, G loss: 0.7293\n",
      "[484/1762] D loss: 1.4116, G loss: 0.9093\n",
      "[564/1762] D loss: 1.3990, G loss: 0.7668\n",
      "[644/1762] D loss: 1.4118, G loss: 0.7057\n",
      "[724/1762] D loss: 1.0061, G loss: 1.0653\n",
      "[804/1762] D loss: 1.3906, G loss: 0.5876\n",
      "[884/1762] D loss: 1.4429, G loss: 0.8683\n",
      "[964/1762] D loss: 1.4066, G loss: 0.8116\n",
      "[1044/1762] D loss: 1.3433, G loss: 1.1300\n",
      "[1124/1762] D loss: 1.2117, G loss: 0.6614\n",
      "[1204/1762] D loss: 1.3828, G loss: 0.5712\n",
      "[1284/1762] D loss: 1.2224, G loss: 0.6246\n",
      "[1364/1762] D loss: 1.1359, G loss: 0.8422\n",
      "[1444/1762] D loss: 1.5181, G loss: 0.9818\n",
      "[1524/1762] D loss: 1.3933, G loss: 0.7851\n",
      "[1604/1762] D loss: 1.1783, G loss: 0.7344\n",
      "[1684/1762] D loss: 1.3945, G loss: 0.6322\n",
      "[1762/1762] D loss: 1.4319, G loss: 0.7645\n",
      "train error: \n",
      " D loss: 1.318108, G loss: 0.753893, D accuracy: 54.4%, cell accuracy: 99.7%, board accuracy: 76.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.298820, G loss: 0.773830, D accuracy: 55.0%, cell accuracy: 99.7%, board accuracy: 74.1% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0833, G loss: 0.8232\n",
      "[84/1762] D loss: 1.3915, G loss: 0.6248\n",
      "[164/1762] D loss: 1.1889, G loss: 0.7644\n",
      "[244/1762] D loss: 0.8747, G loss: 1.1271\n",
      "[324/1762] D loss: 1.1096, G loss: 0.9485\n",
      "[404/1762] D loss: 1.4065, G loss: 0.8013\n",
      "[484/1762] D loss: 1.4297, G loss: 0.9660\n",
      "[564/1762] D loss: 1.3854, G loss: 0.6621\n",
      "[644/1762] D loss: 1.4016, G loss: 0.6725\n",
      "[724/1762] D loss: 1.3987, G loss: 0.7318\n",
      "[804/1762] D loss: 1.3866, G loss: 0.6350\n",
      "[884/1762] D loss: 1.2606, G loss: 0.5719\n",
      "[964/1762] D loss: 1.4003, G loss: 0.6572\n",
      "[1044/1762] D loss: 1.3899, G loss: 0.7305\n",
      "[1124/1762] D loss: 1.3988, G loss: 0.7561\n",
      "[1204/1762] D loss: 1.3886, G loss: 0.7778\n",
      "[1284/1762] D loss: 1.1450, G loss: 0.9342\n",
      "[1364/1762] D loss: 1.1437, G loss: 0.8391\n",
      "[1444/1762] D loss: 1.0840, G loss: 1.0175\n",
      "[1524/1762] D loss: 1.4130, G loss: 0.5347\n",
      "[1604/1762] D loss: 1.0862, G loss: 1.1442\n",
      "[1684/1762] D loss: 1.1829, G loss: 0.8707\n",
      "[1762/1762] D loss: 1.2707, G loss: 0.9032\n",
      "train error: \n",
      " D loss: 1.324162, G loss: 1.019403, D accuracy: 55.3%, cell accuracy: 97.8%, board accuracy: 20.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.305542, G loss: 1.018774, D accuracy: 56.7%, cell accuracy: 97.6%, board accuracy: 20.0% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4149, G loss: 0.9202\n",
      "[84/1762] D loss: 1.1918, G loss: 0.8505\n",
      "[164/1762] D loss: 1.2842, G loss: 1.2824\n",
      "[244/1762] D loss: 1.3953, G loss: 0.8404\n",
      "[324/1762] D loss: 1.1759, G loss: 0.7888\n",
      "[404/1762] D loss: 1.3675, G loss: 0.7325\n",
      "[484/1762] D loss: 1.3920, G loss: 0.6775\n",
      "[564/1762] D loss: 1.1996, G loss: 0.9172\n",
      "[644/1762] D loss: 1.3102, G loss: 0.8051\n",
      "[724/1762] D loss: 1.4229, G loss: 0.5804\n",
      "[804/1762] D loss: 1.1779, G loss: 0.8078\n",
      "[884/1762] D loss: 1.2585, G loss: 0.7635\n",
      "[964/1762] D loss: 1.1932, G loss: 0.9712\n",
      "[1044/1762] D loss: 1.0813, G loss: 0.9453\n",
      "[1124/1762] D loss: 1.3175, G loss: 1.1323\n",
      "[1204/1762] D loss: 1.2218, G loss: 0.9186\n",
      "[1284/1762] D loss: 1.4262, G loss: 1.3210\n",
      "[1364/1762] D loss: 1.3782, G loss: 0.8731\n",
      "[1444/1762] D loss: 1.2528, G loss: 0.7050\n",
      "[1524/1762] D loss: 1.3318, G loss: 0.6902\n",
      "[1604/1762] D loss: 1.3960, G loss: 0.7002\n",
      "[1684/1762] D loss: 1.3325, G loss: 0.8096\n",
      "[1762/1762] D loss: 1.4347, G loss: 0.5742\n",
      "train error: \n",
      " D loss: 1.367662, G loss: 0.712345, D accuracy: 54.3%, cell accuracy: 99.7%, board accuracy: 71.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.366640, G loss: 0.709247, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 72.3% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4613, G loss: 0.7445\n",
      "[84/1762] D loss: 1.3767, G loss: 0.5439\n",
      "[164/1762] D loss: 1.4017, G loss: 0.7601\n",
      "[244/1762] D loss: 1.2474, G loss: 0.8138\n",
      "[324/1762] D loss: 1.1611, G loss: 0.8526\n",
      "[404/1762] D loss: 1.4087, G loss: 0.5736\n",
      "[484/1762] D loss: 1.3760, G loss: 0.7110\n",
      "[564/1762] D loss: 1.4257, G loss: 0.9106\n",
      "[644/1762] D loss: 1.2137, G loss: 0.8066\n",
      "[724/1762] D loss: 1.4465, G loss: 0.4784\n",
      "[804/1762] D loss: 1.3508, G loss: 0.7604\n",
      "[884/1762] D loss: 1.4010, G loss: 0.4467\n",
      "[964/1762] D loss: 1.3905, G loss: 0.7057\n",
      "[1044/1762] D loss: 1.3157, G loss: 0.8058\n",
      "[1124/1762] D loss: 0.9864, G loss: 0.8126\n",
      "[1204/1762] D loss: 0.8251, G loss: 1.1571\n",
      "[1284/1762] D loss: 1.2096, G loss: 0.6792\n",
      "[1364/1762] D loss: 0.9937, G loss: 1.0799\n",
      "[1444/1762] D loss: 1.8322, G loss: 0.8482\n",
      "[1524/1762] D loss: 1.3794, G loss: 0.7265\n",
      "[1604/1762] D loss: 1.3819, G loss: 0.6372\n",
      "[1684/1762] D loss: 1.3939, G loss: 0.7633\n",
      "[1762/1762] D loss: 1.4480, G loss: 0.8844\n",
      "train error: \n",
      " D loss: 1.345507, G loss: 0.790506, D accuracy: 48.2%, cell accuracy: 99.8%, board accuracy: 81.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.328031, G loss: 0.808024, D accuracy: 50.8%, cell accuracy: 99.7%, board accuracy: 78.2% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4274, G loss: 0.7972\n",
      "[84/1762] D loss: 1.3719, G loss: 0.8156\n",
      "[164/1762] D loss: 1.3877, G loss: 0.6979\n",
      "[244/1762] D loss: 1.3895, G loss: 0.6390\n",
      "[324/1762] D loss: 1.3891, G loss: 0.6907\n",
      "[404/1762] D loss: 1.3621, G loss: 0.7761\n",
      "[484/1762] D loss: 1.3325, G loss: 0.8001\n",
      "[564/1762] D loss: 1.3913, G loss: 0.6413\n",
      "[644/1762] D loss: 1.3776, G loss: 0.6508\n",
      "[724/1762] D loss: 1.3937, G loss: 0.6749\n",
      "[804/1762] D loss: 1.3880, G loss: 0.7334\n",
      "[884/1762] D loss: 1.3954, G loss: 0.6799\n",
      "[964/1762] D loss: 1.3755, G loss: 0.6869\n",
      "[1044/1762] D loss: 1.3798, G loss: 0.7196\n",
      "[1124/1762] D loss: 1.3950, G loss: 0.7112\n",
      "[1204/1762] D loss: 1.4383, G loss: 0.6006\n",
      "[1284/1762] D loss: 1.0746, G loss: 1.0122\n",
      "[1364/1762] D loss: 1.4008, G loss: 0.7714\n",
      "[1444/1762] D loss: 1.0563, G loss: 1.3357\n",
      "[1524/1762] D loss: 0.7702, G loss: 1.5463\n",
      "[1604/1762] D loss: 1.3640, G loss: 0.7559\n",
      "[1684/1762] D loss: 1.3827, G loss: 0.7968\n",
      "[1762/1762] D loss: 1.3857, G loss: 0.6744\n",
      "train error: \n",
      " D loss: 1.302507, G loss: 0.798497, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 84.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.277180, G loss: 0.837687, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 82.3% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3908, G loss: 0.6652\n",
      "[84/1762] D loss: 1.3993, G loss: 0.6025\n",
      "[164/1762] D loss: 1.4036, G loss: 0.8119\n",
      "[244/1762] D loss: 0.7858, G loss: 1.4976\n",
      "[324/1762] D loss: 1.3933, G loss: 0.7510\n",
      "[404/1762] D loss: 1.3844, G loss: 0.6629\n",
      "[484/1762] D loss: 1.3984, G loss: 0.7687\n",
      "[564/1762] D loss: 1.3875, G loss: 0.6417\n",
      "[644/1762] D loss: 1.3834, G loss: 0.7232\n",
      "[724/1762] D loss: 0.8852, G loss: 1.2388\n",
      "[804/1762] D loss: 1.3839, G loss: 0.7365\n",
      "[884/1762] D loss: 1.3828, G loss: 0.7502\n",
      "[964/1762] D loss: 1.3992, G loss: 0.5780\n",
      "[1044/1762] D loss: 1.0862, G loss: 1.3100\n",
      "[1124/1762] D loss: 1.3905, G loss: 0.7518\n",
      "[1204/1762] D loss: 1.3884, G loss: 0.6963\n",
      "[1284/1762] D loss: 1.3962, G loss: 0.7640\n",
      "[1364/1762] D loss: 1.3900, G loss: 0.6799\n",
      "[1444/1762] D loss: 1.3934, G loss: 0.7301\n",
      "[1524/1762] D loss: 1.3767, G loss: 0.7565\n",
      "[1604/1762] D loss: 1.3788, G loss: 0.7345\n",
      "[1684/1762] D loss: 1.3812, G loss: 0.7019\n",
      "[1762/1762] D loss: 1.3799, G loss: 0.8086\n",
      "train error: \n",
      " D loss: 1.360684, G loss: 0.772516, D accuracy: 46.7%, cell accuracy: 98.6%, board accuracy: 26.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.349701, G loss: 0.776983, D accuracy: 47.3%, cell accuracy: 98.4%, board accuracy: 24.3% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4327, G loss: 0.7550\n",
      "[84/1762] D loss: 1.1084, G loss: 0.8634\n",
      "[164/1762] D loss: 1.3791, G loss: 0.7170\n",
      "[244/1762] D loss: 1.0468, G loss: 1.2602\n",
      "[324/1762] D loss: 1.0499, G loss: 1.3092\n",
      "[404/1762] D loss: 1.2123, G loss: 0.6665\n",
      "[484/1762] D loss: 1.2110, G loss: 0.6768\n",
      "[564/1762] D loss: 1.4141, G loss: 0.7332\n",
      "[644/1762] D loss: 1.3434, G loss: 0.8916\n",
      "[724/1762] D loss: 1.3654, G loss: 0.6983\n",
      "[804/1762] D loss: 1.3876, G loss: 0.7194\n",
      "[884/1762] D loss: 1.3458, G loss: 0.7475\n",
      "[964/1762] D loss: 1.3534, G loss: 0.6622\n",
      "[1044/1762] D loss: 1.0836, G loss: 1.2560\n",
      "[1124/1762] D loss: 1.3611, G loss: 0.7526\n",
      "[1204/1762] D loss: 1.3193, G loss: 0.7009\n",
      "[1284/1762] D loss: 1.3499, G loss: 0.7165\n",
      "[1364/1762] D loss: 1.3665, G loss: 0.7226\n",
      "[1444/1762] D loss: 1.3671, G loss: 0.7829\n",
      "[1524/1762] D loss: 1.3441, G loss: 0.9444\n",
      "[1604/1762] D loss: 1.2785, G loss: 0.7358\n",
      "[1684/1762] D loss: 1.3794, G loss: 0.6120\n",
      "[1762/1762] D loss: 1.3749, G loss: 0.6857\n",
      "train error: \n",
      " D loss: 1.318613, G loss: 0.709566, D accuracy: 55.4%, cell accuracy: 98.6%, board accuracy: 1.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.298967, G loss: 0.715053, D accuracy: 56.2%, cell accuracy: 98.5%, board accuracy: 0.7% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1915, G loss: 0.7074\n",
      "[84/1762] D loss: 1.1468, G loss: 0.8104\n",
      "[164/1762] D loss: 1.0795, G loss: 0.9987\n",
      "[244/1762] D loss: 1.4879, G loss: 0.6447\n",
      "[324/1762] D loss: 1.3782, G loss: 0.7172\n",
      "[404/1762] D loss: 1.3379, G loss: 0.7532\n",
      "[484/1762] D loss: 1.4356, G loss: 0.6371\n",
      "[564/1762] D loss: 1.3820, G loss: 0.7380\n",
      "[644/1762] D loss: 1.3966, G loss: 0.6901\n",
      "[724/1762] D loss: 1.4331, G loss: 0.9593\n",
      "[804/1762] D loss: 1.2663, G loss: 0.8386\n",
      "[884/1762] D loss: 1.3807, G loss: 0.9213\n",
      "[964/1762] D loss: 1.3383, G loss: 0.8383\n",
      "[1044/1762] D loss: 1.4160, G loss: 0.8402\n",
      "[1124/1762] D loss: 1.4125, G loss: 0.5613\n",
      "[1204/1762] D loss: 1.4080, G loss: 0.6181\n",
      "[1284/1762] D loss: 1.3768, G loss: 0.7205\n",
      "[1364/1762] D loss: 1.3911, G loss: 0.7272\n",
      "[1444/1762] D loss: 1.3962, G loss: 0.6700\n",
      "[1524/1762] D loss: 1.3874, G loss: 0.6531\n",
      "[1604/1762] D loss: 1.3879, G loss: 0.6926\n",
      "[1684/1762] D loss: 1.0750, G loss: 1.0372\n",
      "[1762/1762] D loss: 1.3646, G loss: 0.6813\n",
      "train error: \n",
      " D loss: 1.281868, G loss: 0.848343, D accuracy: 59.6%, cell accuracy: 99.5%, board accuracy: 56.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.257147, G loss: 0.917812, D accuracy: 61.0%, cell accuracy: 99.4%, board accuracy: 50.7% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3580, G loss: 0.7147\n",
      "[84/1762] D loss: 1.3206, G loss: 0.7222\n",
      "[164/1762] D loss: 1.3908, G loss: 0.7798\n",
      "[244/1762] D loss: 1.3197, G loss: 0.7630\n",
      "[324/1762] D loss: 1.4474, G loss: 0.9255\n",
      "[404/1762] D loss: 1.4989, G loss: 0.6743\n",
      "[484/1762] D loss: 1.4385, G loss: 0.9983\n",
      "[564/1762] D loss: 1.4349, G loss: 0.7124\n",
      "[644/1762] D loss: 1.3983, G loss: 0.6146\n",
      "[724/1762] D loss: 1.2587, G loss: 0.7944\n",
      "[804/1762] D loss: 1.0708, G loss: 1.5584\n",
      "[884/1762] D loss: 1.2975, G loss: 0.7466\n",
      "[964/1762] D loss: 1.3290, G loss: 0.7212\n",
      "[1044/1762] D loss: 1.3876, G loss: 0.7165\n",
      "[1124/1762] D loss: 0.7170, G loss: 1.9470\n",
      "[1204/1762] D loss: 1.3487, G loss: 0.7142\n",
      "[1284/1762] D loss: 1.0495, G loss: 2.2030\n",
      "[1364/1762] D loss: 1.0417, G loss: 2.3211\n",
      "[1444/1762] D loss: 1.0974, G loss: 0.9381\n",
      "[1524/1762] D loss: 1.3892, G loss: 0.6810\n",
      "[1604/1762] D loss: 1.3902, G loss: 0.7127\n",
      "[1684/1762] D loss: 1.3892, G loss: 0.7181\n",
      "[1762/1762] D loss: 1.3862, G loss: 0.6836\n",
      "train error: \n",
      " D loss: 1.287174, G loss: 0.912730, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.256324, G loss: 0.993083, D accuracy: 55.6%, cell accuracy: 99.8%, board accuracy: 83.6% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3771, G loss: 0.7240\n",
      "[84/1762] D loss: 1.3895, G loss: 0.7144\n",
      "[164/1762] D loss: 1.3223, G loss: 0.7541\n",
      "[244/1762] D loss: 1.2316, G loss: 0.9028\n",
      "[324/1762] D loss: 0.7971, G loss: 1.8157\n",
      "[404/1762] D loss: 1.4061, G loss: 0.7183\n",
      "[484/1762] D loss: 1.4049, G loss: 0.8072\n",
      "[564/1762] D loss: 1.0549, G loss: 1.4728\n",
      "[644/1762] D loss: 0.9617, G loss: 1.6343\n",
      "[724/1762] D loss: 1.2292, G loss: 0.7392\n",
      "[804/1762] D loss: 1.3932, G loss: 0.7602\n",
      "[884/1762] D loss: 1.3615, G loss: 0.6509\n",
      "[964/1762] D loss: 1.3045, G loss: 0.8159\n",
      "[1044/1762] D loss: 1.1697, G loss: 0.8628\n",
      "[1124/1762] D loss: 1.5058, G loss: 0.8034\n",
      "[1204/1762] D loss: 0.9509, G loss: 1.7203\n",
      "[1284/1762] D loss: 1.0386, G loss: 1.4031\n",
      "[1364/1762] D loss: 1.2023, G loss: 1.0104\n",
      "[1444/1762] D loss: 1.3928, G loss: 0.6491\n",
      "[1524/1762] D loss: 1.4002, G loss: 0.7608\n",
      "[1604/1762] D loss: 1.3631, G loss: 1.8860\n",
      "[1684/1762] D loss: 1.2222, G loss: 1.1176\n",
      "[1762/1762] D loss: 1.4042, G loss: 0.6480\n",
      "train error: \n",
      " D loss: 1.230084, G loss: 0.827905, D accuracy: 63.5%, cell accuracy: 99.3%, board accuracy: 60.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.207017, G loss: 0.873930, D accuracy: 64.7%, cell accuracy: 99.3%, board accuracy: 59.8% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3245, G loss: 0.6171\n",
      "[84/1762] D loss: 1.3340, G loss: 0.5017\n",
      "[164/1762] D loss: 1.4042, G loss: 0.5255\n",
      "[244/1762] D loss: 1.4147, G loss: 0.9082\n",
      "[324/1762] D loss: 1.3165, G loss: 0.8257\n",
      "[404/1762] D loss: 1.1785, G loss: 0.7760\n",
      "[484/1762] D loss: 1.3535, G loss: 1.0753\n",
      "[564/1762] D loss: 0.9950, G loss: 1.4589\n",
      "[644/1762] D loss: 1.3764, G loss: 0.7050\n",
      "[724/1762] D loss: 1.3817, G loss: 0.7100\n",
      "[804/1762] D loss: 1.1764, G loss: 1.0071\n",
      "[884/1762] D loss: 1.0544, G loss: 0.9805\n",
      "[964/1762] D loss: 1.0492, G loss: 1.2147\n",
      "[1044/1762] D loss: 1.3345, G loss: 0.6386\n",
      "[1124/1762] D loss: 1.3656, G loss: 1.7224\n",
      "[1204/1762] D loss: 1.3139, G loss: 0.7178\n",
      "[1284/1762] D loss: 1.3870, G loss: 0.6718\n",
      "[1364/1762] D loss: 1.3876, G loss: 0.7383\n",
      "[1444/1762] D loss: 1.3894, G loss: 0.6797\n",
      "[1524/1762] D loss: 1.3919, G loss: 0.6432\n",
      "[1604/1762] D loss: 1.2165, G loss: 1.0462\n",
      "[1684/1762] D loss: 1.3848, G loss: 0.7214\n",
      "[1762/1762] D loss: 1.3861, G loss: 0.7216\n",
      "train error: \n",
      " D loss: 1.289404, G loss: 1.010889, D accuracy: 56.2%, cell accuracy: 99.7%, board accuracy: 79.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.265378, G loss: 1.113142, D accuracy: 57.2%, cell accuracy: 99.7%, board accuracy: 77.0% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3879, G loss: 0.7296\n",
      "[84/1762] D loss: 1.3666, G loss: 0.7716\n",
      "[164/1762] D loss: 1.3894, G loss: 0.7017\n",
      "[244/1762] D loss: 1.4197, G loss: 0.7891\n",
      "[324/1762] D loss: 1.4161, G loss: 0.5892\n",
      "[404/1762] D loss: 1.3910, G loss: 0.6900\n",
      "[484/1762] D loss: 1.2492, G loss: 0.7864\n",
      "[564/1762] D loss: 1.2825, G loss: 1.1657\n",
      "[644/1762] D loss: 1.3104, G loss: 1.4545\n",
      "[724/1762] D loss: 1.4127, G loss: 0.5703\n",
      "[804/1762] D loss: 1.0292, G loss: 1.8451\n",
      "[884/1762] D loss: 1.3463, G loss: 0.7627\n",
      "[964/1762] D loss: 1.3877, G loss: 0.6646\n",
      "[1044/1762] D loss: 1.3949, G loss: 0.7366\n",
      "[1124/1762] D loss: 0.9744, G loss: 1.4995\n",
      "[1204/1762] D loss: 1.3522, G loss: 0.6457\n",
      "[1284/1762] D loss: 1.0500, G loss: 2.2461\n",
      "[1364/1762] D loss: 1.3943, G loss: 0.6872\n",
      "[1444/1762] D loss: 1.2380, G loss: 0.9260\n",
      "[1524/1762] D loss: 1.0544, G loss: 1.2543\n",
      "[1604/1762] D loss: 1.0948, G loss: 1.9672\n",
      "[1684/1762] D loss: 1.3868, G loss: 0.6821\n",
      "[1762/1762] D loss: 1.4130, G loss: 0.5383\n",
      "train error: \n",
      " D loss: 1.315034, G loss: 0.773233, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 86.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.282599, G loss: 0.855545, D accuracy: 56.0%, cell accuracy: 99.6%, board accuracy: 82.0% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4119, G loss: 0.5494\n",
      "[84/1762] D loss: 1.3882, G loss: 0.7133\n",
      "[164/1762] D loss: 1.3890, G loss: 0.6971\n",
      "[244/1762] D loss: 1.3973, G loss: 0.6295\n",
      "[324/1762] D loss: 1.3895, G loss: 0.6393\n",
      "[404/1762] D loss: 1.3887, G loss: 0.7251\n",
      "[484/1762] D loss: 1.0452, G loss: 1.5881\n",
      "[564/1762] D loss: 1.0539, G loss: 1.3160\n",
      "[644/1762] D loss: 1.3867, G loss: 0.6935\n",
      "[724/1762] D loss: 1.3889, G loss: 0.7248\n",
      "[804/1762] D loss: 1.4090, G loss: 0.5930\n",
      "[884/1762] D loss: 1.3584, G loss: 0.6861\n",
      "[964/1762] D loss: 1.3887, G loss: 0.7610\n",
      "[1044/1762] D loss: 1.4655, G loss: 0.5449\n",
      "[1124/1762] D loss: 1.3644, G loss: 0.6886\n",
      "[1204/1762] D loss: 1.3822, G loss: 0.6426\n",
      "[1284/1762] D loss: 1.2387, G loss: 0.6315\n",
      "[1364/1762] D loss: 1.3870, G loss: 0.7178\n",
      "[1444/1762] D loss: 1.3619, G loss: 0.7122\n",
      "[1524/1762] D loss: 1.3681, G loss: 0.7238\n",
      "[1604/1762] D loss: 1.0012, G loss: 2.6049\n",
      "[1684/1762] D loss: 1.4338, G loss: 0.5270\n",
      "[1762/1762] D loss: 1.4001, G loss: 0.6178\n",
      "train error: \n",
      " D loss: 1.295292, G loss: 0.864733, D accuracy: 55.1%, cell accuracy: 99.7%, board accuracy: 89.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.264889, G loss: 0.963499, D accuracy: 56.0%, cell accuracy: 99.7%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3899, G loss: 0.6841\n",
      "[84/1762] D loss: 1.0298, G loss: 1.6943\n",
      "[164/1762] D loss: 1.3966, G loss: 0.7850\n",
      "[244/1762] D loss: 1.0894, G loss: 1.2017\n",
      "[324/1762] D loss: 1.1249, G loss: 1.6536\n",
      "[404/1762] D loss: 1.2057, G loss: 0.9449\n",
      "[484/1762] D loss: 0.6821, G loss: 1.9999\n",
      "[564/1762] D loss: 1.4206, G loss: 0.7201\n",
      "[644/1762] D loss: 1.3891, G loss: 0.6322\n",
      "[724/1762] D loss: 1.2137, G loss: 0.6985\n",
      "[804/1762] D loss: 1.3818, G loss: 0.6300\n",
      "[884/1762] D loss: 1.3638, G loss: 0.7572\n",
      "[964/1762] D loss: 0.7388, G loss: 1.7217\n",
      "[1044/1762] D loss: 1.3871, G loss: 0.7057\n",
      "[1124/1762] D loss: 1.3661, G loss: 0.7913\n",
      "[1204/1762] D loss: 1.3891, G loss: 0.6887\n",
      "[1284/1762] D loss: 1.3903, G loss: 0.7447\n",
      "[1364/1762] D loss: 1.3944, G loss: 0.6775\n",
      "[1444/1762] D loss: 1.1071, G loss: 1.0074\n",
      "[1524/1762] D loss: 1.3872, G loss: 0.6895\n",
      "[1604/1762] D loss: 1.3645, G loss: 0.7648\n",
      "[1684/1762] D loss: 1.3849, G loss: 0.6950\n",
      "[1762/1762] D loss: 1.3957, G loss: 0.6184\n",
      "train error: \n",
      " D loss: 1.307404, G loss: 0.769556, D accuracy: 54.9%, cell accuracy: 99.6%, board accuracy: 85.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.279325, G loss: 0.806332, D accuracy: 55.9%, cell accuracy: 99.5%, board accuracy: 81.1% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3919, G loss: 0.7403\n",
      "[84/1762] D loss: 1.3854, G loss: 0.6720\n",
      "[164/1762] D loss: 1.0472, G loss: 1.5203\n",
      "[244/1762] D loss: 1.2804, G loss: 1.0812\n",
      "[324/1762] D loss: 1.3928, G loss: 0.6636\n",
      "[404/1762] D loss: 1.3933, G loss: 0.6547\n",
      "[484/1762] D loss: 1.3973, G loss: 0.7648\n",
      "[564/1762] D loss: 1.3876, G loss: 0.6637\n",
      "[644/1762] D loss: 1.3891, G loss: 0.7068\n",
      "[724/1762] D loss: 1.3876, G loss: 0.6730\n",
      "[804/1762] D loss: 1.3394, G loss: 0.7460\n",
      "[884/1762] D loss: 1.3861, G loss: 0.7059\n",
      "[964/1762] D loss: 1.3862, G loss: 0.6785\n",
      "[1044/1762] D loss: 1.3914, G loss: 0.7245\n",
      "[1124/1762] D loss: 1.4549, G loss: 0.5129\n",
      "[1204/1762] D loss: 1.4141, G loss: 0.6620\n",
      "[1284/1762] D loss: 1.3847, G loss: 0.7127\n",
      "[1364/1762] D loss: 1.3884, G loss: 0.6702\n",
      "[1444/1762] D loss: 1.0575, G loss: 1.1835\n",
      "[1524/1762] D loss: 1.2120, G loss: 1.1373\n",
      "[1604/1762] D loss: 1.2081, G loss: 1.1576\n",
      "[1684/1762] D loss: 1.3889, G loss: 0.6455\n",
      "[1762/1762] D loss: 0.7625, G loss: 1.5139\n",
      "train error: \n",
      " D loss: 1.303456, G loss: 0.853147, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.275432, G loss: 0.949656, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0478, G loss: 1.6716\n",
      "[84/1762] D loss: 1.4000, G loss: 0.7721\n",
      "[164/1762] D loss: 1.3890, G loss: 0.6434\n",
      "[244/1762] D loss: 1.0459, G loss: 1.6899\n",
      "[324/1762] D loss: 1.0434, G loss: 1.6033\n",
      "[404/1762] D loss: 1.3802, G loss: 0.6849\n",
      "[484/1762] D loss: 1.4009, G loss: 0.6424\n",
      "[564/1762] D loss: 1.3957, G loss: 0.7260\n",
      "[644/1762] D loss: 1.3896, G loss: 0.7092\n",
      "[724/1762] D loss: 1.4375, G loss: 0.5796\n",
      "[804/1762] D loss: 1.3875, G loss: 0.6665\n",
      "[884/1762] D loss: 1.0433, G loss: 1.8687\n",
      "[964/1762] D loss: 1.3888, G loss: 0.7370\n",
      "[1044/1762] D loss: 1.0627, G loss: 1.2072\n",
      "[1124/1762] D loss: 1.3889, G loss: 0.7169\n",
      "[1204/1762] D loss: 1.3893, G loss: 0.7166\n",
      "[1284/1762] D loss: 1.3609, G loss: 0.6763\n",
      "[1364/1762] D loss: 1.3546, G loss: 0.6419\n",
      "[1444/1762] D loss: 1.3942, G loss: 0.7535\n",
      "[1524/1762] D loss: 1.3873, G loss: 0.6955\n",
      "[1604/1762] D loss: 1.3740, G loss: 0.6680\n",
      "[1684/1762] D loss: 1.0412, G loss: 1.8661\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6858\n",
      "train error: \n",
      " D loss: 1.288664, G loss: 0.914781, D accuracy: 54.1%, cell accuracy: 99.7%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.260057, G loss: 1.005661, D accuracy: 55.5%, cell accuracy: 99.6%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0455, G loss: 1.5995\n",
      "[84/1762] D loss: 1.3155, G loss: 0.9717\n",
      "[164/1762] D loss: 1.4194, G loss: 0.5639\n",
      "[244/1762] D loss: 1.4040, G loss: 0.7363\n",
      "[324/1762] D loss: 1.3910, G loss: 0.6347\n",
      "[404/1762] D loss: 1.3868, G loss: 0.6756\n",
      "[484/1762] D loss: 1.3840, G loss: 0.7203\n",
      "[564/1762] D loss: 1.4406, G loss: 0.7687\n",
      "[644/1762] D loss: 1.3902, G loss: 0.6645\n",
      "[724/1762] D loss: 1.3877, G loss: 0.6610\n",
      "[804/1762] D loss: 1.3874, G loss: 0.6649\n",
      "[884/1762] D loss: 1.0438, G loss: 1.6051\n",
      "[964/1762] D loss: 1.3869, G loss: 0.6777\n",
      "[1044/1762] D loss: 1.3866, G loss: 0.7040\n",
      "[1124/1762] D loss: 1.3866, G loss: 0.7025\n",
      "[1204/1762] D loss: 1.0451, G loss: 1.5060\n",
      "[1284/1762] D loss: 1.3879, G loss: 0.7191\n",
      "[1364/1762] D loss: 1.3984, G loss: 0.7401\n",
      "[1444/1762] D loss: 1.3868, G loss: 0.6865\n",
      "[1524/1762] D loss: 1.3791, G loss: 0.7648\n",
      "[1604/1762] D loss: 1.3952, G loss: 0.7502\n",
      "[1684/1762] D loss: 1.3865, G loss: 0.6857\n",
      "[1762/1762] D loss: 1.3866, G loss: 0.7054\n",
      "train error: \n",
      " D loss: 1.287195, G loss: 1.064603, D accuracy: 54.2%, cell accuracy: 99.7%, board accuracy: 90.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.259288, G loss: 1.225964, D accuracy: 55.0%, cell accuracy: 99.6%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6959, G loss: 3.6935\n",
      "[84/1762] D loss: 1.3876, G loss: 0.7159\n",
      "[164/1762] D loss: 1.3935, G loss: 0.6286\n",
      "[244/1762] D loss: 1.3926, G loss: 0.7561\n",
      "[324/1762] D loss: 1.0471, G loss: 1.6831\n",
      "[404/1762] D loss: 1.3866, G loss: 0.7011\n",
      "[484/1762] D loss: 1.0445, G loss: 1.5459\n",
      "[564/1762] D loss: 1.3867, G loss: 0.6937\n",
      "[644/1762] D loss: 1.3866, G loss: 0.6811\n",
      "[724/1762] D loss: 1.3882, G loss: 0.7252\n",
      "[804/1762] D loss: 1.3888, G loss: 0.7461\n",
      "[884/1762] D loss: 1.3878, G loss: 0.7198\n",
      "[964/1762] D loss: 1.3869, G loss: 0.7134\n",
      "[1044/1762] D loss: 1.3866, G loss: 0.6948\n",
      "[1124/1762] D loss: 1.3872, G loss: 0.7215\n",
      "[1204/1762] D loss: 1.3935, G loss: 0.6553\n",
      "[1284/1762] D loss: 1.3868, G loss: 0.6737\n",
      "[1364/1762] D loss: 1.3862, G loss: 0.6901\n",
      "[1444/1762] D loss: 1.3797, G loss: 0.6916\n",
      "[1524/1762] D loss: 1.3866, G loss: 0.6815\n",
      "[1604/1762] D loss: 1.0905, G loss: 0.9716\n",
      "[1684/1762] D loss: 1.3872, G loss: 0.7077\n",
      "[1762/1762] D loss: 1.3875, G loss: 0.7232\n",
      "train error: \n",
      " D loss: 1.284859, G loss: 1.082791, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 89.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.253268, G loss: 1.239375, D accuracy: 55.7%, cell accuracy: 99.6%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6812\n",
      "[84/1762] D loss: 1.0513, G loss: 1.4780\n",
      "[164/1762] D loss: 1.3866, G loss: 0.6799\n",
      "[244/1762] D loss: 1.0413, G loss: 2.3945\n",
      "[324/1762] D loss: 1.3868, G loss: 0.6938\n",
      "[404/1762] D loss: 1.3873, G loss: 0.6664\n",
      "[484/1762] D loss: 1.3866, G loss: 0.6581\n",
      "[564/1762] D loss: 1.3879, G loss: 0.6963\n",
      "[644/1762] D loss: 1.3870, G loss: 0.7060\n",
      "[724/1762] D loss: 1.3829, G loss: 0.6937\n",
      "[804/1762] D loss: 1.3867, G loss: 0.7002\n",
      "[884/1762] D loss: 1.3871, G loss: 0.6912\n",
      "[964/1762] D loss: 1.3685, G loss: 0.7443\n",
      "[1044/1762] D loss: 1.0455, G loss: 1.5117\n",
      "[1124/1762] D loss: 1.3883, G loss: 0.6853\n",
      "[1204/1762] D loss: 1.3908, G loss: 0.6679\n",
      "[1284/1762] D loss: 0.7000, G loss: 2.3840\n",
      "[1364/1762] D loss: 1.3878, G loss: 0.6857\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6852\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.6972\n",
      "[1604/1762] D loss: 1.3865, G loss: 0.6877\n",
      "[1684/1762] D loss: 1.3862, G loss: 0.6982\n",
      "[1762/1762] D loss: 0.7918, G loss: 1.4005\n",
      "train error: \n",
      " D loss: 1.293942, G loss: 0.884853, D accuracy: 53.7%, cell accuracy: 99.7%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.266672, G loss: 0.961174, D accuracy: 55.0%, cell accuracy: 99.7%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3879, G loss: 0.7164\n",
      "[84/1762] D loss: 1.4073, G loss: 0.5869\n",
      "[164/1762] D loss: 1.3868, G loss: 0.6721\n",
      "[244/1762] D loss: 1.3880, G loss: 0.6629\n",
      "[324/1762] D loss: 1.3872, G loss: 0.7001\n",
      "[404/1762] D loss: 1.3871, G loss: 0.6849\n",
      "[484/1762] D loss: 1.3863, G loss: 0.6870\n",
      "[564/1762] D loss: 1.3865, G loss: 0.6982\n",
      "[644/1762] D loss: 1.3867, G loss: 0.6847\n",
      "[724/1762] D loss: 1.0449, G loss: 1.5136\n",
      "[804/1762] D loss: 1.3878, G loss: 0.7096\n",
      "[884/1762] D loss: 1.3485, G loss: 0.7404\n",
      "[964/1762] D loss: 1.3869, G loss: 0.7068\n",
      "[1044/1762] D loss: 1.3866, G loss: 0.6816\n",
      "[1124/1762] D loss: 1.3874, G loss: 0.7001\n",
      "[1204/1762] D loss: 1.0457, G loss: 1.7510\n",
      "[1284/1762] D loss: 1.0892, G loss: 1.4590\n",
      "[1364/1762] D loss: 1.3906, G loss: 0.7492\n",
      "[1444/1762] D loss: 1.3879, G loss: 0.6549\n",
      "[1524/1762] D loss: 1.3838, G loss: 0.6937\n",
      "[1604/1762] D loss: 1.3872, G loss: 0.7033\n",
      "[1684/1762] D loss: 1.3884, G loss: 0.6620\n",
      "[1762/1762] D loss: 0.6934, G loss: 4.5049\n",
      "train error: \n",
      " D loss: 1.287619, G loss: 1.135761, D accuracy: 54.0%, cell accuracy: 99.7%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.261570, G loss: 1.291715, D accuracy: 54.9%, cell accuracy: 99.6%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0368, G loss: 1.4776\n",
      "[84/1762] D loss: 1.3871, G loss: 0.7137\n",
      "[164/1762] D loss: 1.3871, G loss: 0.6737\n",
      "[244/1762] D loss: 1.3867, G loss: 0.6868\n",
      "[324/1762] D loss: 1.0406, G loss: 2.0791\n",
      "[404/1762] D loss: 1.3866, G loss: 0.6965\n",
      "[484/1762] D loss: 1.3854, G loss: 0.6939\n",
      "[564/1762] D loss: 1.3834, G loss: 0.6971\n",
      "[644/1762] D loss: 1.3876, G loss: 0.6733\n",
      "[724/1762] D loss: 1.4138, G loss: 0.5792\n",
      "[804/1762] D loss: 1.3868, G loss: 0.6857\n",
      "[884/1762] D loss: 1.2822, G loss: 1.0328\n",
      "[964/1762] D loss: 1.3864, G loss: 0.6836\n",
      "[1044/1762] D loss: 1.3885, G loss: 0.8368\n",
      "[1124/1762] D loss: 1.3870, G loss: 0.6952\n",
      "[1204/1762] D loss: 1.3317, G loss: 0.8779\n",
      "[1284/1762] D loss: 1.3900, G loss: 0.6751\n",
      "[1364/1762] D loss: 1.3940, G loss: 0.5666\n",
      "[1444/1762] D loss: 1.3984, G loss: 0.6734\n",
      "[1524/1762] D loss: 1.3861, G loss: 0.6950\n",
      "[1604/1762] D loss: 1.3926, G loss: 0.6096\n",
      "[1684/1762] D loss: 1.3167, G loss: 1.8396\n",
      "[1762/1762] D loss: 1.2903, G loss: 0.8241\n",
      "train error: \n",
      " D loss: 1.264485, G loss: 0.797149, D accuracy: 61.3%, cell accuracy: 99.3%, board accuracy: 66.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.236262, G loss: 0.830074, D accuracy: 62.6%, cell accuracy: 99.3%, board accuracy: 64.5% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2468, G loss: 0.9363\n",
      "[84/1762] D loss: 1.1525, G loss: 0.7713\n",
      "[164/1762] D loss: 1.2455, G loss: 1.5413\n",
      "[244/1762] D loss: 1.4082, G loss: 0.5623\n",
      "[324/1762] D loss: 1.3866, G loss: 0.6700\n",
      "[404/1762] D loss: 1.3878, G loss: 0.7203\n",
      "[484/1762] D loss: 1.3697, G loss: 0.7178\n",
      "[564/1762] D loss: 1.3869, G loss: 0.6970\n",
      "[644/1762] D loss: 1.3885, G loss: 0.6961\n",
      "[724/1762] D loss: 1.2778, G loss: 0.8627\n",
      "[804/1762] D loss: 1.4071, G loss: 0.6773\n",
      "[884/1762] D loss: 1.0572, G loss: 1.1772\n",
      "[964/1762] D loss: 1.3897, G loss: 0.6493\n",
      "[1044/1762] D loss: 1.3872, G loss: 0.6574\n",
      "[1124/1762] D loss: 1.4058, G loss: 0.5891\n",
      "[1204/1762] D loss: 1.3921, G loss: 0.7563\n",
      "[1284/1762] D loss: 0.8887, G loss: 2.4831\n",
      "[1364/1762] D loss: 2.3551, G loss: 0.5016\n",
      "[1444/1762] D loss: 1.3867, G loss: 0.6907\n",
      "[1524/1762] D loss: 1.3867, G loss: 0.6733\n",
      "[1604/1762] D loss: 1.3861, G loss: 0.6730\n",
      "[1684/1762] D loss: 1.0658, G loss: 1.2910\n",
      "[1762/1762] D loss: 1.3810, G loss: 0.6680\n",
      "train error: \n",
      " D loss: 1.282031, G loss: 1.061683, D accuracy: 55.3%, cell accuracy: 99.7%, board accuracy: 81.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.275453, G loss: 1.162198, D accuracy: 55.8%, cell accuracy: 99.7%, board accuracy: 80.9% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2292, G loss: 1.1693\n",
      "[84/1762] D loss: 1.0578, G loss: 1.8470\n",
      "[164/1762] D loss: 1.0476, G loss: 1.9146\n",
      "[244/1762] D loss: 1.3869, G loss: 0.6782\n",
      "[324/1762] D loss: 1.3889, G loss: 0.7094\n",
      "[404/1762] D loss: 1.2101, G loss: 1.5308\n",
      "[484/1762] D loss: 1.3919, G loss: 0.6771\n",
      "[564/1762] D loss: 1.3880, G loss: 0.6921\n",
      "[644/1762] D loss: 1.3875, G loss: 0.6589\n",
      "[724/1762] D loss: 1.3888, G loss: 0.6521\n",
      "[804/1762] D loss: 1.0506, G loss: 1.3359\n",
      "[884/1762] D loss: 1.3866, G loss: 0.6823\n",
      "[964/1762] D loss: 1.0504, G loss: 1.6070\n",
      "[1044/1762] D loss: 1.3865, G loss: 0.6934\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.6924\n",
      "[1204/1762] D loss: 1.3862, G loss: 0.6935\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6913\n",
      "[1364/1762] D loss: 1.3865, G loss: 0.6897\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6942\n",
      "[1524/1762] D loss: 1.3796, G loss: 0.6906\n",
      "[1604/1762] D loss: 1.3867, G loss: 0.6770\n",
      "[1684/1762] D loss: 1.3874, G loss: 0.6983\n",
      "[1762/1762] D loss: 1.3918, G loss: 0.6515\n",
      "train error: \n",
      " D loss: 1.294263, G loss: 0.955360, D accuracy: 54.0%, cell accuracy: 99.7%, board accuracy: 81.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.265674, G loss: 1.035282, D accuracy: 55.7%, cell accuracy: 99.6%, board accuracy: 81.6% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3858, G loss: 0.7315\n",
      "[84/1762] D loss: 1.0411, G loss: 1.9674\n",
      "[164/1762] D loss: 1.2996, G loss: 0.8730\n",
      "[244/1762] D loss: 1.3986, G loss: 0.6104\n",
      "[324/1762] D loss: 1.3895, G loss: 0.6775\n",
      "[404/1762] D loss: 1.4000, G loss: 0.6021\n",
      "[484/1762] D loss: 1.3901, G loss: 0.6513\n",
      "[564/1762] D loss: 1.3860, G loss: 0.7075\n",
      "[644/1762] D loss: 1.0621, G loss: 1.8781\n",
      "[724/1762] D loss: 1.0541, G loss: 1.8828\n",
      "[804/1762] D loss: 1.3878, G loss: 0.6984\n",
      "[884/1762] D loss: 1.0459, G loss: 1.5340\n",
      "[964/1762] D loss: 1.3881, G loss: 0.6825\n",
      "[1044/1762] D loss: 1.2860, G loss: 0.8674\n",
      "[1124/1762] D loss: 1.3860, G loss: 0.6840\n",
      "[1204/1762] D loss: 1.2901, G loss: 1.1076\n",
      "[1284/1762] D loss: 1.3878, G loss: 0.7066\n",
      "[1364/1762] D loss: 1.0500, G loss: 1.9729\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.6999\n",
      "[1524/1762] D loss: 1.0728, G loss: 1.0488\n",
      "[1604/1762] D loss: 1.3885, G loss: 0.6319\n",
      "[1684/1762] D loss: 1.2089, G loss: 1.1185\n",
      "[1762/1762] D loss: 1.3885, G loss: 0.7217\n",
      "train error: \n",
      " D loss: 1.289986, G loss: 1.232396, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 89.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.279078, G loss: 1.486038, D accuracy: 55.3%, cell accuracy: 99.7%, board accuracy: 87.0% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0425, G loss: 2.0263\n",
      "[84/1762] D loss: 1.2358, G loss: 1.3220\n",
      "[164/1762] D loss: 1.0230, G loss: 3.5758\n",
      "[244/1762] D loss: 1.0098, G loss: 1.0793\n",
      "[324/1762] D loss: 1.0448, G loss: 2.2266\n",
      "[404/1762] D loss: 0.6116, G loss: 3.2580\n",
      "[484/1762] D loss: 1.2676, G loss: 0.9572\n",
      "[564/1762] D loss: 1.3867, G loss: 0.6898\n",
      "[644/1762] D loss: 1.3909, G loss: 0.6292\n",
      "[724/1762] D loss: 1.3875, G loss: 0.6763\n",
      "[804/1762] D loss: 1.3865, G loss: 0.6975\n",
      "[884/1762] D loss: 1.3880, G loss: 0.6822\n",
      "[964/1762] D loss: 1.3890, G loss: 0.7374\n",
      "[1044/1762] D loss: 1.3901, G loss: 0.6950\n",
      "[1124/1762] D loss: 1.3938, G loss: 0.6816\n",
      "[1204/1762] D loss: 1.3879, G loss: 0.6606\n",
      "[1284/1762] D loss: 1.3869, G loss: 0.6683\n",
      "[1364/1762] D loss: 1.3872, G loss: 0.6657\n",
      "[1444/1762] D loss: 1.3877, G loss: 0.9088\n",
      "[1524/1762] D loss: 1.3927, G loss: 0.6950\n",
      "[1604/1762] D loss: 1.0044, G loss: 1.8756\n",
      "[1684/1762] D loss: 1.0499, G loss: 1.7326\n",
      "[1762/1762] D loss: 1.4060, G loss: 0.7798\n",
      "train error: \n",
      " D loss: 1.296547, G loss: 0.867568, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 81.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.270876, G loss: 0.920104, D accuracy: 55.3%, cell accuracy: 99.7%, board accuracy: 78.4% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3662, G loss: 0.7056\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6946\n",
      "[164/1762] D loss: 1.3610, G loss: 0.7325\n",
      "[244/1762] D loss: 1.3425, G loss: 0.6607\n",
      "[324/1762] D loss: 1.3876, G loss: 0.6618\n",
      "[404/1762] D loss: 1.3953, G loss: 0.6912\n",
      "[484/1762] D loss: 1.3891, G loss: 0.6322\n",
      "[564/1762] D loss: 1.3874, G loss: 0.7041\n",
      "[644/1762] D loss: 1.3866, G loss: 0.6783\n",
      "[724/1762] D loss: 1.3881, G loss: 0.7273\n",
      "[804/1762] D loss: 1.3876, G loss: 0.6675\n",
      "[884/1762] D loss: 1.3879, G loss: 0.6813\n",
      "[964/1762] D loss: 1.3901, G loss: 0.7164\n",
      "[1044/1762] D loss: 1.3899, G loss: 0.7052\n",
      "[1124/1762] D loss: 1.3869, G loss: 0.6893\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6917\n",
      "[1284/1762] D loss: 0.9401, G loss: 2.1407\n",
      "[1364/1762] D loss: 1.3899, G loss: 0.7347\n",
      "[1444/1762] D loss: 1.3869, G loss: 0.6685\n",
      "[1524/1762] D loss: 1.3962, G loss: 0.7521\n",
      "[1604/1762] D loss: 1.2041, G loss: 1.9764\n",
      "[1684/1762] D loss: 1.2743, G loss: 0.8882\n",
      "[1762/1762] D loss: 1.3939, G loss: 0.6223\n",
      "train error: \n",
      " D loss: 1.255331, G loss: 1.278059, D accuracy: 57.4%, cell accuracy: 99.8%, board accuracy: 84.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.226692, G loss: 1.410705, D accuracy: 59.0%, cell accuracy: 99.7%, board accuracy: 81.4% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3886, G loss: 0.6495\n",
      "[84/1762] D loss: 0.8807, G loss: 2.7297\n",
      "[164/1762] D loss: 1.3887, G loss: 0.7213\n",
      "[244/1762] D loss: 1.3894, G loss: 0.6815\n",
      "[324/1762] D loss: 1.3880, G loss: 0.6583\n",
      "[404/1762] D loss: 0.8929, G loss: 2.4669\n",
      "[484/1762] D loss: 1.3852, G loss: 0.6640\n",
      "[564/1762] D loss: 1.3887, G loss: 0.6855\n",
      "[644/1762] D loss: 1.4084, G loss: 0.5560\n",
      "[724/1762] D loss: 1.2767, G loss: 0.8136\n",
      "[804/1762] D loss: 0.8152, G loss: 3.0574\n",
      "[884/1762] D loss: 1.4099, G loss: 0.5725\n",
      "[964/1762] D loss: 1.3902, G loss: 0.7548\n",
      "[1044/1762] D loss: 1.0409, G loss: 2.1346\n",
      "[1124/1762] D loss: 0.7991, G loss: 2.1465\n",
      "[1204/1762] D loss: 1.3880, G loss: 0.6594\n",
      "[1284/1762] D loss: 1.4136, G loss: 0.7543\n",
      "[1364/1762] D loss: 1.3986, G loss: 0.6604\n",
      "[1444/1762] D loss: 1.1106, G loss: 0.9435\n",
      "[1524/1762] D loss: 1.0412, G loss: 3.0237\n",
      "[1604/1762] D loss: 1.0408, G loss: 2.7248\n",
      "[1684/1762] D loss: 1.0620, G loss: 1.1616\n",
      "[1762/1762] D loss: 1.3866, G loss: 0.7207\n",
      "train error: \n",
      " D loss: 1.294884, G loss: 0.963482, D accuracy: 53.7%, cell accuracy: 99.7%, board accuracy: 75.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.268189, G loss: 1.060179, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 76.1% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0848, G loss: 1.0099\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6996\n",
      "[164/1762] D loss: 1.3880, G loss: 0.6664\n",
      "[244/1762] D loss: 1.3865, G loss: 0.7209\n",
      "[324/1762] D loss: 1.0474, G loss: 2.0816\n",
      "[404/1762] D loss: 1.3870, G loss: 0.6774\n",
      "[484/1762] D loss: 1.3829, G loss: 0.6897\n",
      "[564/1762] D loss: 1.0401, G loss: 2.5821\n",
      "[644/1762] D loss: 1.3747, G loss: 0.7021\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6883\n",
      "[804/1762] D loss: 1.3871, G loss: 0.6832\n",
      "[884/1762] D loss: 1.3920, G loss: 0.7136\n",
      "[964/1762] D loss: 1.3867, G loss: 0.6951\n",
      "[1044/1762] D loss: 1.0406, G loss: 2.7038\n",
      "[1124/1762] D loss: 1.2813, G loss: 0.9664\n",
      "[1204/1762] D loss: 1.3887, G loss: 0.6695\n",
      "[1284/1762] D loss: 1.3894, G loss: 0.6444\n",
      "[1364/1762] D loss: 1.3884, G loss: 0.6885\n",
      "[1444/1762] D loss: 1.0410, G loss: 1.5698\n",
      "[1524/1762] D loss: 1.3875, G loss: 0.6984\n",
      "[1604/1762] D loss: 1.3886, G loss: 0.7263\n",
      "[1684/1762] D loss: 1.0399, G loss: 3.2688\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.6810\n",
      "train error: \n",
      " D loss: 1.289600, G loss: 1.111174, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 89.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.268525, G loss: 1.257417, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3866, G loss: 0.6770\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6834\n",
      "[164/1762] D loss: 1.3867, G loss: 0.6900\n",
      "[244/1762] D loss: 1.3866, G loss: 0.6914\n",
      "[324/1762] D loss: 1.3867, G loss: 0.6901\n",
      "[404/1762] D loss: 1.0402, G loss: 2.3335\n",
      "[484/1762] D loss: 1.3860, G loss: 0.6986\n",
      "[564/1762] D loss: 0.6896, G loss: 3.9679\n",
      "[644/1762] D loss: 1.0396, G loss: 2.3948\n",
      "[724/1762] D loss: 1.3860, G loss: 0.6987\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6853\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6920\n",
      "[964/1762] D loss: 1.3898, G loss: 0.6862\n",
      "[1044/1762] D loss: 1.2740, G loss: 1.1281\n",
      "[1124/1762] D loss: 1.3948, G loss: 0.6326\n",
      "[1204/1762] D loss: 1.3865, G loss: 0.6879\n",
      "[1284/1762] D loss: 1.3865, G loss: 0.6979\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6926\n",
      "[1444/1762] D loss: 1.0403, G loss: 2.6542\n",
      "[1524/1762] D loss: 1.0445, G loss: 1.5565\n",
      "[1604/1762] D loss: 1.3854, G loss: 0.6964\n",
      "[1684/1762] D loss: 1.3869, G loss: 0.6845\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6978\n",
      "train error: \n",
      " D loss: 1.295572, G loss: 0.975855, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 90.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.267618, G loss: 1.071614, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0411, G loss: 1.9207\n",
      "[84/1762] D loss: 1.0412, G loss: 1.9267\n",
      "[164/1762] D loss: 1.2076, G loss: 0.6992\n",
      "[244/1762] D loss: 1.3864, G loss: 0.6921\n",
      "[324/1762] D loss: 1.0402, G loss: 2.1300\n",
      "[404/1762] D loss: 1.0399, G loss: 2.7493\n",
      "[484/1762] D loss: 1.3864, G loss: 0.7019\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6989\n",
      "[644/1762] D loss: 1.3864, G loss: 0.6975\n",
      "[724/1762] D loss: 1.0403, G loss: 2.3611\n",
      "[804/1762] D loss: 1.3866, G loss: 0.6846\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6908\n",
      "[964/1762] D loss: 1.0401, G loss: 2.4145\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6919\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6877\n",
      "[1204/1762] D loss: 1.3875, G loss: 0.7064\n",
      "[1284/1762] D loss: 1.4087, G loss: 0.8189\n",
      "[1364/1762] D loss: 1.3066, G loss: 0.8039\n",
      "[1444/1762] D loss: 1.3872, G loss: 0.7234\n",
      "[1524/1762] D loss: 1.3873, G loss: 0.7170\n",
      "[1604/1762] D loss: 1.4036, G loss: 0.6925\n",
      "[1684/1762] D loss: 1.3891, G loss: 0.6555\n",
      "[1762/1762] D loss: 1.3862, G loss: 0.7001\n",
      "train error: \n",
      " D loss: 1.288786, G loss: 0.985104, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 90.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.262112, G loss: 1.069130, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3865, G loss: 0.7077\n",
      "[84/1762] D loss: 1.3867, G loss: 0.6990\n",
      "[164/1762] D loss: 1.0404, G loss: 1.9439\n",
      "[244/1762] D loss: 1.3864, G loss: 0.6933\n",
      "[324/1762] D loss: 1.3864, G loss: 0.7001\n",
      "[404/1762] D loss: 1.2062, G loss: 1.0448\n",
      "[484/1762] D loss: 1.0369, G loss: 4.9352\n",
      "[564/1762] D loss: 1.4017, G loss: 0.5806\n",
      "[644/1762] D loss: 1.3904, G loss: 0.6340\n",
      "[724/1762] D loss: 1.0414, G loss: 2.2028\n",
      "[804/1762] D loss: 1.3731, G loss: 0.7016\n",
      "[884/1762] D loss: 1.4686, G loss: 0.8053\n",
      "[964/1762] D loss: 1.3887, G loss: 0.6586\n",
      "[1044/1762] D loss: 1.3837, G loss: 0.6940\n",
      "[1124/1762] D loss: 1.3553, G loss: 0.7085\n",
      "[1204/1762] D loss: 1.3729, G loss: 0.6686\n",
      "[1284/1762] D loss: 1.1651, G loss: 0.7777\n",
      "[1364/1762] D loss: 1.3628, G loss: 0.6952\n",
      "[1444/1762] D loss: 0.6957, G loss: 4.8832\n",
      "[1524/1762] D loss: 0.9341, G loss: 3.0801\n",
      "[1604/1762] D loss: 1.3929, G loss: 0.7651\n",
      "[1684/1762] D loss: 1.0502, G loss: 1.5587\n",
      "[1762/1762] D loss: 1.3874, G loss: 0.6481\n",
      "train error: \n",
      " D loss: 1.283827, G loss: 1.007133, D accuracy: 55.4%, cell accuracy: 99.6%, board accuracy: 73.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.249039, G loss: 1.123726, D accuracy: 56.9%, cell accuracy: 99.6%, board accuracy: 70.5% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3895, G loss: 0.6606\n",
      "[84/1762] D loss: 1.0730, G loss: 1.4097\n",
      "[164/1762] D loss: 1.3887, G loss: 0.7386\n",
      "[244/1762] D loss: 1.0682, G loss: 1.1169\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6792\n",
      "[404/1762] D loss: 1.3834, G loss: 0.6808\n",
      "[484/1762] D loss: 1.3880, G loss: 0.7081\n",
      "[564/1762] D loss: 1.3817, G loss: 0.7109\n",
      "[644/1762] D loss: 1.3156, G loss: 0.8044\n",
      "[724/1762] D loss: 1.3870, G loss: 0.7137\n",
      "[804/1762] D loss: 1.3475, G loss: 0.6886\n",
      "[884/1762] D loss: 1.0358, G loss: 2.8818\n",
      "[964/1762] D loss: 1.0829, G loss: 1.0506\n",
      "[1044/1762] D loss: 1.3878, G loss: 0.6940\n",
      "[1124/1762] D loss: 1.3872, G loss: 0.6716\n",
      "[1204/1762] D loss: 1.3876, G loss: 0.6873\n",
      "[1284/1762] D loss: 1.3903, G loss: 0.7085\n",
      "[1364/1762] D loss: 1.3923, G loss: 0.6586\n",
      "[1444/1762] D loss: 1.3890, G loss: 0.6875\n",
      "[1524/1762] D loss: 1.3923, G loss: 0.6342\n",
      "[1604/1762] D loss: 1.3966, G loss: 0.7431\n",
      "[1684/1762] D loss: 1.3880, G loss: 0.7018\n",
      "[1762/1762] D loss: 1.3842, G loss: 0.6905\n",
      "train error: \n",
      " D loss: 1.306356, G loss: 0.984417, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 89.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.270254, G loss: 1.122900, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3881, G loss: 0.7190\n",
      "[84/1762] D loss: 1.3916, G loss: 0.6557\n",
      "[164/1762] D loss: 1.3868, G loss: 0.6971\n",
      "[244/1762] D loss: 1.3903, G loss: 0.7143\n",
      "[324/1762] D loss: 1.3891, G loss: 0.6974\n",
      "[404/1762] D loss: 1.0424, G loss: 1.7522\n",
      "[484/1762] D loss: 1.3879, G loss: 0.6579\n",
      "[564/1762] D loss: 1.2911, G loss: 1.8444\n",
      "[644/1762] D loss: 1.3902, G loss: 0.6306\n",
      "[724/1762] D loss: 1.3840, G loss: 0.6184\n",
      "[804/1762] D loss: 1.0108, G loss: 1.2764\n",
      "[884/1762] D loss: 1.3855, G loss: 0.6055\n",
      "[964/1762] D loss: 1.8284, G loss: 1.6738\n",
      "[1044/1762] D loss: 1.3912, G loss: 0.6312\n",
      "[1124/1762] D loss: 0.7017, G loss: 4.2779\n",
      "[1204/1762] D loss: 1.3862, G loss: 0.7087\n",
      "[1284/1762] D loss: 1.3657, G loss: 0.7259\n",
      "[1364/1762] D loss: 1.1153, G loss: 0.8916\n",
      "[1444/1762] D loss: 1.3875, G loss: 0.7204\n",
      "[1524/1762] D loss: 1.0738, G loss: 1.2186\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6962\n",
      "[1684/1762] D loss: 1.3908, G loss: 0.6719\n",
      "[1762/1762] D loss: 1.3910, G loss: 0.6356\n",
      "train error: \n",
      " D loss: 1.301855, G loss: 0.835120, D accuracy: 54.1%, cell accuracy: 99.9%, board accuracy: 90.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.289856, G loss: 0.846053, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3893, G loss: 0.6461\n",
      "[84/1762] D loss: 1.3880, G loss: 0.6646\n",
      "[164/1762] D loss: 1.3873, G loss: 0.6779\n",
      "[244/1762] D loss: 1.3033, G loss: 0.6505\n",
      "[324/1762] D loss: 1.0411, G loss: 2.0759\n",
      "[404/1762] D loss: 1.1140, G loss: 0.8560\n",
      "[484/1762] D loss: 1.3883, G loss: 0.7226\n",
      "[564/1762] D loss: 1.3892, G loss: 0.6914\n",
      "[644/1762] D loss: 1.3899, G loss: 0.6440\n",
      "[724/1762] D loss: 1.2352, G loss: 1.4903\n",
      "[804/1762] D loss: 1.0489, G loss: 1.9560\n",
      "[884/1762] D loss: 3.8440, G loss: 0.4855\n",
      "[964/1762] D loss: 1.2282, G loss: 1.8866\n",
      "[1044/1762] D loss: 1.3884, G loss: 0.6543\n",
      "[1124/1762] D loss: 1.3780, G loss: 0.7386\n",
      "[1204/1762] D loss: 1.3866, G loss: 0.7062\n",
      "[1284/1762] D loss: 1.2584, G loss: 0.7114\n",
      "[1364/1762] D loss: 1.3885, G loss: 0.6650\n",
      "[1444/1762] D loss: 1.3884, G loss: 0.6534\n",
      "[1524/1762] D loss: 1.5949, G loss: 0.5782\n",
      "[1604/1762] D loss: 1.2865, G loss: 0.6691\n",
      "[1684/1762] D loss: 1.3878, G loss: 0.7414\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.7058\n",
      "train error: \n",
      " D loss: 1.324005, G loss: 0.820410, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 83.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.313301, G loss: 0.831738, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 82.5% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1826, G loss: 1.3107\n",
      "[84/1762] D loss: 1.3679, G loss: 0.6528\n",
      "[164/1762] D loss: 1.3903, G loss: 0.7041\n",
      "[244/1762] D loss: 1.3803, G loss: 0.6437\n",
      "[324/1762] D loss: 1.3924, G loss: 0.6389\n",
      "[404/1762] D loss: 1.3872, G loss: 0.6760\n",
      "[484/1762] D loss: 1.4873, G loss: 1.7767\n",
      "[564/1762] D loss: 1.3866, G loss: 0.6857\n",
      "[644/1762] D loss: 1.3862, G loss: 0.6760\n",
      "[724/1762] D loss: 1.3455, G loss: 0.7233\n",
      "[804/1762] D loss: 1.3865, G loss: 0.7022\n",
      "[884/1762] D loss: 1.2234, G loss: 0.7503\n",
      "[964/1762] D loss: 1.3046, G loss: 0.8473\n",
      "[1044/1762] D loss: 1.3868, G loss: 0.6723\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.6946\n",
      "[1204/1762] D loss: 1.3868, G loss: 0.6810\n",
      "[1284/1762] D loss: 1.3869, G loss: 0.6774\n",
      "[1364/1762] D loss: 1.1885, G loss: 1.6812\n",
      "[1444/1762] D loss: 1.3894, G loss: 0.6849\n",
      "[1524/1762] D loss: 1.0732, G loss: 2.1114\n",
      "[1604/1762] D loss: 1.3875, G loss: 0.6662\n",
      "[1684/1762] D loss: 1.4136, G loss: 0.6589\n",
      "[1762/1762] D loss: 0.8333, G loss: 1.4120\n",
      "train error: \n",
      " D loss: 1.349088, G loss: 0.744411, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 89.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.347670, G loss: 0.737367, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4199, G loss: 0.7395\n",
      "[84/1762] D loss: 1.2653, G loss: 0.9852\n",
      "[164/1762] D loss: 1.4533, G loss: 0.9048\n",
      "[244/1762] D loss: 1.1099, G loss: 0.8760\n",
      "[324/1762] D loss: 1.3868, G loss: 0.6939\n",
      "[404/1762] D loss: 1.2379, G loss: 1.1176\n",
      "[484/1762] D loss: 1.1249, G loss: 0.8366\n",
      "[564/1762] D loss: 1.3862, G loss: 0.8031\n",
      "[644/1762] D loss: 1.3879, G loss: 0.6606\n",
      "[724/1762] D loss: 1.3870, G loss: 0.6899\n",
      "[804/1762] D loss: 1.3869, G loss: 0.6973\n",
      "[884/1762] D loss: 1.3871, G loss: 0.6768\n",
      "[964/1762] D loss: 1.1322, G loss: 0.8637\n",
      "[1044/1762] D loss: 1.3867, G loss: 0.6982\n",
      "[1124/1762] D loss: 1.3918, G loss: 0.7577\n",
      "[1204/1762] D loss: 0.7655, G loss: 1.3689\n",
      "[1284/1762] D loss: 1.3883, G loss: 0.6728\n",
      "[1364/1762] D loss: 1.3868, G loss: 0.6763\n",
      "[1444/1762] D loss: 1.3879, G loss: 0.6908\n",
      "[1524/1762] D loss: 1.3874, G loss: 0.7003\n",
      "[1604/1762] D loss: 1.3866, G loss: 0.7043\n",
      "[1684/1762] D loss: 1.0778, G loss: 1.1199\n",
      "[1762/1762] D loss: 1.3870, G loss: 0.6712\n",
      "train error: \n",
      " D loss: 1.310440, G loss: 0.799282, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.299428, G loss: 0.842130, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0778, G loss: 1.0012\n",
      "[84/1762] D loss: 1.3865, G loss: 0.6921\n",
      "[164/1762] D loss: 1.3865, G loss: 0.6724\n",
      "[244/1762] D loss: 1.3164, G loss: 0.7699\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6955\n",
      "[404/1762] D loss: 1.3865, G loss: 0.6888\n",
      "[484/1762] D loss: 1.3866, G loss: 0.7097\n",
      "[564/1762] D loss: 1.3862, G loss: 0.6691\n",
      "[644/1762] D loss: 1.3868, G loss: 0.6990\n",
      "[724/1762] D loss: 1.3895, G loss: 0.7244\n",
      "[804/1762] D loss: 1.3877, G loss: 0.6674\n",
      "[884/1762] D loss: 1.3878, G loss: 0.6996\n",
      "[964/1762] D loss: 1.1148, G loss: 0.8882\n",
      "[1044/1762] D loss: 1.3870, G loss: 0.6991\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6912\n",
      "[1204/1762] D loss: 1.3873, G loss: 0.6963\n",
      "[1284/1762] D loss: 1.1155, G loss: 0.8576\n",
      "[1364/1762] D loss: 1.2153, G loss: 1.5963\n",
      "[1444/1762] D loss: 1.2098, G loss: 3.1500\n",
      "[1524/1762] D loss: 1.1084, G loss: 0.8811\n",
      "[1604/1762] D loss: 1.2595, G loss: 0.9293\n",
      "[1684/1762] D loss: 1.3878, G loss: 0.6803\n",
      "[1762/1762] D loss: 1.3880, G loss: 0.6551\n",
      "train error: \n",
      " D loss: 1.326415, G loss: 0.862651, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 85.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.310064, G loss: 0.909513, D accuracy: 55.7%, cell accuracy: 99.8%, board accuracy: 82.7% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2148, G loss: 1.4987\n",
      "[84/1762] D loss: 1.3877, G loss: 0.6677\n",
      "[164/1762] D loss: 1.2231, G loss: 1.2858\n",
      "[244/1762] D loss: 1.1328, G loss: 0.8229\n",
      "[324/1762] D loss: 1.3867, G loss: 0.6889\n",
      "[404/1762] D loss: 1.3866, G loss: 0.7007\n",
      "[484/1762] D loss: 1.3868, G loss: 0.6756\n",
      "[564/1762] D loss: 0.9275, G loss: 0.8794\n",
      "[644/1762] D loss: 1.3960, G loss: 0.8228\n",
      "[724/1762] D loss: 1.4335, G loss: 0.8297\n",
      "[804/1762] D loss: 1.3866, G loss: 0.6804\n",
      "[884/1762] D loss: 1.3865, G loss: 0.7041\n",
      "[964/1762] D loss: 1.4462, G loss: 0.8340\n",
      "[1044/1762] D loss: 1.4650, G loss: 0.5938\n",
      "[1124/1762] D loss: 1.0925, G loss: 1.0765\n",
      "[1204/1762] D loss: 1.3878, G loss: 0.6537\n",
      "[1284/1762] D loss: 1.2381, G loss: 1.0340\n",
      "[1364/1762] D loss: 1.3866, G loss: 0.6783\n",
      "[1444/1762] D loss: 1.3876, G loss: 0.6693\n",
      "[1524/1762] D loss: 1.3806, G loss: 0.8751\n",
      "[1604/1762] D loss: 1.1242, G loss: 0.8396\n",
      "[1684/1762] D loss: 1.3872, G loss: 0.6889\n",
      "[1762/1762] D loss: 1.3862, G loss: 0.6865\n",
      "train error: \n",
      " D loss: 1.335583, G loss: 0.766811, D accuracy: 52.9%, cell accuracy: 99.9%, board accuracy: 88.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.320088, G loss: 0.789986, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 85.9% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1219, G loss: 0.8512\n",
      "[84/1762] D loss: 1.3871, G loss: 0.6778\n",
      "[164/1762] D loss: 1.1425, G loss: 0.8383\n",
      "[244/1762] D loss: 1.3937, G loss: 0.6714\n",
      "[324/1762] D loss: 1.3929, G loss: 0.6181\n",
      "[404/1762] D loss: 1.4047, G loss: 0.5657\n",
      "[484/1762] D loss: 1.2613, G loss: 0.6708\n",
      "[564/1762] D loss: 0.9755, G loss: 1.1637\n",
      "[644/1762] D loss: 1.3867, G loss: 0.6770\n",
      "[724/1762] D loss: 1.3947, G loss: 0.6706\n",
      "[804/1762] D loss: 1.3947, G loss: 0.7387\n",
      "[884/1762] D loss: 1.0593, G loss: 1.1001\n",
      "[964/1762] D loss: 1.3891, G loss: 0.6789\n",
      "[1044/1762] D loss: 1.0436, G loss: 1.7109\n",
      "[1124/1762] D loss: 1.2678, G loss: 0.7929\n",
      "[1204/1762] D loss: 1.3839, G loss: 0.7306\n",
      "[1284/1762] D loss: 0.7395, G loss: 2.2037\n",
      "[1364/1762] D loss: 1.3893, G loss: 0.6605\n",
      "[1444/1762] D loss: 1.3866, G loss: 0.7039\n",
      "[1524/1762] D loss: 1.3887, G loss: 0.7224\n",
      "[1604/1762] D loss: 1.2850, G loss: 0.8095\n",
      "[1684/1762] D loss: 1.0412, G loss: 2.0560\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.7069\n",
      "train error: \n",
      " D loss: 1.282686, G loss: 1.073137, D accuracy: 54.1%, cell accuracy: 99.9%, board accuracy: 90.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.254290, G loss: 1.171101, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3840, G loss: 0.7026\n",
      "[84/1762] D loss: 1.3882, G loss: 0.6607\n",
      "[164/1762] D loss: 1.0408, G loss: 5.1022\n",
      "[244/1762] D loss: 1.3888, G loss: 0.6493\n",
      "[324/1762] D loss: 1.3866, G loss: 0.6894\n",
      "[404/1762] D loss: 1.3871, G loss: 0.6709\n",
      "[484/1762] D loss: 1.3874, G loss: 0.7046\n",
      "[564/1762] D loss: 1.0538, G loss: 2.0531\n",
      "[644/1762] D loss: 1.3917, G loss: 0.6610\n",
      "[724/1762] D loss: 1.3866, G loss: 0.6816\n",
      "[804/1762] D loss: 1.3873, G loss: 0.6711\n",
      "[884/1762] D loss: 0.6954, G loss: 4.5998\n",
      "[964/1762] D loss: 1.0416, G loss: 4.1393\n",
      "[1044/1762] D loss: 1.3865, G loss: 0.6852\n",
      "[1124/1762] D loss: 1.3711, G loss: 0.6945\n",
      "[1204/1762] D loss: 1.0431, G loss: 2.2088\n",
      "[1284/1762] D loss: 1.3862, G loss: 0.6751\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6939\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6924\n",
      "[1524/1762] D loss: 1.0417, G loss: 2.2948\n",
      "[1604/1762] D loss: 1.3882, G loss: 0.6595\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6921\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6915\n",
      "train error: \n",
      " D loss: 1.236630, G loss: 1.465522, D accuracy: 57.5%, cell accuracy: 99.7%, board accuracy: 82.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.209416, G loss: 1.602853, D accuracy: 58.1%, cell accuracy: 99.7%, board accuracy: 81.1% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0405, G loss: 2.0355\n",
      "[84/1762] D loss: 1.3875, G loss: 0.6702\n",
      "[164/1762] D loss: 1.2699, G loss: 0.9183\n",
      "[244/1762] D loss: 1.3893, G loss: 0.6464\n",
      "[324/1762] D loss: 1.3876, G loss: 0.6882\n",
      "[404/1762] D loss: 1.3898, G loss: 0.6436\n",
      "[484/1762] D loss: 1.3870, G loss: 0.6808\n",
      "[564/1762] D loss: 1.3870, G loss: 0.6766\n",
      "[644/1762] D loss: 1.3876, G loss: 0.6642\n",
      "[724/1762] D loss: 1.3877, G loss: 0.6638\n",
      "[804/1762] D loss: 1.3867, G loss: 0.6846\n",
      "[884/1762] D loss: 1.0412, G loss: 2.1446\n",
      "[964/1762] D loss: 1.4383, G loss: 0.6909\n",
      "[1044/1762] D loss: 1.3862, G loss: 0.6899\n",
      "[1124/1762] D loss: 1.2240, G loss: 1.4978\n",
      "[1204/1762] D loss: 1.3829, G loss: 0.6688\n",
      "[1284/1762] D loss: 0.9749, G loss: 4.7027\n",
      "[1364/1762] D loss: 0.8784, G loss: 3.7658\n",
      "[1444/1762] D loss: 1.3877, G loss: 0.6851\n",
      "[1524/1762] D loss: 1.3868, G loss: 0.6781\n",
      "[1604/1762] D loss: 1.1994, G loss: 0.8451\n",
      "[1684/1762] D loss: 1.3873, G loss: 0.6997\n",
      "[1762/1762] D loss: 1.3870, G loss: 0.6850\n",
      "train error: \n",
      " D loss: 1.286300, G loss: 1.210444, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.255930, G loss: 1.417988, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3873, G loss: 0.6765\n",
      "[84/1762] D loss: 1.3865, G loss: 0.6866\n",
      "[164/1762] D loss: 1.3864, G loss: 0.6896\n",
      "[244/1762] D loss: 1.0403, G loss: 2.2866\n",
      "[324/1762] D loss: 1.0400, G loss: 2.3884\n",
      "[404/1762] D loss: 1.3866, G loss: 0.6862\n",
      "[484/1762] D loss: 1.3865, G loss: 0.6844\n",
      "[564/1762] D loss: 1.3263, G loss: 0.8128\n",
      "[644/1762] D loss: 1.0408, G loss: 2.2886\n",
      "[724/1762] D loss: 1.2167, G loss: 1.4988\n",
      "[804/1762] D loss: 1.3865, G loss: 0.6865\n",
      "[884/1762] D loss: 1.3785, G loss: 0.6974\n",
      "[964/1762] D loss: 1.3883, G loss: 0.6558\n",
      "[1044/1762] D loss: 1.3870, G loss: 0.6837\n",
      "[1124/1762] D loss: 1.3869, G loss: 0.6920\n",
      "[1204/1762] D loss: 1.3875, G loss: 0.6590\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6900\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6895\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.7024\n",
      "[1524/1762] D loss: 1.0399, G loss: 2.4546\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.7005\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6863\n",
      "[1762/1762] D loss: 0.6934, G loss: 4.6979\n",
      "train error: \n",
      " D loss: 1.284826, G loss: 1.237585, D accuracy: 54.2%, cell accuracy: 99.9%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.255543, G loss: 1.407056, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6948, G loss: 4.2412\n",
      "[84/1762] D loss: 1.3862, G loss: 0.6926\n",
      "[164/1762] D loss: 1.2750, G loss: 0.8680\n",
      "[244/1762] D loss: 1.3884, G loss: 0.6970\n",
      "[324/1762] D loss: 0.9354, G loss: 3.1498\n",
      "[404/1762] D loss: 1.3865, G loss: 0.6866\n",
      "[484/1762] D loss: 1.3870, G loss: 0.6750\n",
      "[564/1762] D loss: 1.3867, G loss: 0.6881\n",
      "[644/1762] D loss: 1.3869, G loss: 0.6841\n",
      "[724/1762] D loss: 1.0391, G loss: 2.6588\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6841\n",
      "[884/1762] D loss: 1.0400, G loss: 2.6067\n",
      "[964/1762] D loss: 1.3865, G loss: 0.7004\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6941\n",
      "[1124/1762] D loss: 1.3892, G loss: 0.6576\n",
      "[1204/1762] D loss: 1.3865, G loss: 0.6950\n",
      "[1284/1762] D loss: 1.3875, G loss: 0.7190\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6858\n",
      "[1444/1762] D loss: 1.0400, G loss: 2.7056\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.6900\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6875\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6863\n",
      "[1762/1762] D loss: 1.3826, G loss: 0.9367\n",
      "train error: \n",
      " D loss: 1.289178, G loss: 1.098774, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.261637, G loss: 1.203895, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6993\n",
      "[84/1762] D loss: 1.0404, G loss: 2.1062\n",
      "[164/1762] D loss: 1.3864, G loss: 0.6984\n",
      "[244/1762] D loss: 1.0401, G loss: 2.2476\n",
      "[324/1762] D loss: 1.3865, G loss: 0.6981\n",
      "[404/1762] D loss: 1.3864, G loss: 0.7003\n",
      "[484/1762] D loss: 1.0403, G loss: 2.0803\n",
      "[564/1762] D loss: 1.3866, G loss: 0.6909\n",
      "[644/1762] D loss: 1.3866, G loss: 0.6789\n",
      "[724/1762] D loss: 1.0532, G loss: 1.4219\n",
      "[804/1762] D loss: 1.2329, G loss: 1.0950\n",
      "[884/1762] D loss: 1.0405, G loss: 2.6568\n",
      "[964/1762] D loss: 1.3862, G loss: 0.6994\n",
      "[1044/1762] D loss: 1.3865, G loss: 0.6945\n",
      "[1124/1762] D loss: 1.3889, G loss: 0.6470\n",
      "[1204/1762] D loss: 1.0393, G loss: 2.1222\n",
      "[1284/1762] D loss: 1.3855, G loss: 0.6970\n",
      "[1364/1762] D loss: 1.1713, G loss: 0.7624\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.7004\n",
      "[1524/1762] D loss: 1.3862, G loss: 0.6853\n",
      "[1604/1762] D loss: 1.3860, G loss: 0.7076\n",
      "[1684/1762] D loss: 1.3862, G loss: 0.6930\n",
      "[1762/1762] D loss: 1.3859, G loss: 0.7063\n",
      "train error: \n",
      " D loss: 1.300628, G loss: 0.926521, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 82.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.273430, G loss: 0.980133, D accuracy: 56.2%, cell accuracy: 99.8%, board accuracy: 78.4% \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.7014\n",
      "[84/1762] D loss: 1.3819, G loss: 0.7157\n",
      "[164/1762] D loss: 1.0523, G loss: 1.3450\n",
      "[244/1762] D loss: 1.3696, G loss: 0.7412\n",
      "[324/1762] D loss: 1.3800, G loss: 0.7475\n",
      "[404/1762] D loss: 1.0574, G loss: 1.3112\n",
      "[484/1762] D loss: 1.1853, G loss: 0.8947\n",
      "[564/1762] D loss: 1.3881, G loss: 0.6502\n",
      "[644/1762] D loss: 1.1487, G loss: 0.8268\n",
      "[724/1762] D loss: 1.2163, G loss: 0.7444\n",
      "[804/1762] D loss: 1.3828, G loss: 0.7351\n",
      "[884/1762] D loss: 1.3868, G loss: 0.7318\n",
      "[964/1762] D loss: 1.3839, G loss: 0.6851\n",
      "[1044/1762] D loss: 1.2347, G loss: 0.9233\n",
      "[1124/1762] D loss: 1.2342, G loss: 1.2377\n",
      "[1204/1762] D loss: 1.0679, G loss: 1.1574\n",
      "[1284/1762] D loss: 1.3862, G loss: 0.7000\n",
      "[1364/1762] D loss: 1.3834, G loss: 0.6707\n",
      "[1444/1762] D loss: 1.3866, G loss: 0.6798\n",
      "[1524/1762] D loss: 1.3874, G loss: 0.6598\n",
      "[1604/1762] D loss: 1.3861, G loss: 0.7016\n",
      "[1684/1762] D loss: 1.3893, G loss: 0.6437\n",
      "[1762/1762] D loss: 1.0748, G loss: 1.9341\n",
      "train error: \n",
      " D loss: 1.336101, G loss: 0.754106, D accuracy: 54.2%, cell accuracy: 99.9%, board accuracy: 85.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.325946, G loss: 0.759498, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 83.4% \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3799, G loss: 0.7087\n",
      "[84/1762] D loss: 1.3987, G loss: 0.5806\n",
      "[164/1762] D loss: 1.0431, G loss: 2.4534\n",
      "[244/1762] D loss: 1.3783, G loss: 0.6921\n",
      "[324/1762] D loss: 1.1297, G loss: 0.8098\n",
      "[404/1762] D loss: 1.3859, G loss: 0.6726\n",
      "[484/1762] D loss: 1.3876, G loss: 0.6938\n",
      "[564/1762] D loss: 1.3830, G loss: 0.6607\n",
      "[644/1762] D loss: 1.3868, G loss: 0.7252\n",
      "[724/1762] D loss: 1.3847, G loss: 0.6737\n",
      "[804/1762] D loss: 1.3845, G loss: 0.7043\n",
      "[884/1762] D loss: 1.3076, G loss: 0.6504\n",
      "[964/1762] D loss: 1.3839, G loss: 0.7472\n",
      "[1044/1762] D loss: 1.4050, G loss: 0.5634\n",
      "[1124/1762] D loss: 1.2145, G loss: 0.7377\n",
      "[1204/1762] D loss: 1.0484, G loss: 1.4421\n",
      "[1284/1762] D loss: 1.3866, G loss: 0.7076\n",
      "[1364/1762] D loss: 1.1216, G loss: 0.9150\n",
      "[1444/1762] D loss: 1.3872, G loss: 0.6970\n",
      "[1524/1762] D loss: 1.3872, G loss: 0.6530\n",
      "[1604/1762] D loss: 1.3883, G loss: 0.7124\n",
      "[1684/1762] D loss: 1.3872, G loss: 0.6731\n",
      "[1762/1762] D loss: 1.3841, G loss: 0.6971\n",
      "train error: \n",
      " D loss: 1.283183, G loss: 0.941823, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.271381, G loss: 0.973355, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 84.1% \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3794, G loss: 0.7206\n",
      "[84/1762] D loss: 1.3868, G loss: 0.6733\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6749\n",
      "[244/1762] D loss: 1.1064, G loss: 0.9448\n",
      "[324/1762] D loss: 1.2338, G loss: 1.0772\n",
      "[404/1762] D loss: 1.3866, G loss: 0.7312\n",
      "[484/1762] D loss: 1.4856, G loss: 0.5848\n",
      "[564/1762] D loss: 1.3882, G loss: 0.6786\n",
      "[644/1762] D loss: 1.2134, G loss: 0.7058\n",
      "[724/1762] D loss: 1.0764, G loss: 1.0566\n",
      "[804/1762] D loss: 1.3866, G loss: 0.7021\n",
      "[884/1762] D loss: 1.3023, G loss: 0.8121\n",
      "[964/1762] D loss: 1.3863, G loss: 0.6821\n",
      "[1044/1762] D loss: 1.1685, G loss: 1.5084\n",
      "[1124/1762] D loss: 1.3834, G loss: 0.6939\n",
      "[1204/1762] D loss: 1.3898, G loss: 0.6647\n",
      "[1284/1762] D loss: 1.3872, G loss: 0.6777\n",
      "[1364/1762] D loss: 1.0894, G loss: 1.2194\n",
      "[1444/1762] D loss: 1.3073, G loss: 0.8063\n",
      "[1524/1762] D loss: 1.3640, G loss: 0.7413\n",
      "[1604/1762] D loss: 1.2284, G loss: 1.0881\n",
      "[1684/1762] D loss: 1.3877, G loss: 0.6615\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.6745\n",
      "train error: \n",
      " D loss: 1.332360, G loss: 0.726528, D accuracy: 54.3%, cell accuracy: 99.9%, board accuracy: 89.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.327950, G loss: 0.726024, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3866, G loss: 0.6784\n",
      "[84/1762] D loss: 1.3864, G loss: 0.7051\n",
      "[164/1762] D loss: 1.3056, G loss: 0.7871\n",
      "[244/1762] D loss: 1.3871, G loss: 0.6748\n",
      "[324/1762] D loss: 1.3691, G loss: 0.9380\n",
      "[404/1762] D loss: 1.3868, G loss: 0.6975\n",
      "[484/1762] D loss: 1.1527, G loss: 0.8344\n",
      "[564/1762] D loss: 1.3869, G loss: 0.6731\n",
      "[644/1762] D loss: 1.3327, G loss: 0.6576\n",
      "[724/1762] D loss: 1.3888, G loss: 0.7337\n",
      "[804/1762] D loss: 1.2517, G loss: 0.9164\n",
      "[884/1762] D loss: 1.3852, G loss: 0.7266\n",
      "[964/1762] D loss: 1.2162, G loss: 0.5917\n",
      "[1044/1762] D loss: 1.3866, G loss: 0.6770\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.6985\n",
      "[1204/1762] D loss: 1.1321, G loss: 0.8283\n",
      "[1284/1762] D loss: 1.3912, G loss: 0.7244\n",
      "[1364/1762] D loss: 1.3499, G loss: 0.7638\n",
      "[1444/1762] D loss: 1.3872, G loss: 0.6685\n",
      "[1524/1762] D loss: 1.3709, G loss: 0.7000\n",
      "[1604/1762] D loss: 1.3871, G loss: 0.6780\n",
      "[1684/1762] D loss: 1.3848, G loss: 0.6905\n",
      "[1762/1762] D loss: 1.3861, G loss: 0.6845\n",
      "train error: \n",
      " D loss: 1.311938, G loss: 0.798316, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.289411, G loss: 0.862786, D accuracy: 56.4%, cell accuracy: 99.7%, board accuracy: 84.1% \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3169, G loss: 0.8000\n",
      "[84/1762] D loss: 1.3870, G loss: 0.6663\n",
      "[164/1762] D loss: 1.3861, G loss: 0.6847\n",
      "[244/1762] D loss: 1.0645, G loss: 1.1360\n",
      "[324/1762] D loss: 1.3862, G loss: 0.6783\n",
      "[404/1762] D loss: 1.3904, G loss: 0.6326\n",
      "[484/1762] D loss: 1.2196, G loss: 1.1039\n",
      "[564/1762] D loss: 1.3865, G loss: 0.6866\n",
      "[644/1762] D loss: 1.3874, G loss: 0.7229\n",
      "[724/1762] D loss: 1.5409, G loss: 0.6745\n",
      "[804/1762] D loss: 1.3210, G loss: 0.8740\n",
      "[884/1762] D loss: 1.0658, G loss: 3.6210\n",
      "[964/1762] D loss: 1.3861, G loss: 0.6910\n",
      "[1044/1762] D loss: 1.3856, G loss: 0.6815\n",
      "[1124/1762] D loss: 1.0512, G loss: 1.4531\n",
      "[1204/1762] D loss: 1.3879, G loss: 0.6630\n",
      "[1284/1762] D loss: 1.1070, G loss: 0.9091\n",
      "[1364/1762] D loss: 1.2679, G loss: 0.8332\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6761\n",
      "[1524/1762] D loss: 1.4703, G loss: 0.5768\n",
      "[1604/1762] D loss: 1.4144, G loss: 0.6589\n",
      "[1684/1762] D loss: 0.8724, G loss: 2.4235\n",
      "[1762/1762] D loss: 1.4010, G loss: 0.6298\n",
      "train error: \n",
      " D loss: 1.296719, G loss: 0.942494, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 90.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.275942, G loss: 1.002634, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2296, G loss: 1.4197\n",
      "[84/1762] D loss: 1.3875, G loss: 0.6624\n",
      "[164/1762] D loss: 1.3896, G loss: 0.6557\n",
      "[244/1762] D loss: 1.3868, G loss: 0.6778\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6925\n",
      "[404/1762] D loss: 1.1731, G loss: 2.0637\n",
      "[484/1762] D loss: 1.3373, G loss: 0.9142\n",
      "[564/1762] D loss: 1.3877, G loss: 0.6599\n",
      "[644/1762] D loss: 1.0410, G loss: 1.8617\n",
      "[724/1762] D loss: 1.3287, G loss: 0.7721\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6805\n",
      "[884/1762] D loss: 1.3868, G loss: 0.6917\n",
      "[964/1762] D loss: 1.3870, G loss: 0.6959\n",
      "[1044/1762] D loss: 1.3874, G loss: 0.7014\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.6816\n",
      "[1204/1762] D loss: 1.3939, G loss: 1.3375\n",
      "[1284/1762] D loss: 1.0703, G loss: 2.0049\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6895\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6903\n",
      "[1524/1762] D loss: 1.3860, G loss: 0.6705\n",
      "[1604/1762] D loss: 1.3870, G loss: 0.7074\n",
      "[1684/1762] D loss: 1.3865, G loss: 0.6883\n",
      "[1762/1762] D loss: 1.0148, G loss: 1.9033\n",
      "train error: \n",
      " D loss: 1.270707, G loss: 1.125083, D accuracy: 56.2%, cell accuracy: 99.8%, board accuracy: 87.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.250187, G loss: 1.174261, D accuracy: 57.2%, cell accuracy: 99.8%, board accuracy: 85.0% \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0463, G loss: 1.5025\n",
      "[84/1762] D loss: 1.1941, G loss: 0.7332\n",
      "[164/1762] D loss: 1.0613, G loss: 1.3750\n",
      "[244/1762] D loss: 1.3867, G loss: 0.6885\n",
      "[324/1762] D loss: 1.3861, G loss: 0.6864\n",
      "[404/1762] D loss: 1.2114, G loss: 2.1853\n",
      "[484/1762] D loss: 1.3865, G loss: 0.6853\n",
      "[564/1762] D loss: 1.3876, G loss: 0.6568\n",
      "[644/1762] D loss: 1.4646, G loss: 0.8373\n",
      "[724/1762] D loss: 1.3869, G loss: 0.6725\n",
      "[804/1762] D loss: 1.1229, G loss: 1.0873\n",
      "[884/1762] D loss: 1.3865, G loss: 0.6784\n",
      "[964/1762] D loss: 1.3864, G loss: 0.6873\n",
      "[1044/1762] D loss: 1.3861, G loss: 0.6975\n",
      "[1124/1762] D loss: 1.3866, G loss: 0.7092\n",
      "[1204/1762] D loss: 1.3866, G loss: 0.6921\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6855\n",
      "[1364/1762] D loss: 1.3881, G loss: 0.6869\n",
      "[1444/1762] D loss: 1.3898, G loss: 0.6727\n",
      "[1524/1762] D loss: 1.3879, G loss: 0.6763\n",
      "[1604/1762] D loss: 1.3875, G loss: 0.7136\n",
      "[1684/1762] D loss: 1.3854, G loss: 0.6998\n",
      "[1762/1762] D loss: 1.3840, G loss: 0.6444\n",
      "train error: \n",
      " D loss: 1.284587, G loss: 1.275133, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 89.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.256285, G loss: 1.451646, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0401, G loss: 2.4137\n",
      "[84/1762] D loss: 1.3865, G loss: 0.6989\n",
      "[164/1762] D loss: 1.3875, G loss: 0.6857\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6920\n",
      "[324/1762] D loss: 1.0399, G loss: 2.5438\n",
      "[404/1762] D loss: 1.3865, G loss: 0.6878\n",
      "[484/1762] D loss: 1.3862, G loss: 0.6930\n",
      "[564/1762] D loss: 1.0415, G loss: 2.5583\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6843\n",
      "[724/1762] D loss: 1.3866, G loss: 0.6790\n",
      "[804/1762] D loss: 1.3865, G loss: 0.6958\n",
      "[884/1762] D loss: 1.3026, G loss: 0.8737\n",
      "[964/1762] D loss: 1.3889, G loss: 0.6482\n",
      "[1044/1762] D loss: 1.3815, G loss: 0.7131\n",
      "[1124/1762] D loss: 1.3867, G loss: 0.6877\n",
      "[1204/1762] D loss: 1.3829, G loss: 0.6837\n",
      "[1284/1762] D loss: 1.3860, G loss: 0.6934\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6999\n",
      "[1444/1762] D loss: 1.0401, G loss: 2.2904\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.6868\n",
      "[1604/1762] D loss: 1.0338, G loss: 1.5396\n",
      "[1684/1762] D loss: 1.3875, G loss: 0.6729\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.6805\n",
      "train error: \n",
      " D loss: 1.285516, G loss: 1.279758, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.256074, G loss: 1.454966, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3867, G loss: 0.6851\n",
      "[84/1762] D loss: 1.0400, G loss: 2.8221\n",
      "[164/1762] D loss: 1.3860, G loss: 0.6843\n",
      "[244/1762] D loss: 1.3868, G loss: 0.6809\n",
      "[324/1762] D loss: 1.0400, G loss: 2.5203\n",
      "[404/1762] D loss: 1.0358, G loss: 3.0106\n",
      "[484/1762] D loss: 1.3860, G loss: 0.6898\n",
      "[564/1762] D loss: 1.3865, G loss: 0.6965\n",
      "[644/1762] D loss: 1.0400, G loss: 2.7982\n",
      "[724/1762] D loss: 1.0400, G loss: 2.4858\n",
      "[804/1762] D loss: 1.3863, G loss: 0.6917\n",
      "[884/1762] D loss: 1.3865, G loss: 0.6872\n",
      "[964/1762] D loss: 1.0402, G loss: 2.1817\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.6885\n",
      "[1124/1762] D loss: 1.3868, G loss: 0.6753\n",
      "[1204/1762] D loss: 1.3801, G loss: 0.6924\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6903\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6962\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.6954\n",
      "[1524/1762] D loss: 1.3867, G loss: 0.6901\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6964\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6904\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.6884\n",
      "train error: \n",
      " D loss: 1.284923, G loss: 1.297415, D accuracy: 54.1%, cell accuracy: 99.9%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.255612, G loss: 1.476291, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.7023\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6994\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6910\n",
      "[244/1762] D loss: 1.3862, G loss: 0.6963\n",
      "[324/1762] D loss: 0.8637, G loss: 5.0194\n",
      "[404/1762] D loss: 1.3863, G loss: 0.6812\n",
      "[484/1762] D loss: 1.0421, G loss: 1.7089\n",
      "[564/1762] D loss: 0.6911, G loss: 3.0343\n",
      "[644/1762] D loss: 1.3879, G loss: 0.6757\n",
      "[724/1762] D loss: 1.3854, G loss: 0.6807\n",
      "[804/1762] D loss: 1.3790, G loss: 0.8141\n",
      "[884/1762] D loss: 1.3415, G loss: 0.7214\n",
      "[964/1762] D loss: 1.2873, G loss: 0.8355\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6780\n",
      "[1124/1762] D loss: 1.0253, G loss: 2.2601\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6969\n",
      "[1284/1762] D loss: 1.3862, G loss: 0.6752\n",
      "[1364/1762] D loss: 1.0555, G loss: 2.1457\n",
      "[1444/1762] D loss: 1.0365, G loss: 2.5609\n",
      "[1524/1762] D loss: 1.3817, G loss: 0.6856\n",
      "[1604/1762] D loss: 1.0370, G loss: 1.6604\n",
      "[1684/1762] D loss: 1.3691, G loss: 0.7557\n",
      "[1762/1762] D loss: 0.6948, G loss: 3.5648\n",
      "train error: \n",
      " D loss: 1.254808, G loss: 1.549956, D accuracy: 54.9%, cell accuracy: 99.2%, board accuracy: 45.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.210654, G loss: 1.785586, D accuracy: 55.2%, cell accuracy: 99.1%, board accuracy: 39.5% \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3748, G loss: 0.7556\n",
      "[84/1762] D loss: 1.1617, G loss: 1.7405\n",
      "[164/1762] D loss: 1.4231, G loss: 0.4823\n",
      "[244/1762] D loss: 1.4387, G loss: 1.4413\n",
      "[324/1762] D loss: 1.3885, G loss: 0.6706\n",
      "[404/1762] D loss: 1.3866, G loss: 0.6903\n",
      "[484/1762] D loss: 1.0399, G loss: 3.0795\n",
      "[564/1762] D loss: 1.0408, G loss: 1.9347\n",
      "[644/1762] D loss: 1.3726, G loss: 0.6869\n",
      "[724/1762] D loss: 1.0421, G loss: 4.3105\n",
      "[804/1762] D loss: 1.3890, G loss: 0.6513\n",
      "[884/1762] D loss: 0.6911, G loss: 5.5340\n",
      "[964/1762] D loss: 1.3878, G loss: 0.6660\n",
      "[1044/1762] D loss: 1.3876, G loss: 0.6605\n",
      "[1124/1762] D loss: 1.3903, G loss: 0.6372\n",
      "[1204/1762] D loss: 1.0403, G loss: 2.0694\n",
      "[1284/1762] D loss: 1.3847, G loss: 0.7096\n",
      "[1364/1762] D loss: 1.0404, G loss: 2.0048\n",
      "[1444/1762] D loss: 1.0405, G loss: 1.9662\n",
      "[1524/1762] D loss: 1.3867, G loss: 0.6733\n",
      "[1604/1762] D loss: 1.3876, G loss: 0.7197\n",
      "[1684/1762] D loss: 1.3876, G loss: 0.6781\n",
      "[1762/1762] D loss: 0.6877, G loss: 3.2243\n",
      "train error: \n",
      " D loss: 1.282261, G loss: 1.333056, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 90.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.253164, G loss: 1.492159, D accuracy: 56.0%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0458, G loss: 2.8350\n",
      "[84/1762] D loss: 1.3861, G loss: 0.6902\n",
      "[164/1762] D loss: 1.3691, G loss: 0.7223\n",
      "[244/1762] D loss: 1.3869, G loss: 0.7101\n",
      "[324/1762] D loss: 1.3843, G loss: 0.6794\n",
      "[404/1762] D loss: 1.3862, G loss: 0.7063\n",
      "[484/1762] D loss: 1.0406, G loss: 2.4142\n",
      "[564/1762] D loss: 1.3855, G loss: 0.6901\n",
      "[644/1762] D loss: 1.3847, G loss: 0.6865\n",
      "[724/1762] D loss: 1.0400, G loss: 2.6455\n",
      "[804/1762] D loss: 1.3861, G loss: 0.7006\n",
      "[884/1762] D loss: 1.3906, G loss: 0.7368\n",
      "[964/1762] D loss: 0.8601, G loss: 4.7483\n",
      "[1044/1762] D loss: 1.4004, G loss: 0.5794\n",
      "[1124/1762] D loss: 0.7657, G loss: 3.0173\n",
      "[1204/1762] D loss: 1.3862, G loss: 0.6661\n",
      "[1284/1762] D loss: 1.4347, G loss: 0.4878\n",
      "[1364/1762] D loss: 1.3775, G loss: 0.7066\n",
      "[1444/1762] D loss: 1.0419, G loss: 2.5950\n",
      "[1524/1762] D loss: 1.3870, G loss: 0.7221\n",
      "[1604/1762] D loss: 1.0434, G loss: 2.1657\n",
      "[1684/1762] D loss: 1.0393, G loss: 2.5192\n",
      "[1762/1762] D loss: 1.3860, G loss: 0.6798\n",
      "train error: \n",
      " D loss: 1.268806, G loss: 1.559125, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 88.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.242506, G loss: 1.767271, D accuracy: 56.0%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3890, G loss: 0.6698\n",
      "[84/1762] D loss: 1.3854, G loss: 0.6819\n",
      "[164/1762] D loss: 1.3926, G loss: 0.6204\n",
      "[244/1762] D loss: 1.0357, G loss: 3.0674\n",
      "[324/1762] D loss: 1.3847, G loss: 0.6756\n",
      "[404/1762] D loss: 1.0421, G loss: 3.6744\n",
      "[484/1762] D loss: 1.0405, G loss: 4.2374\n",
      "[564/1762] D loss: 1.3816, G loss: 0.6811\n",
      "[644/1762] D loss: 1.3820, G loss: 0.6928\n",
      "[724/1762] D loss: 1.0381, G loss: 3.1025\n",
      "[804/1762] D loss: 1.3848, G loss: 0.6852\n",
      "[884/1762] D loss: 1.3859, G loss: 0.6811\n",
      "[964/1762] D loss: 0.6962, G loss: 4.8181\n",
      "[1044/1762] D loss: 1.3876, G loss: 0.6545\n",
      "[1124/1762] D loss: 1.3869, G loss: 0.6765\n",
      "[1204/1762] D loss: 1.0405, G loss: 3.1969\n",
      "[1284/1762] D loss: 1.3865, G loss: 0.6986\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6887\n",
      "[1444/1762] D loss: 1.3866, G loss: 0.6949\n",
      "[1524/1762] D loss: 1.0441, G loss: 1.6002\n",
      "[1604/1762] D loss: 1.3870, G loss: 0.7139\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.6828\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.6796\n",
      "train error: \n",
      " D loss: 1.338121, G loss: 0.900219, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 87.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.330824, G loss: 0.956301, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 84.5% \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3868, G loss: 0.6964\n",
      "[84/1762] D loss: 1.3757, G loss: 0.6915\n",
      "[164/1762] D loss: 1.3868, G loss: 0.6710\n",
      "[244/1762] D loss: 1.3870, G loss: 0.6680\n",
      "[324/1762] D loss: 1.3865, G loss: 0.6919\n",
      "[404/1762] D loss: 1.3869, G loss: 0.7029\n",
      "[484/1762] D loss: 0.7808, G loss: 1.4353\n",
      "[564/1762] D loss: 1.0485, G loss: 1.3846\n",
      "[644/1762] D loss: 1.3870, G loss: 0.6852\n",
      "[724/1762] D loss: 1.3881, G loss: 0.6595\n",
      "[804/1762] D loss: 1.3865, G loss: 0.7009\n",
      "[884/1762] D loss: 1.3876, G loss: 0.6627\n",
      "[964/1762] D loss: 1.3867, G loss: 0.7010\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6927\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6947\n",
      "[1204/1762] D loss: 1.0912, G loss: 0.9861\n",
      "[1284/1762] D loss: 1.3865, G loss: 0.7054\n",
      "[1364/1762] D loss: 1.3865, G loss: 0.7047\n",
      "[1444/1762] D loss: 1.2233, G loss: 0.7406\n",
      "[1524/1762] D loss: 2.2706, G loss: 2.5634\n",
      "[1604/1762] D loss: 1.2039, G loss: 0.7154\n",
      "[1684/1762] D loss: 1.3868, G loss: 0.7105\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6766\n",
      "train error: \n",
      " D loss: 1.306549, G loss: 0.901250, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 90.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.293905, G loss: 0.953006, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7497, G loss: 1.7375\n",
      "[84/1762] D loss: 1.0483, G loss: 1.5291\n",
      "[164/1762] D loss: 1.3864, G loss: 0.6913\n",
      "[244/1762] D loss: 1.3866, G loss: 0.7082\n",
      "[324/1762] D loss: 1.0778, G loss: 1.0335\n",
      "[404/1762] D loss: 1.3865, G loss: 0.6865\n",
      "[484/1762] D loss: 1.3867, G loss: 0.7038\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6905\n",
      "[644/1762] D loss: 1.0441, G loss: 1.2693\n",
      "[724/1762] D loss: 1.3867, G loss: 0.6877\n",
      "[804/1762] D loss: 1.3866, G loss: 0.6800\n",
      "[884/1762] D loss: 1.3868, G loss: 0.6888\n",
      "[964/1762] D loss: 1.3863, G loss: 0.6990\n",
      "[1044/1762] D loss: 1.0509, G loss: 1.6160\n",
      "[1124/1762] D loss: 1.3868, G loss: 0.6777\n",
      "[1204/1762] D loss: 1.3868, G loss: 0.6765\n",
      "[1284/1762] D loss: 1.3867, G loss: 0.6760\n",
      "[1364/1762] D loss: 1.0778, G loss: 1.0121\n",
      "[1444/1762] D loss: 1.0811, G loss: 0.9877\n",
      "[1524/1762] D loss: 1.0767, G loss: 1.0108\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6959\n",
      "[1684/1762] D loss: 1.3867, G loss: 0.6759\n",
      "[1762/1762] D loss: 1.3878, G loss: 0.6653\n",
      "train error: \n",
      " D loss: 1.313312, G loss: 0.750202, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.293209, G loss: 0.804022, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3865, G loss: 0.6863\n",
      "[84/1762] D loss: 1.3867, G loss: 0.6986\n",
      "[164/1762] D loss: 1.0867, G loss: 0.9646\n",
      "[244/1762] D loss: 1.3866, G loss: 0.7077\n",
      "[324/1762] D loss: 1.3913, G loss: 0.7309\n",
      "[404/1762] D loss: 1.3863, G loss: 0.6938\n",
      "[484/1762] D loss: 1.3869, G loss: 0.6991\n",
      "[564/1762] D loss: 1.0671, G loss: 1.1018\n",
      "[644/1762] D loss: 1.3868, G loss: 0.6916\n",
      "[724/1762] D loss: 1.3876, G loss: 0.7011\n",
      "[804/1762] D loss: 1.3840, G loss: 0.6824\n",
      "[884/1762] D loss: 1.2109, G loss: 1.6312\n",
      "[964/1762] D loss: 1.3872, G loss: 0.6896\n",
      "[1044/1762] D loss: 1.3881, G loss: 0.6558\n",
      "[1124/1762] D loss: 1.3903, G loss: 0.7124\n",
      "[1204/1762] D loss: 1.2085, G loss: 3.5318\n",
      "[1284/1762] D loss: 1.3860, G loss: 0.6948\n",
      "[1364/1762] D loss: 1.3871, G loss: 0.6818\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.7004\n",
      "[1524/1762] D loss: 1.3873, G loss: 0.6906\n",
      "[1604/1762] D loss: 1.3866, G loss: 0.6851\n",
      "[1684/1762] D loss: 1.0420, G loss: 1.1935\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.7051\n",
      "train error: \n",
      " D loss: 1.301838, G loss: 0.851131, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.286133, G loss: 0.888040, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0647, G loss: 1.1045\n",
      "[84/1762] D loss: 1.0561, G loss: 1.2669\n",
      "[164/1762] D loss: 0.8861, G loss: 2.9346\n",
      "[244/1762] D loss: 1.2147, G loss: 1.6086\n",
      "[324/1762] D loss: 1.0570, G loss: 1.1932\n",
      "[404/1762] D loss: 1.0540, G loss: 1.2320\n",
      "[484/1762] D loss: 1.3865, G loss: 0.6828\n",
      "[564/1762] D loss: 1.2089, G loss: 2.3358\n",
      "[644/1762] D loss: 1.3867, G loss: 0.6957\n",
      "[724/1762] D loss: 1.2268, G loss: 1.1044\n",
      "[804/1762] D loss: 1.0631, G loss: 1.1403\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6900\n",
      "[964/1762] D loss: 1.3865, G loss: 0.6744\n",
      "[1044/1762] D loss: 1.3866, G loss: 0.6841\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6888\n",
      "[1204/1762] D loss: 1.3866, G loss: 0.6875\n",
      "[1284/1762] D loss: 1.3874, G loss: 0.6654\n",
      "[1364/1762] D loss: 1.3867, G loss: 0.7062\n",
      "[1444/1762] D loss: 0.8509, G loss: 0.9857\n",
      "[1524/1762] D loss: 1.1081, G loss: 0.8978\n",
      "[1604/1762] D loss: 1.0605, G loss: 1.1898\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6901\n",
      "[1762/1762] D loss: 1.3866, G loss: 0.6758\n",
      "train error: \n",
      " D loss: 1.302974, G loss: 0.824584, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.284216, G loss: 0.927058, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6875\n",
      "[84/1762] D loss: 1.3865, G loss: 0.7069\n",
      "[164/1762] D loss: 1.0527, G loss: 1.2847\n",
      "[244/1762] D loss: 1.3870, G loss: 0.6883\n",
      "[324/1762] D loss: 1.3879, G loss: 0.6670\n",
      "[404/1762] D loss: 1.3864, G loss: 0.7145\n",
      "[484/1762] D loss: 1.0474, G loss: 1.4267\n",
      "[564/1762] D loss: 1.3883, G loss: 0.7314\n",
      "[644/1762] D loss: 1.3868, G loss: 0.6714\n",
      "[724/1762] D loss: 1.3866, G loss: 0.6871\n",
      "[804/1762] D loss: 1.3868, G loss: 0.7117\n",
      "[884/1762] D loss: 1.3999, G loss: 0.6213\n",
      "[964/1762] D loss: 1.0906, G loss: 0.9533\n",
      "[1044/1762] D loss: 1.3867, G loss: 0.7098\n",
      "[1124/1762] D loss: 1.3866, G loss: 0.6853\n",
      "[1204/1762] D loss: 0.7156, G loss: 1.9281\n",
      "[1284/1762] D loss: 1.3870, G loss: 0.6866\n",
      "[1364/1762] D loss: 0.3571, G loss: 3.4627\n",
      "[1444/1762] D loss: 1.3872, G loss: 0.6796\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.6901\n",
      "[1604/1762] D loss: 1.3768, G loss: 0.7782\n",
      "[1684/1762] D loss: 1.3910, G loss: 0.6324\n",
      "[1762/1762] D loss: 0.6932, G loss: 3.4916\n",
      "train error: \n",
      " D loss: 1.284595, G loss: 1.200582, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.269421, G loss: 1.236955, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3843, G loss: 0.6963\n",
      "[84/1762] D loss: 1.3867, G loss: 0.7001\n",
      "[164/1762] D loss: 1.0942, G loss: 4.2556\n",
      "[244/1762] D loss: 1.3867, G loss: 0.6767\n",
      "[324/1762] D loss: 1.3872, G loss: 0.6666\n",
      "[404/1762] D loss: 1.0399, G loss: 2.3664\n",
      "[484/1762] D loss: 1.3864, G loss: 0.6879\n",
      "[564/1762] D loss: 1.3866, G loss: 0.7073\n",
      "[644/1762] D loss: 1.0385, G loss: 2.3276\n",
      "[724/1762] D loss: 1.3867, G loss: 0.6899\n",
      "[804/1762] D loss: 1.3867, G loss: 0.6801\n",
      "[884/1762] D loss: 1.0716, G loss: 2.2447\n",
      "[964/1762] D loss: 1.2162, G loss: 0.6880\n",
      "[1044/1762] D loss: 1.3855, G loss: 0.7105\n",
      "[1124/1762] D loss: 1.3896, G loss: 0.6738\n",
      "[1204/1762] D loss: 1.3861, G loss: 0.6962\n",
      "[1284/1762] D loss: 1.3801, G loss: 0.7021\n",
      "[1364/1762] D loss: 1.5049, G loss: 0.9077\n",
      "[1444/1762] D loss: 1.3656, G loss: 0.7006\n",
      "[1524/1762] D loss: 1.4033, G loss: 0.5765\n",
      "[1604/1762] D loss: 1.3908, G loss: 0.7447\n",
      "[1684/1762] D loss: 1.3875, G loss: 0.6774\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6899\n",
      "train error: \n",
      " D loss: 1.300808, G loss: 0.847643, D accuracy: 57.0%, cell accuracy: 99.8%, board accuracy: 78.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.286970, G loss: 0.896069, D accuracy: 58.6%, cell accuracy: 99.7%, board accuracy: 73.9% \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3822, G loss: 0.6942\n",
      "[84/1762] D loss: 1.3814, G loss: 0.6768\n",
      "[164/1762] D loss: 1.3867, G loss: 0.7054\n",
      "[244/1762] D loss: 1.3873, G loss: 0.6805\n",
      "[324/1762] D loss: 1.3844, G loss: 0.6910\n",
      "[404/1762] D loss: 1.3847, G loss: 0.6509\n",
      "[484/1762] D loss: 1.3890, G loss: 0.6793\n",
      "[564/1762] D loss: 1.3871, G loss: 0.6871\n",
      "[644/1762] D loss: 0.8044, G loss: 1.0725\n",
      "[724/1762] D loss: 1.3865, G loss: 0.6852\n",
      "[804/1762] D loss: 1.3588, G loss: 0.7666\n",
      "[884/1762] D loss: 1.3873, G loss: 0.7167\n",
      "[964/1762] D loss: 1.3912, G loss: 0.6295\n",
      "[1044/1762] D loss: 1.3874, G loss: 0.6830\n",
      "[1124/1762] D loss: 1.3877, G loss: 0.6702\n",
      "[1204/1762] D loss: 1.2225, G loss: 1.3629\n",
      "[1284/1762] D loss: 1.3874, G loss: 0.6692\n",
      "[1364/1762] D loss: 1.0456, G loss: 1.7962\n",
      "[1444/1762] D loss: 1.0440, G loss: 1.6188\n",
      "[1524/1762] D loss: 1.0509, G loss: 1.3109\n",
      "[1604/1762] D loss: 1.3876, G loss: 0.7007\n",
      "[1684/1762] D loss: 1.3876, G loss: 0.6777\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.7034\n",
      "train error: \n",
      " D loss: 1.308472, G loss: 0.877612, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.295360, G loss: 0.934350, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3869, G loss: 0.7084\n",
      "[84/1762] D loss: 1.3877, G loss: 0.6876\n",
      "[164/1762] D loss: 1.0482, G loss: 1.3749\n",
      "[244/1762] D loss: 1.3890, G loss: 0.7306\n",
      "[324/1762] D loss: 1.3865, G loss: 0.6858\n",
      "[404/1762] D loss: 1.3865, G loss: 0.6965\n",
      "[484/1762] D loss: 1.0433, G loss: 1.6196\n",
      "[564/1762] D loss: 1.3870, G loss: 0.6955\n",
      "[644/1762] D loss: 1.0515, G loss: 1.2561\n",
      "[724/1762] D loss: 1.3867, G loss: 0.7072\n",
      "[804/1762] D loss: 1.0611, G loss: 1.1330\n",
      "[884/1762] D loss: 1.3869, G loss: 0.7081\n",
      "[964/1762] D loss: 1.3815, G loss: 0.6882\n",
      "[1044/1762] D loss: 1.3883, G loss: 0.7021\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.6934\n",
      "[1204/1762] D loss: 1.0619, G loss: 1.1618\n",
      "[1284/1762] D loss: 1.3874, G loss: 0.7116\n",
      "[1364/1762] D loss: 1.3866, G loss: 0.7026\n",
      "[1444/1762] D loss: 1.3867, G loss: 0.6973\n",
      "[1524/1762] D loss: 1.3865, G loss: 0.6904\n",
      "[1604/1762] D loss: 1.3867, G loss: 0.6821\n",
      "[1684/1762] D loss: 1.3862, G loss: 0.6881\n",
      "[1762/1762] D loss: 1.3783, G loss: 0.7118\n",
      "train error: \n",
      " D loss: 1.305493, G loss: 0.830008, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.291282, G loss: 0.863620, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6977\n",
      "[84/1762] D loss: 1.3865, G loss: 0.6806\n",
      "[164/1762] D loss: 0.7418, G loss: 1.5570\n",
      "[244/1762] D loss: 1.3864, G loss: 0.6944\n",
      "[324/1762] D loss: 1.3867, G loss: 0.6989\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6997\n",
      "[484/1762] D loss: 1.0543, G loss: 1.2486\n",
      "[564/1762] D loss: 1.0523, G loss: 1.2799\n",
      "[644/1762] D loss: 1.3865, G loss: 0.6821\n",
      "[724/1762] D loss: 1.2145, G loss: 1.7830\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6889\n",
      "[884/1762] D loss: 1.0529, G loss: 1.2586\n",
      "[964/1762] D loss: 1.2190, G loss: 1.5484\n",
      "[1044/1762] D loss: 1.0467, G loss: 1.4184\n",
      "[1124/1762] D loss: 1.0620, G loss: 1.0320\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6922\n",
      "[1284/1762] D loss: 1.3865, G loss: 0.7073\n",
      "[1364/1762] D loss: 1.3865, G loss: 0.6811\n",
      "[1444/1762] D loss: 1.0675, G loss: 1.0886\n",
      "[1524/1762] D loss: 1.3865, G loss: 0.6911\n",
      "[1604/1762] D loss: 1.3875, G loss: 0.7081\n",
      "[1684/1762] D loss: 1.0740, G loss: 1.0348\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6956\n",
      "train error: \n",
      " D loss: 1.310658, G loss: 0.770342, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.293786, G loss: 0.799244, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6912\n",
      "[84/1762] D loss: 1.3864, G loss: 0.7005\n",
      "[164/1762] D loss: 1.3871, G loss: 0.7046\n",
      "[244/1762] D loss: 1.3865, G loss: 0.6953\n",
      "[324/1762] D loss: 1.3864, G loss: 0.6983\n",
      "[404/1762] D loss: 1.3863, G loss: 0.6950\n",
      "[484/1762] D loss: 1.3868, G loss: 0.7012\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6967\n",
      "[644/1762] D loss: 1.3867, G loss: 0.6902\n",
      "[724/1762] D loss: 1.3866, G loss: 0.6923\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6924\n",
      "[884/1762] D loss: 1.3869, G loss: 0.7017\n",
      "[964/1762] D loss: 1.3849, G loss: 0.6937\n",
      "[1044/1762] D loss: 1.3866, G loss: 0.6792\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.6908\n",
      "[1204/1762] D loss: 1.3868, G loss: 0.6899\n",
      "[1284/1762] D loss: 1.3865, G loss: 0.6837\n",
      "[1364/1762] D loss: 1.3867, G loss: 0.6838\n",
      "[1444/1762] D loss: 1.2262, G loss: 1.2346\n",
      "[1524/1762] D loss: 1.3868, G loss: 0.6936\n",
      "[1604/1762] D loss: 0.7009, G loss: 2.4739\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6872\n",
      "[1762/1762] D loss: 1.3861, G loss: 0.7030\n",
      "train error: \n",
      " D loss: 1.305284, G loss: 0.848978, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.291689, G loss: 0.881771, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0775, G loss: 1.0253\n",
      "[84/1762] D loss: 0.7114, G loss: 2.2817\n",
      "[164/1762] D loss: 1.0481, G loss: 1.3808\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6970\n",
      "[324/1762] D loss: 1.3869, G loss: 0.7033\n",
      "[404/1762] D loss: 1.3753, G loss: 0.6830\n",
      "[484/1762] D loss: 1.3866, G loss: 0.6960\n",
      "[564/1762] D loss: 1.3865, G loss: 0.6835\n",
      "[644/1762] D loss: 1.3864, G loss: 0.6859\n",
      "[724/1762] D loss: 1.3868, G loss: 0.7189\n",
      "[804/1762] D loss: 1.3979, G loss: 0.5935\n",
      "[884/1762] D loss: 1.3871, G loss: 0.7244\n",
      "[964/1762] D loss: 1.3869, G loss: 0.6904\n",
      "[1044/1762] D loss: 1.7973, G loss: 1.2317\n",
      "[1124/1762] D loss: 1.3867, G loss: 0.7111\n",
      "[1204/1762] D loss: 1.3848, G loss: 0.6892\n",
      "[1284/1762] D loss: 1.1916, G loss: 1.6679\n",
      "[1364/1762] D loss: 1.3883, G loss: 0.6617\n",
      "[1444/1762] D loss: 1.3870, G loss: 0.7212\n",
      "[1524/1762] D loss: 1.3881, G loss: 0.6616\n",
      "[1604/1762] D loss: 1.3883, G loss: 0.7374\n",
      "[1684/1762] D loss: 1.3879, G loss: 0.6617\n",
      "[1762/1762] D loss: 1.3862, G loss: 0.6799\n",
      "train error: \n",
      " D loss: 1.309779, G loss: 0.787340, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.295660, G loss: 0.794157, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3871, G loss: 0.7171\n",
      "[84/1762] D loss: 1.3865, G loss: 0.7024\n",
      "[164/1762] D loss: 1.3845, G loss: 0.6923\n",
      "[244/1762] D loss: 1.3876, G loss: 0.6687\n",
      "[324/1762] D loss: 1.2021, G loss: 3.0783\n",
      "[404/1762] D loss: 1.3867, G loss: 0.6981\n",
      "[484/1762] D loss: 1.0459, G loss: 1.5286\n",
      "[564/1762] D loss: 1.3868, G loss: 0.6853\n",
      "[644/1762] D loss: 1.3867, G loss: 0.6790\n",
      "[724/1762] D loss: 1.2103, G loss: 1.3449\n",
      "[804/1762] D loss: 1.3865, G loss: 0.6907\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6953\n",
      "[964/1762] D loss: 1.3865, G loss: 0.6882\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6920\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.7004\n",
      "[1204/1762] D loss: 1.3854, G loss: 0.6834\n",
      "[1284/1762] D loss: 1.3870, G loss: 0.6705\n",
      "[1364/1762] D loss: 1.3865, G loss: 0.7049\n",
      "[1444/1762] D loss: 1.0800, G loss: 1.0356\n",
      "[1524/1762] D loss: 1.0538, G loss: 1.2797\n",
      "[1604/1762] D loss: 1.3855, G loss: 0.7212\n",
      "[1684/1762] D loss: 1.3919, G loss: 0.6231\n",
      "[1762/1762] D loss: 1.3850, G loss: 0.6709\n",
      "train error: \n",
      " D loss: 1.287837, G loss: 1.097890, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.269053, G loss: 1.226710, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 84.8% \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3867, G loss: 0.6874\n",
      "[84/1762] D loss: 1.3877, G loss: 0.6575\n",
      "[164/1762] D loss: 1.0545, G loss: 1.2905\n",
      "[244/1762] D loss: 1.1987, G loss: 1.9854\n",
      "[324/1762] D loss: 1.2784, G loss: 0.5015\n",
      "[404/1762] D loss: 1.3901, G loss: 0.6586\n",
      "[484/1762] D loss: 0.6999, G loss: 3.8726\n",
      "[564/1762] D loss: 1.2072, G loss: 6.0667\n",
      "[644/1762] D loss: 1.3502, G loss: 0.9938\n",
      "[724/1762] D loss: 1.3915, G loss: 0.6973\n",
      "[804/1762] D loss: 1.3903, G loss: 0.7208\n",
      "[884/1762] D loss: 1.3578, G loss: 0.6797\n",
      "[964/1762] D loss: 1.4674, G loss: 0.7722\n",
      "[1044/1762] D loss: 1.0278, G loss: 2.7580\n",
      "[1124/1762] D loss: 1.3696, G loss: 0.7100\n",
      "[1204/1762] D loss: 1.2363, G loss: 1.3119\n",
      "[1284/1762] D loss: 1.3091, G loss: 0.7438\n",
      "[1364/1762] D loss: 1.4055, G loss: 0.6395\n",
      "[1444/1762] D loss: 0.9134, G loss: 1.7925\n",
      "[1524/1762] D loss: 1.3229, G loss: 0.8106\n",
      "[1604/1762] D loss: 0.6723, G loss: 2.0938\n",
      "[1684/1762] D loss: 1.5268, G loss: 0.6757\n",
      "[1762/1762] D loss: 0.9885, G loss: 0.7741\n",
      "train error: \n",
      " D loss: 1.317640, G loss: 0.959854, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 80.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.306979, G loss: 0.945768, D accuracy: 54.2%, cell accuracy: 99.7%, board accuracy: 80.2% \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3923, G loss: 0.7358\n",
      "[84/1762] D loss: 1.4749, G loss: 0.7449\n",
      "[164/1762] D loss: 0.7421, G loss: 1.7500\n",
      "[244/1762] D loss: 1.3501, G loss: 0.7114\n",
      "[324/1762] D loss: 1.3817, G loss: 0.7770\n",
      "[404/1762] D loss: 1.3931, G loss: 0.6467\n",
      "[484/1762] D loss: 1.3953, G loss: 0.7844\n",
      "[564/1762] D loss: 1.3925, G loss: 0.7494\n",
      "[644/1762] D loss: 1.3914, G loss: 0.7513\n",
      "[724/1762] D loss: 1.3917, G loss: 0.7359\n",
      "[804/1762] D loss: 1.3914, G loss: 0.7319\n",
      "[884/1762] D loss: 1.3910, G loss: 0.7410\n",
      "[964/1762] D loss: 1.3915, G loss: 0.7110\n",
      "[1044/1762] D loss: 1.3897, G loss: 0.6922\n",
      "[1124/1762] D loss: 1.3904, G loss: 0.7529\n",
      "[1204/1762] D loss: 1.3884, G loss: 0.6966\n",
      "[1284/1762] D loss: 1.0262, G loss: 1.3991\n",
      "[1364/1762] D loss: 1.3933, G loss: 0.6824\n",
      "[1444/1762] D loss: 1.3888, G loss: 0.6938\n",
      "[1524/1762] D loss: 1.3899, G loss: 0.7002\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.7028\n",
      "[1684/1762] D loss: 1.3889, G loss: 0.6851\n",
      "[1762/1762] D loss: 1.3802, G loss: 0.6750\n",
      "train error: \n",
      " D loss: 1.308437, G loss: 0.813479, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 85.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.292937, G loss: 0.865667, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3868, G loss: 0.6857\n",
      "[84/1762] D loss: 1.3901, G loss: 0.7533\n",
      "[164/1762] D loss: 1.3885, G loss: 0.6868\n",
      "[244/1762] D loss: 1.3893, G loss: 0.7060\n",
      "[324/1762] D loss: 1.0758, G loss: 1.0567\n",
      "[404/1762] D loss: 1.3857, G loss: 0.6987\n",
      "[484/1762] D loss: 1.3916, G loss: 0.7101\n",
      "[564/1762] D loss: 1.3876, G loss: 0.7121\n",
      "[644/1762] D loss: 1.3880, G loss: 0.6726\n",
      "[724/1762] D loss: 1.3875, G loss: 0.6998\n",
      "[804/1762] D loss: 1.3870, G loss: 0.7038\n",
      "[884/1762] D loss: 1.3871, G loss: 0.7138\n",
      "[964/1762] D loss: 1.0732, G loss: 1.0437\n",
      "[1044/1762] D loss: 1.3869, G loss: 0.6855\n",
      "[1124/1762] D loss: 1.3872, G loss: 0.7067\n",
      "[1204/1762] D loss: 1.3874, G loss: 0.6811\n",
      "[1284/1762] D loss: 1.3909, G loss: 0.7114\n",
      "[1364/1762] D loss: 1.3871, G loss: 0.6847\n",
      "[1444/1762] D loss: 1.3869, G loss: 0.6687\n",
      "[1524/1762] D loss: 1.3880, G loss: 0.6765\n",
      "[1604/1762] D loss: 1.3874, G loss: 0.7068\n",
      "[1684/1762] D loss: 1.3869, G loss: 0.6706\n",
      "[1762/1762] D loss: 1.3874, G loss: 0.7085\n",
      "train error: \n",
      " D loss: 1.306404, G loss: 0.848097, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 90.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.292861, G loss: 0.882770, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3881, G loss: 0.6810\n",
      "[84/1762] D loss: 1.3872, G loss: 0.7183\n",
      "[164/1762] D loss: 1.3988, G loss: 0.7706\n",
      "[244/1762] D loss: 1.3868, G loss: 0.6790\n",
      "[324/1762] D loss: 1.0642, G loss: 1.1140\n",
      "[404/1762] D loss: 1.3864, G loss: 0.7046\n",
      "[484/1762] D loss: 1.3886, G loss: 0.6644\n",
      "[564/1762] D loss: 1.3870, G loss: 0.6992\n",
      "[644/1762] D loss: 1.3866, G loss: 0.6893\n",
      "[724/1762] D loss: 1.3866, G loss: 0.6898\n",
      "[804/1762] D loss: 1.3888, G loss: 0.7306\n",
      "[884/1762] D loss: 1.3871, G loss: 0.7124\n",
      "[964/1762] D loss: 1.3864, G loss: 0.6882\n",
      "[1044/1762] D loss: 1.3873, G loss: 0.6786\n",
      "[1124/1762] D loss: 1.3868, G loss: 0.7158\n",
      "[1204/1762] D loss: 1.3869, G loss: 0.7017\n",
      "[1284/1762] D loss: 1.0586, G loss: 1.1582\n",
      "[1364/1762] D loss: 1.0644, G loss: 1.1244\n",
      "[1444/1762] D loss: 1.3867, G loss: 0.6986\n",
      "[1524/1762] D loss: 1.0476, G loss: 1.4638\n",
      "[1604/1762] D loss: 1.0441, G loss: 1.5559\n",
      "[1684/1762] D loss: 1.2305, G loss: 1.1693\n",
      "[1762/1762] D loss: 0.7280, G loss: 1.7069\n",
      "train error: \n",
      " D loss: 1.303063, G loss: 0.860485, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.293471, G loss: 0.894686, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0496, G loss: 1.3416\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6931\n",
      "[164/1762] D loss: 1.0590, G loss: 1.1743\n",
      "[244/1762] D loss: 1.3871, G loss: 0.6995\n",
      "[324/1762] D loss: 1.0584, G loss: 1.1785\n",
      "[404/1762] D loss: 1.3848, G loss: 0.7061\n",
      "[484/1762] D loss: 1.3844, G loss: 0.6828\n",
      "[564/1762] D loss: 1.3869, G loss: 0.6726\n",
      "[644/1762] D loss: 1.5045, G loss: 0.8955\n",
      "[724/1762] D loss: 1.3873, G loss: 0.6602\n",
      "[804/1762] D loss: 1.3867, G loss: 0.6872\n",
      "[884/1762] D loss: 1.0599, G loss: 1.1713\n",
      "[964/1762] D loss: 1.3867, G loss: 0.7092\n",
      "[1044/1762] D loss: 1.0611, G loss: 1.1327\n",
      "[1124/1762] D loss: 1.3872, G loss: 0.6774\n",
      "[1204/1762] D loss: 1.3861, G loss: 0.6841\n",
      "[1284/1762] D loss: 1.3919, G loss: 0.7127\n",
      "[1364/1762] D loss: 1.3874, G loss: 0.6687\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.6858\n",
      "[1524/1762] D loss: 1.0573, G loss: 1.2103\n",
      "[1604/1762] D loss: 1.3866, G loss: 0.7082\n",
      "[1684/1762] D loss: 1.0402, G loss: 3.8052\n",
      "[1762/1762] D loss: 1.3847, G loss: 0.6790\n",
      "train error: \n",
      " D loss: 1.298897, G loss: 0.880368, D accuracy: 55.2%, cell accuracy: 99.7%, board accuracy: 69.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.292178, G loss: 0.888752, D accuracy: 55.7%, cell accuracy: 99.6%, board accuracy: 67.5% \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0531, G loss: 1.2423\n",
      "[84/1762] D loss: 1.3435, G loss: 0.7343\n",
      "[164/1762] D loss: 1.3808, G loss: 0.6889\n",
      "[244/1762] D loss: 1.6967, G loss: 1.1159\n",
      "[324/1762] D loss: 1.3871, G loss: 0.6767\n",
      "[404/1762] D loss: 1.0671, G loss: 1.0075\n",
      "[484/1762] D loss: 1.0566, G loss: 1.2074\n",
      "[564/1762] D loss: 0.8996, G loss: 4.0203\n",
      "[644/1762] D loss: 1.3869, G loss: 0.6845\n",
      "[724/1762] D loss: 1.3868, G loss: 0.6817\n",
      "[804/1762] D loss: 1.2144, G loss: 1.8950\n",
      "[884/1762] D loss: 1.0589, G loss: 1.1781\n",
      "[964/1762] D loss: 0.7320, G loss: 1.6902\n",
      "[1044/1762] D loss: 1.3873, G loss: 0.6662\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.6816\n",
      "[1204/1762] D loss: 1.0639, G loss: 1.1249\n",
      "[1284/1762] D loss: 1.3829, G loss: 0.6801\n",
      "[1364/1762] D loss: 1.7428, G loss: 1.1737\n",
      "[1444/1762] D loss: 1.3877, G loss: 0.6733\n",
      "[1524/1762] D loss: 1.3868, G loss: 0.6749\n",
      "[1604/1762] D loss: 1.3865, G loss: 0.6818\n",
      "[1684/1762] D loss: 1.0561, G loss: 1.2028\n",
      "[1762/1762] D loss: 1.1231, G loss: 1.5302\n",
      "train error: \n",
      " D loss: 1.302027, G loss: 0.880478, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.292470, G loss: 0.875690, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3866, G loss: 0.6823\n",
      "[84/1762] D loss: 1.1919, G loss: 4.5931\n",
      "[164/1762] D loss: 1.3869, G loss: 0.6842\n",
      "[244/1762] D loss: 1.3866, G loss: 0.6806\n",
      "[324/1762] D loss: 1.3868, G loss: 0.6780\n",
      "[404/1762] D loss: 1.3866, G loss: 0.7079\n",
      "[484/1762] D loss: 1.9640, G loss: 1.3019\n",
      "[564/1762] D loss: 1.0672, G loss: 1.0760\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6871\n",
      "[724/1762] D loss: 1.0410, G loss: 1.8656\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6882\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6894\n",
      "[964/1762] D loss: 1.3864, G loss: 0.6901\n",
      "[1044/1762] D loss: 1.3866, G loss: 0.6913\n",
      "[1124/1762] D loss: 1.1014, G loss: 0.9093\n",
      "[1204/1762] D loss: 1.0795, G loss: 1.0007\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6904\n",
      "[1364/1762] D loss: 1.0561, G loss: 1.2114\n",
      "[1444/1762] D loss: 1.3867, G loss: 0.6737\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.6941\n",
      "[1604/1762] D loss: 1.0623, G loss: 1.1273\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6958\n",
      "[1762/1762] D loss: 0.6981, G loss: 2.6510\n",
      "train error: \n",
      " D loss: 1.301845, G loss: 0.896477, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.298025, G loss: 0.964974, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0559, G loss: 1.2162\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6848\n",
      "[164/1762] D loss: 1.3866, G loss: 0.6770\n",
      "[244/1762] D loss: 1.0778, G loss: 1.0235\n",
      "[324/1762] D loss: 1.3830, G loss: 0.7007\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6859\n",
      "[484/1762] D loss: 0.7929, G loss: 1.2370\n",
      "[564/1762] D loss: 1.3863, G loss: 0.6952\n",
      "[644/1762] D loss: 1.3869, G loss: 0.6956\n",
      "[724/1762] D loss: 1.0621, G loss: 1.1333\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6937\n",
      "[884/1762] D loss: 1.0443, G loss: 1.5305\n",
      "[964/1762] D loss: 1.3871, G loss: 0.6964\n",
      "[1044/1762] D loss: 1.3866, G loss: 0.6756\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.6827\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6878\n",
      "[1284/1762] D loss: 1.3866, G loss: 0.6787\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6798\n",
      "[1444/1762] D loss: 1.3832, G loss: 0.6884\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.6918\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6977\n",
      "[1684/1762] D loss: 1.3911, G loss: 0.7311\n",
      "[1762/1762] D loss: 1.3866, G loss: 0.6766\n",
      "train error: \n",
      " D loss: 1.269497, G loss: 1.056783, D accuracy: 56.1%, cell accuracy: 99.7%, board accuracy: 84.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.270744, G loss: 1.077037, D accuracy: 56.7%, cell accuracy: 99.6%, board accuracy: 83.6% \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3865, G loss: 0.6739\n",
      "[84/1762] D loss: 1.3934, G loss: 0.6110\n",
      "[164/1762] D loss: 1.3985, G loss: 0.5866\n",
      "[244/1762] D loss: 1.3903, G loss: 0.6850\n",
      "[324/1762] D loss: 1.3887, G loss: 0.6977\n",
      "[404/1762] D loss: 1.3879, G loss: 0.6569\n",
      "[484/1762] D loss: 1.5671, G loss: 0.9925\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6894\n",
      "[644/1762] D loss: 1.3864, G loss: 0.6855\n",
      "[724/1762] D loss: 0.3855, G loss: 2.6146\n",
      "[804/1762] D loss: 1.0425, G loss: 1.6385\n",
      "[884/1762] D loss: 1.0489, G loss: 1.3674\n",
      "[964/1762] D loss: 1.0787, G loss: 1.0030\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.6858\n",
      "[1124/1762] D loss: 1.3859, G loss: 0.6699\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6873\n",
      "[1284/1762] D loss: 1.0721, G loss: 1.0606\n",
      "[1364/1762] D loss: 1.0476, G loss: 1.3218\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6840\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.6851\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6988\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.6850\n",
      "[1762/1762] D loss: 0.6971, G loss: 2.7902\n",
      "train error: \n",
      " D loss: 1.302933, G loss: 0.905667, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.301536, G loss: 0.946116, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6875\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6910\n",
      "[164/1762] D loss: 1.3864, G loss: 0.6856\n",
      "[244/1762] D loss: 1.3871, G loss: 0.7013\n",
      "[324/1762] D loss: 1.1146, G loss: 0.8396\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6836\n",
      "[484/1762] D loss: 1.3863, G loss: 0.6954\n",
      "[564/1762] D loss: 1.3863, G loss: 0.6944\n",
      "[644/1762] D loss: 1.0417, G loss: 1.7563\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6893\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6821\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6871\n",
      "[964/1762] D loss: 0.9523, G loss: 1.2655\n",
      "[1044/1762] D loss: 1.3865, G loss: 0.6866\n",
      "[1124/1762] D loss: 1.3858, G loss: 0.6977\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6901\n",
      "[1284/1762] D loss: 1.3859, G loss: 0.6962\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6928\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6860\n",
      "[1524/1762] D loss: 1.3861, G loss: 0.6858\n",
      "[1604/1762] D loss: 1.3865, G loss: 0.6820\n",
      "[1684/1762] D loss: 0.7475, G loss: 1.5025\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6959\n",
      "train error: \n",
      " D loss: 1.302101, G loss: 0.885436, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.297309, G loss: 0.923591, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0461, G loss: 1.4473\n",
      "[84/1762] D loss: 1.0435, G loss: 1.5767\n",
      "[164/1762] D loss: 1.3864, G loss: 0.6847\n",
      "[244/1762] D loss: 1.0581, G loss: 1.1844\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6908\n",
      "[404/1762] D loss: 1.0621, G loss: 1.1199\n",
      "[484/1762] D loss: 1.3864, G loss: 0.6814\n",
      "[564/1762] D loss: 1.3865, G loss: 0.6793\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6970\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6930\n",
      "[804/1762] D loss: 1.0538, G loss: 1.2489\n",
      "[884/1762] D loss: 1.2275, G loss: 1.2066\n",
      "[964/1762] D loss: 1.3866, G loss: 0.6777\n",
      "[1044/1762] D loss: 1.3866, G loss: 0.6765\n",
      "[1124/1762] D loss: 1.0652, G loss: 1.1170\n",
      "[1204/1762] D loss: 1.3869, G loss: 0.6680\n",
      "[1284/1762] D loss: 1.3867, G loss: 0.6749\n",
      "[1364/1762] D loss: 1.3868, G loss: 0.6737\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6954\n",
      "[1524/1762] D loss: 1.0674, G loss: 1.1056\n",
      "[1604/1762] D loss: 1.0633, G loss: 1.1198\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6934\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6933\n",
      "train error: \n",
      " D loss: 1.303610, G loss: 0.850724, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.293149, G loss: 0.868563, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.7004\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6894\n",
      "[164/1762] D loss: 1.0435, G loss: 1.5590\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6983\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6939\n",
      "[404/1762] D loss: 1.3863, G loss: 0.6958\n",
      "[484/1762] D loss: 1.3863, G loss: 0.6931\n",
      "[564/1762] D loss: 1.3863, G loss: 0.6951\n",
      "[644/1762] D loss: 1.3864, G loss: 0.6995\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6954\n",
      "[804/1762] D loss: 1.0418, G loss: 1.7344\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6912\n",
      "[964/1762] D loss: 1.4130, G loss: 0.7644\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.6889\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6964\n",
      "[1204/1762] D loss: 1.3866, G loss: 0.6801\n",
      "[1284/1762] D loss: 1.2173, G loss: 1.4221\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6912\n",
      "[1444/1762] D loss: 1.3866, G loss: 0.6928\n",
      "[1524/1762] D loss: 1.3830, G loss: 0.6949\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6869\n",
      "[1684/1762] D loss: 1.0806, G loss: 0.9894\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6811\n",
      "train error: \n",
      " D loss: 1.305057, G loss: 0.808393, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.298155, G loss: 0.817446, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4074, G loss: 0.7335\n",
      "[84/1762] D loss: 1.4025, G loss: 0.7596\n",
      "[164/1762] D loss: 1.3864, G loss: 0.7003\n",
      "[244/1762] D loss: 1.3858, G loss: 0.6902\n",
      "[324/1762] D loss: 1.3864, G loss: 0.6861\n",
      "[404/1762] D loss: 1.3831, G loss: 0.6958\n",
      "[484/1762] D loss: 1.3864, G loss: 0.6856\n",
      "[564/1762] D loss: 1.3863, G loss: 0.6885\n",
      "[644/1762] D loss: 1.0545, G loss: 1.2398\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6859\n",
      "[804/1762] D loss: 1.0446, G loss: 1.5101\n",
      "[884/1762] D loss: 1.3864, G loss: 0.7005\n",
      "[964/1762] D loss: 1.3864, G loss: 0.6829\n",
      "[1044/1762] D loss: 1.3865, G loss: 0.6815\n",
      "[1124/1762] D loss: 1.0400, G loss: 2.9370\n",
      "[1204/1762] D loss: 1.3865, G loss: 0.6829\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6914\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.7028\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6940\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.6977\n",
      "[1604/1762] D loss: 1.0856, G loss: 0.9659\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.6929\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6916\n",
      "train error: \n",
      " D loss: 1.303362, G loss: 0.904759, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 91.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.298063, G loss: 0.934327, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.8721, G loss: 1.2903\n",
      "[84/1762] D loss: 1.3866, G loss: 0.6753\n",
      "[164/1762] D loss: 1.3865, G loss: 0.6981\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6906\n",
      "[324/1762] D loss: 1.3864, G loss: 0.6866\n",
      "[404/1762] D loss: 1.0444, G loss: 1.5230\n",
      "[484/1762] D loss: 1.3864, G loss: 0.7033\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6815\n",
      "[644/1762] D loss: 1.3864, G loss: 0.6955\n",
      "[724/1762] D loss: 1.3861, G loss: 0.6910\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6941\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6935\n",
      "[964/1762] D loss: 1.0485, G loss: 1.3666\n",
      "[1044/1762] D loss: 1.0416, G loss: 1.7897\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.6881\n",
      "[1204/1762] D loss: 1.3866, G loss: 0.6770\n",
      "[1284/1762] D loss: 1.1080, G loss: 0.8764\n",
      "[1364/1762] D loss: 1.3861, G loss: 0.7008\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6917\n",
      "[1524/1762] D loss: 1.3861, G loss: 0.6955\n",
      "[1604/1762] D loss: 1.0508, G loss: 1.2920\n",
      "[1684/1762] D loss: 1.3867, G loss: 0.6917\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6893\n",
      "train error: \n",
      " D loss: 1.299469, G loss: 0.902350, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 90.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.298846, G loss: 0.900499, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6855\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6959\n",
      "[164/1762] D loss: 1.3862, G loss: 0.6961\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6873\n",
      "[324/1762] D loss: 1.3865, G loss: 0.6815\n",
      "[404/1762] D loss: 0.6955, G loss: 3.0742\n",
      "[484/1762] D loss: 1.3843, G loss: 0.6635\n",
      "[564/1762] D loss: 1.3809, G loss: 0.6927\n",
      "[644/1762] D loss: 1.3731, G loss: 0.6384\n",
      "[724/1762] D loss: 1.0446, G loss: 1.4523\n",
      "[804/1762] D loss: 1.3871, G loss: 0.6288\n",
      "[884/1762] D loss: 1.0443, G loss: 2.4789\n",
      "[964/1762] D loss: 1.3751, G loss: 0.6292\n",
      "[1044/1762] D loss: 1.3889, G loss: 0.6894\n",
      "[1124/1762] D loss: 0.7136, G loss: 1.6772\n",
      "[1204/1762] D loss: 1.4718, G loss: 0.4869\n",
      "[1284/1762] D loss: 1.3905, G loss: 0.7542\n",
      "[1364/1762] D loss: 1.3899, G loss: 0.7494\n",
      "[1444/1762] D loss: 0.7432, G loss: 2.1258\n",
      "[1524/1762] D loss: 1.0428, G loss: 1.7468\n",
      "[1604/1762] D loss: 1.3872, G loss: 0.6967\n",
      "[1684/1762] D loss: 1.3869, G loss: 0.6740\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.7132\n",
      "train error: \n",
      " D loss: 1.303823, G loss: 0.886435, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.304147, G loss: 0.907853, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 91.1% \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6937\n",
      "[84/1762] D loss: 1.3871, G loss: 0.6969\n",
      "[164/1762] D loss: 1.0596, G loss: 1.1624\n",
      "[244/1762] D loss: 1.3871, G loss: 0.7011\n",
      "[324/1762] D loss: 1.3864, G loss: 0.6929\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6948\n",
      "[484/1762] D loss: 1.3865, G loss: 0.7070\n",
      "[564/1762] D loss: 1.3874, G loss: 0.7200\n",
      "[644/1762] D loss: 1.3868, G loss: 0.6991\n",
      "[724/1762] D loss: 1.3866, G loss: 0.7051\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6952\n",
      "[884/1762] D loss: 1.0526, G loss: 1.2684\n",
      "[964/1762] D loss: 1.3869, G loss: 0.7007\n",
      "[1044/1762] D loss: 1.3870, G loss: 0.7135\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.6842\n",
      "[1204/1762] D loss: 1.3867, G loss: 0.7004\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6876\n",
      "[1364/1762] D loss: 1.3865, G loss: 0.6899\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.6881\n",
      "[1524/1762] D loss: 1.3865, G loss: 0.6867\n",
      "[1604/1762] D loss: 1.3865, G loss: 0.6917\n",
      "[1684/1762] D loss: 1.0386, G loss: 2.6345\n",
      "[1762/1762] D loss: 1.3866, G loss: 0.6891\n",
      "train error: \n",
      " D loss: 1.293529, G loss: 1.089269, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 91.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.284075, G loss: 1.206396, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0407, G loss: 2.0215\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6961\n",
      "[164/1762] D loss: 1.3871, G loss: 0.6730\n",
      "[244/1762] D loss: 1.3865, G loss: 0.6889\n",
      "[324/1762] D loss: 1.3862, G loss: 0.6884\n",
      "[404/1762] D loss: 1.0399, G loss: 2.8141\n",
      "[484/1762] D loss: 1.3863, G loss: 0.6961\n",
      "[564/1762] D loss: 1.3865, G loss: 0.6857\n",
      "[644/1762] D loss: 1.3864, G loss: 0.6896\n",
      "[724/1762] D loss: 1.0398, G loss: 2.8955\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6819\n",
      "[884/1762] D loss: 1.3866, G loss: 0.6862\n",
      "[964/1762] D loss: 1.0399, G loss: 2.4668\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.6898\n",
      "[1124/1762] D loss: 1.3866, G loss: 0.6971\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6983\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6849\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6970\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.6804\n",
      "[1524/1762] D loss: 1.3865, G loss: 0.7008\n",
      "[1604/1762] D loss: 1.2111, G loss: 0.6961\n",
      "[1684/1762] D loss: 1.3879, G loss: 0.6882\n",
      "[1762/1762] D loss: 1.0420, G loss: 0.6916\n",
      "train error: \n",
      " D loss: 1.289637, G loss: 1.112305, D accuracy: 58.6%, cell accuracy: 99.6%, board accuracy: 69.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.266575, G loss: 1.260551, D accuracy: 59.5%, cell accuracy: 99.5%, board accuracy: 66.8% \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0329, G loss: 2.4213\n",
      "[84/1762] D loss: 1.3755, G loss: 0.6673\n",
      "[164/1762] D loss: 1.0052, G loss: 2.3638\n",
      "[244/1762] D loss: 1.3930, G loss: 0.6310\n",
      "[324/1762] D loss: 1.3913, G loss: 0.6684\n",
      "[404/1762] D loss: 1.0856, G loss: 2.4605\n",
      "[484/1762] D loss: 1.0404, G loss: 2.1473\n",
      "[564/1762] D loss: 1.3379, G loss: 0.7142\n",
      "[644/1762] D loss: 1.3889, G loss: 0.7445\n",
      "[724/1762] D loss: 1.3947, G loss: 0.6660\n",
      "[804/1762] D loss: 1.3892, G loss: 0.6441\n",
      "[884/1762] D loss: 1.2007, G loss: 1.6028\n",
      "[964/1762] D loss: 1.3924, G loss: 0.7401\n",
      "[1044/1762] D loss: 1.3887, G loss: 0.7308\n",
      "[1124/1762] D loss: 1.3953, G loss: 0.6126\n",
      "[1204/1762] D loss: 1.3876, G loss: 0.6839\n",
      "[1284/1762] D loss: 1.0404, G loss: 2.1146\n",
      "[1364/1762] D loss: 1.3853, G loss: 0.6925\n",
      "[1444/1762] D loss: 1.3880, G loss: 0.6603\n",
      "[1524/1762] D loss: 1.3851, G loss: 0.6823\n",
      "[1604/1762] D loss: 1.3862, G loss: 0.7017\n",
      "[1684/1762] D loss: 1.3836, G loss: 0.7178\n",
      "[1762/1762] D loss: 0.6732, G loss: 4.6109\n",
      "train error: \n",
      " D loss: 1.283484, G loss: 1.306314, D accuracy: 57.5%, cell accuracy: 99.6%, board accuracy: 63.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.263872, G loss: 1.530704, D accuracy: 57.7%, cell accuracy: 99.5%, board accuracy: 63.4% \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3891, G loss: 0.6373\n",
      "[84/1762] D loss: 1.3842, G loss: 0.6471\n",
      "[164/1762] D loss: 1.3882, G loss: 0.6727\n",
      "[244/1762] D loss: 1.3870, G loss: 0.7082\n",
      "[324/1762] D loss: 1.3882, G loss: 0.7254\n",
      "[404/1762] D loss: 1.3865, G loss: 0.6724\n",
      "[484/1762] D loss: 1.3875, G loss: 0.6811\n",
      "[564/1762] D loss: 1.0453, G loss: 1.5202\n",
      "[644/1762] D loss: 1.6638, G loss: 0.9108\n",
      "[724/1762] D loss: 1.3870, G loss: 0.7088\n",
      "[804/1762] D loss: 1.3869, G loss: 0.6700\n",
      "[884/1762] D loss: 1.3867, G loss: 0.7078\n",
      "[964/1762] D loss: 1.3867, G loss: 0.6880\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6983\n",
      "[1124/1762] D loss: 1.3867, G loss: 0.6807\n",
      "[1204/1762] D loss: 1.3870, G loss: 0.6734\n",
      "[1284/1762] D loss: 1.3865, G loss: 0.6953\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6847\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6910\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.6933\n",
      "[1604/1762] D loss: 1.3875, G loss: 0.6660\n",
      "[1684/1762] D loss: 1.5514, G loss: 1.1387\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6989\n",
      "train error: \n",
      " D loss: 1.301636, G loss: 0.876195, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.306904, G loss: 0.852785, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3866, G loss: 0.6783\n",
      "[84/1762] D loss: 1.3866, G loss: 0.6916\n",
      "[164/1762] D loss: 1.3865, G loss: 0.6917\n",
      "[244/1762] D loss: 1.0412, G loss: 1.8028\n",
      "[324/1762] D loss: 1.3866, G loss: 0.7042\n",
      "[404/1762] D loss: 1.0475, G loss: 1.9351\n",
      "[484/1762] D loss: 0.7305, G loss: 1.6933\n",
      "[564/1762] D loss: 1.5695, G loss: 0.9250\n",
      "[644/1762] D loss: 1.3866, G loss: 0.6946\n",
      "[724/1762] D loss: 1.3866, G loss: 0.6912\n",
      "[804/1762] D loss: 1.1046, G loss: 0.8944\n",
      "[884/1762] D loss: 1.0487, G loss: 1.4925\n",
      "[964/1762] D loss: 1.3867, G loss: 0.6732\n",
      "[1044/1762] D loss: 1.3867, G loss: 0.6785\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.6989\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6979\n",
      "[1284/1762] D loss: 1.0411, G loss: 1.8378\n",
      "[1364/1762] D loss: 1.0512, G loss: 1.3133\n",
      "[1444/1762] D loss: 1.3866, G loss: 0.6976\n",
      "[1524/1762] D loss: 1.3866, G loss: 0.7103\n",
      "[1604/1762] D loss: 1.0401, G loss: 2.1632\n",
      "[1684/1762] D loss: 1.3872, G loss: 0.6817\n",
      "[1762/1762] D loss: 1.3866, G loss: 0.7100\n",
      "train error: \n",
      " D loss: 1.301557, G loss: 0.933953, D accuracy: 53.4%, cell accuracy: 99.9%, board accuracy: 92.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.303151, G loss: 0.946843, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 91.1% \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3870, G loss: 0.6936\n",
      "[84/1762] D loss: 1.3869, G loss: 0.6778\n",
      "[164/1762] D loss: 1.3864, G loss: 0.6955\n",
      "[244/1762] D loss: 1.3870, G loss: 0.6840\n",
      "[324/1762] D loss: 1.3866, G loss: 0.6979\n",
      "[404/1762] D loss: 1.3866, G loss: 0.6813\n",
      "[484/1762] D loss: 1.3864, G loss: 0.6885\n",
      "[564/1762] D loss: 1.3868, G loss: 0.6894\n",
      "[644/1762] D loss: 1.3864, G loss: 0.6911\n",
      "[724/1762] D loss: 1.3872, G loss: 0.7178\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6858\n",
      "[884/1762] D loss: 1.6213, G loss: 1.0662\n",
      "[964/1762] D loss: 1.3867, G loss: 0.6751\n",
      "[1044/1762] D loss: 1.0503, G loss: 1.3482\n",
      "[1124/1762] D loss: 1.0843, G loss: 0.9977\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6910\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6869\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6917\n",
      "[1444/1762] D loss: 1.0560, G loss: 1.2314\n",
      "[1524/1762] D loss: 1.3860, G loss: 0.6975\n",
      "[1604/1762] D loss: 1.3867, G loss: 0.6738\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.6811\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.6996\n",
      "train error: \n",
      " D loss: 1.311768, G loss: 1.174517, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.334324, G loss: 1.273708, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6950\n",
      "[84/1762] D loss: 1.3861, G loss: 0.6916\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6966\n",
      "[244/1762] D loss: 1.3862, G loss: 0.6896\n",
      "[324/1762] D loss: 1.3864, G loss: 0.6874\n",
      "[404/1762] D loss: 1.3859, G loss: 0.6984\n",
      "[484/1762] D loss: 1.3864, G loss: 0.6912\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6896\n",
      "[644/1762] D loss: 0.7006, G loss: 2.7146\n",
      "[724/1762] D loss: 1.3871, G loss: 0.6942\n",
      "[804/1762] D loss: 1.3862, G loss: 0.6817\n",
      "[884/1762] D loss: 1.0400, G loss: 2.2400\n",
      "[964/1762] D loss: 1.3862, G loss: 0.6924\n",
      "[1044/1762] D loss: 0.9457, G loss: 0.9202\n",
      "[1124/1762] D loss: 1.0595, G loss: 1.1743\n",
      "[1204/1762] D loss: 1.3861, G loss: 0.6913\n",
      "[1284/1762] D loss: 1.1140, G loss: 0.8741\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6819\n",
      "[1444/1762] D loss: 1.3866, G loss: 0.6908\n",
      "[1524/1762] D loss: 1.3870, G loss: 0.6748\n",
      "[1604/1762] D loss: 1.3868, G loss: 0.7004\n",
      "[1684/1762] D loss: 1.3865, G loss: 0.6684\n",
      "[1762/1762] D loss: 1.3897, G loss: 0.6356\n",
      "train error: \n",
      " D loss: 1.291465, G loss: 0.991425, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 76.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.292126, G loss: 1.016458, D accuracy: 55.3%, cell accuracy: 99.7%, board accuracy: 73.6% \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3884, G loss: 0.6527\n",
      "[84/1762] D loss: 1.3862, G loss: 0.6659\n",
      "[164/1762] D loss: 1.3831, G loss: 0.7175\n",
      "[244/1762] D loss: 1.3798, G loss: 0.6972\n",
      "[324/1762] D loss: 1.0481, G loss: 1.4201\n",
      "[404/1762] D loss: 1.3702, G loss: 0.6860\n",
      "[484/1762] D loss: 1.3942, G loss: 0.7034\n",
      "[564/1762] D loss: 1.3899, G loss: 0.7480\n",
      "[644/1762] D loss: 1.3816, G loss: 0.6925\n",
      "[724/1762] D loss: 1.3869, G loss: 0.7106\n",
      "[804/1762] D loss: 1.3864, G loss: 0.7015\n",
      "[884/1762] D loss: 1.3866, G loss: 0.7075\n",
      "[964/1762] D loss: 1.3856, G loss: 0.7008\n",
      "[1044/1762] D loss: 1.3873, G loss: 0.6637\n",
      "[1124/1762] D loss: 1.3868, G loss: 0.6843\n",
      "[1204/1762] D loss: 1.4496, G loss: 0.8211\n",
      "[1284/1762] D loss: 1.3871, G loss: 0.6805\n",
      "[1364/1762] D loss: 1.3866, G loss: 0.6841\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6964\n",
      "[1524/1762] D loss: 1.3819, G loss: 0.7040\n",
      "[1604/1762] D loss: 1.3867, G loss: 0.7052\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.6944\n",
      "[1762/1762] D loss: 1.3874, G loss: 0.6639\n",
      "train error: \n",
      " D loss: 1.305059, G loss: 1.211829, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 91.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.329032, G loss: 1.381823, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0384, G loss: 2.7133\n",
      "[84/1762] D loss: 1.3868, G loss: 0.6866\n",
      "[164/1762] D loss: 1.7499, G loss: 4.2201\n",
      "[244/1762] D loss: 1.3866, G loss: 0.6820\n",
      "[324/1762] D loss: 1.0647, G loss: 1.1202\n",
      "[404/1762] D loss: 1.3860, G loss: 0.6977\n",
      "[484/1762] D loss: 1.0928, G loss: 0.9416\n",
      "[564/1762] D loss: 1.3870, G loss: 0.6670\n",
      "[644/1762] D loss: 1.3865, G loss: 0.6837\n",
      "[724/1762] D loss: 1.0665, G loss: 1.0982\n",
      "[804/1762] D loss: 1.3873, G loss: 0.6933\n",
      "[884/1762] D loss: 1.0619, G loss: 1.2680\n",
      "[964/1762] D loss: 1.3895, G loss: 0.6538\n",
      "[1044/1762] D loss: 1.0420, G loss: 1.7233\n",
      "[1124/1762] D loss: 1.3849, G loss: 0.6871\n",
      "[1204/1762] D loss: 1.3880, G loss: 0.6621\n",
      "[1284/1762] D loss: 1.3865, G loss: 0.6763\n",
      "[1364/1762] D loss: 1.3865, G loss: 0.6947\n",
      "[1444/1762] D loss: 1.2533, G loss: 0.6626\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.6947\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.7015\n",
      "[1684/1762] D loss: 0.7097, G loss: 2.3542\n",
      "[1762/1762] D loss: 0.7056, G loss: 2.2364\n",
      "train error: \n",
      " D loss: 1.300471, G loss: 0.939878, D accuracy: 53.4%, cell accuracy: 99.9%, board accuracy: 93.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.306249, G loss: 1.047462, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6937\n",
      "[84/1762] D loss: 1.0417, G loss: 1.7816\n",
      "[164/1762] D loss: 1.3870, G loss: 0.6755\n",
      "[244/1762] D loss: 1.3864, G loss: 0.6868\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6958\n",
      "[404/1762] D loss: 1.3866, G loss: 0.6949\n",
      "[484/1762] D loss: 1.3865, G loss: 0.7021\n",
      "[564/1762] D loss: 1.3866, G loss: 0.7005\n",
      "[644/1762] D loss: 1.3865, G loss: 0.7064\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6975\n",
      "[804/1762] D loss: 1.3863, G loss: 0.6923\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6923\n",
      "[964/1762] D loss: 1.3863, G loss: 0.6934\n",
      "[1044/1762] D loss: 1.3751, G loss: 0.6895\n",
      "[1124/1762] D loss: 0.7213, G loss: 1.9421\n",
      "[1204/1762] D loss: 1.0546, G loss: 1.2336\n",
      "[1284/1762] D loss: 1.3869, G loss: 0.7075\n",
      "[1364/1762] D loss: 0.6975, G loss: 4.4259\n",
      "[1444/1762] D loss: 1.0608, G loss: 1.1654\n",
      "[1524/1762] D loss: 1.3866, G loss: 0.7092\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6900\n",
      "[1684/1762] D loss: 1.3865, G loss: 0.6985\n",
      "[1762/1762] D loss: 0.6937, G loss: 3.7536\n",
      "train error: \n",
      " D loss: 1.297851, G loss: 1.122665, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.321866, G loss: 1.305388, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3869, G loss: 0.6699\n",
      "[84/1762] D loss: 1.3866, G loss: 0.6875\n",
      "[164/1762] D loss: 1.3867, G loss: 0.6724\n",
      "[244/1762] D loss: 1.0320, G loss: 2.0673\n",
      "[324/1762] D loss: 1.3876, G loss: 0.6658\n",
      "[404/1762] D loss: 1.3870, G loss: 0.6791\n",
      "[484/1762] D loss: 1.0518, G loss: 1.3054\n",
      "[564/1762] D loss: 1.3860, G loss: 0.6966\n",
      "[644/1762] D loss: 1.3860, G loss: 0.6874\n",
      "[724/1762] D loss: 1.4700, G loss: 1.1751\n",
      "[804/1762] D loss: 1.3865, G loss: 0.6965\n",
      "[884/1762] D loss: 1.0357, G loss: 2.1275\n",
      "[964/1762] D loss: 1.3880, G loss: 0.6555\n",
      "[1044/1762] D loss: 1.3884, G loss: 0.6497\n",
      "[1124/1762] D loss: 1.3866, G loss: 0.6948\n",
      "[1204/1762] D loss: 1.3874, G loss: 0.6689\n",
      "[1284/1762] D loss: 1.3867, G loss: 0.6900\n",
      "[1364/1762] D loss: 1.3891, G loss: 0.7224\n",
      "[1444/1762] D loss: 1.0590, G loss: 1.1671\n",
      "[1524/1762] D loss: 1.3865, G loss: 0.6916\n",
      "[1604/1762] D loss: 1.0456, G loss: 1.4392\n",
      "[1684/1762] D loss: 1.3866, G loss: 0.6849\n",
      "[1762/1762] D loss: 0.6920, G loss: 5.6874\n",
      "train error: \n",
      " D loss: 1.300093, G loss: 0.983350, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.315527, G loss: 1.008524, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6877\n",
      "[84/1762] D loss: 1.3866, G loss: 0.7035\n",
      "[164/1762] D loss: 1.0425, G loss: 2.4322\n",
      "[244/1762] D loss: 1.3865, G loss: 0.6854\n",
      "[324/1762] D loss: 1.3867, G loss: 0.7181\n",
      "[404/1762] D loss: 1.0406, G loss: 2.4779\n",
      "[484/1762] D loss: 1.3863, G loss: 0.6819\n",
      "[564/1762] D loss: 1.0403, G loss: 3.1313\n",
      "[644/1762] D loss: 1.3856, G loss: 0.7063\n",
      "[724/1762] D loss: 1.0431, G loss: 1.9115\n",
      "[804/1762] D loss: 1.0401, G loss: 2.1864\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6953\n",
      "[964/1762] D loss: 1.3868, G loss: 0.7084\n",
      "[1044/1762] D loss: 1.3867, G loss: 0.6951\n",
      "[1124/1762] D loss: 1.3911, G loss: 0.6808\n",
      "[1204/1762] D loss: 1.3865, G loss: 0.6837\n",
      "[1284/1762] D loss: 1.0407, G loss: 2.0488\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6950\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6881\n",
      "[1524/1762] D loss: 1.0398, G loss: 2.8808\n",
      "[1604/1762] D loss: 1.3869, G loss: 0.6820\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.6986\n",
      "[1762/1762] D loss: 0.7156, G loss: 1.9813\n",
      "train error: \n",
      " D loss: 1.299928, G loss: 0.912565, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.310531, G loss: 0.921856, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0721, G loss: 1.0716\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6912\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6961\n",
      "[244/1762] D loss: 1.3865, G loss: 0.6802\n",
      "[324/1762] D loss: 1.3864, G loss: 0.7067\n",
      "[404/1762] D loss: 1.0770, G loss: 1.0120\n",
      "[484/1762] D loss: 1.0450, G loss: 1.4848\n",
      "[564/1762] D loss: 1.3873, G loss: 0.6746\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6983\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6991\n",
      "[804/1762] D loss: 1.3870, G loss: 0.6900\n",
      "[884/1762] D loss: 1.3865, G loss: 0.6929\n",
      "[964/1762] D loss: 1.3845, G loss: 0.6905\n",
      "[1044/1762] D loss: 1.3865, G loss: 0.7012\n",
      "[1124/1762] D loss: 1.3860, G loss: 0.6992\n",
      "[1204/1762] D loss: 1.3871, G loss: 0.6777\n",
      "[1284/1762] D loss: 1.3879, G loss: 0.7096\n",
      "[1364/1762] D loss: 1.3910, G loss: 0.6335\n",
      "[1444/1762] D loss: 1.3876, G loss: 0.7226\n",
      "[1524/1762] D loss: 1.3862, G loss: 0.6976\n",
      "[1604/1762] D loss: 1.3835, G loss: 0.6897\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.6947\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.7026\n",
      "train error: \n",
      " D loss: 1.297147, G loss: 1.044790, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.318978, G loss: 1.073788, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3866, G loss: 0.6816\n",
      "[84/1762] D loss: 1.3859, G loss: 0.6951\n",
      "[164/1762] D loss: 1.3859, G loss: 0.6899\n",
      "[244/1762] D loss: 1.2058, G loss: 3.9222\n",
      "[324/1762] D loss: 1.3895, G loss: 0.6555\n",
      "[404/1762] D loss: 1.0605, G loss: 1.2720\n",
      "[484/1762] D loss: 1.3866, G loss: 0.6957\n",
      "[564/1762] D loss: 1.0564, G loss: 1.2314\n",
      "[644/1762] D loss: 1.3866, G loss: 0.7043\n",
      "[724/1762] D loss: 1.3866, G loss: 0.6792\n",
      "[804/1762] D loss: 1.3867, G loss: 0.6781\n",
      "[884/1762] D loss: 1.3880, G loss: 0.7038\n",
      "[964/1762] D loss: 1.3862, G loss: 0.6904\n",
      "[1044/1762] D loss: 1.0423, G loss: 1.7067\n",
      "[1124/1762] D loss: 1.0418, G loss: 2.5936\n",
      "[1204/1762] D loss: 1.0404, G loss: 2.0761\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6966\n",
      "[1364/1762] D loss: 1.3866, G loss: 0.6990\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.6858\n",
      "[1524/1762] D loss: 1.3865, G loss: 0.6885\n",
      "[1604/1762] D loss: 1.3856, G loss: 0.6958\n",
      "[1684/1762] D loss: 1.0407, G loss: 1.9721\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6861\n",
      "train error: \n",
      " D loss: 1.300289, G loss: 0.932219, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.315175, G loss: 0.966415, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3867, G loss: 0.6995\n",
      "[84/1762] D loss: 1.3865, G loss: 0.6863\n",
      "[164/1762] D loss: 1.3866, G loss: 0.6779\n",
      "[244/1762] D loss: 1.3864, G loss: 0.6897\n",
      "[324/1762] D loss: 1.3868, G loss: 0.6776\n",
      "[404/1762] D loss: 1.0461, G loss: 1.4436\n",
      "[484/1762] D loss: 1.3864, G loss: 0.6961\n",
      "[564/1762] D loss: 1.0442, G loss: 1.5510\n",
      "[644/1762] D loss: 1.3865, G loss: 0.6810\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6965\n",
      "[804/1762] D loss: 1.0398, G loss: 2.9215\n",
      "[884/1762] D loss: 1.0411, G loss: 1.8272\n",
      "[964/1762] D loss: 1.0399, G loss: 2.7252\n",
      "[1044/1762] D loss: 1.3867, G loss: 0.7036\n",
      "[1124/1762] D loss: 1.3840, G loss: 0.6827\n",
      "[1204/1762] D loss: 1.1518, G loss: 2.6713\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6980\n",
      "[1364/1762] D loss: 1.3867, G loss: 0.6781\n",
      "[1444/1762] D loss: 1.3869, G loss: 0.6707\n",
      "[1524/1762] D loss: 1.3865, G loss: 0.6858\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.7028\n",
      "[1684/1762] D loss: 1.3865, G loss: 0.7015\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6862\n",
      "train error: \n",
      " D loss: 1.299063, G loss: 0.949813, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 89.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.323151, G loss: 0.976345, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6937\n",
      "[84/1762] D loss: 1.0577, G loss: 1.1926\n",
      "[164/1762] D loss: 1.0400, G loss: 2.7238\n",
      "[244/1762] D loss: 1.3865, G loss: 0.6939\n",
      "[324/1762] D loss: 1.3872, G loss: 0.6731\n",
      "[404/1762] D loss: 1.3867, G loss: 0.6830\n",
      "[484/1762] D loss: 1.3856, G loss: 0.7091\n",
      "[564/1762] D loss: 1.3865, G loss: 0.6885\n",
      "[644/1762] D loss: 1.3866, G loss: 0.7083\n",
      "[724/1762] D loss: 1.1671, G loss: 1.8718\n",
      "[804/1762] D loss: 1.3867, G loss: 0.7011\n",
      "[884/1762] D loss: 1.3849, G loss: 0.6906\n",
      "[964/1762] D loss: 0.7112, G loss: 2.2594\n",
      "[1044/1762] D loss: 0.7525, G loss: 2.8043\n",
      "[1124/1762] D loss: 1.3858, G loss: 0.6909\n",
      "[1204/1762] D loss: 1.3862, G loss: 0.6890\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6748\n",
      "[1364/1762] D loss: 1.3856, G loss: 0.6804\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.6842\n",
      "[1524/1762] D loss: 1.3865, G loss: 0.6673\n",
      "[1604/1762] D loss: 1.0371, G loss: 3.4710\n",
      "[1684/1762] D loss: 1.3894, G loss: 0.6438\n",
      "[1762/1762] D loss: 1.3873, G loss: 0.7240\n",
      "train error: \n",
      " D loss: 1.298367, G loss: 1.145099, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 87.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.341124, G loss: 1.221712, D accuracy: 55.3%, cell accuracy: 99.7%, board accuracy: 85.0% \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.7023\n",
      "[84/1762] D loss: 1.0660, G loss: 1.0582\n",
      "[164/1762] D loss: 1.0337, G loss: 3.6565\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6881\n",
      "[324/1762] D loss: 1.3839, G loss: 0.6913\n",
      "[404/1762] D loss: 1.3771, G loss: 0.6856\n",
      "[484/1762] D loss: 1.3863, G loss: 0.6858\n",
      "[564/1762] D loss: 1.3732, G loss: 0.6827\n",
      "[644/1762] D loss: 1.3868, G loss: 0.6866\n",
      "[724/1762] D loss: 1.0511, G loss: 1.3936\n",
      "[804/1762] D loss: 1.3815, G loss: 0.6675\n",
      "[884/1762] D loss: 1.1620, G loss: 1.7246\n",
      "[964/1762] D loss: 1.3193, G loss: 0.8323\n",
      "[1044/1762] D loss: 1.3860, G loss: 0.7287\n",
      "[1124/1762] D loss: 1.3872, G loss: 0.6619\n",
      "[1204/1762] D loss: 1.3867, G loss: 0.6866\n",
      "[1284/1762] D loss: 1.3807, G loss: 0.6768\n",
      "[1364/1762] D loss: 1.3781, G loss: 0.6818\n",
      "[1444/1762] D loss: 1.0409, G loss: 1.9486\n",
      "[1524/1762] D loss: 0.7025, G loss: 2.8687\n",
      "[1604/1762] D loss: 1.3869, G loss: 0.6842\n",
      "[1684/1762] D loss: 1.1717, G loss: 1.7816\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.7045\n",
      "train error: \n",
      " D loss: 1.297822, G loss: 0.984712, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 91.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.323224, G loss: 1.028755, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3865, G loss: 0.7000\n",
      "[84/1762] D loss: 1.3864, G loss: 0.7031\n",
      "[164/1762] D loss: 1.0656, G loss: 1.1155\n",
      "[244/1762] D loss: 1.3866, G loss: 0.6817\n",
      "[324/1762] D loss: 0.4289, G loss: 4.2314\n",
      "[404/1762] D loss: 1.3889, G loss: 0.6653\n",
      "[484/1762] D loss: 1.0415, G loss: 1.7937\n",
      "[564/1762] D loss: 1.0442, G loss: 1.5483\n",
      "[644/1762] D loss: 1.3867, G loss: 0.7003\n",
      "[724/1762] D loss: 1.0488, G loss: 1.3673\n",
      "[804/1762] D loss: 1.3863, G loss: 0.6966\n",
      "[884/1762] D loss: 1.3865, G loss: 0.6910\n",
      "[964/1762] D loss: 1.2551, G loss: 1.3132\n",
      "[1044/1762] D loss: 1.2059, G loss: 1.4684\n",
      "[1124/1762] D loss: 1.3952, G loss: 0.6222\n",
      "[1204/1762] D loss: 1.3902, G loss: 0.6566\n",
      "[1284/1762] D loss: 1.3837, G loss: 0.6950\n",
      "[1364/1762] D loss: 1.3874, G loss: 0.7074\n",
      "[1444/1762] D loss: 1.3879, G loss: 0.6718\n",
      "[1524/1762] D loss: 1.0530, G loss: 1.1894\n",
      "[1604/1762] D loss: 0.6956, G loss: 3.3840\n",
      "[1684/1762] D loss: 1.3868, G loss: 0.6940\n",
      "[1762/1762] D loss: 1.3869, G loss: 0.7001\n",
      "train error: \n",
      " D loss: 1.297637, G loss: 0.941536, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.318362, G loss: 0.964964, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6939\n",
      "[84/1762] D loss: 1.3881, G loss: 0.7023\n",
      "[164/1762] D loss: 1.3869, G loss: 0.7035\n",
      "[244/1762] D loss: 1.0412, G loss: 1.8383\n",
      "[324/1762] D loss: 1.3896, G loss: 0.7342\n",
      "[404/1762] D loss: 1.3863, G loss: 0.6938\n",
      "[484/1762] D loss: 1.3865, G loss: 0.6881\n",
      "[564/1762] D loss: 1.3865, G loss: 0.6829\n",
      "[644/1762] D loss: 1.0462, G loss: 1.3678\n",
      "[724/1762] D loss: 1.0411, G loss: 1.9216\n",
      "[804/1762] D loss: 1.3866, G loss: 0.6915\n",
      "[884/1762] D loss: 1.3869, G loss: 0.6738\n",
      "[964/1762] D loss: 1.0424, G loss: 1.7001\n",
      "[1044/1762] D loss: 1.3866, G loss: 0.7065\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.6876\n",
      "[1204/1762] D loss: 1.3867, G loss: 0.7104\n",
      "[1284/1762] D loss: 1.3874, G loss: 0.6772\n",
      "[1364/1762] D loss: 1.3865, G loss: 0.6853\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6889\n",
      "[1524/1762] D loss: 1.3860, G loss: 0.6984\n",
      "[1604/1762] D loss: 1.3865, G loss: 0.6829\n",
      "[1684/1762] D loss: 1.0400, G loss: 3.2562\n",
      "[1762/1762] D loss: 1.3871, G loss: 0.6807\n",
      "train error: \n",
      " D loss: 1.297349, G loss: 1.117467, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.342653, G loss: 1.254938, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 91.1% \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3866, G loss: 0.6889\n",
      "[84/1762] D loss: 1.3865, G loss: 0.6945\n",
      "[164/1762] D loss: 1.3866, G loss: 0.6842\n",
      "[244/1762] D loss: 1.3866, G loss: 0.6948\n",
      "[324/1762] D loss: 1.3864, G loss: 0.6971\n",
      "[404/1762] D loss: 1.3865, G loss: 0.7008\n",
      "[484/1762] D loss: 1.3866, G loss: 0.6929\n",
      "[564/1762] D loss: 1.3863, G loss: 0.6943\n",
      "[644/1762] D loss: 1.3865, G loss: 0.6856\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6971\n",
      "[804/1762] D loss: 1.3876, G loss: 0.7100\n",
      "[884/1762] D loss: 0.7950, G loss: 2.6928\n",
      "[964/1762] D loss: 1.3864, G loss: 0.6866\n",
      "[1044/1762] D loss: 1.0406, G loss: 2.0785\n",
      "[1124/1762] D loss: 1.0400, G loss: 2.6921\n",
      "[1204/1762] D loss: 1.3023, G loss: 3.6605\n",
      "[1284/1762] D loss: 1.3871, G loss: 0.6742\n",
      "[1364/1762] D loss: 1.3870, G loss: 0.7166\n",
      "[1444/1762] D loss: 1.0411, G loss: 1.8274\n",
      "[1524/1762] D loss: 1.0903, G loss: 0.9567\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6921\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.6994\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.7009\n",
      "train error: \n",
      " D loss: 1.303485, G loss: 1.004584, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.316098, G loss: 1.062166, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 91.1% \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6962\n",
      "[84/1762] D loss: 1.0450, G loss: 1.4915\n",
      "[164/1762] D loss: 1.3869, G loss: 0.7157\n",
      "[244/1762] D loss: 1.0880, G loss: 0.9560\n",
      "[324/1762] D loss: 1.0432, G loss: 1.6125\n",
      "[404/1762] D loss: 1.3865, G loss: 0.6986\n",
      "[484/1762] D loss: 1.0868, G loss: 0.9509\n",
      "[564/1762] D loss: 1.3865, G loss: 0.7042\n",
      "[644/1762] D loss: 1.0586, G loss: 1.1770\n",
      "[724/1762] D loss: 1.3865, G loss: 0.7054\n",
      "[804/1762] D loss: 1.0418, G loss: 1.7393\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6964\n",
      "[964/1762] D loss: 1.0480, G loss: 1.3792\n",
      "[1044/1762] D loss: 1.4533, G loss: 0.8327\n",
      "[1124/1762] D loss: 1.2566, G loss: 1.0016\n",
      "[1204/1762] D loss: 1.3866, G loss: 0.7091\n",
      "[1284/1762] D loss: 1.3868, G loss: 0.6784\n",
      "[1364/1762] D loss: 0.7051, G loss: 2.2608\n",
      "[1444/1762] D loss: 1.3867, G loss: 0.7028\n",
      "[1524/1762] D loss: 1.3865, G loss: 0.6850\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6923\n",
      "[1684/1762] D loss: 1.1327, G loss: 0.8583\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6953\n",
      "train error: \n",
      " D loss: 1.299875, G loss: 1.183434, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.349430, G loss: 1.265788, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0682, G loss: 1.1180\n",
      "[84/1762] D loss: 1.0400, G loss: 2.5704\n",
      "[164/1762] D loss: 1.3871, G loss: 0.6716\n",
      "[244/1762] D loss: 1.3865, G loss: 0.6979\n",
      "[324/1762] D loss: 1.0394, G loss: 2.4653\n",
      "[404/1762] D loss: 1.3861, G loss: 0.7019\n",
      "[484/1762] D loss: 1.3865, G loss: 0.6925\n",
      "[564/1762] D loss: 1.3865, G loss: 0.6947\n",
      "[644/1762] D loss: 1.3867, G loss: 0.6732\n",
      "[724/1762] D loss: 1.0424, G loss: 1.6793\n",
      "[804/1762] D loss: 1.3778, G loss: 0.7035\n",
      "[884/1762] D loss: 1.0414, G loss: 1.4115\n",
      "[964/1762] D loss: 1.3835, G loss: 0.6963\n",
      "[1044/1762] D loss: 1.3838, G loss: 0.6743\n",
      "[1124/1762] D loss: 1.3878, G loss: 0.6738\n",
      "[1204/1762] D loss: 1.3797, G loss: 0.6912\n",
      "[1284/1762] D loss: 1.3791, G loss: 0.6947\n",
      "[1364/1762] D loss: 0.9153, G loss: 12.4701\n",
      "[1444/1762] D loss: 1.3968, G loss: 0.6654\n",
      "[1524/1762] D loss: 1.3881, G loss: 0.7249\n",
      "[1604/1762] D loss: 0.7405, G loss: 2.4835\n",
      "[1684/1762] D loss: 0.9018, G loss: 1.7978\n",
      "[1762/1762] D loss: 0.7420, G loss: 1.5670\n",
      "train error: \n",
      " D loss: 1.301628, G loss: 0.892153, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.310563, G loss: 0.924745, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0595, G loss: 1.1798\n",
      "[84/1762] D loss: 1.3874, G loss: 0.6789\n",
      "[164/1762] D loss: 1.3870, G loss: 0.6906\n",
      "[244/1762] D loss: 1.3868, G loss: 0.7026\n",
      "[324/1762] D loss: 1.3871, G loss: 0.7024\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6997\n",
      "[484/1762] D loss: 1.3868, G loss: 0.7120\n",
      "[564/1762] D loss: 1.2019, G loss: 1.7148\n",
      "[644/1762] D loss: 1.3873, G loss: 0.6821\n",
      "[724/1762] D loss: 1.3865, G loss: 0.6983\n",
      "[804/1762] D loss: 1.3850, G loss: 0.7038\n",
      "[884/1762] D loss: 1.0457, G loss: 1.4728\n",
      "[964/1762] D loss: 1.3868, G loss: 0.6895\n",
      "[1044/1762] D loss: 1.3868, G loss: 0.6825\n",
      "[1124/1762] D loss: 1.3870, G loss: 0.6833\n",
      "[1204/1762] D loss: 1.3866, G loss: 0.7067\n",
      "[1284/1762] D loss: 1.3866, G loss: 0.7007\n",
      "[1364/1762] D loss: 1.0446, G loss: 1.5143\n",
      "[1444/1762] D loss: 1.3827, G loss: 0.6748\n",
      "[1524/1762] D loss: 1.3865, G loss: 0.6955\n",
      "[1604/1762] D loss: 1.3860, G loss: 0.6890\n",
      "[1684/1762] D loss: 1.0402, G loss: 2.1062\n",
      "[1762/1762] D loss: 1.3664, G loss: 0.6948\n",
      "train error: \n",
      " D loss: 1.290519, G loss: 1.029095, D accuracy: 56.6%, cell accuracy: 99.6%, board accuracy: 71.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.324085, G loss: 1.089771, D accuracy: 57.2%, cell accuracy: 99.6%, board accuracy: 70.0% \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0412, G loss: 6.5934\n",
      "[84/1762] D loss: 1.2068, G loss: 1.5460\n",
      "[164/1762] D loss: 1.3873, G loss: 0.6885\n",
      "[244/1762] D loss: 1.3881, G loss: 0.6885\n",
      "[324/1762] D loss: 1.3868, G loss: 0.6931\n",
      "[404/1762] D loss: 1.0407, G loss: 2.3654\n",
      "[484/1762] D loss: 1.3875, G loss: 0.7182\n",
      "[564/1762] D loss: 1.0402, G loss: 2.1115\n",
      "[644/1762] D loss: 1.0466, G loss: 1.4650\n",
      "[724/1762] D loss: 1.3859, G loss: 0.7003\n",
      "[804/1762] D loss: 1.3872, G loss: 0.6788\n",
      "[884/1762] D loss: 1.3873, G loss: 0.6977\n",
      "[964/1762] D loss: 1.3856, G loss: 0.7001\n",
      "[1044/1762] D loss: 1.0386, G loss: 2.9273\n",
      "[1124/1762] D loss: 1.3849, G loss: 0.6832\n",
      "[1204/1762] D loss: 1.5386, G loss: 0.9538\n",
      "[1284/1762] D loss: 1.3884, G loss: 0.7313\n",
      "[1364/1762] D loss: 1.3869, G loss: 0.7070\n",
      "[1444/1762] D loss: 1.3552, G loss: 0.7115\n",
      "[1524/1762] D loss: 1.3881, G loss: 0.6766\n",
      "[1604/1762] D loss: 1.3637, G loss: 0.7241\n",
      "[1684/1762] D loss: 1.3882, G loss: 0.6651\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.7012\n",
      "train error: \n",
      " D loss: 1.298115, G loss: 1.125073, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 91.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.337395, G loss: 1.211484, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3874, G loss: 0.7082\n",
      "[84/1762] D loss: 1.3854, G loss: 0.6663\n",
      "[164/1762] D loss: 1.3872, G loss: 0.6898\n",
      "[244/1762] D loss: 1.2132, G loss: 2.1313\n",
      "[324/1762] D loss: 1.0419, G loss: 3.7176\n",
      "[404/1762] D loss: 1.3164, G loss: 0.7579\n",
      "[484/1762] D loss: 1.0535, G loss: 2.8041\n",
      "[564/1762] D loss: 1.3890, G loss: 0.6827\n",
      "[644/1762] D loss: 1.3901, G loss: 0.6993\n",
      "[724/1762] D loss: 1.3884, G loss: 0.6745\n",
      "[804/1762] D loss: 1.2227, G loss: 2.4030\n",
      "[884/1762] D loss: 1.3894, G loss: 0.6686\n",
      "[964/1762] D loss: 1.3882, G loss: 0.6602\n",
      "[1044/1762] D loss: 1.3872, G loss: 0.6811\n",
      "[1124/1762] D loss: 1.3868, G loss: 0.6985\n",
      "[1204/1762] D loss: 1.3871, G loss: 0.7174\n",
      "[1284/1762] D loss: 1.3644, G loss: 0.7130\n",
      "[1364/1762] D loss: 1.3876, G loss: 0.7127\n",
      "[1444/1762] D loss: 1.3870, G loss: 0.6968\n",
      "[1524/1762] D loss: 1.3866, G loss: 0.6886\n",
      "[1604/1762] D loss: 1.3866, G loss: 0.7025\n",
      "[1684/1762] D loss: 1.3877, G loss: 0.6933\n",
      "[1762/1762] D loss: 1.3871, G loss: 0.6784\n",
      "train error: \n",
      " D loss: 1.295246, G loss: 1.016355, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.324850, G loss: 1.036675, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3869, G loss: 0.6588\n",
      "[84/1762] D loss: 1.3876, G loss: 0.6783\n",
      "[164/1762] D loss: 1.0443, G loss: 1.6012\n",
      "[244/1762] D loss: 1.3865, G loss: 0.6949\n",
      "[324/1762] D loss: 1.0750, G loss: 1.0362\n",
      "[404/1762] D loss: 1.3868, G loss: 0.6907\n",
      "[484/1762] D loss: 1.3865, G loss: 0.6984\n",
      "[564/1762] D loss: 1.3870, G loss: 0.6965\n",
      "[644/1762] D loss: 1.0401, G loss: 2.3649\n",
      "[724/1762] D loss: 1.3868, G loss: 0.7044\n",
      "[804/1762] D loss: 1.3872, G loss: 0.6926\n",
      "[884/1762] D loss: 1.0391, G loss: 4.3302\n",
      "[964/1762] D loss: 1.0465, G loss: 1.4807\n",
      "[1044/1762] D loss: 1.3866, G loss: 0.6989\n",
      "[1124/1762] D loss: 1.3876, G loss: 0.6722\n",
      "[1204/1762] D loss: 1.3819, G loss: 0.6991\n",
      "[1284/1762] D loss: 1.3888, G loss: 0.6584\n",
      "[1364/1762] D loss: 1.3811, G loss: 0.6919\n",
      "[1444/1762] D loss: 1.3878, G loss: 0.6634\n",
      "[1524/1762] D loss: 1.3837, G loss: 0.7079\n",
      "[1604/1762] D loss: 1.0559, G loss: 1.2120\n",
      "[1684/1762] D loss: 1.3869, G loss: 0.6943\n",
      "[1762/1762] D loss: 1.3870, G loss: 0.6716\n",
      "train error: \n",
      " D loss: 1.291943, G loss: 1.059829, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 88.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.321110, G loss: 1.151383, D accuracy: 55.7%, cell accuracy: 99.8%, board accuracy: 85.0% \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0436, G loss: 1.7490\n",
      "[84/1762] D loss: 1.3865, G loss: 0.7017\n",
      "[164/1762] D loss: 1.3819, G loss: 0.7186\n",
      "[244/1762] D loss: 1.0402, G loss: 4.6157\n",
      "[324/1762] D loss: 1.3869, G loss: 0.6854\n",
      "[404/1762] D loss: 1.0484, G loss: 1.4188\n",
      "[484/1762] D loss: 1.0452, G loss: 1.5462\n",
      "[564/1762] D loss: 1.3871, G loss: 0.6999\n",
      "[644/1762] D loss: 1.3672, G loss: 0.7074\n",
      "[724/1762] D loss: 1.3870, G loss: 0.7057\n",
      "[804/1762] D loss: 1.3868, G loss: 0.7135\n",
      "[884/1762] D loss: 1.0564, G loss: 1.3509\n",
      "[964/1762] D loss: 1.0610, G loss: 1.1561\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.6850\n",
      "[1124/1762] D loss: 1.3877, G loss: 0.6824\n",
      "[1204/1762] D loss: 1.3877, G loss: 0.6999\n",
      "[1284/1762] D loss: 1.3873, G loss: 0.7095\n",
      "[1364/1762] D loss: 1.3878, G loss: 0.6736\n",
      "[1444/1762] D loss: 1.0398, G loss: 3.7249\n",
      "[1524/1762] D loss: 1.3867, G loss: 0.6817\n",
      "[1604/1762] D loss: 1.0639, G loss: 1.1587\n",
      "[1684/1762] D loss: 1.3876, G loss: 0.7225\n",
      "[1762/1762] D loss: 1.3869, G loss: 0.6694\n",
      "train error: \n",
      " D loss: 1.297088, G loss: 1.088053, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.331844, G loss: 1.134370, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2791, G loss: 0.9565\n",
      "[84/1762] D loss: 1.3873, G loss: 0.6865\n",
      "[164/1762] D loss: 1.3844, G loss: 0.6970\n",
      "[244/1762] D loss: 1.0437, G loss: 1.5678\n",
      "[324/1762] D loss: 1.3866, G loss: 0.6872\n",
      "[404/1762] D loss: 1.0525, G loss: 1.3157\n",
      "[484/1762] D loss: 1.3873, G loss: 0.7150\n",
      "[564/1762] D loss: 1.3875, G loss: 0.6710\n",
      "[644/1762] D loss: 1.3867, G loss: 0.7027\n",
      "[724/1762] D loss: 1.4589, G loss: 0.8198\n",
      "[804/1762] D loss: 1.3873, G loss: 0.6848\n",
      "[884/1762] D loss: 1.3861, G loss: 0.6953\n",
      "[964/1762] D loss: 0.9757, G loss: 5.9319\n",
      "[1044/1762] D loss: 1.3621, G loss: 0.6980\n",
      "[1124/1762] D loss: 1.0403, G loss: 4.0448\n",
      "[1204/1762] D loss: 1.3866, G loss: 0.6760\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6869\n",
      "[1364/1762] D loss: 1.4057, G loss: 0.7197\n",
      "[1444/1762] D loss: 1.3866, G loss: 0.6870\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.6986\n",
      "[1604/1762] D loss: 1.3853, G loss: 0.6937\n",
      "[1684/1762] D loss: 1.0399, G loss: 2.4725\n",
      "[1762/1762] D loss: 1.3866, G loss: 0.6812\n",
      "train error: \n",
      " D loss: 1.296183, G loss: 1.038245, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 91.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.345855, G loss: 1.093624, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3866, G loss: 0.6789\n",
      "[84/1762] D loss: 1.3871, G loss: 0.6948\n",
      "[164/1762] D loss: 1.0416, G loss: 2.3071\n",
      "[244/1762] D loss: 1.3432, G loss: 0.7197\n",
      "[324/1762] D loss: 1.3862, G loss: 0.6883\n",
      "[404/1762] D loss: 1.0421, G loss: 1.8043\n",
      "[484/1762] D loss: 1.0404, G loss: 3.5782\n",
      "[564/1762] D loss: 1.0441, G loss: 1.6448\n",
      "[644/1762] D loss: 1.3867, G loss: 0.7116\n",
      "[724/1762] D loss: 1.3867, G loss: 0.7087\n",
      "[804/1762] D loss: 1.3870, G loss: 0.6796\n",
      "[884/1762] D loss: 1.3875, G loss: 0.7047\n",
      "[964/1762] D loss: 1.0413, G loss: 1.8530\n",
      "[1044/1762] D loss: 1.3866, G loss: 0.6854\n",
      "[1124/1762] D loss: 1.5096, G loss: 0.7122\n",
      "[1204/1762] D loss: 1.3870, G loss: 0.7096\n",
      "[1284/1762] D loss: 1.3877, G loss: 0.6694\n",
      "[1364/1762] D loss: 1.3866, G loss: 0.6967\n",
      "[1444/1762] D loss: 1.0399, G loss: 4.6916\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.6915\n",
      "[1604/1762] D loss: 1.3867, G loss: 0.7059\n",
      "[1684/1762] D loss: 1.3872, G loss: 0.6735\n",
      "[1762/1762] D loss: 1.3878, G loss: 0.7309\n",
      "train error: \n",
      " D loss: 1.296908, G loss: 1.213532, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.363819, G loss: 1.308093, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3865, G loss: 0.6848\n",
      "[84/1762] D loss: 1.3899, G loss: 0.6419\n",
      "[164/1762] D loss: 1.3878, G loss: 0.6598\n",
      "[244/1762] D loss: 1.3865, G loss: 0.6872\n",
      "[324/1762] D loss: 1.3864, G loss: 0.6894\n",
      "[404/1762] D loss: 1.3865, G loss: 0.6973\n",
      "[484/1762] D loss: 1.4863, G loss: 0.8795\n",
      "[564/1762] D loss: 1.3864, G loss: 0.7020\n",
      "[644/1762] D loss: 1.3865, G loss: 0.6847\n",
      "[724/1762] D loss: 1.3865, G loss: 0.7097\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6877\n",
      "[884/1762] D loss: 0.6968, G loss: 4.0785\n",
      "[964/1762] D loss: 1.6354, G loss: 0.8824\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6909\n",
      "[1124/1762] D loss: 1.3866, G loss: 0.6956\n",
      "[1204/1762] D loss: 1.3865, G loss: 0.6965\n",
      "[1284/1762] D loss: 1.3872, G loss: 0.7021\n",
      "[1364/1762] D loss: 1.0400, G loss: 2.4517\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.6970\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.6960\n",
      "[1604/1762] D loss: 1.3867, G loss: 0.6740\n",
      "[1684/1762] D loss: 1.3866, G loss: 0.6774\n",
      "[1762/1762] D loss: 0.6961, G loss: 3.0349\n",
      "train error: \n",
      " D loss: 1.297682, G loss: 1.205415, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.349203, G loss: 1.285419, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4015, G loss: 0.6649\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6907\n",
      "[164/1762] D loss: 1.3867, G loss: 0.6874\n",
      "[244/1762] D loss: 1.0402, G loss: 2.1354\n",
      "[324/1762] D loss: 1.3865, G loss: 0.6897\n",
      "[404/1762] D loss: 1.3869, G loss: 0.6874\n",
      "[484/1762] D loss: 1.0401, G loss: 3.6229\n",
      "[564/1762] D loss: 0.6933, G loss: 5.0588\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6934\n",
      "[724/1762] D loss: 1.3866, G loss: 0.7088\n",
      "[804/1762] D loss: 1.3843, G loss: 0.6910\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6941\n",
      "[964/1762] D loss: 1.3851, G loss: 0.6992\n",
      "[1044/1762] D loss: 1.3868, G loss: 0.6914\n",
      "[1124/1762] D loss: 1.0436, G loss: 2.0159\n",
      "[1204/1762] D loss: 1.3878, G loss: 0.6667\n",
      "[1284/1762] D loss: 1.3749, G loss: 0.7036\n",
      "[1364/1762] D loss: 1.3870, G loss: 0.6879\n",
      "[1444/1762] D loss: 1.0414, G loss: 1.7769\n",
      "[1524/1762] D loss: 1.3882, G loss: 0.6827\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6879\n",
      "[1684/1762] D loss: 1.4617, G loss: 0.6173\n",
      "[1762/1762] D loss: 1.3873, G loss: 0.6689\n",
      "train error: \n",
      " D loss: 1.286505, G loss: 1.387292, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 89.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.338633, G loss: 1.470270, D accuracy: 55.8%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3866, G loss: 0.7052\n",
      "[84/1762] D loss: 1.3805, G loss: 0.6899\n",
      "[164/1762] D loss: 1.3864, G loss: 0.6954\n",
      "[244/1762] D loss: 1.3865, G loss: 0.6924\n",
      "[324/1762] D loss: 1.3867, G loss: 0.6752\n",
      "[404/1762] D loss: 1.3898, G loss: 0.6847\n",
      "[484/1762] D loss: 1.3866, G loss: 0.6736\n",
      "[564/1762] D loss: 1.0452, G loss: 1.4813\n",
      "[644/1762] D loss: 1.0400, G loss: 3.2431\n",
      "[724/1762] D loss: 1.3862, G loss: 0.6854\n",
      "[804/1762] D loss: 1.3959, G loss: 0.7333\n",
      "[884/1762] D loss: 1.3870, G loss: 0.6817\n",
      "[964/1762] D loss: 1.3870, G loss: 0.6704\n",
      "[1044/1762] D loss: 1.3846, G loss: 0.7010\n",
      "[1124/1762] D loss: 1.3847, G loss: 0.7090\n",
      "[1204/1762] D loss: 1.0458, G loss: 1.4560\n",
      "[1284/1762] D loss: 1.3806, G loss: 0.6788\n",
      "[1364/1762] D loss: 1.3865, G loss: 0.7000\n",
      "[1444/1762] D loss: 1.3732, G loss: 0.7077\n",
      "[1524/1762] D loss: 1.2083, G loss: 1.5481\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6912\n",
      "[1684/1762] D loss: 1.3856, G loss: 0.6816\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6963\n",
      "train error: \n",
      " D loss: 1.297165, G loss: 1.125390, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.339051, G loss: 1.201342, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3867, G loss: 0.6911\n",
      "[84/1762] D loss: 1.3865, G loss: 0.6782\n",
      "[164/1762] D loss: 1.0401, G loss: 2.4597\n",
      "[244/1762] D loss: 1.0405, G loss: 1.9685\n",
      "[324/1762] D loss: 1.3864, G loss: 0.6896\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6893\n",
      "[484/1762] D loss: 1.3787, G loss: 0.7061\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6973\n",
      "[644/1762] D loss: 1.3866, G loss: 0.6936\n",
      "[724/1762] D loss: 1.3884, G loss: 0.6513\n",
      "[804/1762] D loss: 1.3872, G loss: 0.6743\n",
      "[884/1762] D loss: 1.3868, G loss: 0.6914\n",
      "[964/1762] D loss: 1.3865, G loss: 0.7085\n",
      "[1044/1762] D loss: 1.1262, G loss: 1.6257\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.6995\n",
      "[1204/1762] D loss: 1.3868, G loss: 0.7069\n",
      "[1284/1762] D loss: 1.3865, G loss: 0.6967\n",
      "[1364/1762] D loss: 1.3969, G loss: 0.6794\n",
      "[1444/1762] D loss: 1.3867, G loss: 0.6989\n",
      "[1524/1762] D loss: 1.3866, G loss: 0.6843\n",
      "[1604/1762] D loss: 1.0505, G loss: 1.3426\n",
      "[1684/1762] D loss: 1.0680, G loss: 1.0745\n",
      "[1762/1762] D loss: 0.8194, G loss: 1.1289\n",
      "train error: \n",
      " D loss: 1.300118, G loss: 1.030661, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 93.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.357550, G loss: 1.116545, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 91.4% \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3868, G loss: 0.7053\n",
      "[84/1762] D loss: 1.0649, G loss: 1.1293\n",
      "[164/1762] D loss: 1.3868, G loss: 0.7105\n",
      "[244/1762] D loss: 0.6982, G loss: 3.4564\n",
      "[324/1762] D loss: 1.3867, G loss: 0.7048\n",
      "[404/1762] D loss: 1.3867, G loss: 0.6974\n",
      "[484/1762] D loss: 1.3868, G loss: 0.6761\n",
      "[564/1762] D loss: 0.7059, G loss: 3.1125\n",
      "[644/1762] D loss: 1.0404, G loss: 2.2602\n",
      "[724/1762] D loss: 1.3867, G loss: 0.6785\n",
      "[804/1762] D loss: 1.3876, G loss: 0.6773\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6944\n",
      "[964/1762] D loss: 1.3864, G loss: 0.6885\n",
      "[1044/1762] D loss: 1.3866, G loss: 0.6797\n",
      "[1124/1762] D loss: 1.3867, G loss: 0.6949\n",
      "[1204/1762] D loss: 1.0561, G loss: 1.2505\n",
      "[1284/1762] D loss: 1.3865, G loss: 0.6914\n",
      "[1364/1762] D loss: 1.3865, G loss: 0.7035\n",
      "[1444/1762] D loss: 1.3871, G loss: 0.7216\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.6914\n",
      "[1604/1762] D loss: 1.3840, G loss: 0.7039\n",
      "[1684/1762] D loss: 1.3866, G loss: 0.7090\n",
      "[1762/1762] D loss: 0.6934, G loss: 5.6051\n",
      "train error: \n",
      " D loss: 1.331562, G loss: 0.887584, D accuracy: 52.8%, cell accuracy: 99.9%, board accuracy: 85.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.378295, G loss: 0.854214, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 85.5% \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3860, G loss: 0.6702\n",
      "[84/1762] D loss: 1.3837, G loss: 0.6968\n",
      "[164/1762] D loss: 1.3876, G loss: 0.7035\n",
      "[244/1762] D loss: 1.1476, G loss: 1.4376\n",
      "[324/1762] D loss: 1.1718, G loss: 0.8468\n",
      "[404/1762] D loss: 1.0457, G loss: 1.4196\n",
      "[484/1762] D loss: 1.2645, G loss: 0.8443\n",
      "[564/1762] D loss: 1.3566, G loss: 0.7307\n",
      "[644/1762] D loss: 1.3876, G loss: 0.7284\n",
      "[724/1762] D loss: 1.0488, G loss: 1.3595\n",
      "[804/1762] D loss: 1.3732, G loss: 0.6793\n",
      "[884/1762] D loss: 1.1056, G loss: 0.8830\n",
      "[964/1762] D loss: 1.3855, G loss: 0.7362\n",
      "[1044/1762] D loss: 1.1690, G loss: 0.7821\n",
      "[1124/1762] D loss: 1.3919, G loss: 0.6247\n",
      "[1204/1762] D loss: 1.3949, G loss: 0.6423\n",
      "[1284/1762] D loss: 1.3875, G loss: 0.6684\n",
      "[1364/1762] D loss: 1.3114, G loss: 0.7685\n",
      "[1444/1762] D loss: 1.3872, G loss: 0.6771\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.6916\n",
      "[1604/1762] D loss: 1.3882, G loss: 0.7109\n",
      "[1684/1762] D loss: 1.3873, G loss: 0.7256\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.6476\n",
      "train error: \n",
      " D loss: 1.329418, G loss: 0.780580, D accuracy: 52.9%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.337764, G loss: 0.794519, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3880, G loss: 0.6618\n",
      "[84/1762] D loss: 1.1482, G loss: 0.7828\n",
      "[164/1762] D loss: 1.3872, G loss: 0.7013\n",
      "[244/1762] D loss: 1.5412, G loss: 1.4354\n",
      "[324/1762] D loss: 1.3886, G loss: 0.6575\n",
      "[404/1762] D loss: 1.3872, G loss: 0.7188\n",
      "[484/1762] D loss: 1.3864, G loss: 0.6986\n",
      "[564/1762] D loss: 1.3869, G loss: 0.6730\n",
      "[644/1762] D loss: 1.3867, G loss: 0.6885\n",
      "[724/1762] D loss: 1.3877, G loss: 0.6935\n",
      "[804/1762] D loss: 1.3872, G loss: 0.6710\n",
      "[884/1762] D loss: 1.1202, G loss: 0.8509\n",
      "[964/1762] D loss: 1.3881, G loss: 0.7163\n",
      "[1044/1762] D loss: 1.3868, G loss: 0.6801\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6923\n",
      "[1204/1762] D loss: 1.3874, G loss: 0.6568\n",
      "[1284/1762] D loss: 0.7336, G loss: 1.9332\n",
      "[1364/1762] D loss: 1.3856, G loss: 0.6635\n",
      "[1444/1762] D loss: 1.3883, G loss: 0.6586\n",
      "[1524/1762] D loss: 1.1409, G loss: 0.8748\n",
      "[1604/1762] D loss: 1.3865, G loss: 0.7029\n",
      "[1684/1762] D loss: 1.3874, G loss: 0.6741\n",
      "[1762/1762] D loss: 1.3897, G loss: 0.6366\n",
      "train error: \n",
      " D loss: 1.346817, G loss: 0.744436, D accuracy: 52.5%, cell accuracy: 99.9%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.371440, G loss: 0.752842, D accuracy: 53.0%, cell accuracy: 99.9%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3893, G loss: 0.6455\n",
      "[84/1762] D loss: 1.3861, G loss: 0.6823\n",
      "[164/1762] D loss: 1.3866, G loss: 0.6852\n",
      "[244/1762] D loss: 1.3700, G loss: 0.7614\n",
      "[324/1762] D loss: 1.3865, G loss: 0.7033\n",
      "[404/1762] D loss: 1.4209, G loss: 0.8050\n",
      "[484/1762] D loss: 1.1277, G loss: 0.8762\n",
      "[564/1762] D loss: 1.3866, G loss: 0.6828\n",
      "[644/1762] D loss: 1.3865, G loss: 0.7074\n",
      "[724/1762] D loss: 1.3862, G loss: 0.6817\n",
      "[804/1762] D loss: 1.4321, G loss: 1.3611\n",
      "[884/1762] D loss: 1.1042, G loss: 0.8997\n",
      "[964/1762] D loss: 1.3879, G loss: 0.6979\n",
      "[1044/1762] D loss: 1.3880, G loss: 0.7278\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6891\n",
      "[1204/1762] D loss: 1.0740, G loss: 1.0558\n",
      "[1284/1762] D loss: 1.3866, G loss: 0.6964\n",
      "[1364/1762] D loss: 1.3873, G loss: 0.7071\n",
      "[1444/1762] D loss: 1.3866, G loss: 0.6817\n",
      "[1524/1762] D loss: 1.3862, G loss: 0.6964\n",
      "[1604/1762] D loss: 1.3866, G loss: 0.7058\n",
      "[1684/1762] D loss: 1.3870, G loss: 0.7072\n",
      "[1762/1762] D loss: 1.3869, G loss: 0.6827\n",
      "train error: \n",
      " D loss: 1.337736, G loss: 0.778451, D accuracy: 52.7%, cell accuracy: 99.9%, board accuracy: 90.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.327759, G loss: 0.801718, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.7046\n",
      "[84/1762] D loss: 1.0974, G loss: 0.9225\n",
      "[164/1762] D loss: 1.0716, G loss: 1.0694\n",
      "[244/1762] D loss: 1.3891, G loss: 0.6513\n",
      "[324/1762] D loss: 1.1200, G loss: 0.8799\n",
      "[404/1762] D loss: 1.3865, G loss: 0.6814\n",
      "[484/1762] D loss: 1.1245, G loss: 0.8361\n",
      "[564/1762] D loss: 1.3843, G loss: 0.6775\n",
      "[644/1762] D loss: 1.3797, G loss: 0.7242\n",
      "[724/1762] D loss: 1.3881, G loss: 0.6593\n",
      "[804/1762] D loss: 1.3865, G loss: 0.7009\n",
      "[884/1762] D loss: 1.0191, G loss: 1.1345\n",
      "[964/1762] D loss: 1.3869, G loss: 0.7131\n",
      "[1044/1762] D loss: 1.3870, G loss: 0.7002\n",
      "[1124/1762] D loss: 0.7416, G loss: 1.5230\n",
      "[1204/1762] D loss: 1.3868, G loss: 0.6824\n",
      "[1284/1762] D loss: 1.1770, G loss: 1.1235\n",
      "[1364/1762] D loss: 1.1615, G loss: 0.7740\n",
      "[1444/1762] D loss: 1.3866, G loss: 0.6825\n",
      "[1524/1762] D loss: 1.3885, G loss: 0.6675\n",
      "[1604/1762] D loss: 1.0627, G loss: 1.1331\n",
      "[1684/1762] D loss: 1.3868, G loss: 0.6922\n",
      "[1762/1762] D loss: 1.3876, G loss: 0.6985\n",
      "train error: \n",
      " D loss: 1.315088, G loss: 0.788541, D accuracy: 54.0%, cell accuracy: 99.9%, board accuracy: 89.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.319725, G loss: 0.823604, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 85.2% \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0926, G loss: 0.9574\n",
      "[84/1762] D loss: 1.3859, G loss: 0.7312\n",
      "[164/1762] D loss: 1.3792, G loss: 0.6920\n",
      "[244/1762] D loss: 1.4025, G loss: 0.7952\n",
      "[324/1762] D loss: 1.3890, G loss: 0.6448\n",
      "[404/1762] D loss: 1.3922, G loss: 0.7869\n",
      "[484/1762] D loss: 1.3884, G loss: 0.7335\n",
      "[564/1762] D loss: 1.3802, G loss: 0.6965\n",
      "[644/1762] D loss: 1.3678, G loss: 0.7642\n",
      "[724/1762] D loss: 1.3872, G loss: 0.6689\n",
      "[804/1762] D loss: 1.3865, G loss: 0.7024\n",
      "[884/1762] D loss: 1.3868, G loss: 0.6819\n",
      "[964/1762] D loss: 1.2255, G loss: 1.6325\n",
      "[1044/1762] D loss: 1.0886, G loss: 0.9832\n",
      "[1124/1762] D loss: 1.4062, G loss: 0.6126\n",
      "[1204/1762] D loss: 1.3869, G loss: 0.7046\n",
      "[1284/1762] D loss: 1.3860, G loss: 0.6627\n",
      "[1364/1762] D loss: 1.3637, G loss: 0.7295\n",
      "[1444/1762] D loss: 1.3849, G loss: 0.7224\n",
      "[1524/1762] D loss: 1.3865, G loss: 0.6992\n",
      "[1604/1762] D loss: 1.3877, G loss: 0.6600\n",
      "[1684/1762] D loss: 1.3882, G loss: 0.6575\n",
      "[1762/1762] D loss: 1.3893, G loss: 0.6645\n",
      "train error: \n",
      " D loss: 1.307716, G loss: 0.963963, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 77.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.317588, G loss: 1.041554, D accuracy: 55.9%, cell accuracy: 99.8%, board accuracy: 74.5% \n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3826, G loss: 0.7110\n",
      "[84/1762] D loss: 1.1092, G loss: 0.8043\n",
      "[164/1762] D loss: 1.3875, G loss: 0.6967\n",
      "[244/1762] D loss: 1.3887, G loss: 0.7200\n",
      "[324/1762] D loss: 1.3881, G loss: 0.6442\n",
      "[404/1762] D loss: 1.3847, G loss: 0.7415\n",
      "[484/1762] D loss: 1.3864, G loss: 0.7057\n",
      "[564/1762] D loss: 1.1452, G loss: 0.7745\n",
      "[644/1762] D loss: 1.1161, G loss: 0.8800\n",
      "[724/1762] D loss: 1.5783, G loss: 1.0288\n",
      "[804/1762] D loss: 1.3907, G loss: 0.6501\n",
      "[884/1762] D loss: 1.3864, G loss: 0.7117\n",
      "[964/1762] D loss: 1.3873, G loss: 0.7110\n",
      "[1044/1762] D loss: 1.3866, G loss: 0.7044\n",
      "[1124/1762] D loss: 1.3874, G loss: 0.6990\n",
      "[1204/1762] D loss: 1.0928, G loss: 1.0808\n",
      "[1284/1762] D loss: 1.3884, G loss: 0.6765\n",
      "[1364/1762] D loss: 1.3871, G loss: 0.7094\n",
      "[1444/1762] D loss: 1.3851, G loss: 0.6931\n",
      "[1524/1762] D loss: 1.3890, G loss: 0.7294\n",
      "[1604/1762] D loss: 1.3867, G loss: 0.7065\n",
      "[1684/1762] D loss: 0.9413, G loss: 1.3808\n",
      "[1762/1762] D loss: 1.3866, G loss: 0.6851\n",
      "train error: \n",
      " D loss: 1.325146, G loss: 0.788838, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 89.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.315173, G loss: 0.803160, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3868, G loss: 0.6791\n",
      "[84/1762] D loss: 1.3881, G loss: 0.7129\n",
      "[164/1762] D loss: 1.3871, G loss: 0.6989\n",
      "[244/1762] D loss: 1.3875, G loss: 0.7137\n",
      "[324/1762] D loss: 1.3867, G loss: 0.6783\n",
      "[404/1762] D loss: 1.0873, G loss: 0.9630\n",
      "[484/1762] D loss: 1.0815, G loss: 1.0012\n",
      "[564/1762] D loss: 0.9311, G loss: 1.0672\n",
      "[644/1762] D loss: 1.3870, G loss: 0.6812\n",
      "[724/1762] D loss: 1.3874, G loss: 0.6724\n",
      "[804/1762] D loss: 1.3898, G loss: 0.7199\n",
      "[884/1762] D loss: 1.3865, G loss: 0.6869\n",
      "[964/1762] D loss: 1.1014, G loss: 0.9125\n",
      "[1044/1762] D loss: 1.3870, G loss: 0.6838\n",
      "[1124/1762] D loss: 1.3867, G loss: 0.7005\n",
      "[1204/1762] D loss: 1.3869, G loss: 0.6989\n",
      "[1284/1762] D loss: 1.0769, G loss: 1.0171\n",
      "[1364/1762] D loss: 1.3865, G loss: 0.6953\n",
      "[1444/1762] D loss: 1.0945, G loss: 0.9858\n",
      "[1524/1762] D loss: 1.3872, G loss: 0.7045\n",
      "[1604/1762] D loss: 1.3872, G loss: 0.6704\n",
      "[1684/1762] D loss: 1.3857, G loss: 0.6861\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6921\n",
      "train error: \n",
      " D loss: 1.317163, G loss: 0.769043, D accuracy: 53.4%, cell accuracy: 99.9%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.298700, G loss: 0.768350, D accuracy: 54.2%, cell accuracy: 99.9%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3876, G loss: 0.6718\n",
      "[84/1762] D loss: 1.4164, G loss: 0.7790\n",
      "[164/1762] D loss: 1.3873, G loss: 0.7186\n",
      "[244/1762] D loss: 1.3865, G loss: 0.6838\n",
      "[324/1762] D loss: 1.3864, G loss: 0.7007\n",
      "[404/1762] D loss: 1.3868, G loss: 0.6748\n",
      "[484/1762] D loss: 1.3865, G loss: 0.6898\n",
      "[564/1762] D loss: 1.3877, G loss: 0.7055\n",
      "[644/1762] D loss: 1.3775, G loss: 0.6936\n",
      "[724/1762] D loss: 1.3865, G loss: 0.6975\n",
      "[804/1762] D loss: 1.3870, G loss: 0.6798\n",
      "[884/1762] D loss: 1.0697, G loss: 1.1088\n",
      "[964/1762] D loss: 0.8065, G loss: 1.1304\n",
      "[1044/1762] D loss: 1.3866, G loss: 0.7088\n",
      "[1124/1762] D loss: 1.0741, G loss: 1.0760\n",
      "[1204/1762] D loss: 1.0796, G loss: 1.0440\n",
      "[1284/1762] D loss: 1.3872, G loss: 0.6686\n",
      "[1364/1762] D loss: 1.3871, G loss: 0.7219\n",
      "[1444/1762] D loss: 1.0953, G loss: 0.9072\n",
      "[1524/1762] D loss: 1.0414, G loss: 1.7425\n",
      "[1604/1762] D loss: 1.3892, G loss: 0.6605\n",
      "[1684/1762] D loss: 1.3866, G loss: 0.7044\n",
      "[1762/1762] D loss: 1.3873, G loss: 0.7097\n",
      "train error: \n",
      " D loss: 1.322664, G loss: 0.869512, D accuracy: 53.2%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.299700, G loss: 0.987613, D accuracy: 54.2%, cell accuracy: 99.9%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0515, G loss: 1.3064\n",
      "[84/1762] D loss: 1.3865, G loss: 0.7031\n",
      "[164/1762] D loss: 1.3867, G loss: 0.6924\n",
      "[244/1762] D loss: 1.3882, G loss: 0.6506\n",
      "[324/1762] D loss: 1.0676, G loss: 1.0870\n",
      "[404/1762] D loss: 5.4180, G loss: 9.8572\n",
      "[484/1762] D loss: 1.0881, G loss: 1.0419\n",
      "[564/1762] D loss: 1.3885, G loss: 0.6681\n",
      "[644/1762] D loss: 1.3880, G loss: 0.7014\n",
      "[724/1762] D loss: 1.2832, G loss: 0.7258\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6872\n",
      "[884/1762] D loss: 1.3865, G loss: 0.6789\n",
      "[964/1762] D loss: 1.3873, G loss: 0.7186\n",
      "[1044/1762] D loss: 1.0776, G loss: 1.0201\n",
      "[1124/1762] D loss: 1.3912, G loss: 0.6788\n",
      "[1204/1762] D loss: 1.3873, G loss: 0.7060\n",
      "[1284/1762] D loss: 1.0646, G loss: 0.9968\n",
      "[1364/1762] D loss: 1.3865, G loss: 0.6929\n",
      "[1444/1762] D loss: 1.0735, G loss: 1.0382\n",
      "[1524/1762] D loss: 1.3874, G loss: 0.6695\n",
      "[1604/1762] D loss: 1.3870, G loss: 0.7147\n",
      "[1684/1762] D loss: 1.3865, G loss: 0.6908\n",
      "[1762/1762] D loss: 1.3526, G loss: 0.6782\n",
      "train error: \n",
      " D loss: 1.354630, G loss: 0.699902, D accuracy: 51.6%, cell accuracy: 99.9%, board accuracy: 87.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.352426, G loss: 0.699803, D accuracy: 52.5%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3876, G loss: 0.6696\n",
      "[84/1762] D loss: 1.3852, G loss: 0.7078\n",
      "[164/1762] D loss: 1.2325, G loss: 1.0934\n",
      "[244/1762] D loss: 1.3866, G loss: 0.6872\n",
      "[324/1762] D loss: 1.3865, G loss: 0.6829\n",
      "[404/1762] D loss: 1.3866, G loss: 0.6971\n",
      "[484/1762] D loss: 1.3862, G loss: 0.6949\n",
      "[564/1762] D loss: 1.3858, G loss: 0.6915\n",
      "[644/1762] D loss: 1.3871, G loss: 0.7170\n",
      "[724/1762] D loss: 1.3862, G loss: 0.6861\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6841\n",
      "[884/1762] D loss: 1.0905, G loss: 0.9467\n",
      "[964/1762] D loss: 1.0831, G loss: 0.9788\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6875\n",
      "[1124/1762] D loss: 1.3862, G loss: 0.6918\n",
      "[1204/1762] D loss: 1.3862, G loss: 0.6904\n",
      "[1284/1762] D loss: 1.3860, G loss: 0.6914\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6969\n",
      "[1444/1762] D loss: 1.0539, G loss: 1.0779\n",
      "[1524/1762] D loss: 1.3865, G loss: 0.6886\n",
      "[1604/1762] D loss: 1.3851, G loss: 0.7032\n",
      "[1684/1762] D loss: 1.2472, G loss: 1.0546\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6902\n",
      "train error: \n",
      " D loss: 1.321399, G loss: 0.776563, D accuracy: 53.4%, cell accuracy: 99.9%, board accuracy: 88.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.313041, G loss: 0.771696, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 84.5% \n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1978, G loss: 0.7345\n",
      "[84/1762] D loss: 1.3879, G loss: 0.6584\n",
      "[164/1762] D loss: 1.3867, G loss: 0.6856\n",
      "[244/1762] D loss: 1.2156, G loss: 1.3277\n",
      "[324/1762] D loss: 1.3787, G loss: 0.6785\n",
      "[404/1762] D loss: 1.3910, G loss: 0.6315\n",
      "[484/1762] D loss: 1.3877, G loss: 0.7204\n",
      "[564/1762] D loss: 1.3874, G loss: 0.6617\n",
      "[644/1762] D loss: 1.3864, G loss: 0.6976\n",
      "[724/1762] D loss: 1.4930, G loss: 1.0051\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6977\n",
      "[884/1762] D loss: 1.3871, G loss: 0.6696\n",
      "[964/1762] D loss: 1.1675, G loss: 0.8874\n",
      "[1044/1762] D loss: 1.3865, G loss: 0.6818\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.6854\n",
      "[1204/1762] D loss: 1.3870, G loss: 0.6922\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.7014\n",
      "[1364/1762] D loss: 1.3870, G loss: 0.6711\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6975\n",
      "[1524/1762] D loss: 1.0754, G loss: 1.0285\n",
      "[1604/1762] D loss: 1.3866, G loss: 0.7076\n",
      "[1684/1762] D loss: 1.3866, G loss: 0.6968\n",
      "[1762/1762] D loss: 0.7421, G loss: 1.5321\n",
      "train error: \n",
      " D loss: 1.314705, G loss: 0.837567, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 93.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.293973, G loss: 0.904388, D accuracy: 54.4%, cell accuracy: 99.9%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3869, G loss: 0.7078\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6954\n",
      "[164/1762] D loss: 1.3867, G loss: 0.7068\n",
      "[244/1762] D loss: 1.2052, G loss: 1.4599\n",
      "[324/1762] D loss: 1.3868, G loss: 0.6835\n",
      "[404/1762] D loss: 1.3865, G loss: 0.7038\n",
      "[484/1762] D loss: 1.3865, G loss: 0.6812\n",
      "[564/1762] D loss: 1.0733, G loss: 1.1586\n",
      "[644/1762] D loss: 1.3865, G loss: 0.6995\n",
      "[724/1762] D loss: 1.3877, G loss: 0.7037\n",
      "[804/1762] D loss: 1.3548, G loss: 1.0365\n",
      "[884/1762] D loss: 1.2940, G loss: 0.7772\n",
      "[964/1762] D loss: 1.3874, G loss: 0.7060\n",
      "[1044/1762] D loss: 1.3862, G loss: 0.6910\n",
      "[1124/1762] D loss: 1.3870, G loss: 0.7140\n",
      "[1204/1762] D loss: 1.2906, G loss: 0.8064\n",
      "[1284/1762] D loss: 1.3624, G loss: 0.7673\n",
      "[1364/1762] D loss: 1.3870, G loss: 0.6892\n",
      "[1444/1762] D loss: 1.3872, G loss: 0.6816\n",
      "[1524/1762] D loss: 1.3985, G loss: 0.6488\n",
      "[1604/1762] D loss: 1.1018, G loss: 0.8913\n",
      "[1684/1762] D loss: 1.3869, G loss: 0.6998\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.6847\n",
      "train error: \n",
      " D loss: 1.310745, G loss: 0.776975, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 91.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.288886, G loss: 0.795789, D accuracy: 54.5%, cell accuracy: 99.9%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3868, G loss: 0.6962\n",
      "[84/1762] D loss: 1.0772, G loss: 1.0133\n",
      "[164/1762] D loss: 1.3887, G loss: 0.6771\n",
      "[244/1762] D loss: 1.2741, G loss: 1.0776\n",
      "[324/1762] D loss: 1.0738, G loss: 1.0292\n",
      "[404/1762] D loss: 1.0727, G loss: 1.1646\n",
      "[484/1762] D loss: 1.3875, G loss: 0.6655\n",
      "[564/1762] D loss: 1.3855, G loss: 0.7141\n",
      "[644/1762] D loss: 1.3864, G loss: 0.6984\n",
      "[724/1762] D loss: 1.3866, G loss: 0.7115\n",
      "[804/1762] D loss: 1.0871, G loss: 0.9616\n",
      "[884/1762] D loss: 1.3869, G loss: 0.6916\n",
      "[964/1762] D loss: 1.1152, G loss: 0.9953\n",
      "[1044/1762] D loss: 1.1347, G loss: 0.8306\n",
      "[1124/1762] D loss: 1.3868, G loss: 0.6864\n",
      "[1204/1762] D loss: 1.3867, G loss: 0.7103\n",
      "[1284/1762] D loss: 1.2319, G loss: 1.1909\n",
      "[1364/1762] D loss: 1.3895, G loss: 0.6427\n",
      "[1444/1762] D loss: 1.3885, G loss: 0.7330\n",
      "[1524/1762] D loss: 1.3873, G loss: 0.6919\n",
      "[1604/1762] D loss: 1.0634, G loss: 1.1212\n",
      "[1684/1762] D loss: 1.3886, G loss: 0.6766\n",
      "[1762/1762] D loss: 1.3874, G loss: 0.6983\n",
      "train error: \n",
      " D loss: 1.296907, G loss: 0.887069, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 90.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.269618, G loss: 0.954839, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3875, G loss: 0.6691\n",
      "[84/1762] D loss: 1.0496, G loss: 1.3524\n",
      "[164/1762] D loss: 1.3868, G loss: 0.6927\n",
      "[244/1762] D loss: 1.3835, G loss: 0.6786\n",
      "[324/1762] D loss: 1.3874, G loss: 0.7044\n",
      "[404/1762] D loss: 1.3880, G loss: 0.6763\n",
      "[484/1762] D loss: 1.3880, G loss: 0.6730\n",
      "[564/1762] D loss: 1.3889, G loss: 0.6583\n",
      "[644/1762] D loss: 1.0874, G loss: 1.0172\n",
      "[724/1762] D loss: 1.3879, G loss: 0.6706\n",
      "[804/1762] D loss: 1.0452, G loss: 1.5534\n",
      "[884/1762] D loss: 1.3875, G loss: 0.6731\n",
      "[964/1762] D loss: 1.3874, G loss: 0.6925\n",
      "[1044/1762] D loss: 1.3866, G loss: 0.6765\n",
      "[1124/1762] D loss: 1.3867, G loss: 0.6698\n",
      "[1204/1762] D loss: 0.7019, G loss: 2.5516\n",
      "[1284/1762] D loss: 1.3868, G loss: 0.7104\n",
      "[1364/1762] D loss: 1.3870, G loss: 0.6718\n",
      "[1444/1762] D loss: 1.3875, G loss: 0.7095\n",
      "[1524/1762] D loss: 1.0427, G loss: 1.7725\n",
      "[1604/1762] D loss: 1.3881, G loss: 0.7047\n",
      "[1684/1762] D loss: 1.3887, G loss: 0.6546\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6884\n",
      "train error: \n",
      " D loss: 1.290691, G loss: 1.065047, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.262750, G loss: 1.167990, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3876, G loss: 0.6793\n",
      "[84/1762] D loss: 1.3866, G loss: 0.6819\n",
      "[164/1762] D loss: 1.3688, G loss: 0.7096\n",
      "[244/1762] D loss: 1.3872, G loss: 0.6848\n",
      "[324/1762] D loss: 1.3871, G loss: 0.6760\n",
      "[404/1762] D loss: 1.0527, G loss: 2.5516\n",
      "[484/1762] D loss: 1.0419, G loss: 1.9474\n",
      "[564/1762] D loss: 1.3871, G loss: 0.6863\n",
      "[644/1762] D loss: 1.3869, G loss: 0.6874\n",
      "[724/1762] D loss: 1.0403, G loss: 2.1094\n",
      "[804/1762] D loss: 1.3857, G loss: 0.6807\n",
      "[884/1762] D loss: 1.3874, G loss: 0.6742\n",
      "[964/1762] D loss: 1.3875, G loss: 0.6792\n",
      "[1044/1762] D loss: 1.3866, G loss: 0.7059\n",
      "[1124/1762] D loss: 1.0416, G loss: 3.9700\n",
      "[1204/1762] D loss: 1.3875, G loss: 0.6931\n",
      "[1284/1762] D loss: 1.3867, G loss: 0.6956\n",
      "[1364/1762] D loss: 1.1854, G loss: 2.1575\n",
      "[1444/1762] D loss: 1.3910, G loss: 0.7222\n",
      "[1524/1762] D loss: 1.3874, G loss: 0.6917\n",
      "[1604/1762] D loss: 1.3889, G loss: 0.6556\n",
      "[1684/1762] D loss: 1.3869, G loss: 0.7059\n",
      "[1762/1762] D loss: 1.3972, G loss: 0.6725\n",
      "train error: \n",
      " D loss: 1.285907, G loss: 1.265212, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.256060, G loss: 1.432881, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3867, G loss: 0.7035\n",
      "[84/1762] D loss: 1.3869, G loss: 0.6697\n",
      "[164/1762] D loss: 1.3874, G loss: 0.6895\n",
      "[244/1762] D loss: 1.0431, G loss: 2.8435\n",
      "[324/1762] D loss: 1.3889, G loss: 0.7015\n",
      "[404/1762] D loss: 1.3865, G loss: 0.6999\n",
      "[484/1762] D loss: 1.3869, G loss: 0.7066\n",
      "[564/1762] D loss: 1.4761, G loss: 0.7424\n",
      "[644/1762] D loss: 1.3938, G loss: 0.7806\n",
      "[724/1762] D loss: 1.3902, G loss: 0.7518\n",
      "[804/1762] D loss: 1.3859, G loss: 0.7328\n",
      "[884/1762] D loss: 1.3899, G loss: 0.7286\n",
      "[964/1762] D loss: 1.2039, G loss: 0.7794\n",
      "[1044/1762] D loss: 1.3882, G loss: 0.7291\n",
      "[1124/1762] D loss: 1.3872, G loss: 0.6885\n",
      "[1204/1762] D loss: 1.3867, G loss: 0.6939\n",
      "[1284/1762] D loss: 1.0766, G loss: 1.0788\n",
      "[1364/1762] D loss: 1.3902, G loss: 0.7320\n",
      "[1444/1762] D loss: 1.3869, G loss: 0.6966\n",
      "[1524/1762] D loss: 1.3896, G loss: 0.7377\n",
      "[1604/1762] D loss: 1.2755, G loss: 0.7584\n",
      "[1684/1762] D loss: 1.3885, G loss: 0.6939\n",
      "[1762/1762] D loss: 1.3866, G loss: 0.7069\n",
      "train error: \n",
      " D loss: 1.325121, G loss: 0.795186, D accuracy: 53.0%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.315469, G loss: 0.823822, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3874, G loss: 0.7120\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6972\n",
      "[164/1762] D loss: 1.3861, G loss: 0.7003\n",
      "[244/1762] D loss: 1.3884, G loss: 0.7128\n",
      "[324/1762] D loss: 1.3885, G loss: 0.6492\n",
      "[404/1762] D loss: 1.3875, G loss: 0.7134\n",
      "[484/1762] D loss: 1.3865, G loss: 0.6735\n",
      "[564/1762] D loss: 1.3870, G loss: 0.7080\n",
      "[644/1762] D loss: 1.2283, G loss: 1.1543\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6882\n",
      "[804/1762] D loss: 1.3884, G loss: 0.7237\n",
      "[884/1762] D loss: 1.3870, G loss: 0.7039\n",
      "[964/1762] D loss: 0.7145, G loss: 2.2738\n",
      "[1044/1762] D loss: 1.0515, G loss: 1.3808\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.6948\n",
      "[1204/1762] D loss: 1.3866, G loss: 0.6974\n",
      "[1284/1762] D loss: 1.3869, G loss: 0.6973\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6820\n",
      "[1444/1762] D loss: 1.1457, G loss: 0.8054\n",
      "[1524/1762] D loss: 1.3880, G loss: 0.7245\n",
      "[1604/1762] D loss: 1.3872, G loss: 0.6772\n",
      "[1684/1762] D loss: 1.3866, G loss: 0.7063\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6918\n",
      "train error: \n",
      " D loss: 1.312093, G loss: 0.850797, D accuracy: 53.4%, cell accuracy: 99.9%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.310581, G loss: 0.876201, D accuracy: 54.0%, cell accuracy: 99.9%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4365, G loss: 2.1752\n",
      "[84/1762] D loss: 1.3792, G loss: 0.6977\n",
      "[164/1762] D loss: 1.0553, G loss: 1.2076\n",
      "[244/1762] D loss: 1.1179, G loss: 0.8585\n",
      "[324/1762] D loss: 1.3868, G loss: 0.7052\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6950\n",
      "[484/1762] D loss: 1.3867, G loss: 0.6755\n",
      "[564/1762] D loss: 1.3867, G loss: 0.7122\n",
      "[644/1762] D loss: 1.3866, G loss: 0.7026\n",
      "[724/1762] D loss: 1.3865, G loss: 0.6830\n",
      "[804/1762] D loss: 1.0655, G loss: 1.0758\n",
      "[884/1762] D loss: 0.7635, G loss: 1.3792\n",
      "[964/1762] D loss: 1.3865, G loss: 0.6826\n",
      "[1044/1762] D loss: 1.3868, G loss: 0.6756\n",
      "[1124/1762] D loss: 1.3883, G loss: 0.7091\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6969\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6881\n",
      "[1364/1762] D loss: 1.3874, G loss: 0.6827\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.7066\n",
      "[1524/1762] D loss: 1.3874, G loss: 0.7188\n",
      "[1604/1762] D loss: 1.3868, G loss: 0.6877\n",
      "[1684/1762] D loss: 1.3865, G loss: 0.6806\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.6872\n",
      "train error: \n",
      " D loss: 1.326496, G loss: 0.864027, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 87.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.308185, G loss: 0.988093, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 81.8% \n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3872, G loss: 0.6820\n",
      "[84/1762] D loss: 1.3865, G loss: 0.7020\n",
      "[164/1762] D loss: 1.3899, G loss: 0.6332\n",
      "[244/1762] D loss: 1.1673, G loss: 0.7923\n",
      "[324/1762] D loss: 1.3906, G loss: 0.6335\n",
      "[404/1762] D loss: 1.3866, G loss: 0.6914\n",
      "[484/1762] D loss: 1.3851, G loss: 0.6919\n",
      "[564/1762] D loss: 1.3338, G loss: 0.8131\n",
      "[644/1762] D loss: 1.3891, G loss: 0.6465\n",
      "[724/1762] D loss: 1.3865, G loss: 0.6893\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6940\n",
      "[884/1762] D loss: 1.3805, G loss: 0.6927\n",
      "[964/1762] D loss: 1.3788, G loss: 0.6936\n",
      "[1044/1762] D loss: 1.3866, G loss: 0.6841\n",
      "[1124/1762] D loss: 1.3866, G loss: 0.6845\n",
      "[1204/1762] D loss: 1.3866, G loss: 0.6797\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6908\n",
      "[1364/1762] D loss: 1.0400, G loss: 2.4117\n",
      "[1444/1762] D loss: 1.2035, G loss: 2.2619\n",
      "[1524/1762] D loss: 1.3866, G loss: 0.6808\n",
      "[1604/1762] D loss: 1.3872, G loss: 0.6933\n",
      "[1684/1762] D loss: 1.2009, G loss: 2.2943\n",
      "[1762/1762] D loss: 0.6941, G loss: 3.8397\n",
      "train error: \n",
      " D loss: 1.290795, G loss: 1.173333, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 90.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.264491, G loss: 1.309524, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3866, G loss: 0.6780\n",
      "[84/1762] D loss: 1.0402, G loss: 2.3860\n",
      "[164/1762] D loss: 1.3866, G loss: 0.7085\n",
      "[244/1762] D loss: 1.3872, G loss: 0.6803\n",
      "[324/1762] D loss: 1.0405, G loss: 2.0665\n",
      "[404/1762] D loss: 1.3870, G loss: 0.6934\n",
      "[484/1762] D loss: 1.0401, G loss: 2.2232\n",
      "[564/1762] D loss: 1.3869, G loss: 0.6970\n",
      "[644/1762] D loss: 1.3866, G loss: 0.6781\n",
      "[724/1762] D loss: 1.3866, G loss: 0.6826\n",
      "[804/1762] D loss: 1.3865, G loss: 0.7006\n",
      "[884/1762] D loss: 1.0398, G loss: 2.6220\n",
      "[964/1762] D loss: 1.3871, G loss: 0.6806\n",
      "[1044/1762] D loss: 1.1643, G loss: 2.3879\n",
      "[1124/1762] D loss: 1.2194, G loss: 9.0827\n",
      "[1204/1762] D loss: 1.3872, G loss: 0.6807\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6728\n",
      "[1364/1762] D loss: 1.3537, G loss: 0.7209\n",
      "[1444/1762] D loss: 1.3881, G loss: 0.6821\n",
      "[1524/1762] D loss: 1.3349, G loss: 0.7045\n",
      "[1604/1762] D loss: 0.9258, G loss: 2.3450\n",
      "[1684/1762] D loss: 0.6765, G loss: 9.6112\n",
      "[1762/1762] D loss: 1.3899, G loss: 0.6400\n",
      "train error: \n",
      " D loss: 1.257313, G loss: 1.395851, D accuracy: 58.2%, cell accuracy: 99.6%, board accuracy: 78.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.225804, G loss: 1.584589, D accuracy: 59.2%, cell accuracy: 99.6%, board accuracy: 75.7% \n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3668, G loss: 0.6619\n",
      "[84/1762] D loss: 1.3893, G loss: 0.6557\n",
      "[164/1762] D loss: 1.0454, G loss: 4.0846\n",
      "[244/1762] D loss: 1.2689, G loss: 1.0872\n",
      "[324/1762] D loss: 1.1865, G loss: 4.9663\n",
      "[404/1762] D loss: 1.3900, G loss: 0.6775\n",
      "[484/1762] D loss: 0.9279, G loss: 5.5934\n",
      "[564/1762] D loss: 1.3949, G loss: 0.6364\n",
      "[644/1762] D loss: 1.0428, G loss: 1.9745\n",
      "[724/1762] D loss: 1.3872, G loss: 0.6701\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6910\n",
      "[884/1762] D loss: 1.3872, G loss: 0.7041\n",
      "[964/1762] D loss: 1.0427, G loss: 2.6642\n",
      "[1044/1762] D loss: 1.0409, G loss: 2.2954\n",
      "[1124/1762] D loss: 1.0400, G loss: 2.6809\n",
      "[1204/1762] D loss: 1.3295, G loss: 0.9804\n",
      "[1284/1762] D loss: 1.3956, G loss: 0.6109\n",
      "[1364/1762] D loss: 1.3884, G loss: 0.7321\n",
      "[1444/1762] D loss: 1.3875, G loss: 0.7101\n",
      "[1524/1762] D loss: 0.8682, G loss: 3.4793\n",
      "[1604/1762] D loss: 1.3867, G loss: 0.6957\n",
      "[1684/1762] D loss: 1.3875, G loss: 0.6759\n",
      "[1762/1762] D loss: 1.3872, G loss: 0.7235\n",
      "train error: \n",
      " D loss: 1.285708, G loss: 1.533810, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.255311, G loss: 1.880968, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3876, G loss: 0.7038\n",
      "[84/1762] D loss: 1.0398, G loss: 2.7661\n",
      "[164/1762] D loss: 1.3866, G loss: 0.7003\n",
      "[244/1762] D loss: 1.3707, G loss: 0.7064\n",
      "[324/1762] D loss: 1.3879, G loss: 0.6876\n",
      "[404/1762] D loss: 1.0398, G loss: 2.8270\n",
      "[484/1762] D loss: 1.3874, G loss: 0.6726\n",
      "[564/1762] D loss: 1.3876, G loss: 0.6665\n",
      "[644/1762] D loss: 0.6935, G loss: 5.4290\n",
      "[724/1762] D loss: 1.3867, G loss: 0.6742\n",
      "[804/1762] D loss: 1.3866, G loss: 0.7017\n",
      "[884/1762] D loss: 1.3872, G loss: 0.6709\n",
      "[964/1762] D loss: 1.0399, G loss: 3.0721\n",
      "[1044/1762] D loss: 1.3881, G loss: 0.6845\n",
      "[1124/1762] D loss: 1.3879, G loss: 0.6738\n",
      "[1204/1762] D loss: 1.3895, G loss: 0.6521\n",
      "[1284/1762] D loss: 1.3866, G loss: 0.6781\n",
      "[1364/1762] D loss: 1.3866, G loss: 0.7059\n",
      "[1444/1762] D loss: 1.3870, G loss: 0.6764\n",
      "[1524/1762] D loss: 1.3873, G loss: 0.6948\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6899\n",
      "[1684/1762] D loss: 1.3869, G loss: 0.6884\n",
      "[1762/1762] D loss: 1.3862, G loss: 0.6842\n",
      "train error: \n",
      " D loss: 1.284780, G loss: 1.414348, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.259242, G loss: 1.607501, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6953\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6955\n",
      "[164/1762] D loss: 1.3892, G loss: 0.6542\n",
      "[244/1762] D loss: 1.0398, G loss: 3.2349\n",
      "[324/1762] D loss: 1.3867, G loss: 0.7054\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6855\n",
      "[484/1762] D loss: 1.3869, G loss: 0.6892\n",
      "[564/1762] D loss: 1.3869, G loss: 0.6734\n",
      "[644/1762] D loss: 1.3874, G loss: 0.6767\n",
      "[724/1762] D loss: 1.0403, G loss: 3.2188\n",
      "[804/1762] D loss: 1.0401, G loss: 3.0908\n",
      "[884/1762] D loss: 1.0398, G loss: 3.1006\n",
      "[964/1762] D loss: 1.3869, G loss: 0.7073\n",
      "[1044/1762] D loss: 1.3865, G loss: 0.6852\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.6781\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.7021\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6939\n",
      "[1364/1762] D loss: 1.3865, G loss: 0.6830\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.7047\n",
      "[1524/1762] D loss: 1.3867, G loss: 0.6826\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6910\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.6979\n",
      "[1762/1762] D loss: 1.3875, G loss: 0.7233\n",
      "train error: \n",
      " D loss: 1.284502, G loss: 1.453526, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.257387, G loss: 1.652743, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6905\n",
      "[84/1762] D loss: 1.0398, G loss: 3.2436\n",
      "[164/1762] D loss: 1.0398, G loss: 2.9812\n",
      "[244/1762] D loss: 1.3872, G loss: 0.6718\n",
      "[324/1762] D loss: 1.3873, G loss: 0.6726\n",
      "[404/1762] D loss: 1.3863, G loss: 0.6969\n",
      "[484/1762] D loss: 1.3865, G loss: 0.6957\n",
      "[564/1762] D loss: 1.0400, G loss: 3.7194\n",
      "[644/1762] D loss: 1.0398, G loss: 3.0307\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6912\n",
      "[804/1762] D loss: 1.0404, G loss: 3.5799\n",
      "[884/1762] D loss: 1.3871, G loss: 0.6823\n",
      "[964/1762] D loss: 1.3864, G loss: 0.6974\n",
      "[1044/1762] D loss: 1.3866, G loss: 0.6881\n",
      "[1124/1762] D loss: 1.0398, G loss: 3.2465\n",
      "[1204/1762] D loss: 1.0399, G loss: 3.3359\n",
      "[1284/1762] D loss: 1.3865, G loss: 0.6912\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6900\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6903\n",
      "[1524/1762] D loss: 1.0398, G loss: 3.1134\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6839\n",
      "[1684/1762] D loss: 1.3866, G loss: 0.7069\n",
      "[1762/1762] D loss: 1.3886, G loss: 0.6537\n",
      "train error: \n",
      " D loss: 1.284478, G loss: 1.491702, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.256814, G loss: 1.703205, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6961\n",
      "[84/1762] D loss: 1.3864, G loss: 0.7010\n",
      "[164/1762] D loss: 1.0398, G loss: 3.1436\n",
      "[244/1762] D loss: 1.0402, G loss: 3.3466\n",
      "[324/1762] D loss: 1.3864, G loss: 0.6878\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6839\n",
      "[484/1762] D loss: 1.0399, G loss: 3.3737\n",
      "[564/1762] D loss: 1.0398, G loss: 2.9974\n",
      "[644/1762] D loss: 1.3867, G loss: 0.6747\n",
      "[724/1762] D loss: 1.3870, G loss: 0.6815\n",
      "[804/1762] D loss: 0.6932, G loss: 5.9337\n",
      "[884/1762] D loss: 1.0401, G loss: 3.8076\n",
      "[964/1762] D loss: 1.3864, G loss: 0.6868\n",
      "[1044/1762] D loss: 1.3869, G loss: 0.7076\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.6904\n",
      "[1204/1762] D loss: 0.6932, G loss: 6.0488\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6964\n",
      "[1364/1762] D loss: 0.6932, G loss: 6.1382\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6937\n",
      "[1524/1762] D loss: 1.3866, G loss: 0.6794\n",
      "[1604/1762] D loss: 1.3867, G loss: 0.6835\n",
      "[1684/1762] D loss: 1.3866, G loss: 0.7101\n",
      "[1762/1762] D loss: 1.3879, G loss: 0.6591\n",
      "train error: \n",
      " D loss: 1.285096, G loss: 1.632461, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.258780, G loss: 1.911063, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3872, G loss: 0.6697\n",
      "[84/1762] D loss: 1.3865, G loss: 0.6922\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6972\n",
      "[244/1762] D loss: 1.0398, G loss: 3.8903\n",
      "[324/1762] D loss: 1.3866, G loss: 0.6926\n",
      "[404/1762] D loss: 1.3891, G loss: 0.6376\n",
      "[484/1762] D loss: 1.3867, G loss: 0.7057\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6900\n",
      "[644/1762] D loss: 1.3865, G loss: 0.6960\n",
      "[724/1762] D loss: 1.3869, G loss: 0.6817\n",
      "[804/1762] D loss: 1.0392, G loss: 3.3516\n",
      "[884/1762] D loss: 1.3867, G loss: 0.7000\n",
      "[964/1762] D loss: 1.3866, G loss: 0.6811\n",
      "[1044/1762] D loss: 1.3872, G loss: 0.7066\n",
      "[1124/1762] D loss: 1.0400, G loss: 3.2683\n",
      "[1204/1762] D loss: 1.3866, G loss: 0.6862\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6836\n",
      "[1364/1762] D loss: 1.3871, G loss: 0.6650\n",
      "[1444/1762] D loss: 1.3876, G loss: 0.6754\n",
      "[1524/1762] D loss: 1.3879, G loss: 0.6608\n",
      "[1604/1762] D loss: 1.3862, G loss: 0.7095\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.6922\n",
      "[1762/1762] D loss: 0.6933, G loss: 5.9268\n",
      "train error: \n",
      " D loss: 1.285308, G loss: 1.629021, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.252029, G loss: 1.973356, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3866, G loss: 0.6881\n",
      "[84/1762] D loss: 1.3581, G loss: 0.7141\n",
      "[164/1762] D loss: 1.3864, G loss: 0.6984\n",
      "[244/1762] D loss: 1.3872, G loss: 0.6576\n",
      "[324/1762] D loss: 1.0398, G loss: 2.8006\n",
      "[404/1762] D loss: 1.3866, G loss: 0.7068\n",
      "[484/1762] D loss: 1.3897, G loss: 0.6510\n",
      "[564/1762] D loss: 1.3866, G loss: 0.7089\n",
      "[644/1762] D loss: 1.3864, G loss: 0.6795\n",
      "[724/1762] D loss: 1.3721, G loss: 0.7243\n",
      "[804/1762] D loss: 1.3860, G loss: 0.6884\n",
      "[884/1762] D loss: 1.3873, G loss: 0.7177\n",
      "[964/1762] D loss: 1.3864, G loss: 0.6981\n",
      "[1044/1762] D loss: 1.0399, G loss: 2.8778\n",
      "[1124/1762] D loss: 1.3669, G loss: 0.7131\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6856\n",
      "[1284/1762] D loss: 1.3867, G loss: 0.6891\n",
      "[1364/1762] D loss: 1.0399, G loss: 2.7858\n",
      "[1444/1762] D loss: 1.0399, G loss: 2.9764\n",
      "[1524/1762] D loss: 1.3884, G loss: 0.6657\n",
      "[1604/1762] D loss: 1.3862, G loss: 0.6904\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6918\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6904\n",
      "train error: \n",
      " D loss: 1.283624, G loss: 1.370661, D accuracy: 54.3%, cell accuracy: 99.9%, board accuracy: 90.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.253590, G loss: 1.581385, D accuracy: 55.6%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0389, G loss: 3.0832\n",
      "[84/1762] D loss: 1.3854, G loss: 0.7032\n",
      "[164/1762] D loss: 1.3861, G loss: 0.6908\n",
      "[244/1762] D loss: 1.3855, G loss: 0.6842\n",
      "[324/1762] D loss: 1.3862, G loss: 0.7072\n",
      "[404/1762] D loss: 1.3862, G loss: 0.6879\n",
      "[484/1762] D loss: 1.3860, G loss: 0.6982\n",
      "[564/1762] D loss: 1.3776, G loss: 0.6951\n",
      "[644/1762] D loss: 1.0379, G loss: 3.7497\n",
      "[724/1762] D loss: 1.3638, G loss: 0.6400\n",
      "[804/1762] D loss: 1.3402, G loss: 0.5105\n",
      "[884/1762] D loss: 0.8207, G loss: 6.8539\n",
      "[964/1762] D loss: 1.2747, G loss: 0.7496\n",
      "[1044/1762] D loss: 1.2841, G loss: 0.7396\n",
      "[1124/1762] D loss: 1.0025, G loss: 1.3270\n",
      "[1204/1762] D loss: 1.0285, G loss: 2.3361\n",
      "[1284/1762] D loss: 0.8974, G loss: 1.6370\n",
      "[1364/1762] D loss: 1.4337, G loss: 0.9700\n",
      "[1444/1762] D loss: 1.4379, G loss: 0.9455\n",
      "[1524/1762] D loss: 1.0545, G loss: 3.3190\n",
      "[1604/1762] D loss: 1.1808, G loss: 2.5788\n",
      "[1684/1762] D loss: 1.2456, G loss: 0.7650\n",
      "[1762/1762] D loss: 1.4016, G loss: 0.8311\n",
      "train error: \n",
      " D loss: 1.238813, G loss: 1.207927, D accuracy: 61.2%, cell accuracy: 99.8%, board accuracy: 89.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.197124, G loss: 1.339823, D accuracy: 64.1%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3533, G loss: 0.7331\n",
      "[84/1762] D loss: 1.3826, G loss: 0.7121\n",
      "[164/1762] D loss: 1.3794, G loss: 0.6845\n",
      "[244/1762] D loss: 1.3486, G loss: 0.6637\n",
      "[324/1762] D loss: 1.3792, G loss: 0.7522\n",
      "[404/1762] D loss: 1.0343, G loss: 2.7542\n",
      "[484/1762] D loss: 1.3540, G loss: 0.6960\n",
      "[564/1762] D loss: 1.3838, G loss: 0.5911\n",
      "[644/1762] D loss: 1.3797, G loss: 0.6809\n",
      "[724/1762] D loss: 1.2355, G loss: 3.7830\n",
      "[804/1762] D loss: 0.5925, G loss: 14.2974\n",
      "[884/1762] D loss: 1.3490, G loss: 0.6729\n",
      "[964/1762] D loss: 1.3602, G loss: 0.6942\n",
      "[1044/1762] D loss: 1.3684, G loss: 0.6846\n",
      "[1124/1762] D loss: 1.3867, G loss: 0.7322\n",
      "[1204/1762] D loss: 1.0457, G loss: 3.1429\n",
      "[1284/1762] D loss: 1.1800, G loss: 2.3525\n",
      "[1364/1762] D loss: 1.3041, G loss: 0.8408\n",
      "[1444/1762] D loss: 1.0516, G loss: 2.9039\n",
      "[1524/1762] D loss: 1.3772, G loss: 0.7100\n",
      "[1604/1762] D loss: 1.3822, G loss: 0.7070\n",
      "[1684/1762] D loss: 1.3800, G loss: 0.6702\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.7612\n",
      "train error: \n",
      " D loss: 1.296094, G loss: 2.193215, D accuracy: 54.5%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.265187, G loss: 2.643219, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3857, G loss: 0.7323\n",
      "[84/1762] D loss: 1.3783, G loss: 0.6930\n",
      "[164/1762] D loss: 1.3810, G loss: 0.6716\n",
      "[244/1762] D loss: 1.3832, G loss: 0.6780\n",
      "[324/1762] D loss: 1.3800, G loss: 0.6356\n",
      "[404/1762] D loss: 1.3808, G loss: 0.7636\n",
      "[484/1762] D loss: 1.3771, G loss: 0.6818\n",
      "[564/1762] D loss: 1.3764, G loss: 0.6630\n",
      "[644/1762] D loss: 1.3683, G loss: 0.6892\n",
      "[724/1762] D loss: 1.3725, G loss: 0.7088\n",
      "[804/1762] D loss: 1.3863, G loss: 0.7739\n",
      "[884/1762] D loss: 1.0378, G loss: 2.3508\n",
      "[964/1762] D loss: 1.3510, G loss: 0.7078\n",
      "[1044/1762] D loss: 1.3853, G loss: 0.6769\n",
      "[1124/1762] D loss: 1.3749, G loss: 0.6861\n",
      "[1204/1762] D loss: 1.3909, G loss: 0.6352\n",
      "[1284/1762] D loss: 1.3759, G loss: 0.7181\n",
      "[1364/1762] D loss: 1.0413, G loss: 1.9674\n",
      "[1444/1762] D loss: 1.0432, G loss: 2.3362\n",
      "[1524/1762] D loss: 1.3834, G loss: 0.6949\n",
      "[1604/1762] D loss: 1.3299, G loss: 0.7321\n",
      "[1684/1762] D loss: 1.3803, G loss: 0.7208\n",
      "[1762/1762] D loss: 1.3862, G loss: 0.6929\n",
      "train error: \n",
      " D loss: 1.277141, G loss: 1.200992, D accuracy: 56.6%, cell accuracy: 99.8%, board accuracy: 88.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.245211, G loss: 1.326376, D accuracy: 58.1%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3849, G loss: 0.6988\n",
      "[84/1762] D loss: 1.3710, G loss: 0.7438\n",
      "[164/1762] D loss: 1.3830, G loss: 0.6804\n",
      "[244/1762] D loss: 1.3843, G loss: 0.7445\n",
      "[324/1762] D loss: 1.2270, G loss: 1.0720\n",
      "[404/1762] D loss: 1.3884, G loss: 0.6212\n",
      "[484/1762] D loss: 1.3857, G loss: 0.7580\n",
      "[564/1762] D loss: 0.9138, G loss: 2.0471\n",
      "[644/1762] D loss: 1.2158, G loss: 3.4682\n",
      "[724/1762] D loss: 1.3904, G loss: 0.7640\n",
      "[804/1762] D loss: 1.0416, G loss: 2.3496\n",
      "[884/1762] D loss: 1.3718, G loss: 0.7126\n",
      "[964/1762] D loss: 1.0385, G loss: 2.5335\n",
      "[1044/1762] D loss: 1.3852, G loss: 0.7408\n",
      "[1124/1762] D loss: 1.3860, G loss: 0.6543\n",
      "[1204/1762] D loss: 1.1679, G loss: 4.1007\n",
      "[1284/1762] D loss: 1.3938, G loss: 0.7504\n",
      "[1364/1762] D loss: 0.6925, G loss: 6.4191\n",
      "[1444/1762] D loss: 1.0414, G loss: 3.7898\n",
      "[1524/1762] D loss: 1.3872, G loss: 0.6617\n",
      "[1604/1762] D loss: 1.3865, G loss: 0.6998\n",
      "[1684/1762] D loss: 1.3888, G loss: 0.7028\n",
      "[1762/1762] D loss: 0.5676, G loss: 4.6491\n",
      "train error: \n",
      " D loss: 1.268878, G loss: 1.791686, D accuracy: 56.9%, cell accuracy: 99.8%, board accuracy: 88.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.240237, G loss: 1.840287, D accuracy: 56.8%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3406, G loss: 0.7699\n",
      "[84/1762] D loss: 1.4181, G loss: 0.6026\n",
      "[164/1762] D loss: 1.3943, G loss: 0.8174\n",
      "[244/1762] D loss: 1.3844, G loss: 0.7102\n",
      "[324/1762] D loss: 0.6935, G loss: 7.5029\n",
      "[404/1762] D loss: 1.3738, G loss: 0.6926\n",
      "[484/1762] D loss: 0.9643, G loss: 3.9508\n",
      "[564/1762] D loss: 1.0346, G loss: 3.6300\n",
      "[644/1762] D loss: 1.0407, G loss: 4.1353\n",
      "[724/1762] D loss: 1.3814, G loss: 0.6899\n",
      "[804/1762] D loss: 1.3998, G loss: 0.5714\n",
      "[884/1762] D loss: 1.4204, G loss: 0.5546\n",
      "[964/1762] D loss: 1.3883, G loss: 0.7469\n",
      "[1044/1762] D loss: 1.3889, G loss: 0.7097\n",
      "[1124/1762] D loss: 1.3817, G loss: 0.7161\n",
      "[1204/1762] D loss: 1.2025, G loss: 3.3370\n",
      "[1284/1762] D loss: 1.0274, G loss: 3.9114\n",
      "[1364/1762] D loss: 1.3726, G loss: 0.6635\n",
      "[1444/1762] D loss: 1.3775, G loss: 0.6647\n",
      "[1524/1762] D loss: 1.3820, G loss: 0.6772\n",
      "[1604/1762] D loss: 1.3874, G loss: 0.6779\n",
      "[1684/1762] D loss: 1.3895, G loss: 0.6967\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.6854\n",
      "train error: \n",
      " D loss: 1.279033, G loss: 1.790105, D accuracy: 54.3%, cell accuracy: 99.9%, board accuracy: 91.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.250052, G loss: 1.950495, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0438, G loss: 3.8207\n",
      "[84/1762] D loss: 1.0434, G loss: 1.8105\n",
      "[164/1762] D loss: 1.3898, G loss: 0.7210\n",
      "[244/1762] D loss: 1.3880, G loss: 0.6771\n",
      "[324/1762] D loss: 1.3870, G loss: 0.7062\n",
      "[404/1762] D loss: 1.3903, G loss: 0.6563\n",
      "[484/1762] D loss: 1.3822, G loss: 0.7044\n",
      "[564/1762] D loss: 1.3453, G loss: 0.7131\n",
      "[644/1762] D loss: 1.3875, G loss: 0.6710\n",
      "[724/1762] D loss: 1.2504, G loss: 0.9805\n",
      "[804/1762] D loss: 1.2986, G loss: 0.7579\n",
      "[884/1762] D loss: 1.4058, G loss: 0.6487\n",
      "[964/1762] D loss: 1.4063, G loss: 0.5924\n",
      "[1044/1762] D loss: 1.0407, G loss: 3.4188\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.6868\n",
      "[1204/1762] D loss: 1.3818, G loss: 0.7288\n",
      "[1284/1762] D loss: 1.0403, G loss: 3.0670\n",
      "[1364/1762] D loss: 1.3859, G loss: 0.7075\n",
      "[1444/1762] D loss: 1.3852, G loss: 0.7189\n",
      "[1524/1762] D loss: 1.3991, G loss: 0.7431\n",
      "[1604/1762] D loss: 1.3858, G loss: 0.6903\n",
      "[1684/1762] D loss: 1.3816, G loss: 0.6745\n",
      "[1762/1762] D loss: 0.6937, G loss: 5.5351\n",
      "train error: \n",
      " D loss: 1.285842, G loss: 2.008163, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 91.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.254971, G loss: 2.445643, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3953, G loss: 0.8242\n",
      "[84/1762] D loss: 1.3834, G loss: 0.6804\n",
      "[164/1762] D loss: 1.0353, G loss: 3.3572\n",
      "[244/1762] D loss: 1.3895, G loss: 0.6503\n",
      "[324/1762] D loss: 1.3789, G loss: 0.6971\n",
      "[404/1762] D loss: 1.3879, G loss: 0.6639\n",
      "[484/1762] D loss: 1.3880, G loss: 0.6508\n",
      "[564/1762] D loss: 1.3793, G loss: 0.6779\n",
      "[644/1762] D loss: 1.2010, G loss: 3.4375\n",
      "[724/1762] D loss: 1.3890, G loss: 0.7169\n",
      "[804/1762] D loss: 1.3847, G loss: 0.7186\n",
      "[884/1762] D loss: 1.3882, G loss: 0.6639\n",
      "[964/1762] D loss: 1.3785, G loss: 0.6848\n",
      "[1044/1762] D loss: 1.0757, G loss: 3.1461\n",
      "[1124/1762] D loss: 1.1179, G loss: 0.8441\n",
      "[1204/1762] D loss: 1.3838, G loss: 0.6982\n",
      "[1284/1762] D loss: 1.3708, G loss: 0.6963\n",
      "[1364/1762] D loss: 1.3811, G loss: 0.7060\n",
      "[1444/1762] D loss: 1.3751, G loss: 0.7037\n",
      "[1524/1762] D loss: 1.3840, G loss: 0.7227\n",
      "[1604/1762] D loss: 1.3520, G loss: 0.7314\n",
      "[1684/1762] D loss: 1.0401, G loss: 2.2144\n",
      "[1762/1762] D loss: 1.3862, G loss: 0.6698\n",
      "train error: \n",
      " D loss: 1.303239, G loss: 1.116901, D accuracy: 54.4%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.265171, G loss: 1.265842, D accuracy: 55.7%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0407, G loss: 2.3334\n",
      "[84/1762] D loss: 1.0395, G loss: 2.5397\n",
      "[164/1762] D loss: 1.0392, G loss: 2.9513\n",
      "[244/1762] D loss: 1.3688, G loss: 0.6962\n",
      "[324/1762] D loss: 1.3578, G loss: 0.7016\n",
      "[404/1762] D loss: 1.0449, G loss: 3.3544\n",
      "[484/1762] D loss: 1.3733, G loss: 0.5813\n",
      "[564/1762] D loss: 0.3487, G loss: 6.9038\n",
      "[644/1762] D loss: 1.3909, G loss: 0.7035\n",
      "[724/1762] D loss: 1.3884, G loss: 0.7708\n",
      "[804/1762] D loss: 1.3787, G loss: 0.7486\n",
      "[884/1762] D loss: 1.3906, G loss: 0.6988\n",
      "[964/1762] D loss: 1.1498, G loss: 1.0702\n",
      "[1044/1762] D loss: 1.2631, G loss: 1.0712\n",
      "[1124/1762] D loss: 1.4140, G loss: 0.8403\n",
      "[1204/1762] D loss: 1.3898, G loss: 0.7409\n",
      "[1284/1762] D loss: 1.3886, G loss: 0.6697\n",
      "[1364/1762] D loss: 1.0506, G loss: 1.4277\n",
      "[1444/1762] D loss: 1.3867, G loss: 0.6938\n",
      "[1524/1762] D loss: 1.3875, G loss: 0.7136\n",
      "[1604/1762] D loss: 1.1294, G loss: 1.5958\n",
      "[1684/1762] D loss: 1.3873, G loss: 0.6846\n",
      "[1762/1762] D loss: 1.3873, G loss: 0.7256\n",
      "train error: \n",
      " D loss: 1.293166, G loss: 1.124283, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 89.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.280699, G loss: 1.116502, D accuracy: 54.1%, cell accuracy: 99.9%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0541, G loss: 1.3369\n",
      "[84/1762] D loss: 1.8170, G loss: 1.1959\n",
      "[164/1762] D loss: 1.3872, G loss: 0.7209\n",
      "[244/1762] D loss: 1.5354, G loss: 0.9717\n",
      "[324/1762] D loss: 1.3869, G loss: 0.7097\n",
      "[404/1762] D loss: 1.0766, G loss: 1.0402\n",
      "[484/1762] D loss: 1.3874, G loss: 0.7229\n",
      "[564/1762] D loss: 1.3852, G loss: 0.6604\n",
      "[644/1762] D loss: 0.7918, G loss: 1.2543\n",
      "[724/1762] D loss: 1.2172, G loss: 0.7459\n",
      "[804/1762] D loss: 1.3878, G loss: 0.6931\n",
      "[884/1762] D loss: 1.3874, G loss: 0.6662\n",
      "[964/1762] D loss: 1.3862, G loss: 0.7061\n",
      "[1044/1762] D loss: 1.3878, G loss: 0.6586\n",
      "[1124/1762] D loss: 1.0606, G loss: 1.1515\n",
      "[1204/1762] D loss: 1.3867, G loss: 0.7039\n",
      "[1284/1762] D loss: 1.3877, G loss: 0.7053\n",
      "[1364/1762] D loss: 1.3866, G loss: 0.6866\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.7087\n",
      "[1524/1762] D loss: 1.0705, G loss: 1.0489\n",
      "[1604/1762] D loss: 1.3868, G loss: 0.6935\n",
      "[1684/1762] D loss: 1.3867, G loss: 0.6833\n",
      "[1762/1762] D loss: 1.3866, G loss: 0.6793\n",
      "train error: \n",
      " D loss: 1.319607, G loss: 0.908658, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 93.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.299668, G loss: 1.056457, D accuracy: 54.2%, cell accuracy: 99.9%, board accuracy: 91.1% \n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3866, G loss: 0.6816\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6968\n",
      "[164/1762] D loss: 1.0445, G loss: 1.5314\n",
      "[244/1762] D loss: 1.0637, G loss: 1.0928\n",
      "[324/1762] D loss: 1.3865, G loss: 0.7107\n",
      "[404/1762] D loss: 1.3867, G loss: 0.6915\n",
      "[484/1762] D loss: 1.3895, G loss: 0.6926\n",
      "[564/1762] D loss: 1.1213, G loss: 0.8679\n",
      "[644/1762] D loss: 1.3881, G loss: 0.7330\n",
      "[724/1762] D loss: 1.0630, G loss: 1.1169\n",
      "[804/1762] D loss: 1.3865, G loss: 0.7034\n",
      "[884/1762] D loss: 1.7982, G loss: 1.2138\n",
      "[964/1762] D loss: 1.0607, G loss: 1.1641\n",
      "[1044/1762] D loss: 1.3866, G loss: 0.7043\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.6925\n",
      "[1204/1762] D loss: 1.0523, G loss: 1.3083\n",
      "[1284/1762] D loss: 1.3866, G loss: 0.6942\n",
      "[1364/1762] D loss: 1.3880, G loss: 0.6680\n",
      "[1444/1762] D loss: 1.3857, G loss: 0.7148\n",
      "[1524/1762] D loss: 1.3015, G loss: 0.8319\n",
      "[1604/1762] D loss: 1.3865, G loss: 0.7006\n",
      "[1684/1762] D loss: 1.3870, G loss: 0.7027\n",
      "[1762/1762] D loss: 1.3866, G loss: 0.6816\n",
      "train error: \n",
      " D loss: 1.309345, G loss: 0.799884, D accuracy: 54.2%, cell accuracy: 99.9%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.290262, G loss: 0.864282, D accuracy: 54.4%, cell accuracy: 99.9%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0849, G loss: 0.9698\n",
      "[84/1762] D loss: 1.3870, G loss: 0.7048\n",
      "[164/1762] D loss: 1.3876, G loss: 0.6679\n",
      "[244/1762] D loss: 1.3886, G loss: 0.7295\n",
      "[324/1762] D loss: 1.4703, G loss: 0.8584\n",
      "[404/1762] D loss: 1.3903, G loss: 0.6451\n",
      "[484/1762] D loss: 1.3867, G loss: 0.7047\n",
      "[564/1762] D loss: 1.1133, G loss: 0.8981\n",
      "[644/1762] D loss: 1.3867, G loss: 0.7100\n",
      "[724/1762] D loss: 1.3870, G loss: 0.6906\n",
      "[804/1762] D loss: 1.0880, G loss: 0.9692\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6941\n",
      "[964/1762] D loss: 1.0721, G loss: 1.0521\n",
      "[1044/1762] D loss: 1.3873, G loss: 0.6973\n",
      "[1124/1762] D loss: 1.3847, G loss: 0.7256\n",
      "[1204/1762] D loss: 1.0544, G loss: 1.2624\n",
      "[1284/1762] D loss: 1.0542, G loss: 1.2477\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.7003\n",
      "[1444/1762] D loss: 1.0581, G loss: 1.1818\n",
      "[1524/1762] D loss: 1.3872, G loss: 0.6760\n",
      "[1604/1762] D loss: 1.3869, G loss: 0.6775\n",
      "[1684/1762] D loss: 1.3869, G loss: 0.7083\n",
      "[1762/1762] D loss: 0.7616, G loss: 1.3514\n",
      "train error: \n",
      " D loss: 1.313467, G loss: 0.814660, D accuracy: 53.4%, cell accuracy: 99.9%, board accuracy: 93.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.294622, G loss: 0.835293, D accuracy: 54.3%, cell accuracy: 99.9%, board accuracy: 91.4% \n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3874, G loss: 0.6722\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6903\n",
      "[164/1762] D loss: 1.3878, G loss: 0.6992\n",
      "[244/1762] D loss: 1.3864, G loss: 0.6973\n",
      "[324/1762] D loss: 1.3865, G loss: 0.6954\n",
      "[404/1762] D loss: 1.3868, G loss: 0.6791\n",
      "[484/1762] D loss: 1.3868, G loss: 0.6923\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6896\n",
      "[644/1762] D loss: 1.0625, G loss: 1.1331\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6903\n",
      "[804/1762] D loss: 1.3864, G loss: 0.7019\n",
      "[884/1762] D loss: 1.3880, G loss: 0.6403\n",
      "[964/1762] D loss: 1.3867, G loss: 0.7075\n",
      "[1044/1762] D loss: 1.3874, G loss: 0.6878\n",
      "[1124/1762] D loss: 1.1004, G loss: 0.9135\n",
      "[1204/1762] D loss: 1.3870, G loss: 0.6982\n",
      "[1284/1762] D loss: 1.3865, G loss: 0.7028\n",
      "[1364/1762] D loss: 1.0564, G loss: 1.2201\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.6844\n",
      "[1524/1762] D loss: 1.3947, G loss: 0.7494\n",
      "[1604/1762] D loss: 1.3894, G loss: 0.7489\n",
      "[1684/1762] D loss: 1.3867, G loss: 0.6953\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.7031\n",
      "train error: \n",
      " D loss: 1.323026, G loss: 0.852190, D accuracy: 53.4%, cell accuracy: 99.9%, board accuracy: 92.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.317518, G loss: 0.795207, D accuracy: 54.2%, cell accuracy: 99.9%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3890, G loss: 0.6977\n",
      "[84/1762] D loss: 1.3866, G loss: 0.6998\n",
      "[164/1762] D loss: 1.3867, G loss: 0.6832\n",
      "[244/1762] D loss: 1.3865, G loss: 0.7053\n",
      "[324/1762] D loss: 1.3875, G loss: 0.6735\n",
      "[404/1762] D loss: 1.3876, G loss: 0.7118\n",
      "[484/1762] D loss: 0.7172, G loss: 1.9564\n",
      "[564/1762] D loss: 1.3867, G loss: 0.6788\n",
      "[644/1762] D loss: 1.3876, G loss: 0.6887\n",
      "[724/1762] D loss: 1.3866, G loss: 0.7061\n",
      "[804/1762] D loss: 1.3875, G loss: 0.6725\n",
      "[884/1762] D loss: 1.3867, G loss: 0.7105\n",
      "[964/1762] D loss: 1.3866, G loss: 0.6947\n",
      "[1044/1762] D loss: 1.0927, G loss: 0.9368\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.6896\n",
      "[1204/1762] D loss: 1.3866, G loss: 0.6898\n",
      "[1284/1762] D loss: 1.3867, G loss: 0.6963\n",
      "[1364/1762] D loss: 1.0783, G loss: 1.0184\n",
      "[1444/1762] D loss: 1.1057, G loss: 0.8667\n",
      "[1524/1762] D loss: 1.1739, G loss: 0.9401\n",
      "[1604/1762] D loss: 1.3866, G loss: 0.6867\n",
      "[1684/1762] D loss: 1.0825, G loss: 1.0070\n",
      "[1762/1762] D loss: 1.3873, G loss: 0.6855\n",
      "train error: \n",
      " D loss: 1.314313, G loss: 0.846464, D accuracy: 53.2%, cell accuracy: 99.9%, board accuracy: 93.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.312797, G loss: 0.873767, D accuracy: 54.0%, cell accuracy: 99.9%, board accuracy: 91.1% \n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.6625, G loss: 1.1107\n",
      "[84/1762] D loss: 1.3866, G loss: 0.6809\n",
      "[164/1762] D loss: 1.3865, G loss: 0.6997\n",
      "[244/1762] D loss: 1.3887, G loss: 0.6517\n",
      "[324/1762] D loss: 1.3870, G loss: 0.6800\n",
      "[404/1762] D loss: 1.3865, G loss: 0.7047\n",
      "[484/1762] D loss: 1.3868, G loss: 0.7020\n",
      "[564/1762] D loss: 1.0605, G loss: 1.0856\n",
      "[644/1762] D loss: 1.0742, G loss: 1.0279\n",
      "[724/1762] D loss: 1.0544, G loss: 1.2446\n",
      "[804/1762] D loss: 1.3870, G loss: 0.7009\n",
      "[884/1762] D loss: 1.3873, G loss: 0.6846\n",
      "[964/1762] D loss: 1.3864, G loss: 0.6946\n",
      "[1044/1762] D loss: 1.0926, G loss: 0.9474\n",
      "[1124/1762] D loss: 1.3868, G loss: 0.6752\n",
      "[1204/1762] D loss: 1.3867, G loss: 0.6832\n",
      "[1284/1762] D loss: 1.3866, G loss: 0.7059\n",
      "[1364/1762] D loss: 1.3865, G loss: 0.6796\n",
      "[1444/1762] D loss: 1.3870, G loss: 0.6999\n",
      "[1524/1762] D loss: 1.0566, G loss: 1.1949\n",
      "[1604/1762] D loss: 1.0549, G loss: 1.2024\n",
      "[1684/1762] D loss: 1.0937, G loss: 0.9380\n",
      "[1762/1762] D loss: 1.3862, G loss: 0.6939\n",
      "train error: \n",
      " D loss: 1.312512, G loss: 0.813028, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 93.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.303415, G loss: 0.835841, D accuracy: 54.0%, cell accuracy: 99.9%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2007, G loss: 1.7724\n",
      "[84/1762] D loss: 1.3871, G loss: 0.7077\n",
      "[164/1762] D loss: 1.3866, G loss: 0.6927\n",
      "[244/1762] D loss: 1.3864, G loss: 0.6923\n",
      "[324/1762] D loss: 1.5720, G loss: 1.0161\n",
      "[404/1762] D loss: 1.3862, G loss: 0.6956\n",
      "[484/1762] D loss: 1.3863, G loss: 0.6920\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6843\n",
      "[644/1762] D loss: 1.3887, G loss: 0.7148\n",
      "[724/1762] D loss: 1.3890, G loss: 0.6610\n",
      "[804/1762] D loss: 1.3873, G loss: 0.6800\n",
      "[884/1762] D loss: 1.4055, G loss: 0.7892\n",
      "[964/1762] D loss: 0.8279, G loss: 1.8966\n",
      "[1044/1762] D loss: 1.3873, G loss: 0.6708\n",
      "[1124/1762] D loss: 1.3873, G loss: 0.6900\n",
      "[1204/1762] D loss: 1.3873, G loss: 0.6726\n",
      "[1284/1762] D loss: 1.3881, G loss: 0.7257\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.7058\n",
      "[1444/1762] D loss: 1.0532, G loss: 1.2716\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.6934\n",
      "[1604/1762] D loss: 1.0738, G loss: 1.0350\n",
      "[1684/1762] D loss: 1.3873, G loss: 0.6654\n",
      "[1762/1762] D loss: 1.1326, G loss: 1.2739\n",
      "train error: \n",
      " D loss: 1.312805, G loss: 0.824391, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 93.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.295459, G loss: 0.831720, D accuracy: 54.2%, cell accuracy: 99.9%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2551, G loss: 0.9923\n",
      "[84/1762] D loss: 1.6394, G loss: 1.0871\n",
      "[164/1762] D loss: 1.3866, G loss: 0.6789\n",
      "[244/1762] D loss: 1.3865, G loss: 0.6924\n",
      "[324/1762] D loss: 1.0606, G loss: 1.1619\n",
      "[404/1762] D loss: 1.3872, G loss: 0.7225\n",
      "[484/1762] D loss: 1.3862, G loss: 0.6918\n",
      "[564/1762] D loss: 1.3876, G loss: 0.7220\n",
      "[644/1762] D loss: 1.0688, G loss: 1.0910\n",
      "[724/1762] D loss: 1.3866, G loss: 0.6806\n",
      "[804/1762] D loss: 1.3866, G loss: 0.7102\n",
      "[884/1762] D loss: 1.3869, G loss: 0.6770\n",
      "[964/1762] D loss: 1.3866, G loss: 0.6899\n",
      "[1044/1762] D loss: 1.3865, G loss: 0.6893\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.7064\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6961\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6991\n",
      "[1364/1762] D loss: 1.2291, G loss: 1.1257\n",
      "[1444/1762] D loss: 1.3870, G loss: 0.7127\n",
      "[1524/1762] D loss: 1.1921, G loss: 1.3061\n",
      "[1604/1762] D loss: 1.3865, G loss: 0.6852\n",
      "[1684/1762] D loss: 1.5722, G loss: 0.9792\n",
      "[1762/1762] D loss: 1.7698, G loss: 2.6285\n",
      "train error: \n",
      " D loss: 1.334396, G loss: 0.827658, D accuracy: 52.9%, cell accuracy: 99.9%, board accuracy: 93.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.356912, G loss: 0.818065, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3873, G loss: 0.6561\n",
      "[84/1762] D loss: 1.3865, G loss: 0.7100\n",
      "[164/1762] D loss: 1.3865, G loss: 0.6782\n",
      "[244/1762] D loss: 1.0672, G loss: 1.0990\n",
      "[324/1762] D loss: 1.3873, G loss: 0.6679\n",
      "[404/1762] D loss: 1.3866, G loss: 0.7001\n",
      "[484/1762] D loss: 1.3871, G loss: 0.6714\n",
      "[564/1762] D loss: 1.0424, G loss: 1.7828\n",
      "[644/1762] D loss: 1.3872, G loss: 0.7156\n",
      "[724/1762] D loss: 1.3895, G loss: 0.6375\n",
      "[804/1762] D loss: 1.3865, G loss: 0.6809\n",
      "[884/1762] D loss: 1.2313, G loss: 1.7040\n",
      "[964/1762] D loss: 1.3868, G loss: 0.6788\n",
      "[1044/1762] D loss: 1.6232, G loss: 1.0797\n",
      "[1124/1762] D loss: 1.3867, G loss: 0.6871\n",
      "[1204/1762] D loss: 1.3869, G loss: 0.7100\n",
      "[1284/1762] D loss: 1.0400, G loss: 3.4265\n",
      "[1364/1762] D loss: 1.3888, G loss: 0.6614\n",
      "[1444/1762] D loss: 1.3871, G loss: 0.6752\n",
      "[1524/1762] D loss: 1.3868, G loss: 0.6762\n",
      "[1604/1762] D loss: 1.3867, G loss: 0.7025\n",
      "[1684/1762] D loss: 1.0817, G loss: 0.9771\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.7019\n",
      "train error: \n",
      " D loss: 1.328394, G loss: 0.892946, D accuracy: 53.0%, cell accuracy: 99.9%, board accuracy: 93.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.347642, G loss: 0.906759, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3867, G loss: 0.6886\n",
      "[84/1762] D loss: 1.0540, G loss: 1.2593\n",
      "[164/1762] D loss: 1.3864, G loss: 0.6930\n",
      "[244/1762] D loss: 1.3866, G loss: 0.7111\n",
      "[324/1762] D loss: 1.3865, G loss: 0.6975\n",
      "[404/1762] D loss: 1.3868, G loss: 0.7012\n",
      "[484/1762] D loss: 1.5433, G loss: 0.9881\n",
      "[564/1762] D loss: 1.3867, G loss: 0.7013\n",
      "[644/1762] D loss: 1.3864, G loss: 0.6942\n",
      "[724/1762] D loss: 1.3886, G loss: 0.6642\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6957\n",
      "[884/1762] D loss: 0.7881, G loss: 1.2478\n",
      "[964/1762] D loss: 1.3873, G loss: 0.7025\n",
      "[1044/1762] D loss: 1.3872, G loss: 0.7094\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6888\n",
      "[1204/1762] D loss: 1.0714, G loss: 1.0434\n",
      "[1284/1762] D loss: 1.0661, G loss: 1.1079\n",
      "[1364/1762] D loss: 1.3873, G loss: 0.7049\n",
      "[1444/1762] D loss: 1.3872, G loss: 0.7172\n",
      "[1524/1762] D loss: 1.3882, G loss: 0.7006\n",
      "[1604/1762] D loss: 1.3866, G loss: 0.6901\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.6994\n",
      "[1762/1762] D loss: 0.8215, G loss: 1.1293\n",
      "train error: \n",
      " D loss: 1.332594, G loss: 0.767155, D accuracy: 52.6%, cell accuracy: 99.9%, board accuracy: 92.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.323968, G loss: 0.784113, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6923\n",
      "[84/1762] D loss: 1.3885, G loss: 0.7300\n",
      "[164/1762] D loss: 1.3868, G loss: 0.6835\n",
      "[244/1762] D loss: 1.3865, G loss: 0.7040\n",
      "[324/1762] D loss: 1.0735, G loss: 1.0654\n",
      "[404/1762] D loss: 1.3884, G loss: 0.6482\n",
      "[484/1762] D loss: 1.4385, G loss: 1.1603\n",
      "[564/1762] D loss: 1.3869, G loss: 0.6868\n",
      "[644/1762] D loss: 1.3642, G loss: 0.8027\n",
      "[724/1762] D loss: 1.3867, G loss: 0.6724\n",
      "[804/1762] D loss: 1.3877, G loss: 0.6679\n",
      "[884/1762] D loss: 1.3868, G loss: 0.6828\n",
      "[964/1762] D loss: 1.3868, G loss: 0.6938\n",
      "[1044/1762] D loss: 1.0847, G loss: 0.9807\n",
      "[1124/1762] D loss: 1.0690, G loss: 1.0635\n",
      "[1204/1762] D loss: 1.3869, G loss: 0.7010\n",
      "[1284/1762] D loss: 1.3866, G loss: 0.6756\n",
      "[1364/1762] D loss: 1.3865, G loss: 0.6918\n",
      "[1444/1762] D loss: 1.2764, G loss: 1.0921\n",
      "[1524/1762] D loss: 1.3867, G loss: 0.6998\n",
      "[1604/1762] D loss: 1.3866, G loss: 0.6853\n",
      "[1684/1762] D loss: 1.3865, G loss: 0.7070\n",
      "[1762/1762] D loss: 0.7070, G loss: 2.1863\n",
      "train error: \n",
      " D loss: 1.313313, G loss: 0.885786, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 92.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.312980, G loss: 0.919062, D accuracy: 54.1%, cell accuracy: 99.9%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3869, G loss: 0.7063\n",
      "[84/1762] D loss: 1.3868, G loss: 0.6773\n",
      "[164/1762] D loss: 1.6084, G loss: 0.7909\n",
      "[244/1762] D loss: 1.4408, G loss: 1.2421\n",
      "[324/1762] D loss: 1.3870, G loss: 0.6874\n",
      "[404/1762] D loss: 1.1260, G loss: 0.8414\n",
      "[484/1762] D loss: 1.3865, G loss: 0.6917\n",
      "[564/1762] D loss: 1.3866, G loss: 0.6915\n",
      "[644/1762] D loss: 1.3865, G loss: 0.6886\n",
      "[724/1762] D loss: 1.3867, G loss: 0.7014\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6870\n",
      "[884/1762] D loss: 1.3865, G loss: 0.6878\n",
      "[964/1762] D loss: 1.3867, G loss: 0.6779\n",
      "[1044/1762] D loss: 1.0532, G loss: 1.2656\n",
      "[1124/1762] D loss: 1.3868, G loss: 0.6827\n",
      "[1204/1762] D loss: 1.0494, G loss: 1.3309\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6922\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6918\n",
      "[1444/1762] D loss: 1.3867, G loss: 0.6884\n",
      "[1524/1762] D loss: 1.0453, G loss: 1.5271\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.7019\n",
      "[1684/1762] D loss: 1.3865, G loss: 0.6793\n",
      "[1762/1762] D loss: 1.3868, G loss: 0.6958\n",
      "train error: \n",
      " D loss: 1.310050, G loss: 0.858649, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 92.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.352468, G loss: 0.886177, D accuracy: 54.1%, cell accuracy: 99.9%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0588, G loss: 1.1809\n",
      "[84/1762] D loss: 1.3866, G loss: 0.6919\n",
      "[164/1762] D loss: 1.3873, G loss: 0.6705\n",
      "[244/1762] D loss: 1.3865, G loss: 0.7048\n",
      "[324/1762] D loss: 1.3865, G loss: 0.6818\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6928\n",
      "[484/1762] D loss: 1.3866, G loss: 0.6943\n",
      "[564/1762] D loss: 1.0545, G loss: 1.2431\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6963\n",
      "[724/1762] D loss: 1.3866, G loss: 0.7014\n",
      "[804/1762] D loss: 1.3864, G loss: 0.7001\n",
      "[884/1762] D loss: 1.3867, G loss: 0.6800\n",
      "[964/1762] D loss: 1.0524, G loss: 1.2960\n",
      "[1044/1762] D loss: 1.3867, G loss: 0.6746\n",
      "[1124/1762] D loss: 1.3867, G loss: 0.7024\n",
      "[1204/1762] D loss: 1.3866, G loss: 0.6869\n",
      "[1284/1762] D loss: 1.0926, G loss: 0.9389\n",
      "[1364/1762] D loss: 1.0433, G loss: 1.5666\n",
      "[1444/1762] D loss: 1.3866, G loss: 0.7059\n",
      "[1524/1762] D loss: 1.3867, G loss: 0.6788\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6914\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.6880\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6981\n",
      "train error: \n",
      " D loss: 1.309610, G loss: 0.854403, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 93.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.321049, G loss: 0.873382, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0716, G loss: 1.0644\n",
      "[84/1762] D loss: 1.3874, G loss: 0.6619\n",
      "[164/1762] D loss: 1.3865, G loss: 0.6998\n",
      "[244/1762] D loss: 1.3865, G loss: 0.6917\n",
      "[324/1762] D loss: 1.0768, G loss: 1.0105\n",
      "[404/1762] D loss: 1.3866, G loss: 0.6909\n",
      "[484/1762] D loss: 1.4144, G loss: 0.7869\n",
      "[564/1762] D loss: 1.3865, G loss: 0.7051\n",
      "[644/1762] D loss: 1.3864, G loss: 0.6877\n",
      "[724/1762] D loss: 1.3865, G loss: 0.7136\n",
      "[804/1762] D loss: 1.3872, G loss: 0.6747\n",
      "[884/1762] D loss: 1.2477, G loss: 1.0238\n",
      "[964/1762] D loss: 1.3867, G loss: 0.6860\n",
      "[1044/1762] D loss: 1.3865, G loss: 0.6937\n",
      "[1124/1762] D loss: 1.3867, G loss: 0.6829\n",
      "[1204/1762] D loss: 1.3870, G loss: 0.6731\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6983\n",
      "[1364/1762] D loss: 1.0651, G loss: 1.1281\n",
      "[1444/1762] D loss: 1.0503, G loss: 1.3120\n",
      "[1524/1762] D loss: 1.3866, G loss: 0.6767\n",
      "[1604/1762] D loss: 1.3867, G loss: 0.7108\n",
      "[1684/1762] D loss: 1.3866, G loss: 0.6998\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6924\n",
      "train error: \n",
      " D loss: 1.309795, G loss: 0.849826, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 93.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.299045, G loss: 0.867753, D accuracy: 54.2%, cell accuracy: 99.9%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0450, G loss: 1.4958\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6930\n",
      "[164/1762] D loss: 1.3864, G loss: 0.6831\n",
      "[244/1762] D loss: 1.0475, G loss: 1.3848\n",
      "[324/1762] D loss: 1.3868, G loss: 0.7156\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6914\n",
      "[484/1762] D loss: 1.3864, G loss: 0.6937\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6981\n",
      "[644/1762] D loss: 1.3864, G loss: 0.7008\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6962\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6893\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6875\n",
      "[964/1762] D loss: 1.3863, G loss: 0.6953\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6944\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.6874\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6885\n",
      "[1284/1762] D loss: 1.0736, G loss: 1.0549\n",
      "[1364/1762] D loss: 1.0567, G loss: 1.2056\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.6930\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.6859\n",
      "[1604/1762] D loss: 1.3866, G loss: 0.6867\n",
      "[1684/1762] D loss: 1.3867, G loss: 0.7099\n",
      "[1762/1762] D loss: 1.3649, G loss: 0.6942\n",
      "train error: \n",
      " D loss: 1.313256, G loss: 0.831241, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 93.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.308279, G loss: 0.855488, D accuracy: 54.0%, cell accuracy: 99.9%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3867, G loss: 0.6819\n",
      "[84/1762] D loss: 1.3868, G loss: 0.6990\n",
      "[164/1762] D loss: 0.7713, G loss: 1.3891\n",
      "[244/1762] D loss: 1.3879, G loss: 0.6640\n",
      "[324/1762] D loss: 0.8774, G loss: 2.0861\n",
      "[404/1762] D loss: 1.3866, G loss: 0.7082\n",
      "[484/1762] D loss: 1.3867, G loss: 0.6763\n",
      "[564/1762] D loss: 1.3863, G loss: 0.6934\n",
      "[644/1762] D loss: 1.3864, G loss: 0.6974\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6978\n",
      "[804/1762] D loss: 1.3868, G loss: 0.6789\n",
      "[884/1762] D loss: 1.3873, G loss: 0.7109\n",
      "[964/1762] D loss: 1.0431, G loss: 1.6520\n",
      "[1044/1762] D loss: 1.3878, G loss: 0.7194\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.6908\n",
      "[1204/1762] D loss: 1.0962, G loss: 2.9363\n",
      "[1284/1762] D loss: 1.0563, G loss: 1.2248\n",
      "[1364/1762] D loss: 1.0593, G loss: 1.1876\n",
      "[1444/1762] D loss: 1.3877, G loss: 0.6721\n",
      "[1524/1762] D loss: 1.3870, G loss: 0.6821\n",
      "[1604/1762] D loss: 1.0768, G loss: 1.0271\n",
      "[1684/1762] D loss: 1.1116, G loss: 0.8616\n",
      "[1762/1762] D loss: 1.3868, G loss: 0.7152\n",
      "train error: \n",
      " D loss: 1.315379, G loss: 0.780490, D accuracy: 53.2%, cell accuracy: 99.9%, board accuracy: 91.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.303987, G loss: 0.795662, D accuracy: 54.1%, cell accuracy: 99.9%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3866, G loss: 0.7008\n",
      "[84/1762] D loss: 1.2410, G loss: 1.0456\n",
      "[164/1762] D loss: 1.0910, G loss: 0.9567\n",
      "[244/1762] D loss: 1.3818, G loss: 0.7044\n",
      "[324/1762] D loss: 1.3866, G loss: 0.6874\n",
      "[404/1762] D loss: 1.3865, G loss: 0.7055\n",
      "[484/1762] D loss: 1.3834, G loss: 0.6917\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6899\n",
      "[644/1762] D loss: 1.3866, G loss: 0.6886\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6833\n",
      "[804/1762] D loss: 1.3865, G loss: 0.7029\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6859\n",
      "[964/1762] D loss: 1.3864, G loss: 0.6869\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6920\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.6990\n",
      "[1204/1762] D loss: 1.3867, G loss: 0.6778\n",
      "[1284/1762] D loss: 1.3866, G loss: 0.7067\n",
      "[1364/1762] D loss: 1.3866, G loss: 0.6925\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6966\n",
      "[1524/1762] D loss: 1.3865, G loss: 0.6828\n",
      "[1604/1762] D loss: 1.1559, G loss: 0.7872\n",
      "[1684/1762] D loss: 0.8284, G loss: 1.1284\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6850\n",
      "train error: \n",
      " D loss: 1.312624, G loss: 0.792707, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.295330, G loss: 0.822175, D accuracy: 54.8%, cell accuracy: 99.9%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6861\n",
      "[84/1762] D loss: 1.0646, G loss: 1.1226\n",
      "[164/1762] D loss: 1.0563, G loss: 1.2159\n",
      "[244/1762] D loss: 1.3865, G loss: 0.6890\n",
      "[324/1762] D loss: 1.0467, G loss: 1.3602\n",
      "[404/1762] D loss: 1.3866, G loss: 0.7036\n",
      "[484/1762] D loss: 1.3880, G loss: 0.7175\n",
      "[564/1762] D loss: 1.5516, G loss: 0.9834\n",
      "[644/1762] D loss: 1.3864, G loss: 0.6993\n",
      "[724/1762] D loss: 1.3870, G loss: 0.6975\n",
      "[804/1762] D loss: 1.0442, G loss: 1.5412\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6905\n",
      "[964/1762] D loss: 1.3867, G loss: 0.7117\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6959\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.6880\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6836\n",
      "[1284/1762] D loss: 1.4560, G loss: 0.6331\n",
      "[1364/1762] D loss: 1.2014, G loss: 1.8933\n",
      "[1444/1762] D loss: 1.0681, G loss: 1.0732\n",
      "[1524/1762] D loss: 1.3871, G loss: 0.6843\n",
      "[1604/1762] D loss: 1.3858, G loss: 0.7098\n",
      "[1684/1762] D loss: 1.0452, G loss: 1.4962\n",
      "[1762/1762] D loss: 1.3896, G loss: 0.6508\n",
      "train error: \n",
      " D loss: 1.346135, G loss: 0.954644, D accuracy: 53.4%, cell accuracy: 99.9%, board accuracy: 92.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.337118, G loss: 0.962026, D accuracy: 54.3%, cell accuracy: 99.9%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3962, G loss: 0.6032\n",
      "[84/1762] D loss: 1.3873, G loss: 0.7224\n",
      "[164/1762] D loss: 1.0468, G loss: 1.4199\n",
      "[244/1762] D loss: 1.3863, G loss: 0.7038\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6941\n",
      "[404/1762] D loss: 1.0696, G loss: 1.0811\n",
      "[484/1762] D loss: 1.0545, G loss: 1.2414\n",
      "[564/1762] D loss: 0.7257, G loss: 2.3068\n",
      "[644/1762] D loss: 1.3867, G loss: 0.7037\n",
      "[724/1762] D loss: 1.3867, G loss: 0.6925\n",
      "[804/1762] D loss: 1.3873, G loss: 0.7223\n",
      "[884/1762] D loss: 1.1000, G loss: 0.9008\n",
      "[964/1762] D loss: 1.3870, G loss: 0.6796\n",
      "[1044/1762] D loss: 1.1010, G loss: 0.8790\n",
      "[1124/1762] D loss: 1.3871, G loss: 0.7144\n",
      "[1204/1762] D loss: 1.3858, G loss: 0.6744\n",
      "[1284/1762] D loss: 1.3866, G loss: 0.6987\n",
      "[1364/1762] D loss: 1.3870, G loss: 0.6843\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.6823\n",
      "[1524/1762] D loss: 1.3866, G loss: 0.7069\n",
      "[1604/1762] D loss: 1.3870, G loss: 0.6743\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.6884\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6997\n",
      "train error: \n",
      " D loss: 1.311354, G loss: 0.858123, D accuracy: 53.4%, cell accuracy: 99.9%, board accuracy: 92.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.313921, G loss: 0.828022, D accuracy: 54.5%, cell accuracy: 99.9%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0518, G loss: 1.2872\n",
      "[84/1762] D loss: 1.3865, G loss: 0.7031\n",
      "[164/1762] D loss: 1.3845, G loss: 0.6872\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6999\n",
      "[324/1762] D loss: 1.3885, G loss: 0.6584\n",
      "[404/1762] D loss: 1.3863, G loss: 0.6939\n",
      "[484/1762] D loss: 1.3864, G loss: 0.6872\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6994\n",
      "[644/1762] D loss: 1.3925, G loss: 0.6159\n",
      "[724/1762] D loss: 1.0431, G loss: 1.6725\n",
      "[804/1762] D loss: 1.0568, G loss: 1.5378\n",
      "[884/1762] D loss: 1.3885, G loss: 0.6574\n",
      "[964/1762] D loss: 1.3872, G loss: 0.7205\n",
      "[1044/1762] D loss: 1.3865, G loss: 0.6963\n",
      "[1124/1762] D loss: 1.3885, G loss: 0.6504\n",
      "[1204/1762] D loss: 1.3882, G loss: 0.7341\n",
      "[1284/1762] D loss: 1.3862, G loss: 0.7003\n",
      "[1364/1762] D loss: 1.3868, G loss: 0.6782\n",
      "[1444/1762] D loss: 1.0841, G loss: 0.9880\n",
      "[1524/1762] D loss: 1.6469, G loss: 1.1085\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6885\n",
      "[1684/1762] D loss: 1.3876, G loss: 0.7261\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.6806\n",
      "train error: \n",
      " D loss: 1.315601, G loss: 0.841372, D accuracy: 53.2%, cell accuracy: 99.9%, board accuracy: 89.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.303721, G loss: 0.881503, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3848, G loss: 0.6966\n",
      "[84/1762] D loss: 1.3865, G loss: 0.6957\n",
      "[164/1762] D loss: 1.3870, G loss: 0.6948\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6967\n",
      "[324/1762] D loss: 1.3866, G loss: 0.7069\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6975\n",
      "[484/1762] D loss: 1.3865, G loss: 0.7056\n",
      "[564/1762] D loss: 1.5049, G loss: 0.9513\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6909\n",
      "[724/1762] D loss: 1.3867, G loss: 0.6762\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6869\n",
      "[884/1762] D loss: 1.3866, G loss: 0.6989\n",
      "[964/1762] D loss: 1.3836, G loss: 0.6836\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.6900\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.6858\n",
      "[1204/1762] D loss: 1.3865, G loss: 0.6933\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6830\n",
      "[1364/1762] D loss: 1.0493, G loss: 1.3465\n",
      "[1444/1762] D loss: 1.3827, G loss: 0.6958\n",
      "[1524/1762] D loss: 1.3899, G loss: 0.6687\n",
      "[1604/1762] D loss: 1.3871, G loss: 0.7079\n",
      "[1684/1762] D loss: 1.3868, G loss: 0.6863\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6874\n",
      "train error: \n",
      " D loss: 1.307185, G loss: 0.826126, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 85.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.295847, G loss: 0.836773, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 84.1% \n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3872, G loss: 0.6648\n",
      "[84/1762] D loss: 1.3880, G loss: 0.6970\n",
      "[164/1762] D loss: 1.0548, G loss: 1.2330\n",
      "[244/1762] D loss: 1.3884, G loss: 0.7364\n",
      "[324/1762] D loss: 1.3868, G loss: 0.6734\n",
      "[404/1762] D loss: 1.3869, G loss: 0.7139\n",
      "[484/1762] D loss: 1.0684, G loss: 1.1021\n",
      "[564/1762] D loss: 1.3820, G loss: 0.6757\n",
      "[644/1762] D loss: 1.0643, G loss: 1.1196\n",
      "[724/1762] D loss: 0.7100, G loss: 2.0935\n",
      "[804/1762] D loss: 1.3870, G loss: 0.6797\n",
      "[884/1762] D loss: 1.3808, G loss: 0.7069\n",
      "[964/1762] D loss: 1.3869, G loss: 0.7055\n",
      "[1044/1762] D loss: 1.3866, G loss: 0.6918\n",
      "[1124/1762] D loss: 1.3862, G loss: 0.6660\n",
      "[1204/1762] D loss: 1.3869, G loss: 0.7002\n",
      "[1284/1762] D loss: 1.3871, G loss: 0.6875\n",
      "[1364/1762] D loss: 1.3866, G loss: 0.7016\n",
      "[1444/1762] D loss: 1.1131, G loss: 0.8562\n",
      "[1524/1762] D loss: 1.0401, G loss: 2.8708\n",
      "[1604/1762] D loss: 1.3867, G loss: 0.7002\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.7026\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6924\n",
      "train error: \n",
      " D loss: 1.310921, G loss: 0.808997, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.316908, G loss: 0.846571, D accuracy: 54.4%, cell accuracy: 99.9%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3865, G loss: 0.6781\n",
      "[84/1762] D loss: 1.0636, G loss: 1.1089\n",
      "[164/1762] D loss: 1.0509, G loss: 1.4336\n",
      "[244/1762] D loss: 1.0603, G loss: 1.1584\n",
      "[324/1762] D loss: 1.3867, G loss: 0.7026\n",
      "[404/1762] D loss: 1.3867, G loss: 0.6879\n",
      "[484/1762] D loss: 1.0407, G loss: 1.7465\n",
      "[564/1762] D loss: 1.5230, G loss: 0.9313\n",
      "[644/1762] D loss: 1.3865, G loss: 0.6870\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6982\n",
      "[804/1762] D loss: 1.3871, G loss: 0.7097\n",
      "[884/1762] D loss: 1.3869, G loss: 0.6713\n",
      "[964/1762] D loss: 1.3867, G loss: 0.7003\n",
      "[1044/1762] D loss: 1.3872, G loss: 0.7028\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.7012\n",
      "[1204/1762] D loss: 1.0706, G loss: 1.3298\n",
      "[1284/1762] D loss: 1.3865, G loss: 0.6865\n",
      "[1364/1762] D loss: 1.3871, G loss: 0.6685\n",
      "[1444/1762] D loss: 1.2204, G loss: 1.0055\n",
      "[1524/1762] D loss: 1.3875, G loss: 0.6958\n",
      "[1604/1762] D loss: 1.3197, G loss: 0.7819\n",
      "[1684/1762] D loss: 1.3873, G loss: 0.6700\n",
      "[1762/1762] D loss: 1.3870, G loss: 0.6813\n",
      "train error: \n",
      " D loss: 1.349453, G loss: 0.827316, D accuracy: 52.6%, cell accuracy: 99.9%, board accuracy: 92.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.325688, G loss: 0.857377, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3837, G loss: 0.7190\n",
      "[84/1762] D loss: 1.3866, G loss: 0.6792\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6906\n",
      "[244/1762] D loss: 1.3867, G loss: 0.6909\n",
      "[324/1762] D loss: 1.1197, G loss: 0.8484\n",
      "[404/1762] D loss: 1.3866, G loss: 0.6902\n",
      "[484/1762] D loss: 1.3866, G loss: 0.6964\n",
      "[564/1762] D loss: 1.3866, G loss: 0.6803\n",
      "[644/1762] D loss: 1.3866, G loss: 0.6930\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6970\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6932\n",
      "[884/1762] D loss: 1.3871, G loss: 0.6780\n",
      "[964/1762] D loss: 1.0659, G loss: 1.1132\n",
      "[1044/1762] D loss: 1.0755, G loss: 1.0240\n",
      "[1124/1762] D loss: 1.0778, G loss: 0.9965\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6932\n",
      "[1284/1762] D loss: 1.3865, G loss: 0.6925\n",
      "[1364/1762] D loss: 1.3867, G loss: 0.7039\n",
      "[1444/1762] D loss: 1.3796, G loss: 0.6919\n",
      "[1524/1762] D loss: 1.3865, G loss: 0.6815\n",
      "[1604/1762] D loss: 1.3865, G loss: 0.6939\n",
      "[1684/1762] D loss: 1.3867, G loss: 0.6743\n",
      "[1762/1762] D loss: 1.3866, G loss: 0.6832\n",
      "train error: \n",
      " D loss: 1.331060, G loss: 0.782631, D accuracy: 52.8%, cell accuracy: 99.9%, board accuracy: 93.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.315195, G loss: 0.810003, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3866, G loss: 0.6795\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6932\n",
      "[164/1762] D loss: 1.0910, G loss: 0.9941\n",
      "[244/1762] D loss: 1.3864, G loss: 0.6970\n",
      "[324/1762] D loss: 1.3864, G loss: 0.6979\n",
      "[404/1762] D loss: 1.0897, G loss: 0.9948\n",
      "[484/1762] D loss: 1.3866, G loss: 0.6820\n",
      "[564/1762] D loss: 1.3864, G loss: 0.7004\n",
      "[644/1762] D loss: 1.3865, G loss: 0.6852\n",
      "[724/1762] D loss: 1.3869, G loss: 0.6789\n",
      "[804/1762] D loss: 1.3867, G loss: 0.7046\n",
      "[884/1762] D loss: 1.2588, G loss: 0.9176\n",
      "[964/1762] D loss: 1.3864, G loss: 0.6935\n",
      "[1044/1762] D loss: 1.3865, G loss: 0.6927\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.6955\n",
      "[1204/1762] D loss: 1.3802, G loss: 0.7055\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6953\n",
      "[1364/1762] D loss: 1.3865, G loss: 0.6959\n",
      "[1444/1762] D loss: 1.3868, G loss: 0.6785\n",
      "[1524/1762] D loss: 1.3867, G loss: 0.6962\n",
      "[1604/1762] D loss: 1.3867, G loss: 0.6873\n",
      "[1684/1762] D loss: 1.3851, G loss: 0.6918\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6912\n",
      "train error: \n",
      " D loss: 1.326853, G loss: 0.796129, D accuracy: 52.7%, cell accuracy: 99.9%, board accuracy: 93.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.312729, G loss: 0.811295, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2409, G loss: 0.9931\n",
      "[84/1762] D loss: 1.3644, G loss: 1.0721\n",
      "[164/1762] D loss: 1.0960, G loss: 0.9264\n",
      "[244/1762] D loss: 1.3866, G loss: 0.6999\n",
      "[324/1762] D loss: 1.0753, G loss: 1.0244\n",
      "[404/1762] D loss: 1.3866, G loss: 0.6850\n",
      "[484/1762] D loss: 1.5456, G loss: 0.9410\n",
      "[564/1762] D loss: 1.3871, G loss: 0.6664\n",
      "[644/1762] D loss: 1.3865, G loss: 0.7003\n",
      "[724/1762] D loss: 1.3865, G loss: 0.6836\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6949\n",
      "[884/1762] D loss: 1.3824, G loss: 0.6868\n",
      "[964/1762] D loss: 1.3864, G loss: 0.6797\n",
      "[1044/1762] D loss: 1.3869, G loss: 0.6888\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6919\n",
      "[1204/1762] D loss: 1.3866, G loss: 0.7052\n",
      "[1284/1762] D loss: 1.0922, G loss: 0.9392\n",
      "[1364/1762] D loss: 1.0936, G loss: 0.9200\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6921\n",
      "[1524/1762] D loss: 1.3877, G loss: 0.6597\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6989\n",
      "[1684/1762] D loss: 1.3865, G loss: 0.6865\n",
      "[1762/1762] D loss: 1.3868, G loss: 0.7076\n",
      "train error: \n",
      " D loss: 1.323891, G loss: 0.802433, D accuracy: 52.8%, cell accuracy: 99.9%, board accuracy: 93.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.314049, G loss: 0.823283, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3867, G loss: 0.6744\n",
      "[84/1762] D loss: 1.0735, G loss: 1.0422\n",
      "[164/1762] D loss: 1.3872, G loss: 0.6785\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6847\n",
      "[324/1762] D loss: 1.3866, G loss: 0.7034\n",
      "[404/1762] D loss: 1.3866, G loss: 0.6925\n",
      "[484/1762] D loss: 1.3865, G loss: 0.6911\n",
      "[564/1762] D loss: 1.0508, G loss: 1.3595\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6967\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6912\n",
      "[804/1762] D loss: 1.3327, G loss: 1.2315\n",
      "[884/1762] D loss: 1.3869, G loss: 0.6872\n",
      "[964/1762] D loss: 1.0754, G loss: 1.0381\n",
      "[1044/1762] D loss: 1.3868, G loss: 0.6789\n",
      "[1124/1762] D loss: 1.3862, G loss: 0.6837\n",
      "[1204/1762] D loss: 1.0996, G loss: 0.9278\n",
      "[1284/1762] D loss: 1.3882, G loss: 0.6595\n",
      "[1364/1762] D loss: 1.3867, G loss: 0.6884\n",
      "[1444/1762] D loss: 1.3873, G loss: 0.6686\n",
      "[1524/1762] D loss: 1.3872, G loss: 0.7092\n",
      "[1604/1762] D loss: 1.3866, G loss: 0.6901\n",
      "[1684/1762] D loss: 1.0769, G loss: 1.0154\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.7028\n",
      "train error: \n",
      " D loss: 1.324072, G loss: 0.815760, D accuracy: 52.8%, cell accuracy: 99.9%, board accuracy: 93.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.309724, G loss: 0.843750, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3865, G loss: 0.6871\n",
      "[84/1762] D loss: 1.0757, G loss: 1.0202\n",
      "[164/1762] D loss: 1.3870, G loss: 0.6850\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6949\n",
      "[324/1762] D loss: 1.3865, G loss: 0.6920\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6950\n",
      "[484/1762] D loss: 1.3868, G loss: 0.6741\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6959\n",
      "[644/1762] D loss: 1.3854, G loss: 0.6913\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6928\n",
      "[804/1762] D loss: 1.3867, G loss: 0.7109\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6886\n",
      "[964/1762] D loss: 1.3864, G loss: 0.6865\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.7030\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.6888\n",
      "[1204/1762] D loss: 0.7564, G loss: 1.4200\n",
      "[1284/1762] D loss: 1.2952, G loss: 0.8418\n",
      "[1364/1762] D loss: 1.0324, G loss: 1.6868\n",
      "[1444/1762] D loss: 1.3881, G loss: 0.6732\n",
      "[1524/1762] D loss: 1.3870, G loss: 0.6790\n",
      "[1604/1762] D loss: 1.3865, G loss: 0.6952\n",
      "[1684/1762] D loss: 1.2293, G loss: 1.2193\n",
      "[1762/1762] D loss: 1.3866, G loss: 0.6816\n",
      "train error: \n",
      " D loss: 1.322650, G loss: 0.832111, D accuracy: 53.0%, cell accuracy: 99.9%, board accuracy: 93.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.309709, G loss: 0.869583, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 91.1% \n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3874, G loss: 0.6663\n",
      "[84/1762] D loss: 1.3867, G loss: 0.6937\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6980\n",
      "[244/1762] D loss: 1.3866, G loss: 0.7079\n",
      "[324/1762] D loss: 1.3867, G loss: 0.6782\n",
      "[404/1762] D loss: 1.0442, G loss: 1.5540\n",
      "[484/1762] D loss: 1.3889, G loss: 0.6522\n",
      "[564/1762] D loss: 1.4950, G loss: 1.3253\n",
      "[644/1762] D loss: 1.3860, G loss: 0.6775\n",
      "[724/1762] D loss: 1.3870, G loss: 0.6945\n",
      "[804/1762] D loss: 1.3861, G loss: 0.6872\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6986\n",
      "[964/1762] D loss: 1.3869, G loss: 0.7073\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6993\n",
      "[1124/1762] D loss: 1.3868, G loss: 0.7123\n",
      "[1204/1762] D loss: 1.3865, G loss: 0.6820\n",
      "[1284/1762] D loss: 1.3870, G loss: 0.7034\n",
      "[1364/1762] D loss: 1.2989, G loss: 0.7926\n",
      "[1444/1762] D loss: 1.3868, G loss: 0.7050\n",
      "[1524/1762] D loss: 1.3865, G loss: 0.6903\n",
      "[1604/1762] D loss: 1.3866, G loss: 0.7017\n",
      "[1684/1762] D loss: 1.3873, G loss: 0.6816\n",
      "[1762/1762] D loss: 0.7739, G loss: 1.3107\n",
      "train error: \n",
      " D loss: 1.319769, G loss: 0.833865, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 93.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.305165, G loss: 0.865500, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6904\n",
      "[84/1762] D loss: 1.0461, G loss: 1.4555\n",
      "[164/1762] D loss: 0.7223, G loss: 1.8408\n",
      "[244/1762] D loss: 1.3866, G loss: 0.6954\n",
      "[324/1762] D loss: 1.0490, G loss: 1.3386\n",
      "[404/1762] D loss: 1.1514, G loss: 0.8302\n",
      "[484/1762] D loss: 1.0819, G loss: 0.9701\n",
      "[564/1762] D loss: 1.3890, G loss: 0.6870\n",
      "[644/1762] D loss: 1.3870, G loss: 0.6973\n",
      "[724/1762] D loss: 1.3874, G loss: 0.6935\n",
      "[804/1762] D loss: 1.3870, G loss: 0.6828\n",
      "[884/1762] D loss: 1.3866, G loss: 0.6818\n",
      "[964/1762] D loss: 1.3885, G loss: 0.6601\n",
      "[1044/1762] D loss: 1.0844, G loss: 0.9969\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.6955\n",
      "[1204/1762] D loss: 1.3865, G loss: 0.6809\n",
      "[1284/1762] D loss: 1.3859, G loss: 0.7092\n",
      "[1364/1762] D loss: 1.3873, G loss: 0.6669\n",
      "[1444/1762] D loss: 1.3866, G loss: 0.7084\n",
      "[1524/1762] D loss: 1.3870, G loss: 0.6672\n",
      "[1604/1762] D loss: 1.0785, G loss: 1.0622\n",
      "[1684/1762] D loss: 1.3882, G loss: 0.6664\n",
      "[1762/1762] D loss: 1.3879, G loss: 0.7070\n",
      "train error: \n",
      " D loss: 1.317116, G loss: 0.825103, D accuracy: 54.5%, cell accuracy: 99.9%, board accuracy: 85.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.299483, G loss: 0.832918, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 83.2% \n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0833, G loss: 0.9737\n",
      "[84/1762] D loss: 1.3971, G loss: 0.5956\n",
      "[164/1762] D loss: 0.7846, G loss: 1.2604\n",
      "[244/1762] D loss: 1.3884, G loss: 0.7184\n",
      "[324/1762] D loss: 1.4175, G loss: 0.7561\n",
      "[404/1762] D loss: 1.0700, G loss: 1.0531\n",
      "[484/1762] D loss: 1.3866, G loss: 0.6814\n",
      "[564/1762] D loss: 1.3887, G loss: 0.6750\n",
      "[644/1762] D loss: 1.3866, G loss: 0.6726\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6888\n",
      "[804/1762] D loss: 1.3885, G loss: 0.7278\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6948\n",
      "[964/1762] D loss: 1.3875, G loss: 0.6663\n",
      "[1044/1762] D loss: 1.3883, G loss: 0.7348\n",
      "[1124/1762] D loss: 1.3873, G loss: 0.6992\n",
      "[1204/1762] D loss: 1.1717, G loss: 0.8005\n",
      "[1284/1762] D loss: 1.3861, G loss: 0.6949\n",
      "[1364/1762] D loss: 1.3867, G loss: 0.6794\n",
      "[1444/1762] D loss: 1.3867, G loss: 0.6788\n",
      "[1524/1762] D loss: 1.3884, G loss: 0.6708\n",
      "[1604/1762] D loss: 1.3861, G loss: 0.6901\n",
      "[1684/1762] D loss: 1.5467, G loss: 0.9718\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6973\n",
      "train error: \n",
      " D loss: 1.314060, G loss: 0.803214, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.294740, G loss: 0.827083, D accuracy: 54.7%, cell accuracy: 99.9%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3794, G loss: 0.7158\n",
      "[84/1762] D loss: 1.3873, G loss: 0.6790\n",
      "[164/1762] D loss: 1.3872, G loss: 0.7189\n",
      "[244/1762] D loss: 1.3773, G loss: 0.7066\n",
      "[324/1762] D loss: 1.3867, G loss: 0.6832\n",
      "[404/1762] D loss: 1.3866, G loss: 0.6902\n",
      "[484/1762] D loss: 1.3863, G loss: 0.7031\n",
      "[564/1762] D loss: 1.3877, G loss: 0.6518\n",
      "[644/1762] D loss: 1.0667, G loss: 1.0960\n",
      "[724/1762] D loss: 1.3865, G loss: 0.6936\n",
      "[804/1762] D loss: 1.3866, G loss: 0.6772\n",
      "[884/1762] D loss: 1.3846, G loss: 0.7085\n",
      "[964/1762] D loss: 1.3115, G loss: 1.9016\n",
      "[1044/1762] D loss: 1.2716, G loss: 0.9139\n",
      "[1124/1762] D loss: 1.3871, G loss: 0.7219\n",
      "[1204/1762] D loss: 1.3866, G loss: 0.6982\n",
      "[1284/1762] D loss: 1.1113, G loss: 0.8631\n",
      "[1364/1762] D loss: 1.3867, G loss: 0.6731\n",
      "[1444/1762] D loss: 1.3872, G loss: 0.6806\n",
      "[1524/1762] D loss: 1.3873, G loss: 0.6793\n",
      "[1604/1762] D loss: 1.3868, G loss: 0.6738\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6986\n",
      "[1762/1762] D loss: 0.6977, G loss: 3.0616\n",
      "train error: \n",
      " D loss: 1.317153, G loss: 0.875843, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.298264, G loss: 0.972278, D accuracy: 54.8%, cell accuracy: 99.9%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6885\n",
      "[84/1762] D loss: 1.3872, G loss: 0.6996\n",
      "[164/1762] D loss: 1.3859, G loss: 0.6857\n",
      "[244/1762] D loss: 1.3865, G loss: 0.6975\n",
      "[324/1762] D loss: 1.3865, G loss: 0.6923\n",
      "[404/1762] D loss: 1.3879, G loss: 0.6648\n",
      "[484/1762] D loss: 1.3880, G loss: 0.6825\n",
      "[564/1762] D loss: 1.3869, G loss: 0.7081\n",
      "[644/1762] D loss: 1.3867, G loss: 0.6870\n",
      "[724/1762] D loss: 1.3872, G loss: 0.6942\n",
      "[804/1762] D loss: 1.3865, G loss: 0.6827\n",
      "[884/1762] D loss: 1.3865, G loss: 0.6873\n",
      "[964/1762] D loss: 1.2327, G loss: 1.0967\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.6886\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.6915\n",
      "[1204/1762] D loss: 1.3865, G loss: 0.7000\n",
      "[1284/1762] D loss: 1.3867, G loss: 0.6751\n",
      "[1364/1762] D loss: 1.3865, G loss: 0.6930\n",
      "[1444/1762] D loss: 1.3878, G loss: 0.6598\n",
      "[1524/1762] D loss: 1.3866, G loss: 0.7158\n",
      "[1604/1762] D loss: 1.3865, G loss: 0.6881\n",
      "[1684/1762] D loss: 1.3867, G loss: 0.6793\n",
      "[1762/1762] D loss: 1.3885, G loss: 0.6683\n",
      "train error: \n",
      " D loss: 1.318056, G loss: 0.843820, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 91.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.300461, G loss: 0.888168, D accuracy: 54.9%, cell accuracy: 99.9%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3069, G loss: 1.5000\n",
      "[84/1762] D loss: 1.3866, G loss: 0.6949\n",
      "[164/1762] D loss: 1.2222, G loss: 1.7354\n",
      "[244/1762] D loss: 1.4789, G loss: 0.7141\n",
      "[324/1762] D loss: 1.3864, G loss: 0.7047\n",
      "[404/1762] D loss: 1.3866, G loss: 0.7090\n",
      "[484/1762] D loss: 1.3865, G loss: 0.6939\n",
      "[564/1762] D loss: 1.3863, G loss: 0.6897\n",
      "[644/1762] D loss: 1.4411, G loss: 0.7695\n",
      "[724/1762] D loss: 1.3865, G loss: 0.6873\n",
      "[804/1762] D loss: 1.0853, G loss: 0.9689\n",
      "[884/1762] D loss: 1.3862, G loss: 0.6940\n",
      "[964/1762] D loss: 1.3864, G loss: 0.6886\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6777\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.7002\n",
      "[1204/1762] D loss: 1.3866, G loss: 0.6825\n",
      "[1284/1762] D loss: 1.3868, G loss: 0.6731\n",
      "[1364/1762] D loss: 1.0529, G loss: 1.2521\n",
      "[1444/1762] D loss: 1.0641, G loss: 1.1100\n",
      "[1524/1762] D loss: 1.3860, G loss: 0.6944\n",
      "[1604/1762] D loss: 1.3862, G loss: 0.6921\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6965\n",
      "[1762/1762] D loss: 1.3861, G loss: 0.6860\n",
      "train error: \n",
      " D loss: 1.362051, G loss: 0.985533, D accuracy: 52.9%, cell accuracy: 99.9%, board accuracy: 89.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.345467, G loss: 1.071889, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3868, G loss: 0.6716\n",
      "[84/1762] D loss: 1.3855, G loss: 0.6893\n",
      "[164/1762] D loss: 1.0630, G loss: 1.1341\n",
      "[244/1762] D loss: 1.3864, G loss: 0.6875\n",
      "[324/1762] D loss: 1.0598, G loss: 1.2094\n",
      "[404/1762] D loss: 1.3868, G loss: 0.6802\n",
      "[484/1762] D loss: 1.0562, G loss: 1.2334\n",
      "[564/1762] D loss: 1.0596, G loss: 1.1919\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6974\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6987\n",
      "[804/1762] D loss: 1.0961, G loss: 0.9126\n",
      "[884/1762] D loss: 1.3866, G loss: 0.6856\n",
      "[964/1762] D loss: 1.3864, G loss: 0.6802\n",
      "[1044/1762] D loss: 1.3871, G loss: 0.6904\n",
      "[1124/1762] D loss: 1.0691, G loss: 1.0594\n",
      "[1204/1762] D loss: 1.3866, G loss: 0.6917\n",
      "[1284/1762] D loss: 1.3873, G loss: 0.6850\n",
      "[1364/1762] D loss: 1.0538, G loss: 1.2564\n",
      "[1444/1762] D loss: 1.3875, G loss: 0.6621\n",
      "[1524/1762] D loss: 1.3866, G loss: 0.6914\n",
      "[1604/1762] D loss: 1.3866, G loss: 0.6933\n",
      "[1684/1762] D loss: 1.3866, G loss: 0.7083\n",
      "[1762/1762] D loss: 0.8060, G loss: 1.1353\n",
      "train error: \n",
      " D loss: 1.314835, G loss: 0.778939, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.299681, G loss: 0.852304, D accuracy: 54.4%, cell accuracy: 99.9%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3866, G loss: 0.6792\n",
      "[84/1762] D loss: 1.1056, G loss: 0.8985\n",
      "[164/1762] D loss: 1.3875, G loss: 0.6785\n",
      "[244/1762] D loss: 1.0765, G loss: 1.0237\n",
      "[324/1762] D loss: 1.3885, G loss: 0.7314\n",
      "[404/1762] D loss: 1.3866, G loss: 0.6980\n",
      "[484/1762] D loss: 0.9557, G loss: 1.2391\n",
      "[564/1762] D loss: 1.3879, G loss: 0.6597\n",
      "[644/1762] D loss: 1.3868, G loss: 0.7102\n",
      "[724/1762] D loss: 1.3846, G loss: 0.7098\n",
      "[804/1762] D loss: 1.3857, G loss: 0.7101\n",
      "[884/1762] D loss: 1.3869, G loss: 0.7072\n",
      "[964/1762] D loss: 1.3864, G loss: 0.6840\n",
      "[1044/1762] D loss: 1.5040, G loss: 0.8887\n",
      "[1124/1762] D loss: 1.3868, G loss: 0.6946\n",
      "[1204/1762] D loss: 1.3867, G loss: 0.6928\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6843\n",
      "[1364/1762] D loss: 1.0866, G loss: 0.9737\n",
      "[1444/1762] D loss: 1.0759, G loss: 1.0258\n",
      "[1524/1762] D loss: 1.3870, G loss: 0.6837\n",
      "[1604/1762] D loss: 1.0514, G loss: 1.3241\n",
      "[1684/1762] D loss: 1.3871, G loss: 0.6722\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6830\n",
      "train error: \n",
      " D loss: 1.311730, G loss: 0.869678, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 93.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.306578, G loss: 0.899142, D accuracy: 54.3%, cell accuracy: 99.9%, board accuracy: 90.7% \n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3866, G loss: 0.6999\n",
      "[84/1762] D loss: 1.3861, G loss: 0.6973\n",
      "[164/1762] D loss: 1.3879, G loss: 0.6602\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6950\n",
      "[324/1762] D loss: 1.3867, G loss: 0.6906\n",
      "[404/1762] D loss: 1.3872, G loss: 0.7021\n",
      "[484/1762] D loss: 1.3866, G loss: 0.6858\n",
      "[564/1762] D loss: 1.3875, G loss: 0.7011\n",
      "[644/1762] D loss: 1.3859, G loss: 0.6931\n",
      "[724/1762] D loss: 1.0494, G loss: 1.3493\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6918\n",
      "[884/1762] D loss: 1.3855, G loss: 0.6914\n",
      "[964/1762] D loss: 1.3849, G loss: 0.6949\n",
      "[1044/1762] D loss: 1.0513, G loss: 1.3403\n",
      "[1124/1762] D loss: 1.3867, G loss: 0.6808\n",
      "[1204/1762] D loss: 1.0400, G loss: 2.2878\n",
      "[1284/1762] D loss: 1.3865, G loss: 0.6935\n",
      "[1364/1762] D loss: 1.3859, G loss: 0.6953\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6919\n",
      "[1524/1762] D loss: 1.0401, G loss: 2.1769\n",
      "[1604/1762] D loss: 1.3877, G loss: 0.6642\n",
      "[1684/1762] D loss: 1.3869, G loss: 0.6900\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.6783\n",
      "train error: \n",
      " D loss: 1.291687, G loss: 1.212996, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 92.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.264647, G loss: 1.360900, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6866\n",
      "[84/1762] D loss: 1.3866, G loss: 0.6890\n",
      "[164/1762] D loss: 1.3867, G loss: 0.6766\n",
      "[244/1762] D loss: 1.3868, G loss: 0.6873\n",
      "[324/1762] D loss: 1.3866, G loss: 0.6849\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6910\n",
      "[484/1762] D loss: 1.3865, G loss: 0.6744\n",
      "[564/1762] D loss: 1.3873, G loss: 0.6890\n",
      "[644/1762] D loss: 1.3865, G loss: 0.6787\n",
      "[724/1762] D loss: 1.3865, G loss: 0.6636\n",
      "[804/1762] D loss: 1.2646, G loss: 1.0112\n",
      "[884/1762] D loss: 1.3858, G loss: 0.6884\n",
      "[964/1762] D loss: 1.3971, G loss: 0.6112\n",
      "[1044/1762] D loss: 1.0414, G loss: 3.6852\n",
      "[1124/1762] D loss: 1.3876, G loss: 0.6582\n",
      "[1204/1762] D loss: 1.3866, G loss: 0.6982\n",
      "[1284/1762] D loss: 1.3870, G loss: 0.6901\n",
      "[1364/1762] D loss: 1.3868, G loss: 0.6821\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.7030\n",
      "[1524/1762] D loss: 1.0398, G loss: 3.0080\n",
      "[1604/1762] D loss: 1.3865, G loss: 0.7020\n",
      "[1684/1762] D loss: 1.3881, G loss: 0.6556\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.7048\n",
      "train error: \n",
      " D loss: 1.290901, G loss: 1.447102, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 92.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.263370, G loss: 1.692508, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.7030\n",
      "[84/1762] D loss: 1.3874, G loss: 0.6753\n",
      "[164/1762] D loss: 1.3853, G loss: 0.6917\n",
      "[244/1762] D loss: 1.3864, G loss: 0.6968\n",
      "[324/1762] D loss: 1.3861, G loss: 0.6962\n",
      "[404/1762] D loss: 1.3865, G loss: 0.6896\n",
      "[484/1762] D loss: 1.0398, G loss: 3.9730\n",
      "[564/1762] D loss: 1.3845, G loss: 0.6809\n",
      "[644/1762] D loss: 1.1986, G loss: 3.0639\n",
      "[724/1762] D loss: 1.3868, G loss: 0.6728\n",
      "[804/1762] D loss: 1.3870, G loss: 0.6971\n",
      "[884/1762] D loss: 1.3867, G loss: 0.6823\n",
      "[964/1762] D loss: 1.0405, G loss: 1.9956\n",
      "[1044/1762] D loss: 1.0411, G loss: 3.0863\n",
      "[1124/1762] D loss: 1.3858, G loss: 0.6982\n",
      "[1204/1762] D loss: 1.3815, G loss: 0.6748\n",
      "[1284/1762] D loss: 1.3825, G loss: 0.6725\n",
      "[1364/1762] D loss: 1.3877, G loss: 0.6907\n",
      "[1444/1762] D loss: 1.3685, G loss: 0.6975\n",
      "[1524/1762] D loss: 1.3412, G loss: 0.6846\n",
      "[1604/1762] D loss: 1.3627, G loss: 0.6518\n",
      "[1684/1762] D loss: 1.3871, G loss: 0.7063\n",
      "[1762/1762] D loss: 0.9156, G loss: 8.3505\n",
      "train error: \n",
      " D loss: 1.268021, G loss: 1.620053, D accuracy: 60.8%, cell accuracy: 99.8%, board accuracy: 73.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.241567, G loss: 1.934744, D accuracy: 61.1%, cell accuracy: 99.7%, board accuracy: 70.7% \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    for cls in [TetrisDiscriminator, DiscWithMoreConv, DiscWithMoreConvPad]:\n",
    "        train(run_name=cls.__name__, disc_cls=cls, epochs=200)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though the two new discriminator architectures don't push the generator to the best possible board accuracy, they still display some desirable properties over the original `TetrisDiscriminator`. The discriminator loss is visibly a lot more stable with the new architectures, and there is even some improvement in the stability of the generator loss! The discriminator accuracy is higher for a given value of the generator board accuracy, which suggests that the discriminator is doing well against the generator, but the generator fails to improve to correct its mistakes.\n",
    "\n",
    "Looking at the generator gradients, they are basically all zero (or close to zero)! This must be why the generator stops improving. Is it because of dead ReLU?\n",
    "\n",
    "In contrast, the discriminator clearly has nonzero gradients even until the end of the training process.\n",
    "\n",
    "Since the two new discriminator architectures have such similar performance, let's pick `DiscWithMoreConv` as it's slightly simpler."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "By freezing one model and training the other, we diagnosed a stability problem in the discriminator. The new `DiscWithMoreConv` architecture solves this by having a larger capacity and no batch normalization. We should update the main GAN training notebook to use this new architecture.\n",
    "\n",
    "As a next step, we should figure out why the generator stops improving. Perhaps it is to with dying ReLU in either the discriminator or the generator. (Dying ReLU in the discriminator could cause this, because backpropagation for the generator always goes via the discriminator.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
