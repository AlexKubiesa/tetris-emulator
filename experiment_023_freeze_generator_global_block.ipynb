{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 023\n",
    "\n",
    "In this experiment, we will test the hypothesis that the generator \"overfits\" to an early discriminator that doesn't care about block spawns and fails to adapt when the same discriminator can detect block spawns. We will freeze the `glob` module  of the generator for a few epochs. We'll continue using a learning rate of 1e-4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecordingDataset(Dataset):\n",
    "    def __init__(self, path: str):\n",
    "        self.path = path\n",
    "        if not os.path.exists(path):\n",
    "            raise FileNotFoundError()\n",
    "        with os.scandir(self.path) as it:\n",
    "            entry: os.DirEntry = next(iter(it))\n",
    "            _, self.ext = os.path.splitext(entry.name)\n",
    "            self.highest_index = max((int(Path(file.path).stem) for file in it), default=-1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.highest_index + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file = os.path.join(self.path, f\"{idx}{self.ext}\")\n",
    "        if not os.path.exists(file):\n",
    "            raise IndexError()\n",
    "        boards = np.load(file)\n",
    "\n",
    "        def transform(board):\n",
    "            board = torch.tensor(board, dtype=torch.long)\n",
    "            board = F.one_hot(board, 2) # One-hot encode the cell types\n",
    "            board = board.type(torch.float) # Convert to floating-point\n",
    "            board = board.permute((2, 0, 1)) # Move channels/classes to dimension 0\n",
    "            return board\n",
    "\n",
    "        x = transform(boards[-2]) # Ignore all boards except the last two\n",
    "        y = transform(boards[-1])\n",
    "        return x, y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2, 22, 10]) torch.float32\n",
      "torch.Size([4, 2, 22, 10]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "train_dataset = RecordingDataset(os.path.join(\"data\", \"tetris_emulator\", \"train\"))\n",
    "test_dataset = RecordingDataset(os.path.join(\"data\", \"tetris_emulator\", \"test\"))\n",
    "batch_size = 4\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "x, y = next(iter(train_dataloader))\n",
    "print(x.shape, x.dtype)\n",
    "print(y.shape, y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TetrisModel(nn.Module):\n",
    "    \"\"\"Predicts the next state of the cells.\n",
    "\n",
    "    Inputs:\n",
    "        x: Tensor of float32 of shape (batch_size, channels, height, width). channels = 2 is the one-hot encoding of cell types, with\n",
    "           0 for empty cells and 1 for filled cells. height = 22 and width = 10 are the dimensions of the game board. The entries\n",
    "           should be 0 for empty cells and 1 for filled cells.\n",
    "        z: Tensor of float32 of shape (batch_size, 4). The entries should be random numbers sampled from a uniform distribution.\n",
    "    \n",
    "    Returns: Tensor of float32 of shape (batch_size, height, width), logits for the new cells. Probabilities close to 0 (negative logits)\n",
    "             correspond to empty cells, and probabilities close to 1 (positive logits) correspond to filled cells.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.loc = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.glob = nn.Sequential(\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(160, 10)\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Conv2d(26, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 2, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, z):\n",
    "        batch_size, channels, height, width = x.shape\n",
    "        \n",
    "        z = z[:, :, None, None] # Expand dims to match x\n",
    "        z = z.repeat(1, 1, height, width) # Upscale to image size\n",
    "        x = torch.cat((x, z), dim=1)\n",
    "\n",
    "        x = self.loc(x)\n",
    "\n",
    "        x_glob = self.glob(x)\n",
    "        x_glob = x_glob[:, :, None, None] # Expand dims\n",
    "        x_glob = x_glob.repeat(1, 1, height, width) # Upscale to image size\n",
    "        x = torch.cat((x, x_glob), dim=1)\n",
    "\n",
    "        y = self.head(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TetrisDiscriminator(nn.Module):\n",
    "    \"\"\"A discriminator for the cell state predictions. Assesses the output of the generator.\n",
    "\n",
    "    Inputs:\n",
    "        x: Tensor of float32 of shape (batch_size, channels, height, width). channels = 2 is the one-hot encoding of cell types, with\n",
    "           0 for empty cells and 1 for filled cells. height = 22 and width = 10 are the dimensions of the game board. The entries\n",
    "           should be 0 for empty cells and 1 for filled cells.\n",
    "        y: Tensor of float32 of shape (batch_size, channels, height, width), as with x. This should be either the output of the\n",
    "           generator (with exp applied) or the one-hot encoding of the ground truth of the next cell states.\n",
    "    \n",
    "    Returns: Tensor of float32 of shape (batch_size, 1), decisions on whether the data are real or fake. Probabilities close to 0 (negative logits)\n",
    "             correspond to fake data, and probabilities close to 1 (positive logits) correspond to real data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.body = nn.Sequential(\n",
    "                nn.Conv2d(4, 16, 3, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2),\n",
    "                nn.Conv2d(16, 16, 3),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(16, 16, 3),\n",
    "                nn.ReLU(),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(112, 16),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(16, 1),\n",
    "                nn.Flatten(start_dim=0)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        x = torch.cat((x, y), dim=1)\n",
    "        logits = self.body(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of generator parameters: 17996\n",
      "Number of discriminator parameters: 7057\n",
      "Predicted label for real data: 0.5467751026153564\n",
      "Predicted label for fake data: 0.5456675291061401\n"
     ]
    }
   ],
   "source": [
    "gen = TetrisModel().to(device)\n",
    "disc = TetrisDiscriminator().to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    X, y = next(iter(train_dataloader))\n",
    "    z = torch.rand(batch_size, 4)\n",
    "    y_gen = gen(X, z)\n",
    "    pred_on_real = F.sigmoid(disc(X, y)[0])\n",
    "    pred_on_fake = F.sigmoid(disc(X, y_gen)[0])\n",
    "    print(f\"Number of generator parameters: {count_parameters(gen)}\")\n",
    "    print(f\"Number of discriminator parameters: {count_parameters(disc)}\")\n",
    "    print(f\"Predicted label for real data: {pred_on_real}\")\n",
    "    print(f\"Predicted label for fake data: {pred_on_fake}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def find_interesting_examples(dataset, num=3):\n",
    "    num_spawns = num\n",
    "    \n",
    "    def inner():\n",
    "        num_spawns_left = num_spawns\n",
    "\n",
    "        for x, y in dataset:\n",
    "            # Check for block spawn\n",
    "            if (x.argmax(0)[0] == 0).all() & (y.argmax(0)[0] == 1).any():\n",
    "                if num_spawns_left > 0:\n",
    "                    num_spawns_left -= 1\n",
    "                    yield x, y\n",
    "                else:\n",
    "                    continue\n",
    "            \n",
    "    return list(itertools.islice(inner(), num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_prediction(x, pred, y):\n",
    "    \"\"\"Renders an example and prediction into a single-image array.\n",
    "    \n",
    "    Inputs:\n",
    "        x: Tensor of shape (height, width), the model input.\n",
    "        pred: Tensor of shape (height, width), the model prediction.\n",
    "        y: Tensor of shape (height, width), the target.\n",
    "    \"\"\"\n",
    "    assert len(x.shape) == 2, f\"Expected tensors of shape (width, height) but got {x.shape}\"\n",
    "    assert x.shape == pred.shape, f\"Shapes do not match: {x.shape} != {pred.shape}\"\n",
    "    assert x.shape == y.shape, f\"Shapes do not match: {x.shape} != {y.shape}\"\n",
    "    height, width = x.shape\n",
    "    with torch.no_grad():\n",
    "        separator = torch.ones(height, 1, dtype=x.dtype)\n",
    "        return torch.cat((x, separator, pred, separator, y), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = [\n",
    "    torch.tensor(\n",
    "        [[0, 0, 0, 1, 1, 1, 1, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
    "        dtype=torch.int), # I\n",
    "\n",
    "    torch.tensor(\n",
    "        [[0, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
    "        dtype=torch.int), # O\n",
    "\n",
    "    torch.tensor(\n",
    "        [[0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 1, 1, 1, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
    "        dtype=torch.int), # J\n",
    "\n",
    "    torch.tensor(\n",
    "        [[0, 0, 0, 1, 1, 1, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
    "        dtype=torch.int), # T\n",
    "\n",
    "    torch.tensor(\n",
    "        [[0, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 1, 1, 0, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
    "        dtype=torch.int), # S\n",
    "\n",
    "    torch.tensor(\n",
    "        [[0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 1, 1, 1, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
    "        dtype=torch.int), # L\n",
    "\n",
    "    torch.tensor(\n",
    "        [[0, 0, 0, 1, 1, 0, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
    "        dtype=torch.int) # Z\n",
    "]\n",
    "\n",
    "def get_valid_block_spawns(classes_X, classes_y_fake):\n",
    "    \"\"\"Determines whether predicted block spawns have a valid shape.\n",
    "    \n",
    "    Inputs:\n",
    "        classes_X: Tensor of int32 of shape (batch_size, height, width), the first time step (with argmax applied on cell types).\n",
    "        classes_y_fake: Tensor of int32 of shape (batch_size, height, width), the model's prediction (with argmax applied on cell types).\n",
    "\n",
    "    Returns: Tensor of bool of shape (batch_size,), whether the items are predicted block spawns AND valid.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        batch_size = classes_X.size(0)\n",
    "        ret = torch.full((batch_size,), False)\n",
    "\n",
    "        # Take difference to see which cells are full but weren't before.\n",
    "        diff = classes_y_fake - classes_X\n",
    "\n",
    "        # It's only a valid block spawn if the change in the first 3 rows matches\n",
    "        # one of the valid configurations.\n",
    "        for block in blocks:\n",
    "            ret |= (diff[:, :3, :] == block).all(-1).all(-1)\n",
    "        \n",
    "        return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_label = 1.0\n",
    "fake_label = 0.0\n",
    "\n",
    "def train_loop(dataloader, gen, disc, loss_fn, optimizer_gen, optimizer_disc):\n",
    "    gen.train()\n",
    "    disc.train()\n",
    "\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        ##################################################################\n",
    "        # (1) Update discriminator: minimize -log(D(x)) - log(1 - D(G(z)))\n",
    "        ##################################################################\n",
    "        disc.zero_grad()\n",
    "\n",
    "        ## Train with all-real batch\n",
    "        # Format batch\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        batch_size = X.size(0)\n",
    "        real_labels = torch.full((batch_size,), real_label, dtype=torch.float, device=device)\n",
    "        # Forward pass real batch through discriminator\n",
    "        output = torch.flatten(disc(X, y))\n",
    "        # Calculate loss on all-real batch\n",
    "        err_disc_real = loss_fn(output, real_labels)\n",
    "        # Calculate gradients for discriminator in backward pass\n",
    "        err_disc_real.backward()\n",
    "\n",
    "        ## Train with all-fake batch\n",
    "        # Generate batch of latent vectors\n",
    "        z = torch.rand(batch_size, 4, device=device)\n",
    "        # Generate fake image batch with generator\n",
    "        y_fake = gen(X, z)\n",
    "        fake_labels = torch.full((batch_size,), fake_label, dtype=torch.float, device=device)\n",
    "        # Classify all fake batch with discriminator\n",
    "        output = torch.flatten(disc(X, y_fake.detach()))\n",
    "        # Calculate discriminator's loss on the all-fake batch\n",
    "        err_disc_fake = loss_fn(output, fake_labels)\n",
    "        # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
    "        err_disc_fake.backward()\n",
    "\n",
    "        ## Update discriminator weights\n",
    "        # Compute error of discriminator as sum over the fake and the real batches\n",
    "        err_disc = err_disc_real + err_disc_fake\n",
    "        # Update discriminator\n",
    "        optimizer_disc.step()\n",
    "\n",
    "        ##############################################\n",
    "        # (2) Update generator: minimize -log(D(G(z)))\n",
    "        ##############################################\n",
    "        gen.zero_grad()\n",
    "        # Since we just updated the discriminator, perform another forward pass of the all-fake batch through it\n",
    "        output = torch.flatten(disc(X, y_fake))\n",
    "        # Calculate the generator's loss based on this output\n",
    "        # We use real labels because the generator wants to fool the discriminator\n",
    "        err_gen = loss_fn(output, real_labels)\n",
    "        # Calculate gradients for generator\n",
    "        err_gen.backward()\n",
    "        # Update generator\n",
    "        optimizer_gen.step()\n",
    "\n",
    "        # Output training stats\n",
    "        if batch % 20 == 0:\n",
    "            current = batch * dataloader.batch_size + batch_size\n",
    "            print(f\"[{current}/{size}] D loss: {err_disc.item():.4f}, G loss: {err_gen.item():.4f}\")\n",
    "\n",
    "\n",
    "def test_loop(split_name, dataloader, gen, disc, loss_fn, tb_writer, epoch, examples):\n",
    "    gen.eval()\n",
    "    disc.eval()\n",
    "\n",
    "    loss_disc = 0.0\n",
    "    loss_gen = 0.0\n",
    "    disc_accuracy = 0.0\n",
    "    cell_accuracy = 0.0\n",
    "    board_accuracy = 0.0\n",
    "    spawn_recall = 0.0\n",
    "    num_spawns = 0.0\n",
    "    spawn_validity = 0.0\n",
    "    num_predicted_spawns = 0.0\n",
    "    spawn_precision = 0.0\n",
    "    scores_real = np.zeros(len(dataloader.dataset))\n",
    "    scores_fake = np.zeros(len(dataloader.dataset))\n",
    "\n",
    "    num_batches = len(dataloader)\n",
    "    with torch.no_grad():        \n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            batch_size = X.size(0)\n",
    "            real_labels = torch.full((batch_size,), real_label, dtype=torch.float, device=device)\n",
    "            fake_labels = torch.full((batch_size,), fake_label, dtype=torch.float, device=device)\n",
    "\n",
    "            output_real = disc(X, y)\n",
    "            loss_disc += loss_fn(output_real, real_labels).item()\n",
    "\n",
    "            z = torch.rand(batch_size, 4, device=device)\n",
    "            y_fake = gen(X, z)\n",
    "            output_fake = disc(X, y_fake)\n",
    "            \n",
    "            loss_disc += loss_fn(output_fake, fake_labels).item()\n",
    "            loss_gen += loss_fn(output_fake, real_labels).item()\n",
    "\n",
    "            pred_real = (output_real > 0.0)\n",
    "            pred_fake = (output_fake > 0.0)\n",
    "            disc_accuracy += pred_real.type(torch.float).mean().item()\n",
    "            disc_accuracy += (~pred_fake).type(torch.float).mean().item()\n",
    "\n",
    "            classes_X = torch.argmax(X, dim=1)\n",
    "            classes_y = torch.argmax(y, dim=1)\n",
    "            classes_y_fake = torch.argmax(y_fake, dim=1)\n",
    "            cell_accuracy += (classes_y_fake == classes_y).type(torch.float).mean().item()\n",
    "            board_accuracy += (classes_y_fake == classes_y).all(-1).all(-1).type(torch.float).mean().item()\n",
    "\n",
    "            actual_spawns = (classes_X[:, 0, :] == 0).all(-1) & (classes_y[:, 0, :] == 1).any(-1)\n",
    "            predicted_spawns = (classes_X[:, 0, :] == 0).all(-1) & (classes_y_fake[:, 0, :] == 1).any(-1)\n",
    "            num_true_positives = (actual_spawns & predicted_spawns).type(torch.float).sum().item()\n",
    "            spawn_recall += num_true_positives\n",
    "            spawn_precision += num_true_positives\n",
    "            num_spawns += actual_spawns.type(torch.float).sum().item()\n",
    "            valid_spawns = get_valid_block_spawns(classes_X, classes_y_fake)\n",
    "            spawn_validity += valid_spawns.type(torch.float).sum().item()\n",
    "            num_predicted_spawns += predicted_spawns.type(torch.float).sum().item()\n",
    "\n",
    "            start_index = dataloader.batch_size * batch\n",
    "            end_index = start_index + batch_size\n",
    "            scores_real[start_index:end_index] = torch.sigmoid(output_real).numpy()\n",
    "            scores_fake[start_index:end_index] = torch.sigmoid(output_fake).numpy()\n",
    "\n",
    "    loss_disc /= num_batches\n",
    "    loss_gen /= num_batches\n",
    "    cell_accuracy /= num_batches\n",
    "    board_accuracy /= num_batches\n",
    "    spawn_recall /= num_spawns\n",
    "    spawn_precision = np.nan if (num_predicted_spawns == 0.0) else spawn_precision / num_predicted_spawns\n",
    "    disc_accuracy /= (2.0 * num_batches)\n",
    "    spawn_validity = np.nan if (num_predicted_spawns == 0.0) else spawn_validity / num_predicted_spawns\n",
    "\n",
    "    print(f\"{split_name} error: \\n D loss: {loss_disc:>8f}, G loss: {loss_gen:>8f}, D accuracy: {(100*disc_accuracy):>0.1f}%, cell accuracy: {(100*cell_accuracy):>0.1f}%, board accuracy: {(100*board_accuracy):>0.1f}% \\n\")\n",
    "\n",
    "    tb_writer.add_scalar(f\"Discriminator loss/{split_name}\", loss_disc, epoch)\n",
    "    tb_writer.add_scalar(f\"Loss/{split_name}\", loss_gen, epoch)\n",
    "    tb_writer.add_scalar(f\"Discriminator accuracy/{split_name}\", disc_accuracy, epoch)\n",
    "    tb_writer.add_scalar(f\"Cell accuracy/{split_name}\", cell_accuracy, epoch)\n",
    "    tb_writer.add_scalar(f\"Board accuracy/{split_name}\", board_accuracy, epoch)\n",
    "    tb_writer.add_scalar(f\"Spawn recall/{split_name}\", spawn_recall, epoch)\n",
    "    tb_writer.add_scalar(f\"Spawn precision/{split_name}\", spawn_precision, epoch)\n",
    "    tb_writer.add_scalar(f\"Spawn validity/{split_name}\", spawn_validity, epoch)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (X, y) in enumerate(examples):\n",
    "            X, y = X.unsqueeze(0), y.unsqueeze(0)\n",
    "            z = torch.rand(1, 4, device=device)\n",
    "            y_fake = gen(X, z)\n",
    "            X, y, y_fake = X.squeeze(0), y.squeeze(0), y_fake.squeeze(0)\n",
    "            X, y, y_fake = X.argmax(0), y.argmax(0), y_fake.argmax(0)\n",
    "            img = render_prediction(X, y_fake, y)\n",
    "            tb_writer.add_image(f\"Predictions/{split_name}/{i}\", img, epoch, dataformats=\"HW\")\n",
    "    \n",
    "    tb_writer.add_histogram(f\"Discriminator scores/{split_name}/real\", scores_real, epoch)\n",
    "    tb_writer.add_histogram(f\"Discriminator scores/{split_name}/fake\", scores_fake, epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(run_name=\"\", learning_rate=1e-4, epochs=100, frozen_epochs=0):\n",
    "    gen = TetrisModel().to(device)\n",
    "    gen.glob.requires_grad_(False)\n",
    "    disc = TetrisDiscriminator().to(device)\n",
    "\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer_gen = torch.optim.Adam(gen.parameters(), lr=learning_rate)\n",
    "    optimizer_disc = torch.optim.Adam(disc.parameters(), lr=learning_rate)\n",
    "\n",
    "    log_dir = os.path.join(\"runs\", \"experiment_023\")\n",
    "    log_subdir = os.path.join(log_dir, run_name + \"_\" + datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"))\n",
    "    tb_writer = SummaryWriter(log_subdir)\n",
    "\n",
    "    train_examples = find_interesting_examples(train_dataset)\n",
    "    test_examples = find_interesting_examples(test_dataset)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch}\\n-------------------------------\")\n",
    "        if epoch == frozen_epochs:\n",
    "            gen.glob.requires_grad_(True)\n",
    "        train_loop(train_dataloader, gen, disc, loss_fn, optimizer_gen, optimizer_disc)\n",
    "        test_loop(\"train\", train_dataloader, gen, disc, loss_fn, tb_writer, epoch, train_examples)\n",
    "        test_loop(\"test\", test_dataloader, gen, disc, loss_fn, tb_writer, epoch, test_examples)\n",
    "        gen_zero_grads = 0\n",
    "        for name, weight in gen.named_parameters():\n",
    "            tb_writer.add_histogram(f\"Weights/{name}\", weight, epoch)\n",
    "            if weight.grad is not None:\n",
    "                tb_writer.add_histogram(f\"Gradients/{name}\", weight.grad, epoch)\n",
    "                gen_zero_grads += weight.grad.numel() - weight.grad.count_nonzero().item()\n",
    "        tb_writer.add_scalar(f\"Zero gradients\", gen_zero_grads, epoch)\n",
    "        disc_zero_grads = 0\n",
    "        for name, weight in disc.named_parameters():\n",
    "            tb_writer.add_histogram(f\"Discriminator weights/{name}\", weight, epoch)\n",
    "            tb_writer.add_histogram(f\"Discriminator gradients/{name}\", weight.grad, epoch)\n",
    "            disc_zero_grads += weight.grad.numel() - weight.grad.count_nonzero().item()\n",
    "        tb_writer.add_scalar(f\"Discriminator zero gradients\", disc_zero_grads, epoch)\n",
    "\n",
    "    tb_writer.close()\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3964, G loss: 0.7889\n",
      "[84/1762] D loss: 1.3883, G loss: 0.7816\n",
      "[164/1762] D loss: 1.3772, G loss: 0.7722\n",
      "[244/1762] D loss: 1.3484, G loss: 0.7714\n",
      "[324/1762] D loss: 1.3075, G loss: 0.7647\n",
      "[404/1762] D loss: 1.2352, G loss: 0.7632\n",
      "[484/1762] D loss: 1.1427, G loss: 0.7284\n",
      "[564/1762] D loss: 1.0364, G loss: 0.7382\n",
      "[644/1762] D loss: 0.8927, G loss: 0.8512\n",
      "[724/1762] D loss: 0.8349, G loss: 0.9508\n",
      "[804/1762] D loss: 0.7055, G loss: 1.1102\n",
      "[884/1762] D loss: 0.5473, G loss: 1.4223\n",
      "[964/1762] D loss: 0.4489, G loss: 1.6392\n",
      "[1044/1762] D loss: 0.3195, G loss: 2.1040\n",
      "[1124/1762] D loss: 0.3599, G loss: 2.5724\n",
      "[1204/1762] D loss: 0.3629, G loss: 2.6392\n",
      "[1284/1762] D loss: 0.3398, G loss: 2.5682\n",
      "[1364/1762] D loss: 0.3013, G loss: 3.1530\n",
      "[1444/1762] D loss: 0.3837, G loss: 3.6000\n",
      "[1524/1762] D loss: 0.2110, G loss: 3.4108\n",
      "[1604/1762] D loss: 0.3226, G loss: 3.7344\n",
      "[1684/1762] D loss: 0.3392, G loss: 3.4309\n",
      "[1762/1762] D loss: 0.1422, G loss: 4.0691\n",
      "train error: \n",
      " D loss: 0.189668, G loss: 3.934002, D accuracy: 98.7%, cell accuracy: 89.3%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.189825, G loss: 4.029508, D accuracy: 98.8%, cell accuracy: 88.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.2199, G loss: 3.4989\n",
      "[84/1762] D loss: 0.3044, G loss: 3.4377\n",
      "[164/1762] D loss: 0.2328, G loss: 4.0585\n",
      "[244/1762] D loss: 0.3342, G loss: 4.3704\n",
      "[324/1762] D loss: 0.3173, G loss: 3.7078\n",
      "[404/1762] D loss: 0.2189, G loss: 4.0153\n",
      "[484/1762] D loss: 0.3340, G loss: 4.1651\n",
      "[564/1762] D loss: 0.3400, G loss: 4.0370\n",
      "[644/1762] D loss: 0.4659, G loss: 3.8492\n",
      "[724/1762] D loss: 0.2866, G loss: 4.1600\n",
      "[804/1762] D loss: 0.2881, G loss: 4.1947\n",
      "[884/1762] D loss: 0.2945, G loss: 4.8828\n",
      "[964/1762] D loss: 0.3185, G loss: 4.2806\n",
      "[1044/1762] D loss: 0.1976, G loss: 4.4773\n",
      "[1124/1762] D loss: 0.3979, G loss: 4.2149\n",
      "[1204/1762] D loss: 0.4002, G loss: 4.1810\n",
      "[1284/1762] D loss: 0.4358, G loss: 4.3437\n",
      "[1364/1762] D loss: 0.5591, G loss: 4.0946\n",
      "[1444/1762] D loss: 0.1577, G loss: 4.5578\n",
      "[1524/1762] D loss: 0.4873, G loss: 4.2130\n",
      "[1604/1762] D loss: 0.1778, G loss: 4.4605\n",
      "[1684/1762] D loss: 0.5327, G loss: 5.0633\n",
      "[1762/1762] D loss: 0.6295, G loss: 4.4359\n",
      "train error: \n",
      " D loss: 0.383127, G loss: 4.617973, D accuracy: 95.7%, cell accuracy: 94.8%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.360836, G loss: 4.829246, D accuracy: 97.0%, cell accuracy: 94.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3467, G loss: 4.7061\n",
      "[84/1762] D loss: 0.4977, G loss: 4.8080\n",
      "[164/1762] D loss: 0.3887, G loss: 5.3226\n",
      "[244/1762] D loss: 0.3421, G loss: 4.3870\n",
      "[324/1762] D loss: 0.4623, G loss: 4.8199\n",
      "[404/1762] D loss: 0.2625, G loss: 3.9887\n",
      "[484/1762] D loss: 0.4321, G loss: 4.7391\n",
      "[564/1762] D loss: 0.5956, G loss: 5.1057\n",
      "[644/1762] D loss: 0.3107, G loss: 3.5510\n",
      "[724/1762] D loss: 0.7746, G loss: 4.6706\n",
      "[804/1762] D loss: 0.4327, G loss: 4.7909\n",
      "[884/1762] D loss: 0.6922, G loss: 4.6834\n",
      "[964/1762] D loss: 0.4132, G loss: 3.6347\n",
      "[1044/1762] D loss: 0.5531, G loss: 4.8382\n",
      "[1124/1762] D loss: 0.9218, G loss: 4.8507\n",
      "[1204/1762] D loss: 0.7012, G loss: 4.8479\n",
      "[1284/1762] D loss: 0.3153, G loss: 4.0851\n",
      "[1364/1762] D loss: 0.2345, G loss: 4.1441\n",
      "[1444/1762] D loss: 0.2362, G loss: 5.2767\n",
      "[1524/1762] D loss: 0.5425, G loss: 5.3423\n",
      "[1604/1762] D loss: 0.6349, G loss: 4.3317\n",
      "[1684/1762] D loss: 1.1175, G loss: 3.7114\n",
      "[1762/1762] D loss: 0.7777, G loss: 5.3779\n",
      "train error: \n",
      " D loss: 0.536482, G loss: 4.575731, D accuracy: 93.6%, cell accuracy: 94.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.550050, G loss: 4.448972, D accuracy: 94.0%, cell accuracy: 95.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3959, G loss: 5.4982\n",
      "[84/1762] D loss: 0.5305, G loss: 3.4189\n",
      "[164/1762] D loss: 0.3861, G loss: 3.9794\n",
      "[244/1762] D loss: 0.2909, G loss: 3.6568\n",
      "[324/1762] D loss: 0.6824, G loss: 5.2293\n",
      "[404/1762] D loss: 0.3232, G loss: 4.1957\n",
      "[484/1762] D loss: 0.2381, G loss: 4.0993\n",
      "[564/1762] D loss: 0.4016, G loss: 3.9643\n",
      "[644/1762] D loss: 0.5193, G loss: 4.9393\n",
      "[724/1762] D loss: 0.8433, G loss: 4.3595\n",
      "[804/1762] D loss: 0.3676, G loss: 4.7503\n",
      "[884/1762] D loss: 0.4237, G loss: 4.3574\n",
      "[964/1762] D loss: 0.8735, G loss: 3.4995\n",
      "[1044/1762] D loss: 0.5748, G loss: 3.3404\n",
      "[1124/1762] D loss: 0.5092, G loss: 3.7578\n",
      "[1204/1762] D loss: 0.3731, G loss: 4.7415\n",
      "[1284/1762] D loss: 0.5305, G loss: 3.8225\n",
      "[1364/1762] D loss: 0.3873, G loss: 5.5495\n",
      "[1444/1762] D loss: 0.4721, G loss: 3.9883\n",
      "[1524/1762] D loss: 0.4949, G loss: 4.5865\n",
      "[1604/1762] D loss: 0.3076, G loss: 4.8225\n",
      "[1684/1762] D loss: 0.3173, G loss: 4.4229\n",
      "[1762/1762] D loss: 1.1199, G loss: 5.2185\n",
      "train error: \n",
      " D loss: 0.745446, G loss: 4.126114, D accuracy: 84.7%, cell accuracy: 94.5%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.720296, G loss: 4.101903, D accuracy: 84.5%, cell accuracy: 94.5%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7976, G loss: 5.4898\n",
      "[84/1762] D loss: 0.6866, G loss: 3.8743\n",
      "[164/1762] D loss: 0.5700, G loss: 4.5772\n",
      "[244/1762] D loss: 0.6205, G loss: 3.7517\n",
      "[324/1762] D loss: 1.5145, G loss: 3.2806\n",
      "[404/1762] D loss: 1.2454, G loss: 3.5161\n",
      "[484/1762] D loss: 0.7452, G loss: 3.8201\n",
      "[564/1762] D loss: 1.2293, G loss: 3.5918\n",
      "[644/1762] D loss: 0.8779, G loss: 4.3970\n",
      "[724/1762] D loss: 0.8912, G loss: 3.9563\n",
      "[804/1762] D loss: 0.3152, G loss: 4.2645\n",
      "[884/1762] D loss: 0.4971, G loss: 6.1925\n",
      "[964/1762] D loss: 0.8718, G loss: 4.3500\n",
      "[1044/1762] D loss: 0.2558, G loss: 4.5883\n",
      "[1124/1762] D loss: 0.8031, G loss: 4.4314\n",
      "[1204/1762] D loss: 0.3594, G loss: 3.9098\n",
      "[1284/1762] D loss: 1.0008, G loss: 3.8993\n",
      "[1364/1762] D loss: 0.6849, G loss: 3.6014\n",
      "[1444/1762] D loss: 0.6583, G loss: 4.1800\n",
      "[1524/1762] D loss: 0.7804, G loss: 3.4383\n",
      "[1604/1762] D loss: 0.7608, G loss: 4.5148\n",
      "[1684/1762] D loss: 0.5190, G loss: 4.9733\n",
      "[1762/1762] D loss: 0.2179, G loss: 5.3173\n",
      "train error: \n",
      " D loss: 0.657645, G loss: 3.708312, D accuracy: 87.3%, cell accuracy: 95.0%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.654734, G loss: 3.798878, D accuracy: 89.1%, cell accuracy: 95.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6908, G loss: 3.8961\n",
      "[84/1762] D loss: 0.8766, G loss: 3.4937\n",
      "[164/1762] D loss: 0.9506, G loss: 3.3873\n",
      "[244/1762] D loss: 0.6332, G loss: 3.1804\n",
      "[324/1762] D loss: 0.7497, G loss: 3.2965\n",
      "[404/1762] D loss: 0.4638, G loss: 4.6117\n",
      "[484/1762] D loss: 0.5410, G loss: 3.6512\n",
      "[564/1762] D loss: 0.5698, G loss: 3.3908\n",
      "[644/1762] D loss: 0.5001, G loss: 2.8647\n",
      "[724/1762] D loss: 0.7471, G loss: 2.4617\n",
      "[804/1762] D loss: 0.6966, G loss: 3.4929\n",
      "[884/1762] D loss: 0.3841, G loss: 2.6231\n",
      "[964/1762] D loss: 0.4132, G loss: 3.0173\n",
      "[1044/1762] D loss: 0.8158, G loss: 3.7866\n",
      "[1124/1762] D loss: 0.6044, G loss: 3.6135\n",
      "[1204/1762] D loss: 0.6074, G loss: 2.9682\n",
      "[1284/1762] D loss: 0.4774, G loss: 2.7821\n",
      "[1364/1762] D loss: 0.5580, G loss: 2.7762\n",
      "[1444/1762] D loss: 0.7095, G loss: 2.6929\n",
      "[1524/1762] D loss: 0.6232, G loss: 4.5662\n",
      "[1604/1762] D loss: 0.7190, G loss: 2.8146\n",
      "[1684/1762] D loss: 0.2804, G loss: 3.7020\n",
      "[1762/1762] D loss: 0.5071, G loss: 3.8541\n",
      "train error: \n",
      " D loss: 0.586910, G loss: 2.792129, D accuracy: 91.8%, cell accuracy: 95.4%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.622645, G loss: 2.785528, D accuracy: 90.1%, cell accuracy: 95.6%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6142, G loss: 3.1209\n",
      "[84/1762] D loss: 0.8422, G loss: 2.4315\n",
      "[164/1762] D loss: 0.6528, G loss: 2.9305\n",
      "[244/1762] D loss: 0.6423, G loss: 2.6731\n",
      "[324/1762] D loss: 0.5225, G loss: 2.6237\n",
      "[404/1762] D loss: 0.3000, G loss: 2.2577\n",
      "[484/1762] D loss: 0.3815, G loss: 3.0483\n",
      "[564/1762] D loss: 0.2908, G loss: 2.0604\n",
      "[644/1762] D loss: 0.3913, G loss: 2.4008\n",
      "[724/1762] D loss: 0.4798, G loss: 3.3779\n",
      "[804/1762] D loss: 0.7296, G loss: 1.6362\n",
      "[884/1762] D loss: 0.6692, G loss: 2.4695\n",
      "[964/1762] D loss: 0.5334, G loss: 2.0201\n",
      "[1044/1762] D loss: 0.6828, G loss: 1.9179\n",
      "[1124/1762] D loss: 0.4903, G loss: 2.0825\n",
      "[1204/1762] D loss: 0.3831, G loss: 1.9360\n",
      "[1284/1762] D loss: 0.7250, G loss: 1.0219\n",
      "[1364/1762] D loss: 0.4159, G loss: 1.8143\n",
      "[1444/1762] D loss: 1.4603, G loss: 1.6529\n",
      "[1524/1762] D loss: 0.7853, G loss: 1.2131\n",
      "[1604/1762] D loss: 0.8435, G loss: 1.7848\n",
      "[1684/1762] D loss: 0.9149, G loss: 2.1977\n",
      "[1762/1762] D loss: 0.4599, G loss: 3.4236\n",
      "train error: \n",
      " D loss: 0.715128, G loss: 1.476421, D accuracy: 84.9%, cell accuracy: 97.3%, board accuracy: 0.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.743504, G loss: 1.491177, D accuracy: 84.8%, cell accuracy: 97.4%, board accuracy: 0.5% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5872, G loss: 1.1190\n",
      "[84/1762] D loss: 1.0245, G loss: 0.7921\n",
      "[164/1762] D loss: 0.5713, G loss: 1.4810\n",
      "[244/1762] D loss: 0.7224, G loss: 1.5975\n",
      "[324/1762] D loss: 1.9442, G loss: 2.7829\n",
      "[404/1762] D loss: 1.0582, G loss: 2.1773\n",
      "[484/1762] D loss: 0.5445, G loss: 1.6753\n",
      "[564/1762] D loss: 0.8037, G loss: 2.1336\n",
      "[644/1762] D loss: 0.9034, G loss: 1.9614\n",
      "[724/1762] D loss: 0.6219, G loss: 1.4889\n",
      "[804/1762] D loss: 1.0321, G loss: 1.0121\n",
      "[884/1762] D loss: 1.0428, G loss: 0.9373\n",
      "[964/1762] D loss: 1.0240, G loss: 1.0796\n",
      "[1044/1762] D loss: 1.0619, G loss: 0.5348\n",
      "[1124/1762] D loss: 0.8420, G loss: 2.1114\n",
      "[1204/1762] D loss: 0.7463, G loss: 1.5998\n",
      "[1284/1762] D loss: 1.2707, G loss: 0.5610\n",
      "[1364/1762] D loss: 0.6473, G loss: 2.0361\n",
      "[1444/1762] D loss: 0.8128, G loss: 1.6466\n",
      "[1524/1762] D loss: 0.8041, G loss: 1.7187\n",
      "[1604/1762] D loss: 0.8686, G loss: 1.6135\n",
      "[1684/1762] D loss: 1.0010, G loss: 1.8530\n",
      "[1762/1762] D loss: 1.4985, G loss: 2.1964\n",
      "train error: \n",
      " D loss: 0.975521, G loss: 1.576962, D accuracy: 76.9%, cell accuracy: 98.3%, board accuracy: 13.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.984020, G loss: 1.711496, D accuracy: 76.0%, cell accuracy: 98.1%, board accuracy: 10.2% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9217, G loss: 1.4218\n",
      "[84/1762] D loss: 0.9360, G loss: 1.1074\n",
      "[164/1762] D loss: 0.8010, G loss: 0.9167\n",
      "[244/1762] D loss: 1.1195, G loss: 1.5936\n",
      "[324/1762] D loss: 0.9879, G loss: 1.3225\n",
      "[404/1762] D loss: 0.8720, G loss: 1.5724\n",
      "[484/1762] D loss: 1.1025, G loss: 1.4144\n",
      "[564/1762] D loss: 0.4554, G loss: 2.3470\n",
      "[644/1762] D loss: 0.9645, G loss: 2.2042\n",
      "[724/1762] D loss: 1.0190, G loss: 1.5295\n",
      "[804/1762] D loss: 1.4518, G loss: 0.8525\n",
      "[884/1762] D loss: 1.3441, G loss: 0.4453\n",
      "[964/1762] D loss: 1.5420, G loss: 1.1658\n",
      "[1044/1762] D loss: 0.9342, G loss: 1.0936\n",
      "[1124/1762] D loss: 0.9210, G loss: 0.9421\n",
      "[1204/1762] D loss: 1.0787, G loss: 1.1386\n",
      "[1284/1762] D loss: 1.1299, G loss: 0.8951\n",
      "[1364/1762] D loss: 0.8852, G loss: 2.4621\n",
      "[1444/1762] D loss: 1.1119, G loss: 0.7348\n",
      "[1524/1762] D loss: 1.2156, G loss: 1.3575\n",
      "[1604/1762] D loss: 1.1334, G loss: 0.7101\n",
      "[1684/1762] D loss: 0.9129, G loss: 1.2398\n",
      "[1762/1762] D loss: 0.8746, G loss: 1.3695\n",
      "train error: \n",
      " D loss: 1.196814, G loss: 1.375190, D accuracy: 65.6%, cell accuracy: 99.0%, board accuracy: 28.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.222456, G loss: 1.458412, D accuracy: 63.7%, cell accuracy: 98.9%, board accuracy: 26.6% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2790, G loss: 0.9191\n",
      "[84/1762] D loss: 0.9739, G loss: 1.4849\n",
      "[164/1762] D loss: 1.1151, G loss: 0.9582\n",
      "[244/1762] D loss: 0.9061, G loss: 1.6509\n",
      "[324/1762] D loss: 1.3373, G loss: 1.0168\n",
      "[404/1762] D loss: 1.0981, G loss: 1.4393\n",
      "[484/1762] D loss: 1.3253, G loss: 0.5296\n",
      "[564/1762] D loss: 1.3659, G loss: 1.0256\n",
      "[644/1762] D loss: 1.1304, G loss: 0.7799\n",
      "[724/1762] D loss: 1.2009, G loss: 0.5758\n",
      "[804/1762] D loss: 1.3473, G loss: 0.9702\n",
      "[884/1762] D loss: 1.4235, G loss: 0.9371\n",
      "[964/1762] D loss: 1.2013, G loss: 1.0757\n",
      "[1044/1762] D loss: 1.2319, G loss: 0.6083\n",
      "[1124/1762] D loss: 1.1775, G loss: 0.7197\n",
      "[1204/1762] D loss: 1.3722, G loss: 1.8089\n",
      "[1284/1762] D loss: 1.7661, G loss: 1.2433\n",
      "[1364/1762] D loss: 1.5146, G loss: 1.0648\n",
      "[1444/1762] D loss: 1.2527, G loss: 0.8997\n",
      "[1524/1762] D loss: 1.2546, G loss: 0.7344\n",
      "[1604/1762] D loss: 1.7373, G loss: 0.5113\n",
      "[1684/1762] D loss: 1.6972, G loss: 0.9150\n",
      "[1762/1762] D loss: 1.1378, G loss: 0.6251\n",
      "train error: \n",
      " D loss: 1.349677, G loss: 0.640928, D accuracy: 59.6%, cell accuracy: 99.2%, board accuracy: 37.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.344799, G loss: 0.659999, D accuracy: 60.1%, cell accuracy: 99.2%, board accuracy: 35.9% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3773, G loss: 0.5108\n",
      "[84/1762] D loss: 0.9790, G loss: 0.8493\n",
      "[164/1762] D loss: 1.1105, G loss: 0.9714\n",
      "[244/1762] D loss: 1.2456, G loss: 0.7760\n",
      "[324/1762] D loss: 1.5620, G loss: 1.3773\n",
      "[404/1762] D loss: 1.0316, G loss: 0.9574\n",
      "[484/1762] D loss: 1.0492, G loss: 1.2431\n",
      "[564/1762] D loss: 1.2669, G loss: 1.0316\n",
      "[644/1762] D loss: 1.2956, G loss: 0.9545\n",
      "[724/1762] D loss: 1.3612, G loss: 0.7972\n",
      "[804/1762] D loss: 1.1443, G loss: 1.2835\n",
      "[884/1762] D loss: 1.1657, G loss: 0.5596\n",
      "[964/1762] D loss: 1.3422, G loss: 0.8832\n",
      "[1044/1762] D loss: 1.2587, G loss: 0.8784\n",
      "[1124/1762] D loss: 1.4083, G loss: 0.7430\n",
      "[1204/1762] D loss: 1.4851, G loss: 0.9481\n",
      "[1284/1762] D loss: 1.1832, G loss: 0.9893\n",
      "[1364/1762] D loss: 1.0995, G loss: 1.2242\n",
      "[1444/1762] D loss: 1.1809, G loss: 1.5934\n",
      "[1524/1762] D loss: 1.3905, G loss: 1.0387\n",
      "[1604/1762] D loss: 1.1203, G loss: 1.3452\n",
      "[1684/1762] D loss: 1.2511, G loss: 0.8190\n",
      "[1762/1762] D loss: 1.3904, G loss: 0.8764\n",
      "train error: \n",
      " D loss: 1.369492, G loss: 0.994916, D accuracy: 58.1%, cell accuracy: 99.5%, board accuracy: 56.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.386862, G loss: 1.045854, D accuracy: 56.1%, cell accuracy: 99.4%, board accuracy: 53.2% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.6978, G loss: 0.8620\n",
      "[84/1762] D loss: 1.3152, G loss: 0.8427\n",
      "[164/1762] D loss: 1.3608, G loss: 0.7862\n",
      "[244/1762] D loss: 1.3899, G loss: 0.6211\n",
      "[324/1762] D loss: 1.3043, G loss: 0.8953\n",
      "[404/1762] D loss: 1.3708, G loss: 0.7806\n",
      "[484/1762] D loss: 1.5284, G loss: 0.4676\n",
      "[564/1762] D loss: 1.2843, G loss: 0.7082\n",
      "[644/1762] D loss: 1.3781, G loss: 0.5976\n",
      "[724/1762] D loss: 1.2468, G loss: 0.9075\n",
      "[804/1762] D loss: 1.3570, G loss: 0.7194\n",
      "[884/1762] D loss: 1.4916, G loss: 0.6008\n",
      "[964/1762] D loss: 1.3034, G loss: 1.1439\n",
      "[1044/1762] D loss: 1.2144, G loss: 1.1832\n",
      "[1124/1762] D loss: 1.4657, G loss: 0.4551\n",
      "[1204/1762] D loss: 1.2947, G loss: 1.2860\n",
      "[1284/1762] D loss: 1.4354, G loss: 0.5481\n",
      "[1364/1762] D loss: 1.2429, G loss: 0.5496\n",
      "[1444/1762] D loss: 1.1991, G loss: 1.2312\n",
      "[1524/1762] D loss: 1.6835, G loss: 0.6944\n",
      "[1604/1762] D loss: 1.3433, G loss: 0.7469\n",
      "[1684/1762] D loss: 1.6612, G loss: 1.0499\n",
      "[1762/1762] D loss: 1.3402, G loss: 0.6182\n",
      "train error: \n",
      " D loss: 1.504448, G loss: 0.475370, D accuracy: 53.8%, cell accuracy: 99.5%, board accuracy: 58.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.486941, G loss: 0.498277, D accuracy: 53.9%, cell accuracy: 99.5%, board accuracy: 57.5% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4927, G loss: 0.5061\n",
      "[84/1762] D loss: 1.3870, G loss: 0.5331\n",
      "[164/1762] D loss: 1.2636, G loss: 0.7961\n",
      "[244/1762] D loss: 1.5102, G loss: 0.7079\n",
      "[324/1762] D loss: 1.3255, G loss: 0.6183\n",
      "[404/1762] D loss: 1.3673, G loss: 1.0623\n",
      "[484/1762] D loss: 1.5195, G loss: 0.5149\n",
      "[564/1762] D loss: 1.3259, G loss: 0.5259\n",
      "[644/1762] D loss: 1.4379, G loss: 0.9543\n",
      "[724/1762] D loss: 1.3756, G loss: 0.8465\n",
      "[804/1762] D loss: 1.4862, G loss: 1.1404\n",
      "[884/1762] D loss: 1.3822, G loss: 0.8015\n",
      "[964/1762] D loss: 1.4273, G loss: 1.0670\n",
      "[1044/1762] D loss: 1.7078, G loss: 0.5439\n",
      "[1124/1762] D loss: 1.3739, G loss: 0.7593\n",
      "[1204/1762] D loss: 1.3322, G loss: 0.7695\n",
      "[1284/1762] D loss: 1.3631, G loss: 0.7634\n",
      "[1364/1762] D loss: 1.1300, G loss: 0.8203\n",
      "[1444/1762] D loss: 1.3968, G loss: 0.6241\n",
      "[1524/1762] D loss: 1.3745, G loss: 0.7721\n",
      "[1604/1762] D loss: 1.3294, G loss: 0.7412\n",
      "[1684/1762] D loss: 1.3326, G loss: 0.6014\n",
      "[1762/1762] D loss: 1.4348, G loss: 0.4193\n",
      "train error: \n",
      " D loss: 1.427161, G loss: 0.593809, D accuracy: 54.3%, cell accuracy: 99.5%, board accuracy: 60.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.420498, G loss: 0.612244, D accuracy: 54.1%, cell accuracy: 99.5%, board accuracy: 59.5% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4340, G loss: 0.5592\n",
      "[84/1762] D loss: 1.5652, G loss: 0.7339\n",
      "[164/1762] D loss: 1.3936, G loss: 0.8249\n",
      "[244/1762] D loss: 1.3835, G loss: 0.7055\n",
      "[324/1762] D loss: 1.1361, G loss: 0.8896\n",
      "[404/1762] D loss: 1.3172, G loss: 0.5579\n",
      "[484/1762] D loss: 1.4134, G loss: 0.7508\n",
      "[564/1762] D loss: 1.4093, G loss: 0.7029\n",
      "[644/1762] D loss: 1.4911, G loss: 0.5976\n",
      "[724/1762] D loss: 1.3978, G loss: 0.9573\n",
      "[804/1762] D loss: 1.4691, G loss: 0.6664\n",
      "[884/1762] D loss: 1.3991, G loss: 0.8630\n",
      "[964/1762] D loss: 1.3536, G loss: 0.6917\n",
      "[1044/1762] D loss: 1.3642, G loss: 0.8092\n",
      "[1124/1762] D loss: 1.6038, G loss: 0.7427\n",
      "[1204/1762] D loss: 1.3302, G loss: 0.5764\n",
      "[1284/1762] D loss: 1.5347, G loss: 0.8893\n",
      "[1364/1762] D loss: 1.7954, G loss: 1.7246\n",
      "[1444/1762] D loss: 1.3798, G loss: 0.7275\n",
      "[1524/1762] D loss: 1.2140, G loss: 0.8534\n",
      "[1604/1762] D loss: 1.3398, G loss: 0.7050\n",
      "[1684/1762] D loss: 1.2408, G loss: 0.8709\n",
      "[1762/1762] D loss: 1.3609, G loss: 0.5682\n",
      "train error: \n",
      " D loss: 1.395091, G loss: 0.706604, D accuracy: 54.2%, cell accuracy: 99.5%, board accuracy: 60.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.405044, G loss: 0.737598, D accuracy: 54.9%, cell accuracy: 99.5%, board accuracy: 60.2% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3466, G loss: 0.5825\n",
      "[84/1762] D loss: 1.3717, G loss: 0.6372\n",
      "[164/1762] D loss: 1.3555, G loss: 0.6001\n",
      "[244/1762] D loss: 1.4256, G loss: 0.8512\n",
      "[324/1762] D loss: 1.4654, G loss: 0.7844\n",
      "[404/1762] D loss: 1.4031, G loss: 0.7555\n",
      "[484/1762] D loss: 1.5195, G loss: 0.6631\n",
      "[564/1762] D loss: 1.3667, G loss: 0.6162\n",
      "[644/1762] D loss: 1.3982, G loss: 0.7100\n",
      "[724/1762] D loss: 1.4469, G loss: 0.6028\n",
      "[804/1762] D loss: 1.3784, G loss: 0.7581\n",
      "[884/1762] D loss: 1.4388, G loss: 0.8369\n",
      "[964/1762] D loss: 1.7655, G loss: 1.4390\n",
      "[1044/1762] D loss: 1.3680, G loss: 0.5515\n",
      "[1124/1762] D loss: 1.3615, G loss: 0.6676\n",
      "[1204/1762] D loss: 1.2736, G loss: 0.6614\n",
      "[1284/1762] D loss: 1.5840, G loss: 0.8811\n",
      "[1364/1762] D loss: 1.3552, G loss: 0.9250\n",
      "[1444/1762] D loss: 1.4659, G loss: 0.9409\n",
      "[1524/1762] D loss: 1.4720, G loss: 0.6207\n",
      "[1604/1762] D loss: 1.1323, G loss: 0.7549\n",
      "[1684/1762] D loss: 1.5446, G loss: 1.1120\n",
      "[1762/1762] D loss: 1.4172, G loss: 0.6881\n",
      "train error: \n",
      " D loss: 1.376200, G loss: 0.735200, D accuracy: 54.9%, cell accuracy: 99.5%, board accuracy: 59.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.384010, G loss: 0.760376, D accuracy: 56.1%, cell accuracy: 99.5%, board accuracy: 58.4% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4030, G loss: 0.8816\n",
      "[84/1762] D loss: 1.3530, G loss: 0.7040\n",
      "[164/1762] D loss: 1.2769, G loss: 1.0262\n",
      "[244/1762] D loss: 1.3756, G loss: 0.5747\n",
      "[324/1762] D loss: 1.4663, G loss: 0.7476\n",
      "[404/1762] D loss: 1.2903, G loss: 0.7176\n",
      "[484/1762] D loss: 1.3267, G loss: 0.6517\n",
      "[564/1762] D loss: 1.4930, G loss: 1.0162\n",
      "[644/1762] D loss: 1.3847, G loss: 0.4936\n",
      "[724/1762] D loss: 1.5329, G loss: 1.0499\n",
      "[804/1762] D loss: 1.4212, G loss: 0.9308\n",
      "[884/1762] D loss: 1.4463, G loss: 0.9016\n",
      "[964/1762] D loss: 1.3353, G loss: 0.7848\n",
      "[1044/1762] D loss: 1.4269, G loss: 0.8896\n",
      "[1124/1762] D loss: 1.4026, G loss: 0.6814\n",
      "[1204/1762] D loss: 1.3554, G loss: 0.8961\n",
      "[1284/1762] D loss: 1.3912, G loss: 0.6081\n",
      "[1364/1762] D loss: 1.4717, G loss: 0.5498\n",
      "[1444/1762] D loss: 1.2895, G loss: 0.9506\n",
      "[1524/1762] D loss: 1.4097, G loss: 0.8266\n",
      "[1604/1762] D loss: 1.3435, G loss: 0.8028\n",
      "[1684/1762] D loss: 1.4680, G loss: 0.8341\n",
      "[1762/1762] D loss: 1.5442, G loss: 1.1674\n",
      "train error: \n",
      " D loss: 1.356535, G loss: 0.727303, D accuracy: 56.3%, cell accuracy: 99.5%, board accuracy: 57.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.349990, G loss: 0.768302, D accuracy: 57.8%, cell accuracy: 99.4%, board accuracy: 54.1% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3312, G loss: 0.6295\n",
      "[84/1762] D loss: 1.4014, G loss: 0.5224\n",
      "[164/1762] D loss: 1.4104, G loss: 0.8095\n",
      "[244/1762] D loss: 1.4023, G loss: 0.7035\n",
      "[324/1762] D loss: 1.3758, G loss: 0.8626\n",
      "[404/1762] D loss: 1.2932, G loss: 0.7949\n",
      "[484/1762] D loss: 1.3887, G loss: 0.7716\n",
      "[564/1762] D loss: 1.3992, G loss: 0.5143\n",
      "[644/1762] D loss: 1.4036, G loss: 0.8412\n",
      "[724/1762] D loss: 1.4534, G loss: 1.0294\n",
      "[804/1762] D loss: 1.4718, G loss: 0.4469\n",
      "[884/1762] D loss: 1.4327, G loss: 0.7365\n",
      "[964/1762] D loss: 1.3255, G loss: 0.6540\n",
      "[1044/1762] D loss: 1.3227, G loss: 0.8447\n",
      "[1124/1762] D loss: 1.2584, G loss: 0.7137\n",
      "[1204/1762] D loss: 1.5055, G loss: 0.9224\n",
      "[1284/1762] D loss: 1.5369, G loss: 0.7215\n",
      "[1364/1762] D loss: 1.4017, G loss: 0.5951\n",
      "[1444/1762] D loss: 1.3310, G loss: 0.7748\n",
      "[1524/1762] D loss: 1.3465, G loss: 0.8944\n",
      "[1604/1762] D loss: 1.4423, G loss: 0.7180\n",
      "[1684/1762] D loss: 1.3836, G loss: 0.8048\n",
      "[1762/1762] D loss: 1.2736, G loss: 0.7047\n",
      "train error: \n",
      " D loss: 1.408247, G loss: 0.547113, D accuracy: 54.2%, cell accuracy: 99.5%, board accuracy: 60.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.402221, G loss: 0.564949, D accuracy: 55.3%, cell accuracy: 99.4%, board accuracy: 58.4% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1731, G loss: 0.7454\n",
      "[84/1762] D loss: 1.3522, G loss: 0.8072\n",
      "[164/1762] D loss: 1.3792, G loss: 0.6693\n",
      "[244/1762] D loss: 1.5198, G loss: 1.0288\n",
      "[324/1762] D loss: 1.3774, G loss: 0.7775\n",
      "[404/1762] D loss: 1.4079, G loss: 0.9402\n",
      "[484/1762] D loss: 1.3872, G loss: 0.6656\n",
      "[564/1762] D loss: 1.4413, G loss: 0.6192\n",
      "[644/1762] D loss: 1.3948, G loss: 0.7843\n",
      "[724/1762] D loss: 1.3574, G loss: 0.6024\n",
      "[804/1762] D loss: 1.3031, G loss: 0.7842\n",
      "[884/1762] D loss: 1.4024, G loss: 0.6128\n",
      "[964/1762] D loss: 1.1672, G loss: 1.0589\n",
      "[1044/1762] D loss: 1.3375, G loss: 0.7199\n",
      "[1124/1762] D loss: 1.3844, G loss: 0.7899\n",
      "[1204/1762] D loss: 1.4220, G loss: 0.9032\n",
      "[1284/1762] D loss: 1.1098, G loss: 0.8756\n",
      "[1364/1762] D loss: 1.5067, G loss: 0.9958\n",
      "[1444/1762] D loss: 1.3465, G loss: 0.6593\n",
      "[1524/1762] D loss: 1.4117, G loss: 0.7203\n",
      "[1604/1762] D loss: 1.3748, G loss: 0.7142\n",
      "[1684/1762] D loss: 1.4439, G loss: 0.5913\n",
      "[1762/1762] D loss: 1.3246, G loss: 0.7688\n",
      "train error: \n",
      " D loss: 1.355429, G loss: 0.882095, D accuracy: 56.3%, cell accuracy: 99.5%, board accuracy: 59.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.362225, G loss: 0.903682, D accuracy: 55.1%, cell accuracy: 99.5%, board accuracy: 58.0% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4981, G loss: 0.9994\n",
      "[84/1762] D loss: 1.3861, G loss: 0.6705\n",
      "[164/1762] D loss: 1.3309, G loss: 0.6079\n",
      "[244/1762] D loss: 1.1474, G loss: 0.7654\n",
      "[324/1762] D loss: 1.3894, G loss: 0.7171\n",
      "[404/1762] D loss: 1.3638, G loss: 0.6748\n",
      "[484/1762] D loss: 1.3346, G loss: 0.7402\n",
      "[564/1762] D loss: 1.4061, G loss: 0.9634\n",
      "[644/1762] D loss: 1.3465, G loss: 0.7093\n",
      "[724/1762] D loss: 1.3765, G loss: 1.0451\n",
      "[804/1762] D loss: 1.3876, G loss: 0.8590\n",
      "[884/1762] D loss: 1.3495, G loss: 0.8328\n",
      "[964/1762] D loss: 1.3041, G loss: 0.8286\n",
      "[1044/1762] D loss: 1.4111, G loss: 0.6764\n",
      "[1124/1762] D loss: 1.3805, G loss: 0.6345\n",
      "[1204/1762] D loss: 1.4023, G loss: 0.4992\n",
      "[1284/1762] D loss: 1.3387, G loss: 0.7704\n",
      "[1364/1762] D loss: 1.4148, G loss: 0.5547\n",
      "[1444/1762] D loss: 1.4604, G loss: 0.7193\n",
      "[1524/1762] D loss: 1.4412, G loss: 1.0731\n",
      "[1604/1762] D loss: 1.4729, G loss: 0.5046\n",
      "[1684/1762] D loss: 1.3168, G loss: 0.8094\n",
      "[1762/1762] D loss: 1.4205, G loss: 0.7662\n",
      "train error: \n",
      " D loss: 1.360710, G loss: 0.630107, D accuracy: 55.2%, cell accuracy: 99.5%, board accuracy: 60.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.357947, G loss: 0.646186, D accuracy: 55.8%, cell accuracy: 99.5%, board accuracy: 59.1% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3838, G loss: 0.5738\n",
      "[84/1762] D loss: 1.3949, G loss: 0.6942\n",
      "[164/1762] D loss: 1.3912, G loss: 0.7303\n",
      "[244/1762] D loss: 1.4464, G loss: 0.5196\n",
      "[324/1762] D loss: 1.3671, G loss: 0.7081\n",
      "[404/1762] D loss: 1.5403, G loss: 0.5671\n",
      "[484/1762] D loss: 1.3826, G loss: 0.5813\n",
      "[564/1762] D loss: 1.3810, G loss: 0.6428\n",
      "[644/1762] D loss: 1.2840, G loss: 0.8375\n",
      "[724/1762] D loss: 1.3144, G loss: 0.6987\n",
      "[804/1762] D loss: 1.4147, G loss: 0.7424\n",
      "[884/1762] D loss: 1.3562, G loss: 0.9842\n",
      "[964/1762] D loss: 1.2435, G loss: 1.1673\n",
      "[1044/1762] D loss: 1.4535, G loss: 0.4948\n",
      "[1124/1762] D loss: 1.2950, G loss: 0.7257\n",
      "[1204/1762] D loss: 1.3497, G loss: 0.9134\n",
      "[1284/1762] D loss: 1.3791, G loss: 0.7524\n",
      "[1364/1762] D loss: 1.4543, G loss: 0.8169\n",
      "[1444/1762] D loss: 1.3371, G loss: 0.6617\n",
      "[1524/1762] D loss: 1.1813, G loss: 0.9025\n",
      "[1604/1762] D loss: 1.2353, G loss: 1.0069\n",
      "[1684/1762] D loss: 1.1892, G loss: 0.8935\n",
      "[1762/1762] D loss: 1.3819, G loss: 0.8752\n",
      "train error: \n",
      " D loss: 1.450159, G loss: 0.457987, D accuracy: 52.5%, cell accuracy: 99.6%, board accuracy: 62.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.448354, G loss: 0.468965, D accuracy: 52.8%, cell accuracy: 99.5%, board accuracy: 61.1% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4581, G loss: 0.3931\n",
      "[84/1762] D loss: 1.3897, G loss: 0.7020\n",
      "[164/1762] D loss: 1.3975, G loss: 0.5729\n",
      "[244/1762] D loss: 1.2796, G loss: 0.7796\n",
      "[324/1762] D loss: 1.4997, G loss: 0.9286\n",
      "[404/1762] D loss: 1.4868, G loss: 0.9536\n",
      "[484/1762] D loss: 1.4005, G loss: 0.8231\n",
      "[564/1762] D loss: 1.4315, G loss: 0.7593\n",
      "[644/1762] D loss: 1.3236, G loss: 0.6981\n",
      "[724/1762] D loss: 1.3908, G loss: 0.7453\n",
      "[804/1762] D loss: 1.4083, G loss: 0.7138\n",
      "[884/1762] D loss: 1.5190, G loss: 0.7760\n",
      "[964/1762] D loss: 1.4880, G loss: 0.4908\n",
      "[1044/1762] D loss: 1.4155, G loss: 0.6189\n",
      "[1124/1762] D loss: 1.2726, G loss: 0.7713\n",
      "[1204/1762] D loss: 1.3548, G loss: 0.6675\n",
      "[1284/1762] D loss: 1.3369, G loss: 0.8204\n",
      "[1364/1762] D loss: 1.3138, G loss: 0.5573\n",
      "[1444/1762] D loss: 1.3976, G loss: 0.8117\n",
      "[1524/1762] D loss: 1.2281, G loss: 0.9308\n",
      "[1604/1762] D loss: 1.3415, G loss: 0.7548\n",
      "[1684/1762] D loss: 1.4567, G loss: 0.5298\n",
      "[1762/1762] D loss: 1.2071, G loss: 0.7425\n",
      "train error: \n",
      " D loss: 1.345264, G loss: 0.694121, D accuracy: 57.1%, cell accuracy: 99.5%, board accuracy: 62.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.345828, G loss: 0.721366, D accuracy: 56.8%, cell accuracy: 99.5%, board accuracy: 60.5% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2595, G loss: 0.9487\n",
      "[84/1762] D loss: 1.4012, G loss: 0.5414\n",
      "[164/1762] D loss: 1.4373, G loss: 0.5709\n",
      "[244/1762] D loss: 1.4300, G loss: 0.7635\n",
      "[324/1762] D loss: 1.4203, G loss: 0.7614\n",
      "[404/1762] D loss: 1.4216, G loss: 0.5215\n",
      "[484/1762] D loss: 1.3281, G loss: 0.7768\n",
      "[564/1762] D loss: 1.3751, G loss: 0.7880\n",
      "[644/1762] D loss: 1.2895, G loss: 0.7668\n",
      "[724/1762] D loss: 1.3706, G loss: 0.6823\n",
      "[804/1762] D loss: 1.4608, G loss: 0.5734\n",
      "[884/1762] D loss: 1.5298, G loss: 0.5492\n",
      "[964/1762] D loss: 1.4020, G loss: 0.7287\n",
      "[1044/1762] D loss: 1.3056, G loss: 0.6908\n",
      "[1124/1762] D loss: 1.3907, G loss: 0.7855\n",
      "[1204/1762] D loss: 1.2742, G loss: 0.6994\n",
      "[1284/1762] D loss: 1.4387, G loss: 0.5016\n",
      "[1364/1762] D loss: 1.4834, G loss: 0.4679\n",
      "[1444/1762] D loss: 1.4082, G loss: 0.5816\n",
      "[1524/1762] D loss: 1.3384, G loss: 0.8081\n",
      "[1604/1762] D loss: 1.4018, G loss: 0.8097\n",
      "[1684/1762] D loss: 1.4659, G loss: 0.9813\n",
      "[1762/1762] D loss: 1.4071, G loss: 0.7723\n",
      "train error: \n",
      " D loss: 1.342527, G loss: 0.838489, D accuracy: 57.5%, cell accuracy: 99.6%, board accuracy: 70.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.344873, G loss: 0.855369, D accuracy: 56.8%, cell accuracy: 99.6%, board accuracy: 69.5% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3823, G loss: 0.6981\n",
      "[84/1762] D loss: 1.2290, G loss: 0.9912\n",
      "[164/1762] D loss: 1.3696, G loss: 0.8965\n",
      "[244/1762] D loss: 1.4024, G loss: 0.7554\n",
      "[324/1762] D loss: 1.3950, G loss: 0.8404\n",
      "[404/1762] D loss: 1.4492, G loss: 1.0167\n",
      "[484/1762] D loss: 1.4015, G loss: 0.8179\n",
      "[564/1762] D loss: 1.4894, G loss: 0.4771\n",
      "[644/1762] D loss: 1.4007, G loss: 0.6713\n",
      "[724/1762] D loss: 1.3137, G loss: 0.7940\n",
      "[804/1762] D loss: 1.4275, G loss: 0.7801\n",
      "[884/1762] D loss: 1.2393, G loss: 1.0716\n",
      "[964/1762] D loss: 1.4161, G loss: 0.8179\n",
      "[1044/1762] D loss: 1.3931, G loss: 0.6221\n",
      "[1124/1762] D loss: 1.2354, G loss: 0.6673\n",
      "[1204/1762] D loss: 1.1834, G loss: 0.9011\n",
      "[1284/1762] D loss: 1.3997, G loss: 0.7109\n",
      "[1364/1762] D loss: 1.3046, G loss: 0.6855\n",
      "[1444/1762] D loss: 1.3103, G loss: 0.7166\n",
      "[1524/1762] D loss: 1.4178, G loss: 0.5877\n",
      "[1604/1762] D loss: 1.3859, G loss: 0.5469\n",
      "[1684/1762] D loss: 1.3928, G loss: 0.8488\n",
      "[1762/1762] D loss: 1.3649, G loss: 0.6802\n",
      "train error: \n",
      " D loss: 1.351120, G loss: 0.728745, D accuracy: 56.0%, cell accuracy: 99.7%, board accuracy: 74.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.350740, G loss: 0.749293, D accuracy: 56.8%, cell accuracy: 99.6%, board accuracy: 71.4% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4037, G loss: 0.7444\n",
      "[84/1762] D loss: 1.3343, G loss: 0.7524\n",
      "[164/1762] D loss: 1.3840, G loss: 0.6185\n",
      "[244/1762] D loss: 1.2010, G loss: 0.8992\n",
      "[324/1762] D loss: 1.3116, G loss: 0.8346\n",
      "[404/1762] D loss: 1.3420, G loss: 0.7555\n",
      "[484/1762] D loss: 1.4155, G loss: 0.7086\n",
      "[564/1762] D loss: 1.4159, G loss: 0.6782\n",
      "[644/1762] D loss: 1.3690, G loss: 0.8541\n",
      "[724/1762] D loss: 1.3909, G loss: 0.7134\n",
      "[804/1762] D loss: 1.3074, G loss: 0.8567\n",
      "[884/1762] D loss: 1.3942, G loss: 0.7063\n",
      "[964/1762] D loss: 1.2161, G loss: 0.8731\n",
      "[1044/1762] D loss: 1.3910, G loss: 0.9253\n",
      "[1124/1762] D loss: 1.4094, G loss: 0.6712\n",
      "[1204/1762] D loss: 1.4569, G loss: 0.7296\n",
      "[1284/1762] D loss: 1.3424, G loss: 0.6104\n",
      "[1364/1762] D loss: 1.2605, G loss: 0.7622\n",
      "[1444/1762] D loss: 1.4619, G loss: 0.8553\n",
      "[1524/1762] D loss: 1.4050, G loss: 0.7146\n",
      "[1604/1762] D loss: 1.4045, G loss: 0.7748\n",
      "[1684/1762] D loss: 1.2292, G loss: 1.0623\n",
      "[1762/1762] D loss: 1.4027, G loss: 0.7407\n",
      "train error: \n",
      " D loss: 1.361622, G loss: 0.639618, D accuracy: 55.4%, cell accuracy: 99.6%, board accuracy: 73.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.357820, G loss: 0.657452, D accuracy: 55.3%, cell accuracy: 99.6%, board accuracy: 70.7% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3959, G loss: 0.5304\n",
      "[84/1762] D loss: 1.3837, G loss: 0.8495\n",
      "[164/1762] D loss: 1.4083, G loss: 0.7072\n",
      "[244/1762] D loss: 1.3427, G loss: 1.0065\n",
      "[324/1762] D loss: 1.4447, G loss: 0.7358\n",
      "[404/1762] D loss: 1.2961, G loss: 0.6826\n",
      "[484/1762] D loss: 1.3459, G loss: 0.6793\n",
      "[564/1762] D loss: 1.3854, G loss: 0.8020\n",
      "[644/1762] D loss: 1.3970, G loss: 0.8092\n",
      "[724/1762] D loss: 1.3253, G loss: 0.9020\n",
      "[804/1762] D loss: 1.3435, G loss: 0.8082\n",
      "[884/1762] D loss: 1.4315, G loss: 0.5884\n",
      "[964/1762] D loss: 1.1221, G loss: 0.8917\n",
      "[1044/1762] D loss: 1.3940, G loss: 1.0127\n",
      "[1124/1762] D loss: 1.4047, G loss: 0.7928\n",
      "[1204/1762] D loss: 1.1198, G loss: 1.2072\n",
      "[1284/1762] D loss: 1.4462, G loss: 0.8044\n",
      "[1364/1762] D loss: 1.4507, G loss: 1.1492\n",
      "[1444/1762] D loss: 1.3931, G loss: 0.8174\n",
      "[1524/1762] D loss: 1.2377, G loss: 0.7146\n",
      "[1604/1762] D loss: 1.2211, G loss: 0.7519\n",
      "[1684/1762] D loss: 1.3443, G loss: 0.8477\n",
      "[1762/1762] D loss: 1.4945, G loss: 0.4779\n",
      "train error: \n",
      " D loss: 1.346137, G loss: 0.691671, D accuracy: 55.9%, cell accuracy: 99.7%, board accuracy: 77.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.341822, G loss: 0.711895, D accuracy: 56.7%, cell accuracy: 99.7%, board accuracy: 75.9% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4489, G loss: 0.6366\n",
      "[84/1762] D loss: 1.4184, G loss: 0.6337\n",
      "[164/1762] D loss: 1.4193, G loss: 0.6995\n",
      "[244/1762] D loss: 1.3971, G loss: 0.5323\n",
      "[324/1762] D loss: 1.4711, G loss: 0.4616\n",
      "[404/1762] D loss: 1.4175, G loss: 0.5644\n",
      "[484/1762] D loss: 1.2667, G loss: 0.7492\n",
      "[564/1762] D loss: 1.3174, G loss: 0.7715\n",
      "[644/1762] D loss: 1.1954, G loss: 0.9310\n",
      "[724/1762] D loss: 1.4170, G loss: 0.7508\n",
      "[804/1762] D loss: 1.4101, G loss: 0.6702\n",
      "[884/1762] D loss: 1.2147, G loss: 0.8227\n",
      "[964/1762] D loss: 1.3947, G loss: 0.7217\n",
      "[1044/1762] D loss: 1.2910, G loss: 0.7790\n",
      "[1124/1762] D loss: 1.2447, G loss: 0.8000\n",
      "[1204/1762] D loss: 1.2880, G loss: 0.9976\n",
      "[1284/1762] D loss: 1.2980, G loss: 0.8261\n",
      "[1364/1762] D loss: 1.3818, G loss: 0.8086\n",
      "[1444/1762] D loss: 1.4429, G loss: 0.5332\n",
      "[1524/1762] D loss: 1.3154, G loss: 0.5974\n",
      "[1604/1762] D loss: 1.3550, G loss: 0.6525\n",
      "[1684/1762] D loss: 1.3457, G loss: 0.6557\n",
      "[1762/1762] D loss: 0.9138, G loss: 0.9271\n",
      "train error: \n",
      " D loss: 1.371927, G loss: 0.597377, D accuracy: 55.0%, cell accuracy: 99.7%, board accuracy: 75.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.359608, G loss: 0.614951, D accuracy: 55.6%, cell accuracy: 99.7%, board accuracy: 72.3% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3152, G loss: 0.5724\n",
      "[84/1762] D loss: 1.2680, G loss: 0.7047\n",
      "[164/1762] D loss: 1.3350, G loss: 0.8356\n",
      "[244/1762] D loss: 1.1226, G loss: 0.7270\n",
      "[324/1762] D loss: 1.2761, G loss: 0.8260\n",
      "[404/1762] D loss: 1.3202, G loss: 0.7793\n",
      "[484/1762] D loss: 1.3962, G loss: 0.6591\n",
      "[564/1762] D loss: 1.4157, G loss: 0.6587\n",
      "[644/1762] D loss: 1.2945, G loss: 0.7093\n",
      "[724/1762] D loss: 1.3945, G loss: 0.7707\n",
      "[804/1762] D loss: 1.3986, G loss: 0.7038\n",
      "[884/1762] D loss: 1.4241, G loss: 0.5275\n",
      "[964/1762] D loss: 1.3922, G loss: 0.6841\n",
      "[1044/1762] D loss: 1.4144, G loss: 0.7339\n",
      "[1124/1762] D loss: 1.2993, G loss: 0.7200\n",
      "[1204/1762] D loss: 1.4264, G loss: 0.5332\n",
      "[1284/1762] D loss: 1.4895, G loss: 0.5153\n",
      "[1364/1762] D loss: 1.4406, G loss: 0.5808\n",
      "[1444/1762] D loss: 1.4385, G loss: 0.6004\n",
      "[1524/1762] D loss: 1.4220, G loss: 0.5825\n",
      "[1604/1762] D loss: 1.2720, G loss: 0.7602\n",
      "[1684/1762] D loss: 1.4791, G loss: 0.6012\n",
      "[1762/1762] D loss: 1.4549, G loss: 0.4592\n",
      "train error: \n",
      " D loss: 1.410328, G loss: 0.513405, D accuracy: 53.9%, cell accuracy: 99.7%, board accuracy: 81.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.394202, G loss: 0.532908, D accuracy: 55.1%, cell accuracy: 99.7%, board accuracy: 78.0% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4723, G loss: 0.5375\n",
      "[84/1762] D loss: 1.3973, G loss: 0.6122\n",
      "[164/1762] D loss: 1.3978, G loss: 0.6230\n",
      "[244/1762] D loss: 1.3899, G loss: 0.7928\n",
      "[324/1762] D loss: 1.2837, G loss: 0.8620\n",
      "[404/1762] D loss: 1.3597, G loss: 0.6174\n",
      "[484/1762] D loss: 1.3894, G loss: 0.7349\n",
      "[564/1762] D loss: 1.4237, G loss: 0.6509\n",
      "[644/1762] D loss: 1.2205, G loss: 0.8090\n",
      "[724/1762] D loss: 1.4289, G loss: 0.5456\n",
      "[804/1762] D loss: 1.3780, G loss: 0.7740\n",
      "[884/1762] D loss: 1.3935, G loss: 0.7960\n",
      "[964/1762] D loss: 1.3976, G loss: 0.7104\n",
      "[1044/1762] D loss: 1.3926, G loss: 0.8528\n",
      "[1124/1762] D loss: 1.2785, G loss: 0.8294\n",
      "[1204/1762] D loss: 1.3153, G loss: 0.8892\n",
      "[1284/1762] D loss: 1.3845, G loss: 0.6533\n",
      "[1364/1762] D loss: 1.3982, G loss: 0.6471\n",
      "[1444/1762] D loss: 1.4205, G loss: 0.6766\n",
      "[1524/1762] D loss: 1.1627, G loss: 0.8726\n",
      "[1604/1762] D loss: 1.4037, G loss: 0.8434\n",
      "[1684/1762] D loss: 1.3917, G loss: 0.8350\n",
      "[1762/1762] D loss: 1.4128, G loss: 0.7899\n",
      "train error: \n",
      " D loss: 1.348892, G loss: 0.691479, D accuracy: 55.6%, cell accuracy: 99.7%, board accuracy: 81.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.339954, G loss: 0.708200, D accuracy: 56.6%, cell accuracy: 99.7%, board accuracy: 78.2% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1237, G loss: 0.8477\n",
      "[84/1762] D loss: 1.3925, G loss: 0.6556\n",
      "[164/1762] D loss: 1.3915, G loss: 0.6924\n",
      "[244/1762] D loss: 1.3915, G loss: 0.7267\n",
      "[324/1762] D loss: 1.3918, G loss: 0.6670\n",
      "[404/1762] D loss: 1.1737, G loss: 0.9127\n",
      "[484/1762] D loss: 1.5500, G loss: 1.1485\n",
      "[564/1762] D loss: 1.4047, G loss: 0.8143\n",
      "[644/1762] D loss: 1.3308, G loss: 0.6308\n",
      "[724/1762] D loss: 1.3242, G loss: 0.5559\n",
      "[804/1762] D loss: 1.2732, G loss: 0.7643\n",
      "[884/1762] D loss: 1.3719, G loss: 0.7179\n",
      "[964/1762] D loss: 1.4103, G loss: 0.8002\n",
      "[1044/1762] D loss: 1.4178, G loss: 0.8286\n",
      "[1124/1762] D loss: 1.2959, G loss: 0.8532\n",
      "[1204/1762] D loss: 1.3969, G loss: 0.6857\n",
      "[1284/1762] D loss: 1.4432, G loss: 0.8379\n",
      "[1364/1762] D loss: 1.4277, G loss: 0.6342\n",
      "[1444/1762] D loss: 1.2880, G loss: 0.6370\n",
      "[1524/1762] D loss: 1.3770, G loss: 0.6221\n",
      "[1604/1762] D loss: 1.2826, G loss: 0.8350\n",
      "[1684/1762] D loss: 1.3929, G loss: 0.7424\n",
      "[1762/1762] D loss: 1.1227, G loss: 1.0021\n",
      "train error: \n",
      " D loss: 1.342391, G loss: 0.780720, D accuracy: 56.1%, cell accuracy: 99.7%, board accuracy: 78.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.338070, G loss: 0.803181, D accuracy: 56.7%, cell accuracy: 99.6%, board accuracy: 75.5% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3271, G loss: 0.7057\n",
      "[84/1762] D loss: 1.4087, G loss: 0.7536\n",
      "[164/1762] D loss: 1.4824, G loss: 0.9266\n",
      "[244/1762] D loss: 1.3996, G loss: 0.6506\n",
      "[324/1762] D loss: 1.1879, G loss: 0.9139\n",
      "[404/1762] D loss: 1.3210, G loss: 0.6517\n",
      "[484/1762] D loss: 1.3913, G loss: 0.6670\n",
      "[564/1762] D loss: 1.4450, G loss: 1.1333\n",
      "[644/1762] D loss: 1.3866, G loss: 0.6888\n",
      "[724/1762] D loss: 1.3382, G loss: 0.7573\n",
      "[804/1762] D loss: 1.4340, G loss: 0.7234\n",
      "[884/1762] D loss: 1.4077, G loss: 0.7069\n",
      "[964/1762] D loss: 1.4240, G loss: 0.6750\n",
      "[1044/1762] D loss: 1.3300, G loss: 0.7086\n",
      "[1124/1762] D loss: 1.4161, G loss: 0.6379\n",
      "[1204/1762] D loss: 1.2576, G loss: 0.8486\n",
      "[1284/1762] D loss: 1.3088, G loss: 0.7763\n",
      "[1364/1762] D loss: 1.3102, G loss: 0.9247\n",
      "[1444/1762] D loss: 1.1641, G loss: 0.7857\n",
      "[1524/1762] D loss: 1.2756, G loss: 0.7735\n",
      "[1604/1762] D loss: 1.4304, G loss: 0.5407\n",
      "[1684/1762] D loss: 1.4560, G loss: 0.5095\n",
      "[1762/1762] D loss: 1.2616, G loss: 0.7148\n",
      "train error: \n",
      " D loss: 1.388504, G loss: 0.548481, D accuracy: 55.0%, cell accuracy: 99.7%, board accuracy: 81.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.380440, G loss: 0.565685, D accuracy: 55.3%, cell accuracy: 99.7%, board accuracy: 78.2% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3350, G loss: 0.5065\n",
      "[84/1762] D loss: 1.4404, G loss: 0.8442\n",
      "[164/1762] D loss: 1.3983, G loss: 0.6502\n",
      "[244/1762] D loss: 1.3948, G loss: 0.6548\n",
      "[324/1762] D loss: 1.4095, G loss: 0.6228\n",
      "[404/1762] D loss: 1.4136, G loss: 0.5536\n",
      "[484/1762] D loss: 1.4245, G loss: 0.8508\n",
      "[564/1762] D loss: 1.2080, G loss: 0.9267\n",
      "[644/1762] D loss: 1.4354, G loss: 0.8597\n",
      "[724/1762] D loss: 1.3952, G loss: 0.7826\n",
      "[804/1762] D loss: 1.4217, G loss: 0.7074\n",
      "[884/1762] D loss: 1.4766, G loss: 0.6099\n",
      "[964/1762] D loss: 1.4032, G loss: 0.7801\n",
      "[1044/1762] D loss: 1.4123, G loss: 0.7589\n",
      "[1124/1762] D loss: 1.2993, G loss: 0.7412\n",
      "[1204/1762] D loss: 1.4794, G loss: 0.9050\n",
      "[1284/1762] D loss: 1.4603, G loss: 0.8208\n",
      "[1364/1762] D loss: 1.3539, G loss: 0.7837\n",
      "[1444/1762] D loss: 1.4091, G loss: 0.6903\n",
      "[1524/1762] D loss: 1.4461, G loss: 0.9517\n",
      "[1604/1762] D loss: 1.4365, G loss: 0.6491\n",
      "[1684/1762] D loss: 1.3400, G loss: 0.7505\n",
      "[1762/1762] D loss: 1.3909, G loss: 0.6193\n",
      "train error: \n",
      " D loss: 1.338922, G loss: 0.709798, D accuracy: 56.1%, cell accuracy: 99.8%, board accuracy: 82.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.329119, G loss: 0.733624, D accuracy: 57.3%, cell accuracy: 99.7%, board accuracy: 77.5% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3944, G loss: 0.6351\n",
      "[84/1762] D loss: 1.3662, G loss: 0.8032\n",
      "[164/1762] D loss: 1.3875, G loss: 0.6846\n",
      "[244/1762] D loss: 1.3751, G loss: 0.7907\n",
      "[324/1762] D loss: 1.2833, G loss: 0.8526\n",
      "[404/1762] D loss: 1.2795, G loss: 0.6759\n",
      "[484/1762] D loss: 1.3933, G loss: 0.6068\n",
      "[564/1762] D loss: 1.3884, G loss: 0.6405\n",
      "[644/1762] D loss: 1.4082, G loss: 0.6533\n",
      "[724/1762] D loss: 1.3200, G loss: 1.1231\n",
      "[804/1762] D loss: 1.2834, G loss: 1.0602\n",
      "[884/1762] D loss: 1.3869, G loss: 0.7429\n",
      "[964/1762] D loss: 1.4431, G loss: 0.7647\n",
      "[1044/1762] D loss: 1.4177, G loss: 0.5913\n",
      "[1124/1762] D loss: 1.2788, G loss: 0.8415\n",
      "[1204/1762] D loss: 1.1156, G loss: 1.1749\n",
      "[1284/1762] D loss: 1.1726, G loss: 0.7514\n",
      "[1364/1762] D loss: 1.0635, G loss: 0.9631\n",
      "[1444/1762] D loss: 1.2487, G loss: 0.9801\n",
      "[1524/1762] D loss: 1.2398, G loss: 1.0142\n",
      "[1604/1762] D loss: 1.4001, G loss: 0.5884\n",
      "[1684/1762] D loss: 1.1601, G loss: 0.7909\n",
      "[1762/1762] D loss: 1.1950, G loss: 0.9525\n",
      "train error: \n",
      " D loss: 1.343535, G loss: 0.849187, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 83.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.336914, G loss: 0.875163, D accuracy: 55.8%, cell accuracy: 99.7%, board accuracy: 80.5% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3922, G loss: 0.8050\n",
      "[84/1762] D loss: 1.3899, G loss: 0.7982\n",
      "[164/1762] D loss: 1.4050, G loss: 0.7976\n",
      "[244/1762] D loss: 1.2802, G loss: 0.7962\n",
      "[324/1762] D loss: 1.4360, G loss: 0.5714\n",
      "[404/1762] D loss: 1.4074, G loss: 0.5440\n",
      "[484/1762] D loss: 1.2097, G loss: 1.0886\n",
      "[564/1762] D loss: 1.2428, G loss: 0.6382\n",
      "[644/1762] D loss: 1.1412, G loss: 0.9520\n",
      "[724/1762] D loss: 1.5118, G loss: 0.9292\n",
      "[804/1762] D loss: 1.3865, G loss: 0.6997\n",
      "[884/1762] D loss: 1.3895, G loss: 0.8153\n",
      "[964/1762] D loss: 1.3906, G loss: 0.7820\n",
      "[1044/1762] D loss: 1.3971, G loss: 0.7112\n",
      "[1124/1762] D loss: 1.3366, G loss: 1.0939\n",
      "[1204/1762] D loss: 1.2981, G loss: 1.0694\n",
      "[1284/1762] D loss: 1.3948, G loss: 0.8039\n",
      "[1364/1762] D loss: 1.2825, G loss: 0.7439\n",
      "[1444/1762] D loss: 1.2767, G loss: 0.7346\n",
      "[1524/1762] D loss: 1.5196, G loss: 0.5726\n",
      "[1604/1762] D loss: 1.3071, G loss: 0.8107\n",
      "[1684/1762] D loss: 1.3103, G loss: 0.7536\n",
      "[1762/1762] D loss: 1.0420, G loss: 0.9826\n",
      "train error: \n",
      " D loss: 1.319766, G loss: 0.695863, D accuracy: 58.5%, cell accuracy: 99.5%, board accuracy: 59.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.312477, G loss: 0.713873, D accuracy: 59.1%, cell accuracy: 99.4%, board accuracy: 59.8% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3926, G loss: 0.6895\n",
      "[84/1762] D loss: 0.9923, G loss: 0.9459\n",
      "[164/1762] D loss: 1.0480, G loss: 0.9589\n",
      "[244/1762] D loss: 1.4078, G loss: 0.6379\n",
      "[324/1762] D loss: 1.3921, G loss: 0.7724\n",
      "[404/1762] D loss: 1.2413, G loss: 0.9691\n",
      "[484/1762] D loss: 1.0996, G loss: 0.8705\n",
      "[564/1762] D loss: 1.1140, G loss: 0.8983\n",
      "[644/1762] D loss: 1.0992, G loss: 0.9757\n",
      "[724/1762] D loss: 1.3904, G loss: 0.6749\n",
      "[804/1762] D loss: 1.4090, G loss: 0.6401\n",
      "[884/1762] D loss: 1.4223, G loss: 0.8163\n",
      "[964/1762] D loss: 1.3540, G loss: 1.1922\n",
      "[1044/1762] D loss: 1.2779, G loss: 0.8311\n",
      "[1124/1762] D loss: 1.2698, G loss: 0.7659\n",
      "[1204/1762] D loss: 1.1453, G loss: 0.9139\n",
      "[1284/1762] D loss: 1.2126, G loss: 0.9071\n",
      "[1364/1762] D loss: 1.3060, G loss: 0.7219\n",
      "[1444/1762] D loss: 1.4182, G loss: 0.6784\n",
      "[1524/1762] D loss: 1.4208, G loss: 0.6487\n",
      "[1604/1762] D loss: 1.4474, G loss: 0.8564\n",
      "[1684/1762] D loss: 1.4130, G loss: 0.5523\n",
      "[1762/1762] D loss: 1.4507, G loss: 0.5432\n",
      "train error: \n",
      " D loss: 1.338639, G loss: 0.701229, D accuracy: 56.1%, cell accuracy: 99.7%, board accuracy: 76.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.329542, G loss: 0.720679, D accuracy: 56.6%, cell accuracy: 99.6%, board accuracy: 74.3% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4212, G loss: 0.7332\n",
      "[84/1762] D loss: 1.3862, G loss: 0.7199\n",
      "[164/1762] D loss: 1.3974, G loss: 0.6361\n",
      "[244/1762] D loss: 1.3922, G loss: 0.6106\n",
      "[324/1762] D loss: 1.2312, G loss: 0.8022\n",
      "[404/1762] D loss: 1.4223, G loss: 0.8551\n",
      "[484/1762] D loss: 1.2920, G loss: 0.8507\n",
      "[564/1762] D loss: 1.2434, G loss: 0.9567\n",
      "[644/1762] D loss: 1.4370, G loss: 0.6498\n",
      "[724/1762] D loss: 1.3952, G loss: 0.6760\n",
      "[804/1762] D loss: 1.4055, G loss: 0.6873\n",
      "[884/1762] D loss: 1.3943, G loss: 0.5645\n",
      "[964/1762] D loss: 1.4408, G loss: 0.8344\n",
      "[1044/1762] D loss: 1.4421, G loss: 0.8994\n",
      "[1124/1762] D loss: 1.3691, G loss: 0.8558\n",
      "[1204/1762] D loss: 1.2374, G loss: 1.0109\n",
      "[1284/1762] D loss: 1.4279, G loss: 0.6063\n",
      "[1364/1762] D loss: 1.3126, G loss: 0.9116\n",
      "[1444/1762] D loss: 1.3850, G loss: 0.6000\n",
      "[1524/1762] D loss: 1.3489, G loss: 0.6155\n",
      "[1604/1762] D loss: 1.3917, G loss: 0.5874\n",
      "[1684/1762] D loss: 1.4090, G loss: 0.5886\n",
      "[1762/1762] D loss: 1.3913, G loss: 0.6985\n",
      "train error: \n",
      " D loss: 1.355948, G loss: 0.747599, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 84.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.352437, G loss: 0.775383, D accuracy: 54.2%, cell accuracy: 99.7%, board accuracy: 81.1% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3884, G loss: 0.7513\n",
      "[84/1762] D loss: 1.3956, G loss: 0.7562\n",
      "[164/1762] D loss: 1.2278, G loss: 0.8092\n",
      "[244/1762] D loss: 1.3877, G loss: 0.6502\n",
      "[324/1762] D loss: 1.2548, G loss: 0.7118\n",
      "[404/1762] D loss: 1.4346, G loss: 0.6350\n",
      "[484/1762] D loss: 1.4073, G loss: 0.7036\n",
      "[564/1762] D loss: 1.4996, G loss: 0.6120\n",
      "[644/1762] D loss: 1.4100, G loss: 0.8173\n",
      "[724/1762] D loss: 1.2944, G loss: 0.8461\n",
      "[804/1762] D loss: 1.2392, G loss: 0.7197\n",
      "[884/1762] D loss: 0.9247, G loss: 1.0231\n",
      "[964/1762] D loss: 1.4043, G loss: 0.9082\n",
      "[1044/1762] D loss: 1.4052, G loss: 0.7120\n",
      "[1124/1762] D loss: 1.3786, G loss: 0.8799\n",
      "[1204/1762] D loss: 1.2459, G loss: 0.8228\n",
      "[1284/1762] D loss: 1.3365, G loss: 0.7738\n",
      "[1364/1762] D loss: 1.2367, G loss: 0.8611\n",
      "[1444/1762] D loss: 1.4262, G loss: 0.6386\n",
      "[1524/1762] D loss: 1.4233, G loss: 0.7365\n",
      "[1604/1762] D loss: 1.3950, G loss: 0.8241\n",
      "[1684/1762] D loss: 1.5009, G loss: 0.7196\n",
      "[1762/1762] D loss: 1.3894, G loss: 0.7515\n",
      "train error: \n",
      " D loss: 1.358729, G loss: 0.801618, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.352677, G loss: 0.833230, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 83.2% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3815, G loss: 0.7504\n",
      "[84/1762] D loss: 1.2407, G loss: 1.0456\n",
      "[164/1762] D loss: 1.0480, G loss: 0.8682\n",
      "[244/1762] D loss: 1.3967, G loss: 0.6861\n",
      "[324/1762] D loss: 1.4143, G loss: 0.6967\n",
      "[404/1762] D loss: 1.0263, G loss: 1.0673\n",
      "[484/1762] D loss: 1.3884, G loss: 0.6706\n",
      "[564/1762] D loss: 1.2574, G loss: 1.0249\n",
      "[644/1762] D loss: 1.4040, G loss: 0.6131\n",
      "[724/1762] D loss: 1.4484, G loss: 0.7785\n",
      "[804/1762] D loss: 1.4027, G loss: 0.8220\n",
      "[884/1762] D loss: 1.2530, G loss: 0.8234\n",
      "[964/1762] D loss: 1.4120, G loss: 0.8426\n",
      "[1044/1762] D loss: 1.3934, G loss: 0.6585\n",
      "[1124/1762] D loss: 1.3941, G loss: 0.6594\n",
      "[1204/1762] D loss: 1.3846, G loss: 0.6891\n",
      "[1284/1762] D loss: 1.4092, G loss: 0.5730\n",
      "[1364/1762] D loss: 1.3933, G loss: 0.6259\n",
      "[1444/1762] D loss: 1.2877, G loss: 0.7671\n",
      "[1524/1762] D loss: 1.3660, G loss: 0.8004\n",
      "[1604/1762] D loss: 1.3913, G loss: 0.7193\n",
      "[1684/1762] D loss: 1.1517, G loss: 0.9039\n",
      "[1762/1762] D loss: 1.3845, G loss: 0.7234\n",
      "train error: \n",
      " D loss: 1.359989, G loss: 0.713765, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 84.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.357071, G loss: 0.733085, D accuracy: 53.2%, cell accuracy: 99.7%, board accuracy: 79.5% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3952, G loss: 0.6495\n",
      "[84/1762] D loss: 1.3916, G loss: 0.6462\n",
      "[164/1762] D loss: 1.6158, G loss: 0.4864\n",
      "[244/1762] D loss: 1.4551, G loss: 0.6125\n",
      "[324/1762] D loss: 1.2416, G loss: 0.9089\n",
      "[404/1762] D loss: 1.4844, G loss: 0.7410\n",
      "[484/1762] D loss: 1.3790, G loss: 0.7092\n",
      "[564/1762] D loss: 1.3137, G loss: 0.8423\n",
      "[644/1762] D loss: 1.4129, G loss: 0.7298\n",
      "[724/1762] D loss: 1.5720, G loss: 0.6219\n",
      "[804/1762] D loss: 1.2431, G loss: 0.7641\n",
      "[884/1762] D loss: 1.3986, G loss: 0.6174\n",
      "[964/1762] D loss: 1.4238, G loss: 0.5640\n",
      "[1044/1762] D loss: 1.4167, G loss: 0.8473\n",
      "[1124/1762] D loss: 1.2513, G loss: 0.7129\n",
      "[1204/1762] D loss: 1.2388, G loss: 0.8481\n",
      "[1284/1762] D loss: 1.4702, G loss: 0.6722\n",
      "[1364/1762] D loss: 1.3441, G loss: 0.5625\n",
      "[1444/1762] D loss: 1.4673, G loss: 0.6664\n",
      "[1524/1762] D loss: 1.3689, G loss: 0.7948\n",
      "[1604/1762] D loss: 1.4870, G loss: 0.6286\n",
      "[1684/1762] D loss: 1.3888, G loss: 0.6322\n",
      "[1762/1762] D loss: 1.3081, G loss: 0.8229\n",
      "train error: \n",
      " D loss: 1.375076, G loss: 0.664501, D accuracy: 54.4%, cell accuracy: 99.5%, board accuracy: 70.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.371854, G loss: 0.675890, D accuracy: 54.4%, cell accuracy: 99.4%, board accuracy: 64.1% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2649, G loss: 0.7866\n",
      "[84/1762] D loss: 1.2907, G loss: 0.8270\n",
      "[164/1762] D loss: 1.4510, G loss: 0.8824\n",
      "[244/1762] D loss: 1.4170, G loss: 0.7324\n",
      "[324/1762] D loss: 1.4399, G loss: 0.5583\n",
      "[404/1762] D loss: 1.3209, G loss: 0.6295\n",
      "[484/1762] D loss: 1.3938, G loss: 0.6872\n",
      "[564/1762] D loss: 1.3891, G loss: 0.7397\n",
      "[644/1762] D loss: 1.4529, G loss: 0.7531\n",
      "[724/1762] D loss: 1.3971, G loss: 0.7256\n",
      "[804/1762] D loss: 1.3988, G loss: 0.6738\n",
      "[884/1762] D loss: 1.4403, G loss: 0.7512\n",
      "[964/1762] D loss: 1.4327, G loss: 0.7143\n",
      "[1044/1762] D loss: 1.3870, G loss: 0.6578\n",
      "[1124/1762] D loss: 1.2183, G loss: 0.7433\n",
      "[1204/1762] D loss: 1.4121, G loss: 0.6073\n",
      "[1284/1762] D loss: 1.2413, G loss: 0.6776\n",
      "[1364/1762] D loss: 1.4794, G loss: 0.5524\n",
      "[1444/1762] D loss: 1.3854, G loss: 0.6816\n",
      "[1524/1762] D loss: 1.2794, G loss: 0.7177\n",
      "[1604/1762] D loss: 1.3896, G loss: 0.7274\n",
      "[1684/1762] D loss: 1.3923, G loss: 0.6430\n",
      "[1762/1762] D loss: 1.4014, G loss: 0.8302\n",
      "train error: \n",
      " D loss: 1.378923, G loss: 0.800842, D accuracy: 51.8%, cell accuracy: 99.7%, board accuracy: 73.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.374986, G loss: 0.811816, D accuracy: 51.1%, cell accuracy: 99.6%, board accuracy: 67.5% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3657, G loss: 0.7481\n",
      "[84/1762] D loss: 1.3557, G loss: 0.8504\n",
      "[164/1762] D loss: 1.2314, G loss: 0.8385\n",
      "[244/1762] D loss: 1.3457, G loss: 0.6445\n",
      "[324/1762] D loss: 1.3949, G loss: 0.5998\n",
      "[404/1762] D loss: 1.3615, G loss: 0.6685\n",
      "[484/1762] D loss: 1.3298, G loss: 0.5993\n",
      "[564/1762] D loss: 1.3679, G loss: 0.7523\n",
      "[644/1762] D loss: 1.4189, G loss: 0.8751\n",
      "[724/1762] D loss: 1.3918, G loss: 0.6562\n",
      "[804/1762] D loss: 1.3928, G loss: 0.5895\n",
      "[884/1762] D loss: 1.2549, G loss: 0.7255\n",
      "[964/1762] D loss: 1.3989, G loss: 0.7819\n",
      "[1044/1762] D loss: 1.3945, G loss: 0.7833\n",
      "[1124/1762] D loss: 1.3723, G loss: 0.9125\n",
      "[1204/1762] D loss: 1.3860, G loss: 0.7246\n",
      "[1284/1762] D loss: 1.3876, G loss: 0.7576\n",
      "[1364/1762] D loss: 1.2362, G loss: 0.8049\n",
      "[1444/1762] D loss: 1.3934, G loss: 0.7168\n",
      "[1524/1762] D loss: 1.3984, G loss: 0.7308\n",
      "[1604/1762] D loss: 1.4205, G loss: 0.6813\n",
      "[1684/1762] D loss: 1.3358, G loss: 0.7695\n",
      "[1762/1762] D loss: 1.3462, G loss: 0.6624\n",
      "train error: \n",
      " D loss: 1.364980, G loss: 0.697882, D accuracy: 53.9%, cell accuracy: 99.7%, board accuracy: 71.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.363602, G loss: 0.701361, D accuracy: 53.8%, cell accuracy: 99.6%, board accuracy: 65.7% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3994, G loss: 0.6833\n",
      "[84/1762] D loss: 1.3760, G loss: 0.6954\n",
      "[164/1762] D loss: 1.3879, G loss: 0.7004\n",
      "[244/1762] D loss: 1.2542, G loss: 0.7953\n",
      "[324/1762] D loss: 1.2676, G loss: 0.7863\n",
      "[404/1762] D loss: 1.3952, G loss: 0.6289\n",
      "[484/1762] D loss: 1.3984, G loss: 0.6749\n",
      "[564/1762] D loss: 1.3869, G loss: 0.6804\n",
      "[644/1762] D loss: 1.2632, G loss: 0.8082\n",
      "[724/1762] D loss: 1.2674, G loss: 0.7628\n",
      "[804/1762] D loss: 1.4358, G loss: 0.8157\n",
      "[884/1762] D loss: 1.4743, G loss: 0.8553\n",
      "[964/1762] D loss: 1.3913, G loss: 0.6675\n",
      "[1044/1762] D loss: 1.2366, G loss: 0.7789\n",
      "[1124/1762] D loss: 1.4237, G loss: 0.6920\n",
      "[1204/1762] D loss: 1.4143, G loss: 0.7305\n",
      "[1284/1762] D loss: 1.3992, G loss: 0.6175\n",
      "[1364/1762] D loss: 1.4191, G loss: 0.8650\n",
      "[1444/1762] D loss: 1.3980, G loss: 0.8225\n",
      "[1524/1762] D loss: 1.4335, G loss: 0.7289\n",
      "[1604/1762] D loss: 1.4064, G loss: 0.7463\n",
      "[1684/1762] D loss: 1.4029, G loss: 0.8004\n",
      "[1762/1762] D loss: 1.3143, G loss: 0.6866\n",
      "train error: \n",
      " D loss: 1.358432, G loss: 0.669570, D accuracy: 55.4%, cell accuracy: 99.7%, board accuracy: 74.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.350137, G loss: 0.679771, D accuracy: 55.8%, cell accuracy: 99.6%, board accuracy: 67.0% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3395, G loss: 0.6446\n",
      "[84/1762] D loss: 1.2899, G loss: 0.8052\n",
      "[164/1762] D loss: 1.4233, G loss: 0.6079\n",
      "[244/1762] D loss: 1.2977, G loss: 0.6516\n",
      "[324/1762] D loss: 1.3901, G loss: 0.6842\n",
      "[404/1762] D loss: 1.3084, G loss: 0.6442\n",
      "[484/1762] D loss: 1.3966, G loss: 0.7688\n",
      "[564/1762] D loss: 1.4020, G loss: 0.8417\n",
      "[644/1762] D loss: 1.2193, G loss: 0.6970\n",
      "[724/1762] D loss: 1.2812, G loss: 0.6323\n",
      "[804/1762] D loss: 1.2789, G loss: 0.6276\n",
      "[884/1762] D loss: 1.3488, G loss: 0.6472\n",
      "[964/1762] D loss: 1.4045, G loss: 0.6248\n",
      "[1044/1762] D loss: 1.3914, G loss: 0.7476\n",
      "[1124/1762] D loss: 1.3803, G loss: 0.6068\n",
      "[1204/1762] D loss: 1.3883, G loss: 0.7758\n",
      "[1284/1762] D loss: 1.3693, G loss: 0.7523\n",
      "[1364/1762] D loss: 1.3971, G loss: 0.6042\n",
      "[1444/1762] D loss: 1.2859, G loss: 0.7601\n",
      "[1524/1762] D loss: 1.3973, G loss: 0.7261\n",
      "[1604/1762] D loss: 1.3822, G loss: 0.7257\n",
      "[1684/1762] D loss: 1.3782, G loss: 0.6795\n",
      "[1762/1762] D loss: 1.3976, G loss: 0.7224\n",
      "train error: \n",
      " D loss: 1.354969, G loss: 0.842487, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 73.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.345467, G loss: 0.851796, D accuracy: 55.1%, cell accuracy: 99.6%, board accuracy: 69.3% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4031, G loss: 0.7621\n",
      "[84/1762] D loss: 1.3073, G loss: 0.7684\n",
      "[164/1762] D loss: 1.3972, G loss: 0.8236\n",
      "[244/1762] D loss: 1.4348, G loss: 0.9536\n",
      "[324/1762] D loss: 1.3239, G loss: 0.9578\n",
      "[404/1762] D loss: 1.3862, G loss: 0.6973\n",
      "[484/1762] D loss: 1.3568, G loss: 0.6891\n",
      "[564/1762] D loss: 1.3278, G loss: 0.6655\n",
      "[644/1762] D loss: 1.4140, G loss: 0.7930\n",
      "[724/1762] D loss: 1.4026, G loss: 0.6846\n",
      "[804/1762] D loss: 1.2169, G loss: 0.8398\n",
      "[884/1762] D loss: 1.3408, G loss: 0.6387\n",
      "[964/1762] D loss: 0.9933, G loss: 0.8149\n",
      "[1044/1762] D loss: 1.3884, G loss: 0.5914\n",
      "[1124/1762] D loss: 1.3988, G loss: 0.6516\n",
      "[1204/1762] D loss: 1.3698, G loss: 0.7944\n",
      "[1284/1762] D loss: 1.3436, G loss: 0.8054\n",
      "[1364/1762] D loss: 1.3831, G loss: 0.7158\n",
      "[1444/1762] D loss: 1.2972, G loss: 0.7942\n",
      "[1524/1762] D loss: 1.3957, G loss: 0.6946\n",
      "[1604/1762] D loss: 1.3910, G loss: 0.6129\n",
      "[1684/1762] D loss: 1.4438, G loss: 0.5087\n",
      "[1762/1762] D loss: 1.2192, G loss: 0.9061\n",
      "train error: \n",
      " D loss: 1.347406, G loss: 0.651903, D accuracy: 56.9%, cell accuracy: 99.6%, board accuracy: 63.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.336822, G loss: 0.660900, D accuracy: 57.5%, cell accuracy: 99.5%, board accuracy: 59.1% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2988, G loss: 0.9119\n",
      "[84/1762] D loss: 1.3984, G loss: 0.5886\n",
      "[164/1762] D loss: 1.3095, G loss: 0.8569\n",
      "[244/1762] D loss: 1.5588, G loss: 0.9288\n",
      "[324/1762] D loss: 1.3714, G loss: 0.7016\n",
      "[404/1762] D loss: 1.4182, G loss: 0.5709\n",
      "[484/1762] D loss: 1.4060, G loss: 0.7656\n",
      "[564/1762] D loss: 1.2436, G loss: 0.7307\n",
      "[644/1762] D loss: 1.3910, G loss: 0.6522\n",
      "[724/1762] D loss: 1.4165, G loss: 0.5818\n",
      "[804/1762] D loss: 1.3942, G loss: 0.6784\n",
      "[884/1762] D loss: 1.3417, G loss: 0.8829\n",
      "[964/1762] D loss: 1.2247, G loss: 0.7054\n",
      "[1044/1762] D loss: 1.4115, G loss: 0.6707\n",
      "[1124/1762] D loss: 1.4030, G loss: 0.6072\n",
      "[1204/1762] D loss: 1.3993, G loss: 0.7311\n",
      "[1284/1762] D loss: 1.3935, G loss: 0.5924\n",
      "[1364/1762] D loss: 1.4170, G loss: 0.7810\n",
      "[1444/1762] D loss: 1.4307, G loss: 0.7279\n",
      "[1524/1762] D loss: 1.4365, G loss: 0.7195\n",
      "[1604/1762] D loss: 1.3909, G loss: 0.6598\n",
      "[1684/1762] D loss: 1.4028, G loss: 0.8836\n",
      "[1762/1762] D loss: 1.0571, G loss: 1.1530\n",
      "train error: \n",
      " D loss: 1.359193, G loss: 0.814471, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 84.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.347931, G loss: 0.822788, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 82.0% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4679, G loss: 0.8938\n",
      "[84/1762] D loss: 1.1522, G loss: 1.0452\n",
      "[164/1762] D loss: 1.4028, G loss: 0.8274\n",
      "[244/1762] D loss: 1.4088, G loss: 0.6664\n",
      "[324/1762] D loss: 1.3966, G loss: 0.6738\n",
      "[404/1762] D loss: 1.0539, G loss: 1.0684\n",
      "[484/1762] D loss: 1.3914, G loss: 0.6487\n",
      "[564/1762] D loss: 1.4099, G loss: 0.7826\n",
      "[644/1762] D loss: 1.3804, G loss: 0.6697\n",
      "[724/1762] D loss: 1.2584, G loss: 0.7899\n",
      "[804/1762] D loss: 1.3878, G loss: 0.7583\n",
      "[884/1762] D loss: 1.3741, G loss: 0.7768\n",
      "[964/1762] D loss: 1.3960, G loss: 0.8037\n",
      "[1044/1762] D loss: 1.4197, G loss: 0.8107\n",
      "[1124/1762] D loss: 1.4588, G loss: 0.4787\n",
      "[1204/1762] D loss: 1.4079, G loss: 0.5506\n",
      "[1284/1762] D loss: 1.4172, G loss: 0.8115\n",
      "[1364/1762] D loss: 1.4002, G loss: 0.6169\n",
      "[1444/1762] D loss: 1.4219, G loss: 0.8135\n",
      "[1524/1762] D loss: 1.0417, G loss: 0.9266\n",
      "[1604/1762] D loss: 1.2119, G loss: 0.8705\n",
      "[1684/1762] D loss: 1.4076, G loss: 0.8763\n",
      "[1762/1762] D loss: 1.3915, G loss: 0.6469\n",
      "train error: \n",
      " D loss: 1.348884, G loss: 0.689378, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 81.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.329869, G loss: 0.701328, D accuracy: 56.0%, cell accuracy: 99.7%, board accuracy: 79.3% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3818, G loss: 0.7117\n",
      "[84/1762] D loss: 1.4480, G loss: 0.7837\n",
      "[164/1762] D loss: 1.2042, G loss: 0.9077\n",
      "[244/1762] D loss: 1.4205, G loss: 0.6241\n",
      "[324/1762] D loss: 1.4204, G loss: 0.5398\n",
      "[404/1762] D loss: 1.4064, G loss: 0.6460\n",
      "[484/1762] D loss: 1.4247, G loss: 0.8833\n",
      "[564/1762] D loss: 1.3922, G loss: 0.7271\n",
      "[644/1762] D loss: 1.2156, G loss: 0.8111\n",
      "[724/1762] D loss: 1.3919, G loss: 0.7035\n",
      "[804/1762] D loss: 1.3973, G loss: 0.6507\n",
      "[884/1762] D loss: 1.3939, G loss: 0.7308\n",
      "[964/1762] D loss: 1.3883, G loss: 0.7606\n",
      "[1044/1762] D loss: 1.2179, G loss: 0.6568\n",
      "[1124/1762] D loss: 1.3928, G loss: 0.6572\n",
      "[1204/1762] D loss: 1.2260, G loss: 0.6551\n",
      "[1284/1762] D loss: 1.4339, G loss: 0.5444\n",
      "[1364/1762] D loss: 1.3937, G loss: 0.6881\n",
      "[1444/1762] D loss: 1.3851, G loss: 0.7465\n",
      "[1524/1762] D loss: 1.3237, G loss: 0.8412\n",
      "[1604/1762] D loss: 1.4584, G loss: 0.6726\n",
      "[1684/1762] D loss: 1.3999, G loss: 0.8398\n",
      "[1762/1762] D loss: 1.4036, G loss: 0.6874\n",
      "train error: \n",
      " D loss: 1.350563, G loss: 0.656978, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 82.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.341803, G loss: 0.661536, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 79.8% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2055, G loss: 0.8508\n",
      "[84/1762] D loss: 1.4213, G loss: 0.5972\n",
      "[164/1762] D loss: 1.3879, G loss: 0.6208\n",
      "[244/1762] D loss: 1.4047, G loss: 0.7459\n",
      "[324/1762] D loss: 1.3941, G loss: 0.6674\n",
      "[404/1762] D loss: 1.4273, G loss: 0.7342\n",
      "[484/1762] D loss: 1.4016, G loss: 0.7690\n",
      "[564/1762] D loss: 1.4039, G loss: 0.6285\n",
      "[644/1762] D loss: 1.4044, G loss: 0.6396\n",
      "[724/1762] D loss: 1.4133, G loss: 0.9754\n",
      "[804/1762] D loss: 1.4334, G loss: 0.6804\n",
      "[884/1762] D loss: 1.3469, G loss: 0.6651\n",
      "[964/1762] D loss: 1.3871, G loss: 0.6271\n",
      "[1044/1762] D loss: 1.3950, G loss: 0.8502\n",
      "[1124/1762] D loss: 1.3481, G loss: 0.7598\n",
      "[1204/1762] D loss: 1.4159, G loss: 0.5553\n",
      "[1284/1762] D loss: 1.4841, G loss: 0.6009\n",
      "[1364/1762] D loss: 1.4166, G loss: 0.6948\n",
      "[1444/1762] D loss: 1.4463, G loss: 0.5667\n",
      "[1524/1762] D loss: 1.4213, G loss: 0.5986\n",
      "[1604/1762] D loss: 1.2009, G loss: 0.7763\n",
      "[1684/1762] D loss: 1.3978, G loss: 0.6075\n",
      "[1762/1762] D loss: 1.1868, G loss: 0.9768\n",
      "train error: \n",
      " D loss: 1.341618, G loss: 0.741813, D accuracy: 54.6%, cell accuracy: 99.7%, board accuracy: 71.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.330268, G loss: 0.747663, D accuracy: 55.6%, cell accuracy: 99.6%, board accuracy: 65.9% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4266, G loss: 0.6254\n",
      "[84/1762] D loss: 1.4156, G loss: 0.7046\n",
      "[164/1762] D loss: 1.4067, G loss: 0.5039\n",
      "[244/1762] D loss: 1.4374, G loss: 0.8949\n",
      "[324/1762] D loss: 1.3228, G loss: 0.7028\n",
      "[404/1762] D loss: 1.3774, G loss: 0.6741\n",
      "[484/1762] D loss: 1.4303, G loss: 0.8583\n",
      "[564/1762] D loss: 1.3968, G loss: 0.7412\n",
      "[644/1762] D loss: 1.3934, G loss: 0.6583\n",
      "[724/1762] D loss: 1.3065, G loss: 0.6223\n",
      "[804/1762] D loss: 1.3907, G loss: 0.6595\n",
      "[884/1762] D loss: 1.3937, G loss: 0.6590\n",
      "[964/1762] D loss: 1.3881, G loss: 0.7896\n",
      "[1044/1762] D loss: 1.4130, G loss: 0.5922\n",
      "[1124/1762] D loss: 1.2042, G loss: 0.7770\n",
      "[1204/1762] D loss: 1.2035, G loss: 0.7800\n",
      "[1284/1762] D loss: 1.1875, G loss: 0.7244\n",
      "[1364/1762] D loss: 1.3986, G loss: 0.6988\n",
      "[1444/1762] D loss: 1.4081, G loss: 0.8528\n",
      "[1524/1762] D loss: 1.4593, G loss: 0.8269\n",
      "[1604/1762] D loss: 1.4697, G loss: 0.8684\n",
      "[1684/1762] D loss: 1.3956, G loss: 0.7438\n",
      "[1762/1762] D loss: 1.3913, G loss: 0.6790\n",
      "train error: \n",
      " D loss: 1.339774, G loss: 0.760270, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 84.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.327498, G loss: 0.766354, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 82.5% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3923, G loss: 0.8084\n",
      "[84/1762] D loss: 1.1753, G loss: 0.8442\n",
      "[164/1762] D loss: 1.4345, G loss: 0.9363\n",
      "[244/1762] D loss: 1.0254, G loss: 0.9070\n",
      "[324/1762] D loss: 1.4186, G loss: 0.6015\n",
      "[404/1762] D loss: 1.4109, G loss: 0.8425\n",
      "[484/1762] D loss: 1.4201, G loss: 0.8292\n",
      "[564/1762] D loss: 1.4170, G loss: 0.5629\n",
      "[644/1762] D loss: 1.4418, G loss: 0.7235\n",
      "[724/1762] D loss: 1.3959, G loss: 0.6854\n",
      "[804/1762] D loss: 1.4464, G loss: 0.9019\n",
      "[884/1762] D loss: 1.4002, G loss: 0.8435\n",
      "[964/1762] D loss: 1.2193, G loss: 0.6240\n",
      "[1044/1762] D loss: 1.3924, G loss: 0.6961\n",
      "[1124/1762] D loss: 1.3968, G loss: 0.6870\n",
      "[1204/1762] D loss: 1.4261, G loss: 0.5443\n",
      "[1284/1762] D loss: 1.3702, G loss: 0.6070\n",
      "[1364/1762] D loss: 1.3981, G loss: 0.7045\n",
      "[1444/1762] D loss: 1.4652, G loss: 0.8427\n",
      "[1524/1762] D loss: 1.4061, G loss: 0.6174\n",
      "[1604/1762] D loss: 1.3667, G loss: 0.8083\n",
      "[1684/1762] D loss: 1.4252, G loss: 0.8889\n",
      "[1762/1762] D loss: 1.4342, G loss: 0.5276\n",
      "train error: \n",
      " D loss: 1.349784, G loss: 0.637442, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 84.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.337633, G loss: 0.641993, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 82.7% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3957, G loss: 0.6663\n",
      "[84/1762] D loss: 1.3867, G loss: 0.6579\n",
      "[164/1762] D loss: 1.4061, G loss: 0.7574\n",
      "[244/1762] D loss: 1.3952, G loss: 0.6816\n",
      "[324/1762] D loss: 1.1921, G loss: 0.9368\n",
      "[404/1762] D loss: 1.3904, G loss: 0.6810\n",
      "[484/1762] D loss: 1.1952, G loss: 0.7869\n",
      "[564/1762] D loss: 1.1439, G loss: 0.8324\n",
      "[644/1762] D loss: 1.3917, G loss: 0.7527\n",
      "[724/1762] D loss: 1.3939, G loss: 0.7080\n",
      "[804/1762] D loss: 1.3915, G loss: 0.6273\n",
      "[884/1762] D loss: 1.3932, G loss: 0.6583\n",
      "[964/1762] D loss: 1.4292, G loss: 0.7741\n",
      "[1044/1762] D loss: 1.3684, G loss: 0.8390\n",
      "[1124/1762] D loss: 1.3869, G loss: 0.6799\n",
      "[1204/1762] D loss: 1.4305, G loss: 0.8783\n",
      "[1284/1762] D loss: 1.4298, G loss: 0.7783\n",
      "[1364/1762] D loss: 1.3826, G loss: 0.6438\n",
      "[1444/1762] D loss: 1.3889, G loss: 0.6919\n",
      "[1524/1762] D loss: 1.7536, G loss: 0.8344\n",
      "[1604/1762] D loss: 1.4531, G loss: 0.7623\n",
      "[1684/1762] D loss: 1.1335, G loss: 0.8831\n",
      "[1762/1762] D loss: 1.5006, G loss: 0.6365\n",
      "train error: \n",
      " D loss: 1.301415, G loss: 0.759152, D accuracy: 64.4%, cell accuracy: 96.5%, board accuracy: 1.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.303692, G loss: 0.766547, D accuracy: 63.2%, cell accuracy: 96.5%, board accuracy: 1.4% \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1736, G loss: 0.7289\n",
      "[84/1762] D loss: 1.2829, G loss: 0.9508\n",
      "[164/1762] D loss: 1.0951, G loss: 0.8811\n",
      "[244/1762] D loss: 1.0517, G loss: 0.7002\n",
      "[324/1762] D loss: 0.9693, G loss: 0.9451\n",
      "[404/1762] D loss: 1.1391, G loss: 1.1915\n",
      "[484/1762] D loss: 1.4745, G loss: 0.9659\n",
      "[564/1762] D loss: 1.4913, G loss: 0.4228\n",
      "[644/1762] D loss: 1.4548, G loss: 0.9328\n",
      "[724/1762] D loss: 1.4937, G loss: 0.9573\n",
      "[804/1762] D loss: 1.4894, G loss: 1.0806\n",
      "[884/1762] D loss: 1.4195, G loss: 0.5251\n",
      "[964/1762] D loss: 1.4219, G loss: 0.7790\n",
      "[1044/1762] D loss: 1.4092, G loss: 0.7644\n",
      "[1124/1762] D loss: 1.4336, G loss: 0.5615\n",
      "[1204/1762] D loss: 1.3958, G loss: 0.6618\n",
      "[1284/1762] D loss: 1.4078, G loss: 0.8209\n",
      "[1364/1762] D loss: 1.4014, G loss: 0.6861\n",
      "[1444/1762] D loss: 1.4076, G loss: 0.7883\n",
      "[1524/1762] D loss: 1.3987, G loss: 0.7114\n",
      "[1604/1762] D loss: 1.4007, G loss: 0.6408\n",
      "[1684/1762] D loss: 1.4177, G loss: 0.6236\n",
      "[1762/1762] D loss: 1.4084, G loss: 0.8498\n",
      "train error: \n",
      " D loss: 1.400605, G loss: 0.736313, D accuracy: 50.1%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.403808, G loss: 0.745600, D accuracy: 50.0%, cell accuracy: 99.8%, board accuracy: 83.0% \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4060, G loss: 0.6864\n",
      "[84/1762] D loss: 1.3916, G loss: 0.6685\n",
      "[164/1762] D loss: 1.4024, G loss: 0.7365\n",
      "[244/1762] D loss: 1.4081, G loss: 0.6435\n",
      "[324/1762] D loss: 1.4050, G loss: 0.7149\n",
      "[404/1762] D loss: 1.3612, G loss: 0.7620\n",
      "[484/1762] D loss: 1.3891, G loss: 0.6553\n",
      "[564/1762] D loss: 1.4079, G loss: 0.8306\n",
      "[644/1762] D loss: 1.3681, G loss: 0.8215\n",
      "[724/1762] D loss: 1.3994, G loss: 0.7940\n",
      "[804/1762] D loss: 1.3976, G loss: 0.7441\n",
      "[884/1762] D loss: 1.3957, G loss: 0.7085\n",
      "[964/1762] D loss: 1.3920, G loss: 0.6867\n",
      "[1044/1762] D loss: 1.3327, G loss: 0.6494\n",
      "[1124/1762] D loss: 1.3959, G loss: 0.7012\n",
      "[1204/1762] D loss: 1.3966, G loss: 0.6365\n",
      "[1284/1762] D loss: 1.3883, G loss: 0.7048\n",
      "[1364/1762] D loss: 1.3925, G loss: 0.7386\n",
      "[1444/1762] D loss: 1.4094, G loss: 0.6918\n",
      "[1524/1762] D loss: 1.4032, G loss: 0.6448\n",
      "[1604/1762] D loss: 1.3588, G loss: 0.7084\n",
      "[1684/1762] D loss: 1.3945, G loss: 0.6452\n",
      "[1762/1762] D loss: 1.3756, G loss: 0.6359\n",
      "train error: \n",
      " D loss: 1.372440, G loss: 0.702974, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 85.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.368747, G loss: 0.713342, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 83.6% \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3897, G loss: 0.6700\n",
      "[84/1762] D loss: 1.2273, G loss: 0.7069\n",
      "[164/1762] D loss: 1.4202, G loss: 0.8034\n",
      "[244/1762] D loss: 1.4123, G loss: 0.7790\n",
      "[324/1762] D loss: 1.3995, G loss: 0.6498\n",
      "[404/1762] D loss: 1.3928, G loss: 0.7051\n",
      "[484/1762] D loss: 1.3930, G loss: 0.7392\n",
      "[564/1762] D loss: 1.3883, G loss: 0.7603\n",
      "[644/1762] D loss: 1.3562, G loss: 0.6955\n",
      "[724/1762] D loss: 1.3949, G loss: 0.7529\n",
      "[804/1762] D loss: 1.3732, G loss: 0.7027\n",
      "[884/1762] D loss: 1.4075, G loss: 0.7974\n",
      "[964/1762] D loss: 1.3682, G loss: 0.6881\n",
      "[1044/1762] D loss: 1.3276, G loss: 0.7618\n",
      "[1124/1762] D loss: 1.3239, G loss: 0.8529\n",
      "[1204/1762] D loss: 1.4020, G loss: 0.6681\n",
      "[1284/1762] D loss: 1.2203, G loss: 0.7454\n",
      "[1364/1762] D loss: 1.3128, G loss: 0.7404\n",
      "[1444/1762] D loss: 1.4015, G loss: 0.6026\n",
      "[1524/1762] D loss: 1.3964, G loss: 0.6540\n",
      "[1604/1762] D loss: 1.3957, G loss: 0.7626\n",
      "[1684/1762] D loss: 1.3908, G loss: 0.7189\n",
      "[1762/1762] D loss: 1.3817, G loss: 0.6513\n",
      "train error: \n",
      " D loss: 1.359675, G loss: 0.710923, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 88.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.353322, G loss: 0.719146, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4021, G loss: 0.7860\n",
      "[84/1762] D loss: 1.3909, G loss: 0.7843\n",
      "[164/1762] D loss: 1.3883, G loss: 0.7298\n",
      "[244/1762] D loss: 1.2558, G loss: 0.7604\n",
      "[324/1762] D loss: 1.0922, G loss: 0.8278\n",
      "[404/1762] D loss: 1.3798, G loss: 0.5883\n",
      "[484/1762] D loss: 1.3856, G loss: 0.7050\n",
      "[564/1762] D loss: 1.2731, G loss: 0.6847\n",
      "[644/1762] D loss: 1.3575, G loss: 0.6582\n",
      "[724/1762] D loss: 1.4011, G loss: 0.5800\n",
      "[804/1762] D loss: 1.3510, G loss: 0.7716\n",
      "[884/1762] D loss: 1.3550, G loss: 0.7671\n",
      "[964/1762] D loss: 1.2451, G loss: 0.8510\n",
      "[1044/1762] D loss: 1.3875, G loss: 0.7168\n",
      "[1124/1762] D loss: 1.3934, G loss: 0.6925\n",
      "[1204/1762] D loss: 1.4252, G loss: 0.8630\n",
      "[1284/1762] D loss: 1.4009, G loss: 0.7055\n",
      "[1364/1762] D loss: 1.3947, G loss: 0.6357\n",
      "[1444/1762] D loss: 1.3991, G loss: 0.7321\n",
      "[1524/1762] D loss: 1.2234, G loss: 0.8218\n",
      "[1604/1762] D loss: 1.3890, G loss: 0.7362\n",
      "[1684/1762] D loss: 1.4013, G loss: 0.7438\n",
      "[1762/1762] D loss: 1.3972, G loss: 0.6195\n",
      "train error: \n",
      " D loss: 1.345783, G loss: 0.740557, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 87.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.334822, G loss: 0.751324, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 84.8% \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3939, G loss: 0.7511\n",
      "[84/1762] D loss: 1.2712, G loss: 0.8089\n",
      "[164/1762] D loss: 1.3911, G loss: 0.7037\n",
      "[244/1762] D loss: 1.3978, G loss: 0.5982\n",
      "[324/1762] D loss: 1.3939, G loss: 0.5985\n",
      "[404/1762] D loss: 1.3910, G loss: 0.6836\n",
      "[484/1762] D loss: 1.3446, G loss: 0.7577\n",
      "[564/1762] D loss: 1.1968, G loss: 0.8550\n",
      "[644/1762] D loss: 1.3968, G loss: 0.6682\n",
      "[724/1762] D loss: 1.4044, G loss: 0.6973\n",
      "[804/1762] D loss: 1.4598, G loss: 0.4892\n",
      "[884/1762] D loss: 1.3882, G loss: 0.7042\n",
      "[964/1762] D loss: 1.0161, G loss: 0.9152\n",
      "[1044/1762] D loss: 1.3924, G loss: 0.6829\n",
      "[1124/1762] D loss: 1.3913, G loss: 0.6993\n",
      "[1204/1762] D loss: 1.4028, G loss: 0.5876\n",
      "[1284/1762] D loss: 1.1905, G loss: 0.8286\n",
      "[1364/1762] D loss: 1.3272, G loss: 0.9204\n",
      "[1444/1762] D loss: 1.3927, G loss: 0.7600\n",
      "[1524/1762] D loss: 1.3364, G loss: 0.7509\n",
      "[1604/1762] D loss: 1.4309, G loss: 0.8685\n",
      "[1684/1762] D loss: 1.2632, G loss: 0.8029\n",
      "[1762/1762] D loss: 1.3905, G loss: 0.7615\n",
      "train error: \n",
      " D loss: 1.340086, G loss: 0.780952, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 87.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.328068, G loss: 0.793225, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 84.5% \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3898, G loss: 0.7294\n",
      "[84/1762] D loss: 1.4360, G loss: 0.8065\n",
      "[164/1762] D loss: 1.3191, G loss: 0.9926\n",
      "[244/1762] D loss: 1.1735, G loss: 0.8601\n",
      "[324/1762] D loss: 1.3914, G loss: 0.7291\n",
      "[404/1762] D loss: 1.3928, G loss: 0.6499\n",
      "[484/1762] D loss: 1.3097, G loss: 0.6903\n",
      "[564/1762] D loss: 1.3925, G loss: 0.7448\n",
      "[644/1762] D loss: 1.4015, G loss: 0.7319\n",
      "[724/1762] D loss: 1.2974, G loss: 0.9735\n",
      "[804/1762] D loss: 1.1775, G loss: 0.7166\n",
      "[884/1762] D loss: 1.2023, G loss: 0.7320\n",
      "[964/1762] D loss: 1.3964, G loss: 0.6868\n",
      "[1044/1762] D loss: 1.3978, G loss: 0.6044\n",
      "[1124/1762] D loss: 1.3925, G loss: 0.5841\n",
      "[1204/1762] D loss: 1.4059, G loss: 0.6091\n",
      "[1284/1762] D loss: 1.2625, G loss: 0.8615\n",
      "[1364/1762] D loss: 1.3891, G loss: 0.7083\n",
      "[1444/1762] D loss: 1.3794, G loss: 0.9248\n",
      "[1524/1762] D loss: 1.3764, G loss: 0.6795\n",
      "[1604/1762] D loss: 1.4020, G loss: 0.6046\n",
      "[1684/1762] D loss: 1.3952, G loss: 0.5845\n",
      "[1762/1762] D loss: 1.3883, G loss: 0.6908\n",
      "train error: \n",
      " D loss: 1.335259, G loss: 0.785653, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 82.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.321967, G loss: 0.798007, D accuracy: 53.9%, cell accuracy: 99.7%, board accuracy: 78.2% \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2596, G loss: 0.8387\n",
      "[84/1762] D loss: 1.2320, G loss: 0.8135\n",
      "[164/1762] D loss: 1.4214, G loss: 0.7476\n",
      "[244/1762] D loss: 1.7488, G loss: 0.4569\n",
      "[324/1762] D loss: 1.1572, G loss: 0.8332\n",
      "[404/1762] D loss: 1.2241, G loss: 0.7147\n",
      "[484/1762] D loss: 1.1019, G loss: 1.0648\n",
      "[564/1762] D loss: 1.4596, G loss: 0.7498\n",
      "[644/1762] D loss: 1.3807, G loss: 0.8232\n",
      "[724/1762] D loss: 1.3939, G loss: 0.8066\n",
      "[804/1762] D loss: 1.3749, G loss: 0.6996\n",
      "[884/1762] D loss: 1.2872, G loss: 0.8715\n",
      "[964/1762] D loss: 1.3081, G loss: 0.6541\n",
      "[1044/1762] D loss: 1.2990, G loss: 0.6421\n",
      "[1124/1762] D loss: 1.3941, G loss: 0.8128\n",
      "[1204/1762] D loss: 1.3867, G loss: 0.7056\n",
      "[1284/1762] D loss: 1.3882, G loss: 0.7449\n",
      "[1364/1762] D loss: 1.3924, G loss: 0.7199\n",
      "[1444/1762] D loss: 1.4649, G loss: 0.6091\n",
      "[1524/1762] D loss: 1.4090, G loss: 0.6683\n",
      "[1604/1762] D loss: 1.3566, G loss: 0.9137\n",
      "[1684/1762] D loss: 1.3879, G loss: 0.6144\n",
      "[1762/1762] D loss: 1.3357, G loss: 0.7639\n",
      "train error: \n",
      " D loss: 1.353881, G loss: 0.708076, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 85.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.343587, G loss: 0.717810, D accuracy: 55.7%, cell accuracy: 99.8%, board accuracy: 84.8% \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3086, G loss: 0.7336\n",
      "[84/1762] D loss: 1.3914, G loss: 0.7024\n",
      "[164/1762] D loss: 1.4015, G loss: 0.6331\n",
      "[244/1762] D loss: 1.3386, G loss: 0.7085\n",
      "[324/1762] D loss: 1.4499, G loss: 0.6017\n",
      "[404/1762] D loss: 1.3483, G loss: 0.6853\n",
      "[484/1762] D loss: 1.2208, G loss: 0.7336\n",
      "[564/1762] D loss: 1.3994, G loss: 0.8094\n",
      "[644/1762] D loss: 1.3651, G loss: 0.7602\n",
      "[724/1762] D loss: 1.3904, G loss: 0.6973\n",
      "[804/1762] D loss: 1.3964, G loss: 0.7856\n",
      "[884/1762] D loss: 1.2415, G loss: 0.7854\n",
      "[964/1762] D loss: 1.3904, G loss: 0.6996\n",
      "[1044/1762] D loss: 1.4115, G loss: 0.6584\n",
      "[1124/1762] D loss: 1.4026, G loss: 0.6459\n",
      "[1204/1762] D loss: 1.4191, G loss: 0.8042\n",
      "[1284/1762] D loss: 1.3998, G loss: 0.6453\n",
      "[1364/1762] D loss: 1.3715, G loss: 0.7029\n",
      "[1444/1762] D loss: 1.3880, G loss: 0.6784\n",
      "[1524/1762] D loss: 1.4087, G loss: 0.8483\n",
      "[1604/1762] D loss: 1.0400, G loss: 0.8823\n",
      "[1684/1762] D loss: 1.3904, G loss: 0.6392\n",
      "[1762/1762] D loss: 1.0069, G loss: 0.7944\n",
      "train error: \n",
      " D loss: 1.336558, G loss: 0.735070, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 85.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.321555, G loss: 0.744471, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 83.0% \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3966, G loss: 0.7414\n",
      "[84/1762] D loss: 1.3673, G loss: 0.7440\n",
      "[164/1762] D loss: 1.3890, G loss: 0.6408\n",
      "[244/1762] D loss: 1.3875, G loss: 0.7274\n",
      "[324/1762] D loss: 1.1861, G loss: 0.7843\n",
      "[404/1762] D loss: 1.3901, G loss: 0.6653\n",
      "[484/1762] D loss: 1.3921, G loss: 0.7088\n",
      "[564/1762] D loss: 1.4167, G loss: 0.6216\n",
      "[644/1762] D loss: 1.3949, G loss: 0.6365\n",
      "[724/1762] D loss: 1.3891, G loss: 0.6909\n",
      "[804/1762] D loss: 1.4125, G loss: 0.7069\n",
      "[884/1762] D loss: 1.4012, G loss: 0.6937\n",
      "[964/1762] D loss: 1.3569, G loss: 0.6610\n",
      "[1044/1762] D loss: 1.1554, G loss: 0.8776\n",
      "[1124/1762] D loss: 1.2547, G loss: 0.7746\n",
      "[1204/1762] D loss: 1.2190, G loss: 0.7535\n",
      "[1284/1762] D loss: 1.3606, G loss: 0.7361\n",
      "[1364/1762] D loss: 1.1753, G loss: 0.9038\n",
      "[1444/1762] D loss: 1.4142, G loss: 0.7837\n",
      "[1524/1762] D loss: 1.3925, G loss: 0.6640\n",
      "[1604/1762] D loss: 1.3899, G loss: 0.6365\n",
      "[1684/1762] D loss: 1.2284, G loss: 1.0738\n",
      "[1762/1762] D loss: 1.4053, G loss: 0.7735\n",
      "train error: \n",
      " D loss: 1.338435, G loss: 0.811792, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 85.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.322435, G loss: 0.823039, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 83.4% \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2472, G loss: 0.8156\n",
      "[84/1762] D loss: 1.3925, G loss: 0.7528\n",
      "[164/1762] D loss: 1.3993, G loss: 0.6619\n",
      "[244/1762] D loss: 1.3901, G loss: 0.7087\n",
      "[324/1762] D loss: 1.4080, G loss: 0.7911\n",
      "[404/1762] D loss: 1.1915, G loss: 0.8726\n",
      "[484/1762] D loss: 1.3919, G loss: 0.7674\n",
      "[564/1762] D loss: 1.3940, G loss: 0.7447\n",
      "[644/1762] D loss: 1.3874, G loss: 0.7276\n",
      "[724/1762] D loss: 1.4440, G loss: 0.9642\n",
      "[804/1762] D loss: 1.2574, G loss: 0.7423\n",
      "[884/1762] D loss: 1.4141, G loss: 0.7709\n",
      "[964/1762] D loss: 1.3783, G loss: 0.7918\n",
      "[1044/1762] D loss: 1.4010, G loss: 0.7003\n",
      "[1124/1762] D loss: 1.3929, G loss: 0.7481\n",
      "[1204/1762] D loss: 1.1318, G loss: 0.8616\n",
      "[1284/1762] D loss: 1.3898, G loss: 0.7039\n",
      "[1364/1762] D loss: 1.4073, G loss: 0.8152\n",
      "[1444/1762] D loss: 1.4005, G loss: 0.6815\n",
      "[1524/1762] D loss: 1.3924, G loss: 0.7720\n",
      "[1604/1762] D loss: 1.3817, G loss: 0.8525\n",
      "[1684/1762] D loss: 1.1980, G loss: 0.6346\n",
      "[1762/1762] D loss: 1.3938, G loss: 0.7180\n",
      "train error: \n",
      " D loss: 1.332031, G loss: 0.717103, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 83.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.315674, G loss: 0.728758, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 77.7% \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3995, G loss: 0.6282\n",
      "[84/1762] D loss: 1.4104, G loss: 0.8719\n",
      "[164/1762] D loss: 1.3469, G loss: 0.8284\n",
      "[244/1762] D loss: 1.4149, G loss: 0.5859\n",
      "[324/1762] D loss: 1.3884, G loss: 0.6751\n",
      "[404/1762] D loss: 1.3905, G loss: 0.6367\n",
      "[484/1762] D loss: 1.3911, G loss: 0.7565\n",
      "[564/1762] D loss: 1.3882, G loss: 0.6735\n",
      "[644/1762] D loss: 1.3897, G loss: 0.6143\n",
      "[724/1762] D loss: 1.2104, G loss: 0.8386\n",
      "[804/1762] D loss: 0.9641, G loss: 1.1112\n",
      "[884/1762] D loss: 1.1853, G loss: 0.9743\n",
      "[964/1762] D loss: 1.4230, G loss: 0.5098\n",
      "[1044/1762] D loss: 0.9501, G loss: 0.8151\n",
      "[1124/1762] D loss: 1.3986, G loss: 0.6774\n",
      "[1204/1762] D loss: 1.4192, G loss: 0.6577\n",
      "[1284/1762] D loss: 1.3907, G loss: 0.7138\n",
      "[1364/1762] D loss: 1.3858, G loss: 0.6744\n",
      "[1444/1762] D loss: 1.4026, G loss: 0.6482\n",
      "[1524/1762] D loss: 1.3953, G loss: 0.6225\n",
      "[1604/1762] D loss: 1.3788, G loss: 0.7918\n",
      "[1684/1762] D loss: 1.3919, G loss: 0.7172\n",
      "[1762/1762] D loss: 1.3967, G loss: 0.6012\n",
      "train error: \n",
      " D loss: 1.333395, G loss: 0.667162, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 80.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.318396, G loss: 0.674827, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 78.6% \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3813, G loss: 0.6661\n",
      "[84/1762] D loss: 1.4417, G loss: 0.8410\n",
      "[164/1762] D loss: 1.3956, G loss: 0.7586\n",
      "[244/1762] D loss: 1.3925, G loss: 0.6268\n",
      "[324/1762] D loss: 1.3913, G loss: 0.6923\n",
      "[404/1762] D loss: 1.1399, G loss: 0.8520\n",
      "[484/1762] D loss: 0.9608, G loss: 0.8425\n",
      "[564/1762] D loss: 1.1600, G loss: 0.7565\n",
      "[644/1762] D loss: 1.4063, G loss: 0.6333\n",
      "[724/1762] D loss: 1.3976, G loss: 0.6613\n",
      "[804/1762] D loss: 1.3822, G loss: 0.6702\n",
      "[884/1762] D loss: 1.4110, G loss: 0.7541\n",
      "[964/1762] D loss: 1.4217, G loss: 0.8938\n",
      "[1044/1762] D loss: 1.3869, G loss: 0.7041\n",
      "[1124/1762] D loss: 1.3924, G loss: 0.7075\n",
      "[1204/1762] D loss: 1.5220, G loss: 0.7144\n",
      "[1284/1762] D loss: 1.3539, G loss: 0.7972\n",
      "[1364/1762] D loss: 1.2280, G loss: 0.6795\n",
      "[1444/1762] D loss: 1.3626, G loss: 0.5843\n",
      "[1524/1762] D loss: 1.4600, G loss: 0.8455\n",
      "[1604/1762] D loss: 1.4481, G loss: 0.6456\n",
      "[1684/1762] D loss: 1.3944, G loss: 0.6202\n",
      "[1762/1762] D loss: 1.4265, G loss: 0.9007\n",
      "train error: \n",
      " D loss: 1.384004, G loss: 0.869026, D accuracy: 53.0%, cell accuracy: 99.8%, board accuracy: 80.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.375043, G loss: 0.884775, D accuracy: 53.4%, cell accuracy: 99.7%, board accuracy: 74.1% \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3656, G loss: 0.8927\n",
      "[84/1762] D loss: 1.3647, G loss: 0.8040\n",
      "[164/1762] D loss: 1.2979, G loss: 0.8549\n",
      "[244/1762] D loss: 1.3754, G loss: 0.6061\n",
      "[324/1762] D loss: 1.6033, G loss: 0.9222\n",
      "[404/1762] D loss: 1.6049, G loss: 0.6437\n",
      "[484/1762] D loss: 1.4526, G loss: 0.7680\n",
      "[564/1762] D loss: 1.5031, G loss: 0.9807\n",
      "[644/1762] D loss: 1.1938, G loss: 0.7750\n",
      "[724/1762] D loss: 1.0978, G loss: 0.7503\n",
      "[804/1762] D loss: 1.1245, G loss: 0.7313\n",
      "[884/1762] D loss: 1.3918, G loss: 0.7080\n",
      "[964/1762] D loss: 1.4636, G loss: 0.6286\n",
      "[1044/1762] D loss: 1.5474, G loss: 0.6915\n",
      "[1124/1762] D loss: 1.4174, G loss: 0.8238\n",
      "[1204/1762] D loss: 1.4244, G loss: 0.6027\n",
      "[1284/1762] D loss: 1.4109, G loss: 0.7946\n",
      "[1364/1762] D loss: 1.4072, G loss: 0.6364\n",
      "[1444/1762] D loss: 1.3242, G loss: 0.7109\n",
      "[1524/1762] D loss: 1.3960, G loss: 0.5987\n",
      "[1604/1762] D loss: 1.4056, G loss: 0.7976\n",
      "[1684/1762] D loss: 1.4004, G loss: 0.7093\n",
      "[1762/1762] D loss: 1.3872, G loss: 0.6714\n",
      "train error: \n",
      " D loss: 1.378488, G loss: 0.727914, D accuracy: 52.6%, cell accuracy: 99.8%, board accuracy: 81.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.379431, G loss: 0.738326, D accuracy: 53.1%, cell accuracy: 99.7%, board accuracy: 78.6% \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3664, G loss: 0.7764\n",
      "[84/1762] D loss: 1.3476, G loss: 0.9134\n",
      "[164/1762] D loss: 1.3894, G loss: 0.6962\n",
      "[244/1762] D loss: 1.3907, G loss: 0.7536\n",
      "[324/1762] D loss: 1.3892, G loss: 0.6428\n",
      "[404/1762] D loss: 1.3878, G loss: 0.7232\n",
      "[484/1762] D loss: 1.3359, G loss: 0.6884\n",
      "[564/1762] D loss: 1.3894, G loss: 0.7360\n",
      "[644/1762] D loss: 1.3464, G loss: 0.7124\n",
      "[724/1762] D loss: 1.3927, G loss: 0.6386\n",
      "[804/1762] D loss: 1.2929, G loss: 0.6880\n",
      "[884/1762] D loss: 1.3970, G loss: 0.7078\n",
      "[964/1762] D loss: 1.1457, G loss: 0.7491\n",
      "[1044/1762] D loss: 1.4585, G loss: 0.7145\n",
      "[1124/1762] D loss: 1.3896, G loss: 0.7097\n",
      "[1204/1762] D loss: 1.3976, G loss: 0.7823\n",
      "[1284/1762] D loss: 1.3952, G loss: 0.6328\n",
      "[1364/1762] D loss: 1.3888, G loss: 0.6746\n",
      "[1444/1762] D loss: 1.3318, G loss: 0.7710\n",
      "[1524/1762] D loss: 1.3888, G loss: 0.7357\n",
      "[1604/1762] D loss: 1.3921, G loss: 0.6491\n",
      "[1684/1762] D loss: 1.3899, G loss: 0.6612\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6964\n",
      "train error: \n",
      " D loss: 1.352560, G loss: 0.712469, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 84.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.344648, G loss: 0.723742, D accuracy: 54.9%, cell accuracy: 99.7%, board accuracy: 80.7% \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2226, G loss: 0.7871\n",
      "[84/1762] D loss: 1.4004, G loss: 0.6029\n",
      "[164/1762] D loss: 1.3970, G loss: 0.7541\n",
      "[244/1762] D loss: 1.4097, G loss: 0.7942\n",
      "[324/1762] D loss: 1.3895, G loss: 0.7869\n",
      "[404/1762] D loss: 1.3956, G loss: 0.6818\n",
      "[484/1762] D loss: 1.3964, G loss: 0.7261\n",
      "[564/1762] D loss: 1.0322, G loss: 0.8887\n",
      "[644/1762] D loss: 1.3944, G loss: 0.6930\n",
      "[724/1762] D loss: 1.3981, G loss: 0.7672\n",
      "[804/1762] D loss: 1.2671, G loss: 0.7909\n",
      "[884/1762] D loss: 1.3878, G loss: 0.6602\n",
      "[964/1762] D loss: 1.2381, G loss: 0.7893\n",
      "[1044/1762] D loss: 1.3903, G loss: 0.6821\n",
      "[1124/1762] D loss: 1.3908, G loss: 0.7195\n",
      "[1204/1762] D loss: 1.3959, G loss: 0.6628\n",
      "[1284/1762] D loss: 1.3972, G loss: 0.6514\n",
      "[1364/1762] D loss: 1.1938, G loss: 0.7705\n",
      "[1444/1762] D loss: 1.3884, G loss: 0.6708\n",
      "[1524/1762] D loss: 1.4014, G loss: 0.8192\n",
      "[1604/1762] D loss: 1.2015, G loss: 0.7319\n",
      "[1684/1762] D loss: 1.3903, G loss: 0.6865\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6794\n",
      "train error: \n",
      " D loss: 1.340054, G loss: 0.716624, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 86.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.327685, G loss: 0.727908, D accuracy: 55.7%, cell accuracy: 99.8%, board accuracy: 83.4% \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3893, G loss: 0.7069\n",
      "[84/1762] D loss: 1.2004, G loss: 0.8038\n",
      "[164/1762] D loss: 1.2223, G loss: 0.7276\n",
      "[244/1762] D loss: 1.4079, G loss: 0.6361\n",
      "[324/1762] D loss: 1.3910, G loss: 0.6372\n",
      "[404/1762] D loss: 1.3723, G loss: 0.8010\n",
      "[484/1762] D loss: 1.3649, G loss: 0.7040\n",
      "[564/1762] D loss: 1.3995, G loss: 0.6704\n",
      "[644/1762] D loss: 1.4026, G loss: 0.7874\n",
      "[724/1762] D loss: 1.3869, G loss: 0.6851\n",
      "[804/1762] D loss: 1.3165, G loss: 0.7989\n",
      "[884/1762] D loss: 1.5263, G loss: 0.6650\n",
      "[964/1762] D loss: 1.4222, G loss: 0.8510\n",
      "[1044/1762] D loss: 1.4029, G loss: 0.8988\n",
      "[1124/1762] D loss: 1.5594, G loss: 0.5830\n",
      "[1204/1762] D loss: 2.0105, G loss: 0.4501\n",
      "[1284/1762] D loss: 1.4358, G loss: 0.7977\n",
      "[1364/1762] D loss: 1.1793, G loss: 0.8399\n",
      "[1444/1762] D loss: 0.9155, G loss: 0.9793\n",
      "[1524/1762] D loss: 0.8745, G loss: 1.1762\n",
      "[1604/1762] D loss: 1.5809, G loss: 0.7876\n",
      "[1684/1762] D loss: 1.5374, G loss: 1.1805\n",
      "[1762/1762] D loss: 1.4818, G loss: 0.4524\n",
      "train error: \n",
      " D loss: 1.560069, G loss: 0.514097, D accuracy: 48.4%, cell accuracy: 99.8%, board accuracy: 81.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.566613, G loss: 0.530547, D accuracy: 48.4%, cell accuracy: 99.7%, board accuracy: 78.2% \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5267, G loss: 0.4387\n",
      "[84/1762] D loss: 1.8172, G loss: 1.3881\n",
      "[164/1762] D loss: 1.4097, G loss: 0.7145\n",
      "[244/1762] D loss: 1.4054, G loss: 0.6130\n",
      "[324/1762] D loss: 1.5249, G loss: 0.6535\n",
      "[404/1762] D loss: 1.3858, G loss: 0.7068\n",
      "[484/1762] D loss: 1.4179, G loss: 0.8049\n",
      "[564/1762] D loss: 1.4149, G loss: 0.7865\n",
      "[644/1762] D loss: 1.4046, G loss: 0.6106\n",
      "[724/1762] D loss: 1.3890, G loss: 0.7252\n",
      "[804/1762] D loss: 1.4026, G loss: 0.7203\n",
      "[884/1762] D loss: 1.3966, G loss: 0.6586\n",
      "[964/1762] D loss: 1.3909, G loss: 0.7402\n",
      "[1044/1762] D loss: 1.4240, G loss: 0.7047\n",
      "[1124/1762] D loss: 1.4749, G loss: 0.7068\n",
      "[1204/1762] D loss: 1.3928, G loss: 0.7519\n",
      "[1284/1762] D loss: 1.3858, G loss: 0.6422\n",
      "[1364/1762] D loss: 1.3936, G loss: 0.6409\n",
      "[1444/1762] D loss: 1.3894, G loss: 0.6846\n",
      "[1524/1762] D loss: 1.3982, G loss: 0.6820\n",
      "[1604/1762] D loss: 1.3847, G loss: 0.7071\n",
      "[1684/1762] D loss: 1.3885, G loss: 0.7339\n",
      "[1762/1762] D loss: 1.3932, G loss: 0.7112\n",
      "train error: \n",
      " D loss: 1.393225, G loss: 0.722667, D accuracy: 50.6%, cell accuracy: 99.8%, board accuracy: 88.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.398290, G loss: 0.728782, D accuracy: 49.5%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3702, G loss: 0.7091\n",
      "[84/1762] D loss: 1.3397, G loss: 0.7117\n",
      "[164/1762] D loss: 1.4830, G loss: 0.7575\n",
      "[244/1762] D loss: 1.3906, G loss: 0.7116\n",
      "[324/1762] D loss: 1.3900, G loss: 0.7360\n",
      "[404/1762] D loss: 1.3893, G loss: 0.7240\n",
      "[484/1762] D loss: 1.3707, G loss: 0.6381\n",
      "[564/1762] D loss: 1.4259, G loss: 0.7171\n",
      "[644/1762] D loss: 1.4809, G loss: 0.7569\n",
      "[724/1762] D loss: 1.3883, G loss: 0.7010\n",
      "[804/1762] D loss: 1.3894, G loss: 0.6694\n",
      "[884/1762] D loss: 1.3903, G loss: 0.6982\n",
      "[964/1762] D loss: 1.3872, G loss: 0.6916\n",
      "[1044/1762] D loss: 1.3668, G loss: 0.6178\n",
      "[1124/1762] D loss: 1.3941, G loss: 0.7779\n",
      "[1204/1762] D loss: 1.3878, G loss: 0.6656\n",
      "[1284/1762] D loss: 1.4016, G loss: 0.6913\n",
      "[1364/1762] D loss: 1.3941, G loss: 0.6399\n",
      "[1444/1762] D loss: 1.3990, G loss: 0.7474\n",
      "[1524/1762] D loss: 1.3942, G loss: 0.7570\n",
      "[1604/1762] D loss: 1.3393, G loss: 0.7112\n",
      "[1684/1762] D loss: 1.3325, G loss: 0.7577\n",
      "[1762/1762] D loss: 1.3880, G loss: 0.6922\n",
      "train error: \n",
      " D loss: 1.374962, G loss: 0.713532, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.374167, G loss: 0.720220, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3889, G loss: 0.7365\n",
      "[84/1762] D loss: 1.3965, G loss: 0.7137\n",
      "[164/1762] D loss: 1.3816, G loss: 0.6981\n",
      "[244/1762] D loss: 1.3253, G loss: 0.7182\n",
      "[324/1762] D loss: 1.3248, G loss: 0.8281\n",
      "[404/1762] D loss: 1.3935, G loss: 0.6426\n",
      "[484/1762] D loss: 1.3909, G loss: 0.7022\n",
      "[564/1762] D loss: 1.3893, G loss: 0.6667\n",
      "[644/1762] D loss: 1.3070, G loss: 0.7493\n",
      "[724/1762] D loss: 1.3031, G loss: 0.7163\n",
      "[804/1762] D loss: 1.3911, G loss: 0.7157\n",
      "[884/1762] D loss: 1.3103, G loss: 0.7044\n",
      "[964/1762] D loss: 1.2980, G loss: 0.8209\n",
      "[1044/1762] D loss: 1.2916, G loss: 0.7801\n",
      "[1124/1762] D loss: 1.3948, G loss: 0.6416\n",
      "[1204/1762] D loss: 1.2930, G loss: 0.7463\n",
      "[1284/1762] D loss: 1.3898, G loss: 0.6468\n",
      "[1364/1762] D loss: 1.3878, G loss: 0.7255\n",
      "[1444/1762] D loss: 1.3962, G loss: 0.7578\n",
      "[1524/1762] D loss: 1.3872, G loss: 0.7133\n",
      "[1604/1762] D loss: 1.3939, G loss: 0.6716\n",
      "[1684/1762] D loss: 1.3878, G loss: 0.7309\n",
      "[1762/1762] D loss: 1.3862, G loss: 0.6753\n",
      "train error: \n",
      " D loss: 1.360508, G loss: 0.687090, D accuracy: 54.3%, cell accuracy: 99.7%, board accuracy: 77.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.353541, G loss: 0.692599, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 74.8% \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2763, G loss: 0.6845\n",
      "[84/1762] D loss: 1.3692, G loss: 0.8193\n",
      "[164/1762] D loss: 1.4162, G loss: 0.5849\n",
      "[244/1762] D loss: 1.3882, G loss: 0.6707\n",
      "[324/1762] D loss: 1.4171, G loss: 0.6254\n",
      "[404/1762] D loss: 1.3953, G loss: 0.6651\n",
      "[484/1762] D loss: 1.3886, G loss: 0.7128\n",
      "[564/1762] D loss: 1.3868, G loss: 0.6968\n",
      "[644/1762] D loss: 1.3898, G loss: 0.6571\n",
      "[724/1762] D loss: 1.3869, G loss: 0.7062\n",
      "[804/1762] D loss: 1.3984, G loss: 0.5889\n",
      "[884/1762] D loss: 1.3778, G loss: 0.6819\n",
      "[964/1762] D loss: 1.3929, G loss: 0.7152\n",
      "[1044/1762] D loss: 1.3907, G loss: 0.7136\n",
      "[1124/1762] D loss: 1.3947, G loss: 0.6137\n",
      "[1204/1762] D loss: 1.2482, G loss: 0.8932\n",
      "[1284/1762] D loss: 1.3812, G loss: 0.7385\n",
      "[1364/1762] D loss: 1.2684, G loss: 0.7453\n",
      "[1444/1762] D loss: 1.3882, G loss: 0.6899\n",
      "[1524/1762] D loss: 1.3896, G loss: 0.6931\n",
      "[1604/1762] D loss: 1.4022, G loss: 0.6495\n",
      "[1684/1762] D loss: 1.3948, G loss: 0.7126\n",
      "[1762/1762] D loss: 1.3947, G loss: 0.8171\n",
      "train error: \n",
      " D loss: 1.353247, G loss: 0.802071, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.342235, G loss: 0.811486, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3959, G loss: 0.7913\n",
      "[84/1762] D loss: 1.3965, G loss: 0.7449\n",
      "[164/1762] D loss: 1.2502, G loss: 0.8453\n",
      "[244/1762] D loss: 1.3945, G loss: 0.6515\n",
      "[324/1762] D loss: 1.3873, G loss: 0.6701\n",
      "[404/1762] D loss: 1.3966, G loss: 0.7948\n",
      "[484/1762] D loss: 1.3912, G loss: 0.6579\n",
      "[564/1762] D loss: 1.4005, G loss: 0.6350\n",
      "[644/1762] D loss: 1.3935, G loss: 0.6521\n",
      "[724/1762] D loss: 1.3732, G loss: 0.7911\n",
      "[804/1762] D loss: 1.1943, G loss: 0.7607\n",
      "[884/1762] D loss: 1.3883, G loss: 0.6579\n",
      "[964/1762] D loss: 1.3872, G loss: 0.7018\n",
      "[1044/1762] D loss: 1.4133, G loss: 0.7843\n",
      "[1124/1762] D loss: 1.4038, G loss: 0.8003\n",
      "[1204/1762] D loss: 1.3937, G loss: 0.6266\n",
      "[1284/1762] D loss: 1.3878, G loss: 0.7198\n",
      "[1364/1762] D loss: 1.3957, G loss: 0.6725\n",
      "[1444/1762] D loss: 1.3884, G loss: 0.7491\n",
      "[1524/1762] D loss: 1.3981, G loss: 0.6725\n",
      "[1604/1762] D loss: 1.2084, G loss: 0.7804\n",
      "[1684/1762] D loss: 1.4238, G loss: 0.8767\n",
      "[1762/1762] D loss: 1.3892, G loss: 0.7870\n",
      "train error: \n",
      " D loss: 1.338698, G loss: 0.773107, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.325598, G loss: 0.779544, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 83.6% \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1815, G loss: 0.8723\n",
      "[84/1762] D loss: 1.3958, G loss: 0.6660\n",
      "[164/1762] D loss: 1.1800, G loss: 0.7665\n",
      "[244/1762] D loss: 1.4036, G loss: 0.6182\n",
      "[324/1762] D loss: 1.4843, G loss: 0.6620\n",
      "[404/1762] D loss: 1.5337, G loss: 0.9213\n",
      "[484/1762] D loss: 1.3285, G loss: 0.5198\n",
      "[564/1762] D loss: 1.3910, G loss: 0.5834\n",
      "[644/1762] D loss: 1.4172, G loss: 0.7975\n",
      "[724/1762] D loss: 1.4050, G loss: 0.7641\n",
      "[804/1762] D loss: 1.4141, G loss: 0.8180\n",
      "[884/1762] D loss: 1.4602, G loss: 0.8783\n",
      "[964/1762] D loss: 1.3872, G loss: 0.7370\n",
      "[1044/1762] D loss: 1.3937, G loss: 0.7790\n",
      "[1124/1762] D loss: 1.3813, G loss: 0.7331\n",
      "[1204/1762] D loss: 1.3883, G loss: 0.6305\n",
      "[1284/1762] D loss: 1.3936, G loss: 0.7100\n",
      "[1364/1762] D loss: 1.3901, G loss: 0.7471\n",
      "[1444/1762] D loss: 1.2317, G loss: 0.8313\n",
      "[1524/1762] D loss: 1.4398, G loss: 0.9116\n",
      "[1604/1762] D loss: 1.3873, G loss: 0.6440\n",
      "[1684/1762] D loss: 1.4303, G loss: 0.9394\n",
      "[1762/1762] D loss: 1.5103, G loss: 0.6058\n",
      "train error: \n",
      " D loss: 1.330054, G loss: 0.704706, D accuracy: 56.9%, cell accuracy: 99.4%, board accuracy: 56.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.319136, G loss: 0.709143, D accuracy: 57.6%, cell accuracy: 99.3%, board accuracy: 55.7% \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3645, G loss: 0.7481\n",
      "[84/1762] D loss: 1.3738, G loss: 0.6696\n",
      "[164/1762] D loss: 1.3894, G loss: 0.7367\n",
      "[244/1762] D loss: 1.3720, G loss: 0.7738\n",
      "[324/1762] D loss: 1.0497, G loss: 0.9609\n",
      "[404/1762] D loss: 1.3876, G loss: 0.6719\n",
      "[484/1762] D loss: 1.2352, G loss: 0.7229\n",
      "[564/1762] D loss: 1.3962, G loss: 0.7345\n",
      "[644/1762] D loss: 1.2247, G loss: 0.7144\n",
      "[724/1762] D loss: 1.3840, G loss: 0.7368\n",
      "[804/1762] D loss: 1.1931, G loss: 0.7282\n",
      "[884/1762] D loss: 1.2017, G loss: 0.9001\n",
      "[964/1762] D loss: 1.2144, G loss: 0.7718\n",
      "[1044/1762] D loss: 1.3933, G loss: 0.6484\n",
      "[1124/1762] D loss: 1.3884, G loss: 0.7341\n",
      "[1204/1762] D loss: 1.3900, G loss: 0.6949\n",
      "[1284/1762] D loss: 1.1929, G loss: 0.8515\n",
      "[1364/1762] D loss: 1.3900, G loss: 0.6841\n",
      "[1444/1762] D loss: 1.3910, G loss: 0.6961\n",
      "[1524/1762] D loss: 1.3873, G loss: 0.6714\n",
      "[1604/1762] D loss: 1.2968, G loss: 1.0034\n",
      "[1684/1762] D loss: 1.3944, G loss: 0.7348\n",
      "[1762/1762] D loss: 1.3889, G loss: 0.6945\n",
      "train error: \n",
      " D loss: 1.332095, G loss: 0.692892, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.318539, G loss: 0.696159, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3895, G loss: 0.6584\n",
      "[84/1762] D loss: 1.3964, G loss: 0.7919\n",
      "[164/1762] D loss: 1.3896, G loss: 0.6945\n",
      "[244/1762] D loss: 1.3883, G loss: 0.6901\n",
      "[324/1762] D loss: 1.1833, G loss: 0.7732\n",
      "[404/1762] D loss: 1.3925, G loss: 0.7359\n",
      "[484/1762] D loss: 1.1696, G loss: 0.7990\n",
      "[564/1762] D loss: 1.4000, G loss: 0.7630\n",
      "[644/1762] D loss: 1.3837, G loss: 0.7557\n",
      "[724/1762] D loss: 1.4185, G loss: 0.5724\n",
      "[804/1762] D loss: 1.4051, G loss: 0.7033\n",
      "[884/1762] D loss: 1.3895, G loss: 0.7326\n",
      "[964/1762] D loss: 1.3979, G loss: 0.6307\n",
      "[1044/1762] D loss: 1.4011, G loss: 0.7780\n",
      "[1124/1762] D loss: 1.3927, G loss: 0.7319\n",
      "[1204/1762] D loss: 1.3996, G loss: 0.6915\n",
      "[1284/1762] D loss: 1.3857, G loss: 0.6198\n",
      "[1364/1762] D loss: 1.4228, G loss: 0.8943\n",
      "[1444/1762] D loss: 1.1994, G loss: 0.6626\n",
      "[1524/1762] D loss: 1.4078, G loss: 0.7156\n",
      "[1604/1762] D loss: 1.1722, G loss: 0.9165\n",
      "[1684/1762] D loss: 1.3849, G loss: 0.6378\n",
      "[1762/1762] D loss: 1.4129, G loss: 0.8300\n",
      "train error: \n",
      " D loss: 1.325986, G loss: 0.781017, D accuracy: 54.4%, cell accuracy: 99.6%, board accuracy: 72.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.307873, G loss: 0.786461, D accuracy: 55.5%, cell accuracy: 99.5%, board accuracy: 69.1% \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1645, G loss: 0.8413\n",
      "[84/1762] D loss: 1.3878, G loss: 0.6619\n",
      "[164/1762] D loss: 1.3763, G loss: 0.8134\n",
      "[244/1762] D loss: 1.3904, G loss: 0.6728\n",
      "[324/1762] D loss: 1.3873, G loss: 0.6438\n",
      "[404/1762] D loss: 1.4069, G loss: 0.8714\n",
      "[484/1762] D loss: 1.3526, G loss: 0.8002\n",
      "[564/1762] D loss: 1.3916, G loss: 0.6341\n",
      "[644/1762] D loss: 0.9376, G loss: 0.9623\n",
      "[724/1762] D loss: 1.1926, G loss: 0.7364\n",
      "[804/1762] D loss: 1.1533, G loss: 0.8036\n",
      "[884/1762] D loss: 1.3866, G loss: 0.6557\n",
      "[964/1762] D loss: 1.3792, G loss: 0.7126\n",
      "[1044/1762] D loss: 1.3925, G loss: 0.6436\n",
      "[1124/1762] D loss: 1.3868, G loss: 0.7234\n",
      "[1204/1762] D loss: 1.4105, G loss: 0.5437\n",
      "[1284/1762] D loss: 1.1652, G loss: 0.8280\n",
      "[1364/1762] D loss: 1.4033, G loss: 0.7102\n",
      "[1444/1762] D loss: 1.3675, G loss: 0.7973\n",
      "[1524/1762] D loss: 0.9340, G loss: 0.8757\n",
      "[1604/1762] D loss: 1.1932, G loss: 1.0107\n",
      "[1684/1762] D loss: 1.4000, G loss: 0.7481\n",
      "[1762/1762] D loss: 1.3837, G loss: 0.6551\n",
      "train error: \n",
      " D loss: 1.324124, G loss: 0.699512, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 78.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.307622, G loss: 0.703257, D accuracy: 56.0%, cell accuracy: 99.6%, board accuracy: 75.7% \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.7158\n",
      "[84/1762] D loss: 1.3649, G loss: 0.7867\n",
      "[164/1762] D loss: 1.1556, G loss: 0.8618\n",
      "[244/1762] D loss: 1.3380, G loss: 0.6526\n",
      "[324/1762] D loss: 1.3905, G loss: 0.7252\n",
      "[404/1762] D loss: 1.3987, G loss: 0.6208\n",
      "[484/1762] D loss: 1.4044, G loss: 0.7471\n",
      "[564/1762] D loss: 1.3947, G loss: 0.7365\n",
      "[644/1762] D loss: 1.3998, G loss: 0.7423\n",
      "[724/1762] D loss: 1.3995, G loss: 0.6204\n",
      "[804/1762] D loss: 1.1275, G loss: 0.8996\n",
      "[884/1762] D loss: 1.3768, G loss: 0.6508\n",
      "[964/1762] D loss: 0.9675, G loss: 0.8311\n",
      "[1044/1762] D loss: 1.1621, G loss: 0.7955\n",
      "[1124/1762] D loss: 1.3917, G loss: 0.6907\n",
      "[1204/1762] D loss: 1.3952, G loss: 0.6020\n",
      "[1284/1762] D loss: 1.4534, G loss: 0.9183\n",
      "[1364/1762] D loss: 1.1422, G loss: 0.8780\n",
      "[1444/1762] D loss: 1.4197, G loss: 0.8397\n",
      "[1524/1762] D loss: 1.3899, G loss: 0.7203\n",
      "[1604/1762] D loss: 1.1711, G loss: 0.7292\n",
      "[1684/1762] D loss: 1.3495, G loss: 0.6942\n",
      "[1762/1762] D loss: 1.3904, G loss: 0.7217\n",
      "train error: \n",
      " D loss: 1.322754, G loss: 0.805049, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 82.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.306193, G loss: 0.807660, D accuracy: 55.0%, cell accuracy: 99.7%, board accuracy: 81.4% \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3946, G loss: 0.7251\n",
      "[84/1762] D loss: 1.1550, G loss: 0.8894\n",
      "[164/1762] D loss: 1.3907, G loss: 0.6880\n",
      "[244/1762] D loss: 1.4057, G loss: 0.7689\n",
      "[324/1762] D loss: 1.3148, G loss: 0.7230\n",
      "[404/1762] D loss: 1.3964, G loss: 0.7805\n",
      "[484/1762] D loss: 1.3796, G loss: 0.6236\n",
      "[564/1762] D loss: 1.3986, G loss: 0.7056\n",
      "[644/1762] D loss: 1.1613, G loss: 0.8771\n",
      "[724/1762] D loss: 1.3793, G loss: 0.5952\n",
      "[804/1762] D loss: 1.3959, G loss: 0.8039\n",
      "[884/1762] D loss: 1.3786, G loss: 0.6554\n",
      "[964/1762] D loss: 1.3266, G loss: 0.7402\n",
      "[1044/1762] D loss: 1.3834, G loss: 0.6966\n",
      "[1124/1762] D loss: 1.3927, G loss: 0.5895\n",
      "[1204/1762] D loss: 1.1679, G loss: 0.7841\n",
      "[1284/1762] D loss: 1.1560, G loss: 0.9171\n",
      "[1364/1762] D loss: 1.1399, G loss: 0.8083\n",
      "[1444/1762] D loss: 1.4153, G loss: 0.8625\n",
      "[1524/1762] D loss: 1.3970, G loss: 0.6448\n",
      "[1604/1762] D loss: 1.3872, G loss: 0.6999\n",
      "[1684/1762] D loss: 1.3956, G loss: 0.7369\n",
      "[1762/1762] D loss: 1.3965, G loss: 0.6783\n",
      "train error: \n",
      " D loss: 1.334283, G loss: 0.663232, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 84.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.314934, G loss: 0.675217, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 83.9% \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1980, G loss: 0.6537\n",
      "[84/1762] D loss: 1.3929, G loss: 0.7338\n",
      "[164/1762] D loss: 1.1665, G loss: 0.7496\n",
      "[244/1762] D loss: 1.3999, G loss: 0.6415\n",
      "[324/1762] D loss: 1.1547, G loss: 0.8106\n",
      "[404/1762] D loss: 1.3879, G loss: 0.6743\n",
      "[484/1762] D loss: 1.3973, G loss: 0.7021\n",
      "[564/1762] D loss: 1.1741, G loss: 0.9332\n",
      "[644/1762] D loss: 1.1842, G loss: 0.7106\n",
      "[724/1762] D loss: 1.3969, G loss: 0.5992\n",
      "[804/1762] D loss: 1.3927, G loss: 0.6502\n",
      "[884/1762] D loss: 1.1542, G loss: 0.8498\n",
      "[964/1762] D loss: 1.3960, G loss: 0.6559\n",
      "[1044/1762] D loss: 1.3914, G loss: 0.6582\n",
      "[1124/1762] D loss: 1.3926, G loss: 0.7808\n",
      "[1204/1762] D loss: 1.4001, G loss: 0.5849\n",
      "[1284/1762] D loss: 1.3642, G loss: 0.7017\n",
      "[1364/1762] D loss: 1.3771, G loss: 0.6912\n",
      "[1444/1762] D loss: 1.3875, G loss: 0.7342\n",
      "[1524/1762] D loss: 1.3474, G loss: 0.7703\n",
      "[1604/1762] D loss: 1.3909, G loss: 0.7539\n",
      "[1684/1762] D loss: 1.3977, G loss: 0.7691\n",
      "[1762/1762] D loss: 1.3927, G loss: 0.6482\n",
      "train error: \n",
      " D loss: 1.321767, G loss: 0.759504, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.303206, G loss: 0.771331, D accuracy: 55.5%, cell accuracy: 99.8%, board accuracy: 83.6% \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3922, G loss: 0.7276\n",
      "[84/1762] D loss: 1.4021, G loss: 0.6716\n",
      "[164/1762] D loss: 1.2015, G loss: 0.9608\n",
      "[244/1762] D loss: 1.3992, G loss: 0.6934\n",
      "[324/1762] D loss: 1.4051, G loss: 0.7750\n",
      "[404/1762] D loss: 1.4286, G loss: 0.7853\n",
      "[484/1762] D loss: 1.1361, G loss: 0.9258\n",
      "[564/1762] D loss: 1.3871, G loss: 0.6921\n",
      "[644/1762] D loss: 1.4126, G loss: 0.7976\n",
      "[724/1762] D loss: 1.3878, G loss: 0.6816\n",
      "[804/1762] D loss: 1.3884, G loss: 0.6347\n",
      "[884/1762] D loss: 1.3875, G loss: 0.6952\n",
      "[964/1762] D loss: 1.1478, G loss: 0.8614\n",
      "[1044/1762] D loss: 1.4087, G loss: 0.6452\n",
      "[1124/1762] D loss: 1.4067, G loss: 0.7892\n",
      "[1204/1762] D loss: 1.4106, G loss: 0.5823\n",
      "[1284/1762] D loss: 1.3739, G loss: 0.6295\n",
      "[1364/1762] D loss: 1.1789, G loss: 0.9546\n",
      "[1444/1762] D loss: 1.1436, G loss: 0.8531\n",
      "[1524/1762] D loss: 1.3637, G loss: 0.7809\n",
      "[1604/1762] D loss: 1.3911, G loss: 0.7211\n",
      "[1684/1762] D loss: 1.3943, G loss: 0.7016\n",
      "[1762/1762] D loss: 0.8744, G loss: 1.0342\n",
      "train error: \n",
      " D loss: 1.330064, G loss: 0.867404, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 85.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.309004, G loss: 0.879887, D accuracy: 54.9%, cell accuracy: 99.7%, board accuracy: 82.5% \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4383, G loss: 0.8401\n",
      "[84/1762] D loss: 1.1246, G loss: 0.8633\n",
      "[164/1762] D loss: 1.4068, G loss: 0.6288\n",
      "[244/1762] D loss: 1.3977, G loss: 0.5911\n",
      "[324/1762] D loss: 1.1194, G loss: 0.9416\n",
      "[404/1762] D loss: 1.4067, G loss: 0.6108\n",
      "[484/1762] D loss: 1.4223, G loss: 0.8307\n",
      "[564/1762] D loss: 1.1440, G loss: 0.8253\n",
      "[644/1762] D loss: 1.4312, G loss: 0.8240\n",
      "[724/1762] D loss: 1.1326, G loss: 0.8468\n",
      "[804/1762] D loss: 1.1453, G loss: 0.7563\n",
      "[884/1762] D loss: 1.1294, G loss: 0.8769\n",
      "[964/1762] D loss: 1.3981, G loss: 0.6352\n",
      "[1044/1762] D loss: 1.3895, G loss: 0.6502\n",
      "[1124/1762] D loss: 1.4077, G loss: 0.6040\n",
      "[1204/1762] D loss: 0.8405, G loss: 1.3245\n",
      "[1284/1762] D loss: 1.3922, G loss: 0.6886\n",
      "[1364/1762] D loss: 1.3911, G loss: 0.6649\n",
      "[1444/1762] D loss: 1.3885, G loss: 0.7212\n",
      "[1524/1762] D loss: 1.3913, G loss: 0.6551\n",
      "[1604/1762] D loss: 1.1059, G loss: 0.9198\n",
      "[1684/1762] D loss: 1.3857, G loss: 0.7364\n",
      "[1762/1762] D loss: 1.4134, G loss: 0.8990\n",
      "train error: \n",
      " D loss: 1.382797, G loss: 0.926029, D accuracy: 51.1%, cell accuracy: 99.8%, board accuracy: 82.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.370874, G loss: 0.935800, D accuracy: 51.2%, cell accuracy: 99.7%, board accuracy: 76.6% \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1399, G loss: 1.0092\n",
      "[84/1762] D loss: 2.2441, G loss: 0.6093\n",
      "[164/1762] D loss: 1.2647, G loss: 0.6210\n",
      "[244/1762] D loss: 1.1102, G loss: 0.9827\n",
      "[324/1762] D loss: 1.5604, G loss: 0.9628\n",
      "[404/1762] D loss: 1.4060, G loss: 0.6419\n",
      "[484/1762] D loss: 1.3907, G loss: 0.7223\n",
      "[564/1762] D loss: 1.2230, G loss: 0.6726\n",
      "[644/1762] D loss: 1.4142, G loss: 0.7230\n",
      "[724/1762] D loss: 1.4970, G loss: 0.8139\n",
      "[804/1762] D loss: 1.4091, G loss: 0.8452\n",
      "[884/1762] D loss: 1.4005, G loss: 0.6044\n",
      "[964/1762] D loss: 1.1980, G loss: 0.7769\n",
      "[1044/1762] D loss: 1.2875, G loss: 0.8981\n",
      "[1124/1762] D loss: 1.0194, G loss: 0.7391\n",
      "[1204/1762] D loss: 1.3967, G loss: 0.7527\n",
      "[1284/1762] D loss: 1.4064, G loss: 0.7782\n",
      "[1364/1762] D loss: 1.4168, G loss: 0.8567\n",
      "[1444/1762] D loss: 1.3948, G loss: 0.6143\n",
      "[1524/1762] D loss: 1.3911, G loss: 0.6772\n",
      "[1604/1762] D loss: 1.2288, G loss: 0.8450\n",
      "[1684/1762] D loss: 1.3925, G loss: 0.6806\n",
      "[1762/1762] D loss: 1.3919, G loss: 0.6881\n",
      "train error: \n",
      " D loss: 1.330927, G loss: 0.719922, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.318196, G loss: 0.730375, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3946, G loss: 0.6312\n",
      "[84/1762] D loss: 1.3887, G loss: 0.6753\n",
      "[164/1762] D loss: 1.3902, G loss: 0.7499\n",
      "[244/1762] D loss: 1.1842, G loss: 0.8663\n",
      "[324/1762] D loss: 1.3898, G loss: 0.7008\n",
      "[404/1762] D loss: 1.3972, G loss: 0.6674\n",
      "[484/1762] D loss: 1.3915, G loss: 0.6225\n",
      "[564/1762] D loss: 1.3885, G loss: 0.7354\n",
      "[644/1762] D loss: 1.4066, G loss: 0.8488\n",
      "[724/1762] D loss: 1.3872, G loss: 0.7099\n",
      "[804/1762] D loss: 1.3879, G loss: 0.7149\n",
      "[884/1762] D loss: 1.3270, G loss: 0.8525\n",
      "[964/1762] D loss: 1.3938, G loss: 0.7782\n",
      "[1044/1762] D loss: 1.3921, G loss: 0.6203\n",
      "[1124/1762] D loss: 1.3894, G loss: 0.7120\n",
      "[1204/1762] D loss: 1.1927, G loss: 0.7264\n",
      "[1284/1762] D loss: 1.3876, G loss: 0.7150\n",
      "[1364/1762] D loss: 1.3914, G loss: 0.6910\n",
      "[1444/1762] D loss: 1.4007, G loss: 0.7957\n",
      "[1524/1762] D loss: 1.3900, G loss: 0.7909\n",
      "[1604/1762] D loss: 1.3883, G loss: 0.6759\n",
      "[1684/1762] D loss: 1.3433, G loss: 0.6796\n",
      "[1762/1762] D loss: 1.3501, G loss: 0.6845\n",
      "train error: \n",
      " D loss: 1.330344, G loss: 0.653961, D accuracy: 55.1%, cell accuracy: 99.6%, board accuracy: 74.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.316946, G loss: 0.662853, D accuracy: 55.9%, cell accuracy: 99.6%, board accuracy: 73.4% \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4166, G loss: 0.6271\n",
      "[84/1762] D loss: 1.3733, G loss: 0.7642\n",
      "[164/1762] D loss: 1.4085, G loss: 0.6163\n",
      "[244/1762] D loss: 1.3877, G loss: 0.7224\n",
      "[324/1762] D loss: 1.3929, G loss: 0.6727\n",
      "[404/1762] D loss: 1.3894, G loss: 0.6400\n",
      "[484/1762] D loss: 1.4182, G loss: 0.8602\n",
      "[564/1762] D loss: 1.3789, G loss: 0.6945\n",
      "[644/1762] D loss: 1.3911, G loss: 0.7418\n",
      "[724/1762] D loss: 1.3986, G loss: 0.7994\n",
      "[804/1762] D loss: 1.3719, G loss: 0.7920\n",
      "[884/1762] D loss: 1.2976, G loss: 0.6859\n",
      "[964/1762] D loss: 1.3771, G loss: 0.6783\n",
      "[1044/1762] D loss: 1.3814, G loss: 0.7108\n",
      "[1124/1762] D loss: 1.3682, G loss: 0.7159\n",
      "[1204/1762] D loss: 1.3550, G loss: 0.7945\n",
      "[1284/1762] D loss: 1.1940, G loss: 0.7609\n",
      "[1364/1762] D loss: 1.1453, G loss: 0.8730\n",
      "[1444/1762] D loss: 1.3786, G loss: 0.6974\n",
      "[1524/1762] D loss: 1.3654, G loss: 0.6622\n",
      "[1604/1762] D loss: 1.1927, G loss: 0.8250\n",
      "[1684/1762] D loss: 1.3610, G loss: 0.6687\n",
      "[1762/1762] D loss: 0.9469, G loss: 0.9019\n",
      "train error: \n",
      " D loss: 1.324303, G loss: 0.832028, D accuracy: 54.6%, cell accuracy: 99.7%, board accuracy: 80.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.303715, G loss: 0.843001, D accuracy: 56.4%, cell accuracy: 99.6%, board accuracy: 78.9% \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1056, G loss: 1.0453\n",
      "[84/1762] D loss: 1.1191, G loss: 0.9518\n",
      "[164/1762] D loss: 1.3961, G loss: 0.8198\n",
      "[244/1762] D loss: 1.3892, G loss: 0.7291\n",
      "[324/1762] D loss: 1.4000, G loss: 0.6189\n",
      "[404/1762] D loss: 1.1507, G loss: 0.8539\n",
      "[484/1762] D loss: 1.1740, G loss: 0.8641\n",
      "[564/1762] D loss: 1.1215, G loss: 0.8806\n",
      "[644/1762] D loss: 1.1545, G loss: 0.8390\n",
      "[724/1762] D loss: 1.4119, G loss: 0.6102\n",
      "[804/1762] D loss: 1.4230, G loss: 0.9479\n",
      "[884/1762] D loss: 1.3996, G loss: 0.7809\n",
      "[964/1762] D loss: 1.3927, G loss: 0.6911\n",
      "[1044/1762] D loss: 1.3834, G loss: 0.6400\n",
      "[1124/1762] D loss: 1.4032, G loss: 0.7863\n",
      "[1204/1762] D loss: 1.1307, G loss: 1.0376\n",
      "[1284/1762] D loss: 1.3769, G loss: 0.6678\n",
      "[1364/1762] D loss: 1.4229, G loss: 0.5984\n",
      "[1444/1762] D loss: 1.3882, G loss: 0.6172\n",
      "[1524/1762] D loss: 1.3996, G loss: 0.8190\n",
      "[1604/1762] D loss: 1.4025, G loss: 0.7651\n",
      "[1684/1762] D loss: 1.3937, G loss: 0.7204\n",
      "[1762/1762] D loss: 1.3667, G loss: 0.6407\n",
      "train error: \n",
      " D loss: 1.330677, G loss: 0.657092, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 91.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.313718, G loss: 0.666469, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3980, G loss: 0.6249\n",
      "[84/1762] D loss: 1.4079, G loss: 0.7736\n",
      "[164/1762] D loss: 1.1329, G loss: 0.9333\n",
      "[244/1762] D loss: 0.9345, G loss: 0.8958\n",
      "[324/1762] D loss: 1.1573, G loss: 0.8743\n",
      "[404/1762] D loss: 1.4056, G loss: 0.7781\n",
      "[484/1762] D loss: 1.4018, G loss: 0.6596\n",
      "[564/1762] D loss: 1.1507, G loss: 0.8555\n",
      "[644/1762] D loss: 1.3830, G loss: 0.6744\n",
      "[724/1762] D loss: 1.3963, G loss: 0.6833\n",
      "[804/1762] D loss: 1.3904, G loss: 0.7571\n",
      "[884/1762] D loss: 1.3914, G loss: 0.6199\n",
      "[964/1762] D loss: 1.4005, G loss: 0.7803\n",
      "[1044/1762] D loss: 1.1469, G loss: 0.7479\n",
      "[1124/1762] D loss: 1.3950, G loss: 0.7441\n",
      "[1204/1762] D loss: 1.1142, G loss: 1.0657\n",
      "[1284/1762] D loss: 1.3957, G loss: 0.7157\n",
      "[1364/1762] D loss: 1.3888, G loss: 0.7043\n",
      "[1444/1762] D loss: 1.1436, G loss: 0.8471\n",
      "[1524/1762] D loss: 1.3921, G loss: 0.6537\n",
      "[1604/1762] D loss: 1.3899, G loss: 0.6600\n",
      "[1684/1762] D loss: 1.4028, G loss: 0.8090\n",
      "[1762/1762] D loss: 1.3957, G loss: 0.6585\n",
      "train error: \n",
      " D loss: 1.318014, G loss: 0.742103, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 90.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.301016, G loss: 0.753666, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3901, G loss: 0.6919\n",
      "[84/1762] D loss: 1.3888, G loss: 0.6332\n",
      "[164/1762] D loss: 1.1179, G loss: 1.0611\n",
      "[244/1762] D loss: 1.3888, G loss: 0.6778\n",
      "[324/1762] D loss: 1.3905, G loss: 0.6204\n",
      "[404/1762] D loss: 1.1303, G loss: 0.9109\n",
      "[484/1762] D loss: 1.2651, G loss: 0.8793\n",
      "[564/1762] D loss: 1.1197, G loss: 1.0300\n",
      "[644/1762] D loss: 1.3696, G loss: 0.7049\n",
      "[724/1762] D loss: 1.6082, G loss: 0.6147\n",
      "[804/1762] D loss: 1.1563, G loss: 0.8339\n",
      "[884/1762] D loss: 2.9675, G loss: 0.2294\n",
      "[964/1762] D loss: 1.4160, G loss: 0.6620\n",
      "[1044/1762] D loss: 1.4027, G loss: 1.2336\n",
      "[1124/1762] D loss: 1.5640, G loss: 0.8481\n",
      "[1204/1762] D loss: 1.2072, G loss: 0.7423\n",
      "[1284/1762] D loss: 1.0049, G loss: 0.9404\n",
      "[1364/1762] D loss: 0.8964, G loss: 1.0850\n",
      "[1444/1762] D loss: 0.5577, G loss: 1.2554\n",
      "[1524/1762] D loss: 0.9827, G loss: 1.2529\n",
      "[1604/1762] D loss: 1.2385, G loss: 0.9784\n",
      "[1684/1762] D loss: 1.6456, G loss: 0.4123\n",
      "[1762/1762] D loss: 2.0815, G loss: 1.1239\n",
      "train error: \n",
      " D loss: 1.621683, G loss: 1.064874, D accuracy: 49.5%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.646216, G loss: 1.069600, D accuracy: 49.4%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.9089, G loss: 0.8058\n",
      "[84/1762] D loss: 1.6346, G loss: 0.7925\n",
      "[164/1762] D loss: 1.4064, G loss: 0.6977\n",
      "[244/1762] D loss: 1.4033, G loss: 0.6244\n",
      "[324/1762] D loss: 1.4157, G loss: 0.6122\n",
      "[404/1762] D loss: 1.5016, G loss: 0.6524\n",
      "[484/1762] D loss: 1.5300, G loss: 0.7124\n",
      "[564/1762] D loss: 1.4021, G loss: 0.7469\n",
      "[644/1762] D loss: 1.4023, G loss: 0.7893\n",
      "[724/1762] D loss: 1.4288, G loss: 0.9043\n",
      "[804/1762] D loss: 1.4048, G loss: 0.8110\n",
      "[884/1762] D loss: 1.4066, G loss: 0.7988\n",
      "[964/1762] D loss: 1.4122, G loss: 0.8237\n",
      "[1044/1762] D loss: 1.3891, G loss: 0.6648\n",
      "[1124/1762] D loss: 1.4074, G loss: 0.7176\n",
      "[1204/1762] D loss: 1.4528, G loss: 0.6711\n",
      "[1284/1762] D loss: 1.3936, G loss: 0.7104\n",
      "[1364/1762] D loss: 1.4087, G loss: 0.5693\n",
      "[1444/1762] D loss: 1.3950, G loss: 0.7333\n",
      "[1524/1762] D loss: 1.4061, G loss: 0.7060\n",
      "[1604/1762] D loss: 1.4052, G loss: 0.7912\n",
      "[1684/1762] D loss: 1.3919, G loss: 0.6998\n",
      "[1762/1762] D loss: 1.4036, G loss: 0.6813\n",
      "train error: \n",
      " D loss: 1.404593, G loss: 0.739277, D accuracy: 49.9%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.412476, G loss: 0.747629, D accuracy: 50.0%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4721, G loss: 0.7715\n",
      "[84/1762] D loss: 1.3942, G loss: 0.7884\n",
      "[164/1762] D loss: 1.3950, G loss: 0.6436\n",
      "[244/1762] D loss: 1.3942, G loss: 0.7201\n",
      "[324/1762] D loss: 1.4684, G loss: 0.7144\n",
      "[404/1762] D loss: 1.3873, G loss: 0.6789\n",
      "[484/1762] D loss: 1.4091, G loss: 0.7086\n",
      "[564/1762] D loss: 1.3952, G loss: 0.7392\n",
      "[644/1762] D loss: 1.4160, G loss: 0.6361\n",
      "[724/1762] D loss: 1.3907, G loss: 0.6760\n",
      "[804/1762] D loss: 1.3880, G loss: 0.6992\n",
      "[884/1762] D loss: 1.3961, G loss: 0.7440\n",
      "[964/1762] D loss: 1.4288, G loss: 0.6978\n",
      "[1044/1762] D loss: 1.3912, G loss: 0.7419\n",
      "[1124/1762] D loss: 1.3876, G loss: 0.7176\n",
      "[1204/1762] D loss: 1.3803, G loss: 0.7224\n",
      "[1284/1762] D loss: 1.3890, G loss: 0.6587\n",
      "[1364/1762] D loss: 1.4093, G loss: 0.7261\n",
      "[1444/1762] D loss: 1.3901, G loss: 0.6823\n",
      "[1524/1762] D loss: 1.3868, G loss: 0.6886\n",
      "[1604/1762] D loss: 1.3948, G loss: 0.7452\n",
      "[1684/1762] D loss: 1.3906, G loss: 0.7329\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6993\n",
      "train error: \n",
      " D loss: 1.386357, G loss: 0.689302, D accuracy: 51.6%, cell accuracy: 99.9%, board accuracy: 91.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.388232, G loss: 0.697952, D accuracy: 51.6%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3896, G loss: 0.6807\n",
      "[84/1762] D loss: 1.3907, G loss: 0.7225\n",
      "[164/1762] D loss: 1.3909, G loss: 0.6771\n",
      "[244/1762] D loss: 1.3868, G loss: 0.7074\n",
      "[324/1762] D loss: 1.3902, G loss: 0.6696\n",
      "[404/1762] D loss: 1.3881, G loss: 0.6948\n",
      "[484/1762] D loss: 1.3271, G loss: 0.7087\n",
      "[564/1762] D loss: 1.3902, G loss: 0.6624\n",
      "[644/1762] D loss: 1.3875, G loss: 0.7054\n",
      "[724/1762] D loss: 1.3885, G loss: 0.6830\n",
      "[804/1762] D loss: 1.3600, G loss: 0.6936\n",
      "[884/1762] D loss: 1.4004, G loss: 0.6190\n",
      "[964/1762] D loss: 1.3903, G loss: 0.6462\n",
      "[1044/1762] D loss: 1.3870, G loss: 0.7001\n",
      "[1124/1762] D loss: 1.4001, G loss: 0.6366\n",
      "[1204/1762] D loss: 1.4471, G loss: 0.7489\n",
      "[1284/1762] D loss: 1.3476, G loss: 0.7196\n",
      "[1364/1762] D loss: 1.3875, G loss: 0.6948\n",
      "[1444/1762] D loss: 1.3923, G loss: 0.7058\n",
      "[1524/1762] D loss: 1.3419, G loss: 0.6853\n",
      "[1604/1762] D loss: 1.3350, G loss: 0.7139\n",
      "[1684/1762] D loss: 1.3887, G loss: 0.6632\n",
      "[1762/1762] D loss: 1.2890, G loss: 0.6555\n",
      "train error: \n",
      " D loss: 1.374927, G loss: 0.682334, D accuracy: 53.4%, cell accuracy: 99.9%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.373361, G loss: 0.690139, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3908, G loss: 0.6543\n",
      "[84/1762] D loss: 1.3882, G loss: 0.6996\n",
      "[164/1762] D loss: 1.3882, G loss: 0.7121\n",
      "[244/1762] D loss: 1.3878, G loss: 0.6829\n",
      "[324/1762] D loss: 1.3997, G loss: 0.6539\n",
      "[404/1762] D loss: 1.3986, G loss: 0.7058\n",
      "[484/1762] D loss: 1.3999, G loss: 0.6207\n",
      "[564/1762] D loss: 1.3893, G loss: 0.6812\n",
      "[644/1762] D loss: 1.3969, G loss: 0.6551\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6934\n",
      "[804/1762] D loss: 1.3160, G loss: 0.7134\n",
      "[884/1762] D loss: 1.3876, G loss: 0.6795\n",
      "[964/1762] D loss: 1.3399, G loss: 0.7773\n",
      "[1044/1762] D loss: 1.3895, G loss: 0.7018\n",
      "[1124/1762] D loss: 1.3879, G loss: 0.7175\n",
      "[1204/1762] D loss: 1.3129, G loss: 0.7368\n",
      "[1284/1762] D loss: 1.3006, G loss: 0.8000\n",
      "[1364/1762] D loss: 1.3870, G loss: 0.6955\n",
      "[1444/1762] D loss: 1.3897, G loss: 0.6817\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.7001\n",
      "[1604/1762] D loss: 1.4204, G loss: 0.7008\n",
      "[1684/1762] D loss: 1.2992, G loss: 0.7217\n",
      "[1762/1762] D loss: 1.3886, G loss: 0.7312\n",
      "train error: \n",
      " D loss: 1.362969, G loss: 0.725680, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.358133, G loss: 0.735264, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3878, G loss: 0.7148\n",
      "[84/1762] D loss: 1.3868, G loss: 0.6968\n",
      "[164/1762] D loss: 1.3865, G loss: 0.7008\n",
      "[244/1762] D loss: 1.3905, G loss: 0.7175\n",
      "[324/1762] D loss: 1.3885, G loss: 0.6667\n",
      "[404/1762] D loss: 1.2862, G loss: 0.7850\n",
      "[484/1762] D loss: 1.3904, G loss: 0.6955\n",
      "[564/1762] D loss: 1.4000, G loss: 0.6687\n",
      "[644/1762] D loss: 1.3960, G loss: 0.7459\n",
      "[724/1762] D loss: 1.2423, G loss: 0.7657\n",
      "[804/1762] D loss: 1.3886, G loss: 0.6866\n",
      "[884/1762] D loss: 1.3932, G loss: 0.6795\n",
      "[964/1762] D loss: 1.2635, G loss: 0.7398\n",
      "[1044/1762] D loss: 1.2778, G loss: 0.7408\n",
      "[1124/1762] D loss: 1.3134, G loss: 0.8245\n",
      "[1204/1762] D loss: 1.3872, G loss: 0.6977\n",
      "[1284/1762] D loss: 1.4061, G loss: 0.6347\n",
      "[1364/1762] D loss: 1.2667, G loss: 0.6998\n",
      "[1444/1762] D loss: 1.4004, G loss: 0.7057\n",
      "[1524/1762] D loss: 1.3959, G loss: 0.7947\n",
      "[1604/1762] D loss: 1.3886, G loss: 0.7023\n",
      "[1684/1762] D loss: 1.3886, G loss: 0.7291\n",
      "[1762/1762] D loss: 1.3874, G loss: 0.7261\n",
      "train error: \n",
      " D loss: 1.348006, G loss: 0.722529, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.340089, G loss: 0.732689, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3987, G loss: 0.6722\n",
      "[84/1762] D loss: 1.3894, G loss: 0.7131\n",
      "[164/1762] D loss: 1.3879, G loss: 0.7046\n",
      "[244/1762] D loss: 1.2445, G loss: 0.8006\n",
      "[324/1762] D loss: 1.1064, G loss: 0.9145\n",
      "[404/1762] D loss: 1.1917, G loss: 0.7537\n",
      "[484/1762] D loss: 1.3939, G loss: 0.7362\n",
      "[564/1762] D loss: 1.0592, G loss: 0.8554\n",
      "[644/1762] D loss: 1.3881, G loss: 0.6813\n",
      "[724/1762] D loss: 1.3902, G loss: 0.7556\n",
      "[804/1762] D loss: 1.3904, G loss: 0.7281\n",
      "[884/1762] D loss: 1.3825, G loss: 0.7227\n",
      "[964/1762] D loss: 1.3920, G loss: 0.7436\n",
      "[1044/1762] D loss: 1.3958, G loss: 0.7526\n",
      "[1124/1762] D loss: 1.3923, G loss: 0.7208\n",
      "[1204/1762] D loss: 1.3891, G loss: 0.6860\n",
      "[1284/1762] D loss: 1.3879, G loss: 0.7171\n",
      "[1364/1762] D loss: 1.1859, G loss: 0.8120\n",
      "[1444/1762] D loss: 1.3963, G loss: 0.6665\n",
      "[1524/1762] D loss: 1.3891, G loss: 0.7249\n",
      "[1604/1762] D loss: 1.3917, G loss: 0.6971\n",
      "[1684/1762] D loss: 1.1885, G loss: 0.8231\n",
      "[1762/1762] D loss: 1.3873, G loss: 0.7452\n",
      "train error: \n",
      " D loss: 1.334580, G loss: 0.794107, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.320484, G loss: 0.806041, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1589, G loss: 0.9434\n",
      "[84/1762] D loss: 1.3888, G loss: 0.6773\n",
      "[164/1762] D loss: 1.3650, G loss: 0.6965\n",
      "[244/1762] D loss: 1.3995, G loss: 0.7630\n",
      "[324/1762] D loss: 1.4050, G loss: 0.7641\n",
      "[404/1762] D loss: 1.3905, G loss: 0.6560\n",
      "[484/1762] D loss: 1.3947, G loss: 0.6702\n",
      "[564/1762] D loss: 1.3980, G loss: 0.7852\n",
      "[644/1762] D loss: 1.1465, G loss: 0.8140\n",
      "[724/1762] D loss: 1.1511, G loss: 0.8024\n",
      "[804/1762] D loss: 1.3921, G loss: 0.7690\n",
      "[884/1762] D loss: 1.3898, G loss: 0.6994\n",
      "[964/1762] D loss: 1.3971, G loss: 0.7806\n",
      "[1044/1762] D loss: 1.2364, G loss: 0.7520\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.7102\n",
      "[1204/1762] D loss: 1.3849, G loss: 0.7603\n",
      "[1284/1762] D loss: 1.1548, G loss: 0.7930\n",
      "[1364/1762] D loss: 1.1995, G loss: 0.8468\n",
      "[1444/1762] D loss: 1.2101, G loss: 0.8251\n",
      "[1524/1762] D loss: 1.4079, G loss: 0.7833\n",
      "[1604/1762] D loss: 1.3879, G loss: 0.7332\n",
      "[1684/1762] D loss: 1.3871, G loss: 0.6712\n",
      "[1762/1762] D loss: 1.3826, G loss: 0.7756\n",
      "train error: \n",
      " D loss: 1.340487, G loss: 0.899123, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.324256, G loss: 0.911187, D accuracy: 54.2%, cell accuracy: 99.7%, board accuracy: 83.2% \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4445, G loss: 0.8960\n",
      "[84/1762] D loss: 1.1405, G loss: 0.8516\n",
      "[164/1762] D loss: 1.3935, G loss: 0.6467\n",
      "[244/1762] D loss: 1.3536, G loss: 0.6378\n",
      "[324/1762] D loss: 1.1229, G loss: 1.0184\n",
      "[404/1762] D loss: 1.4264, G loss: 0.6305\n",
      "[484/1762] D loss: 1.3670, G loss: 0.8552\n",
      "[564/1762] D loss: 1.3421, G loss: 0.7160\n",
      "[644/1762] D loss: 1.3153, G loss: 0.6642\n",
      "[724/1762] D loss: 1.1195, G loss: 0.9012\n",
      "[804/1762] D loss: 0.8296, G loss: 1.0359\n",
      "[884/1762] D loss: 1.3697, G loss: 0.8181\n",
      "[964/1762] D loss: 1.3576, G loss: 0.7392\n",
      "[1044/1762] D loss: 1.1111, G loss: 1.0002\n",
      "[1124/1762] D loss: 1.3460, G loss: 0.7308\n",
      "[1204/1762] D loss: 1.4018, G loss: 0.5662\n",
      "[1284/1762] D loss: 1.1864, G loss: 0.8112\n",
      "[1364/1762] D loss: 1.4059, G loss: 0.7625\n",
      "[1444/1762] D loss: 1.4332, G loss: 0.9226\n",
      "[1524/1762] D loss: 1.3939, G loss: 0.7438\n",
      "[1604/1762] D loss: 1.1380, G loss: 0.8086\n",
      "[1684/1762] D loss: 1.1224, G loss: 0.8841\n",
      "[1762/1762] D loss: 1.3945, G loss: 0.5950\n",
      "train error: \n",
      " D loss: 1.350802, G loss: 0.599189, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 85.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.333003, G loss: 0.604889, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 80.9% \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4071, G loss: 0.5870\n",
      "[84/1762] D loss: 1.4298, G loss: 0.8193\n",
      "[164/1762] D loss: 1.4082, G loss: 0.8323\n",
      "[244/1762] D loss: 1.4029, G loss: 0.7387\n",
      "[324/1762] D loss: 1.3903, G loss: 0.7119\n",
      "[404/1762] D loss: 1.1355, G loss: 1.1280\n",
      "[484/1762] D loss: 1.6897, G loss: 0.5048\n",
      "[564/1762] D loss: 1.3788, G loss: 0.8794\n",
      "[644/1762] D loss: 1.2701, G loss: 0.6673\n",
      "[724/1762] D loss: 1.3821, G loss: 0.6821\n",
      "[804/1762] D loss: 1.4173, G loss: 0.5822\n",
      "[884/1762] D loss: 1.4098, G loss: 0.7823\n",
      "[964/1762] D loss: 1.3937, G loss: 0.8109\n",
      "[1044/1762] D loss: 1.3747, G loss: 0.7124\n",
      "[1124/1762] D loss: 1.4267, G loss: 0.7809\n",
      "[1204/1762] D loss: 1.3824, G loss: 0.6795\n",
      "[1284/1762] D loss: 1.3860, G loss: 0.6335\n",
      "[1364/1762] D loss: 1.3901, G loss: 0.6487\n",
      "[1444/1762] D loss: 1.2265, G loss: 0.7024\n",
      "[1524/1762] D loss: 1.3753, G loss: 0.6906\n",
      "[1604/1762] D loss: 1.3887, G loss: 0.7352\n",
      "[1684/1762] D loss: 1.3885, G loss: 0.6658\n",
      "[1762/1762] D loss: 0.9696, G loss: 0.8576\n",
      "train error: \n",
      " D loss: 1.340539, G loss: 0.773546, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 82.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.329951, G loss: 0.776611, D accuracy: 54.2%, cell accuracy: 99.7%, board accuracy: 78.9% \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3946, G loss: 0.8019\n",
      "[84/1762] D loss: 1.4066, G loss: 0.8075\n",
      "[164/1762] D loss: 1.3842, G loss: 0.7546\n",
      "[244/1762] D loss: 1.3944, G loss: 0.7841\n",
      "[324/1762] D loss: 1.4329, G loss: 0.7809\n",
      "[404/1762] D loss: 1.3986, G loss: 0.6242\n",
      "[484/1762] D loss: 1.2544, G loss: 0.7847\n",
      "[564/1762] D loss: 1.3653, G loss: 0.7328\n",
      "[644/1762] D loss: 1.3968, G loss: 0.7134\n",
      "[724/1762] D loss: 1.4209, G loss: 0.8730\n",
      "[804/1762] D loss: 1.4031, G loss: 0.7926\n",
      "[884/1762] D loss: 1.3787, G loss: 0.7515\n",
      "[964/1762] D loss: 1.3779, G loss: 0.8431\n",
      "[1044/1762] D loss: 1.3758, G loss: 0.6617\n",
      "[1124/1762] D loss: 1.4050, G loss: 0.8095\n",
      "[1204/1762] D loss: 0.9047, G loss: 0.9522\n",
      "[1284/1762] D loss: 1.3950, G loss: 0.7196\n",
      "[1364/1762] D loss: 1.3932, G loss: 0.6760\n",
      "[1444/1762] D loss: 1.1610, G loss: 0.8731\n",
      "[1524/1762] D loss: 1.4020, G loss: 0.8150\n",
      "[1604/1762] D loss: 1.3910, G loss: 0.7151\n",
      "[1684/1762] D loss: 1.3908, G loss: 0.6406\n",
      "[1762/1762] D loss: 1.3872, G loss: 0.7259\n",
      "train error: \n",
      " D loss: 1.330239, G loss: 0.721345, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 87.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.316173, G loss: 0.728515, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 85.5% \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1698, G loss: 0.7847\n",
      "[84/1762] D loss: 1.3899, G loss: 0.6535\n",
      "[164/1762] D loss: 1.3953, G loss: 0.6224\n",
      "[244/1762] D loss: 1.4000, G loss: 0.7505\n",
      "[324/1762] D loss: 1.1900, G loss: 0.8233\n",
      "[404/1762] D loss: 1.3917, G loss: 0.7815\n",
      "[484/1762] D loss: 1.4057, G loss: 0.7892\n",
      "[564/1762] D loss: 1.3893, G loss: 0.7116\n",
      "[644/1762] D loss: 1.3983, G loss: 0.7611\n",
      "[724/1762] D loss: 1.3881, G loss: 0.7037\n",
      "[804/1762] D loss: 1.3929, G loss: 0.6306\n",
      "[884/1762] D loss: 1.3765, G loss: 0.7159\n",
      "[964/1762] D loss: 1.3962, G loss: 0.7670\n",
      "[1044/1762] D loss: 1.1939, G loss: 0.7018\n",
      "[1124/1762] D loss: 1.3926, G loss: 0.6441\n",
      "[1204/1762] D loss: 1.3948, G loss: 0.7689\n",
      "[1284/1762] D loss: 1.3912, G loss: 0.7492\n",
      "[1364/1762] D loss: 1.4030, G loss: 0.7446\n",
      "[1444/1762] D loss: 1.3775, G loss: 0.7164\n",
      "[1524/1762] D loss: 1.3877, G loss: 0.6973\n",
      "[1604/1762] D loss: 1.1894, G loss: 0.7547\n",
      "[1684/1762] D loss: 1.3953, G loss: 0.7039\n",
      "[1762/1762] D loss: 0.8464, G loss: 1.0054\n",
      "train error: \n",
      " D loss: 1.324241, G loss: 0.749003, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 86.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.308103, G loss: 0.755621, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 84.3% \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3950, G loss: 0.7579\n",
      "[84/1762] D loss: 1.3966, G loss: 0.7028\n",
      "[164/1762] D loss: 1.3908, G loss: 0.7509\n",
      "[244/1762] D loss: 1.1504, G loss: 0.8559\n",
      "[324/1762] D loss: 1.1649, G loss: 0.7850\n",
      "[404/1762] D loss: 1.1194, G loss: 0.8877\n",
      "[484/1762] D loss: 1.4007, G loss: 0.6122\n",
      "[564/1762] D loss: 1.3789, G loss: 0.7504\n",
      "[644/1762] D loss: 1.1805, G loss: 0.7686\n",
      "[724/1762] D loss: 1.3509, G loss: 0.6713\n",
      "[804/1762] D loss: 1.3920, G loss: 0.7083\n",
      "[884/1762] D loss: 1.1428, G loss: 0.8266\n",
      "[964/1762] D loss: 1.1414, G loss: 0.8817\n",
      "[1044/1762] D loss: 1.3889, G loss: 0.6686\n",
      "[1124/1762] D loss: 1.1634, G loss: 0.7710\n",
      "[1204/1762] D loss: 1.3915, G loss: 0.7331\n",
      "[1284/1762] D loss: 1.3896, G loss: 0.6498\n",
      "[1364/1762] D loss: 0.9358, G loss: 0.9243\n",
      "[1444/1762] D loss: 1.3957, G loss: 0.6542\n",
      "[1524/1762] D loss: 1.3922, G loss: 0.7467\n",
      "[1604/1762] D loss: 1.3888, G loss: 0.6857\n",
      "[1684/1762] D loss: 1.1309, G loss: 0.9151\n",
      "[1762/1762] D loss: 1.3961, G loss: 0.6013\n",
      "train error: \n",
      " D loss: 1.331641, G loss: 0.646733, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.314152, G loss: 0.657034, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4162, G loss: 0.5771\n",
      "[84/1762] D loss: 1.4172, G loss: 0.8630\n",
      "[164/1762] D loss: 0.9557, G loss: 0.7869\n",
      "[244/1762] D loss: 1.3910, G loss: 0.7273\n",
      "[324/1762] D loss: 1.1562, G loss: 0.8432\n",
      "[404/1762] D loss: 1.3906, G loss: 0.6310\n",
      "[484/1762] D loss: 1.3919, G loss: 0.7575\n",
      "[564/1762] D loss: 1.3882, G loss: 0.6471\n",
      "[644/1762] D loss: 1.1513, G loss: 0.8131\n",
      "[724/1762] D loss: 1.4025, G loss: 0.7631\n",
      "[804/1762] D loss: 1.1173, G loss: 0.8559\n",
      "[884/1762] D loss: 1.1282, G loss: 0.9504\n",
      "[964/1762] D loss: 1.3809, G loss: 0.7710\n",
      "[1044/1762] D loss: 1.3882, G loss: 0.7125\n",
      "[1124/1762] D loss: 1.3955, G loss: 0.6558\n",
      "[1204/1762] D loss: 1.4143, G loss: 0.7896\n",
      "[1284/1762] D loss: 1.1568, G loss: 0.7771\n",
      "[1364/1762] D loss: 1.3917, G loss: 0.7231\n",
      "[1444/1762] D loss: 1.3994, G loss: 0.6158\n",
      "[1524/1762] D loss: 1.3923, G loss: 0.6143\n",
      "[1604/1762] D loss: 1.3878, G loss: 0.7230\n",
      "[1684/1762] D loss: 1.4016, G loss: 0.7098\n",
      "[1762/1762] D loss: 0.8960, G loss: 1.1005\n",
      "train error: \n",
      " D loss: 1.328180, G loss: 0.853336, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 87.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.307023, G loss: 0.870205, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 83.6% \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3727, G loss: 0.9379\n",
      "[84/1762] D loss: 1.3895, G loss: 0.7022\n",
      "[164/1762] D loss: 1.1151, G loss: 0.8765\n",
      "[244/1762] D loss: 1.3851, G loss: 0.7838\n",
      "[324/1762] D loss: 1.1287, G loss: 0.9209\n",
      "[404/1762] D loss: 1.1275, G loss: 0.9709\n",
      "[484/1762] D loss: 1.3468, G loss: 0.7167\n",
      "[564/1762] D loss: 1.3917, G loss: 0.7061\n",
      "[644/1762] D loss: 1.3912, G loss: 0.6382\n",
      "[724/1762] D loss: 1.3988, G loss: 0.7560\n",
      "[804/1762] D loss: 1.1335, G loss: 0.8434\n",
      "[884/1762] D loss: 1.3986, G loss: 0.6750\n",
      "[964/1762] D loss: 1.3925, G loss: 0.7350\n",
      "[1044/1762] D loss: 1.1832, G loss: 0.8014\n",
      "[1124/1762] D loss: 1.1464, G loss: 0.8648\n",
      "[1204/1762] D loss: 1.3866, G loss: 0.6803\n",
      "[1284/1762] D loss: 1.1448, G loss: 0.8795\n",
      "[1364/1762] D loss: 1.4075, G loss: 0.7474\n",
      "[1444/1762] D loss: 1.3971, G loss: 0.6399\n",
      "[1524/1762] D loss: 1.3945, G loss: 0.7507\n",
      "[1604/1762] D loss: 1.1554, G loss: 0.7796\n",
      "[1684/1762] D loss: 1.1535, G loss: 0.7538\n",
      "[1762/1762] D loss: 1.3888, G loss: 0.7311\n",
      "train error: \n",
      " D loss: 1.319052, G loss: 0.734135, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.299606, G loss: 0.749818, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 84.1% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3849, G loss: 0.7385\n",
      "[84/1762] D loss: 1.3777, G loss: 0.7421\n",
      "[164/1762] D loss: 1.3694, G loss: 0.7400\n",
      "[244/1762] D loss: 1.3569, G loss: 0.7374\n",
      "[324/1762] D loss: 1.3316, G loss: 0.7303\n",
      "[404/1762] D loss: 1.2591, G loss: 0.7313\n",
      "[484/1762] D loss: 1.1680, G loss: 0.7124\n",
      "[564/1762] D loss: 1.0759, G loss: 0.6900\n",
      "[644/1762] D loss: 1.0079, G loss: 0.6886\n",
      "[724/1762] D loss: 0.9208, G loss: 0.7193\n",
      "[804/1762] D loss: 0.7673, G loss: 0.8158\n",
      "[884/1762] D loss: 0.8549, G loss: 0.7458\n",
      "[964/1762] D loss: 0.7994, G loss: 0.8353\n",
      "[1044/1762] D loss: 0.8423, G loss: 0.8614\n",
      "[1124/1762] D loss: 0.7415, G loss: 0.8640\n",
      "[1204/1762] D loss: 0.6352, G loss: 1.0289\n",
      "[1284/1762] D loss: 0.6221, G loss: 1.0555\n",
      "[1364/1762] D loss: 0.6106, G loss: 1.1587\n",
      "[1444/1762] D loss: 0.4655, G loss: 1.3599\n",
      "[1524/1762] D loss: 0.5341, G loss: 1.3686\n",
      "[1604/1762] D loss: 0.6082, G loss: 1.5028\n",
      "[1684/1762] D loss: 0.4685, G loss: 1.5507\n",
      "[1762/1762] D loss: 0.4686, G loss: 1.6568\n",
      "train error: \n",
      " D loss: 0.523816, G loss: 1.778484, D accuracy: 89.5%, cell accuracy: 47.6%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.511372, G loss: 1.790638, D accuracy: 89.7%, cell accuracy: 47.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5576, G loss: 1.7003\n",
      "[84/1762] D loss: 0.5963, G loss: 1.9355\n",
      "[164/1762] D loss: 0.4781, G loss: 1.7442\n",
      "[244/1762] D loss: 0.5156, G loss: 2.0963\n",
      "[324/1762] D loss: 0.4745, G loss: 2.1159\n",
      "[404/1762] D loss: 0.5137, G loss: 1.9989\n",
      "[484/1762] D loss: 0.4737, G loss: 2.2309\n",
      "[564/1762] D loss: 0.3412, G loss: 2.0225\n",
      "[644/1762] D loss: 0.5856, G loss: 2.3315\n",
      "[724/1762] D loss: 0.6834, G loss: 2.1573\n",
      "[804/1762] D loss: 0.6842, G loss: 2.1634\n",
      "[884/1762] D loss: 0.4818, G loss: 2.5035\n",
      "[964/1762] D loss: 0.4336, G loss: 2.5901\n",
      "[1044/1762] D loss: 0.5472, G loss: 2.4552\n",
      "[1124/1762] D loss: 0.5805, G loss: 2.9978\n",
      "[1204/1762] D loss: 0.6883, G loss: 2.6672\n",
      "[1284/1762] D loss: 0.6469, G loss: 2.5689\n",
      "[1364/1762] D loss: 0.7258, G loss: 2.4150\n",
      "[1444/1762] D loss: 0.4378, G loss: 2.7680\n",
      "[1524/1762] D loss: 0.3726, G loss: 2.2225\n",
      "[1604/1762] D loss: 0.5289, G loss: 2.7894\n",
      "[1684/1762] D loss: 0.4119, G loss: 2.5077\n",
      "[1762/1762] D loss: 0.5096, G loss: 2.9390\n",
      "train error: \n",
      " D loss: 0.586197, G loss: 2.881318, D accuracy: 97.4%, cell accuracy: 86.2%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.592426, G loss: 2.953853, D accuracy: 96.9%, cell accuracy: 85.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6688, G loss: 2.6657\n",
      "[84/1762] D loss: 0.4613, G loss: 2.4888\n",
      "[164/1762] D loss: 0.5303, G loss: 2.2751\n",
      "[244/1762] D loss: 0.4010, G loss: 2.2561\n",
      "[324/1762] D loss: 0.3487, G loss: 2.4049\n",
      "[404/1762] D loss: 0.7759, G loss: 2.8676\n",
      "[484/1762] D loss: 0.4027, G loss: 2.3951\n",
      "[564/1762] D loss: 0.6833, G loss: 2.7450\n",
      "[644/1762] D loss: 0.6753, G loss: 2.1578\n",
      "[724/1762] D loss: 0.9528, G loss: 2.2811\n",
      "[804/1762] D loss: 0.6855, G loss: 1.8414\n",
      "[884/1762] D loss: 0.5796, G loss: 2.8057\n",
      "[964/1762] D loss: 0.5928, G loss: 2.3928\n",
      "[1044/1762] D loss: 0.6465, G loss: 2.5196\n",
      "[1124/1762] D loss: 0.3716, G loss: 2.7133\n",
      "[1204/1762] D loss: 0.8281, G loss: 2.3700\n",
      "[1284/1762] D loss: 0.7314, G loss: 2.2320\n",
      "[1364/1762] D loss: 0.6475, G loss: 2.1988\n",
      "[1444/1762] D loss: 0.6377, G loss: 2.3005\n",
      "[1524/1762] D loss: 0.6063, G loss: 2.1582\n",
      "[1604/1762] D loss: 0.6922, G loss: 2.2172\n",
      "[1684/1762] D loss: 0.5852, G loss: 2.7355\n",
      "[1762/1762] D loss: 0.8260, G loss: 2.2128\n",
      "train error: \n",
      " D loss: 0.693452, G loss: 2.218269, D accuracy: 90.8%, cell accuracy: 90.7%, board accuracy: 3.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.695025, G loss: 2.144247, D accuracy: 91.4%, cell accuracy: 91.0%, board accuracy: 3.4% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7120, G loss: 1.9409\n",
      "[84/1762] D loss: 0.6681, G loss: 2.0326\n",
      "[164/1762] D loss: 0.9800, G loss: 2.6161\n",
      "[244/1762] D loss: 0.8124, G loss: 1.9622\n",
      "[324/1762] D loss: 0.7666, G loss: 1.9613\n",
      "[404/1762] D loss: 1.0677, G loss: 2.4014\n",
      "[484/1762] D loss: 0.8026, G loss: 1.9434\n",
      "[564/1762] D loss: 0.8062, G loss: 1.9966\n",
      "[644/1762] D loss: 0.7045, G loss: 2.7310\n",
      "[724/1762] D loss: 0.8386, G loss: 2.5183\n",
      "[804/1762] D loss: 0.7168, G loss: 2.3428\n",
      "[884/1762] D loss: 0.9781, G loss: 2.0031\n",
      "[964/1762] D loss: 0.6649, G loss: 2.2063\n",
      "[1044/1762] D loss: 0.7323, G loss: 2.0233\n",
      "[1124/1762] D loss: 0.9214, G loss: 2.0325\n",
      "[1204/1762] D loss: 1.0043, G loss: 2.0891\n",
      "[1284/1762] D loss: 0.9133, G loss: 1.8269\n",
      "[1364/1762] D loss: 1.0604, G loss: 1.7390\n",
      "[1444/1762] D loss: 0.9423, G loss: 1.9291\n",
      "[1524/1762] D loss: 0.9251, G loss: 2.0409\n",
      "[1604/1762] D loss: 0.9917, G loss: 1.9120\n",
      "[1684/1762] D loss: 0.8417, G loss: 2.2666\n",
      "[1762/1762] D loss: 1.0228, G loss: 2.5521\n",
      "train error: \n",
      " D loss: 0.872767, G loss: 2.192606, D accuracy: 84.7%, cell accuracy: 97.1%, board accuracy: 17.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.892311, G loss: 2.067629, D accuracy: 83.1%, cell accuracy: 97.2%, board accuracy: 15.5% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8997, G loss: 1.9733\n",
      "[84/1762] D loss: 0.8099, G loss: 1.8465\n",
      "[164/1762] D loss: 0.8540, G loss: 1.6067\n",
      "[244/1762] D loss: 0.6080, G loss: 1.8640\n",
      "[324/1762] D loss: 0.7179, G loss: 1.8311\n",
      "[404/1762] D loss: 0.7629, G loss: 2.2472\n",
      "[484/1762] D loss: 0.7991, G loss: 1.6631\n",
      "[564/1762] D loss: 0.8058, G loss: 1.5608\n",
      "[644/1762] D loss: 0.7319, G loss: 1.6585\n",
      "[724/1762] D loss: 0.8145, G loss: 1.5863\n",
      "[804/1762] D loss: 1.0365, G loss: 1.8292\n",
      "[884/1762] D loss: 0.9874, G loss: 1.5303\n",
      "[964/1762] D loss: 0.8935, G loss: 1.5963\n",
      "[1044/1762] D loss: 0.6771, G loss: 2.1497\n",
      "[1124/1762] D loss: 0.7836, G loss: 1.9825\n",
      "[1204/1762] D loss: 0.8588, G loss: 1.5167\n",
      "[1284/1762] D loss: 1.1312, G loss: 1.3233\n",
      "[1364/1762] D loss: 0.8537, G loss: 1.3311\n",
      "[1444/1762] D loss: 1.2207, G loss: 1.4532\n",
      "[1524/1762] D loss: 0.9652, G loss: 1.3625\n",
      "[1604/1762] D loss: 0.9445, G loss: 1.3195\n",
      "[1684/1762] D loss: 0.9926, G loss: 1.5894\n",
      "[1762/1762] D loss: 0.8258, G loss: 1.7841\n",
      "train error: \n",
      " D loss: 1.045649, G loss: 1.239191, D accuracy: 70.8%, cell accuracy: 99.2%, board accuracy: 44.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.034740, G loss: 1.333332, D accuracy: 70.5%, cell accuracy: 99.2%, board accuracy: 37.5% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0508, G loss: 1.2534\n",
      "[84/1762] D loss: 0.9979, G loss: 1.4301\n",
      "[164/1762] D loss: 0.9298, G loss: 1.3590\n",
      "[244/1762] D loss: 1.2057, G loss: 1.6640\n",
      "[324/1762] D loss: 1.0045, G loss: 1.6114\n",
      "[404/1762] D loss: 0.8250, G loss: 1.6597\n",
      "[484/1762] D loss: 0.9988, G loss: 1.4002\n",
      "[564/1762] D loss: 0.9700, G loss: 0.9685\n",
      "[644/1762] D loss: 1.2069, G loss: 1.1755\n",
      "[724/1762] D loss: 1.1819, G loss: 1.5238\n",
      "[804/1762] D loss: 1.0713, G loss: 1.0184\n",
      "[884/1762] D loss: 1.1902, G loss: 0.6453\n",
      "[964/1762] D loss: 1.0423, G loss: 0.9723\n",
      "[1044/1762] D loss: 1.2330, G loss: 0.9128\n",
      "[1124/1762] D loss: 0.8560, G loss: 1.1464\n",
      "[1204/1762] D loss: 1.1206, G loss: 1.3482\n",
      "[1284/1762] D loss: 1.4334, G loss: 1.6890\n",
      "[1364/1762] D loss: 1.1369, G loss: 1.0349\n",
      "[1444/1762] D loss: 1.3970, G loss: 0.9064\n",
      "[1524/1762] D loss: 1.1814, G loss: 0.7862\n",
      "[1604/1762] D loss: 1.3495, G loss: 0.6664\n",
      "[1684/1762] D loss: 1.0752, G loss: 1.0516\n",
      "[1762/1762] D loss: 0.9956, G loss: 0.9726\n",
      "train error: \n",
      " D loss: 1.221350, G loss: 0.747115, D accuracy: 65.2%, cell accuracy: 99.6%, board accuracy: 63.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.222038, G loss: 0.779791, D accuracy: 65.6%, cell accuracy: 99.5%, board accuracy: 59.8% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1505, G loss: 0.6659\n",
      "[84/1762] D loss: 1.2166, G loss: 1.0473\n",
      "[164/1762] D loss: 1.0436, G loss: 1.1663\n",
      "[244/1762] D loss: 1.1628, G loss: 0.9402\n",
      "[324/1762] D loss: 1.2665, G loss: 1.0050\n",
      "[404/1762] D loss: 1.3808, G loss: 0.6616\n",
      "[484/1762] D loss: 1.2427, G loss: 1.0044\n",
      "[564/1762] D loss: 1.1929, G loss: 0.6172\n",
      "[644/1762] D loss: 1.1088, G loss: 0.8702\n",
      "[724/1762] D loss: 1.2655, G loss: 0.6623\n",
      "[804/1762] D loss: 1.1190, G loss: 0.6409\n",
      "[884/1762] D loss: 1.3530, G loss: 0.6321\n",
      "[964/1762] D loss: 1.1535, G loss: 1.0955\n",
      "[1044/1762] D loss: 1.2734, G loss: 0.8820\n",
      "[1124/1762] D loss: 1.2297, G loss: 1.2491\n",
      "[1204/1762] D loss: 1.2604, G loss: 0.9132\n",
      "[1284/1762] D loss: 1.3733, G loss: 0.7640\n",
      "[1364/1762] D loss: 1.3354, G loss: 0.9541\n",
      "[1444/1762] D loss: 1.4889, G loss: 0.7479\n",
      "[1524/1762] D loss: 1.2251, G loss: 0.6827\n",
      "[1604/1762] D loss: 1.2669, G loss: 1.1101\n",
      "[1684/1762] D loss: 1.2910, G loss: 0.8666\n",
      "[1762/1762] D loss: 1.1915, G loss: 0.9762\n",
      "train error: \n",
      " D loss: 1.299941, G loss: 0.904701, D accuracy: 62.4%, cell accuracy: 99.6%, board accuracy: 72.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.311016, G loss: 0.914806, D accuracy: 61.9%, cell accuracy: 99.6%, board accuracy: 71.4% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3594, G loss: 0.9368\n",
      "[84/1762] D loss: 1.3284, G loss: 0.8665\n",
      "[164/1762] D loss: 1.4388, G loss: 1.3046\n",
      "[244/1762] D loss: 1.2051, G loss: 0.7207\n",
      "[324/1762] D loss: 1.2614, G loss: 0.8903\n",
      "[404/1762] D loss: 1.2713, G loss: 0.8970\n",
      "[484/1762] D loss: 1.3887, G loss: 0.5632\n",
      "[564/1762] D loss: 1.3425, G loss: 1.0756\n",
      "[644/1762] D loss: 1.2836, G loss: 0.7846\n",
      "[724/1762] D loss: 1.3624, G loss: 0.6446\n",
      "[804/1762] D loss: 1.2187, G loss: 0.8157\n",
      "[884/1762] D loss: 1.3947, G loss: 0.8016\n",
      "[964/1762] D loss: 1.2976, G loss: 0.8998\n",
      "[1044/1762] D loss: 1.3210, G loss: 0.8155\n",
      "[1124/1762] D loss: 1.2421, G loss: 0.7826\n",
      "[1204/1762] D loss: 1.3042, G loss: 0.5714\n",
      "[1284/1762] D loss: 1.2777, G loss: 0.8054\n",
      "[1364/1762] D loss: 1.1703, G loss: 0.7425\n",
      "[1444/1762] D loss: 1.3551, G loss: 0.8219\n",
      "[1524/1762] D loss: 1.3679, G loss: 0.4363\n",
      "[1604/1762] D loss: 1.3590, G loss: 0.6520\n",
      "[1684/1762] D loss: 1.3530, G loss: 0.6061\n",
      "[1762/1762] D loss: 1.1051, G loss: 0.9183\n",
      "train error: \n",
      " D loss: 1.364167, G loss: 0.662856, D accuracy: 57.3%, cell accuracy: 99.7%, board accuracy: 75.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.372239, G loss: 0.669811, D accuracy: 58.1%, cell accuracy: 99.6%, board accuracy: 73.9% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4195, G loss: 0.3842\n",
      "[84/1762] D loss: 1.3693, G loss: 0.6790\n",
      "[164/1762] D loss: 1.3664, G loss: 0.6209\n",
      "[244/1762] D loss: 1.7502, G loss: 0.4863\n",
      "[324/1762] D loss: 1.2557, G loss: 0.6920\n",
      "[404/1762] D loss: 1.3353, G loss: 0.5826\n",
      "[484/1762] D loss: 1.3895, G loss: 0.6329\n",
      "[564/1762] D loss: 1.3241, G loss: 0.6052\n",
      "[644/1762] D loss: 1.3555, G loss: 0.9371\n",
      "[724/1762] D loss: 1.3259, G loss: 0.6460\n",
      "[804/1762] D loss: 1.4547, G loss: 1.0005\n",
      "[884/1762] D loss: 1.3270, G loss: 0.7847\n",
      "[964/1762] D loss: 1.4349, G loss: 0.6606\n",
      "[1044/1762] D loss: 1.4411, G loss: 0.5920\n",
      "[1124/1762] D loss: 1.4858, G loss: 0.4690\n",
      "[1204/1762] D loss: 1.3974, G loss: 0.5009\n",
      "[1284/1762] D loss: 1.4016, G loss: 0.5936\n",
      "[1364/1762] D loss: 1.2658, G loss: 0.7469\n",
      "[1444/1762] D loss: 1.3238, G loss: 0.7313\n",
      "[1524/1762] D loss: 1.4394, G loss: 0.4396\n",
      "[1604/1762] D loss: 1.4035, G loss: 0.4912\n",
      "[1684/1762] D loss: 1.3033, G loss: 0.7461\n",
      "[1762/1762] D loss: 1.2640, G loss: 0.6435\n",
      "train error: \n",
      " D loss: 1.375582, G loss: 0.650774, D accuracy: 54.9%, cell accuracy: 99.6%, board accuracy: 65.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.399722, G loss: 0.632168, D accuracy: 53.6%, cell accuracy: 99.6%, board accuracy: 66.4% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4259, G loss: 0.5542\n",
      "[84/1762] D loss: 1.4122, G loss: 0.8115\n",
      "[164/1762] D loss: 1.4417, G loss: 0.8592\n",
      "[244/1762] D loss: 1.5199, G loss: 0.5613\n",
      "[324/1762] D loss: 1.3889, G loss: 0.8058\n",
      "[404/1762] D loss: 1.6373, G loss: 0.5950\n",
      "[484/1762] D loss: 1.5247, G loss: 0.4902\n",
      "[564/1762] D loss: 1.2622, G loss: 0.8628\n",
      "[644/1762] D loss: 1.3411, G loss: 0.7533\n",
      "[724/1762] D loss: 1.3468, G loss: 0.7599\n",
      "[804/1762] D loss: 1.3423, G loss: 0.7117\n",
      "[884/1762] D loss: 1.2344, G loss: 0.8908\n",
      "[964/1762] D loss: 1.3412, G loss: 0.7421\n",
      "[1044/1762] D loss: 1.2867, G loss: 0.7728\n",
      "[1124/1762] D loss: 1.3575, G loss: 0.8033\n",
      "[1204/1762] D loss: 1.4750, G loss: 0.5117\n",
      "[1284/1762] D loss: 1.3484, G loss: 0.6034\n",
      "[1364/1762] D loss: 1.4407, G loss: 0.5712\n",
      "[1444/1762] D loss: 1.3489, G loss: 0.5818\n",
      "[1524/1762] D loss: 1.2827, G loss: 0.7146\n",
      "[1604/1762] D loss: 1.3607, G loss: 0.5696\n",
      "[1684/1762] D loss: 1.4861, G loss: 0.5324\n",
      "[1762/1762] D loss: 1.3305, G loss: 0.7080\n",
      "train error: \n",
      " D loss: 1.369366, G loss: 0.721469, D accuracy: 54.9%, cell accuracy: 99.6%, board accuracy: 63.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.384174, G loss: 0.712598, D accuracy: 54.5%, cell accuracy: 99.5%, board accuracy: 60.9% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5273, G loss: 0.6834\n",
      "[84/1762] D loss: 1.3803, G loss: 0.7320\n",
      "[164/1762] D loss: 1.3238, G loss: 0.9548\n",
      "[244/1762] D loss: 1.4089, G loss: 0.8803\n",
      "[324/1762] D loss: 1.4741, G loss: 1.1012\n",
      "[404/1762] D loss: 1.4804, G loss: 0.5517\n",
      "[484/1762] D loss: 1.3803, G loss: 0.6807\n",
      "[564/1762] D loss: 1.3560, G loss: 0.9163\n",
      "[644/1762] D loss: 1.4795, G loss: 0.4298\n",
      "[724/1762] D loss: 1.4170, G loss: 0.7641\n",
      "[804/1762] D loss: 1.3644, G loss: 0.7591\n",
      "[884/1762] D loss: 1.4088, G loss: 0.7189\n",
      "[964/1762] D loss: 1.4249, G loss: 0.8315\n",
      "[1044/1762] D loss: 1.3576, G loss: 0.5654\n",
      "[1124/1762] D loss: 1.4206, G loss: 0.6380\n",
      "[1204/1762] D loss: 1.3825, G loss: 0.6796\n",
      "[1284/1762] D loss: 1.3988, G loss: 0.8220\n",
      "[1364/1762] D loss: 1.4008, G loss: 0.7464\n",
      "[1444/1762] D loss: 1.2510, G loss: 0.9691\n",
      "[1524/1762] D loss: 1.4074, G loss: 0.8202\n",
      "[1604/1762] D loss: 1.3391, G loss: 0.7523\n",
      "[1684/1762] D loss: 1.4408, G loss: 0.7945\n",
      "[1762/1762] D loss: 1.3449, G loss: 0.7585\n",
      "train error: \n",
      " D loss: 1.382922, G loss: 0.799589, D accuracy: 53.8%, cell accuracy: 99.6%, board accuracy: 63.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.383593, G loss: 0.817871, D accuracy: 55.5%, cell accuracy: 99.5%, board accuracy: 58.9% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3999, G loss: 0.8016\n",
      "[84/1762] D loss: 1.3589, G loss: 0.8061\n",
      "[164/1762] D loss: 1.5057, G loss: 0.4990\n",
      "[244/1762] D loss: 1.3914, G loss: 0.6345\n",
      "[324/1762] D loss: 1.3480, G loss: 0.7661\n",
      "[404/1762] D loss: 1.3600, G loss: 0.7349\n",
      "[484/1762] D loss: 1.4386, G loss: 0.6414\n",
      "[564/1762] D loss: 1.4008, G loss: 0.7281\n",
      "[644/1762] D loss: 1.3775, G loss: 0.6919\n",
      "[724/1762] D loss: 1.3229, G loss: 0.7741\n",
      "[804/1762] D loss: 1.4559, G loss: 0.5654\n",
      "[884/1762] D loss: 1.3469, G loss: 0.7192\n",
      "[964/1762] D loss: 1.6350, G loss: 0.7718\n",
      "[1044/1762] D loss: 1.3232, G loss: 0.6530\n",
      "[1124/1762] D loss: 1.4551, G loss: 0.6928\n",
      "[1204/1762] D loss: 1.3464, G loss: 0.8464\n",
      "[1284/1762] D loss: 1.3282, G loss: 0.8048\n",
      "[1364/1762] D loss: 1.4057, G loss: 0.6615\n",
      "[1444/1762] D loss: 1.5422, G loss: 0.3829\n",
      "[1524/1762] D loss: 1.4057, G loss: 0.8066\n",
      "[1604/1762] D loss: 1.3732, G loss: 0.7980\n",
      "[1684/1762] D loss: 1.3911, G loss: 0.6986\n",
      "[1762/1762] D loss: 1.6097, G loss: 0.8444\n",
      "train error: \n",
      " D loss: 1.368775, G loss: 0.698206, D accuracy: 54.0%, cell accuracy: 99.6%, board accuracy: 62.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.368744, G loss: 0.716479, D accuracy: 52.8%, cell accuracy: 99.5%, board accuracy: 61.4% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3397, G loss: 0.6206\n",
      "[84/1762] D loss: 1.3312, G loss: 0.5974\n",
      "[164/1762] D loss: 1.3906, G loss: 0.7434\n",
      "[244/1762] D loss: 1.4249, G loss: 0.7921\n",
      "[324/1762] D loss: 1.4162, G loss: 0.5215\n",
      "[404/1762] D loss: 1.5060, G loss: 0.4948\n",
      "[484/1762] D loss: 1.2804, G loss: 0.7001\n",
      "[564/1762] D loss: 1.4031, G loss: 0.8353\n",
      "[644/1762] D loss: 1.3322, G loss: 0.9015\n",
      "[724/1762] D loss: 1.3788, G loss: 0.8102\n",
      "[804/1762] D loss: 1.5050, G loss: 0.5743\n",
      "[884/1762] D loss: 1.4666, G loss: 0.6022\n",
      "[964/1762] D loss: 1.3951, G loss: 0.8266\n",
      "[1044/1762] D loss: 1.3731, G loss: 0.6559\n",
      "[1124/1762] D loss: 1.4075, G loss: 0.6960\n",
      "[1204/1762] D loss: 1.3770, G loss: 0.6272\n",
      "[1284/1762] D loss: 1.3654, G loss: 0.7913\n",
      "[1364/1762] D loss: 1.4046, G loss: 0.8961\n",
      "[1444/1762] D loss: 1.3730, G loss: 0.8095\n",
      "[1524/1762] D loss: 1.4739, G loss: 0.8677\n",
      "[1604/1762] D loss: 1.3285, G loss: 0.9515\n",
      "[1684/1762] D loss: 1.4404, G loss: 0.8136\n",
      "[1762/1762] D loss: 1.3989, G loss: 0.8303\n",
      "train error: \n",
      " D loss: 1.388453, G loss: 0.680365, D accuracy: 52.4%, cell accuracy: 99.6%, board accuracy: 67.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.395467, G loss: 0.685041, D accuracy: 51.8%, cell accuracy: 99.6%, board accuracy: 66.4% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3725, G loss: 0.6603\n",
      "[84/1762] D loss: 1.3282, G loss: 0.7228\n",
      "[164/1762] D loss: 1.3677, G loss: 0.6182\n",
      "[244/1762] D loss: 1.3931, G loss: 0.6341\n",
      "[324/1762] D loss: 1.4073, G loss: 0.7563\n",
      "[404/1762] D loss: 1.3997, G loss: 0.8421\n",
      "[484/1762] D loss: 1.4816, G loss: 0.7552\n",
      "[564/1762] D loss: 1.4485, G loss: 0.6811\n",
      "[644/1762] D loss: 1.3649, G loss: 0.6379\n",
      "[724/1762] D loss: 1.3493, G loss: 0.7367\n",
      "[804/1762] D loss: 1.4019, G loss: 0.8055\n",
      "[884/1762] D loss: 1.4202, G loss: 0.5814\n",
      "[964/1762] D loss: 1.4716, G loss: 0.8731\n",
      "[1044/1762] D loss: 1.4536, G loss: 0.8432\n",
      "[1124/1762] D loss: 1.3745, G loss: 0.7535\n",
      "[1204/1762] D loss: 1.3801, G loss: 0.7614\n",
      "[1284/1762] D loss: 1.3970, G loss: 0.7372\n",
      "[1364/1762] D loss: 1.3826, G loss: 0.7148\n",
      "[1444/1762] D loss: 1.4329, G loss: 0.9401\n",
      "[1524/1762] D loss: 1.3823, G loss: 0.8793\n",
      "[1604/1762] D loss: 1.3771, G loss: 0.7414\n",
      "[1684/1762] D loss: 1.3839, G loss: 0.7658\n",
      "[1762/1762] D loss: 1.3454, G loss: 0.8542\n",
      "train error: \n",
      " D loss: 1.384060, G loss: 0.774980, D accuracy: 52.3%, cell accuracy: 99.6%, board accuracy: 68.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.389427, G loss: 0.785075, D accuracy: 53.1%, cell accuracy: 99.6%, board accuracy: 67.3% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3804, G loss: 0.8456\n",
      "[84/1762] D loss: 1.4071, G loss: 0.5592\n",
      "[164/1762] D loss: 1.4173, G loss: 0.5295\n",
      "[244/1762] D loss: 1.3893, G loss: 0.6446\n",
      "[324/1762] D loss: 1.3862, G loss: 0.6581\n",
      "[404/1762] D loss: 1.3140, G loss: 0.7384\n",
      "[484/1762] D loss: 1.3754, G loss: 0.7227\n",
      "[564/1762] D loss: 1.3687, G loss: 1.0883\n",
      "[644/1762] D loss: 1.3272, G loss: 0.9535\n",
      "[724/1762] D loss: 1.4347, G loss: 0.7684\n",
      "[804/1762] D loss: 1.3794, G loss: 0.6788\n",
      "[884/1762] D loss: 1.3239, G loss: 1.0201\n",
      "[964/1762] D loss: 1.3634, G loss: 0.6632\n",
      "[1044/1762] D loss: 1.3942, G loss: 0.8161\n",
      "[1124/1762] D loss: 1.3771, G loss: 0.6942\n",
      "[1204/1762] D loss: 1.3836, G loss: 0.7259\n",
      "[1284/1762] D loss: 1.3713, G loss: 0.6391\n",
      "[1364/1762] D loss: 1.3747, G loss: 0.6281\n",
      "[1444/1762] D loss: 1.4221, G loss: 0.6599\n",
      "[1524/1762] D loss: 1.3742, G loss: 0.6584\n",
      "[1604/1762] D loss: 1.4202, G loss: 0.7815\n",
      "[1684/1762] D loss: 1.4135, G loss: 0.6986\n",
      "[1762/1762] D loss: 1.3951, G loss: 0.7331\n",
      "train error: \n",
      " D loss: 1.374380, G loss: 0.679192, D accuracy: 54.5%, cell accuracy: 99.6%, board accuracy: 68.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.386800, G loss: 0.673206, D accuracy: 52.0%, cell accuracy: 99.6%, board accuracy: 68.0% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3911, G loss: 0.5876\n",
      "[84/1762] D loss: 1.4164, G loss: 0.6106\n",
      "[164/1762] D loss: 1.4280, G loss: 0.5351\n",
      "[244/1762] D loss: 1.3316, G loss: 0.8404\n",
      "[324/1762] D loss: 1.3808, G loss: 0.6407\n",
      "[404/1762] D loss: 1.4430, G loss: 0.5168\n",
      "[484/1762] D loss: 1.3862, G loss: 0.9048\n",
      "[564/1762] D loss: 1.3383, G loss: 0.6192\n",
      "[644/1762] D loss: 1.3807, G loss: 0.6212\n",
      "[724/1762] D loss: 1.3372, G loss: 0.8150\n",
      "[804/1762] D loss: 1.3932, G loss: 0.6492\n",
      "[884/1762] D loss: 1.3990, G loss: 0.6592\n",
      "[964/1762] D loss: 1.3427, G loss: 0.6737\n",
      "[1044/1762] D loss: 1.4291, G loss: 0.8340\n",
      "[1124/1762] D loss: 1.3990, G loss: 0.7322\n",
      "[1204/1762] D loss: 1.3697, G loss: 0.6195\n",
      "[1284/1762] D loss: 1.3984, G loss: 0.5705\n",
      "[1364/1762] D loss: 1.3993, G loss: 0.8418\n",
      "[1444/1762] D loss: 1.3991, G loss: 0.8556\n",
      "[1524/1762] D loss: 1.4233, G loss: 0.6007\n",
      "[1604/1762] D loss: 1.3872, G loss: 0.7725\n",
      "[1684/1762] D loss: 1.3804, G loss: 0.7177\n",
      "[1762/1762] D loss: 1.4165, G loss: 0.8353\n",
      "train error: \n",
      " D loss: 1.406714, G loss: 0.970448, D accuracy: 50.5%, cell accuracy: 99.6%, board accuracy: 67.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.412945, G loss: 0.985288, D accuracy: 50.7%, cell accuracy: 99.5%, board accuracy: 66.8% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4138, G loss: 0.8449\n",
      "[84/1762] D loss: 1.3797, G loss: 0.7378\n",
      "[164/1762] D loss: 1.3929, G loss: 0.7209\n",
      "[244/1762] D loss: 1.3790, G loss: 0.7456\n",
      "[324/1762] D loss: 1.3723, G loss: 0.8842\n",
      "[404/1762] D loss: 1.4974, G loss: 0.9827\n",
      "[484/1762] D loss: 1.3954, G loss: 0.7751\n",
      "[564/1762] D loss: 1.4451, G loss: 0.7593\n",
      "[644/1762] D loss: 1.3205, G loss: 0.6989\n",
      "[724/1762] D loss: 1.3820, G loss: 0.7732\n",
      "[804/1762] D loss: 1.3653, G loss: 0.8330\n",
      "[884/1762] D loss: 1.4220, G loss: 0.6733\n",
      "[964/1762] D loss: 1.4143, G loss: 0.5622\n",
      "[1044/1762] D loss: 1.4519, G loss: 0.6632\n",
      "[1124/1762] D loss: 1.3995, G loss: 0.5834\n",
      "[1204/1762] D loss: 1.3941, G loss: 0.7028\n",
      "[1284/1762] D loss: 1.3938, G loss: 0.6084\n",
      "[1364/1762] D loss: 1.4032, G loss: 0.6736\n",
      "[1444/1762] D loss: 1.4103, G loss: 0.6011\n",
      "[1524/1762] D loss: 1.3891, G loss: 0.6496\n",
      "[1604/1762] D loss: 1.3742, G loss: 0.8607\n",
      "[1684/1762] D loss: 1.3119, G loss: 0.8100\n",
      "[1762/1762] D loss: 1.4051, G loss: 0.7328\n",
      "train error: \n",
      " D loss: 1.369012, G loss: 0.799783, D accuracy: 52.7%, cell accuracy: 99.6%, board accuracy: 66.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.370276, G loss: 0.816947, D accuracy: 53.1%, cell accuracy: 99.6%, board accuracy: 66.6% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3114, G loss: 0.7961\n",
      "[84/1762] D loss: 1.3761, G loss: 0.6891\n",
      "[164/1762] D loss: 1.3900, G loss: 0.7419\n",
      "[244/1762] D loss: 1.4835, G loss: 0.6478\n",
      "[324/1762] D loss: 1.4049, G loss: 0.5784\n",
      "[404/1762] D loss: 1.3975, G loss: 0.5534\n",
      "[484/1762] D loss: 1.3701, G loss: 0.7915\n",
      "[564/1762] D loss: 1.3616, G loss: 0.7388\n",
      "[644/1762] D loss: 1.3933, G loss: 0.8349\n",
      "[724/1762] D loss: 1.3772, G loss: 0.7074\n",
      "[804/1762] D loss: 1.3686, G loss: 0.7597\n",
      "[884/1762] D loss: 1.3831, G loss: 0.8205\n",
      "[964/1762] D loss: 1.3949, G loss: 0.7539\n",
      "[1044/1762] D loss: 1.3287, G loss: 0.8534\n",
      "[1124/1762] D loss: 1.4182, G loss: 0.7507\n",
      "[1204/1762] D loss: 1.4071, G loss: 0.8101\n",
      "[1284/1762] D loss: 1.3665, G loss: 0.8604\n",
      "[1364/1762] D loss: 1.3875, G loss: 0.5804\n",
      "[1444/1762] D loss: 1.4423, G loss: 0.5687\n",
      "[1524/1762] D loss: 1.3596, G loss: 0.7793\n",
      "[1604/1762] D loss: 1.3522, G loss: 0.6180\n",
      "[1684/1762] D loss: 1.3523, G loss: 0.7843\n",
      "[1762/1762] D loss: 1.4400, G loss: 0.6680\n",
      "train error: \n",
      " D loss: 1.365976, G loss: 0.679572, D accuracy: 55.4%, cell accuracy: 99.5%, board accuracy: 56.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.367034, G loss: 0.686695, D accuracy: 54.5%, cell accuracy: 99.5%, board accuracy: 54.1% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3947, G loss: 0.6438\n",
      "[84/1762] D loss: 1.3764, G loss: 0.6241\n",
      "[164/1762] D loss: 1.3406, G loss: 0.7069\n",
      "[244/1762] D loss: 1.3775, G loss: 0.5637\n",
      "[324/1762] D loss: 1.3335, G loss: 0.6295\n",
      "[404/1762] D loss: 1.4070, G loss: 0.8381\n",
      "[484/1762] D loss: 1.2745, G loss: 0.6987\n",
      "[564/1762] D loss: 1.3783, G loss: 0.7106\n",
      "[644/1762] D loss: 1.3341, G loss: 0.7443\n",
      "[724/1762] D loss: 1.5176, G loss: 0.6754\n",
      "[804/1762] D loss: 1.3944, G loss: 0.7547\n",
      "[884/1762] D loss: 1.4074, G loss: 0.5676\n",
      "[964/1762] D loss: 1.3608, G loss: 0.5899\n",
      "[1044/1762] D loss: 1.4179, G loss: 0.7609\n",
      "[1124/1762] D loss: 1.4089, G loss: 0.5677\n",
      "[1204/1762] D loss: 1.4557, G loss: 0.5778\n",
      "[1284/1762] D loss: 1.3781, G loss: 0.6857\n",
      "[1364/1762] D loss: 1.4970, G loss: 0.6963\n",
      "[1444/1762] D loss: 1.3957, G loss: 0.7153\n",
      "[1524/1762] D loss: 1.3947, G loss: 0.6851\n",
      "[1604/1762] D loss: 1.2927, G loss: 0.8391\n",
      "[1684/1762] D loss: 1.3770, G loss: 0.7388\n",
      "[1762/1762] D loss: 1.3980, G loss: 0.7328\n",
      "train error: \n",
      " D loss: 1.390321, G loss: 0.828896, D accuracy: 51.1%, cell accuracy: 99.7%, board accuracy: 70.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.395220, G loss: 0.835266, D accuracy: 51.1%, cell accuracy: 99.6%, board accuracy: 68.9% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3741, G loss: 0.7115\n",
      "[84/1762] D loss: 1.4264, G loss: 0.7695\n",
      "[164/1762] D loss: 1.3420, G loss: 0.5990\n",
      "[244/1762] D loss: 1.3093, G loss: 0.8028\n",
      "[324/1762] D loss: 1.3022, G loss: 0.8328\n",
      "[404/1762] D loss: 1.3972, G loss: 0.7979\n",
      "[484/1762] D loss: 1.3858, G loss: 0.7534\n",
      "[564/1762] D loss: 1.3187, G loss: 0.8439\n",
      "[644/1762] D loss: 1.3529, G loss: 0.7634\n",
      "[724/1762] D loss: 1.3625, G loss: 0.6250\n",
      "[804/1762] D loss: 1.4241, G loss: 0.5247\n",
      "[884/1762] D loss: 1.3689, G loss: 0.7082\n",
      "[964/1762] D loss: 1.3606, G loss: 0.7050\n",
      "[1044/1762] D loss: 1.3855, G loss: 0.8748\n",
      "[1124/1762] D loss: 1.3921, G loss: 0.7754\n",
      "[1204/1762] D loss: 1.4203, G loss: 0.6138\n",
      "[1284/1762] D loss: 1.4087, G loss: 0.8058\n",
      "[1364/1762] D loss: 1.3855, G loss: 0.7859\n",
      "[1444/1762] D loss: 1.3941, G loss: 0.6887\n",
      "[1524/1762] D loss: 1.3503, G loss: 0.9356\n",
      "[1604/1762] D loss: 1.4177, G loss: 0.7755\n",
      "[1684/1762] D loss: 1.3965, G loss: 0.8049\n",
      "[1762/1762] D loss: 1.3452, G loss: 0.8666\n",
      "train error: \n",
      " D loss: 1.369415, G loss: 0.809431, D accuracy: 51.5%, cell accuracy: 99.6%, board accuracy: 66.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.375741, G loss: 0.807173, D accuracy: 51.4%, cell accuracy: 99.6%, board accuracy: 66.4% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3892, G loss: 0.6983\n",
      "[84/1762] D loss: 1.4241, G loss: 0.8785\n",
      "[164/1762] D loss: 1.3766, G loss: 0.8823\n",
      "[244/1762] D loss: 1.3823, G loss: 0.9113\n",
      "[324/1762] D loss: 1.3943, G loss: 0.7375\n",
      "[404/1762] D loss: 1.3336, G loss: 0.7489\n",
      "[484/1762] D loss: 1.3877, G loss: 0.7242\n",
      "[564/1762] D loss: 1.4193, G loss: 0.7276\n",
      "[644/1762] D loss: 1.3817, G loss: 0.7987\n",
      "[724/1762] D loss: 1.3998, G loss: 0.6005\n",
      "[804/1762] D loss: 1.3714, G loss: 0.6994\n",
      "[884/1762] D loss: 1.3879, G loss: 0.6214\n",
      "[964/1762] D loss: 1.3879, G loss: 0.7606\n",
      "[1044/1762] D loss: 1.3841, G loss: 0.7528\n",
      "[1124/1762] D loss: 1.4537, G loss: 0.7025\n",
      "[1204/1762] D loss: 1.3982, G loss: 0.7844\n",
      "[1284/1762] D loss: 1.3915, G loss: 0.7516\n",
      "[1364/1762] D loss: 1.3157, G loss: 0.6819\n",
      "[1444/1762] D loss: 1.4356, G loss: 0.6834\n",
      "[1524/1762] D loss: 1.2729, G loss: 0.7757\n",
      "[1604/1762] D loss: 1.3932, G loss: 0.6649\n",
      "[1684/1762] D loss: 1.3954, G loss: 0.6438\n",
      "[1762/1762] D loss: 1.3828, G loss: 0.6422\n",
      "train error: \n",
      " D loss: 1.378419, G loss: 0.646139, D accuracy: 53.9%, cell accuracy: 99.7%, board accuracy: 70.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.379848, G loss: 0.653348, D accuracy: 53.1%, cell accuracy: 99.6%, board accuracy: 70.0% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3297, G loss: 0.7581\n",
      "[84/1762] D loss: 1.3879, G loss: 0.6240\n",
      "[164/1762] D loss: 1.4401, G loss: 0.5757\n",
      "[244/1762] D loss: 1.4265, G loss: 0.6269\n",
      "[324/1762] D loss: 1.3919, G loss: 0.6972\n",
      "[404/1762] D loss: 1.3922, G loss: 0.7759\n",
      "[484/1762] D loss: 1.4094, G loss: 0.8309\n",
      "[564/1762] D loss: 1.2727, G loss: 0.6435\n",
      "[644/1762] D loss: 1.4298, G loss: 0.5974\n",
      "[724/1762] D loss: 1.4240, G loss: 0.7645\n",
      "[804/1762] D loss: 1.3756, G loss: 0.7525\n",
      "[884/1762] D loss: 1.3782, G loss: 0.6441\n",
      "[964/1762] D loss: 1.3925, G loss: 0.6612\n",
      "[1044/1762] D loss: 1.3930, G loss: 0.7694\n",
      "[1124/1762] D loss: 1.3798, G loss: 0.8582\n",
      "[1204/1762] D loss: 1.4133, G loss: 0.5964\n",
      "[1284/1762] D loss: 1.3405, G loss: 0.7224\n",
      "[1364/1762] D loss: 1.4046, G loss: 0.6365\n",
      "[1444/1762] D loss: 1.3799, G loss: 0.5401\n",
      "[1524/1762] D loss: 1.3886, G loss: 0.5459\n",
      "[1604/1762] D loss: 1.3751, G loss: 0.5897\n",
      "[1684/1762] D loss: 1.4112, G loss: 0.6359\n",
      "[1762/1762] D loss: 1.4142, G loss: 0.7010\n",
      "train error: \n",
      " D loss: 1.382420, G loss: 0.832474, D accuracy: 51.0%, cell accuracy: 99.6%, board accuracy: 66.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.385225, G loss: 0.838975, D accuracy: 50.8%, cell accuracy: 99.6%, board accuracy: 64.5% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3897, G loss: 0.7982\n",
      "[84/1762] D loss: 1.4204, G loss: 0.6221\n",
      "[164/1762] D loss: 1.3886, G loss: 0.7281\n",
      "[244/1762] D loss: 1.4038, G loss: 0.7151\n",
      "[324/1762] D loss: 1.3960, G loss: 0.7706\n",
      "[404/1762] D loss: 1.4074, G loss: 0.6717\n",
      "[484/1762] D loss: 1.3907, G loss: 0.6733\n",
      "[564/1762] D loss: 1.3494, G loss: 0.7020\n",
      "[644/1762] D loss: 1.3746, G loss: 0.6807\n",
      "[724/1762] D loss: 1.4254, G loss: 0.7654\n",
      "[804/1762] D loss: 1.3894, G loss: 0.6651\n",
      "[884/1762] D loss: 1.3916, G loss: 0.6437\n",
      "[964/1762] D loss: 1.3859, G loss: 0.6846\n",
      "[1044/1762] D loss: 1.3718, G loss: 0.7367\n",
      "[1124/1762] D loss: 1.3983, G loss: 0.6020\n",
      "[1204/1762] D loss: 1.4215, G loss: 0.5674\n",
      "[1284/1762] D loss: 1.3944, G loss: 0.6211\n",
      "[1364/1762] D loss: 1.4104, G loss: 0.5893\n",
      "[1444/1762] D loss: 1.3372, G loss: 0.6722\n",
      "[1524/1762] D loss: 1.3901, G loss: 0.5954\n",
      "[1604/1762] D loss: 1.3971, G loss: 0.6052\n",
      "[1684/1762] D loss: 1.4173, G loss: 0.8268\n",
      "[1762/1762] D loss: 1.3912, G loss: 0.6604\n",
      "train error: \n",
      " D loss: 1.374357, G loss: 0.692682, D accuracy: 52.7%, cell accuracy: 99.7%, board accuracy: 70.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.377287, G loss: 0.696334, D accuracy: 51.9%, cell accuracy: 99.6%, board accuracy: 68.2% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3993, G loss: 0.6932\n",
      "[84/1762] D loss: 1.3724, G loss: 0.6876\n",
      "[164/1762] D loss: 1.3249, G loss: 0.6477\n",
      "[244/1762] D loss: 1.3519, G loss: 0.6923\n",
      "[324/1762] D loss: 1.3757, G loss: 0.6873\n",
      "[404/1762] D loss: 1.3805, G loss: 0.6519\n",
      "[484/1762] D loss: 1.3980, G loss: 0.6790\n",
      "[564/1762] D loss: 1.3764, G loss: 0.6884\n",
      "[644/1762] D loss: 1.3647, G loss: 0.8533\n",
      "[724/1762] D loss: 1.3845, G loss: 0.6886\n",
      "[804/1762] D loss: 1.3926, G loss: 0.7130\n",
      "[884/1762] D loss: 1.3787, G loss: 0.6211\n",
      "[964/1762] D loss: 1.3021, G loss: 0.8096\n",
      "[1044/1762] D loss: 1.3330, G loss: 0.7228\n",
      "[1124/1762] D loss: 1.3499, G loss: 0.7725\n",
      "[1204/1762] D loss: 1.3508, G loss: 0.7985\n",
      "[1284/1762] D loss: 1.3554, G loss: 0.8661\n",
      "[1364/1762] D loss: 1.3815, G loss: 0.8296\n",
      "[1444/1762] D loss: 1.3448, G loss: 0.8766\n",
      "[1524/1762] D loss: 1.3567, G loss: 0.7259\n",
      "[1604/1762] D loss: 1.3994, G loss: 0.7797\n",
      "[1684/1762] D loss: 1.3917, G loss: 0.6867\n",
      "[1762/1762] D loss: 1.1361, G loss: 0.8570\n",
      "train error: \n",
      " D loss: 1.375315, G loss: 0.624934, D accuracy: 55.3%, cell accuracy: 99.6%, board accuracy: 63.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.368581, G loss: 0.639793, D accuracy: 54.5%, cell accuracy: 99.6%, board accuracy: 62.5% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4013, G loss: 0.5639\n",
      "[84/1762] D loss: 1.3440, G loss: 0.6690\n",
      "[164/1762] D loss: 1.4345, G loss: 0.6849\n",
      "[244/1762] D loss: 1.4163, G loss: 0.7505\n",
      "[324/1762] D loss: 1.3309, G loss: 0.7436\n",
      "[404/1762] D loss: 1.3370, G loss: 0.9099\n",
      "[484/1762] D loss: 1.3823, G loss: 0.7964\n",
      "[564/1762] D loss: 1.3553, G loss: 0.7503\n",
      "[644/1762] D loss: 1.3741, G loss: 0.6680\n",
      "[724/1762] D loss: 1.3080, G loss: 0.8044\n",
      "[804/1762] D loss: 1.3910, G loss: 0.6200\n",
      "[884/1762] D loss: 1.3851, G loss: 0.7375\n",
      "[964/1762] D loss: 1.3488, G loss: 0.8187\n",
      "[1044/1762] D loss: 1.4399, G loss: 0.9682\n",
      "[1124/1762] D loss: 1.3833, G loss: 0.5941\n",
      "[1204/1762] D loss: 1.3366, G loss: 0.7481\n",
      "[1284/1762] D loss: 1.3715, G loss: 0.8720\n",
      "[1364/1762] D loss: 1.2479, G loss: 0.8024\n",
      "[1444/1762] D loss: 1.3940, G loss: 0.7042\n",
      "[1524/1762] D loss: 1.3818, G loss: 0.7053\n",
      "[1604/1762] D loss: 1.3862, G loss: 0.6910\n",
      "[1684/1762] D loss: 1.2597, G loss: 0.8907\n",
      "[1762/1762] D loss: 1.2727, G loss: 0.6902\n",
      "train error: \n",
      " D loss: 1.367457, G loss: 0.639742, D accuracy: 56.5%, cell accuracy: 99.5%, board accuracy: 51.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.361206, G loss: 0.649852, D accuracy: 56.0%, cell accuracy: 99.5%, board accuracy: 48.4% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3861, G loss: 0.6458\n",
      "[84/1762] D loss: 1.3507, G loss: 0.6352\n",
      "[164/1762] D loss: 1.4369, G loss: 0.6146\n",
      "[244/1762] D loss: 1.3045, G loss: 0.7096\n",
      "[324/1762] D loss: 1.3454, G loss: 0.6874\n",
      "[404/1762] D loss: 1.4225, G loss: 0.6470\n",
      "[484/1762] D loss: 1.3945, G loss: 0.6778\n",
      "[564/1762] D loss: 1.3870, G loss: 0.6521\n",
      "[644/1762] D loss: 1.4144, G loss: 0.6863\n",
      "[724/1762] D loss: 1.3846, G loss: 0.8314\n",
      "[804/1762] D loss: 1.2762, G loss: 0.7678\n",
      "[884/1762] D loss: 1.4338, G loss: 0.7839\n",
      "[964/1762] D loss: 1.3682, G loss: 0.7110\n",
      "[1044/1762] D loss: 1.3624, G loss: 0.7990\n",
      "[1124/1762] D loss: 1.2764, G loss: 0.8055\n",
      "[1204/1762] D loss: 1.4124, G loss: 0.7802\n",
      "[1284/1762] D loss: 1.3978, G loss: 0.5963\n",
      "[1364/1762] D loss: 1.3973, G loss: 0.6595\n",
      "[1444/1762] D loss: 1.4174, G loss: 0.8667\n",
      "[1524/1762] D loss: 1.3835, G loss: 0.6448\n",
      "[1604/1762] D loss: 1.3892, G loss: 0.6620\n",
      "[1684/1762] D loss: 1.3445, G loss: 0.6971\n",
      "[1762/1762] D loss: 1.4502, G loss: 0.9656\n",
      "train error: \n",
      " D loss: 1.376901, G loss: 0.768341, D accuracy: 51.6%, cell accuracy: 99.6%, board accuracy: 61.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.379080, G loss: 0.774300, D accuracy: 51.5%, cell accuracy: 99.6%, board accuracy: 62.5% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3268, G loss: 0.6916\n",
      "[84/1762] D loss: 1.3814, G loss: 0.6579\n",
      "[164/1762] D loss: 1.3496, G loss: 0.5808\n",
      "[244/1762] D loss: 1.4036, G loss: 0.6161\n",
      "[324/1762] D loss: 1.3875, G loss: 0.7583\n",
      "[404/1762] D loss: 1.4404, G loss: 0.5751\n",
      "[484/1762] D loss: 1.4246, G loss: 0.7095\n",
      "[564/1762] D loss: 1.3200, G loss: 0.8513\n",
      "[644/1762] D loss: 1.4279, G loss: 0.6506\n",
      "[724/1762] D loss: 1.3893, G loss: 0.6779\n",
      "[804/1762] D loss: 1.4067, G loss: 0.8574\n",
      "[884/1762] D loss: 1.3200, G loss: 0.8546\n",
      "[964/1762] D loss: 1.3757, G loss: 0.7188\n",
      "[1044/1762] D loss: 1.2646, G loss: 0.8660\n",
      "[1124/1762] D loss: 1.3635, G loss: 0.6898\n",
      "[1204/1762] D loss: 1.4030, G loss: 0.5706\n",
      "[1284/1762] D loss: 1.3541, G loss: 0.6527\n",
      "[1364/1762] D loss: 1.3403, G loss: 0.6958\n",
      "[1444/1762] D loss: 1.3572, G loss: 0.6317\n",
      "[1524/1762] D loss: 1.3963, G loss: 0.6059\n",
      "[1604/1762] D loss: 1.3932, G loss: 0.7063\n",
      "[1684/1762] D loss: 1.3143, G loss: 0.8506\n",
      "[1762/1762] D loss: 1.4819, G loss: 0.5421\n",
      "train error: \n",
      " D loss: 1.365767, G loss: 0.716702, D accuracy: 54.7%, cell accuracy: 99.6%, board accuracy: 60.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.366287, G loss: 0.719004, D accuracy: 54.2%, cell accuracy: 99.6%, board accuracy: 60.0% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3022, G loss: 0.9126\n",
      "[84/1762] D loss: 1.3927, G loss: 0.7402\n",
      "[164/1762] D loss: 1.3541, G loss: 0.6750\n",
      "[244/1762] D loss: 1.3929, G loss: 0.7069\n",
      "[324/1762] D loss: 1.4018, G loss: 0.6937\n",
      "[404/1762] D loss: 1.2908, G loss: 0.8393\n",
      "[484/1762] D loss: 1.3679, G loss: 0.6572\n",
      "[564/1762] D loss: 1.3883, G loss: 0.6960\n",
      "[644/1762] D loss: 1.3836, G loss: 0.7229\n",
      "[724/1762] D loss: 1.4043, G loss: 0.6878\n",
      "[804/1762] D loss: 1.4036, G loss: 0.7679\n",
      "[884/1762] D loss: 1.3815, G loss: 0.8859\n",
      "[964/1762] D loss: 1.4244, G loss: 0.7289\n",
      "[1044/1762] D loss: 1.3610, G loss: 0.7250\n",
      "[1124/1762] D loss: 1.3967, G loss: 0.6534\n",
      "[1204/1762] D loss: 1.3689, G loss: 0.7115\n",
      "[1284/1762] D loss: 1.3570, G loss: 0.6328\n",
      "[1364/1762] D loss: 1.3800, G loss: 0.7561\n",
      "[1444/1762] D loss: 1.4052, G loss: 0.8028\n",
      "[1524/1762] D loss: 1.3579, G loss: 0.6549\n",
      "[1604/1762] D loss: 1.3427, G loss: 0.9296\n",
      "[1684/1762] D loss: 1.3898, G loss: 0.7399\n",
      "[1762/1762] D loss: 1.3821, G loss: 0.6623\n",
      "train error: \n",
      " D loss: 1.363128, G loss: 0.673338, D accuracy: 54.6%, cell accuracy: 99.6%, board accuracy: 62.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.365085, G loss: 0.677831, D accuracy: 54.0%, cell accuracy: 99.6%, board accuracy: 63.2% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2361, G loss: 0.7758\n",
      "[84/1762] D loss: 1.3980, G loss: 0.7569\n",
      "[164/1762] D loss: 1.3864, G loss: 0.6567\n",
      "[244/1762] D loss: 1.3943, G loss: 0.6763\n",
      "[324/1762] D loss: 1.3893, G loss: 0.7765\n",
      "[404/1762] D loss: 1.3719, G loss: 0.7648\n",
      "[484/1762] D loss: 1.3745, G loss: 0.7575\n",
      "[564/1762] D loss: 1.3971, G loss: 0.5922\n",
      "[644/1762] D loss: 1.4097, G loss: 0.7787\n",
      "[724/1762] D loss: 1.2808, G loss: 0.8069\n",
      "[804/1762] D loss: 1.3957, G loss: 0.7353\n",
      "[884/1762] D loss: 1.3223, G loss: 0.7774\n",
      "[964/1762] D loss: 1.3925, G loss: 0.7639\n",
      "[1044/1762] D loss: 1.4354, G loss: 0.5331\n",
      "[1124/1762] D loss: 1.4098, G loss: 0.7544\n",
      "[1204/1762] D loss: 1.3756, G loss: 0.8337\n",
      "[1284/1762] D loss: 1.3868, G loss: 0.6196\n",
      "[1364/1762] D loss: 1.3882, G loss: 0.6154\n",
      "[1444/1762] D loss: 1.3985, G loss: 0.6547\n",
      "[1524/1762] D loss: 1.4013, G loss: 0.6122\n",
      "[1604/1762] D loss: 1.3904, G loss: 0.6607\n",
      "[1684/1762] D loss: 1.3602, G loss: 0.7402\n",
      "[1762/1762] D loss: 1.3932, G loss: 0.7304\n",
      "train error: \n",
      " D loss: 1.361270, G loss: 0.766549, D accuracy: 53.7%, cell accuracy: 99.6%, board accuracy: 69.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.362403, G loss: 0.766531, D accuracy: 53.8%, cell accuracy: 99.6%, board accuracy: 66.8% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4132, G loss: 0.7952\n",
      "[84/1762] D loss: 1.4013, G loss: 0.6625\n",
      "[164/1762] D loss: 1.3831, G loss: 0.7739\n",
      "[244/1762] D loss: 1.3864, G loss: 0.6654\n",
      "[324/1762] D loss: 1.2828, G loss: 0.7323\n",
      "[404/1762] D loss: 1.3968, G loss: 0.6498\n",
      "[484/1762] D loss: 1.4004, G loss: 0.7449\n",
      "[564/1762] D loss: 1.4055, G loss: 0.7100\n",
      "[644/1762] D loss: 1.3681, G loss: 0.7807\n",
      "[724/1762] D loss: 1.3156, G loss: 0.8324\n",
      "[804/1762] D loss: 1.3885, G loss: 0.7393\n",
      "[884/1762] D loss: 1.3059, G loss: 0.8128\n",
      "[964/1762] D loss: 1.3820, G loss: 0.7307\n",
      "[1044/1762] D loss: 1.3914, G loss: 0.8854\n",
      "[1124/1762] D loss: 1.3877, G loss: 0.7062\n",
      "[1204/1762] D loss: 1.3940, G loss: 0.7853\n",
      "[1284/1762] D loss: 1.3990, G loss: 0.6537\n",
      "[1364/1762] D loss: 1.4046, G loss: 0.5862\n",
      "[1444/1762] D loss: 1.3004, G loss: 0.7056\n",
      "[1524/1762] D loss: 1.3824, G loss: 0.6956\n",
      "[1604/1762] D loss: 1.3600, G loss: 0.6465\n",
      "[1684/1762] D loss: 1.3862, G loss: 0.6666\n",
      "[1762/1762] D loss: 1.4018, G loss: 0.6461\n",
      "train error: \n",
      " D loss: 1.366001, G loss: 0.671544, D accuracy: 54.3%, cell accuracy: 99.7%, board accuracy: 73.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.364458, G loss: 0.677223, D accuracy: 53.8%, cell accuracy: 99.7%, board accuracy: 71.8% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2943, G loss: 0.7391\n",
      "[84/1762] D loss: 1.3252, G loss: 0.8107\n",
      "[164/1762] D loss: 1.2971, G loss: 0.7839\n",
      "[244/1762] D loss: 1.3254, G loss: 0.7968\n",
      "[324/1762] D loss: 1.3647, G loss: 0.7285\n",
      "[404/1762] D loss: 1.3000, G loss: 0.7536\n",
      "[484/1762] D loss: 1.2760, G loss: 0.6758\n",
      "[564/1762] D loss: 1.3838, G loss: 0.7004\n",
      "[644/1762] D loss: 1.3663, G loss: 0.6974\n",
      "[724/1762] D loss: 1.2911, G loss: 0.7705\n",
      "[804/1762] D loss: 1.3837, G loss: 0.6944\n",
      "[884/1762] D loss: 1.4045, G loss: 0.6215\n",
      "[964/1762] D loss: 1.3877, G loss: 0.7148\n",
      "[1044/1762] D loss: 1.3929, G loss: 0.6784\n",
      "[1124/1762] D loss: 1.2946, G loss: 0.6310\n",
      "[1204/1762] D loss: 1.3918, G loss: 0.6901\n",
      "[1284/1762] D loss: 1.3135, G loss: 0.8012\n",
      "[1364/1762] D loss: 1.3163, G loss: 0.6594\n",
      "[1444/1762] D loss: 1.2308, G loss: 0.7587\n",
      "[1524/1762] D loss: 1.3982, G loss: 0.6867\n",
      "[1604/1762] D loss: 1.3951, G loss: 0.8154\n",
      "[1684/1762] D loss: 1.4019, G loss: 0.5962\n",
      "[1762/1762] D loss: 1.3914, G loss: 0.7563\n",
      "train error: \n",
      " D loss: 1.360281, G loss: 0.737291, D accuracy: 53.3%, cell accuracy: 99.7%, board accuracy: 77.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.356975, G loss: 0.744330, D accuracy: 53.9%, cell accuracy: 99.7%, board accuracy: 77.7% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3695, G loss: 0.6798\n",
      "[84/1762] D loss: 1.3009, G loss: 0.7256\n",
      "[164/1762] D loss: 1.4044, G loss: 0.5822\n",
      "[244/1762] D loss: 1.3955, G loss: 0.6673\n",
      "[324/1762] D loss: 1.3943, G loss: 0.6568\n",
      "[404/1762] D loss: 1.3889, G loss: 0.7319\n",
      "[484/1762] D loss: 1.3964, G loss: 0.6445\n",
      "[564/1762] D loss: 1.4064, G loss: 0.6671\n",
      "[644/1762] D loss: 1.3925, G loss: 0.8132\n",
      "[724/1762] D loss: 1.3928, G loss: 0.8874\n",
      "[804/1762] D loss: 1.3100, G loss: 0.7040\n",
      "[884/1762] D loss: 1.3904, G loss: 0.6657\n",
      "[964/1762] D loss: 1.3974, G loss: 0.5682\n",
      "[1044/1762] D loss: 1.4024, G loss: 0.6086\n",
      "[1124/1762] D loss: 1.3257, G loss: 0.7653\n",
      "[1204/1762] D loss: 1.3875, G loss: 0.7118\n",
      "[1284/1762] D loss: 1.3906, G loss: 0.7034\n",
      "[1364/1762] D loss: 1.4081, G loss: 0.8093\n",
      "[1444/1762] D loss: 1.3923, G loss: 0.6537\n",
      "[1524/1762] D loss: 1.3891, G loss: 0.7109\n",
      "[1604/1762] D loss: 1.4108, G loss: 0.6744\n",
      "[1684/1762] D loss: 1.3684, G loss: 0.7756\n",
      "[1762/1762] D loss: 1.3941, G loss: 0.7569\n",
      "train error: \n",
      " D loss: 1.363557, G loss: 0.610649, D accuracy: 56.0%, cell accuracy: 99.5%, board accuracy: 37.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.359594, G loss: 0.616237, D accuracy: 56.7%, cell accuracy: 99.5%, board accuracy: 39.1% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2974, G loss: 0.6387\n",
      "[84/1762] D loss: 1.2054, G loss: 0.8610\n",
      "[164/1762] D loss: 1.3952, G loss: 0.5700\n",
      "[244/1762] D loss: 1.2864, G loss: 0.6767\n",
      "[324/1762] D loss: 1.4028, G loss: 0.6825\n",
      "[404/1762] D loss: 1.4147, G loss: 0.6602\n",
      "[484/1762] D loss: 1.2896, G loss: 0.8442\n",
      "[564/1762] D loss: 1.3816, G loss: 0.6517\n",
      "[644/1762] D loss: 1.1445, G loss: 0.7140\n",
      "[724/1762] D loss: 1.4051, G loss: 0.6614\n",
      "[804/1762] D loss: 1.3903, G loss: 0.7106\n",
      "[884/1762] D loss: 1.3071, G loss: 0.8298\n",
      "[964/1762] D loss: 1.3980, G loss: 0.6206\n",
      "[1044/1762] D loss: 1.4020, G loss: 0.6290\n",
      "[1124/1762] D loss: 1.3715, G loss: 0.6996\n",
      "[1204/1762] D loss: 1.3962, G loss: 0.6593\n",
      "[1284/1762] D loss: 1.4000, G loss: 0.7734\n",
      "[1364/1762] D loss: 1.3975, G loss: 0.7881\n",
      "[1444/1762] D loss: 1.3609, G loss: 0.8618\n",
      "[1524/1762] D loss: 1.3664, G loss: 0.7125\n",
      "[1604/1762] D loss: 1.2743, G loss: 0.7474\n",
      "[1684/1762] D loss: 1.4173, G loss: 0.6097\n",
      "[1762/1762] D loss: 1.3913, G loss: 0.7597\n",
      "train error: \n",
      " D loss: 1.356721, G loss: 0.756246, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 78.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.351286, G loss: 0.762050, D accuracy: 55.3%, cell accuracy: 99.7%, board accuracy: 74.3% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3930, G loss: 0.7681\n",
      "[84/1762] D loss: 1.3927, G loss: 0.7346\n",
      "[164/1762] D loss: 1.3930, G loss: 0.7184\n",
      "[244/1762] D loss: 1.3721, G loss: 0.7477\n",
      "[324/1762] D loss: 1.3522, G loss: 0.7181\n",
      "[404/1762] D loss: 1.2927, G loss: 0.7539\n",
      "[484/1762] D loss: 1.4145, G loss: 0.6531\n",
      "[564/1762] D loss: 1.3879, G loss: 0.6813\n",
      "[644/1762] D loss: 1.2701, G loss: 0.7240\n",
      "[724/1762] D loss: 1.3616, G loss: 0.6393\n",
      "[804/1762] D loss: 1.4156, G loss: 0.5787\n",
      "[884/1762] D loss: 1.4083, G loss: 0.8262\n",
      "[964/1762] D loss: 1.3917, G loss: 0.6519\n",
      "[1044/1762] D loss: 1.2641, G loss: 0.8729\n",
      "[1124/1762] D loss: 1.3957, G loss: 0.7174\n",
      "[1204/1762] D loss: 1.4167, G loss: 0.6529\n",
      "[1284/1762] D loss: 1.3914, G loss: 0.6080\n",
      "[1364/1762] D loss: 1.3876, G loss: 0.7824\n",
      "[1444/1762] D loss: 1.4186, G loss: 0.7134\n",
      "[1524/1762] D loss: 1.3941, G loss: 0.7209\n",
      "[1604/1762] D loss: 1.3891, G loss: 0.6607\n",
      "[1684/1762] D loss: 1.3961, G loss: 0.5806\n",
      "[1762/1762] D loss: 1.4071, G loss: 0.6879\n",
      "train error: \n",
      " D loss: 1.362467, G loss: 0.670342, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 77.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.354773, G loss: 0.677550, D accuracy: 54.2%, cell accuracy: 99.7%, board accuracy: 75.5% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3921, G loss: 0.6394\n",
      "[84/1762] D loss: 1.3508, G loss: 0.9633\n",
      "[164/1762] D loss: 1.3551, G loss: 0.6480\n",
      "[244/1762] D loss: 1.2663, G loss: 0.6988\n",
      "[324/1762] D loss: 1.4009, G loss: 0.6756\n",
      "[404/1762] D loss: 1.3891, G loss: 0.7064\n",
      "[484/1762] D loss: 1.3916, G loss: 0.6915\n",
      "[564/1762] D loss: 1.3963, G loss: 0.6632\n",
      "[644/1762] D loss: 1.3512, G loss: 0.7568\n",
      "[724/1762] D loss: 1.2801, G loss: 0.7192\n",
      "[804/1762] D loss: 1.3767, G loss: 0.7472\n",
      "[884/1762] D loss: 1.3362, G loss: 0.7822\n",
      "[964/1762] D loss: 1.3971, G loss: 0.6992\n",
      "[1044/1762] D loss: 1.3859, G loss: 0.6856\n",
      "[1124/1762] D loss: 1.2668, G loss: 0.7400\n",
      "[1204/1762] D loss: 1.4105, G loss: 0.7912\n",
      "[1284/1762] D loss: 1.2684, G loss: 0.8480\n",
      "[1364/1762] D loss: 1.3883, G loss: 0.6682\n",
      "[1444/1762] D loss: 1.3827, G loss: 0.6199\n",
      "[1524/1762] D loss: 1.4155, G loss: 0.6105\n",
      "[1604/1762] D loss: 1.4060, G loss: 0.6650\n",
      "[1684/1762] D loss: 1.2678, G loss: 0.7367\n",
      "[1762/1762] D loss: 1.3926, G loss: 0.8226\n",
      "train error: \n",
      " D loss: 1.360401, G loss: 0.810763, D accuracy: 53.1%, cell accuracy: 99.8%, board accuracy: 79.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.354858, G loss: 0.815878, D accuracy: 53.4%, cell accuracy: 99.7%, board accuracy: 75.7% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3933, G loss: 0.7836\n",
      "[84/1762] D loss: 1.2621, G loss: 0.7341\n",
      "[164/1762] D loss: 1.3839, G loss: 0.6839\n",
      "[244/1762] D loss: 1.3893, G loss: 0.7843\n",
      "[324/1762] D loss: 1.1217, G loss: 0.9336\n",
      "[404/1762] D loss: 1.2887, G loss: 0.6751\n",
      "[484/1762] D loss: 1.2766, G loss: 0.8389\n",
      "[564/1762] D loss: 1.3479, G loss: 0.5935\n",
      "[644/1762] D loss: 1.4011, G loss: 0.6301\n",
      "[724/1762] D loss: 1.2740, G loss: 0.6839\n",
      "[804/1762] D loss: 1.3596, G loss: 0.6194\n",
      "[884/1762] D loss: 1.4097, G loss: 0.6288\n",
      "[964/1762] D loss: 1.3997, G loss: 0.6763\n",
      "[1044/1762] D loss: 1.3921, G loss: 0.6787\n",
      "[1124/1762] D loss: 1.4103, G loss: 0.8229\n",
      "[1204/1762] D loss: 1.3939, G loss: 0.7141\n",
      "[1284/1762] D loss: 1.3418, G loss: 0.8324\n",
      "[1364/1762] D loss: 1.4125, G loss: 0.7260\n",
      "[1444/1762] D loss: 1.3340, G loss: 0.7379\n",
      "[1524/1762] D loss: 1.3971, G loss: 0.7468\n",
      "[1604/1762] D loss: 1.4096, G loss: 0.7091\n",
      "[1684/1762] D loss: 1.2905, G loss: 0.8433\n",
      "[1762/1762] D loss: 1.3940, G loss: 0.6572\n",
      "train error: \n",
      " D loss: 1.381044, G loss: 0.817855, D accuracy: 48.8%, cell accuracy: 99.7%, board accuracy: 62.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.366645, G loss: 0.834594, D accuracy: 50.7%, cell accuracy: 99.6%, board accuracy: 58.9% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2456, G loss: 1.0204\n",
      "[84/1762] D loss: 1.8062, G loss: 0.6942\n",
      "[164/1762] D loss: 1.4914, G loss: 0.8568\n",
      "[244/1762] D loss: 1.5236, G loss: 0.6376\n",
      "[324/1762] D loss: 1.4244, G loss: 0.7455\n",
      "[404/1762] D loss: 1.4238, G loss: 0.7153\n",
      "[484/1762] D loss: 1.4008, G loss: 0.7768\n",
      "[564/1762] D loss: 1.3497, G loss: 0.7480\n",
      "[644/1762] D loss: 1.4052, G loss: 0.6402\n",
      "[724/1762] D loss: 1.4168, G loss: 0.5331\n",
      "[804/1762] D loss: 1.3379, G loss: 0.6123\n",
      "[884/1762] D loss: 1.4954, G loss: 0.6488\n",
      "[964/1762] D loss: 1.4001, G loss: 0.6069\n",
      "[1044/1762] D loss: 1.3859, G loss: 0.5967\n",
      "[1124/1762] D loss: 1.4299, G loss: 0.6591\n",
      "[1204/1762] D loss: 1.3362, G loss: 0.8724\n",
      "[1284/1762] D loss: 1.4120, G loss: 0.6987\n",
      "[1364/1762] D loss: 1.3504, G loss: 0.7965\n",
      "[1444/1762] D loss: 1.3264, G loss: 0.6694\n",
      "[1524/1762] D loss: 1.3927, G loss: 0.8078\n",
      "[1604/1762] D loss: 1.2785, G loss: 0.7532\n",
      "[1684/1762] D loss: 1.3823, G loss: 0.7451\n",
      "[1762/1762] D loss: 1.3745, G loss: 0.7335\n",
      "train error: \n",
      " D loss: 1.359571, G loss: 0.638658, D accuracy: 56.4%, cell accuracy: 99.2%, board accuracy: 46.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.355075, G loss: 0.637935, D accuracy: 55.7%, cell accuracy: 99.2%, board accuracy: 44.1% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3820, G loss: 0.6054\n",
      "[84/1762] D loss: 1.3267, G loss: 0.6581\n",
      "[164/1762] D loss: 1.3829, G loss: 0.8082\n",
      "[244/1762] D loss: 1.3612, G loss: 0.8135\n",
      "[324/1762] D loss: 1.3483, G loss: 0.7744\n",
      "[404/1762] D loss: 1.3917, G loss: 0.6492\n",
      "[484/1762] D loss: 1.3253, G loss: 0.6369\n",
      "[564/1762] D loss: 1.3688, G loss: 0.6911\n",
      "[644/1762] D loss: 1.2969, G loss: 0.8660\n",
      "[724/1762] D loss: 1.3306, G loss: 0.7109\n",
      "[804/1762] D loss: 1.4141, G loss: 0.6365\n",
      "[884/1762] D loss: 1.3571, G loss: 0.7509\n",
      "[964/1762] D loss: 1.4090, G loss: 0.7762\n",
      "[1044/1762] D loss: 1.3885, G loss: 0.6648\n",
      "[1124/1762] D loss: 1.4188, G loss: 0.5903\n",
      "[1204/1762] D loss: 1.3898, G loss: 0.6660\n",
      "[1284/1762] D loss: 1.3874, G loss: 0.6607\n",
      "[1364/1762] D loss: 1.3889, G loss: 0.6713\n",
      "[1444/1762] D loss: 1.3852, G loss: 0.6503\n",
      "[1524/1762] D loss: 1.3493, G loss: 0.8219\n",
      "[1604/1762] D loss: 1.3984, G loss: 0.7803\n",
      "[1684/1762] D loss: 1.3920, G loss: 0.6534\n",
      "[1762/1762] D loss: 1.3954, G loss: 0.6162\n",
      "train error: \n",
      " D loss: 1.368642, G loss: 0.681012, D accuracy: 53.5%, cell accuracy: 99.6%, board accuracy: 55.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.368857, G loss: 0.679643, D accuracy: 54.0%, cell accuracy: 99.6%, board accuracy: 57.5% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3943, G loss: 0.6848\n",
      "[84/1762] D loss: 1.3511, G loss: 0.7391\n",
      "[164/1762] D loss: 1.3868, G loss: 0.7523\n",
      "[244/1762] D loss: 1.3848, G loss: 0.7365\n",
      "[324/1762] D loss: 1.3744, G loss: 0.6945\n",
      "[404/1762] D loss: 1.3282, G loss: 0.6718\n",
      "[484/1762] D loss: 1.3010, G loss: 0.7045\n",
      "[564/1762] D loss: 1.3846, G loss: 0.7649\n",
      "[644/1762] D loss: 1.4011, G loss: 0.7691\n",
      "[724/1762] D loss: 1.3047, G loss: 0.7472\n",
      "[804/1762] D loss: 1.3202, G loss: 0.6945\n",
      "[884/1762] D loss: 1.3907, G loss: 0.6996\n",
      "[964/1762] D loss: 1.3987, G loss: 0.6196\n",
      "[1044/1762] D loss: 1.3410, G loss: 0.6079\n",
      "[1124/1762] D loss: 1.3936, G loss: 0.6239\n",
      "[1204/1762] D loss: 1.3597, G loss: 0.7186\n",
      "[1284/1762] D loss: 1.3413, G loss: 0.7099\n",
      "[1364/1762] D loss: 1.3642, G loss: 0.5933\n",
      "[1444/1762] D loss: 1.2904, G loss: 0.7012\n",
      "[1524/1762] D loss: 1.3635, G loss: 0.7344\n",
      "[1604/1762] D loss: 1.3880, G loss: 0.7498\n",
      "[1684/1762] D loss: 1.4178, G loss: 0.8751\n",
      "[1762/1762] D loss: 1.3754, G loss: 0.6926\n",
      "train error: \n",
      " D loss: 1.349896, G loss: 0.726314, D accuracy: 57.7%, cell accuracy: 99.7%, board accuracy: 73.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.349558, G loss: 0.730647, D accuracy: 57.0%, cell accuracy: 99.7%, board accuracy: 72.3% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3930, G loss: 0.6859\n",
      "[84/1762] D loss: 1.3916, G loss: 0.6865\n",
      "[164/1762] D loss: 1.3940, G loss: 0.7831\n",
      "[244/1762] D loss: 1.3918, G loss: 0.7435\n",
      "[324/1762] D loss: 1.3895, G loss: 0.6481\n",
      "[404/1762] D loss: 1.3813, G loss: 0.7418\n",
      "[484/1762] D loss: 1.3885, G loss: 0.6768\n",
      "[564/1762] D loss: 1.3777, G loss: 0.6878\n",
      "[644/1762] D loss: 1.3517, G loss: 0.6938\n",
      "[724/1762] D loss: 1.3270, G loss: 0.6775\n",
      "[804/1762] D loss: 1.2344, G loss: 0.7112\n",
      "[884/1762] D loss: 1.3886, G loss: 0.6472\n",
      "[964/1762] D loss: 1.3901, G loss: 0.7263\n",
      "[1044/1762] D loss: 1.3581, G loss: 0.6862\n",
      "[1124/1762] D loss: 1.3782, G loss: 0.6813\n",
      "[1204/1762] D loss: 1.3917, G loss: 0.7258\n",
      "[1284/1762] D loss: 1.3836, G loss: 0.6814\n",
      "[1364/1762] D loss: 1.3418, G loss: 0.6063\n",
      "[1444/1762] D loss: 1.3876, G loss: 0.7963\n",
      "[1524/1762] D loss: 1.3926, G loss: 0.7160\n",
      "[1604/1762] D loss: 1.3392, G loss: 0.6444\n",
      "[1684/1762] D loss: 1.4261, G loss: 0.9541\n",
      "[1762/1762] D loss: 1.4068, G loss: 0.5594\n",
      "train error: \n",
      " D loss: 1.370448, G loss: 0.619063, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.365005, G loss: 0.628293, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 84.1% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3945, G loss: 0.6684\n",
      "[84/1762] D loss: 1.2854, G loss: 0.8363\n",
      "[164/1762] D loss: 1.3883, G loss: 0.6631\n",
      "[244/1762] D loss: 1.3984, G loss: 0.7471\n",
      "[324/1762] D loss: 1.3902, G loss: 0.7848\n",
      "[404/1762] D loss: 1.1773, G loss: 1.0743\n",
      "[484/1762] D loss: 1.3913, G loss: 0.6625\n",
      "[564/1762] D loss: 1.3782, G loss: 0.6360\n",
      "[644/1762] D loss: 1.3871, G loss: 0.6598\n",
      "[724/1762] D loss: 1.4392, G loss: 0.5734\n",
      "[804/1762] D loss: 1.3907, G loss: 0.7129\n",
      "[884/1762] D loss: 1.4669, G loss: 0.5394\n",
      "[964/1762] D loss: 1.1707, G loss: 0.7386\n",
      "[1044/1762] D loss: 1.3959, G loss: 0.7312\n",
      "[1124/1762] D loss: 1.2699, G loss: 0.8023\n",
      "[1204/1762] D loss: 1.3947, G loss: 0.6731\n",
      "[1284/1762] D loss: 1.3757, G loss: 0.6833\n",
      "[1364/1762] D loss: 1.2372, G loss: 0.7576\n",
      "[1444/1762] D loss: 1.3623, G loss: 0.8217\n",
      "[1524/1762] D loss: 1.2540, G loss: 0.7157\n",
      "[1604/1762] D loss: 1.3808, G loss: 0.6552\n",
      "[1684/1762] D loss: 1.3880, G loss: 0.7394\n",
      "[1762/1762] D loss: 1.3896, G loss: 0.7422\n",
      "train error: \n",
      " D loss: 1.347583, G loss: 0.688241, D accuracy: 56.1%, cell accuracy: 99.6%, board accuracy: 70.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.337899, G loss: 0.696234, D accuracy: 56.9%, cell accuracy: 99.6%, board accuracy: 65.9% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3756, G loss: 0.6577\n",
      "[84/1762] D loss: 1.4258, G loss: 0.6748\n",
      "[164/1762] D loss: 1.3662, G loss: 0.6411\n",
      "[244/1762] D loss: 1.4106, G loss: 0.5923\n",
      "[324/1762] D loss: 1.2500, G loss: 0.9018\n",
      "[404/1762] D loss: 1.3862, G loss: 0.6673\n",
      "[484/1762] D loss: 1.3910, G loss: 0.6928\n",
      "[564/1762] D loss: 1.3919, G loss: 0.7603\n",
      "[644/1762] D loss: 1.3921, G loss: 0.7786\n",
      "[724/1762] D loss: 1.1831, G loss: 0.7870\n",
      "[804/1762] D loss: 1.3938, G loss: 0.6685\n",
      "[884/1762] D loss: 1.4045, G loss: 0.6309\n",
      "[964/1762] D loss: 1.2385, G loss: 0.8301\n",
      "[1044/1762] D loss: 1.4133, G loss: 0.6800\n",
      "[1124/1762] D loss: 1.3992, G loss: 0.7393\n",
      "[1204/1762] D loss: 1.3917, G loss: 0.6817\n",
      "[1284/1762] D loss: 1.2689, G loss: 0.7283\n",
      "[1364/1762] D loss: 1.4008, G loss: 0.5930\n",
      "[1444/1762] D loss: 1.3875, G loss: 0.6779\n",
      "[1524/1762] D loss: 1.3871, G loss: 0.7952\n",
      "[1604/1762] D loss: 1.2881, G loss: 0.6436\n",
      "[1684/1762] D loss: 1.3976, G loss: 0.7137\n",
      "[1762/1762] D loss: 1.3920, G loss: 0.6761\n",
      "train error: \n",
      " D loss: 1.354514, G loss: 0.755313, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.345396, G loss: 0.765204, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 82.5% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3920, G loss: 0.7151\n",
      "[84/1762] D loss: 1.3976, G loss: 0.6417\n",
      "[164/1762] D loss: 1.3955, G loss: 0.7701\n",
      "[244/1762] D loss: 1.3889, G loss: 0.7734\n",
      "[324/1762] D loss: 1.3142, G loss: 0.7033\n",
      "[404/1762] D loss: 1.6052, G loss: 0.7484\n",
      "[484/1762] D loss: 1.4462, G loss: 0.7926\n",
      "[564/1762] D loss: 1.2905, G loss: 0.7589\n",
      "[644/1762] D loss: 1.1862, G loss: 0.8013\n",
      "[724/1762] D loss: 1.0912, G loss: 0.9428\n",
      "[804/1762] D loss: 1.3312, G loss: 0.8201\n",
      "[884/1762] D loss: 1.4297, G loss: 0.8436\n",
      "[964/1762] D loss: 1.4440, G loss: 0.8130\n",
      "[1044/1762] D loss: 1.4079, G loss: 0.6555\n",
      "[1124/1762] D loss: 1.4337, G loss: 0.5877\n",
      "[1204/1762] D loss: 1.3851, G loss: 0.6647\n",
      "[1284/1762] D loss: 1.3322, G loss: 0.7524\n",
      "[1364/1762] D loss: 1.4018, G loss: 0.6123\n",
      "[1444/1762] D loss: 1.4077, G loss: 0.6693\n",
      "[1524/1762] D loss: 1.3879, G loss: 0.7428\n",
      "[1604/1762] D loss: 1.3898, G loss: 0.6946\n",
      "[1684/1762] D loss: 1.3924, G loss: 0.6709\n",
      "[1762/1762] D loss: 1.3184, G loss: 0.6429\n",
      "train error: \n",
      " D loss: 1.388482, G loss: 0.586059, D accuracy: 50.5%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.383292, G loss: 0.590977, D accuracy: 51.4%, cell accuracy: 99.8%, board accuracy: 83.9% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3941, G loss: 0.5799\n",
      "[84/1762] D loss: 1.3973, G loss: 0.6799\n",
      "[164/1762] D loss: 1.3944, G loss: 0.7255\n",
      "[244/1762] D loss: 1.3931, G loss: 0.7549\n",
      "[324/1762] D loss: 1.3919, G loss: 0.7558\n",
      "[404/1762] D loss: 1.3572, G loss: 0.7218\n",
      "[484/1762] D loss: 1.4030, G loss: 0.7107\n",
      "[564/1762] D loss: 1.3953, G loss: 0.6940\n",
      "[644/1762] D loss: 1.3887, G loss: 0.7101\n",
      "[724/1762] D loss: 1.3595, G loss: 0.9635\n",
      "[804/1762] D loss: 1.3910, G loss: 0.6760\n",
      "[884/1762] D loss: 1.3928, G loss: 0.6240\n",
      "[964/1762] D loss: 1.2987, G loss: 0.8066\n",
      "[1044/1762] D loss: 1.3921, G loss: 0.6622\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.6992\n",
      "[1204/1762] D loss: 1.2154, G loss: 0.8844\n",
      "[1284/1762] D loss: 1.2901, G loss: 0.7272\n",
      "[1364/1762] D loss: 1.3956, G loss: 0.6568\n",
      "[1444/1762] D loss: 1.3940, G loss: 0.6801\n",
      "[1524/1762] D loss: 1.3894, G loss: 0.7099\n",
      "[1604/1762] D loss: 1.3907, G loss: 0.6696\n",
      "[1684/1762] D loss: 1.3907, G loss: 0.7220\n",
      "[1762/1762] D loss: 1.3868, G loss: 0.7083\n",
      "train error: \n",
      " D loss: 1.360252, G loss: 0.783268, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.353662, G loss: 0.789591, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 85.0% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3899, G loss: 0.7027\n",
      "[84/1762] D loss: 1.4141, G loss: 0.7702\n",
      "[164/1762] D loss: 1.4007, G loss: 0.6311\n",
      "[244/1762] D loss: 1.3960, G loss: 0.6874\n",
      "[324/1762] D loss: 1.3858, G loss: 0.7783\n",
      "[404/1762] D loss: 1.4014, G loss: 0.7581\n",
      "[484/1762] D loss: 1.3998, G loss: 0.7196\n",
      "[564/1762] D loss: 1.3231, G loss: 0.8279\n",
      "[644/1762] D loss: 1.3880, G loss: 0.7010\n",
      "[724/1762] D loss: 1.2639, G loss: 0.6855\n",
      "[804/1762] D loss: 1.3683, G loss: 0.7295\n",
      "[884/1762] D loss: 1.5226, G loss: 0.5146\n",
      "[964/1762] D loss: 1.3507, G loss: 0.7983\n",
      "[1044/1762] D loss: 1.3090, G loss: 0.8840\n",
      "[1124/1762] D loss: 1.3029, G loss: 0.7795\n",
      "[1204/1762] D loss: 1.3821, G loss: 0.7263\n",
      "[1284/1762] D loss: 1.3116, G loss: 0.7389\n",
      "[1364/1762] D loss: 1.3963, G loss: 0.6665\n",
      "[1444/1762] D loss: 1.3918, G loss: 0.6473\n",
      "[1524/1762] D loss: 1.3894, G loss: 0.6091\n",
      "[1604/1762] D loss: 1.3622, G loss: 0.5961\n",
      "[1684/1762] D loss: 1.3866, G loss: 0.6438\n",
      "[1762/1762] D loss: 1.4055, G loss: 0.6116\n",
      "train error: \n",
      " D loss: 1.365948, G loss: 0.695729, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.360372, G loss: 0.704525, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 82.7% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3921, G loss: 0.7455\n",
      "[84/1762] D loss: 1.3869, G loss: 0.7363\n",
      "[164/1762] D loss: 1.4032, G loss: 0.7107\n",
      "[244/1762] D loss: 1.3886, G loss: 0.6948\n",
      "[324/1762] D loss: 1.3881, G loss: 0.7059\n",
      "[404/1762] D loss: 1.3879, G loss: 0.6643\n",
      "[484/1762] D loss: 1.3726, G loss: 0.6799\n",
      "[564/1762] D loss: 1.3896, G loss: 0.7556\n",
      "[644/1762] D loss: 1.3929, G loss: 0.7827\n",
      "[724/1762] D loss: 1.1871, G loss: 0.7629\n",
      "[804/1762] D loss: 1.4050, G loss: 0.7454\n",
      "[884/1762] D loss: 1.3982, G loss: 0.6586\n",
      "[964/1762] D loss: 1.3901, G loss: 0.7868\n",
      "[1044/1762] D loss: 1.3873, G loss: 0.7183\n",
      "[1124/1762] D loss: 1.3934, G loss: 0.7314\n",
      "[1204/1762] D loss: 1.3911, G loss: 0.6821\n",
      "[1284/1762] D loss: 1.3149, G loss: 0.6943\n",
      "[1364/1762] D loss: 1.4062, G loss: 0.8135\n",
      "[1444/1762] D loss: 1.3958, G loss: 0.6223\n",
      "[1524/1762] D loss: 1.2616, G loss: 0.7608\n",
      "[1604/1762] D loss: 1.3912, G loss: 0.6727\n",
      "[1684/1762] D loss: 1.3927, G loss: 0.5737\n",
      "[1762/1762] D loss: 1.3884, G loss: 0.6548\n",
      "train error: \n",
      " D loss: 1.363515, G loss: 0.628818, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.352231, G loss: 0.639483, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 83.0% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2907, G loss: 0.7572\n",
      "[84/1762] D loss: 1.3884, G loss: 0.7158\n",
      "[164/1762] D loss: 1.2202, G loss: 0.8817\n",
      "[244/1762] D loss: 1.3071, G loss: 0.6660\n",
      "[324/1762] D loss: 1.2359, G loss: 0.7628\n",
      "[404/1762] D loss: 1.4042, G loss: 0.8690\n",
      "[484/1762] D loss: 1.4129, G loss: 0.6433\n",
      "[564/1762] D loss: 1.3962, G loss: 0.6842\n",
      "[644/1762] D loss: 1.3926, G loss: 0.7834\n",
      "[724/1762] D loss: 1.3953, G loss: 0.7107\n",
      "[804/1762] D loss: 1.4038, G loss: 0.6496\n",
      "[884/1762] D loss: 1.3927, G loss: 0.7153\n",
      "[964/1762] D loss: 1.3951, G loss: 0.7287\n",
      "[1044/1762] D loss: 1.2268, G loss: 0.8105\n",
      "[1124/1762] D loss: 1.2910, G loss: 0.6945\n",
      "[1204/1762] D loss: 1.4383, G loss: 0.8914\n",
      "[1284/1762] D loss: 1.4429, G loss: 0.5889\n",
      "[1364/1762] D loss: 1.2151, G loss: 0.7933\n",
      "[1444/1762] D loss: 1.3821, G loss: 0.6574\n",
      "[1524/1762] D loss: 1.2188, G loss: 0.8955\n",
      "[1604/1762] D loss: 1.2267, G loss: 0.6954\n",
      "[1684/1762] D loss: 1.4394, G loss: 0.8949\n",
      "[1762/1762] D loss: 1.3349, G loss: 0.6960\n",
      "train error: \n",
      " D loss: 1.320154, G loss: 0.647016, D accuracy: 60.2%, cell accuracy: 98.9%, board accuracy: 28.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.310829, G loss: 0.650885, D accuracy: 59.7%, cell accuracy: 98.8%, board accuracy: 28.9% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3873, G loss: 0.5577\n",
      "[84/1762] D loss: 1.2378, G loss: 0.6513\n",
      "[164/1762] D loss: 1.3844, G loss: 0.6995\n",
      "[244/1762] D loss: 1.3867, G loss: 0.8250\n",
      "[324/1762] D loss: 1.3937, G loss: 0.7785\n",
      "[404/1762] D loss: 1.4156, G loss: 0.9515\n",
      "[484/1762] D loss: 1.2264, G loss: 0.7276\n",
      "[564/1762] D loss: 1.3968, G loss: 0.7600\n",
      "[644/1762] D loss: 1.4426, G loss: 0.8491\n",
      "[724/1762] D loss: 1.3904, G loss: 0.7792\n",
      "[804/1762] D loss: 1.3746, G loss: 0.7203\n",
      "[884/1762] D loss: 1.4207, G loss: 0.7629\n",
      "[964/1762] D loss: 1.3983, G loss: 0.8584\n",
      "[1044/1762] D loss: 1.3575, G loss: 0.7400\n",
      "[1124/1762] D loss: 1.5112, G loss: 0.7604\n",
      "[1204/1762] D loss: 1.3427, G loss: 0.8916\n",
      "[1284/1762] D loss: 1.6503, G loss: 0.4529\n",
      "[1364/1762] D loss: 1.7133, G loss: 0.5667\n",
      "[1444/1762] D loss: 1.7739, G loss: 0.7187\n",
      "[1524/1762] D loss: 1.5825, G loss: 0.6463\n",
      "[1604/1762] D loss: 1.5610, G loss: 0.8378\n",
      "[1684/1762] D loss: 1.5883, G loss: 0.7680\n",
      "[1762/1762] D loss: 1.3761, G loss: 0.7163\n",
      "train error: \n",
      " D loss: 1.446204, G loss: 0.690652, D accuracy: 45.8%, cell accuracy: 98.6%, board accuracy: 5.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.444507, G loss: 0.688912, D accuracy: 46.0%, cell accuracy: 98.6%, board accuracy: 5.5% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3085, G loss: 0.8877\n",
      "[84/1762] D loss: 1.4885, G loss: 0.5654\n",
      "[164/1762] D loss: 1.4334, G loss: 0.5792\n",
      "[244/1762] D loss: 1.3622, G loss: 0.7696\n",
      "[324/1762] D loss: 1.2677, G loss: 0.6712\n",
      "[404/1762] D loss: 1.3072, G loss: 0.6570\n",
      "[484/1762] D loss: 1.2479, G loss: 0.7160\n",
      "[564/1762] D loss: 1.2191, G loss: 0.7713\n",
      "[644/1762] D loss: 1.2646, G loss: 0.5632\n",
      "[724/1762] D loss: 1.4038, G loss: 0.6607\n",
      "[804/1762] D loss: 1.4207, G loss: 0.8555\n",
      "[884/1762] D loss: 1.4235, G loss: 0.8794\n",
      "[964/1762] D loss: 1.4451, G loss: 0.7761\n",
      "[1044/1762] D loss: 1.3974, G loss: 0.9631\n",
      "[1124/1762] D loss: 1.4329, G loss: 0.5676\n",
      "[1204/1762] D loss: 1.3821, G loss: 0.7017\n",
      "[1284/1762] D loss: 1.4223, G loss: 0.8389\n",
      "[1364/1762] D loss: 1.3958, G loss: 0.7669\n",
      "[1444/1762] D loss: 1.3427, G loss: 0.8284\n",
      "[1524/1762] D loss: 1.4376, G loss: 0.9052\n",
      "[1604/1762] D loss: 1.4063, G loss: 0.6029\n",
      "[1684/1762] D loss: 1.3976, G loss: 0.5784\n",
      "[1762/1762] D loss: 1.4178, G loss: 0.6878\n",
      "train error: \n",
      " D loss: 1.387809, G loss: 0.696822, D accuracy: 50.5%, cell accuracy: 99.8%, board accuracy: 86.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.386965, G loss: 0.692591, D accuracy: 50.7%, cell accuracy: 99.8%, board accuracy: 82.7% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4049, G loss: 0.6888\n",
      "[84/1762] D loss: 1.3522, G loss: 0.7101\n",
      "[164/1762] D loss: 1.3775, G loss: 0.6923\n",
      "[244/1762] D loss: 1.3881, G loss: 0.6892\n",
      "[324/1762] D loss: 1.3892, G loss: 0.7102\n",
      "[404/1762] D loss: 1.3702, G loss: 0.6250\n",
      "[484/1762] D loss: 1.3595, G loss: 0.6480\n",
      "[564/1762] D loss: 1.3932, G loss: 0.6924\n",
      "[644/1762] D loss: 1.3956, G loss: 0.8170\n",
      "[724/1762] D loss: 1.3915, G loss: 0.7149\n",
      "[804/1762] D loss: 1.3907, G loss: 0.6737\n",
      "[884/1762] D loss: 1.3507, G loss: 0.8177\n",
      "[964/1762] D loss: 1.4102, G loss: 0.6727\n",
      "[1044/1762] D loss: 1.3896, G loss: 0.6986\n",
      "[1124/1762] D loss: 1.3878, G loss: 0.7086\n",
      "[1204/1762] D loss: 1.3634, G loss: 0.7021\n",
      "[1284/1762] D loss: 1.3946, G loss: 0.6973\n",
      "[1364/1762] D loss: 1.3377, G loss: 0.7294\n",
      "[1444/1762] D loss: 1.3983, G loss: 0.7268\n",
      "[1524/1762] D loss: 1.3282, G loss: 0.7385\n",
      "[1604/1762] D loss: 1.3236, G loss: 0.7229\n",
      "[1684/1762] D loss: 1.3924, G loss: 0.7353\n",
      "[1762/1762] D loss: 1.3885, G loss: 0.6838\n",
      "train error: \n",
      " D loss: 1.372776, G loss: 0.754637, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 84.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.367937, G loss: 0.753910, D accuracy: 54.1%, cell accuracy: 99.7%, board accuracy: 79.5% \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3929, G loss: 0.7770\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6901\n",
      "[164/1762] D loss: 1.3483, G loss: 0.7523\n",
      "[244/1762] D loss: 1.3909, G loss: 0.7201\n",
      "[324/1762] D loss: 1.3968, G loss: 0.6985\n",
      "[404/1762] D loss: 1.3896, G loss: 0.6945\n",
      "[484/1762] D loss: 1.4033, G loss: 0.6556\n",
      "[564/1762] D loss: 1.4047, G loss: 0.6944\n",
      "[644/1762] D loss: 1.2878, G loss: 0.6786\n",
      "[724/1762] D loss: 1.3879, G loss: 0.6556\n",
      "[804/1762] D loss: 1.3153, G loss: 0.7641\n",
      "[884/1762] D loss: 1.3872, G loss: 0.7399\n",
      "[964/1762] D loss: 1.4132, G loss: 0.7661\n",
      "[1044/1762] D loss: 1.3909, G loss: 0.7013\n",
      "[1124/1762] D loss: 1.3658, G loss: 0.7498\n",
      "[1204/1762] D loss: 1.1324, G loss: 0.8235\n",
      "[1284/1762] D loss: 1.4009, G loss: 0.6887\n",
      "[1364/1762] D loss: 1.3934, G loss: 0.7092\n",
      "[1444/1762] D loss: 1.3872, G loss: 0.6961\n",
      "[1524/1762] D loss: 1.3915, G loss: 0.6996\n",
      "[1604/1762] D loss: 1.3876, G loss: 0.7485\n",
      "[1684/1762] D loss: 1.3121, G loss: 0.7871\n",
      "[1762/1762] D loss: 1.3915, G loss: 0.6749\n",
      "train error: \n",
      " D loss: 1.366467, G loss: 0.700660, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 87.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.362408, G loss: 0.699273, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 84.5% \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4103, G loss: 0.7107\n",
      "[84/1762] D loss: 1.3897, G loss: 0.6794\n",
      "[164/1762] D loss: 1.2912, G loss: 0.7188\n",
      "[244/1762] D loss: 1.2859, G loss: 0.7766\n",
      "[324/1762] D loss: 1.3912, G loss: 0.7337\n",
      "[404/1762] D loss: 1.3883, G loss: 0.7027\n",
      "[484/1762] D loss: 1.2960, G loss: 0.6987\n",
      "[564/1762] D loss: 1.3012, G loss: 0.6591\n",
      "[644/1762] D loss: 1.3375, G loss: 0.6609\n",
      "[724/1762] D loss: 1.2881, G loss: 0.6745\n",
      "[804/1762] D loss: 1.3884, G loss: 0.6822\n",
      "[884/1762] D loss: 1.3464, G loss: 0.7298\n",
      "[964/1762] D loss: 1.3948, G loss: 0.6655\n",
      "[1044/1762] D loss: 1.3985, G loss: 0.7936\n",
      "[1124/1762] D loss: 1.4002, G loss: 0.7611\n",
      "[1204/1762] D loss: 1.4036, G loss: 0.6671\n",
      "[1284/1762] D loss: 1.1508, G loss: 0.8188\n",
      "[1364/1762] D loss: 1.2561, G loss: 0.7570\n",
      "[1444/1762] D loss: 1.3916, G loss: 0.7262\n",
      "[1524/1762] D loss: 1.3865, G loss: 0.6866\n",
      "[1604/1762] D loss: 1.3906, G loss: 0.6992\n",
      "[1684/1762] D loss: 1.4083, G loss: 0.6107\n",
      "[1762/1762] D loss: 1.3983, G loss: 0.7919\n",
      "train error: \n",
      " D loss: 1.360995, G loss: 0.766199, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 88.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.354135, G loss: 0.767966, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 85.5% \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2840, G loss: 0.8101\n",
      "[84/1762] D loss: 1.3900, G loss: 0.6740\n",
      "[164/1762] D loss: 1.3890, G loss: 0.7155\n",
      "[244/1762] D loss: 1.2595, G loss: 0.7326\n",
      "[324/1762] D loss: 1.4002, G loss: 0.7747\n",
      "[404/1762] D loss: 1.3876, G loss: 0.7097\n",
      "[484/1762] D loss: 1.2723, G loss: 0.7753\n",
      "[564/1762] D loss: 1.2711, G loss: 0.6445\n",
      "[644/1762] D loss: 1.3379, G loss: 0.6814\n",
      "[724/1762] D loss: 1.3953, G loss: 0.6439\n",
      "[804/1762] D loss: 1.3768, G loss: 0.7444\n",
      "[884/1762] D loss: 1.2632, G loss: 0.8825\n",
      "[964/1762] D loss: 1.3999, G loss: 0.7956\n",
      "[1044/1762] D loss: 1.1100, G loss: 0.9224\n",
      "[1124/1762] D loss: 1.3951, G loss: 0.7122\n",
      "[1204/1762] D loss: 1.3997, G loss: 0.7418\n",
      "[1284/1762] D loss: 1.3906, G loss: 0.5570\n",
      "[1364/1762] D loss: 1.3861, G loss: 0.6247\n",
      "[1444/1762] D loss: 1.3884, G loss: 0.6746\n",
      "[1524/1762] D loss: 1.3796, G loss: 0.7073\n",
      "[1604/1762] D loss: 1.3934, G loss: 0.6860\n",
      "[1684/1762] D loss: 1.2209, G loss: 0.8611\n",
      "[1762/1762] D loss: 1.3894, G loss: 0.6547\n",
      "train error: \n",
      " D loss: 1.357601, G loss: 0.676490, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 76.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.346971, G loss: 0.685515, D accuracy: 55.5%, cell accuracy: 99.7%, board accuracy: 74.8% \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3829, G loss: 0.6458\n",
      "[84/1762] D loss: 1.3975, G loss: 0.6896\n",
      "[164/1762] D loss: 1.3906, G loss: 0.7206\n",
      "[244/1762] D loss: 1.4159, G loss: 0.5955\n",
      "[324/1762] D loss: 1.3771, G loss: 0.6223\n",
      "[404/1762] D loss: 1.2520, G loss: 0.7169\n",
      "[484/1762] D loss: 1.2440, G loss: 0.7751\n",
      "[564/1762] D loss: 1.2536, G loss: 0.6902\n",
      "[644/1762] D loss: 1.3869, G loss: 0.6663\n",
      "[724/1762] D loss: 1.3978, G loss: 0.6428\n",
      "[804/1762] D loss: 1.3696, G loss: 0.6338\n",
      "[884/1762] D loss: 1.3908, G loss: 0.7386\n",
      "[964/1762] D loss: 1.3914, G loss: 0.6851\n",
      "[1044/1762] D loss: 1.3632, G loss: 0.6742\n",
      "[1124/1762] D loss: 1.2192, G loss: 0.7202\n",
      "[1204/1762] D loss: 1.4000, G loss: 0.5935\n",
      "[1284/1762] D loss: 1.3931, G loss: 0.7197\n",
      "[1364/1762] D loss: 1.1631, G loss: 0.8583\n",
      "[1444/1762] D loss: 1.7469, G loss: 0.5674\n",
      "[1524/1762] D loss: 1.3721, G loss: 0.6665\n",
      "[1604/1762] D loss: 1.4168, G loss: 0.5430\n",
      "[1684/1762] D loss: 1.3463, G loss: 0.6628\n",
      "[1762/1762] D loss: 1.3416, G loss: 0.7155\n",
      "train error: \n",
      " D loss: 1.312989, G loss: 0.627493, D accuracy: 55.4%, cell accuracy: 98.9%, board accuracy: 16.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.312646, G loss: 0.634796, D accuracy: 56.9%, cell accuracy: 98.9%, board accuracy: 15.7% \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2995, G loss: 0.5570\n",
      "[84/1762] D loss: 1.2814, G loss: 0.8155\n",
      "[164/1762] D loss: 1.3078, G loss: 0.8641\n",
      "[244/1762] D loss: 1.3766, G loss: 1.0538\n",
      "[324/1762] D loss: 1.3906, G loss: 0.7779\n",
      "[404/1762] D loss: 1.3357, G loss: 0.7791\n",
      "[484/1762] D loss: 1.4031, G loss: 0.6569\n",
      "[564/1762] D loss: 1.3915, G loss: 0.6397\n",
      "[644/1762] D loss: 1.4053, G loss: 0.6605\n",
      "[724/1762] D loss: 1.4002, G loss: 0.6325\n",
      "[804/1762] D loss: 1.3935, G loss: 0.7438\n",
      "[884/1762] D loss: 1.3512, G loss: 0.7028\n",
      "[964/1762] D loss: 1.3211, G loss: 0.7014\n",
      "[1044/1762] D loss: 1.3985, G loss: 0.6273\n",
      "[1124/1762] D loss: 1.3986, G loss: 0.6002\n",
      "[1204/1762] D loss: 1.3942, G loss: 0.7295\n",
      "[1284/1762] D loss: 1.3869, G loss: 0.6771\n",
      "[1364/1762] D loss: 1.3880, G loss: 0.7234\n",
      "[1444/1762] D loss: 1.3699, G loss: 0.6488\n",
      "[1524/1762] D loss: 1.3924, G loss: 0.7458\n",
      "[1604/1762] D loss: 1.3867, G loss: 0.6944\n",
      "[1684/1762] D loss: 1.3908, G loss: 0.7122\n",
      "[1762/1762] D loss: 1.3873, G loss: 0.6788\n",
      "train error: \n",
      " D loss: 1.366205, G loss: 0.718744, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 88.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.360693, G loss: 0.726268, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 84.1% \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3017, G loss: 0.7211\n",
      "[84/1762] D loss: 1.3433, G loss: 0.7092\n",
      "[164/1762] D loss: 1.3890, G loss: 0.7182\n",
      "[244/1762] D loss: 1.3959, G loss: 0.6370\n",
      "[324/1762] D loss: 1.2844, G loss: 0.8128\n",
      "[404/1762] D loss: 1.3867, G loss: 0.7335\n",
      "[484/1762] D loss: 1.3988, G loss: 0.7365\n",
      "[564/1762] D loss: 1.4040, G loss: 0.6658\n",
      "[644/1762] D loss: 1.3910, G loss: 0.7019\n",
      "[724/1762] D loss: 1.2569, G loss: 0.7873\n",
      "[804/1762] D loss: 1.3786, G loss: 0.7030\n",
      "[884/1762] D loss: 1.3755, G loss: 0.7801\n",
      "[964/1762] D loss: 1.4000, G loss: 0.7267\n",
      "[1044/1762] D loss: 1.3838, G loss: 0.7472\n",
      "[1124/1762] D loss: 1.2264, G loss: 0.7889\n",
      "[1204/1762] D loss: 1.2050, G loss: 0.8120\n",
      "[1284/1762] D loss: 1.2915, G loss: 0.6821\n",
      "[1364/1762] D loss: 1.3891, G loss: 0.6540\n",
      "[1444/1762] D loss: 1.4089, G loss: 0.6532\n",
      "[1524/1762] D loss: 1.1582, G loss: 0.7874\n",
      "[1604/1762] D loss: 1.3253, G loss: 0.7475\n",
      "[1684/1762] D loss: 1.4349, G loss: 0.5787\n",
      "[1762/1762] D loss: 1.1598, G loss: 0.6758\n",
      "train error: \n",
      " D loss: 1.382296, G loss: 0.633204, D accuracy: 54.3%, cell accuracy: 99.7%, board accuracy: 63.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.373644, G loss: 0.637779, D accuracy: 54.3%, cell accuracy: 99.6%, board accuracy: 65.5% \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3816, G loss: 0.6940\n",
      "[84/1762] D loss: 1.3959, G loss: 0.6040\n",
      "[164/1762] D loss: 1.3857, G loss: 0.6461\n",
      "[244/1762] D loss: 1.2820, G loss: 0.6950\n",
      "[324/1762] D loss: 1.3198, G loss: 0.7048\n",
      "[404/1762] D loss: 1.4242, G loss: 0.5679\n",
      "[484/1762] D loss: 1.3968, G loss: 0.5907\n",
      "[564/1762] D loss: 1.3548, G loss: 0.7512\n",
      "[644/1762] D loss: 1.3260, G loss: 0.6757\n",
      "[724/1762] D loss: 1.3675, G loss: 0.6111\n",
      "[804/1762] D loss: 1.3769, G loss: 0.6260\n",
      "[884/1762] D loss: 1.3983, G loss: 0.6093\n",
      "[964/1762] D loss: 1.4386, G loss: 0.8826\n",
      "[1044/1762] D loss: 1.4169, G loss: 0.8863\n",
      "[1124/1762] D loss: 1.3929, G loss: 0.7957\n",
      "[1204/1762] D loss: 1.3908, G loss: 0.7462\n",
      "[1284/1762] D loss: 1.3643, G loss: 0.7695\n",
      "[1364/1762] D loss: 1.4061, G loss: 0.5954\n",
      "[1444/1762] D loss: 1.3891, G loss: 0.6308\n",
      "[1524/1762] D loss: 1.2905, G loss: 0.6870\n",
      "[1604/1762] D loss: 1.3903, G loss: 0.6785\n",
      "[1684/1762] D loss: 1.3887, G loss: 0.7446\n",
      "[1762/1762] D loss: 1.3802, G loss: 0.6293\n",
      "train error: \n",
      " D loss: 1.367248, G loss: 0.631052, D accuracy: 52.2%, cell accuracy: 99.8%, board accuracy: 83.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.361140, G loss: 0.633892, D accuracy: 52.3%, cell accuracy: 99.7%, board accuracy: 78.6% \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4034, G loss: 0.6271\n",
      "[84/1762] D loss: 1.3930, G loss: 0.6090\n",
      "[164/1762] D loss: 1.2471, G loss: 0.7025\n",
      "[244/1762] D loss: 1.1658, G loss: 0.7820\n",
      "[324/1762] D loss: 1.3913, G loss: 0.7020\n",
      "[404/1762] D loss: 1.3886, G loss: 0.7416\n",
      "[484/1762] D loss: 1.3011, G loss: 0.6742\n",
      "[564/1762] D loss: 1.3905, G loss: 0.6782\n",
      "[644/1762] D loss: 1.3948, G loss: 0.6958\n",
      "[724/1762] D loss: 1.3698, G loss: 0.7076\n",
      "[804/1762] D loss: 1.3967, G loss: 0.7359\n",
      "[884/1762] D loss: 1.4090, G loss: 0.7374\n",
      "[964/1762] D loss: 1.3751, G loss: 0.6971\n",
      "[1044/1762] D loss: 1.3926, G loss: 0.7344\n",
      "[1124/1762] D loss: 1.3892, G loss: 0.7096\n",
      "[1204/1762] D loss: 1.4230, G loss: 0.5081\n",
      "[1284/1762] D loss: 1.2696, G loss: 0.8471\n",
      "[1364/1762] D loss: 1.4002, G loss: 0.6764\n",
      "[1444/1762] D loss: 1.2332, G loss: 0.7241\n",
      "[1524/1762] D loss: 1.3955, G loss: 0.7945\n",
      "[1604/1762] D loss: 1.3929, G loss: 0.7661\n",
      "[1684/1762] D loss: 1.3382, G loss: 0.7659\n",
      "[1762/1762] D loss: 1.3979, G loss: 0.6136\n",
      "train error: \n",
      " D loss: 1.347647, G loss: 0.672195, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 85.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.336809, G loss: 0.678513, D accuracy: 55.5%, cell accuracy: 99.7%, board accuracy: 82.0% \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2063, G loss: 0.7889\n",
      "[84/1762] D loss: 1.3989, G loss: 0.8208\n",
      "[164/1762] D loss: 1.3916, G loss: 0.7229\n",
      "[244/1762] D loss: 1.2475, G loss: 0.7006\n",
      "[324/1762] D loss: 1.4021, G loss: 0.5879\n",
      "[404/1762] D loss: 1.3737, G loss: 0.7252\n",
      "[484/1762] D loss: 1.3886, G loss: 0.6960\n",
      "[564/1762] D loss: 1.2405, G loss: 0.8675\n",
      "[644/1762] D loss: 1.2332, G loss: 0.8783\n",
      "[724/1762] D loss: 1.3804, G loss: 0.7263\n",
      "[804/1762] D loss: 1.3926, G loss: 0.7589\n",
      "[884/1762] D loss: 1.2566, G loss: 0.9375\n",
      "[964/1762] D loss: 1.3975, G loss: 0.5923\n",
      "[1044/1762] D loss: 1.4348, G loss: 0.8072\n",
      "[1124/1762] D loss: 1.4132, G loss: 0.7928\n",
      "[1204/1762] D loss: 1.1845, G loss: 0.8368\n",
      "[1284/1762] D loss: 1.1833, G loss: 0.8753\n",
      "[1364/1762] D loss: 1.2233, G loss: 0.8105\n",
      "[1444/1762] D loss: 1.4027, G loss: 0.7769\n",
      "[1524/1762] D loss: 1.3914, G loss: 0.7044\n",
      "[1604/1762] D loss: 1.2218, G loss: 0.8708\n",
      "[1684/1762] D loss: 1.3945, G loss: 0.8333\n",
      "[1762/1762] D loss: 1.4018, G loss: 0.8110\n",
      "train error: \n",
      " D loss: 1.340912, G loss: 0.747223, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 83.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.327980, G loss: 0.753265, D accuracy: 55.0%, cell accuracy: 99.7%, board accuracy: 79.8% \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3890, G loss: 0.6969\n",
      "[84/1762] D loss: 1.3924, G loss: 0.6286\n",
      "[164/1762] D loss: 1.3875, G loss: 0.7020\n",
      "[244/1762] D loss: 1.4044, G loss: 0.7548\n",
      "[324/1762] D loss: 1.1822, G loss: 0.8343\n",
      "[404/1762] D loss: 1.2573, G loss: 0.9577\n",
      "[484/1762] D loss: 1.4118, G loss: 0.7935\n",
      "[564/1762] D loss: 1.2618, G loss: 0.9404\n",
      "[644/1762] D loss: 1.4251, G loss: 0.8411\n",
      "[724/1762] D loss: 1.3902, G loss: 0.6832\n",
      "[804/1762] D loss: 1.3933, G loss: 0.6730\n",
      "[884/1762] D loss: 1.1869, G loss: 0.7600\n",
      "[964/1762] D loss: 1.4026, G loss: 0.6522\n",
      "[1044/1762] D loss: 1.2781, G loss: 0.8027\n",
      "[1124/1762] D loss: 1.3897, G loss: 0.6531\n",
      "[1204/1762] D loss: 1.1831, G loss: 0.7712\n",
      "[1284/1762] D loss: 1.4072, G loss: 0.7455\n",
      "[1364/1762] D loss: 1.3882, G loss: 0.6458\n",
      "[1444/1762] D loss: 1.3910, G loss: 0.6658\n",
      "[1524/1762] D loss: 1.3988, G loss: 0.7302\n",
      "[1604/1762] D loss: 1.2065, G loss: 0.7763\n",
      "[1684/1762] D loss: 1.3964, G loss: 0.7175\n",
      "[1762/1762] D loss: 0.9809, G loss: 0.8518\n",
      "train error: \n",
      " D loss: 1.337762, G loss: 0.796441, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.323042, G loss: 0.806253, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3958, G loss: 0.7601\n",
      "[84/1762] D loss: 1.3868, G loss: 0.6973\n",
      "[164/1762] D loss: 1.1561, G loss: 0.8707\n",
      "[244/1762] D loss: 1.4040, G loss: 0.6811\n",
      "[324/1762] D loss: 1.3894, G loss: 0.8153\n",
      "[404/1762] D loss: 1.3875, G loss: 0.7730\n",
      "[484/1762] D loss: 1.3888, G loss: 0.6999\n",
      "[564/1762] D loss: 1.3841, G loss: 0.6364\n",
      "[644/1762] D loss: 1.3914, G loss: 0.6065\n",
      "[724/1762] D loss: 1.3928, G loss: 0.7715\n",
      "[804/1762] D loss: 1.1580, G loss: 0.8560\n",
      "[884/1762] D loss: 0.9433, G loss: 0.9053\n",
      "[964/1762] D loss: 1.3926, G loss: 0.7311\n",
      "[1044/1762] D loss: 1.4132, G loss: 0.7611\n",
      "[1124/1762] D loss: 1.4049, G loss: 0.7528\n",
      "[1204/1762] D loss: 1.1612, G loss: 0.9625\n",
      "[1284/1762] D loss: 1.3818, G loss: 0.6477\n",
      "[1364/1762] D loss: 1.4033, G loss: 0.6659\n",
      "[1444/1762] D loss: 1.3692, G loss: 0.7616\n",
      "[1524/1762] D loss: 1.3866, G loss: 0.6452\n",
      "[1604/1762] D loss: 1.3978, G loss: 0.6577\n",
      "[1684/1762] D loss: 1.3460, G loss: 0.6810\n",
      "[1762/1762] D loss: 1.3959, G loss: 0.6648\n",
      "train error: \n",
      " D loss: 1.330548, G loss: 0.763629, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.315723, G loss: 0.773284, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4177, G loss: 0.7843\n",
      "[84/1762] D loss: 1.3996, G loss: 0.5578\n",
      "[164/1762] D loss: 1.3895, G loss: 0.6682\n",
      "[244/1762] D loss: 1.1614, G loss: 0.7925\n",
      "[324/1762] D loss: 1.4234, G loss: 0.8283\n",
      "[404/1762] D loss: 1.1344, G loss: 0.8080\n",
      "[484/1762] D loss: 1.2161, G loss: 0.7455\n",
      "[564/1762] D loss: 1.3956, G loss: 0.6934\n",
      "[644/1762] D loss: 1.4247, G loss: 0.5422\n",
      "[724/1762] D loss: 1.3901, G loss: 0.6212\n",
      "[804/1762] D loss: 1.3946, G loss: 0.6840\n",
      "[884/1762] D loss: 1.1581, G loss: 0.8595\n",
      "[964/1762] D loss: 1.4067, G loss: 0.8272\n",
      "[1044/1762] D loss: 1.1538, G loss: 0.8584\n",
      "[1124/1762] D loss: 1.1949, G loss: 0.8378\n",
      "[1204/1762] D loss: 1.1869, G loss: 0.7069\n",
      "[1284/1762] D loss: 1.1635, G loss: 0.7359\n",
      "[1364/1762] D loss: 1.4040, G loss: 0.7177\n",
      "[1444/1762] D loss: 1.4001, G loss: 0.6478\n",
      "[1524/1762] D loss: 1.3750, G loss: 0.7821\n",
      "[1604/1762] D loss: 0.9011, G loss: 1.1242\n",
      "[1684/1762] D loss: 1.4104, G loss: 0.7653\n",
      "[1762/1762] D loss: 1.3915, G loss: 0.7983\n",
      "train error: \n",
      " D loss: 1.334626, G loss: 0.884165, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 77.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.315321, G loss: 0.897637, D accuracy: 55.1%, cell accuracy: 99.7%, board accuracy: 72.0% \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1544, G loss: 1.0082\n",
      "[84/1762] D loss: 1.3876, G loss: 0.7448\n",
      "[164/1762] D loss: 1.3930, G loss: 0.8294\n",
      "[244/1762] D loss: 1.1306, G loss: 0.9438\n",
      "[324/1762] D loss: 1.3922, G loss: 0.6154\n",
      "[404/1762] D loss: 1.3912, G loss: 0.6828\n",
      "[484/1762] D loss: 1.4105, G loss: 0.8235\n",
      "[564/1762] D loss: 1.4106, G loss: 0.8113\n",
      "[644/1762] D loss: 1.4160, G loss: 0.7974\n",
      "[724/1762] D loss: 1.3993, G loss: 0.7927\n",
      "[804/1762] D loss: 1.4109, G loss: 0.8161\n",
      "[884/1762] D loss: 1.4487, G loss: 0.6964\n",
      "[964/1762] D loss: 1.3891, G loss: 0.6149\n",
      "[1044/1762] D loss: 1.4049, G loss: 0.8859\n",
      "[1124/1762] D loss: 1.1553, G loss: 0.8970\n",
      "[1204/1762] D loss: 1.3918, G loss: 0.8190\n",
      "[1284/1762] D loss: 1.4209, G loss: 0.6114\n",
      "[1364/1762] D loss: 1.4001, G loss: 0.6612\n",
      "[1444/1762] D loss: 1.3385, G loss: 0.7679\n",
      "[1524/1762] D loss: 1.3991, G loss: 0.7152\n",
      "[1604/1762] D loss: 1.4023, G loss: 0.7591\n",
      "[1684/1762] D loss: 1.6957, G loss: 0.8019\n",
      "[1762/1762] D loss: 1.6747, G loss: 0.6170\n",
      "train error: \n",
      " D loss: 1.482023, G loss: 0.750598, D accuracy: 30.4%, cell accuracy: 98.6%, board accuracy: 20.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.469683, G loss: 0.753375, D accuracy: 31.5%, cell accuracy: 98.6%, board accuracy: 20.0% \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5610, G loss: 0.6806\n",
      "[84/1762] D loss: 1.4009, G loss: 0.9458\n",
      "[164/1762] D loss: 1.2091, G loss: 0.7589\n",
      "[244/1762] D loss: 1.0312, G loss: 0.8158\n",
      "[324/1762] D loss: 1.4357, G loss: 0.6526\n",
      "[404/1762] D loss: 1.4086, G loss: 0.6056\n",
      "[484/1762] D loss: 1.3692, G loss: 0.7373\n",
      "[564/1762] D loss: 1.4032, G loss: 0.4806\n",
      "[644/1762] D loss: 1.3202, G loss: 0.5586\n",
      "[724/1762] D loss: 1.4035, G loss: 0.7576\n",
      "[804/1762] D loss: 1.5168, G loss: 1.0515\n",
      "[884/1762] D loss: 1.3850, G loss: 0.7746\n",
      "[964/1762] D loss: 1.3906, G loss: 0.5924\n",
      "[1044/1762] D loss: 1.4047, G loss: 0.6399\n",
      "[1124/1762] D loss: 1.3881, G loss: 0.6097\n",
      "[1204/1762] D loss: 1.3918, G loss: 0.6420\n",
      "[1284/1762] D loss: 1.3970, G loss: 0.7064\n",
      "[1364/1762] D loss: 1.4024, G loss: 0.7607\n",
      "[1444/1762] D loss: 1.3932, G loss: 0.6471\n",
      "[1524/1762] D loss: 1.2994, G loss: 0.6753\n",
      "[1604/1762] D loss: 1.4052, G loss: 0.8336\n",
      "[1684/1762] D loss: 1.4025, G loss: 0.5939\n",
      "[1762/1762] D loss: 1.3981, G loss: 0.7409\n",
      "train error: \n",
      " D loss: 1.341716, G loss: 0.716477, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.329922, G loss: 0.721890, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 85.5% \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3958, G loss: 0.6287\n",
      "[84/1762] D loss: 1.2841, G loss: 0.6173\n",
      "[164/1762] D loss: 1.3844, G loss: 0.7311\n",
      "[244/1762] D loss: 1.3759, G loss: 0.6462\n",
      "[324/1762] D loss: 1.4052, G loss: 0.8369\n",
      "[404/1762] D loss: 1.3973, G loss: 0.6539\n",
      "[484/1762] D loss: 1.4024, G loss: 0.7641\n",
      "[564/1762] D loss: 1.2077, G loss: 0.8451\n",
      "[644/1762] D loss: 1.3864, G loss: 0.7265\n",
      "[724/1762] D loss: 1.3877, G loss: 0.6559\n",
      "[804/1762] D loss: 1.3932, G loss: 0.6853\n",
      "[884/1762] D loss: 1.3872, G loss: 0.6781\n",
      "[964/1762] D loss: 1.1859, G loss: 0.9036\n",
      "[1044/1762] D loss: 1.4125, G loss: 0.8279\n",
      "[1124/1762] D loss: 1.1705, G loss: 0.9033\n",
      "[1204/1762] D loss: 1.0022, G loss: 1.0132\n",
      "[1284/1762] D loss: 1.3987, G loss: 0.6605\n",
      "[1364/1762] D loss: 1.3960, G loss: 0.6301\n",
      "[1444/1762] D loss: 1.3928, G loss: 0.6914\n",
      "[1524/1762] D loss: 1.0069, G loss: 0.9883\n",
      "[1604/1762] D loss: 1.3945, G loss: 0.7455\n",
      "[1684/1762] D loss: 1.3890, G loss: 0.7679\n",
      "[1762/1762] D loss: 1.0094, G loss: 0.9076\n",
      "train error: \n",
      " D loss: 1.344227, G loss: 0.838231, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.327926, G loss: 0.846205, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4000, G loss: 0.7640\n",
      "[84/1762] D loss: 1.2067, G loss: 0.8350\n",
      "[164/1762] D loss: 1.3899, G loss: 0.6700\n",
      "[244/1762] D loss: 1.3898, G loss: 0.7183\n",
      "[324/1762] D loss: 1.3902, G loss: 0.6862\n",
      "[404/1762] D loss: 1.3932, G loss: 0.7519\n",
      "[484/1762] D loss: 1.3999, G loss: 0.7107\n",
      "[564/1762] D loss: 1.4027, G loss: 0.5895\n",
      "[644/1762] D loss: 1.3897, G loss: 0.6263\n",
      "[724/1762] D loss: 1.2100, G loss: 0.8206\n",
      "[804/1762] D loss: 1.3896, G loss: 0.7031\n",
      "[884/1762] D loss: 1.3910, G loss: 0.6567\n",
      "[964/1762] D loss: 1.3879, G loss: 0.7663\n",
      "[1044/1762] D loss: 1.1738, G loss: 0.7678\n",
      "[1124/1762] D loss: 1.4010, G loss: 0.6105\n",
      "[1204/1762] D loss: 1.4145, G loss: 0.8260\n",
      "[1284/1762] D loss: 1.3892, G loss: 0.6874\n",
      "[1364/1762] D loss: 1.3949, G loss: 0.7647\n",
      "[1444/1762] D loss: 1.3990, G loss: 0.6308\n",
      "[1524/1762] D loss: 1.3913, G loss: 0.6801\n",
      "[1604/1762] D loss: 1.3937, G loss: 0.6326\n",
      "[1684/1762] D loss: 1.3885, G loss: 0.7296\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.7070\n",
      "train error: \n",
      " D loss: 1.335167, G loss: 0.830226, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 91.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.317585, G loss: 0.840944, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3927, G loss: 0.7480\n",
      "[84/1762] D loss: 1.4133, G loss: 0.6894\n",
      "[164/1762] D loss: 1.3956, G loss: 0.7037\n",
      "[244/1762] D loss: 1.1742, G loss: 0.9608\n",
      "[324/1762] D loss: 0.9685, G loss: 1.0485\n",
      "[404/1762] D loss: 1.3897, G loss: 0.6448\n",
      "[484/1762] D loss: 1.1853, G loss: 0.6660\n",
      "[564/1762] D loss: 1.3975, G loss: 0.7800\n",
      "[644/1762] D loss: 1.3963, G loss: 0.7231\n",
      "[724/1762] D loss: 1.3933, G loss: 0.7252\n",
      "[804/1762] D loss: 1.4031, G loss: 0.6453\n",
      "[884/1762] D loss: 1.3956, G loss: 0.6325\n",
      "[964/1762] D loss: 1.3940, G loss: 0.7493\n",
      "[1044/1762] D loss: 1.4076, G loss: 0.8176\n",
      "[1124/1762] D loss: 1.3934, G loss: 0.6627\n",
      "[1204/1762] D loss: 1.3975, G loss: 0.6314\n",
      "[1284/1762] D loss: 1.4128, G loss: 0.7362\n",
      "[1364/1762] D loss: 1.4369, G loss: 0.7882\n",
      "[1444/1762] D loss: 1.5641, G loss: 0.6461\n",
      "[1524/1762] D loss: 1.4647, G loss: 0.7073\n",
      "[1604/1762] D loss: 1.2430, G loss: 0.6773\n",
      "[1684/1762] D loss: 1.2536, G loss: 0.8578\n",
      "[1762/1762] D loss: 1.4348, G loss: 0.9223\n",
      "train error: \n",
      " D loss: 1.363156, G loss: 0.809894, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 87.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.353104, G loss: 0.816555, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3986, G loss: 0.7563\n",
      "[84/1762] D loss: 1.3777, G loss: 0.8292\n",
      "[164/1762] D loss: 1.3854, G loss: 0.6873\n",
      "[244/1762] D loss: 1.4347, G loss: 0.8114\n",
      "[324/1762] D loss: 1.0076, G loss: 0.9114\n",
      "[404/1762] D loss: 1.0617, G loss: 0.7974\n",
      "[484/1762] D loss: 1.3859, G loss: 0.6508\n",
      "[564/1762] D loss: 1.4130, G loss: 0.8067\n",
      "[644/1762] D loss: 1.3947, G loss: 0.7117\n",
      "[724/1762] D loss: 1.3895, G loss: 0.7393\n",
      "[804/1762] D loss: 1.3769, G loss: 0.6892\n",
      "[884/1762] D loss: 1.3918, G loss: 0.6346\n",
      "[964/1762] D loss: 1.1719, G loss: 0.7753\n",
      "[1044/1762] D loss: 1.2394, G loss: 0.8333\n",
      "[1124/1762] D loss: 1.2066, G loss: 0.6800\n",
      "[1204/1762] D loss: 1.4005, G loss: 0.5836\n",
      "[1284/1762] D loss: 1.4252, G loss: 0.5261\n",
      "[1364/1762] D loss: 1.3889, G loss: 0.6380\n",
      "[1444/1762] D loss: 1.4198, G loss: 0.8484\n",
      "[1524/1762] D loss: 1.3902, G loss: 0.7080\n",
      "[1604/1762] D loss: 1.3527, G loss: 0.6977\n",
      "[1684/1762] D loss: 1.4235, G loss: 0.7548\n",
      "[1762/1762] D loss: 1.3976, G loss: 0.7665\n",
      "train error: \n",
      " D loss: 1.333719, G loss: 0.803913, D accuracy: 54.0%, cell accuracy: 99.7%, board accuracy: 77.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.317645, G loss: 0.811268, D accuracy: 54.0%, cell accuracy: 99.7%, board accuracy: 77.5% \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3958, G loss: 0.7112\n",
      "[84/1762] D loss: 1.1786, G loss: 0.7857\n",
      "[164/1762] D loss: 1.1625, G loss: 0.8065\n",
      "[244/1762] D loss: 1.3908, G loss: 0.6768\n",
      "[324/1762] D loss: 1.3827, G loss: 0.8661\n",
      "[404/1762] D loss: 1.4139, G loss: 0.8571\n",
      "[484/1762] D loss: 1.2296, G loss: 0.9477\n",
      "[564/1762] D loss: 1.3917, G loss: 0.8350\n",
      "[644/1762] D loss: 1.3920, G loss: 0.6570\n",
      "[724/1762] D loss: 1.3928, G loss: 0.7406\n",
      "[804/1762] D loss: 1.3869, G loss: 0.6589\n",
      "[884/1762] D loss: 1.3957, G loss: 0.8084\n",
      "[964/1762] D loss: 1.4221, G loss: 0.6838\n",
      "[1044/1762] D loss: 1.1729, G loss: 0.9685\n",
      "[1124/1762] D loss: 1.3916, G loss: 0.5815\n",
      "[1204/1762] D loss: 1.3496, G loss: 0.7368\n",
      "[1284/1762] D loss: 1.3610, G loss: 0.7045\n",
      "[1364/1762] D loss: 1.2047, G loss: 0.7981\n",
      "[1444/1762] D loss: 1.4056, G loss: 0.6625\n",
      "[1524/1762] D loss: 1.3818, G loss: 0.7927\n",
      "[1604/1762] D loss: 1.3905, G loss: 0.7371\n",
      "[1684/1762] D loss: 1.1665, G loss: 0.8537\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.7066\n",
      "train error: \n",
      " D loss: 1.330328, G loss: 0.714358, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.313925, G loss: 0.719089, D accuracy: 55.6%, cell accuracy: 99.8%, board accuracy: 84.1% \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3540, G loss: 0.6897\n",
      "[84/1762] D loss: 1.3973, G loss: 0.6447\n",
      "[164/1762] D loss: 1.3702, G loss: 0.6556\n",
      "[244/1762] D loss: 1.3958, G loss: 0.6206\n",
      "[324/1762] D loss: 1.4079, G loss: 0.7317\n",
      "[404/1762] D loss: 1.4200, G loss: 0.8486\n",
      "[484/1762] D loss: 1.4472, G loss: 0.9020\n",
      "[564/1762] D loss: 1.1311, G loss: 0.9984\n",
      "[644/1762] D loss: 1.4119, G loss: 0.6351\n",
      "[724/1762] D loss: 1.3933, G loss: 0.7591\n",
      "[804/1762] D loss: 1.3930, G loss: 0.7383\n",
      "[884/1762] D loss: 1.1715, G loss: 0.9012\n",
      "[964/1762] D loss: 1.1931, G loss: 0.7352\n",
      "[1044/1762] D loss: 1.4002, G loss: 0.6088\n",
      "[1124/1762] D loss: 1.3952, G loss: 0.7196\n",
      "[1204/1762] D loss: 1.3968, G loss: 0.7044\n",
      "[1284/1762] D loss: 1.3947, G loss: 0.7434\n",
      "[1364/1762] D loss: 1.4005, G loss: 0.8034\n",
      "[1444/1762] D loss: 1.4167, G loss: 0.8026\n",
      "[1524/1762] D loss: 1.3886, G loss: 0.6305\n",
      "[1604/1762] D loss: 1.3911, G loss: 0.7190\n",
      "[1684/1762] D loss: 1.3967, G loss: 0.6861\n",
      "[1762/1762] D loss: 0.9009, G loss: 0.9377\n",
      "train error: \n",
      " D loss: 1.329449, G loss: 0.789141, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.312389, G loss: 0.794598, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 83.6% \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4155, G loss: 0.8259\n",
      "[84/1762] D loss: 1.1796, G loss: 0.7788\n",
      "[164/1762] D loss: 1.3983, G loss: 0.5720\n",
      "[244/1762] D loss: 1.3967, G loss: 0.6711\n",
      "[324/1762] D loss: 1.1609, G loss: 1.0095\n",
      "[404/1762] D loss: 1.3951, G loss: 0.6847\n",
      "[484/1762] D loss: 1.3927, G loss: 0.6764\n",
      "[564/1762] D loss: 1.1403, G loss: 0.8267\n",
      "[644/1762] D loss: 1.3766, G loss: 0.8381\n",
      "[724/1762] D loss: 1.3890, G loss: 0.7619\n",
      "[804/1762] D loss: 1.4103, G loss: 0.8461\n",
      "[884/1762] D loss: 1.1562, G loss: 0.7445\n",
      "[964/1762] D loss: 1.1429, G loss: 0.8171\n",
      "[1044/1762] D loss: 1.3899, G loss: 0.6367\n",
      "[1124/1762] D loss: 1.1808, G loss: 0.9219\n",
      "[1204/1762] D loss: 1.3769, G loss: 0.6947\n",
      "[1284/1762] D loss: 1.1444, G loss: 0.8096\n",
      "[1364/1762] D loss: 0.9390, G loss: 0.9331\n",
      "[1444/1762] D loss: 1.4000, G loss: 0.6255\n",
      "[1524/1762] D loss: 1.1496, G loss: 0.7518\n",
      "[1604/1762] D loss: 1.3898, G loss: 0.8005\n",
      "[1684/1762] D loss: 1.4395, G loss: 0.7583\n",
      "[1762/1762] D loss: 1.3920, G loss: 0.6435\n",
      "train error: \n",
      " D loss: 1.328692, G loss: 0.705310, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 90.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.311125, G loss: 0.713792, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3893, G loss: 0.6896\n",
      "[84/1762] D loss: 1.3937, G loss: 0.7152\n",
      "[164/1762] D loss: 1.3921, G loss: 0.6632\n",
      "[244/1762] D loss: 1.1432, G loss: 0.8572\n",
      "[324/1762] D loss: 1.4018, G loss: 0.6007\n",
      "[404/1762] D loss: 1.4135, G loss: 0.8446\n",
      "[484/1762] D loss: 1.3899, G loss: 0.7781\n",
      "[564/1762] D loss: 1.4095, G loss: 0.6666\n",
      "[644/1762] D loss: 1.3925, G loss: 0.6706\n",
      "[724/1762] D loss: 1.3957, G loss: 0.7953\n",
      "[804/1762] D loss: 1.3964, G loss: 0.6857\n",
      "[884/1762] D loss: 1.3879, G loss: 0.7006\n",
      "[964/1762] D loss: 1.4010, G loss: 0.5904\n",
      "[1044/1762] D loss: 1.3895, G loss: 0.6872\n",
      "[1124/1762] D loss: 1.4020, G loss: 0.7337\n",
      "[1204/1762] D loss: 1.3922, G loss: 0.6680\n",
      "[1284/1762] D loss: 1.3963, G loss: 0.6686\n",
      "[1364/1762] D loss: 0.9321, G loss: 0.8835\n",
      "[1444/1762] D loss: 1.4309, G loss: 0.8312\n",
      "[1524/1762] D loss: 1.4172, G loss: 0.7823\n",
      "[1604/1762] D loss: 1.1775, G loss: 0.9026\n",
      "[1684/1762] D loss: 1.1250, G loss: 0.9658\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.6552\n",
      "train error: \n",
      " D loss: 1.325479, G loss: 0.723383, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 90.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.307540, G loss: 0.733601, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3904, G loss: 0.6444\n",
      "[84/1762] D loss: 1.3597, G loss: 0.7208\n",
      "[164/1762] D loss: 1.4069, G loss: 0.7113\n",
      "[244/1762] D loss: 1.3965, G loss: 0.7663\n",
      "[324/1762] D loss: 1.3984, G loss: 0.7615\n",
      "[404/1762] D loss: 1.1469, G loss: 0.7641\n",
      "[484/1762] D loss: 1.4165, G loss: 0.8420\n",
      "[564/1762] D loss: 1.3827, G loss: 0.6692\n",
      "[644/1762] D loss: 1.3917, G loss: 0.6786\n",
      "[724/1762] D loss: 1.4095, G loss: 0.5353\n",
      "[804/1762] D loss: 1.3902, G loss: 0.7230\n",
      "[884/1762] D loss: 1.4000, G loss: 0.6444\n",
      "[964/1762] D loss: 1.3875, G loss: 0.6688\n",
      "[1044/1762] D loss: 1.3970, G loss: 0.8202\n",
      "[1124/1762] D loss: 1.3912, G loss: 0.6486\n",
      "[1204/1762] D loss: 1.3875, G loss: 0.6598\n",
      "[1284/1762] D loss: 1.4274, G loss: 0.6676\n",
      "[1364/1762] D loss: 1.1631, G loss: 0.8003\n",
      "[1444/1762] D loss: 1.1391, G loss: 0.8847\n",
      "[1524/1762] D loss: 1.3905, G loss: 0.7081\n",
      "[1604/1762] D loss: 1.3959, G loss: 0.6624\n",
      "[1684/1762] D loss: 1.3896, G loss: 0.6991\n",
      "[1762/1762] D loss: 1.4366, G loss: 1.0163\n",
      "train error: \n",
      " D loss: 1.323702, G loss: 0.789999, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.303643, G loss: 0.802291, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3918, G loss: 0.6672\n",
      "[84/1762] D loss: 1.3956, G loss: 0.6725\n",
      "[164/1762] D loss: 1.1667, G loss: 0.7181\n",
      "[244/1762] D loss: 1.3572, G loss: 0.8053\n",
      "[324/1762] D loss: 0.6689, G loss: 1.0536\n",
      "[404/1762] D loss: 1.3876, G loss: 0.6798\n",
      "[484/1762] D loss: 1.2060, G loss: 0.9125\n",
      "[564/1762] D loss: 1.3880, G loss: 0.6783\n",
      "[644/1762] D loss: 1.4284, G loss: 0.8031\n",
      "[724/1762] D loss: 1.1569, G loss: 0.9262\n",
      "[804/1762] D loss: 1.1804, G loss: 1.1118\n",
      "[884/1762] D loss: 1.3947, G loss: 0.7289\n",
      "[964/1762] D loss: 1.4084, G loss: 0.6008\n",
      "[1044/1762] D loss: 1.1395, G loss: 0.8032\n",
      "[1124/1762] D loss: 1.3892, G loss: 0.6473\n",
      "[1204/1762] D loss: 1.4300, G loss: 0.9169\n",
      "[1284/1762] D loss: 1.4018, G loss: 0.6651\n",
      "[1364/1762] D loss: 1.4057, G loss: 0.6417\n",
      "[1444/1762] D loss: 1.1379, G loss: 0.8366\n",
      "[1524/1762] D loss: 1.3910, G loss: 0.6794\n",
      "[1604/1762] D loss: 1.3946, G loss: 0.6822\n",
      "[1684/1762] D loss: 1.3895, G loss: 0.6449\n",
      "[1762/1762] D loss: 1.4016, G loss: 0.7216\n",
      "train error: \n",
      " D loss: 1.324482, G loss: 0.772506, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.305695, G loss: 0.785110, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 84.3% \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3796, G loss: 0.7487\n",
      "[84/1762] D loss: 1.4005, G loss: 0.7701\n",
      "[164/1762] D loss: 1.3993, G loss: 0.7730\n",
      "[244/1762] D loss: 0.8876, G loss: 1.0966\n",
      "[324/1762] D loss: 1.3972, G loss: 0.6509\n",
      "[404/1762] D loss: 1.1546, G loss: 0.7526\n",
      "[484/1762] D loss: 1.1470, G loss: 0.9638\n",
      "[564/1762] D loss: 1.3814, G loss: 0.6164\n",
      "[644/1762] D loss: 1.3840, G loss: 0.6962\n",
      "[724/1762] D loss: 1.4044, G loss: 0.7493\n",
      "[804/1762] D loss: 1.3866, G loss: 0.7796\n",
      "[884/1762] D loss: 0.9119, G loss: 1.0070\n",
      "[964/1762] D loss: 1.4484, G loss: 0.5023\n",
      "[1044/1762] D loss: 1.1664, G loss: 0.7204\n",
      "[1124/1762] D loss: 1.1450, G loss: 0.7633\n",
      "[1204/1762] D loss: 1.4709, G loss: 0.9695\n",
      "[1284/1762] D loss: 1.3829, G loss: 0.7515\n",
      "[1364/1762] D loss: 1.4028, G loss: 0.5903\n",
      "[1444/1762] D loss: 1.3898, G loss: 0.6079\n",
      "[1524/1762] D loss: 1.1304, G loss: 0.9629\n",
      "[1604/1762] D loss: 1.4124, G loss: 0.9121\n",
      "[1684/1762] D loss: 2.9349, G loss: 0.7612\n",
      "[1762/1762] D loss: 1.9617, G loss: 0.7799\n",
      "train error: \n",
      " D loss: 1.827707, G loss: 0.855012, D accuracy: 46.7%, cell accuracy: 96.3%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.809508, G loss: 0.859962, D accuracy: 47.8%, cell accuracy: 96.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5231, G loss: 1.0166\n",
      "[84/1762] D loss: 1.5577, G loss: 0.7507\n",
      "[164/1762] D loss: 1.4608, G loss: 0.6729\n",
      "[244/1762] D loss: 1.4417, G loss: 0.6299\n",
      "[324/1762] D loss: 1.4864, G loss: 0.6583\n",
      "[404/1762] D loss: 1.4709, G loss: 0.7326\n",
      "[484/1762] D loss: 1.4300, G loss: 0.6807\n",
      "[564/1762] D loss: 1.4483, G loss: 0.6430\n",
      "[644/1762] D loss: 1.3919, G loss: 0.7261\n",
      "[724/1762] D loss: 1.4546, G loss: 0.7097\n",
      "[804/1762] D loss: 1.4727, G loss: 0.7894\n",
      "[884/1762] D loss: 1.4720, G loss: 0.6816\n",
      "[964/1762] D loss: 1.3760, G loss: 0.6983\n",
      "[1044/1762] D loss: 1.4561, G loss: 0.8607\n",
      "[1124/1762] D loss: 1.1991, G loss: 0.6967\n",
      "[1204/1762] D loss: 1.0787, G loss: 0.6976\n",
      "[1284/1762] D loss: 1.1811, G loss: 1.0532\n",
      "[1364/1762] D loss: 0.9669, G loss: 0.7551\n",
      "[1444/1762] D loss: 0.9247, G loss: 0.8871\n",
      "[1524/1762] D loss: 1.4318, G loss: 0.6390\n",
      "[1604/1762] D loss: 1.3959, G loss: 0.6952\n",
      "[1684/1762] D loss: 1.3920, G loss: 0.7001\n",
      "[1762/1762] D loss: 1.3854, G loss: 0.6764\n",
      "train error: \n",
      " D loss: 1.416127, G loss: 0.744446, D accuracy: 48.5%, cell accuracy: 99.7%, board accuracy: 78.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.420343, G loss: 0.746743, D accuracy: 47.7%, cell accuracy: 99.6%, board accuracy: 73.2% \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3817, G loss: 0.6670\n",
      "[84/1762] D loss: 1.4442, G loss: 0.7396\n",
      "[164/1762] D loss: 1.4885, G loss: 0.8307\n",
      "[244/1762] D loss: 1.3865, G loss: 0.7080\n",
      "[324/1762] D loss: 1.4014, G loss: 0.7177\n",
      "[404/1762] D loss: 1.3959, G loss: 0.7249\n",
      "[484/1762] D loss: 1.3939, G loss: 0.7481\n",
      "[564/1762] D loss: 1.3882, G loss: 0.7797\n",
      "[644/1762] D loss: 1.4005, G loss: 0.6085\n",
      "[724/1762] D loss: 1.3932, G loss: 0.6172\n",
      "[804/1762] D loss: 1.3966, G loss: 0.7802\n",
      "[884/1762] D loss: 1.3929, G loss: 0.7339\n",
      "[964/1762] D loss: 1.3935, G loss: 0.7614\n",
      "[1044/1762] D loss: 1.3884, G loss: 0.6765\n",
      "[1124/1762] D loss: 1.3877, G loss: 0.6655\n",
      "[1204/1762] D loss: 1.3874, G loss: 0.6885\n",
      "[1284/1762] D loss: 1.3886, G loss: 0.7329\n",
      "[1364/1762] D loss: 1.3913, G loss: 0.6767\n",
      "[1444/1762] D loss: 1.3895, G loss: 0.7038\n",
      "[1524/1762] D loss: 1.3835, G loss: 0.7215\n",
      "[1604/1762] D loss: 1.3958, G loss: 0.6821\n",
      "[1684/1762] D loss: 1.4257, G loss: 0.6809\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.6937\n",
      "train error: \n",
      " D loss: 1.392262, G loss: 0.703297, D accuracy: 49.7%, cell accuracy: 99.7%, board accuracy: 77.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.393176, G loss: 0.703224, D accuracy: 48.6%, cell accuracy: 99.6%, board accuracy: 74.1% \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3929, G loss: 0.6507\n",
      "[84/1762] D loss: 1.3875, G loss: 0.6698\n",
      "[164/1762] D loss: 1.4063, G loss: 0.7081\n",
      "[244/1762] D loss: 1.3898, G loss: 0.6909\n",
      "[324/1762] D loss: 1.3919, G loss: 0.7223\n",
      "[404/1762] D loss: 1.3990, G loss: 0.6989\n",
      "[484/1762] D loss: 1.3805, G loss: 0.7234\n",
      "[564/1762] D loss: 1.3870, G loss: 0.7291\n",
      "[644/1762] D loss: 1.3856, G loss: 0.7161\n",
      "[724/1762] D loss: 1.3831, G loss: 0.6998\n",
      "[804/1762] D loss: 1.3936, G loss: 0.6680\n",
      "[884/1762] D loss: 1.3962, G loss: 0.7590\n",
      "[964/1762] D loss: 1.3883, G loss: 0.6818\n",
      "[1044/1762] D loss: 1.3904, G loss: 0.6675\n",
      "[1124/1762] D loss: 1.3868, G loss: 0.6831\n",
      "[1204/1762] D loss: 1.3849, G loss: 0.7259\n",
      "[1284/1762] D loss: 1.3871, G loss: 0.7433\n",
      "[1364/1762] D loss: 1.3840, G loss: 0.6769\n",
      "[1444/1762] D loss: 1.3850, G loss: 0.6700\n",
      "[1524/1762] D loss: 1.3957, G loss: 0.6548\n",
      "[1604/1762] D loss: 1.3647, G loss: 0.6549\n",
      "[1684/1762] D loss: 1.3857, G loss: 0.7219\n",
      "[1762/1762] D loss: 1.3852, G loss: 0.6566\n",
      "train error: \n",
      " D loss: 1.384567, G loss: 0.692138, D accuracy: 51.8%, cell accuracy: 99.4%, board accuracy: 63.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.384884, G loss: 0.690278, D accuracy: 51.9%, cell accuracy: 99.3%, board accuracy: 59.5% \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3813, G loss: 0.7304\n",
      "[84/1762] D loss: 1.3947, G loss: 0.6903\n",
      "[164/1762] D loss: 1.3808, G loss: 0.7089\n",
      "[244/1762] D loss: 1.3746, G loss: 0.6801\n",
      "[324/1762] D loss: 1.3930, G loss: 0.6925\n",
      "[404/1762] D loss: 1.3802, G loss: 0.6913\n",
      "[484/1762] D loss: 1.3880, G loss: 0.7182\n",
      "[564/1762] D loss: 1.3886, G loss: 0.6527\n",
      "[644/1762] D loss: 1.3876, G loss: 0.6867\n",
      "[724/1762] D loss: 1.3872, G loss: 0.6809\n",
      "[804/1762] D loss: 1.3814, G loss: 0.6771\n",
      "[884/1762] D loss: 1.3906, G loss: 0.7334\n",
      "[964/1762] D loss: 1.3543, G loss: 0.6677\n",
      "[1044/1762] D loss: 1.3965, G loss: 0.6579\n",
      "[1124/1762] D loss: 1.3893, G loss: 0.7362\n",
      "[1204/1762] D loss: 1.3908, G loss: 0.6438\n",
      "[1284/1762] D loss: 1.3858, G loss: 0.8210\n",
      "[1364/1762] D loss: 1.3938, G loss: 0.6730\n",
      "[1444/1762] D loss: 1.3602, G loss: 0.7386\n",
      "[1524/1762] D loss: 1.3889, G loss: 0.7354\n",
      "[1604/1762] D loss: 1.3875, G loss: 0.7452\n",
      "[1684/1762] D loss: 1.3631, G loss: 0.7200\n",
      "[1762/1762] D loss: 1.3915, G loss: 0.6617\n",
      "train error: \n",
      " D loss: 1.382582, G loss: 0.637052, D accuracy: 51.2%, cell accuracy: 99.8%, board accuracy: 85.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.382183, G loss: 0.632817, D accuracy: 50.6%, cell accuracy: 99.8%, board accuracy: 81.1% \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4407, G loss: 0.6205\n",
      "[84/1762] D loss: 1.3874, G loss: 0.6966\n",
      "[164/1762] D loss: 1.3387, G loss: 0.6931\n",
      "[244/1762] D loss: 1.3824, G loss: 0.7175\n",
      "[324/1762] D loss: 1.3274, G loss: 0.6974\n",
      "[404/1762] D loss: 1.3699, G loss: 0.6850\n",
      "[484/1762] D loss: 1.3881, G loss: 0.7110\n",
      "[564/1762] D loss: 1.3887, G loss: 0.6946\n",
      "[644/1762] D loss: 1.3853, G loss: 0.6946\n",
      "[724/1762] D loss: 1.3876, G loss: 0.7099\n",
      "[804/1762] D loss: 1.4021, G loss: 0.5927\n",
      "[884/1762] D loss: 1.3479, G loss: 0.7003\n",
      "[964/1762] D loss: 1.3900, G loss: 0.7004\n",
      "[1044/1762] D loss: 1.3921, G loss: 0.7546\n",
      "[1124/1762] D loss: 1.3900, G loss: 0.6677\n",
      "[1204/1762] D loss: 1.3905, G loss: 0.7598\n",
      "[1284/1762] D loss: 1.3885, G loss: 0.6900\n",
      "[1364/1762] D loss: 1.3947, G loss: 0.6479\n",
      "[1444/1762] D loss: 1.3914, G loss: 0.6468\n",
      "[1524/1762] D loss: 1.3894, G loss: 0.7717\n",
      "[1604/1762] D loss: 1.3853, G loss: 0.7280\n",
      "[1684/1762] D loss: 1.4171, G loss: 0.6018\n",
      "[1762/1762] D loss: 1.3921, G loss: 0.7436\n",
      "train error: \n",
      " D loss: 1.363037, G loss: 0.734306, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.356811, G loss: 0.730740, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 83.9% \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3915, G loss: 0.7353\n",
      "[84/1762] D loss: 1.2875, G loss: 0.7178\n",
      "[164/1762] D loss: 1.1746, G loss: 0.7676\n",
      "[244/1762] D loss: 1.2713, G loss: 0.7262\n",
      "[324/1762] D loss: 1.3868, G loss: 0.7048\n",
      "[404/1762] D loss: 1.2721, G loss: 0.7281\n",
      "[484/1762] D loss: 1.3943, G loss: 0.7232\n",
      "[564/1762] D loss: 1.2817, G loss: 0.6687\n",
      "[644/1762] D loss: 1.3242, G loss: 0.7597\n",
      "[724/1762] D loss: 1.2896, G loss: 0.7692\n",
      "[804/1762] D loss: 1.3871, G loss: 0.6980\n",
      "[884/1762] D loss: 1.3893, G loss: 0.6913\n",
      "[964/1762] D loss: 1.3538, G loss: 0.7002\n",
      "[1044/1762] D loss: 1.4551, G loss: 0.6410\n",
      "[1124/1762] D loss: 1.3880, G loss: 0.6175\n",
      "[1204/1762] D loss: 1.4010, G loss: 0.6755\n",
      "[1284/1762] D loss: 1.3790, G loss: 0.7876\n",
      "[1364/1762] D loss: 1.2606, G loss: 0.7561\n",
      "[1444/1762] D loss: 1.2455, G loss: 0.8270\n",
      "[1524/1762] D loss: 1.3905, G loss: 0.8100\n",
      "[1604/1762] D loss: 1.1521, G loss: 0.8182\n",
      "[1684/1762] D loss: 1.2465, G loss: 0.7675\n",
      "[1762/1762] D loss: 1.3913, G loss: 0.7231\n",
      "train error: \n",
      " D loss: 1.365784, G loss: 0.673730, D accuracy: 53.0%, cell accuracy: 99.7%, board accuracy: 80.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.359229, G loss: 0.672599, D accuracy: 54.0%, cell accuracy: 99.7%, board accuracy: 78.6% \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3893, G loss: 0.6353\n",
      "[84/1762] D loss: 1.2465, G loss: 0.6711\n",
      "[164/1762] D loss: 1.3881, G loss: 0.6986\n",
      "[244/1762] D loss: 1.4189, G loss: 0.6278\n",
      "[324/1762] D loss: 1.3934, G loss: 0.5983\n",
      "[404/1762] D loss: 1.4092, G loss: 0.6660\n",
      "[484/1762] D loss: 1.3916, G loss: 0.7151\n",
      "[564/1762] D loss: 1.2714, G loss: 0.6770\n",
      "[644/1762] D loss: 1.3761, G loss: 0.6722\n",
      "[724/1762] D loss: 1.3965, G loss: 0.6874\n",
      "[804/1762] D loss: 1.2489, G loss: 0.6816\n",
      "[884/1762] D loss: 1.3865, G loss: 0.7385\n",
      "[964/1762] D loss: 1.3976, G loss: 0.6034\n",
      "[1044/1762] D loss: 1.2283, G loss: 0.7997\n",
      "[1124/1762] D loss: 1.3932, G loss: 0.6980\n",
      "[1204/1762] D loss: 1.4460, G loss: 0.6068\n",
      "[1284/1762] D loss: 1.4115, G loss: 0.6200\n",
      "[1364/1762] D loss: 1.3797, G loss: 0.8140\n",
      "[1444/1762] D loss: 1.4276, G loss: 0.6828\n",
      "[1524/1762] D loss: 1.3859, G loss: 0.6228\n",
      "[1604/1762] D loss: 1.3966, G loss: 0.6181\n",
      "[1684/1762] D loss: 1.4026, G loss: 0.7437\n",
      "[1762/1762] D loss: 1.0647, G loss: 0.9231\n",
      "train error: \n",
      " D loss: 1.353397, G loss: 0.771656, D accuracy: 53.3%, cell accuracy: 99.7%, board accuracy: 80.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.344261, G loss: 0.774757, D accuracy: 54.3%, cell accuracy: 99.7%, board accuracy: 78.2% \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2299, G loss: 0.7769\n",
      "[84/1762] D loss: 1.3909, G loss: 0.8396\n",
      "[164/1762] D loss: 1.3896, G loss: 0.7101\n",
      "[244/1762] D loss: 1.3533, G loss: 0.6946\n",
      "[324/1762] D loss: 1.3867, G loss: 0.7052\n",
      "[404/1762] D loss: 1.3798, G loss: 0.7593\n",
      "[484/1762] D loss: 1.3803, G loss: 0.6842\n",
      "[564/1762] D loss: 1.3887, G loss: 0.6041\n",
      "[644/1762] D loss: 1.4052, G loss: 0.6796\n",
      "[724/1762] D loss: 1.3942, G loss: 0.7608\n",
      "[804/1762] D loss: 1.4097, G loss: 0.8375\n",
      "[884/1762] D loss: 1.3948, G loss: 0.6291\n",
      "[964/1762] D loss: 1.4012, G loss: 0.6866\n",
      "[1044/1762] D loss: 1.3879, G loss: 0.7049\n",
      "[1124/1762] D loss: 1.1991, G loss: 0.8648\n",
      "[1204/1762] D loss: 1.3621, G loss: 0.7284\n",
      "[1284/1762] D loss: 1.3887, G loss: 0.6973\n",
      "[1364/1762] D loss: 1.3913, G loss: 0.6853\n",
      "[1444/1762] D loss: 1.3898, G loss: 0.6492\n",
      "[1524/1762] D loss: 1.3856, G loss: 0.6594\n",
      "[1604/1762] D loss: 1.3984, G loss: 0.6022\n",
      "[1684/1762] D loss: 1.3903, G loss: 0.6092\n",
      "[1762/1762] D loss: 1.4300, G loss: 0.7934\n",
      "train error: \n",
      " D loss: 1.345797, G loss: 0.684071, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 84.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.332444, G loss: 0.696795, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 80.5% \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3933, G loss: 0.5635\n",
      "[84/1762] D loss: 1.4073, G loss: 0.7852\n",
      "[164/1762] D loss: 1.1892, G loss: 0.7929\n",
      "[244/1762] D loss: 1.3891, G loss: 0.7188\n",
      "[324/1762] D loss: 1.1946, G loss: 0.8463\n",
      "[404/1762] D loss: 1.4058, G loss: 0.7381\n",
      "[484/1762] D loss: 1.3900, G loss: 0.6572\n",
      "[564/1762] D loss: 1.4594, G loss: 0.5769\n",
      "[644/1762] D loss: 1.3896, G loss: 0.6892\n",
      "[724/1762] D loss: 1.4024, G loss: 0.7477\n",
      "[804/1762] D loss: 1.1844, G loss: 0.8229\n",
      "[884/1762] D loss: 1.3943, G loss: 0.6997\n",
      "[964/1762] D loss: 1.3988, G loss: 0.7374\n",
      "[1044/1762] D loss: 1.3976, G loss: 0.7805\n",
      "[1124/1762] D loss: 1.3811, G loss: 0.7395\n",
      "[1204/1762] D loss: 1.4137, G loss: 0.8555\n",
      "[1284/1762] D loss: 1.3940, G loss: 0.7741\n",
      "[1364/1762] D loss: 1.4297, G loss: 0.8215\n",
      "[1444/1762] D loss: 1.3962, G loss: 0.5867\n",
      "[1524/1762] D loss: 1.4288, G loss: 0.5952\n",
      "[1604/1762] D loss: 1.4010, G loss: 0.7696\n",
      "[1684/1762] D loss: 1.2278, G loss: 0.7192\n",
      "[1762/1762] D loss: 1.3974, G loss: 0.6084\n",
      "train error: \n",
      " D loss: 1.336931, G loss: 0.718385, D accuracy: 54.9%, cell accuracy: 99.6%, board accuracy: 70.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.323514, G loss: 0.726763, D accuracy: 55.6%, cell accuracy: 99.5%, board accuracy: 64.3% \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3894, G loss: 0.6856\n",
      "[84/1762] D loss: 1.3883, G loss: 0.7046\n",
      "[164/1762] D loss: 1.3924, G loss: 0.7696\n",
      "[244/1762] D loss: 1.4547, G loss: 0.5482\n",
      "[324/1762] D loss: 1.3774, G loss: 0.6838\n",
      "[404/1762] D loss: 1.7466, G loss: 0.4003\n",
      "[484/1762] D loss: 1.3283, G loss: 1.0934\n",
      "[564/1762] D loss: 1.1191, G loss: 0.9153\n",
      "[644/1762] D loss: 1.2610, G loss: 1.0602\n",
      "[724/1762] D loss: 1.1926, G loss: 0.7630\n",
      "[804/1762] D loss: 1.1774, G loss: 0.8958\n",
      "[884/1762] D loss: 1.1794, G loss: 0.8497\n",
      "[964/1762] D loss: 1.0857, G loss: 1.0016\n",
      "[1044/1762] D loss: 1.1175, G loss: 0.8097\n",
      "[1124/1762] D loss: 1.3204, G loss: 0.7347\n",
      "[1204/1762] D loss: 1.2528, G loss: 0.6076\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6758\n",
      "[1364/1762] D loss: 1.3954, G loss: 0.7281\n",
      "[1444/1762] D loss: 1.4302, G loss: 0.6338\n",
      "[1524/1762] D loss: 1.3064, G loss: 0.6577\n",
      "[1604/1762] D loss: 1.1798, G loss: 0.9320\n",
      "[1684/1762] D loss: 1.3933, G loss: 0.8037\n",
      "[1762/1762] D loss: 1.3988, G loss: 0.8357\n",
      "train error: \n",
      " D loss: 1.366387, G loss: 0.865206, D accuracy: 52.9%, cell accuracy: 99.4%, board accuracy: 47.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.356880, G loss: 0.869637, D accuracy: 54.0%, cell accuracy: 99.3%, board accuracy: 43.4% \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4214, G loss: 0.8333\n",
      "[84/1762] D loss: 1.4247, G loss: 0.6469\n",
      "[164/1762] D loss: 1.2259, G loss: 0.7606\n",
      "[244/1762] D loss: 1.2354, G loss: 0.7484\n",
      "[324/1762] D loss: 1.3919, G loss: 0.6913\n",
      "[404/1762] D loss: 1.2139, G loss: 0.7471\n",
      "[484/1762] D loss: 1.2201, G loss: 0.8673\n",
      "[564/1762] D loss: 1.3899, G loss: 0.6986\n",
      "[644/1762] D loss: 1.2762, G loss: 0.7995\n",
      "[724/1762] D loss: 1.3896, G loss: 0.6583\n",
      "[804/1762] D loss: 1.1339, G loss: 0.8760\n",
      "[884/1762] D loss: 1.2551, G loss: 0.8535\n",
      "[964/1762] D loss: 1.2276, G loss: 0.7275\n",
      "[1044/1762] D loss: 1.3906, G loss: 0.7448\n",
      "[1124/1762] D loss: 1.1994, G loss: 0.7988\n",
      "[1204/1762] D loss: 1.1904, G loss: 0.8637\n",
      "[1284/1762] D loss: 1.3933, G loss: 0.6646\n",
      "[1364/1762] D loss: 1.4001, G loss: 0.6331\n",
      "[1444/1762] D loss: 1.2285, G loss: 0.7366\n",
      "[1524/1762] D loss: 1.1859, G loss: 0.8414\n",
      "[1604/1762] D loss: 1.3932, G loss: 0.7105\n",
      "[1684/1762] D loss: 1.3884, G loss: 0.6924\n",
      "[1762/1762] D loss: 1.4103, G loss: 0.7817\n",
      "train error: \n",
      " D loss: 1.348352, G loss: 0.812273, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 83.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.336956, G loss: 0.819788, D accuracy: 54.2%, cell accuracy: 99.7%, board accuracy: 78.9% \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4247, G loss: 0.7595\n",
      "[84/1762] D loss: 1.2539, G loss: 0.8996\n",
      "[164/1762] D loss: 1.2140, G loss: 0.7275\n",
      "[244/1762] D loss: 1.3883, G loss: 0.7143\n",
      "[324/1762] D loss: 1.3905, G loss: 0.6404\n",
      "[404/1762] D loss: 1.3377, G loss: 0.7611\n",
      "[484/1762] D loss: 1.3971, G loss: 0.7603\n",
      "[564/1762] D loss: 1.3904, G loss: 0.7013\n",
      "[644/1762] D loss: 1.4737, G loss: 0.6064\n",
      "[724/1762] D loss: 1.3956, G loss: 0.6909\n",
      "[804/1762] D loss: 1.2151, G loss: 0.7681\n",
      "[884/1762] D loss: 1.2277, G loss: 0.7612\n",
      "[964/1762] D loss: 1.2146, G loss: 0.9709\n",
      "[1044/1762] D loss: 1.4038, G loss: 0.5376\n",
      "[1124/1762] D loss: 1.4024, G loss: 0.8251\n",
      "[1204/1762] D loss: 1.3980, G loss: 0.6544\n",
      "[1284/1762] D loss: 1.4120, G loss: 0.8005\n",
      "[1364/1762] D loss: 1.3917, G loss: 0.6795\n",
      "[1444/1762] D loss: 1.3673, G loss: 0.7321\n",
      "[1524/1762] D loss: 1.3977, G loss: 0.6430\n",
      "[1604/1762] D loss: 1.3920, G loss: 0.6778\n",
      "[1684/1762] D loss: 1.4006, G loss: 0.6452\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6776\n",
      "train error: \n",
      " D loss: 1.335804, G loss: 0.783327, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 85.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.322388, G loss: 0.790859, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 81.6% \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3935, G loss: 0.7218\n",
      "[84/1762] D loss: 1.3937, G loss: 0.7465\n",
      "[164/1762] D loss: 1.3900, G loss: 0.7648\n",
      "[244/1762] D loss: 1.3725, G loss: 0.6518\n",
      "[324/1762] D loss: 1.3932, G loss: 0.7647\n",
      "[404/1762] D loss: 1.3981, G loss: 0.6704\n",
      "[484/1762] D loss: 1.4048, G loss: 0.8004\n",
      "[564/1762] D loss: 1.3917, G loss: 0.6791\n",
      "[644/1762] D loss: 1.4114, G loss: 0.8215\n",
      "[724/1762] D loss: 1.4007, G loss: 0.8258\n",
      "[804/1762] D loss: 0.9668, G loss: 0.8990\n",
      "[884/1762] D loss: 1.3972, G loss: 0.7545\n",
      "[964/1762] D loss: 1.3687, G loss: 0.8191\n",
      "[1044/1762] D loss: 1.4013, G loss: 0.6048\n",
      "[1124/1762] D loss: 1.3931, G loss: 0.6636\n",
      "[1204/1762] D loss: 1.3875, G loss: 0.7133\n",
      "[1284/1762] D loss: 1.1923, G loss: 0.7427\n",
      "[1364/1762] D loss: 1.3919, G loss: 0.6684\n",
      "[1444/1762] D loss: 1.3918, G loss: 0.7551\n",
      "[1524/1762] D loss: 1.2054, G loss: 0.8079\n",
      "[1604/1762] D loss: 1.1454, G loss: 0.8189\n",
      "[1684/1762] D loss: 1.1522, G loss: 0.9319\n",
      "[1762/1762] D loss: 1.3903, G loss: 0.6401\n",
      "train error: \n",
      " D loss: 1.330865, G loss: 0.680219, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 84.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.315149, G loss: 0.690399, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 78.4% \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3916, G loss: 0.6569\n",
      "[84/1762] D loss: 1.4071, G loss: 0.6986\n",
      "[164/1762] D loss: 1.3675, G loss: 0.7284\n",
      "[244/1762] D loss: 1.1805, G loss: 0.7533\n",
      "[324/1762] D loss: 1.3830, G loss: 0.8335\n",
      "[404/1762] D loss: 1.1725, G loss: 0.8536\n",
      "[484/1762] D loss: 1.1924, G loss: 1.0153\n",
      "[564/1762] D loss: 1.1590, G loss: 0.8753\n",
      "[644/1762] D loss: 1.3923, G loss: 0.7244\n",
      "[724/1762] D loss: 1.4063, G loss: 0.7559\n",
      "[804/1762] D loss: 1.1344, G loss: 0.9111\n",
      "[884/1762] D loss: 1.1831, G loss: 0.6945\n",
      "[964/1762] D loss: 1.4055, G loss: 0.7823\n",
      "[1044/1762] D loss: 1.3952, G loss: 0.7980\n",
      "[1124/1762] D loss: 1.3808, G loss: 0.6206\n",
      "[1204/1762] D loss: 1.3871, G loss: 0.6745\n",
      "[1284/1762] D loss: 1.3915, G loss: 0.7289\n",
      "[1364/1762] D loss: 1.3882, G loss: 0.6564\n",
      "[1444/1762] D loss: 1.4179, G loss: 0.8540\n",
      "[1524/1762] D loss: 1.4075, G loss: 0.8493\n",
      "[1604/1762] D loss: 1.3879, G loss: 0.6644\n",
      "[1684/1762] D loss: 1.4470, G loss: 0.8728\n",
      "[1762/1762] D loss: 1.4097, G loss: 0.9450\n",
      "train error: \n",
      " D loss: 1.322753, G loss: 0.797582, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.301595, G loss: 0.816469, D accuracy: 55.6%, cell accuracy: 99.8%, board accuracy: 83.0% \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9065, G loss: 1.0334\n",
      "[84/1762] D loss: 1.3935, G loss: 0.7702\n",
      "[164/1762] D loss: 1.4097, G loss: 0.7251\n",
      "[244/1762] D loss: 1.1898, G loss: 0.8237\n",
      "[324/1762] D loss: 1.3890, G loss: 0.7016\n",
      "[404/1762] D loss: 1.3900, G loss: 0.6483\n",
      "[484/1762] D loss: 1.3940, G loss: 0.6815\n",
      "[564/1762] D loss: 1.3939, G loss: 0.6777\n",
      "[644/1762] D loss: 1.3700, G loss: 0.7761\n",
      "[724/1762] D loss: 1.4006, G loss: 0.7485\n",
      "[804/1762] D loss: 1.1224, G loss: 0.9276\n",
      "[884/1762] D loss: 1.3915, G loss: 0.7172\n",
      "[964/1762] D loss: 1.3986, G loss: 0.6199\n",
      "[1044/1762] D loss: 1.1651, G loss: 0.7256\n",
      "[1124/1762] D loss: 1.3306, G loss: 0.7296\n",
      "[1204/1762] D loss: 1.3969, G loss: 0.6143\n",
      "[1284/1762] D loss: 1.3919, G loss: 0.6318\n",
      "[1364/1762] D loss: 1.3918, G loss: 0.6474\n",
      "[1444/1762] D loss: 1.3945, G loss: 0.6857\n",
      "[1524/1762] D loss: 1.4212, G loss: 0.8148\n",
      "[1604/1762] D loss: 1.1444, G loss: 0.8239\n",
      "[1684/1762] D loss: 1.1268, G loss: 0.9043\n",
      "[1762/1762] D loss: 1.3576, G loss: 0.8966\n",
      "train error: \n",
      " D loss: 1.346524, G loss: 0.962208, D accuracy: 54.6%, cell accuracy: 99.7%, board accuracy: 79.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.324834, G loss: 0.980750, D accuracy: 55.7%, cell accuracy: 99.7%, board accuracy: 75.0% \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3893, G loss: 0.9542\n",
      "[84/1762] D loss: 1.3922, G loss: 0.7461\n",
      "[164/1762] D loss: 1.4242, G loss: 0.8570\n",
      "[244/1762] D loss: 0.9213, G loss: 1.0658\n",
      "[324/1762] D loss: 1.3194, G loss: 0.7155\n",
      "[404/1762] D loss: 1.3870, G loss: 0.7137\n",
      "[484/1762] D loss: 1.1666, G loss: 0.8369\n",
      "[564/1762] D loss: 1.3820, G loss: 0.5681\n",
      "[644/1762] D loss: 1.2260, G loss: 0.5967\n",
      "[724/1762] D loss: 1.1068, G loss: 0.9720\n",
      "[804/1762] D loss: 1.4163, G loss: 0.6699\n",
      "[884/1762] D loss: 1.4005, G loss: 0.8225\n",
      "[964/1762] D loss: 1.3886, G loss: 0.6950\n",
      "[1044/1762] D loss: 1.1539, G loss: 0.9869\n",
      "[1124/1762] D loss: 1.4047, G loss: 0.8429\n",
      "[1204/1762] D loss: 1.4003, G loss: 0.7541\n",
      "[1284/1762] D loss: 1.3901, G loss: 0.6436\n",
      "[1364/1762] D loss: 1.3920, G loss: 0.6356\n",
      "[1444/1762] D loss: 1.1410, G loss: 0.9187\n",
      "[1524/1762] D loss: 1.3660, G loss: 0.8009\n",
      "[1604/1762] D loss: 1.2199, G loss: 0.9157\n",
      "[1684/1762] D loss: 1.3991, G loss: 0.8030\n",
      "[1762/1762] D loss: 1.3330, G loss: 0.6709\n",
      "train error: \n",
      " D loss: 1.320694, G loss: 0.746364, D accuracy: 54.8%, cell accuracy: 99.5%, board accuracy: 74.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.305603, G loss: 0.757628, D accuracy: 55.9%, cell accuracy: 99.4%, board accuracy: 72.5% \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3875, G loss: 0.7490\n",
      "[84/1762] D loss: 1.4082, G loss: 0.7513\n",
      "[164/1762] D loss: 1.1753, G loss: 0.8694\n",
      "[244/1762] D loss: 1.4021, G loss: 0.6418\n",
      "[324/1762] D loss: 1.1265, G loss: 0.8364\n",
      "[404/1762] D loss: 1.3562, G loss: 0.7012\n",
      "[484/1762] D loss: 1.4161, G loss: 0.8541\n",
      "[564/1762] D loss: 1.3878, G loss: 0.7258\n",
      "[644/1762] D loss: 1.3806, G loss: 0.7024\n",
      "[724/1762] D loss: 1.3680, G loss: 0.7204\n",
      "[804/1762] D loss: 1.0209, G loss: 0.9875\n",
      "[884/1762] D loss: 1.3325, G loss: 0.8280\n",
      "[964/1762] D loss: 1.3268, G loss: 0.9694\n",
      "[1044/1762] D loss: 1.4610, G loss: 1.0246\n",
      "[1124/1762] D loss: 1.3342, G loss: 0.8268\n",
      "[1204/1762] D loss: 1.3247, G loss: 0.9065\n",
      "[1284/1762] D loss: 1.1518, G loss: 0.8388\n",
      "[1364/1762] D loss: 1.0451, G loss: 0.9090\n",
      "[1444/1762] D loss: 1.4104, G loss: 0.7174\n",
      "[1524/1762] D loss: 1.1572, G loss: 0.8054\n",
      "[1604/1762] D loss: 1.3302, G loss: 0.7458\n",
      "[1684/1762] D loss: 1.3996, G loss: 0.7146\n",
      "[1762/1762] D loss: 1.3891, G loss: 0.6591\n",
      "train error: \n",
      " D loss: 1.334849, G loss: 0.766550, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 79.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.312244, G loss: 0.778970, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 76.4% \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3979, G loss: 0.7112\n",
      "[84/1762] D loss: 1.3911, G loss: 0.6474\n",
      "[164/1762] D loss: 1.4203, G loss: 0.5593\n",
      "[244/1762] D loss: 1.1834, G loss: 0.7594\n",
      "[324/1762] D loss: 1.3912, G loss: 0.6465\n",
      "[404/1762] D loss: 1.1561, G loss: 0.7889\n",
      "[484/1762] D loss: 0.9452, G loss: 0.9857\n",
      "[564/1762] D loss: 1.3960, G loss: 0.6841\n",
      "[644/1762] D loss: 1.3953, G loss: 0.5508\n",
      "[724/1762] D loss: 1.3963, G loss: 0.7306\n",
      "[804/1762] D loss: 1.4000, G loss: 0.7034\n",
      "[884/1762] D loss: 1.1679, G loss: 0.7308\n",
      "[964/1762] D loss: 0.9232, G loss: 0.9782\n",
      "[1044/1762] D loss: 1.3965, G loss: 0.6847\n",
      "[1124/1762] D loss: 1.3881, G loss: 0.7153\n",
      "[1204/1762] D loss: 1.1556, G loss: 0.7561\n",
      "[1284/1762] D loss: 1.4099, G loss: 0.6169\n",
      "[1364/1762] D loss: 1.4025, G loss: 0.8698\n",
      "[1444/1762] D loss: 1.3987, G loss: 0.8032\n",
      "[1524/1762] D loss: 1.1651, G loss: 0.7318\n",
      "[1604/1762] D loss: 1.4085, G loss: 0.5486\n",
      "[1684/1762] D loss: 1.3966, G loss: 0.7612\n",
      "[1762/1762] D loss: 0.9784, G loss: 0.8227\n",
      "train error: \n",
      " D loss: 1.346195, G loss: 0.608315, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 89.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.327689, G loss: 0.619430, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4387, G loss: 0.5915\n",
      "[84/1762] D loss: 0.8862, G loss: 1.0526\n",
      "[164/1762] D loss: 0.8627, G loss: 1.0574\n",
      "[244/1762] D loss: 1.3906, G loss: 0.7190\n",
      "[324/1762] D loss: 1.0925, G loss: 1.0350\n",
      "[404/1762] D loss: 1.1527, G loss: 0.7278\n",
      "[484/1762] D loss: 1.3870, G loss: 0.6865\n",
      "[564/1762] D loss: 1.3945, G loss: 0.6275\n",
      "[644/1762] D loss: 1.4031, G loss: 0.6338\n",
      "[724/1762] D loss: 1.4350, G loss: 0.9181\n",
      "[804/1762] D loss: 1.3915, G loss: 0.7486\n",
      "[884/1762] D loss: 1.3941, G loss: 0.7702\n",
      "[964/1762] D loss: 1.3948, G loss: 0.7931\n",
      "[1044/1762] D loss: 1.3987, G loss: 0.7694\n",
      "[1124/1762] D loss: 1.1807, G loss: 0.7165\n",
      "[1204/1762] D loss: 1.3989, G loss: 0.6709\n",
      "[1284/1762] D loss: 1.1270, G loss: 1.0560\n",
      "[1364/1762] D loss: 1.1381, G loss: 1.0012\n",
      "[1444/1762] D loss: 1.1581, G loss: 0.7480\n",
      "[1524/1762] D loss: 1.3911, G loss: 0.7282\n",
      "[1604/1762] D loss: 1.3933, G loss: 0.6569\n",
      "[1684/1762] D loss: 1.3931, G loss: 0.7684\n",
      "[1762/1762] D loss: 1.3502, G loss: 0.7564\n",
      "train error: \n",
      " D loss: 1.328484, G loss: 0.658993, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 81.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.309846, G loss: 0.670822, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 78.4% \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4034, G loss: 0.5786\n",
      "[84/1762] D loss: 1.3964, G loss: 0.7977\n",
      "[164/1762] D loss: 1.4019, G loss: 0.6341\n",
      "[244/1762] D loss: 1.4112, G loss: 0.8223\n",
      "[324/1762] D loss: 1.3983, G loss: 0.6505\n",
      "[404/1762] D loss: 1.3928, G loss: 0.7242\n",
      "[484/1762] D loss: 1.1573, G loss: 0.7871\n",
      "[564/1762] D loss: 1.3913, G loss: 0.7304\n",
      "[644/1762] D loss: 1.4084, G loss: 0.8231\n",
      "[724/1762] D loss: 1.4000, G loss: 0.6631\n",
      "[804/1762] D loss: 1.4152, G loss: 0.8763\n",
      "[884/1762] D loss: 1.4057, G loss: 0.7405\n",
      "[964/1762] D loss: 1.3907, G loss: 0.7332\n",
      "[1044/1762] D loss: 1.3285, G loss: 0.9662\n",
      "[1124/1762] D loss: 1.1449, G loss: 0.9651\n",
      "[1204/1762] D loss: 1.4131, G loss: 0.6923\n",
      "[1284/1762] D loss: 1.3945, G loss: 0.7276\n",
      "[1364/1762] D loss: 1.4004, G loss: 0.8441\n",
      "[1444/1762] D loss: 1.3898, G loss: 0.6717\n",
      "[1524/1762] D loss: 1.3880, G loss: 0.7588\n",
      "[1604/1762] D loss: 1.1326, G loss: 1.0267\n",
      "[1684/1762] D loss: 1.3936, G loss: 0.7062\n",
      "[1762/1762] D loss: 0.8620, G loss: 0.9979\n",
      "train error: \n",
      " D loss: 1.317555, G loss: 0.779368, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.298736, G loss: 0.794077, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 82.5% \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3915, G loss: 0.6627\n",
      "[84/1762] D loss: 1.3898, G loss: 0.6507\n",
      "[164/1762] D loss: 1.4248, G loss: 0.8180\n",
      "[244/1762] D loss: 1.3886, G loss: 0.7450\n",
      "[324/1762] D loss: 1.4135, G loss: 0.8358\n",
      "[404/1762] D loss: 0.8869, G loss: 0.9613\n",
      "[484/1762] D loss: 1.3868, G loss: 0.7160\n",
      "[564/1762] D loss: 1.3909, G loss: 0.6944\n",
      "[644/1762] D loss: 1.3989, G loss: 0.6324\n",
      "[724/1762] D loss: 1.3630, G loss: 0.6032\n",
      "[804/1762] D loss: 1.1200, G loss: 0.9658\n",
      "[884/1762] D loss: 1.1289, G loss: 0.8733\n",
      "[964/1762] D loss: 1.1156, G loss: 0.8745\n",
      "[1044/1762] D loss: 1.1403, G loss: 0.8319\n",
      "[1124/1762] D loss: 1.3892, G loss: 0.7374\n",
      "[1204/1762] D loss: 1.3905, G loss: 0.7077\n",
      "[1284/1762] D loss: 1.4401, G loss: 0.9451\n",
      "[1364/1762] D loss: 1.3982, G loss: 0.9533\n",
      "[1444/1762] D loss: 0.8793, G loss: 0.9498\n",
      "[1524/1762] D loss: 1.4060, G loss: 0.6485\n",
      "[1604/1762] D loss: 1.4109, G loss: 0.8030\n",
      "[1684/1762] D loss: 1.0920, G loss: 1.0245\n",
      "[1762/1762] D loss: 1.3914, G loss: 0.6369\n",
      "train error: \n",
      " D loss: 1.320901, G loss: 0.722975, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 85.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.300216, G loss: 0.740133, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 83.9% \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1481, G loss: 0.7795\n",
      "[84/1762] D loss: 1.1289, G loss: 0.8722\n",
      "[164/1762] D loss: 1.3976, G loss: 0.8001\n",
      "[244/1762] D loss: 1.3928, G loss: 0.7295\n",
      "[324/1762] D loss: 1.3935, G loss: 0.6351\n",
      "[404/1762] D loss: 1.1365, G loss: 0.9258\n",
      "[484/1762] D loss: 1.3892, G loss: 0.6683\n",
      "[564/1762] D loss: 1.4153, G loss: 0.8238\n",
      "[644/1762] D loss: 1.3829, G loss: 0.6394\n",
      "[724/1762] D loss: 1.3887, G loss: 0.5903\n",
      "[804/1762] D loss: 1.3920, G loss: 0.7256\n",
      "[884/1762] D loss: 1.4027, G loss: 0.7605\n",
      "[964/1762] D loss: 1.3900, G loss: 0.6441\n",
      "[1044/1762] D loss: 1.3580, G loss: 0.7491\n",
      "[1124/1762] D loss: 1.1177, G loss: 0.9091\n",
      "[1204/1762] D loss: 1.3884, G loss: 0.6331\n",
      "[1284/1762] D loss: 1.3931, G loss: 0.6781\n",
      "[1364/1762] D loss: 1.3767, G loss: 0.7783\n",
      "[1444/1762] D loss: 0.8948, G loss: 1.0356\n",
      "[1524/1762] D loss: 1.3882, G loss: 0.6944\n",
      "[1604/1762] D loss: 1.3880, G loss: 0.7115\n",
      "[1684/1762] D loss: 1.4250, G loss: 0.6251\n",
      "[1762/1762] D loss: 0.8751, G loss: 0.9573\n",
      "train error: \n",
      " D loss: 1.322268, G loss: 0.844306, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 86.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.302540, G loss: 0.864240, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 83.9% \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3887, G loss: 0.7452\n",
      "[84/1762] D loss: 1.3969, G loss: 0.7488\n",
      "[164/1762] D loss: 1.1166, G loss: 0.8572\n",
      "[244/1762] D loss: 1.3924, G loss: 0.6232\n",
      "[324/1762] D loss: 1.3904, G loss: 0.7000\n",
      "[404/1762] D loss: 1.3961, G loss: 0.7321\n",
      "[484/1762] D loss: 1.3955, G loss: 0.7132\n",
      "[564/1762] D loss: 1.3901, G loss: 0.7103\n",
      "[644/1762] D loss: 1.3988, G loss: 0.7854\n",
      "[724/1762] D loss: 1.1502, G loss: 0.8040\n",
      "[804/1762] D loss: 1.3925, G loss: 0.6866\n",
      "[884/1762] D loss: 1.3914, G loss: 0.6586\n",
      "[964/1762] D loss: 1.4090, G loss: 0.8450\n",
      "[1044/1762] D loss: 1.4061, G loss: 0.7475\n",
      "[1124/1762] D loss: 1.4033, G loss: 0.7126\n",
      "[1204/1762] D loss: 1.3963, G loss: 0.7930\n",
      "[1284/1762] D loss: 1.3838, G loss: 0.7319\n",
      "[1364/1762] D loss: 1.3853, G loss: 0.6617\n",
      "[1444/1762] D loss: 1.4251, G loss: 0.6792\n",
      "[1524/1762] D loss: 1.4617, G loss: 0.7907\n",
      "[1604/1762] D loss: 1.3991, G loss: 0.7058\n",
      "[1684/1762] D loss: 1.4058, G loss: 0.8591\n",
      "[1762/1762] D loss: 0.7873, G loss: 1.3513\n",
      "train error: \n",
      " D loss: 1.303966, G loss: 0.744331, D accuracy: 58.6%, cell accuracy: 99.5%, board accuracy: 60.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.279851, G loss: 0.767915, D accuracy: 59.9%, cell accuracy: 99.4%, board accuracy: 55.9% \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3542, G loss: 0.7041\n",
      "[84/1762] D loss: 1.1016, G loss: 1.1755\n",
      "[164/1762] D loss: 1.3736, G loss: 0.7167\n",
      "[244/1762] D loss: 1.0924, G loss: 0.9971\n",
      "[324/1762] D loss: 1.3982, G loss: 0.6205\n",
      "[404/1762] D loss: 1.2920, G loss: 0.7202\n",
      "[484/1762] D loss: 1.0695, G loss: 0.8940\n",
      "[564/1762] D loss: 1.4102, G loss: 0.7966\n",
      "[644/1762] D loss: 1.4263, G loss: 0.8396\n",
      "[724/1762] D loss: 1.1520, G loss: 0.9473\n",
      "[804/1762] D loss: 1.0608, G loss: 1.1539\n",
      "[884/1762] D loss: 1.3425, G loss: 0.7126\n",
      "[964/1762] D loss: 1.3800, G loss: 0.6971\n",
      "[1044/1762] D loss: 1.2846, G loss: 0.7179\n",
      "[1124/1762] D loss: 1.3936, G loss: 0.8523\n",
      "[1204/1762] D loss: 1.2903, G loss: 0.7802\n",
      "[1284/1762] D loss: 1.3991, G loss: 0.7805\n",
      "[1364/1762] D loss: 1.3886, G loss: 0.6741\n",
      "[1444/1762] D loss: 1.0717, G loss: 0.8381\n",
      "[1524/1762] D loss: 0.8765, G loss: 1.1352\n",
      "[1604/1762] D loss: 1.3926, G loss: 0.7690\n",
      "[1684/1762] D loss: 1.3923, G loss: 0.7684\n",
      "[1762/1762] D loss: 1.4024, G loss: 0.7201\n",
      "train error: \n",
      " D loss: 1.329434, G loss: 0.732426, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 86.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.309752, G loss: 0.739609, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 83.0% \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0731, G loss: 0.8144\n",
      "[84/1762] D loss: 1.3917, G loss: 0.6966\n",
      "[164/1762] D loss: 1.3913, G loss: 0.7421\n",
      "[244/1762] D loss: 1.5013, G loss: 0.7275\n",
      "[324/1762] D loss: 1.4894, G loss: 0.9036\n",
      "[404/1762] D loss: 1.6995, G loss: 0.5971\n",
      "[484/1762] D loss: 1.4939, G loss: 0.9180\n",
      "[564/1762] D loss: 1.0461, G loss: 0.7402\n",
      "[644/1762] D loss: 1.0295, G loss: 1.0879\n",
      "[724/1762] D loss: 1.1858, G loss: 1.1701\n",
      "[804/1762] D loss: 1.4518, G loss: 0.4621\n",
      "[884/1762] D loss: 1.5391, G loss: 0.9539\n",
      "[964/1762] D loss: 1.4709, G loss: 1.1048\n",
      "[1044/1762] D loss: 1.3862, G loss: 0.8066\n",
      "[1124/1762] D loss: 1.4266, G loss: 0.8857\n",
      "[1204/1762] D loss: 1.2854, G loss: 0.6279\n",
      "[1284/1762] D loss: 1.3989, G loss: 0.7189\n",
      "[1364/1762] D loss: 1.2669, G loss: 0.6357\n",
      "[1444/1762] D loss: 1.2023, G loss: 0.7824\n",
      "[1524/1762] D loss: 1.3645, G loss: 0.8036\n",
      "[1604/1762] D loss: 1.4056, G loss: 0.5644\n",
      "[1684/1762] D loss: 1.0347, G loss: 0.8461\n",
      "[1762/1762] D loss: 1.4093, G loss: 0.7880\n",
      "train error: \n",
      " D loss: 1.344843, G loss: 0.780755, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 89.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.334348, G loss: 0.784759, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    train(run_name=\"freeze_glob_5_epochs\", frozen_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3958, G loss: 0.6033\n",
      "[84/1762] D loss: 1.3921, G loss: 0.6086\n",
      "[164/1762] D loss: 1.3892, G loss: 0.6101\n",
      "[244/1762] D loss: 1.3819, G loss: 0.6125\n",
      "[324/1762] D loss: 1.3770, G loss: 0.6141\n",
      "[404/1762] D loss: 1.3689, G loss: 0.6124\n",
      "[484/1762] D loss: 1.3551, G loss: 0.6092\n",
      "[564/1762] D loss: 1.3354, G loss: 0.6034\n",
      "[644/1762] D loss: 1.3159, G loss: 0.5860\n",
      "[724/1762] D loss: 1.2895, G loss: 0.5767\n",
      "[804/1762] D loss: 1.2385, G loss: 0.5989\n",
      "[884/1762] D loss: 1.1697, G loss: 0.6230\n",
      "[964/1762] D loss: 1.1121, G loss: 0.6718\n",
      "[1044/1762] D loss: 1.0863, G loss: 0.7209\n",
      "[1124/1762] D loss: 0.9387, G loss: 0.7873\n",
      "[1204/1762] D loss: 0.9458, G loss: 0.8156\n",
      "[1284/1762] D loss: 0.8931, G loss: 1.0035\n",
      "[1364/1762] D loss: 0.8034, G loss: 1.0141\n",
      "[1444/1762] D loss: 0.7111, G loss: 1.3062\n",
      "[1524/1762] D loss: 0.6920, G loss: 1.2501\n",
      "[1604/1762] D loss: 0.7413, G loss: 1.6753\n",
      "[1684/1762] D loss: 0.7193, G loss: 1.5099\n",
      "[1762/1762] D loss: 0.5712, G loss: 1.6925\n",
      "train error: \n",
      " D loss: 0.620041, G loss: 1.550250, D accuracy: 96.4%, cell accuracy: 94.3%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.625167, G loss: 1.518959, D accuracy: 96.2%, cell accuracy: 94.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.6424, G loss: 1.3739\n",
      "[84/1762] D loss: 0.6489, G loss: 1.5229\n",
      "[164/1762] D loss: 0.6593, G loss: 1.6815\n",
      "[244/1762] D loss: 0.6689, G loss: 1.7557\n",
      "[324/1762] D loss: 0.5259, G loss: 1.9612\n",
      "[404/1762] D loss: 0.4697, G loss: 1.8088\n",
      "[484/1762] D loss: 0.6665, G loss: 1.7015\n",
      "[564/1762] D loss: 0.5207, G loss: 1.8107\n",
      "[644/1762] D loss: 0.6587, G loss: 1.8076\n",
      "[724/1762] D loss: 0.5404, G loss: 2.0460\n",
      "[804/1762] D loss: 0.5103, G loss: 1.7414\n",
      "[884/1762] D loss: 0.6630, G loss: 1.7674\n",
      "[964/1762] D loss: 0.5802, G loss: 1.5836\n",
      "[1044/1762] D loss: 0.5328, G loss: 1.6751\n",
      "[1124/1762] D loss: 0.6578, G loss: 1.4510\n",
      "[1204/1762] D loss: 0.6948, G loss: 2.2524\n",
      "[1284/1762] D loss: 0.6174, G loss: 1.8384\n",
      "[1364/1762] D loss: 0.5361, G loss: 1.6891\n",
      "[1444/1762] D loss: 0.6858, G loss: 1.6707\n",
      "[1524/1762] D loss: 0.7029, G loss: 1.3422\n",
      "[1604/1762] D loss: 0.5707, G loss: 1.4702\n",
      "[1684/1762] D loss: 0.6749, G loss: 1.5971\n",
      "[1762/1762] D loss: 0.6526, G loss: 2.0132\n",
      "train error: \n",
      " D loss: 0.611427, G loss: 1.527363, D accuracy: 94.2%, cell accuracy: 95.4%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.613481, G loss: 1.548752, D accuracy: 93.6%, cell accuracy: 95.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7101, G loss: 1.7755\n",
      "[84/1762] D loss: 0.7759, G loss: 2.1102\n",
      "[164/1762] D loss: 0.7088, G loss: 1.9491\n",
      "[244/1762] D loss: 0.6525, G loss: 2.2309\n",
      "[324/1762] D loss: 0.6899, G loss: 1.4244\n",
      "[404/1762] D loss: 0.7028, G loss: 1.3426\n",
      "[484/1762] D loss: 0.5811, G loss: 2.0835\n",
      "[564/1762] D loss: 0.6355, G loss: 1.7006\n",
      "[644/1762] D loss: 0.5631, G loss: 1.6844\n",
      "[724/1762] D loss: 0.4729, G loss: 2.2954\n",
      "[804/1762] D loss: 0.5930, G loss: 1.5136\n",
      "[884/1762] D loss: 0.7668, G loss: 1.2499\n",
      "[964/1762] D loss: 0.7165, G loss: 1.7933\n",
      "[1044/1762] D loss: 0.7497, G loss: 1.1675\n",
      "[1124/1762] D loss: 0.7002, G loss: 1.2278\n",
      "[1204/1762] D loss: 0.7548, G loss: 1.6154\n",
      "[1284/1762] D loss: 0.4970, G loss: 1.0978\n",
      "[1364/1762] D loss: 0.6447, G loss: 1.6260\n",
      "[1444/1762] D loss: 0.7203, G loss: 1.2008\n",
      "[1524/1762] D loss: 0.6498, G loss: 1.7462\n",
      "[1604/1762] D loss: 0.9640, G loss: 1.6057\n",
      "[1684/1762] D loss: 0.6168, G loss: 1.8883\n",
      "[1762/1762] D loss: 0.7390, G loss: 1.2170\n",
      "train error: \n",
      " D loss: 0.831684, G loss: 1.026023, D accuracy: 79.6%, cell accuracy: 96.3%, board accuracy: 2.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.815449, G loss: 1.032138, D accuracy: 81.2%, cell accuracy: 96.3%, board accuracy: 2.0% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7832, G loss: 1.0816\n",
      "[84/1762] D loss: 0.8229, G loss: 1.4634\n",
      "[164/1762] D loss: 0.4811, G loss: 2.2777\n",
      "[244/1762] D loss: 0.6653, G loss: 1.4616\n",
      "[324/1762] D loss: 0.8414, G loss: 1.2636\n",
      "[404/1762] D loss: 0.5848, G loss: 1.9379\n",
      "[484/1762] D loss: 0.7276, G loss: 1.5541\n",
      "[564/1762] D loss: 0.9047, G loss: 1.4382\n",
      "[644/1762] D loss: 0.8433, G loss: 1.0884\n",
      "[724/1762] D loss: 0.7704, G loss: 1.7950\n",
      "[804/1762] D loss: 0.6407, G loss: 1.7759\n",
      "[884/1762] D loss: 0.7714, G loss: 1.7743\n",
      "[964/1762] D loss: 0.7893, G loss: 1.3792\n",
      "[1044/1762] D loss: 0.8799, G loss: 1.3697\n",
      "[1124/1762] D loss: 0.9587, G loss: 0.9810\n",
      "[1204/1762] D loss: 0.6140, G loss: 1.7232\n",
      "[1284/1762] D loss: 0.9657, G loss: 1.2198\n",
      "[1364/1762] D loss: 0.9013, G loss: 1.7203\n",
      "[1444/1762] D loss: 0.8812, G loss: 1.5240\n",
      "[1524/1762] D loss: 0.9234, G loss: 1.0782\n",
      "[1604/1762] D loss: 1.0522, G loss: 0.9417\n",
      "[1684/1762] D loss: 0.8414, G loss: 0.8057\n",
      "[1762/1762] D loss: 1.1125, G loss: 1.0674\n",
      "train error: \n",
      " D loss: 1.083925, G loss: 1.676297, D accuracy: 67.3%, cell accuracy: 97.9%, board accuracy: 0.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.096814, G loss: 1.734292, D accuracy: 65.8%, cell accuracy: 97.8%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8754, G loss: 1.4181\n",
      "[84/1762] D loss: 1.0483, G loss: 1.1910\n",
      "[164/1762] D loss: 0.9842, G loss: 1.1499\n",
      "[244/1762] D loss: 0.8945, G loss: 1.1886\n",
      "[324/1762] D loss: 0.9357, G loss: 1.5417\n",
      "[404/1762] D loss: 1.1917, G loss: 0.8376\n",
      "[484/1762] D loss: 1.4587, G loss: 1.7408\n",
      "[564/1762] D loss: 1.0668, G loss: 1.1263\n",
      "[644/1762] D loss: 0.9504, G loss: 0.9618\n",
      "[724/1762] D loss: 1.0173, G loss: 1.1752\n",
      "[804/1762] D loss: 0.6395, G loss: 2.7753\n",
      "[884/1762] D loss: 1.1556, G loss: 1.1330\n",
      "[964/1762] D loss: 1.0594, G loss: 0.9486\n",
      "[1044/1762] D loss: 1.3236, G loss: 0.7880\n",
      "[1124/1762] D loss: 1.0659, G loss: 1.1905\n",
      "[1204/1762] D loss: 1.2572, G loss: 0.6793\n",
      "[1284/1762] D loss: 1.2174, G loss: 0.8249\n",
      "[1364/1762] D loss: 1.0151, G loss: 0.8232\n",
      "[1444/1762] D loss: 1.0827, G loss: 0.9399\n",
      "[1524/1762] D loss: 1.1824, G loss: 0.7501\n",
      "[1604/1762] D loss: 1.0639, G loss: 0.5971\n",
      "[1684/1762] D loss: 1.1109, G loss: 0.9087\n",
      "[1762/1762] D loss: 1.6025, G loss: 1.7074\n",
      "train error: \n",
      " D loss: 1.031436, G loss: 1.264927, D accuracy: 77.9%, cell accuracy: 98.3%, board accuracy: 0.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.033078, G loss: 1.305155, D accuracy: 77.8%, cell accuracy: 98.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9897, G loss: 1.1055\n",
      "[84/1762] D loss: 1.2087, G loss: 1.0142\n",
      "[164/1762] D loss: 0.9271, G loss: 1.0453\n",
      "[244/1762] D loss: 0.6375, G loss: 2.2769\n",
      "[324/1762] D loss: 1.0398, G loss: 0.6988\n",
      "[404/1762] D loss: 1.6771, G loss: 0.4184\n",
      "[484/1762] D loss: 1.0096, G loss: 1.2415\n",
      "[564/1762] D loss: 1.2252, G loss: 1.3169\n",
      "[644/1762] D loss: 0.9154, G loss: 1.4209\n",
      "[724/1762] D loss: 1.1042, G loss: 0.8637\n",
      "[804/1762] D loss: 0.8039, G loss: 1.3143\n",
      "[884/1762] D loss: 1.1532, G loss: 1.1261\n",
      "[964/1762] D loss: 0.9758, G loss: 1.0335\n",
      "[1044/1762] D loss: 1.0138, G loss: 0.8341\n",
      "[1124/1762] D loss: 0.8555, G loss: 1.5877\n",
      "[1204/1762] D loss: 1.2740, G loss: 0.5236\n",
      "[1284/1762] D loss: 1.1083, G loss: 1.0991\n",
      "[1364/1762] D loss: 1.1431, G loss: 2.2545\n",
      "[1444/1762] D loss: 0.9449, G loss: 0.9697\n",
      "[1524/1762] D loss: 0.8393, G loss: 1.0557\n",
      "[1604/1762] D loss: 0.9451, G loss: 0.8415\n",
      "[1684/1762] D loss: 1.1022, G loss: 1.1948\n",
      "[1762/1762] D loss: 1.0753, G loss: 1.3022\n",
      "train error: \n",
      " D loss: 0.976259, G loss: 1.128697, D accuracy: 80.2%, cell accuracy: 98.4%, board accuracy: 2.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.978779, G loss: 1.134245, D accuracy: 80.1%, cell accuracy: 98.4%, board accuracy: 2.0% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8525, G loss: 1.0815\n",
      "[84/1762] D loss: 1.4586, G loss: 0.5146\n",
      "[164/1762] D loss: 1.1670, G loss: 0.9009\n",
      "[244/1762] D loss: 0.8728, G loss: 0.9127\n",
      "[324/1762] D loss: 1.2978, G loss: 0.9664\n",
      "[404/1762] D loss: 1.6707, G loss: 1.3796\n",
      "[484/1762] D loss: 0.8762, G loss: 1.0583\n",
      "[564/1762] D loss: 1.0941, G loss: 1.2268\n",
      "[644/1762] D loss: 0.9785, G loss: 0.8589\n",
      "[724/1762] D loss: 0.9620, G loss: 1.2226\n",
      "[804/1762] D loss: 0.7837, G loss: 1.5638\n",
      "[884/1762] D loss: 0.7356, G loss: 1.6238\n",
      "[964/1762] D loss: 1.1007, G loss: 0.9455\n",
      "[1044/1762] D loss: 1.2186, G loss: 0.8350\n",
      "[1124/1762] D loss: 0.9646, G loss: 1.4192\n",
      "[1204/1762] D loss: 0.8757, G loss: 0.8372\n",
      "[1284/1762] D loss: 0.7310, G loss: 1.8184\n",
      "[1364/1762] D loss: 0.9832, G loss: 1.5207\n",
      "[1444/1762] D loss: 1.4056, G loss: 1.0433\n",
      "[1524/1762] D loss: 1.1182, G loss: 1.5674\n",
      "[1604/1762] D loss: 1.2276, G loss: 0.9116\n",
      "[1684/1762] D loss: 1.1472, G loss: 1.0139\n",
      "[1762/1762] D loss: 0.9045, G loss: 1.3533\n",
      "train error: \n",
      " D loss: 1.223287, G loss: 1.119667, D accuracy: 69.0%, cell accuracy: 98.5%, board accuracy: 5.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.225417, G loss: 1.136849, D accuracy: 68.0%, cell accuracy: 98.4%, board accuracy: 2.7% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8052, G loss: 1.5247\n",
      "[84/1762] D loss: 1.1100, G loss: 1.3128\n",
      "[164/1762] D loss: 1.1075, G loss: 1.2214\n",
      "[244/1762] D loss: 0.8444, G loss: 1.4439\n",
      "[324/1762] D loss: 1.3976, G loss: 1.1247\n",
      "[404/1762] D loss: 0.9739, G loss: 1.0266\n",
      "[484/1762] D loss: 1.1664, G loss: 0.9047\n",
      "[564/1762] D loss: 0.8978, G loss: 1.6343\n",
      "[644/1762] D loss: 1.2591, G loss: 1.8697\n",
      "[724/1762] D loss: 1.1853, G loss: 1.1855\n",
      "[804/1762] D loss: 1.0405, G loss: 1.0943\n",
      "[884/1762] D loss: 1.2035, G loss: 0.5548\n",
      "[964/1762] D loss: 1.4308, G loss: 1.8422\n",
      "[1044/1762] D loss: 1.2048, G loss: 0.8159\n",
      "[1124/1762] D loss: 0.9751, G loss: 1.4602\n",
      "[1204/1762] D loss: 1.3250, G loss: 0.5689\n",
      "[1284/1762] D loss: 1.6165, G loss: 0.3712\n",
      "[1364/1762] D loss: 0.9162, G loss: 1.8758\n",
      "[1444/1762] D loss: 1.6809, G loss: 0.9808\n",
      "[1524/1762] D loss: 1.0766, G loss: 0.9928\n",
      "[1604/1762] D loss: 1.2419, G loss: 0.9755\n",
      "[1684/1762] D loss: 1.4749, G loss: 1.0845\n",
      "[1762/1762] D loss: 1.2333, G loss: 1.9433\n",
      "train error: \n",
      " D loss: 1.316231, G loss: 1.435888, D accuracy: 58.6%, cell accuracy: 99.1%, board accuracy: 24.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.318753, G loss: 1.460962, D accuracy: 58.8%, cell accuracy: 99.0%, board accuracy: 20.5% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3827, G loss: 1.0696\n",
      "[84/1762] D loss: 0.9495, G loss: 0.7660\n",
      "[164/1762] D loss: 1.3075, G loss: 0.6918\n",
      "[244/1762] D loss: 1.3428, G loss: 1.3115\n",
      "[324/1762] D loss: 1.3234, G loss: 1.0053\n",
      "[404/1762] D loss: 1.5713, G loss: 1.5415\n",
      "[484/1762] D loss: 1.1729, G loss: 0.9461\n",
      "[564/1762] D loss: 1.3102, G loss: 0.7692\n",
      "[644/1762] D loss: 1.2462, G loss: 0.8588\n",
      "[724/1762] D loss: 1.3486, G loss: 0.6933\n",
      "[804/1762] D loss: 1.2821, G loss: 0.7242\n",
      "[884/1762] D loss: 1.3054, G loss: 0.8596\n",
      "[964/1762] D loss: 1.2669, G loss: 0.6761\n",
      "[1044/1762] D loss: 1.2380, G loss: 0.7122\n",
      "[1124/1762] D loss: 1.6485, G loss: 1.7834\n",
      "[1204/1762] D loss: 1.1339, G loss: 1.0744\n",
      "[1284/1762] D loss: 1.5149, G loss: 1.0701\n",
      "[1364/1762] D loss: 1.3124, G loss: 1.0136\n",
      "[1444/1762] D loss: 1.3207, G loss: 0.7647\n",
      "[1524/1762] D loss: 1.1513, G loss: 1.1131\n",
      "[1604/1762] D loss: 1.6778, G loss: 0.3911\n",
      "[1684/1762] D loss: 1.0959, G loss: 1.0758\n",
      "[1762/1762] D loss: 1.2014, G loss: 0.6967\n",
      "train error: \n",
      " D loss: 1.386134, G loss: 0.523718, D accuracy: 57.3%, cell accuracy: 99.3%, board accuracy: 36.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.358396, G loss: 0.544808, D accuracy: 58.4%, cell accuracy: 99.2%, board accuracy: 28.6% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4669, G loss: 0.4462\n",
      "[84/1762] D loss: 1.1713, G loss: 0.9347\n",
      "[164/1762] D loss: 1.3704, G loss: 0.9303\n",
      "[244/1762] D loss: 1.2110, G loss: 0.9632\n",
      "[324/1762] D loss: 1.3102, G loss: 0.6738\n",
      "[404/1762] D loss: 1.2140, G loss: 1.2561\n",
      "[484/1762] D loss: 1.1449, G loss: 1.0449\n",
      "[564/1762] D loss: 1.3641, G loss: 0.6569\n",
      "[644/1762] D loss: 1.2925, G loss: 0.7408\n",
      "[724/1762] D loss: 1.2858, G loss: 0.9937\n",
      "[804/1762] D loss: 1.5333, G loss: 1.2691\n",
      "[884/1762] D loss: 1.2941, G loss: 0.7018\n",
      "[964/1762] D loss: 1.5237, G loss: 1.1806\n",
      "[1044/1762] D loss: 1.2535, G loss: 1.2919\n",
      "[1124/1762] D loss: 1.1276, G loss: 0.7397\n",
      "[1204/1762] D loss: 1.3083, G loss: 0.7548\n",
      "[1284/1762] D loss: 1.3870, G loss: 0.7664\n",
      "[1364/1762] D loss: 1.0697, G loss: 0.6444\n",
      "[1444/1762] D loss: 1.3243, G loss: 0.7832\n",
      "[1524/1762] D loss: 0.9955, G loss: 1.0609\n",
      "[1604/1762] D loss: 1.4438, G loss: 0.4770\n",
      "[1684/1762] D loss: 1.3758, G loss: 0.6220\n",
      "[1762/1762] D loss: 1.4255, G loss: 0.6082\n",
      "train error: \n",
      " D loss: 1.323564, G loss: 1.164715, D accuracy: 61.1%, cell accuracy: 99.4%, board accuracy: 41.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.328425, G loss: 1.198473, D accuracy: 62.0%, cell accuracy: 99.3%, board accuracy: 34.5% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1603, G loss: 1.3261\n",
      "[84/1762] D loss: 1.4968, G loss: 0.4862\n",
      "[164/1762] D loss: 1.3316, G loss: 0.8468\n",
      "[244/1762] D loss: 1.4411, G loss: 0.7961\n",
      "[324/1762] D loss: 1.2991, G loss: 0.8239\n",
      "[404/1762] D loss: 1.3766, G loss: 1.2077\n",
      "[484/1762] D loss: 1.4753, G loss: 0.5773\n",
      "[564/1762] D loss: 1.3701, G loss: 0.5553\n",
      "[644/1762] D loss: 1.6290, G loss: 1.3338\n",
      "[724/1762] D loss: 1.5891, G loss: 0.6933\n",
      "[804/1762] D loss: 1.3891, G loss: 0.9942\n",
      "[884/1762] D loss: 1.1667, G loss: 1.1174\n",
      "[964/1762] D loss: 1.4499, G loss: 0.5618\n",
      "[1044/1762] D loss: 1.3874, G loss: 0.9317\n",
      "[1124/1762] D loss: 1.1180, G loss: 1.0957\n",
      "[1204/1762] D loss: 1.4219, G loss: 0.8682\n",
      "[1284/1762] D loss: 1.3571, G loss: 0.6563\n",
      "[1364/1762] D loss: 1.9788, G loss: 1.9856\n",
      "[1444/1762] D loss: 1.2183, G loss: 1.2332\n",
      "[1524/1762] D loss: 1.2950, G loss: 0.5595\n",
      "[1604/1762] D loss: 1.1187, G loss: 0.9799\n",
      "[1684/1762] D loss: 1.2757, G loss: 1.0126\n",
      "[1762/1762] D loss: 1.4858, G loss: 0.4316\n",
      "train error: \n",
      " D loss: 1.350105, G loss: 0.634490, D accuracy: 58.9%, cell accuracy: 99.5%, board accuracy: 46.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.357409, G loss: 0.646276, D accuracy: 58.2%, cell accuracy: 99.4%, board accuracy: 42.5% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2993, G loss: 0.7618\n",
      "[84/1762] D loss: 1.2254, G loss: 0.7854\n",
      "[164/1762] D loss: 1.3702, G loss: 0.9478\n",
      "[244/1762] D loss: 1.2626, G loss: 1.0502\n",
      "[324/1762] D loss: 1.3130, G loss: 1.1502\n",
      "[404/1762] D loss: 1.3613, G loss: 0.8799\n",
      "[484/1762] D loss: 1.4137, G loss: 0.5966\n",
      "[564/1762] D loss: 1.4009, G loss: 0.8277\n",
      "[644/1762] D loss: 1.4202, G loss: 0.9206\n",
      "[724/1762] D loss: 1.2487, G loss: 0.9034\n",
      "[804/1762] D loss: 1.3807, G loss: 0.8664\n",
      "[884/1762] D loss: 1.4242, G loss: 0.7317\n",
      "[964/1762] D loss: 1.4506, G loss: 0.6747\n",
      "[1044/1762] D loss: 1.3263, G loss: 0.6380\n",
      "[1124/1762] D loss: 1.2142, G loss: 0.7463\n",
      "[1204/1762] D loss: 1.3505, G loss: 0.5845\n",
      "[1284/1762] D loss: 1.3108, G loss: 0.7529\n",
      "[1364/1762] D loss: 1.3300, G loss: 1.1280\n",
      "[1444/1762] D loss: 1.4179, G loss: 0.9123\n",
      "[1524/1762] D loss: 1.4201, G loss: 0.5875\n",
      "[1604/1762] D loss: 1.3233, G loss: 0.7830\n",
      "[1684/1762] D loss: 1.4268, G loss: 0.7385\n",
      "[1762/1762] D loss: 1.3803, G loss: 0.9295\n",
      "train error: \n",
      " D loss: 1.328839, G loss: 0.936485, D accuracy: 59.3%, cell accuracy: 99.5%, board accuracy: 48.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.359430, G loss: 0.911071, D accuracy: 58.6%, cell accuracy: 99.5%, board accuracy: 43.0% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3867, G loss: 0.8508\n",
      "[84/1762] D loss: 1.2682, G loss: 0.8943\n",
      "[164/1762] D loss: 1.3952, G loss: 0.4544\n",
      "[244/1762] D loss: 1.4132, G loss: 0.9106\n",
      "[324/1762] D loss: 1.4725, G loss: 1.0601\n",
      "[404/1762] D loss: 1.4631, G loss: 0.5002\n",
      "[484/1762] D loss: 1.4149, G loss: 0.5359\n",
      "[564/1762] D loss: 1.3079, G loss: 0.6724\n",
      "[644/1762] D loss: 1.5108, G loss: 0.9413\n",
      "[724/1762] D loss: 1.3887, G loss: 0.7949\n",
      "[804/1762] D loss: 1.3151, G loss: 0.7758\n",
      "[884/1762] D loss: 1.3823, G loss: 0.6367\n",
      "[964/1762] D loss: 1.4296, G loss: 0.5387\n",
      "[1044/1762] D loss: 1.3347, G loss: 0.8917\n",
      "[1124/1762] D loss: 1.4193, G loss: 0.5689\n",
      "[1204/1762] D loss: 1.3147, G loss: 0.6396\n",
      "[1284/1762] D loss: 1.2180, G loss: 0.8879\n",
      "[1364/1762] D loss: 1.4926, G loss: 0.9102\n",
      "[1444/1762] D loss: 1.4864, G loss: 0.5227\n",
      "[1524/1762] D loss: 1.3064, G loss: 0.7396\n",
      "[1604/1762] D loss: 1.3349, G loss: 0.7396\n",
      "[1684/1762] D loss: 1.2728, G loss: 0.7976\n",
      "[1762/1762] D loss: 1.0914, G loss: 0.7539\n",
      "train error: \n",
      " D loss: 1.339486, G loss: 0.705943, D accuracy: 58.9%, cell accuracy: 99.5%, board accuracy: 45.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.349307, G loss: 0.708023, D accuracy: 57.7%, cell accuracy: 99.5%, board accuracy: 45.5% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3483, G loss: 0.6636\n",
      "[84/1762] D loss: 1.2823, G loss: 0.8929\n",
      "[164/1762] D loss: 1.3421, G loss: 0.9290\n",
      "[244/1762] D loss: 1.2907, G loss: 0.7466\n",
      "[324/1762] D loss: 1.4320, G loss: 0.7262\n",
      "[404/1762] D loss: 1.4985, G loss: 0.5178\n",
      "[484/1762] D loss: 1.3711, G loss: 0.7212\n",
      "[564/1762] D loss: 1.3693, G loss: 0.9780\n",
      "[644/1762] D loss: 1.2936, G loss: 0.9503\n",
      "[724/1762] D loss: 1.3641, G loss: 0.6889\n",
      "[804/1762] D loss: 1.3966, G loss: 1.1563\n",
      "[884/1762] D loss: 1.3154, G loss: 1.0177\n",
      "[964/1762] D loss: 1.3608, G loss: 0.7576\n",
      "[1044/1762] D loss: 1.4338, G loss: 0.6733\n",
      "[1124/1762] D loss: 1.5318, G loss: 0.6956\n",
      "[1204/1762] D loss: 1.2979, G loss: 0.6738\n",
      "[1284/1762] D loss: 1.3546, G loss: 0.9271\n",
      "[1364/1762] D loss: 1.4358, G loss: 0.6411\n",
      "[1444/1762] D loss: 1.4681, G loss: 0.5133\n",
      "[1524/1762] D loss: 1.2861, G loss: 0.7993\n",
      "[1604/1762] D loss: 1.3580, G loss: 0.6543\n",
      "[1684/1762] D loss: 1.4338, G loss: 1.0432\n",
      "[1762/1762] D loss: 1.3400, G loss: 0.7730\n",
      "train error: \n",
      " D loss: 1.409474, G loss: 0.623109, D accuracy: 53.0%, cell accuracy: 99.7%, board accuracy: 70.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.417899, G loss: 0.630236, D accuracy: 52.7%, cell accuracy: 99.6%, board accuracy: 68.0% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3978, G loss: 0.7029\n",
      "[84/1762] D loss: 1.5077, G loss: 1.1119\n",
      "[164/1762] D loss: 1.2737, G loss: 0.8289\n",
      "[244/1762] D loss: 1.4566, G loss: 0.7201\n",
      "[324/1762] D loss: 1.4535, G loss: 0.7799\n",
      "[404/1762] D loss: 1.4093, G loss: 0.5272\n",
      "[484/1762] D loss: 1.3772, G loss: 0.6804\n",
      "[564/1762] D loss: 1.4730, G loss: 0.5527\n",
      "[644/1762] D loss: 1.4226, G loss: 0.6588\n",
      "[724/1762] D loss: 1.4064, G loss: 0.6163\n",
      "[804/1762] D loss: 1.2667, G loss: 0.9310\n",
      "[884/1762] D loss: 1.4014, G loss: 0.6841\n",
      "[964/1762] D loss: 1.3958, G loss: 0.6652\n",
      "[1044/1762] D loss: 1.2531, G loss: 0.8516\n",
      "[1124/1762] D loss: 1.5096, G loss: 0.7907\n",
      "[1204/1762] D loss: 1.3203, G loss: 0.8046\n",
      "[1284/1762] D loss: 1.3786, G loss: 0.7484\n",
      "[1364/1762] D loss: 1.4473, G loss: 0.7932\n",
      "[1444/1762] D loss: 1.3299, G loss: 1.0694\n",
      "[1524/1762] D loss: 1.3729, G loss: 0.7848\n",
      "[1604/1762] D loss: 1.4814, G loss: 0.5110\n",
      "[1684/1762] D loss: 1.5147, G loss: 0.6957\n",
      "[1762/1762] D loss: 1.3809, G loss: 0.7280\n",
      "train error: \n",
      " D loss: 1.493257, G loss: 1.137143, D accuracy: 50.1%, cell accuracy: 99.6%, board accuracy: 61.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.506978, G loss: 1.156477, D accuracy: 49.4%, cell accuracy: 99.5%, board accuracy: 57.3% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5446, G loss: 1.1346\n",
      "[84/1762] D loss: 1.3320, G loss: 0.6748\n",
      "[164/1762] D loss: 1.3707, G loss: 0.8320\n",
      "[244/1762] D loss: 1.4630, G loss: 0.9427\n",
      "[324/1762] D loss: 1.2592, G loss: 0.8248\n",
      "[404/1762] D loss: 1.4876, G loss: 0.5834\n",
      "[484/1762] D loss: 1.4411, G loss: 0.6250\n",
      "[564/1762] D loss: 1.6281, G loss: 0.5247\n",
      "[644/1762] D loss: 1.5514, G loss: 0.4878\n",
      "[724/1762] D loss: 1.4230, G loss: 0.6556\n",
      "[804/1762] D loss: 1.4067, G loss: 0.7310\n",
      "[884/1762] D loss: 1.3227, G loss: 0.9861\n",
      "[964/1762] D loss: 1.4337, G loss: 0.7256\n",
      "[1044/1762] D loss: 1.4541, G loss: 0.5853\n",
      "[1124/1762] D loss: 1.4187, G loss: 0.9044\n",
      "[1204/1762] D loss: 1.4465, G loss: 0.6958\n",
      "[1284/1762] D loss: 1.5130, G loss: 0.5961\n",
      "[1364/1762] D loss: 1.3875, G loss: 0.7968\n",
      "[1444/1762] D loss: 1.4183, G loss: 0.8868\n",
      "[1524/1762] D loss: 1.4257, G loss: 0.7598\n",
      "[1604/1762] D loss: 1.3912, G loss: 0.7566\n",
      "[1684/1762] D loss: 1.4157, G loss: 0.5611\n",
      "[1762/1762] D loss: 1.4902, G loss: 0.9462\n",
      "train error: \n",
      " D loss: 1.411625, G loss: 0.853397, D accuracy: 51.3%, cell accuracy: 99.5%, board accuracy: 43.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.421966, G loss: 0.864627, D accuracy: 51.5%, cell accuracy: 99.5%, board accuracy: 42.3% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4878, G loss: 0.8317\n",
      "[84/1762] D loss: 1.3497, G loss: 0.7626\n",
      "[164/1762] D loss: 1.4507, G loss: 0.6669\n",
      "[244/1762] D loss: 1.3636, G loss: 0.7578\n",
      "[324/1762] D loss: 1.4507, G loss: 0.7018\n",
      "[404/1762] D loss: 1.4930, G loss: 0.6084\n",
      "[484/1762] D loss: 1.3946, G loss: 0.5686\n",
      "[564/1762] D loss: 1.3930, G loss: 0.7462\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6835\n",
      "[724/1762] D loss: 1.4133, G loss: 0.6667\n",
      "[804/1762] D loss: 1.3582, G loss: 0.6366\n",
      "[884/1762] D loss: 1.4374, G loss: 0.6736\n",
      "[964/1762] D loss: 1.4547, G loss: 0.6514\n",
      "[1044/1762] D loss: 1.1749, G loss: 1.0434\n",
      "[1124/1762] D loss: 1.3258, G loss: 0.6684\n",
      "[1204/1762] D loss: 1.2904, G loss: 0.9343\n",
      "[1284/1762] D loss: 1.4457, G loss: 0.8384\n",
      "[1364/1762] D loss: 1.3868, G loss: 0.8867\n",
      "[1444/1762] D loss: 1.4063, G loss: 1.0670\n",
      "[1524/1762] D loss: 1.4247, G loss: 0.8109\n",
      "[1604/1762] D loss: 1.4452, G loss: 0.7234\n",
      "[1684/1762] D loss: 1.3268, G loss: 0.5337\n",
      "[1762/1762] D loss: 1.4012, G loss: 0.7880\n",
      "train error: \n",
      " D loss: 1.391711, G loss: 0.926081, D accuracy: 52.4%, cell accuracy: 99.5%, board accuracy: 47.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.403994, G loss: 0.934724, D accuracy: 51.9%, cell accuracy: 99.5%, board accuracy: 47.0% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3530, G loss: 0.8321\n",
      "[84/1762] D loss: 1.4351, G loss: 0.7407\n",
      "[164/1762] D loss: 1.4168, G loss: 0.5528\n",
      "[244/1762] D loss: 1.3795, G loss: 0.6258\n",
      "[324/1762] D loss: 1.4659, G loss: 0.6308\n",
      "[404/1762] D loss: 1.4791, G loss: 0.6842\n",
      "[484/1762] D loss: 1.2719, G loss: 0.7129\n",
      "[564/1762] D loss: 1.3423, G loss: 0.6447\n",
      "[644/1762] D loss: 1.4184, G loss: 0.9076\n",
      "[724/1762] D loss: 1.2836, G loss: 0.8407\n",
      "[804/1762] D loss: 1.4182, G loss: 0.7620\n",
      "[884/1762] D loss: 1.2945, G loss: 0.7213\n",
      "[964/1762] D loss: 1.3511, G loss: 0.7406\n",
      "[1044/1762] D loss: 1.4449, G loss: 0.5897\n",
      "[1124/1762] D loss: 1.5344, G loss: 0.9532\n",
      "[1204/1762] D loss: 1.3529, G loss: 0.8024\n",
      "[1284/1762] D loss: 1.2389, G loss: 0.8928\n",
      "[1364/1762] D loss: 1.3466, G loss: 0.7758\n",
      "[1444/1762] D loss: 1.3996, G loss: 0.5157\n",
      "[1524/1762] D loss: 1.4375, G loss: 0.8772\n",
      "[1604/1762] D loss: 1.3602, G loss: 0.7756\n",
      "[1684/1762] D loss: 1.4330, G loss: 0.8487\n",
      "[1762/1762] D loss: 1.3570, G loss: 0.6930\n",
      "train error: \n",
      " D loss: 1.396309, G loss: 0.774438, D accuracy: 51.5%, cell accuracy: 99.7%, board accuracy: 68.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.403222, G loss: 0.786410, D accuracy: 51.9%, cell accuracy: 99.6%, board accuracy: 64.5% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3853, G loss: 0.7844\n",
      "[84/1762] D loss: 1.3623, G loss: 0.5989\n",
      "[164/1762] D loss: 1.4375, G loss: 0.5225\n",
      "[244/1762] D loss: 1.4105, G loss: 0.6427\n",
      "[324/1762] D loss: 1.4662, G loss: 0.7147\n",
      "[404/1762] D loss: 1.4272, G loss: 0.5191\n",
      "[484/1762] D loss: 1.4605, G loss: 0.6328\n",
      "[564/1762] D loss: 1.4245, G loss: 0.5081\n",
      "[644/1762] D loss: 1.3772, G loss: 0.9049\n",
      "[724/1762] D loss: 1.3946, G loss: 0.6088\n",
      "[804/1762] D loss: 1.4003, G loss: 0.7319\n",
      "[884/1762] D loss: 1.4554, G loss: 0.5297\n",
      "[964/1762] D loss: 1.4151, G loss: 0.7702\n",
      "[1044/1762] D loss: 1.3938, G loss: 0.8214\n",
      "[1124/1762] D loss: 1.4439, G loss: 0.7287\n",
      "[1204/1762] D loss: 1.3103, G loss: 0.8395\n",
      "[1284/1762] D loss: 1.2544, G loss: 0.7651\n",
      "[1364/1762] D loss: 1.4571, G loss: 0.6115\n",
      "[1444/1762] D loss: 1.4219, G loss: 0.7835\n",
      "[1524/1762] D loss: 1.4512, G loss: 0.8810\n",
      "[1604/1762] D loss: 1.3874, G loss: 0.7905\n",
      "[1684/1762] D loss: 1.4621, G loss: 0.7804\n",
      "[1762/1762] D loss: 1.4132, G loss: 0.6337\n",
      "train error: \n",
      " D loss: 1.390131, G loss: 0.648946, D accuracy: 53.4%, cell accuracy: 99.6%, board accuracy: 65.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.394054, G loss: 0.659950, D accuracy: 54.0%, cell accuracy: 99.6%, board accuracy: 62.5% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3622, G loss: 0.7715\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6885\n",
      "[164/1762] D loss: 1.4668, G loss: 0.5871\n",
      "[244/1762] D loss: 1.4985, G loss: 0.5854\n",
      "[324/1762] D loss: 1.3970, G loss: 0.9723\n",
      "[404/1762] D loss: 1.3380, G loss: 0.9032\n",
      "[484/1762] D loss: 1.3897, G loss: 0.7850\n",
      "[564/1762] D loss: 1.4064, G loss: 0.6574\n",
      "[644/1762] D loss: 1.4118, G loss: 0.6001\n",
      "[724/1762] D loss: 1.4086, G loss: 0.7161\n",
      "[804/1762] D loss: 1.3761, G loss: 0.5678\n",
      "[884/1762] D loss: 1.4063, G loss: 0.6115\n",
      "[964/1762] D loss: 1.5060, G loss: 0.7272\n",
      "[1044/1762] D loss: 1.3856, G loss: 0.9824\n",
      "[1124/1762] D loss: 1.2753, G loss: 0.6412\n",
      "[1204/1762] D loss: 1.4445, G loss: 0.5287\n",
      "[1284/1762] D loss: 1.3570, G loss: 0.7078\n",
      "[1364/1762] D loss: 1.3917, G loss: 0.6425\n",
      "[1444/1762] D loss: 1.4474, G loss: 0.8077\n",
      "[1524/1762] D loss: 1.3544, G loss: 0.8413\n",
      "[1604/1762] D loss: 1.3849, G loss: 0.5291\n",
      "[1684/1762] D loss: 1.4395, G loss: 0.6637\n",
      "[1762/1762] D loss: 1.3465, G loss: 0.5832\n",
      "train error: \n",
      " D loss: 1.396080, G loss: 0.619948, D accuracy: 53.1%, cell accuracy: 99.7%, board accuracy: 67.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.396304, G loss: 0.634102, D accuracy: 53.5%, cell accuracy: 99.6%, board accuracy: 64.1% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3486, G loss: 0.6941\n",
      "[84/1762] D loss: 1.3802, G loss: 0.6531\n",
      "[164/1762] D loss: 1.4347, G loss: 0.6182\n",
      "[244/1762] D loss: 1.3839, G loss: 0.6289\n",
      "[324/1762] D loss: 1.4851, G loss: 0.8078\n",
      "[404/1762] D loss: 1.3894, G loss: 0.6110\n",
      "[484/1762] D loss: 1.4284, G loss: 0.7859\n",
      "[564/1762] D loss: 1.4406, G loss: 0.6136\n",
      "[644/1762] D loss: 1.3895, G loss: 0.6881\n",
      "[724/1762] D loss: 1.4058, G loss: 0.7262\n",
      "[804/1762] D loss: 1.3983, G loss: 0.5878\n",
      "[884/1762] D loss: 1.3018, G loss: 0.7416\n",
      "[964/1762] D loss: 1.5396, G loss: 0.5920\n",
      "[1044/1762] D loss: 1.2614, G loss: 1.0711\n",
      "[1124/1762] D loss: 1.3467, G loss: 0.7949\n",
      "[1204/1762] D loss: 1.4285, G loss: 0.6996\n",
      "[1284/1762] D loss: 1.3497, G loss: 0.6450\n",
      "[1364/1762] D loss: 1.3639, G loss: 0.6714\n",
      "[1444/1762] D loss: 1.4149, G loss: 0.5795\n",
      "[1524/1762] D loss: 1.3693, G loss: 0.7206\n",
      "[1604/1762] D loss: 1.4059, G loss: 0.7647\n",
      "[1684/1762] D loss: 1.3940, G loss: 0.6726\n",
      "[1762/1762] D loss: 1.4502, G loss: 0.6501\n",
      "train error: \n",
      " D loss: 1.383491, G loss: 0.753240, D accuracy: 50.9%, cell accuracy: 99.7%, board accuracy: 68.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.386253, G loss: 0.766371, D accuracy: 51.2%, cell accuracy: 99.6%, board accuracy: 66.4% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4525, G loss: 1.0673\n",
      "[84/1762] D loss: 1.3901, G loss: 0.7286\n",
      "[164/1762] D loss: 1.4463, G loss: 0.8403\n",
      "[244/1762] D loss: 1.3663, G loss: 0.6945\n",
      "[324/1762] D loss: 1.3615, G loss: 0.7711\n",
      "[404/1762] D loss: 1.3628, G loss: 0.6726\n",
      "[484/1762] D loss: 1.3909, G loss: 0.7001\n",
      "[564/1762] D loss: 1.3598, G loss: 0.7370\n",
      "[644/1762] D loss: 1.4097, G loss: 0.5853\n",
      "[724/1762] D loss: 1.3652, G loss: 0.7093\n",
      "[804/1762] D loss: 1.3975, G loss: 0.6551\n",
      "[884/1762] D loss: 1.4183, G loss: 0.6358\n",
      "[964/1762] D loss: 1.3677, G loss: 0.9006\n",
      "[1044/1762] D loss: 1.4172, G loss: 0.6203\n",
      "[1124/1762] D loss: 1.3027, G loss: 0.7506\n",
      "[1204/1762] D loss: 1.3364, G loss: 0.9471\n",
      "[1284/1762] D loss: 1.3509, G loss: 0.8391\n",
      "[1364/1762] D loss: 1.4001, G loss: 0.7810\n",
      "[1444/1762] D loss: 1.4051, G loss: 0.9315\n",
      "[1524/1762] D loss: 1.4039, G loss: 0.5899\n",
      "[1604/1762] D loss: 1.4147, G loss: 0.8820\n",
      "[1684/1762] D loss: 1.3963, G loss: 0.6561\n",
      "[1762/1762] D loss: 1.4199, G loss: 0.6067\n",
      "train error: \n",
      " D loss: 1.381170, G loss: 0.693195, D accuracy: 52.1%, cell accuracy: 99.7%, board accuracy: 69.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.381355, G loss: 0.709293, D accuracy: 53.4%, cell accuracy: 99.6%, board accuracy: 68.9% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4187, G loss: 0.7643\n",
      "[84/1762] D loss: 1.4251, G loss: 0.6940\n",
      "[164/1762] D loss: 1.3874, G loss: 0.7171\n",
      "[244/1762] D loss: 1.3944, G loss: 0.8521\n",
      "[324/1762] D loss: 1.4164, G loss: 0.5621\n",
      "[404/1762] D loss: 1.2959, G loss: 0.6578\n",
      "[484/1762] D loss: 1.3603, G loss: 0.7211\n",
      "[564/1762] D loss: 1.4205, G loss: 0.6662\n",
      "[644/1762] D loss: 1.3644, G loss: 0.7066\n",
      "[724/1762] D loss: 1.3805, G loss: 0.7112\n",
      "[804/1762] D loss: 1.3764, G loss: 0.7636\n",
      "[884/1762] D loss: 1.4019, G loss: 0.8613\n",
      "[964/1762] D loss: 1.3413, G loss: 0.6758\n",
      "[1044/1762] D loss: 1.3566, G loss: 0.6996\n",
      "[1124/1762] D loss: 1.4011, G loss: 0.7105\n",
      "[1204/1762] D loss: 1.3433, G loss: 0.6621\n",
      "[1284/1762] D loss: 1.3901, G loss: 0.5640\n",
      "[1364/1762] D loss: 1.4101, G loss: 0.6995\n",
      "[1444/1762] D loss: 1.3181, G loss: 0.7985\n",
      "[1524/1762] D loss: 1.2667, G loss: 0.7747\n",
      "[1604/1762] D loss: 1.3734, G loss: 0.7311\n",
      "[1684/1762] D loss: 1.3940, G loss: 0.7049\n",
      "[1762/1762] D loss: 1.3916, G loss: 0.8252\n",
      "train error: \n",
      " D loss: 1.378536, G loss: 0.741852, D accuracy: 51.5%, cell accuracy: 99.7%, board accuracy: 69.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.377807, G loss: 0.759520, D accuracy: 51.8%, cell accuracy: 99.6%, board accuracy: 66.8% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4103, G loss: 0.6895\n",
      "[84/1762] D loss: 1.4695, G loss: 0.6656\n",
      "[164/1762] D loss: 1.3895, G loss: 0.6799\n",
      "[244/1762] D loss: 1.4055, G loss: 0.6844\n",
      "[324/1762] D loss: 1.3630, G loss: 0.7939\n",
      "[404/1762] D loss: 1.4448, G loss: 0.8199\n",
      "[484/1762] D loss: 1.4009, G loss: 0.6345\n",
      "[564/1762] D loss: 1.3934, G loss: 0.6922\n",
      "[644/1762] D loss: 1.4359, G loss: 0.8108\n",
      "[724/1762] D loss: 1.3888, G loss: 1.0795\n",
      "[804/1762] D loss: 1.2586, G loss: 0.8192\n",
      "[884/1762] D loss: 1.3568, G loss: 0.7245\n",
      "[964/1762] D loss: 1.4565, G loss: 0.6530\n",
      "[1044/1762] D loss: 1.4184, G loss: 0.7529\n",
      "[1124/1762] D loss: 1.3813, G loss: 0.6667\n",
      "[1204/1762] D loss: 1.4296, G loss: 0.5721\n",
      "[1284/1762] D loss: 1.4411, G loss: 0.8199\n",
      "[1364/1762] D loss: 1.3971, G loss: 0.8084\n",
      "[1444/1762] D loss: 1.3877, G loss: 0.8185\n",
      "[1524/1762] D loss: 1.3720, G loss: 0.7077\n",
      "[1604/1762] D loss: 1.3120, G loss: 0.7705\n",
      "[1684/1762] D loss: 1.4523, G loss: 0.7066\n",
      "[1762/1762] D loss: 1.4214, G loss: 0.6188\n",
      "train error: \n",
      " D loss: 1.376626, G loss: 0.754238, D accuracy: 51.6%, cell accuracy: 99.7%, board accuracy: 66.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.375780, G loss: 0.771194, D accuracy: 51.7%, cell accuracy: 99.6%, board accuracy: 65.2% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4057, G loss: 0.7546\n",
      "[84/1762] D loss: 1.4032, G loss: 0.7809\n",
      "[164/1762] D loss: 1.3610, G loss: 0.7939\n",
      "[244/1762] D loss: 1.4281, G loss: 0.7179\n",
      "[324/1762] D loss: 1.4018, G loss: 0.7360\n",
      "[404/1762] D loss: 1.4137, G loss: 0.6212\n",
      "[484/1762] D loss: 1.4013, G loss: 0.6795\n",
      "[564/1762] D loss: 1.3875, G loss: 0.6620\n",
      "[644/1762] D loss: 1.3952, G loss: 0.7189\n",
      "[724/1762] D loss: 1.4039, G loss: 0.5742\n",
      "[804/1762] D loss: 1.3127, G loss: 0.7075\n",
      "[884/1762] D loss: 1.3893, G loss: 0.6792\n",
      "[964/1762] D loss: 1.4096, G loss: 0.6832\n",
      "[1044/1762] D loss: 1.4067, G loss: 0.7520\n",
      "[1124/1762] D loss: 1.4295, G loss: 0.6543\n",
      "[1204/1762] D loss: 1.3057, G loss: 0.6460\n",
      "[1284/1762] D loss: 1.3952, G loss: 0.7767\n",
      "[1364/1762] D loss: 1.4534, G loss: 0.5515\n",
      "[1444/1762] D loss: 1.4082, G loss: 0.5847\n",
      "[1524/1762] D loss: 1.4717, G loss: 0.8705\n",
      "[1604/1762] D loss: 1.4050, G loss: 0.7694\n",
      "[1684/1762] D loss: 1.3197, G loss: 0.6527\n",
      "[1762/1762] D loss: 1.4075, G loss: 0.7144\n",
      "train error: \n",
      " D loss: 1.376897, G loss: 0.678970, D accuracy: 52.9%, cell accuracy: 99.7%, board accuracy: 67.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.377386, G loss: 0.691401, D accuracy: 52.3%, cell accuracy: 99.6%, board accuracy: 63.9% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3887, G loss: 0.6637\n",
      "[84/1762] D loss: 1.3204, G loss: 0.7575\n",
      "[164/1762] D loss: 1.4293, G loss: 0.7231\n",
      "[244/1762] D loss: 1.4063, G loss: 0.7388\n",
      "[324/1762] D loss: 1.3399, G loss: 0.6952\n",
      "[404/1762] D loss: 1.3544, G loss: 0.7354\n",
      "[484/1762] D loss: 1.3230, G loss: 0.7789\n",
      "[564/1762] D loss: 1.3810, G loss: 0.6880\n",
      "[644/1762] D loss: 1.3956, G loss: 0.7066\n",
      "[724/1762] D loss: 1.4120, G loss: 0.7038\n",
      "[804/1762] D loss: 1.4308, G loss: 0.6594\n",
      "[884/1762] D loss: 1.4469, G loss: 0.5870\n",
      "[964/1762] D loss: 1.4372, G loss: 0.6212\n",
      "[1044/1762] D loss: 1.4710, G loss: 0.6305\n",
      "[1124/1762] D loss: 1.4039, G loss: 0.7802\n",
      "[1204/1762] D loss: 1.3888, G loss: 0.6291\n",
      "[1284/1762] D loss: 1.4148, G loss: 0.7488\n",
      "[1364/1762] D loss: 1.3880, G loss: 0.7237\n",
      "[1444/1762] D loss: 1.4633, G loss: 0.6066\n",
      "[1524/1762] D loss: 1.2158, G loss: 0.9926\n",
      "[1604/1762] D loss: 1.3915, G loss: 0.7627\n",
      "[1684/1762] D loss: 1.3945, G loss: 0.7948\n",
      "[1762/1762] D loss: 1.4248, G loss: 0.6188\n",
      "train error: \n",
      " D loss: 1.378386, G loss: 0.645496, D accuracy: 54.2%, cell accuracy: 99.7%, board accuracy: 65.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.375789, G loss: 0.658874, D accuracy: 55.2%, cell accuracy: 99.6%, board accuracy: 64.1% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3843, G loss: 0.7068\n",
      "[84/1762] D loss: 1.3996, G loss: 0.6657\n",
      "[164/1762] D loss: 1.3847, G loss: 0.6117\n",
      "[244/1762] D loss: 1.4108, G loss: 0.8220\n",
      "[324/1762] D loss: 1.3206, G loss: 0.7957\n",
      "[404/1762] D loss: 1.3362, G loss: 0.8862\n",
      "[484/1762] D loss: 1.4076, G loss: 0.6560\n",
      "[564/1762] D loss: 1.3297, G loss: 0.6573\n",
      "[644/1762] D loss: 1.4063, G loss: 0.6867\n",
      "[724/1762] D loss: 1.3382, G loss: 0.6389\n",
      "[804/1762] D loss: 1.3984, G loss: 0.6043\n",
      "[884/1762] D loss: 1.3977, G loss: 0.6241\n",
      "[964/1762] D loss: 1.4029, G loss: 0.6671\n",
      "[1044/1762] D loss: 1.3715, G loss: 0.6266\n",
      "[1124/1762] D loss: 1.4394, G loss: 0.8609\n",
      "[1204/1762] D loss: 1.2857, G loss: 0.8016\n",
      "[1284/1762] D loss: 1.4411, G loss: 0.7146\n",
      "[1364/1762] D loss: 1.3430, G loss: 0.7663\n",
      "[1444/1762] D loss: 1.2988, G loss: 0.9252\n",
      "[1524/1762] D loss: 1.3217, G loss: 0.7923\n",
      "[1604/1762] D loss: 1.4053, G loss: 0.5564\n",
      "[1684/1762] D loss: 1.3967, G loss: 0.7358\n",
      "[1762/1762] D loss: 1.3876, G loss: 0.7768\n",
      "train error: \n",
      " D loss: 1.383099, G loss: 0.806291, D accuracy: 50.9%, cell accuracy: 99.7%, board accuracy: 67.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.381596, G loss: 0.821341, D accuracy: 50.8%, cell accuracy: 99.7%, board accuracy: 65.7% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3971, G loss: 0.7946\n",
      "[84/1762] D loss: 1.3943, G loss: 0.7184\n",
      "[164/1762] D loss: 1.3564, G loss: 0.8372\n",
      "[244/1762] D loss: 1.4140, G loss: 0.8105\n",
      "[324/1762] D loss: 1.4156, G loss: 0.7534\n",
      "[404/1762] D loss: 1.3950, G loss: 0.7142\n",
      "[484/1762] D loss: 1.3913, G loss: 0.6806\n",
      "[564/1762] D loss: 1.3876, G loss: 0.7986\n",
      "[644/1762] D loss: 1.4188, G loss: 0.8513\n",
      "[724/1762] D loss: 1.4171, G loss: 0.6948\n",
      "[804/1762] D loss: 1.4102, G loss: 0.8035\n",
      "[884/1762] D loss: 1.3270, G loss: 0.7606\n",
      "[964/1762] D loss: 1.4570, G loss: 0.5475\n",
      "[1044/1762] D loss: 1.3324, G loss: 0.7020\n",
      "[1124/1762] D loss: 1.4055, G loss: 0.8443\n",
      "[1204/1762] D loss: 1.1197, G loss: 0.9529\n",
      "[1284/1762] D loss: 1.4015, G loss: 0.6338\n",
      "[1364/1762] D loss: 1.3053, G loss: 0.7981\n",
      "[1444/1762] D loss: 1.4022, G loss: 0.5905\n",
      "[1524/1762] D loss: 1.4051, G loss: 0.7440\n",
      "[1604/1762] D loss: 1.4507, G loss: 0.5396\n",
      "[1684/1762] D loss: 1.3193, G loss: 0.7660\n",
      "[1762/1762] D loss: 1.3916, G loss: 0.6206\n",
      "train error: \n",
      " D loss: 1.367859, G loss: 0.696872, D accuracy: 54.2%, cell accuracy: 99.7%, board accuracy: 65.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.364149, G loss: 0.710316, D accuracy: 55.1%, cell accuracy: 99.6%, board accuracy: 63.4% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4255, G loss: 0.6207\n",
      "[84/1762] D loss: 1.3922, G loss: 0.7074\n",
      "[164/1762] D loss: 1.4149, G loss: 0.8828\n",
      "[244/1762] D loss: 1.3740, G loss: 0.8438\n",
      "[324/1762] D loss: 1.3395, G loss: 0.7233\n",
      "[404/1762] D loss: 1.3992, G loss: 0.6275\n",
      "[484/1762] D loss: 1.3657, G loss: 0.6992\n",
      "[564/1762] D loss: 1.3460, G loss: 0.5769\n",
      "[644/1762] D loss: 1.4083, G loss: 0.5777\n",
      "[724/1762] D loss: 1.4109, G loss: 0.5820\n",
      "[804/1762] D loss: 1.3396, G loss: 0.7043\n",
      "[884/1762] D loss: 1.2786, G loss: 0.9092\n",
      "[964/1762] D loss: 1.4003, G loss: 0.6850\n",
      "[1044/1762] D loss: 1.4397, G loss: 0.9218\n",
      "[1124/1762] D loss: 1.3900, G loss: 0.6645\n",
      "[1204/1762] D loss: 1.3690, G loss: 0.8160\n",
      "[1284/1762] D loss: 1.3900, G loss: 0.7399\n",
      "[1364/1762] D loss: 1.3766, G loss: 0.6782\n",
      "[1444/1762] D loss: 1.3901, G loss: 0.7728\n",
      "[1524/1762] D loss: 1.3906, G loss: 0.7274\n",
      "[1604/1762] D loss: 1.3147, G loss: 0.7223\n",
      "[1684/1762] D loss: 1.4391, G loss: 0.6526\n",
      "[1762/1762] D loss: 1.3151, G loss: 0.9013\n",
      "train error: \n",
      " D loss: 1.368631, G loss: 0.675726, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 73.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.363644, G loss: 0.688382, D accuracy: 56.1%, cell accuracy: 99.7%, board accuracy: 66.8% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4003, G loss: 0.6496\n",
      "[84/1762] D loss: 1.3954, G loss: 0.6468\n",
      "[164/1762] D loss: 1.3822, G loss: 0.7051\n",
      "[244/1762] D loss: 1.3969, G loss: 0.6543\n",
      "[324/1762] D loss: 1.3664, G loss: 0.8807\n",
      "[404/1762] D loss: 1.4100, G loss: 0.6597\n",
      "[484/1762] D loss: 1.3891, G loss: 0.7512\n",
      "[564/1762] D loss: 1.3010, G loss: 0.8103\n",
      "[644/1762] D loss: 1.3975, G loss: 0.7620\n",
      "[724/1762] D loss: 1.2602, G loss: 0.9742\n",
      "[804/1762] D loss: 1.3920, G loss: 0.7228\n",
      "[884/1762] D loss: 1.3753, G loss: 0.7715\n",
      "[964/1762] D loss: 1.4196, G loss: 0.7212\n",
      "[1044/1762] D loss: 1.3720, G loss: 0.7195\n",
      "[1124/1762] D loss: 1.3926, G loss: 0.7273\n",
      "[1204/1762] D loss: 1.3101, G loss: 0.9573\n",
      "[1284/1762] D loss: 1.4185, G loss: 0.8464\n",
      "[1364/1762] D loss: 1.3553, G loss: 0.7615\n",
      "[1444/1762] D loss: 1.3329, G loss: 0.6972\n",
      "[1524/1762] D loss: 1.2992, G loss: 0.7145\n",
      "[1604/1762] D loss: 1.4155, G loss: 0.7215\n",
      "[1684/1762] D loss: 1.3915, G loss: 0.6860\n",
      "[1762/1762] D loss: 1.3880, G loss: 0.6637\n",
      "train error: \n",
      " D loss: 1.371908, G loss: 0.700187, D accuracy: 53.1%, cell accuracy: 99.8%, board accuracy: 76.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.367290, G loss: 0.709646, D accuracy: 54.4%, cell accuracy: 99.7%, board accuracy: 73.4% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3890, G loss: 0.7384\n",
      "[84/1762] D loss: 1.3703, G loss: 0.6661\n",
      "[164/1762] D loss: 1.4096, G loss: 0.6787\n",
      "[244/1762] D loss: 1.3297, G loss: 0.8884\n",
      "[324/1762] D loss: 1.3868, G loss: 0.6277\n",
      "[404/1762] D loss: 1.4209, G loss: 0.5939\n",
      "[484/1762] D loss: 1.3273, G loss: 0.7616\n",
      "[564/1762] D loss: 1.3813, G loss: 0.6096\n",
      "[644/1762] D loss: 1.4011, G loss: 0.6649\n",
      "[724/1762] D loss: 1.2833, G loss: 0.9752\n",
      "[804/1762] D loss: 1.4233, G loss: 0.6225\n",
      "[884/1762] D loss: 1.4127, G loss: 0.6829\n",
      "[964/1762] D loss: 1.3376, G loss: 0.6109\n",
      "[1044/1762] D loss: 1.4090, G loss: 0.6404\n",
      "[1124/1762] D loss: 1.3954, G loss: 0.7338\n",
      "[1204/1762] D loss: 1.2335, G loss: 0.6961\n",
      "[1284/1762] D loss: 1.3922, G loss: 0.6270\n",
      "[1364/1762] D loss: 1.3091, G loss: 0.7418\n",
      "[1444/1762] D loss: 1.4086, G loss: 0.7550\n",
      "[1524/1762] D loss: 1.4217, G loss: 0.6929\n",
      "[1604/1762] D loss: 1.4890, G loss: 0.6700\n",
      "[1684/1762] D loss: 1.3787, G loss: 0.6578\n",
      "[1762/1762] D loss: 1.4175, G loss: 0.6688\n",
      "train error: \n",
      " D loss: 1.375562, G loss: 0.654356, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 74.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.369429, G loss: 0.665136, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 72.7% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4016, G loss: 0.6424\n",
      "[84/1762] D loss: 1.3957, G loss: 0.6580\n",
      "[164/1762] D loss: 1.4150, G loss: 0.6192\n",
      "[244/1762] D loss: 1.4117, G loss: 0.6007\n",
      "[324/1762] D loss: 1.4268, G loss: 0.7138\n",
      "[404/1762] D loss: 1.3960, G loss: 0.6569\n",
      "[484/1762] D loss: 1.4055, G loss: 0.6765\n",
      "[564/1762] D loss: 1.3171, G loss: 0.8040\n",
      "[644/1762] D loss: 1.4325, G loss: 0.7890\n",
      "[724/1762] D loss: 1.3845, G loss: 0.7158\n",
      "[804/1762] D loss: 1.3757, G loss: 0.6288\n",
      "[884/1762] D loss: 1.4092, G loss: 0.6119\n",
      "[964/1762] D loss: 1.4486, G loss: 0.5481\n",
      "[1044/1762] D loss: 1.3038, G loss: 0.7767\n",
      "[1124/1762] D loss: 1.3883, G loss: 0.5782\n",
      "[1204/1762] D loss: 1.3685, G loss: 0.6421\n",
      "[1284/1762] D loss: 1.3943, G loss: 0.6191\n",
      "[1364/1762] D loss: 1.3876, G loss: 0.6797\n",
      "[1444/1762] D loss: 1.1697, G loss: 0.7933\n",
      "[1524/1762] D loss: 1.3857, G loss: 0.5890\n",
      "[1604/1762] D loss: 1.3903, G loss: 0.7326\n",
      "[1684/1762] D loss: 1.4569, G loss: 0.6698\n",
      "[1762/1762] D loss: 1.0961, G loss: 0.9963\n",
      "train error: \n",
      " D loss: 1.370403, G loss: 0.709365, D accuracy: 53.2%, cell accuracy: 99.7%, board accuracy: 73.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.364613, G loss: 0.719144, D accuracy: 53.8%, cell accuracy: 99.7%, board accuracy: 71.6% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3064, G loss: 0.6815\n",
      "[84/1762] D loss: 1.2941, G loss: 0.6489\n",
      "[164/1762] D loss: 1.3781, G loss: 0.8305\n",
      "[244/1762] D loss: 1.4053, G loss: 0.8171\n",
      "[324/1762] D loss: 1.4157, G loss: 0.8180\n",
      "[404/1762] D loss: 1.3985, G loss: 0.6856\n",
      "[484/1762] D loss: 1.4135, G loss: 0.5974\n",
      "[564/1762] D loss: 1.3216, G loss: 0.6828\n",
      "[644/1762] D loss: 1.3902, G loss: 0.6746\n",
      "[724/1762] D loss: 1.3009, G loss: 0.7229\n",
      "[804/1762] D loss: 1.4030, G loss: 0.7916\n",
      "[884/1762] D loss: 1.3932, G loss: 0.6130\n",
      "[964/1762] D loss: 1.4449, G loss: 0.6407\n",
      "[1044/1762] D loss: 1.2972, G loss: 0.7471\n",
      "[1124/1762] D loss: 1.3884, G loss: 0.7143\n",
      "[1204/1762] D loss: 1.4022, G loss: 0.7284\n",
      "[1284/1762] D loss: 1.3857, G loss: 0.7256\n",
      "[1364/1762] D loss: 1.2963, G loss: 0.8714\n",
      "[1444/1762] D loss: 1.3958, G loss: 0.6958\n",
      "[1524/1762] D loss: 1.2994, G loss: 0.6972\n",
      "[1604/1762] D loss: 1.3784, G loss: 0.6658\n",
      "[1684/1762] D loss: 1.3937, G loss: 0.6659\n",
      "[1762/1762] D loss: 1.4784, G loss: 0.5301\n",
      "train error: \n",
      " D loss: 1.369957, G loss: 0.692991, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 80.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.363538, G loss: 0.701280, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 77.5% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3550, G loss: 0.7197\n",
      "[84/1762] D loss: 1.3966, G loss: 0.7253\n",
      "[164/1762] D loss: 1.4088, G loss: 0.6464\n",
      "[244/1762] D loss: 1.3982, G loss: 0.6698\n",
      "[324/1762] D loss: 1.3888, G loss: 0.7037\n",
      "[404/1762] D loss: 1.3960, G loss: 0.6868\n",
      "[484/1762] D loss: 1.3886, G loss: 0.7127\n",
      "[564/1762] D loss: 1.3225, G loss: 0.7606\n",
      "[644/1762] D loss: 1.4070, G loss: 0.7637\n",
      "[724/1762] D loss: 1.3802, G loss: 0.7423\n",
      "[804/1762] D loss: 1.3953, G loss: 0.7505\n",
      "[884/1762] D loss: 1.3880, G loss: 0.7380\n",
      "[964/1762] D loss: 1.4113, G loss: 0.6647\n",
      "[1044/1762] D loss: 1.2919, G loss: 0.7566\n",
      "[1124/1762] D loss: 1.4174, G loss: 0.7252\n",
      "[1204/1762] D loss: 1.3886, G loss: 0.7715\n",
      "[1284/1762] D loss: 1.3987, G loss: 0.7797\n",
      "[1364/1762] D loss: 1.3881, G loss: 0.6784\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.6360\n",
      "[1524/1762] D loss: 1.3720, G loss: 0.7322\n",
      "[1604/1762] D loss: 1.2973, G loss: 0.7690\n",
      "[1684/1762] D loss: 1.3416, G loss: 1.0139\n",
      "[1762/1762] D loss: 1.4306, G loss: 0.8487\n",
      "train error: \n",
      " D loss: 1.366811, G loss: 0.793209, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 75.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.357804, G loss: 0.808243, D accuracy: 54.4%, cell accuracy: 99.7%, board accuracy: 72.3% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4108, G loss: 0.6287\n",
      "[84/1762] D loss: 1.3892, G loss: 0.6396\n",
      "[164/1762] D loss: 1.3945, G loss: 0.7281\n",
      "[244/1762] D loss: 1.3893, G loss: 0.7139\n",
      "[324/1762] D loss: 1.3643, G loss: 0.8193\n",
      "[404/1762] D loss: 1.3911, G loss: 0.6900\n",
      "[484/1762] D loss: 1.3904, G loss: 0.6756\n",
      "[564/1762] D loss: 1.2752, G loss: 0.7485\n",
      "[644/1762] D loss: 1.2697, G loss: 0.6688\n",
      "[724/1762] D loss: 1.3959, G loss: 0.6077\n",
      "[804/1762] D loss: 1.4072, G loss: 0.7250\n",
      "[884/1762] D loss: 1.4372, G loss: 0.6969\n",
      "[964/1762] D loss: 1.3997, G loss: 0.7061\n",
      "[1044/1762] D loss: 1.3929, G loss: 0.7354\n",
      "[1124/1762] D loss: 1.4398, G loss: 0.9581\n",
      "[1204/1762] D loss: 1.4067, G loss: 0.8584\n",
      "[1284/1762] D loss: 1.3951, G loss: 0.7968\n",
      "[1364/1762] D loss: 1.3882, G loss: 0.6647\n",
      "[1444/1762] D loss: 1.3638, G loss: 0.6646\n",
      "[1524/1762] D loss: 1.4264, G loss: 0.4930\n",
      "[1604/1762] D loss: 1.3838, G loss: 0.6410\n",
      "[1684/1762] D loss: 1.4005, G loss: 0.7078\n",
      "[1762/1762] D loss: 1.3908, G loss: 0.5973\n",
      "train error: \n",
      " D loss: 1.358598, G loss: 0.718074, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 81.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.350392, G loss: 0.729986, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 78.0% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3998, G loss: 0.5979\n",
      "[84/1762] D loss: 1.2784, G loss: 0.7184\n",
      "[164/1762] D loss: 1.4046, G loss: 0.6326\n",
      "[244/1762] D loss: 1.3858, G loss: 0.7484\n",
      "[324/1762] D loss: 1.3969, G loss: 0.8513\n",
      "[404/1762] D loss: 1.3972, G loss: 0.7353\n",
      "[484/1762] D loss: 1.3990, G loss: 0.6439\n",
      "[564/1762] D loss: 1.4076, G loss: 0.7031\n",
      "[644/1762] D loss: 1.4008, G loss: 0.6725\n",
      "[724/1762] D loss: 1.4023, G loss: 0.6963\n",
      "[804/1762] D loss: 1.3935, G loss: 0.6964\n",
      "[884/1762] D loss: 1.4052, G loss: 0.6839\n",
      "[964/1762] D loss: 1.2724, G loss: 0.7774\n",
      "[1044/1762] D loss: 1.3987, G loss: 0.7396\n",
      "[1124/1762] D loss: 1.4050, G loss: 0.6349\n",
      "[1204/1762] D loss: 1.3987, G loss: 0.7639\n",
      "[1284/1762] D loss: 1.4409, G loss: 0.6130\n",
      "[1364/1762] D loss: 1.4037, G loss: 0.5678\n",
      "[1444/1762] D loss: 1.2162, G loss: 0.8261\n",
      "[1524/1762] D loss: 1.2978, G loss: 0.6069\n",
      "[1604/1762] D loss: 1.2712, G loss: 0.7554\n",
      "[1684/1762] D loss: 1.4105, G loss: 0.8045\n",
      "[1762/1762] D loss: 1.3850, G loss: 0.6338\n",
      "train error: \n",
      " D loss: 1.361630, G loss: 0.696950, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 80.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.352772, G loss: 0.706293, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 78.4% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1363, G loss: 0.8368\n",
      "[84/1762] D loss: 1.3729, G loss: 0.7926\n",
      "[164/1762] D loss: 1.3962, G loss: 0.8885\n",
      "[244/1762] D loss: 1.4011, G loss: 0.6508\n",
      "[324/1762] D loss: 1.4030, G loss: 0.7227\n",
      "[404/1762] D loss: 1.4133, G loss: 0.6490\n",
      "[484/1762] D loss: 1.3905, G loss: 0.7338\n",
      "[564/1762] D loss: 1.4094, G loss: 0.6355\n",
      "[644/1762] D loss: 1.3926, G loss: 0.6899\n",
      "[724/1762] D loss: 1.3912, G loss: 0.6763\n",
      "[804/1762] D loss: 1.4081, G loss: 0.7946\n",
      "[884/1762] D loss: 1.3960, G loss: 0.7186\n",
      "[964/1762] D loss: 1.1573, G loss: 0.9110\n",
      "[1044/1762] D loss: 1.2691, G loss: 0.7214\n",
      "[1124/1762] D loss: 1.3260, G loss: 0.7847\n",
      "[1204/1762] D loss: 1.4007, G loss: 0.6075\n",
      "[1284/1762] D loss: 1.2716, G loss: 0.7053\n",
      "[1364/1762] D loss: 1.2793, G loss: 0.8359\n",
      "[1444/1762] D loss: 1.3938, G loss: 0.7152\n",
      "[1524/1762] D loss: 1.3896, G loss: 0.6680\n",
      "[1604/1762] D loss: 1.4011, G loss: 0.6275\n",
      "[1684/1762] D loss: 1.3979, G loss: 0.5872\n",
      "[1762/1762] D loss: 1.2552, G loss: 0.9482\n",
      "train error: \n",
      " D loss: 1.359486, G loss: 0.779364, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 81.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.350582, G loss: 0.792609, D accuracy: 53.3%, cell accuracy: 99.7%, board accuracy: 78.6% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3957, G loss: 0.7469\n",
      "[84/1762] D loss: 1.3979, G loss: 0.6896\n",
      "[164/1762] D loss: 1.4139, G loss: 0.6748\n",
      "[244/1762] D loss: 1.3295, G loss: 0.8659\n",
      "[324/1762] D loss: 1.4041, G loss: 0.6339\n",
      "[404/1762] D loss: 1.4097, G loss: 0.7605\n",
      "[484/1762] D loss: 1.3936, G loss: 0.6851\n",
      "[564/1762] D loss: 1.3894, G loss: 0.6886\n",
      "[644/1762] D loss: 1.4181, G loss: 0.7251\n",
      "[724/1762] D loss: 1.3036, G loss: 0.7581\n",
      "[804/1762] D loss: 1.3904, G loss: 0.6804\n",
      "[884/1762] D loss: 1.2747, G loss: 0.8210\n",
      "[964/1762] D loss: 1.4173, G loss: 0.6492\n",
      "[1044/1762] D loss: 1.3990, G loss: 0.6974\n",
      "[1124/1762] D loss: 1.3901, G loss: 0.7165\n",
      "[1204/1762] D loss: 1.3426, G loss: 0.6181\n",
      "[1284/1762] D loss: 1.2609, G loss: 0.8589\n",
      "[1364/1762] D loss: 1.3993, G loss: 0.8474\n",
      "[1444/1762] D loss: 1.3982, G loss: 0.7715\n",
      "[1524/1762] D loss: 1.3939, G loss: 0.7612\n",
      "[1604/1762] D loss: 1.4148, G loss: 0.5746\n",
      "[1684/1762] D loss: 1.3755, G loss: 0.6944\n",
      "[1762/1762] D loss: 1.4081, G loss: 0.7244\n",
      "train error: \n",
      " D loss: 1.358451, G loss: 0.756922, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 79.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.345376, G loss: 0.774642, D accuracy: 54.0%, cell accuracy: 99.7%, board accuracy: 74.3% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2545, G loss: 0.8006\n",
      "[84/1762] D loss: 1.2831, G loss: 0.7714\n",
      "[164/1762] D loss: 1.2893, G loss: 0.6234\n",
      "[244/1762] D loss: 1.3929, G loss: 0.6278\n",
      "[324/1762] D loss: 1.3921, G loss: 0.6995\n",
      "[404/1762] D loss: 1.4183, G loss: 0.7476\n",
      "[484/1762] D loss: 1.1407, G loss: 0.8905\n",
      "[564/1762] D loss: 1.3871, G loss: 0.6828\n",
      "[644/1762] D loss: 1.2477, G loss: 0.7621\n",
      "[724/1762] D loss: 1.2855, G loss: 0.7560\n",
      "[804/1762] D loss: 1.3981, G loss: 0.6364\n",
      "[884/1762] D loss: 1.4474, G loss: 0.6471\n",
      "[964/1762] D loss: 1.2799, G loss: 0.7439\n",
      "[1044/1762] D loss: 1.4001, G loss: 0.7725\n",
      "[1124/1762] D loss: 1.3987, G loss: 0.7553\n",
      "[1204/1762] D loss: 1.3178, G loss: 0.8441\n",
      "[1284/1762] D loss: 1.4160, G loss: 0.5765\n",
      "[1364/1762] D loss: 1.3933, G loss: 0.6929\n",
      "[1444/1762] D loss: 1.3912, G loss: 0.6036\n",
      "[1524/1762] D loss: 1.3990, G loss: 0.7185\n",
      "[1604/1762] D loss: 1.4103, G loss: 0.6150\n",
      "[1684/1762] D loss: 1.4231, G loss: 0.7054\n",
      "[1762/1762] D loss: 1.4056, G loss: 0.7181\n",
      "train error: \n",
      " D loss: 1.359819, G loss: 0.759902, D accuracy: 52.3%, cell accuracy: 99.8%, board accuracy: 78.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.346187, G loss: 0.776586, D accuracy: 53.9%, cell accuracy: 99.7%, board accuracy: 77.3% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2368, G loss: 0.7497\n",
      "[84/1762] D loss: 1.2315, G loss: 0.7739\n",
      "[164/1762] D loss: 1.3601, G loss: 0.7023\n",
      "[244/1762] D loss: 1.2470, G loss: 0.7373\n",
      "[324/1762] D loss: 1.3913, G loss: 0.6633\n",
      "[404/1762] D loss: 1.3870, G loss: 0.7446\n",
      "[484/1762] D loss: 1.3913, G loss: 0.6434\n",
      "[564/1762] D loss: 1.2986, G loss: 0.8001\n",
      "[644/1762] D loss: 1.4095, G loss: 0.6483\n",
      "[724/1762] D loss: 1.3896, G loss: 0.7642\n",
      "[804/1762] D loss: 1.4055, G loss: 0.6742\n",
      "[884/1762] D loss: 1.4022, G loss: 0.7849\n",
      "[964/1762] D loss: 1.3913, G loss: 0.7084\n",
      "[1044/1762] D loss: 1.3897, G loss: 0.7896\n",
      "[1124/1762] D loss: 1.3680, G loss: 0.7782\n",
      "[1204/1762] D loss: 1.3054, G loss: 0.8034\n",
      "[1284/1762] D loss: 1.1949, G loss: 0.9304\n",
      "[1364/1762] D loss: 1.3860, G loss: 0.6610\n",
      "[1444/1762] D loss: 1.4023, G loss: 0.6352\n",
      "[1524/1762] D loss: 1.4067, G loss: 0.7798\n",
      "[1604/1762] D loss: 1.4431, G loss: 0.6133\n",
      "[1684/1762] D loss: 1.3987, G loss: 0.7143\n",
      "[1762/1762] D loss: 1.0918, G loss: 0.9106\n",
      "train error: \n",
      " D loss: 1.367455, G loss: 0.841561, D accuracy: 52.4%, cell accuracy: 99.8%, board accuracy: 78.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.356335, G loss: 0.858566, D accuracy: 53.3%, cell accuracy: 99.7%, board accuracy: 78.6% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4223, G loss: 0.7939\n",
      "[84/1762] D loss: 1.2369, G loss: 0.7697\n",
      "[164/1762] D loss: 1.2450, G loss: 0.7317\n",
      "[244/1762] D loss: 1.2341, G loss: 0.8443\n",
      "[324/1762] D loss: 1.3929, G loss: 0.6409\n",
      "[404/1762] D loss: 1.3235, G loss: 0.8603\n",
      "[484/1762] D loss: 1.4491, G loss: 0.5923\n",
      "[564/1762] D loss: 1.4089, G loss: 0.7795\n",
      "[644/1762] D loss: 1.3939, G loss: 0.8468\n",
      "[724/1762] D loss: 1.4019, G loss: 0.7266\n",
      "[804/1762] D loss: 1.4108, G loss: 0.7952\n",
      "[884/1762] D loss: 1.3959, G loss: 0.7726\n",
      "[964/1762] D loss: 1.3993, G loss: 0.6349\n",
      "[1044/1762] D loss: 1.3260, G loss: 0.7583\n",
      "[1124/1762] D loss: 1.2725, G loss: 0.7750\n",
      "[1204/1762] D loss: 1.2532, G loss: 0.8280\n",
      "[1284/1762] D loss: 1.3650, G loss: 0.7926\n",
      "[1364/1762] D loss: 1.3988, G loss: 0.8665\n",
      "[1444/1762] D loss: 1.4069, G loss: 0.7361\n",
      "[1524/1762] D loss: 1.2445, G loss: 0.7490\n",
      "[1604/1762] D loss: 1.5049, G loss: 0.5859\n",
      "[1684/1762] D loss: 1.4208, G loss: 0.7105\n",
      "[1762/1762] D loss: 1.1816, G loss: 0.9983\n",
      "train error: \n",
      " D loss: 1.355403, G loss: 0.756291, D accuracy: 52.6%, cell accuracy: 99.8%, board accuracy: 76.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.342383, G loss: 0.770261, D accuracy: 53.2%, cell accuracy: 99.7%, board accuracy: 76.1% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2454, G loss: 0.7618\n",
      "[84/1762] D loss: 1.3962, G loss: 0.6255\n",
      "[164/1762] D loss: 1.4056, G loss: 0.6047\n",
      "[244/1762] D loss: 1.2210, G loss: 0.7236\n",
      "[324/1762] D loss: 1.3916, G loss: 0.6408\n",
      "[404/1762] D loss: 1.4212, G loss: 0.5676\n",
      "[484/1762] D loss: 1.3930, G loss: 0.7291\n",
      "[564/1762] D loss: 1.4278, G loss: 0.8146\n",
      "[644/1762] D loss: 1.4335, G loss: 0.8185\n",
      "[724/1762] D loss: 1.3945, G loss: 0.8070\n",
      "[804/1762] D loss: 1.4019, G loss: 0.7441\n",
      "[884/1762] D loss: 1.0636, G loss: 1.0071\n",
      "[964/1762] D loss: 1.4022, G loss: 0.5985\n",
      "[1044/1762] D loss: 1.3966, G loss: 0.7304\n",
      "[1124/1762] D loss: 1.1365, G loss: 0.8573\n",
      "[1204/1762] D loss: 1.4001, G loss: 0.6821\n",
      "[1284/1762] D loss: 1.3953, G loss: 0.6662\n",
      "[1364/1762] D loss: 1.4554, G loss: 0.6022\n",
      "[1444/1762] D loss: 1.3681, G loss: 0.6417\n",
      "[1524/1762] D loss: 1.3840, G loss: 0.6844\n",
      "[1604/1762] D loss: 1.4041, G loss: 0.6868\n",
      "[1684/1762] D loss: 1.4280, G loss: 0.6172\n",
      "[1762/1762] D loss: 1.3957, G loss: 0.7609\n",
      "train error: \n",
      " D loss: 1.365681, G loss: 0.795944, D accuracy: 51.8%, cell accuracy: 99.7%, board accuracy: 66.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.350752, G loss: 0.812822, D accuracy: 53.6%, cell accuracy: 99.7%, board accuracy: 66.4% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4277, G loss: 0.7688\n",
      "[84/1762] D loss: 1.2770, G loss: 0.8251\n",
      "[164/1762] D loss: 1.3797, G loss: 0.6918\n",
      "[244/1762] D loss: 1.4307, G loss: 0.6469\n",
      "[324/1762] D loss: 1.3982, G loss: 0.6551\n",
      "[404/1762] D loss: 1.4471, G loss: 0.5552\n",
      "[484/1762] D loss: 1.4029, G loss: 0.7767\n",
      "[564/1762] D loss: 1.2128, G loss: 0.9751\n",
      "[644/1762] D loss: 1.3829, G loss: 0.6554\n",
      "[724/1762] D loss: 1.4512, G loss: 0.6683\n",
      "[804/1762] D loss: 1.2780, G loss: 0.7588\n",
      "[884/1762] D loss: 1.4262, G loss: 0.6905\n",
      "[964/1762] D loss: 1.3760, G loss: 0.7884\n",
      "[1044/1762] D loss: 1.3187, G loss: 0.8658\n",
      "[1124/1762] D loss: 1.3877, G loss: 0.6724\n",
      "[1204/1762] D loss: 1.3913, G loss: 0.6507\n",
      "[1284/1762] D loss: 1.3847, G loss: 0.6567\n",
      "[1364/1762] D loss: 1.4083, G loss: 0.7725\n",
      "[1444/1762] D loss: 1.3525, G loss: 0.7355\n",
      "[1524/1762] D loss: 1.3910, G loss: 0.7268\n",
      "[1604/1762] D loss: 1.2405, G loss: 0.8100\n",
      "[1684/1762] D loss: 1.3974, G loss: 0.7740\n",
      "[1762/1762] D loss: 1.4147, G loss: 0.7256\n",
      "train error: \n",
      " D loss: 1.357249, G loss: 0.882954, D accuracy: 54.6%, cell accuracy: 99.7%, board accuracy: 66.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.347037, G loss: 0.897680, D accuracy: 55.8%, cell accuracy: 99.7%, board accuracy: 68.0% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3617, G loss: 0.8203\n",
      "[84/1762] D loss: 1.2443, G loss: 1.0240\n",
      "[164/1762] D loss: 1.3470, G loss: 0.6519\n",
      "[244/1762] D loss: 1.2432, G loss: 0.7348\n",
      "[324/1762] D loss: 1.4041, G loss: 0.5954\n",
      "[404/1762] D loss: 1.3577, G loss: 0.7083\n",
      "[484/1762] D loss: 1.3546, G loss: 0.6279\n",
      "[564/1762] D loss: 1.2592, G loss: 0.7955\n",
      "[644/1762] D loss: 1.3983, G loss: 0.5753\n",
      "[724/1762] D loss: 1.4730, G loss: 0.7349\n",
      "[804/1762] D loss: 1.1292, G loss: 0.8895\n",
      "[884/1762] D loss: 1.0696, G loss: 0.8386\n",
      "[964/1762] D loss: 1.4108, G loss: 0.8401\n",
      "[1044/1762] D loss: 1.4024, G loss: 0.7562\n",
      "[1124/1762] D loss: 1.4210, G loss: 0.7281\n",
      "[1204/1762] D loss: 1.2582, G loss: 0.7062\n",
      "[1284/1762] D loss: 1.4085, G loss: 0.5915\n",
      "[1364/1762] D loss: 1.3823, G loss: 0.7097\n",
      "[1444/1762] D loss: 1.4004, G loss: 0.7271\n",
      "[1524/1762] D loss: 1.3878, G loss: 0.7466\n",
      "[1604/1762] D loss: 1.4207, G loss: 0.6039\n",
      "[1684/1762] D loss: 1.3083, G loss: 0.6946\n",
      "[1762/1762] D loss: 1.3434, G loss: 0.7482\n",
      "train error: \n",
      " D loss: 1.346086, G loss: 0.741939, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 77.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.333974, G loss: 0.754961, D accuracy: 55.2%, cell accuracy: 99.7%, board accuracy: 78.9% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2715, G loss: 0.8482\n",
      "[84/1762] D loss: 1.3907, G loss: 0.5861\n",
      "[164/1762] D loss: 1.4041, G loss: 0.6669\n",
      "[244/1762] D loss: 1.2216, G loss: 0.8305\n",
      "[324/1762] D loss: 1.3851, G loss: 0.6440\n",
      "[404/1762] D loss: 1.3851, G loss: 0.8020\n",
      "[484/1762] D loss: 1.3844, G loss: 0.7455\n",
      "[564/1762] D loss: 1.4093, G loss: 0.7313\n",
      "[644/1762] D loss: 1.3429, G loss: 0.8556\n",
      "[724/1762] D loss: 1.4458, G loss: 0.8402\n",
      "[804/1762] D loss: 1.3924, G loss: 0.7302\n",
      "[884/1762] D loss: 1.3926, G loss: 0.7525\n",
      "[964/1762] D loss: 1.3911, G loss: 0.6077\n",
      "[1044/1762] D loss: 1.1997, G loss: 0.9389\n",
      "[1124/1762] D loss: 1.3992, G loss: 0.5946\n",
      "[1204/1762] D loss: 1.2196, G loss: 0.8154\n",
      "[1284/1762] D loss: 1.3872, G loss: 0.6573\n",
      "[1364/1762] D loss: 1.4350, G loss: 0.8641\n",
      "[1444/1762] D loss: 1.2605, G loss: 0.7236\n",
      "[1524/1762] D loss: 1.3815, G loss: 0.6918\n",
      "[1604/1762] D loss: 1.4116, G loss: 0.6339\n",
      "[1684/1762] D loss: 1.3813, G loss: 0.7124\n",
      "[1762/1762] D loss: 1.4270, G loss: 0.8191\n",
      "train error: \n",
      " D loss: 1.351265, G loss: 0.707262, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 70.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.341211, G loss: 0.715097, D accuracy: 55.1%, cell accuracy: 99.7%, board accuracy: 69.1% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3949, G loss: 0.6388\n",
      "[84/1762] D loss: 1.3939, G loss: 0.7502\n",
      "[164/1762] D loss: 1.2594, G loss: 0.6789\n",
      "[244/1762] D loss: 1.2391, G loss: 0.7317\n",
      "[324/1762] D loss: 1.4011, G loss: 0.6751\n",
      "[404/1762] D loss: 1.3879, G loss: 0.6902\n",
      "[484/1762] D loss: 1.2835, G loss: 0.8236\n",
      "[564/1762] D loss: 1.2720, G loss: 0.8121\n",
      "[644/1762] D loss: 1.3412, G loss: 0.6568\n",
      "[724/1762] D loss: 1.4437, G loss: 0.8052\n",
      "[804/1762] D loss: 1.2369, G loss: 0.8525\n",
      "[884/1762] D loss: 1.2412, G loss: 0.6233\n",
      "[964/1762] D loss: 1.3765, G loss: 0.6439\n",
      "[1044/1762] D loss: 1.2033, G loss: 0.8373\n",
      "[1124/1762] D loss: 1.3670, G loss: 0.7648\n",
      "[1204/1762] D loss: 1.4012, G loss: 0.6653\n",
      "[1284/1762] D loss: 1.4764, G loss: 0.6063\n",
      "[1364/1762] D loss: 1.6549, G loss: 0.5305\n",
      "[1444/1762] D loss: 1.7503, G loss: 0.7038\n",
      "[1524/1762] D loss: 1.6871, G loss: 0.6764\n",
      "[1604/1762] D loss: 1.6006, G loss: 0.6277\n",
      "[1684/1762] D loss: 1.5767, G loss: 0.4758\n",
      "[1762/1762] D loss: 1.3013, G loss: 0.9191\n",
      "train error: \n",
      " D loss: 1.415348, G loss: 0.587495, D accuracy: 51.9%, cell accuracy: 98.2%, board accuracy: 3.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.410366, G loss: 0.593447, D accuracy: 52.6%, cell accuracy: 98.2%, board accuracy: 5.0% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4212, G loss: 0.4389\n",
      "[84/1762] D loss: 1.4033, G loss: 0.7038\n",
      "[164/1762] D loss: 1.3026, G loss: 0.6506\n",
      "[244/1762] D loss: 1.2547, G loss: 0.8581\n",
      "[324/1762] D loss: 1.3332, G loss: 0.6606\n",
      "[404/1762] D loss: 1.3836, G loss: 0.7282\n",
      "[484/1762] D loss: 1.3910, G loss: 0.6530\n",
      "[564/1762] D loss: 1.3662, G loss: 0.7410\n",
      "[644/1762] D loss: 1.3940, G loss: 0.6989\n",
      "[724/1762] D loss: 1.4045, G loss: 0.7673\n",
      "[804/1762] D loss: 1.4000, G loss: 0.7379\n",
      "[884/1762] D loss: 1.3917, G loss: 0.5663\n",
      "[964/1762] D loss: 1.4328, G loss: 0.6304\n",
      "[1044/1762] D loss: 1.3990, G loss: 0.6800\n",
      "[1124/1762] D loss: 1.3857, G loss: 0.7070\n",
      "[1204/1762] D loss: 1.4132, G loss: 0.7589\n",
      "[1284/1762] D loss: 1.4017, G loss: 0.6293\n",
      "[1364/1762] D loss: 1.4123, G loss: 0.7963\n",
      "[1444/1762] D loss: 1.3062, G loss: 0.7454\n",
      "[1524/1762] D loss: 1.3910, G loss: 0.6644\n",
      "[1604/1762] D loss: 1.3404, G loss: 0.6486\n",
      "[1684/1762] D loss: 1.3825, G loss: 0.7208\n",
      "[1762/1762] D loss: 1.4158, G loss: 0.8095\n",
      "train error: \n",
      " D loss: 1.379738, G loss: 0.737137, D accuracy: 52.0%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.378204, G loss: 0.736969, D accuracy: 52.4%, cell accuracy: 99.8%, board accuracy: 85.0% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3974, G loss: 0.7687\n",
      "[84/1762] D loss: 1.4035, G loss: 0.6728\n",
      "[164/1762] D loss: 1.3432, G loss: 0.7348\n",
      "[244/1762] D loss: 1.3915, G loss: 0.6906\n",
      "[324/1762] D loss: 1.3962, G loss: 0.6262\n",
      "[404/1762] D loss: 1.3916, G loss: 0.7418\n",
      "[484/1762] D loss: 1.4273, G loss: 0.7548\n",
      "[564/1762] D loss: 1.4080, G loss: 0.7865\n",
      "[644/1762] D loss: 1.3467, G loss: 0.6339\n",
      "[724/1762] D loss: 1.4221, G loss: 0.7814\n",
      "[804/1762] D loss: 1.3895, G loss: 0.7263\n",
      "[884/1762] D loss: 1.3891, G loss: 0.7133\n",
      "[964/1762] D loss: 1.3235, G loss: 0.8650\n",
      "[1044/1762] D loss: 1.2910, G loss: 0.7853\n",
      "[1124/1762] D loss: 1.2957, G loss: 0.7376\n",
      "[1204/1762] D loss: 1.3965, G loss: 0.7712\n",
      "[1284/1762] D loss: 1.3951, G loss: 0.7239\n",
      "[1364/1762] D loss: 1.3651, G loss: 0.6664\n",
      "[1444/1762] D loss: 1.3893, G loss: 0.7018\n",
      "[1524/1762] D loss: 1.3973, G loss: 0.6846\n",
      "[1604/1762] D loss: 1.3016, G loss: 0.8305\n",
      "[1684/1762] D loss: 1.3807, G loss: 0.6554\n",
      "[1762/1762] D loss: 1.2050, G loss: 0.8585\n",
      "train error: \n",
      " D loss: 1.368249, G loss: 0.761672, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.363050, G loss: 0.764907, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3124, G loss: 0.7742\n",
      "[84/1762] D loss: 1.3044, G loss: 0.6540\n",
      "[164/1762] D loss: 1.3945, G loss: 0.6130\n",
      "[244/1762] D loss: 1.3982, G loss: 0.6046\n",
      "[324/1762] D loss: 1.3585, G loss: 0.7701\n",
      "[404/1762] D loss: 1.1781, G loss: 0.7504\n",
      "[484/1762] D loss: 1.3935, G loss: 0.7626\n",
      "[564/1762] D loss: 1.3722, G loss: 0.6761\n",
      "[644/1762] D loss: 1.3962, G loss: 0.7802\n",
      "[724/1762] D loss: 1.3992, G loss: 0.6227\n",
      "[804/1762] D loss: 1.3751, G loss: 0.7187\n",
      "[884/1762] D loss: 1.3511, G loss: 0.7325\n",
      "[964/1762] D loss: 1.2750, G loss: 0.7288\n",
      "[1044/1762] D loss: 1.2706, G loss: 0.7067\n",
      "[1124/1762] D loss: 1.4131, G loss: 0.5990\n",
      "[1204/1762] D loss: 1.4098, G loss: 0.6065\n",
      "[1284/1762] D loss: 1.4015, G loss: 0.6213\n",
      "[1364/1762] D loss: 1.3759, G loss: 0.6385\n",
      "[1444/1762] D loss: 1.3908, G loss: 0.6927\n",
      "[1524/1762] D loss: 1.3989, G loss: 0.6545\n",
      "[1604/1762] D loss: 1.4035, G loss: 0.5830\n",
      "[1684/1762] D loss: 1.3988, G loss: 0.6640\n",
      "[1762/1762] D loss: 1.3873, G loss: 0.7101\n",
      "train error: \n",
      " D loss: 1.359368, G loss: 0.749503, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 87.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.351946, G loss: 0.755258, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 84.8% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2593, G loss: 0.7954\n",
      "[84/1762] D loss: 1.3922, G loss: 0.6436\n",
      "[164/1762] D loss: 1.3923, G loss: 0.6588\n",
      "[244/1762] D loss: 1.4228, G loss: 0.5425\n",
      "[324/1762] D loss: 1.2514, G loss: 0.7903\n",
      "[404/1762] D loss: 1.2692, G loss: 0.7327\n",
      "[484/1762] D loss: 1.3964, G loss: 0.6593\n",
      "[564/1762] D loss: 1.2546, G loss: 0.7774\n",
      "[644/1762] D loss: 1.3946, G loss: 0.7818\n",
      "[724/1762] D loss: 1.1094, G loss: 0.9109\n",
      "[804/1762] D loss: 1.4074, G loss: 0.7635\n",
      "[884/1762] D loss: 1.4038, G loss: 0.6152\n",
      "[964/1762] D loss: 1.4200, G loss: 0.5714\n",
      "[1044/1762] D loss: 1.3889, G loss: 0.6792\n",
      "[1124/1762] D loss: 1.3996, G loss: 0.7626\n",
      "[1204/1762] D loss: 1.2593, G loss: 0.7640\n",
      "[1284/1762] D loss: 1.2586, G loss: 0.7665\n",
      "[1364/1762] D loss: 1.3965, G loss: 0.6828\n",
      "[1444/1762] D loss: 1.3903, G loss: 0.7487\n",
      "[1524/1762] D loss: 1.3868, G loss: 0.7424\n",
      "[1604/1762] D loss: 1.2495, G loss: 0.6810\n",
      "[1684/1762] D loss: 1.3988, G loss: 0.7400\n",
      "[1762/1762] D loss: 1.3876, G loss: 0.7498\n",
      "train error: \n",
      " D loss: 1.360774, G loss: 0.815017, D accuracy: 53.0%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.351210, G loss: 0.823348, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3965, G loss: 0.7313\n",
      "[84/1762] D loss: 1.2420, G loss: 0.8126\n",
      "[164/1762] D loss: 1.2419, G loss: 0.8358\n",
      "[244/1762] D loss: 1.3899, G loss: 0.6345\n",
      "[324/1762] D loss: 1.2633, G loss: 0.7770\n",
      "[404/1762] D loss: 1.4084, G loss: 0.6218\n",
      "[484/1762] D loss: 1.3883, G loss: 0.6406\n",
      "[564/1762] D loss: 1.4129, G loss: 0.5940\n",
      "[644/1762] D loss: 1.3681, G loss: 0.6807\n",
      "[724/1762] D loss: 1.4610, G loss: 0.5950\n",
      "[804/1762] D loss: 1.2202, G loss: 0.7524\n",
      "[884/1762] D loss: 1.4169, G loss: 0.7225\n",
      "[964/1762] D loss: 1.3863, G loss: 0.6833\n",
      "[1044/1762] D loss: 1.3881, G loss: 0.7046\n",
      "[1124/1762] D loss: 1.4286, G loss: 0.7541\n",
      "[1204/1762] D loss: 1.3967, G loss: 0.6581\n",
      "[1284/1762] D loss: 1.3904, G loss: 0.6327\n",
      "[1364/1762] D loss: 1.3911, G loss: 0.7116\n",
      "[1444/1762] D loss: 1.3892, G loss: 0.6558\n",
      "[1524/1762] D loss: 1.3964, G loss: 0.6551\n",
      "[1604/1762] D loss: 1.4069, G loss: 0.7375\n",
      "[1684/1762] D loss: 1.3889, G loss: 0.6840\n",
      "[1762/1762] D loss: 1.3932, G loss: 0.7362\n",
      "train error: \n",
      " D loss: 1.350468, G loss: 0.699993, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.338827, G loss: 0.710669, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3884, G loss: 0.6564\n",
      "[84/1762] D loss: 1.4286, G loss: 0.5795\n",
      "[164/1762] D loss: 1.3935, G loss: 0.7611\n",
      "[244/1762] D loss: 1.3706, G loss: 0.7500\n",
      "[324/1762] D loss: 1.2269, G loss: 0.7851\n",
      "[404/1762] D loss: 1.2035, G loss: 0.7724\n",
      "[484/1762] D loss: 1.3896, G loss: 0.7600\n",
      "[564/1762] D loss: 1.3697, G loss: 0.7965\n",
      "[644/1762] D loss: 1.4018, G loss: 0.6051\n",
      "[724/1762] D loss: 1.0440, G loss: 0.8494\n",
      "[804/1762] D loss: 1.4024, G loss: 0.8197\n",
      "[884/1762] D loss: 1.3955, G loss: 0.6264\n",
      "[964/1762] D loss: 1.3899, G loss: 0.6571\n",
      "[1044/1762] D loss: 1.3670, G loss: 0.7295\n",
      "[1124/1762] D loss: 1.2031, G loss: 0.8288\n",
      "[1204/1762] D loss: 1.3973, G loss: 0.6381\n",
      "[1284/1762] D loss: 1.2196, G loss: 0.8382\n",
      "[1364/1762] D loss: 1.3984, G loss: 0.7007\n",
      "[1444/1762] D loss: 1.4037, G loss: 0.8245\n",
      "[1524/1762] D loss: 1.3960, G loss: 0.6788\n",
      "[1604/1762] D loss: 1.3978, G loss: 0.6844\n",
      "[1684/1762] D loss: 1.2144, G loss: 0.7805\n",
      "[1762/1762] D loss: 1.3908, G loss: 0.7176\n",
      "train error: \n",
      " D loss: 1.344518, G loss: 0.740926, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.332208, G loss: 0.754060, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 85.5% \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3915, G loss: 0.6697\n",
      "[84/1762] D loss: 1.3897, G loss: 0.7209\n",
      "[164/1762] D loss: 1.3930, G loss: 0.7550\n",
      "[244/1762] D loss: 1.1959, G loss: 0.8519\n",
      "[324/1762] D loss: 1.4166, G loss: 0.8162\n",
      "[404/1762] D loss: 1.3919, G loss: 0.6986\n",
      "[484/1762] D loss: 1.3986, G loss: 0.7048\n",
      "[564/1762] D loss: 1.1882, G loss: 0.8406\n",
      "[644/1762] D loss: 1.4188, G loss: 0.6826\n",
      "[724/1762] D loss: 1.4311, G loss: 0.5593\n",
      "[804/1762] D loss: 1.3907, G loss: 0.6979\n",
      "[884/1762] D loss: 1.4037, G loss: 0.6399\n",
      "[964/1762] D loss: 1.3879, G loss: 0.6745\n",
      "[1044/1762] D loss: 1.0462, G loss: 0.9488\n",
      "[1124/1762] D loss: 1.2095, G loss: 0.8682\n",
      "[1204/1762] D loss: 1.1905, G loss: 0.8293\n",
      "[1284/1762] D loss: 1.3940, G loss: 0.7121\n",
      "[1364/1762] D loss: 1.4090, G loss: 0.6447\n",
      "[1444/1762] D loss: 1.4528, G loss: 0.6439\n",
      "[1524/1762] D loss: 1.3940, G loss: 0.8004\n",
      "[1604/1762] D loss: 0.9949, G loss: 1.1198\n",
      "[1684/1762] D loss: 1.4318, G loss: 0.6233\n",
      "[1762/1762] D loss: 1.4082, G loss: 0.8733\n",
      "train error: \n",
      " D loss: 1.354476, G loss: 0.862322, D accuracy: 52.7%, cell accuracy: 99.8%, board accuracy: 82.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.337788, G loss: 0.881276, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 79.1% \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4213, G loss: 0.7604\n",
      "[84/1762] D loss: 1.4470, G loss: 0.6007\n",
      "[164/1762] D loss: 1.3615, G loss: 0.6810\n",
      "[244/1762] D loss: 1.2621, G loss: 0.8642\n",
      "[324/1762] D loss: 1.1969, G loss: 0.8065\n",
      "[404/1762] D loss: 1.2163, G loss: 0.6985\n",
      "[484/1762] D loss: 1.2279, G loss: 0.6709\n",
      "[564/1762] D loss: 1.4184, G loss: 0.6659\n",
      "[644/1762] D loss: 1.4009, G loss: 0.6500\n",
      "[724/1762] D loss: 1.3923, G loss: 0.6153\n",
      "[804/1762] D loss: 1.1767, G loss: 0.8752\n",
      "[884/1762] D loss: 1.4612, G loss: 0.5535\n",
      "[964/1762] D loss: 1.4301, G loss: 0.5324\n",
      "[1044/1762] D loss: 1.3927, G loss: 0.7104\n",
      "[1124/1762] D loss: 1.3977, G loss: 0.6533\n",
      "[1204/1762] D loss: 1.4382, G loss: 0.5739\n",
      "[1284/1762] D loss: 1.4123, G loss: 0.6581\n",
      "[1364/1762] D loss: 1.4301, G loss: 0.9206\n",
      "[1444/1762] D loss: 1.4249, G loss: 0.6950\n",
      "[1524/1762] D loss: 1.4530, G loss: 0.6868\n",
      "[1604/1762] D loss: 1.5599, G loss: 0.6905\n",
      "[1684/1762] D loss: 1.4148, G loss: 0.5278\n",
      "[1762/1762] D loss: 1.0698, G loss: 1.0223\n",
      "train error: \n",
      " D loss: 1.344015, G loss: 0.705005, D accuracy: 57.2%, cell accuracy: 99.6%, board accuracy: 48.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.322659, G loss: 0.726720, D accuracy: 58.2%, cell accuracy: 99.6%, board accuracy: 57.0% \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3792, G loss: 0.5880\n",
      "[84/1762] D loss: 1.4722, G loss: 0.6074\n",
      "[164/1762] D loss: 1.4120, G loss: 0.6757\n",
      "[244/1762] D loss: 1.2105, G loss: 0.8150\n",
      "[324/1762] D loss: 1.3887, G loss: 0.6917\n",
      "[404/1762] D loss: 1.2195, G loss: 0.9750\n",
      "[484/1762] D loss: 1.3916, G loss: 0.7729\n",
      "[564/1762] D loss: 1.3893, G loss: 0.7994\n",
      "[644/1762] D loss: 1.3900, G loss: 0.6529\n",
      "[724/1762] D loss: 1.1962, G loss: 0.7267\n",
      "[804/1762] D loss: 1.3919, G loss: 0.7281\n",
      "[884/1762] D loss: 1.3455, G loss: 0.6761\n",
      "[964/1762] D loss: 1.2195, G loss: 0.6927\n",
      "[1044/1762] D loss: 1.4190, G loss: 0.5511\n",
      "[1124/1762] D loss: 1.0403, G loss: 0.7522\n",
      "[1204/1762] D loss: 1.3911, G loss: 0.7645\n",
      "[1284/1762] D loss: 1.3944, G loss: 0.7051\n",
      "[1364/1762] D loss: 1.3922, G loss: 0.7228\n",
      "[1444/1762] D loss: 1.3932, G loss: 0.7061\n",
      "[1524/1762] D loss: 1.2173, G loss: 0.6436\n",
      "[1604/1762] D loss: 1.3991, G loss: 0.7695\n",
      "[1684/1762] D loss: 1.3891, G loss: 0.6861\n",
      "[1762/1762] D loss: 1.1411, G loss: 0.7556\n",
      "train error: \n",
      " D loss: 1.347987, G loss: 0.839906, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 83.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.332222, G loss: 0.856693, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 82.3% \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4060, G loss: 0.8012\n",
      "[84/1762] D loss: 1.1827, G loss: 0.8807\n",
      "[164/1762] D loss: 1.4469, G loss: 0.7104\n",
      "[244/1762] D loss: 1.4100, G loss: 0.6982\n",
      "[324/1762] D loss: 1.1738, G loss: 0.8707\n",
      "[404/1762] D loss: 1.1796, G loss: 0.8904\n",
      "[484/1762] D loss: 1.4108, G loss: 0.6684\n",
      "[564/1762] D loss: 1.2026, G loss: 0.8553\n",
      "[644/1762] D loss: 1.3935, G loss: 0.6639\n",
      "[724/1762] D loss: 1.3932, G loss: 0.6468\n",
      "[804/1762] D loss: 1.0337, G loss: 0.8970\n",
      "[884/1762] D loss: 1.3893, G loss: 0.7027\n",
      "[964/1762] D loss: 1.3906, G loss: 0.7727\n",
      "[1044/1762] D loss: 1.3866, G loss: 0.6868\n",
      "[1124/1762] D loss: 1.3697, G loss: 0.7624\n",
      "[1204/1762] D loss: 1.3810, G loss: 0.7245\n",
      "[1284/1762] D loss: 1.3843, G loss: 0.6767\n",
      "[1364/1762] D loss: 1.3986, G loss: 0.7094\n",
      "[1444/1762] D loss: 1.3878, G loss: 0.7980\n",
      "[1524/1762] D loss: 1.3873, G loss: 0.7494\n",
      "[1604/1762] D loss: 1.3951, G loss: 0.7485\n",
      "[1684/1762] D loss: 1.1599, G loss: 0.8958\n",
      "[1762/1762] D loss: 1.3905, G loss: 0.8091\n",
      "train error: \n",
      " D loss: 1.348310, G loss: 0.868438, D accuracy: 53.1%, cell accuracy: 99.8%, board accuracy: 86.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.330999, G loss: 0.887685, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4013, G loss: 0.8058\n",
      "[84/1762] D loss: 1.3888, G loss: 0.7041\n",
      "[164/1762] D loss: 1.3891, G loss: 0.6992\n",
      "[244/1762] D loss: 1.3897, G loss: 0.6856\n",
      "[324/1762] D loss: 1.3933, G loss: 0.6981\n",
      "[404/1762] D loss: 1.4261, G loss: 0.6671\n",
      "[484/1762] D loss: 1.2223, G loss: 0.9159\n",
      "[564/1762] D loss: 1.3867, G loss: 0.6981\n",
      "[644/1762] D loss: 1.3801, G loss: 0.8775\n",
      "[724/1762] D loss: 1.4001, G loss: 0.6093\n",
      "[804/1762] D loss: 1.3914, G loss: 0.6519\n",
      "[884/1762] D loss: 1.2016, G loss: 1.0117\n",
      "[964/1762] D loss: 1.1913, G loss: 0.8949\n",
      "[1044/1762] D loss: 1.3812, G loss: 0.6663\n",
      "[1124/1762] D loss: 1.3908, G loss: 0.6811\n",
      "[1204/1762] D loss: 1.3830, G loss: 0.6502\n",
      "[1284/1762] D loss: 1.3923, G loss: 0.6676\n",
      "[1364/1762] D loss: 1.3972, G loss: 0.6367\n",
      "[1444/1762] D loss: 1.3990, G loss: 0.7025\n",
      "[1524/1762] D loss: 1.1823, G loss: 0.9037\n",
      "[1604/1762] D loss: 1.2033, G loss: 0.8200\n",
      "[1684/1762] D loss: 1.4004, G loss: 0.7258\n",
      "[1762/1762] D loss: 1.3853, G loss: 0.7542\n",
      "train error: \n",
      " D loss: 1.347618, G loss: 0.806425, D accuracy: 53.0%, cell accuracy: 99.6%, board accuracy: 63.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.326534, G loss: 0.827003, D accuracy: 54.9%, cell accuracy: 99.6%, board accuracy: 63.2% \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1753, G loss: 0.9665\n",
      "[84/1762] D loss: 1.1638, G loss: 0.8397\n",
      "[164/1762] D loss: 1.5435, G loss: 0.8281\n",
      "[244/1762] D loss: 1.4151, G loss: 0.7845\n",
      "[324/1762] D loss: 1.7338, G loss: 1.1939\n",
      "[404/1762] D loss: 1.6284, G loss: 0.5927\n",
      "[484/1762] D loss: 1.4658, G loss: 0.6864\n",
      "[564/1762] D loss: 1.4017, G loss: 0.7036\n",
      "[644/1762] D loss: 1.3280, G loss: 0.7405\n",
      "[724/1762] D loss: 1.4996, G loss: 0.9052\n",
      "[804/1762] D loss: 1.4865, G loss: 1.0162\n",
      "[884/1762] D loss: 1.4338, G loss: 0.7193\n",
      "[964/1762] D loss: 1.4191, G loss: 0.8757\n",
      "[1044/1762] D loss: 1.4649, G loss: 0.5295\n",
      "[1124/1762] D loss: 1.4279, G loss: 0.7955\n",
      "[1204/1762] D loss: 1.3912, G loss: 0.7948\n",
      "[1284/1762] D loss: 1.3770, G loss: 0.6477\n",
      "[1364/1762] D loss: 1.3981, G loss: 0.7683\n",
      "[1444/1762] D loss: 1.3849, G loss: 0.6814\n",
      "[1524/1762] D loss: 1.3994, G loss: 0.7283\n",
      "[1604/1762] D loss: 1.1830, G loss: 0.8341\n",
      "[1684/1762] D loss: 1.4324, G loss: 0.6229\n",
      "[1762/1762] D loss: 1.3983, G loss: 0.7773\n",
      "train error: \n",
      " D loss: 1.362725, G loss: 0.691456, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 88.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.354778, G loss: 0.699257, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 85.5% \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2837, G loss: 0.7173\n",
      "[84/1762] D loss: 1.3937, G loss: 0.7322\n",
      "[164/1762] D loss: 1.3864, G loss: 0.7924\n",
      "[244/1762] D loss: 1.3904, G loss: 0.7451\n",
      "[324/1762] D loss: 1.3896, G loss: 0.6977\n",
      "[404/1762] D loss: 1.2988, G loss: 0.8322\n",
      "[484/1762] D loss: 1.3933, G loss: 0.8197\n",
      "[564/1762] D loss: 1.3989, G loss: 0.7722\n",
      "[644/1762] D loss: 1.3896, G loss: 0.7632\n",
      "[724/1762] D loss: 1.3895, G loss: 0.6855\n",
      "[804/1762] D loss: 1.3889, G loss: 0.6434\n",
      "[884/1762] D loss: 1.3629, G loss: 0.7192\n",
      "[964/1762] D loss: 1.0619, G loss: 0.9659\n",
      "[1044/1762] D loss: 1.3881, G loss: 0.7112\n",
      "[1124/1762] D loss: 1.3896, G loss: 0.7460\n",
      "[1204/1762] D loss: 1.3912, G loss: 0.7053\n",
      "[1284/1762] D loss: 1.3874, G loss: 0.6591\n",
      "[1364/1762] D loss: 1.3909, G loss: 0.7027\n",
      "[1444/1762] D loss: 1.2044, G loss: 0.7740\n",
      "[1524/1762] D loss: 1.3943, G loss: 0.6121\n",
      "[1604/1762] D loss: 1.2443, G loss: 0.7827\n",
      "[1684/1762] D loss: 1.3952, G loss: 0.7240\n",
      "[1762/1762] D loss: 1.3872, G loss: 0.7522\n",
      "train error: \n",
      " D loss: 1.345893, G loss: 0.797860, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 89.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.333419, G loss: 0.809765, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3895, G loss: 0.7772\n",
      "[84/1762] D loss: 1.3931, G loss: 0.7706\n",
      "[164/1762] D loss: 1.4082, G loss: 0.7391\n",
      "[244/1762] D loss: 1.1957, G loss: 0.7649\n",
      "[324/1762] D loss: 1.3880, G loss: 0.6635\n",
      "[404/1762] D loss: 1.3821, G loss: 0.6936\n",
      "[484/1762] D loss: 1.3870, G loss: 0.6970\n",
      "[564/1762] D loss: 1.2540, G loss: 0.6964\n",
      "[644/1762] D loss: 1.3943, G loss: 0.6139\n",
      "[724/1762] D loss: 1.3930, G loss: 0.5847\n",
      "[804/1762] D loss: 1.3915, G loss: 0.7294\n",
      "[884/1762] D loss: 1.3863, G loss: 0.7159\n",
      "[964/1762] D loss: 1.3669, G loss: 0.6819\n",
      "[1044/1762] D loss: 1.3896, G loss: 0.6622\n",
      "[1124/1762] D loss: 1.3985, G loss: 0.7651\n",
      "[1204/1762] D loss: 1.4005, G loss: 0.6824\n",
      "[1284/1762] D loss: 1.3880, G loss: 0.6482\n",
      "[1364/1762] D loss: 1.3867, G loss: 0.6361\n",
      "[1444/1762] D loss: 1.4061, G loss: 0.7621\n",
      "[1524/1762] D loss: 1.3959, G loss: 0.6961\n",
      "[1604/1762] D loss: 1.4073, G loss: 0.7696\n",
      "[1684/1762] D loss: 1.3907, G loss: 0.6721\n",
      "[1762/1762] D loss: 1.3951, G loss: 0.7916\n",
      "train error: \n",
      " D loss: 1.336183, G loss: 0.795926, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 88.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.321498, G loss: 0.810128, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2050, G loss: 0.8726\n",
      "[84/1762] D loss: 1.3941, G loss: 0.6586\n",
      "[164/1762] D loss: 1.3914, G loss: 0.6829\n",
      "[244/1762] D loss: 1.3693, G loss: 0.8037\n",
      "[324/1762] D loss: 1.4020, G loss: 0.8361\n",
      "[404/1762] D loss: 1.3927, G loss: 0.6233\n",
      "[484/1762] D loss: 1.3891, G loss: 0.7416\n",
      "[564/1762] D loss: 1.3886, G loss: 0.7157\n",
      "[644/1762] D loss: 1.1718, G loss: 0.7198\n",
      "[724/1762] D loss: 1.3893, G loss: 0.6707\n",
      "[804/1762] D loss: 1.3984, G loss: 0.6334\n",
      "[884/1762] D loss: 1.1925, G loss: 0.8003\n",
      "[964/1762] D loss: 1.3993, G loss: 0.7392\n",
      "[1044/1762] D loss: 1.3857, G loss: 0.7001\n",
      "[1124/1762] D loss: 1.3928, G loss: 0.7098\n",
      "[1204/1762] D loss: 1.3732, G loss: 0.7239\n",
      "[1284/1762] D loss: 1.3907, G loss: 0.6634\n",
      "[1364/1762] D loss: 1.3761, G loss: 0.6828\n",
      "[1444/1762] D loss: 1.3894, G loss: 0.6810\n",
      "[1524/1762] D loss: 1.3980, G loss: 0.7675\n",
      "[1604/1762] D loss: 1.3921, G loss: 0.6724\n",
      "[1684/1762] D loss: 1.3983, G loss: 0.5814\n",
      "[1762/1762] D loss: 1.3891, G loss: 0.7165\n",
      "train error: \n",
      " D loss: 1.334611, G loss: 0.838479, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 87.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.318697, G loss: 0.852158, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 85.9% \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3985, G loss: 0.7328\n",
      "[84/1762] D loss: 1.3887, G loss: 0.6635\n",
      "[164/1762] D loss: 1.3904, G loss: 0.6618\n",
      "[244/1762] D loss: 1.3896, G loss: 0.7088\n",
      "[324/1762] D loss: 1.4178, G loss: 0.7038\n",
      "[404/1762] D loss: 1.4076, G loss: 0.6623\n",
      "[484/1762] D loss: 1.1433, G loss: 0.9372\n",
      "[564/1762] D loss: 1.3873, G loss: 0.6902\n",
      "[644/1762] D loss: 1.3961, G loss: 0.8479\n",
      "[724/1762] D loss: 1.3602, G loss: 0.7173\n",
      "[804/1762] D loss: 1.3926, G loss: 0.6724\n",
      "[884/1762] D loss: 1.3771, G loss: 0.7152\n",
      "[964/1762] D loss: 1.4875, G loss: 0.4543\n",
      "[1044/1762] D loss: 1.3593, G loss: 0.7023\n",
      "[1124/1762] D loss: 1.1790, G loss: 0.7501\n",
      "[1204/1762] D loss: 1.4057, G loss: 0.6285\n",
      "[1284/1762] D loss: 1.3914, G loss: 0.6995\n",
      "[1364/1762] D loss: 1.4344, G loss: 0.8820\n",
      "[1444/1762] D loss: 2.4237, G loss: 0.4405\n",
      "[1524/1762] D loss: 2.2075, G loss: 0.5455\n",
      "[1604/1762] D loss: 2.0290, G loss: 0.3307\n",
      "[1684/1762] D loss: 1.6727, G loss: 0.6888\n",
      "[1762/1762] D loss: 1.4886, G loss: 0.8393\n",
      "train error: \n",
      " D loss: 1.567655, G loss: 0.623909, D accuracy: 27.5%, cell accuracy: 98.5%, board accuracy: 11.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.564676, G loss: 0.630621, D accuracy: 28.7%, cell accuracy: 98.5%, board accuracy: 13.9% \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5373, G loss: 0.5900\n",
      "[84/1762] D loss: 1.5203, G loss: 0.7349\n",
      "[164/1762] D loss: 1.3779, G loss: 0.6029\n",
      "[244/1762] D loss: 1.3902, G loss: 0.8343\n",
      "[324/1762] D loss: 1.2737, G loss: 0.8779\n",
      "[404/1762] D loss: 1.3041, G loss: 0.6804\n",
      "[484/1762] D loss: 1.4241, G loss: 0.5559\n",
      "[564/1762] D loss: 1.4040, G loss: 0.8344\n",
      "[644/1762] D loss: 1.4373, G loss: 0.6082\n",
      "[724/1762] D loss: 1.5375, G loss: 0.9266\n",
      "[804/1762] D loss: 1.3722, G loss: 0.6806\n",
      "[884/1762] D loss: 1.5432, G loss: 1.0369\n",
      "[964/1762] D loss: 1.4425, G loss: 0.4937\n",
      "[1044/1762] D loss: 1.3983, G loss: 0.7996\n",
      "[1124/1762] D loss: 1.3895, G loss: 0.7352\n",
      "[1204/1762] D loss: 1.3951, G loss: 0.7950\n",
      "[1284/1762] D loss: 1.4097, G loss: 0.7520\n",
      "[1364/1762] D loss: 1.3949, G loss: 0.7193\n",
      "[1444/1762] D loss: 1.4145, G loss: 0.5492\n",
      "[1524/1762] D loss: 1.3964, G loss: 0.7626\n",
      "[1604/1762] D loss: 1.4078, G loss: 0.6410\n",
      "[1684/1762] D loss: 1.3894, G loss: 0.6851\n",
      "[1762/1762] D loss: 1.3299, G loss: 0.7991\n",
      "train error: \n",
      " D loss: 1.384547, G loss: 0.667030, D accuracy: 50.7%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.384587, G loss: 0.670626, D accuracy: 50.8%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3521, G loss: 0.6552\n",
      "[84/1762] D loss: 1.3876, G loss: 0.7143\n",
      "[164/1762] D loss: 1.3967, G loss: 0.6416\n",
      "[244/1762] D loss: 1.3958, G loss: 0.7595\n",
      "[324/1762] D loss: 1.3893, G loss: 0.6999\n",
      "[404/1762] D loss: 1.3927, G loss: 0.7389\n",
      "[484/1762] D loss: 1.4081, G loss: 0.6558\n",
      "[564/1762] D loss: 1.4044, G loss: 0.7257\n",
      "[644/1762] D loss: 1.3949, G loss: 0.7295\n",
      "[724/1762] D loss: 1.3949, G loss: 0.7363\n",
      "[804/1762] D loss: 1.3930, G loss: 0.6594\n",
      "[884/1762] D loss: 1.4031, G loss: 0.8204\n",
      "[964/1762] D loss: 1.3873, G loss: 0.6891\n",
      "[1044/1762] D loss: 1.3808, G loss: 0.7597\n",
      "[1124/1762] D loss: 1.3157, G loss: 0.8038\n",
      "[1204/1762] D loss: 1.3030, G loss: 0.7781\n",
      "[1284/1762] D loss: 1.3959, G loss: 0.6232\n",
      "[1364/1762] D loss: 1.3958, G loss: 0.7297\n",
      "[1444/1762] D loss: 1.3938, G loss: 0.7589\n",
      "[1524/1762] D loss: 1.3859, G loss: 0.7144\n",
      "[1604/1762] D loss: 1.3940, G loss: 0.6598\n",
      "[1684/1762] D loss: 1.3894, G loss: 0.6983\n",
      "[1762/1762] D loss: 1.3904, G loss: 0.7260\n",
      "train error: \n",
      " D loss: 1.373944, G loss: 0.828235, D accuracy: 53.0%, cell accuracy: 99.8%, board accuracy: 88.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.369001, G loss: 0.834653, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 85.9% \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4162, G loss: 0.8344\n",
      "[84/1762] D loss: 1.3961, G loss: 0.7068\n",
      "[164/1762] D loss: 1.3915, G loss: 0.7201\n",
      "[244/1762] D loss: 1.4045, G loss: 0.6950\n",
      "[324/1762] D loss: 1.3868, G loss: 0.6657\n",
      "[404/1762] D loss: 1.4036, G loss: 0.6959\n",
      "[484/1762] D loss: 1.4026, G loss: 0.7757\n",
      "[564/1762] D loss: 1.3840, G loss: 0.6968\n",
      "[644/1762] D loss: 1.3993, G loss: 0.6330\n",
      "[724/1762] D loss: 1.3919, G loss: 0.6651\n",
      "[804/1762] D loss: 1.3886, G loss: 0.7365\n",
      "[884/1762] D loss: 1.3834, G loss: 0.6861\n",
      "[964/1762] D loss: 1.3909, G loss: 0.7112\n",
      "[1044/1762] D loss: 1.3897, G loss: 0.7485\n",
      "[1124/1762] D loss: 1.3895, G loss: 0.7512\n",
      "[1204/1762] D loss: 1.2487, G loss: 0.7792\n",
      "[1284/1762] D loss: 1.3002, G loss: 0.7362\n",
      "[1364/1762] D loss: 1.2313, G loss: 0.8162\n",
      "[1444/1762] D loss: 1.3861, G loss: 0.7481\n",
      "[1524/1762] D loss: 1.3978, G loss: 0.8319\n",
      "[1604/1762] D loss: 1.4553, G loss: 0.7175\n",
      "[1684/1762] D loss: 1.3156, G loss: 0.7131\n",
      "[1762/1762] D loss: 1.2858, G loss: 0.6851\n",
      "train error: \n",
      " D loss: 1.288690, G loss: 0.806455, D accuracy: 71.5%, cell accuracy: 99.3%, board accuracy: 16.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.295607, G loss: 0.807894, D accuracy: 70.8%, cell accuracy: 99.3%, board accuracy: 17.5% \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2509, G loss: 0.7478\n",
      "[84/1762] D loss: 1.3450, G loss: 0.7577\n",
      "[164/1762] D loss: 1.4251, G loss: 0.6537\n",
      "[244/1762] D loss: 1.4319, G loss: 0.7570\n",
      "[324/1762] D loss: 1.4415, G loss: 0.6080\n",
      "[404/1762] D loss: 1.4498, G loss: 0.7868\n",
      "[484/1762] D loss: 1.3954, G loss: 0.6793\n",
      "[564/1762] D loss: 1.4532, G loss: 0.6450\n",
      "[644/1762] D loss: 1.3886, G loss: 0.6909\n",
      "[724/1762] D loss: 1.3487, G loss: 0.6853\n",
      "[804/1762] D loss: 1.3170, G loss: 0.7737\n",
      "[884/1762] D loss: 1.2701, G loss: 0.6580\n",
      "[964/1762] D loss: 1.2786, G loss: 0.6879\n",
      "[1044/1762] D loss: 1.2994, G loss: 0.8296\n",
      "[1124/1762] D loss: 1.4233, G loss: 0.6625\n",
      "[1204/1762] D loss: 1.3960, G loss: 0.6812\n",
      "[1284/1762] D loss: 1.4116, G loss: 0.7056\n",
      "[1364/1762] D loss: 1.3969, G loss: 0.7179\n",
      "[1444/1762] D loss: 1.4103, G loss: 0.5724\n",
      "[1524/1762] D loss: 1.3982, G loss: 0.7545\n",
      "[1604/1762] D loss: 1.3947, G loss: 0.7301\n",
      "[1684/1762] D loss: 1.4046, G loss: 0.8335\n",
      "[1762/1762] D loss: 1.3567, G loss: 0.6337\n",
      "train error: \n",
      " D loss: 1.385652, G loss: 0.692019, D accuracy: 51.4%, cell accuracy: 99.9%, board accuracy: 90.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.386552, G loss: 0.700469, D accuracy: 50.8%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4343, G loss: 0.6727\n",
      "[84/1762] D loss: 1.3930, G loss: 0.6644\n",
      "[164/1762] D loss: 1.3769, G loss: 0.7900\n",
      "[244/1762] D loss: 1.3876, G loss: 0.6996\n",
      "[324/1762] D loss: 1.3982, G loss: 0.7057\n",
      "[404/1762] D loss: 1.3920, G loss: 0.6841\n",
      "[484/1762] D loss: 1.3935, G loss: 0.6501\n",
      "[564/1762] D loss: 1.3952, G loss: 0.6072\n",
      "[644/1762] D loss: 1.3916, G loss: 0.6783\n",
      "[724/1762] D loss: 1.3891, G loss: 0.6705\n",
      "[804/1762] D loss: 1.3920, G loss: 0.7739\n",
      "[884/1762] D loss: 1.3868, G loss: 0.7309\n",
      "[964/1762] D loss: 1.3915, G loss: 0.6585\n",
      "[1044/1762] D loss: 1.3878, G loss: 0.7184\n",
      "[1124/1762] D loss: 1.3918, G loss: 0.6328\n",
      "[1204/1762] D loss: 1.2855, G loss: 0.7501\n",
      "[1284/1762] D loss: 1.3919, G loss: 0.6211\n",
      "[1364/1762] D loss: 1.3914, G loss: 0.7383\n",
      "[1444/1762] D loss: 1.3891, G loss: 0.7415\n",
      "[1524/1762] D loss: 1.3916, G loss: 0.6745\n",
      "[1604/1762] D loss: 1.3904, G loss: 0.6507\n",
      "[1684/1762] D loss: 1.2705, G loss: 0.7946\n",
      "[1762/1762] D loss: 1.1396, G loss: 0.9027\n",
      "train error: \n",
      " D loss: 1.362005, G loss: 0.763051, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 90.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.356583, G loss: 0.772630, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3884, G loss: 0.6923\n",
      "[84/1762] D loss: 1.3884, G loss: 0.6719\n",
      "[164/1762] D loss: 1.3795, G loss: 0.6294\n",
      "[244/1762] D loss: 1.3908, G loss: 0.6725\n",
      "[324/1762] D loss: 1.3077, G loss: 0.7145\n",
      "[404/1762] D loss: 1.3688, G loss: 0.6923\n",
      "[484/1762] D loss: 1.3870, G loss: 0.6666\n",
      "[564/1762] D loss: 1.3965, G loss: 0.7515\n",
      "[644/1762] D loss: 1.1088, G loss: 0.7905\n",
      "[724/1762] D loss: 1.2305, G loss: 0.7464\n",
      "[804/1762] D loss: 1.3897, G loss: 0.6688\n",
      "[884/1762] D loss: 1.3938, G loss: 0.7568\n",
      "[964/1762] D loss: 1.3894, G loss: 0.6947\n",
      "[1044/1762] D loss: 1.3929, G loss: 0.6302\n",
      "[1124/1762] D loss: 1.3886, G loss: 0.7900\n",
      "[1204/1762] D loss: 1.4124, G loss: 0.8442\n",
      "[1284/1762] D loss: 1.2761, G loss: 0.8176\n",
      "[1364/1762] D loss: 1.3975, G loss: 0.7809\n",
      "[1444/1762] D loss: 1.3998, G loss: 0.6810\n",
      "[1524/1762] D loss: 1.3872, G loss: 0.6662\n",
      "[1604/1762] D loss: 1.3971, G loss: 0.6963\n",
      "[1684/1762] D loss: 1.3917, G loss: 0.6926\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.7091\n",
      "train error: \n",
      " D loss: 1.346693, G loss: 0.768243, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.336487, G loss: 0.777329, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3585, G loss: 0.7337\n",
      "[84/1762] D loss: 1.2167, G loss: 0.7837\n",
      "[164/1762] D loss: 1.3898, G loss: 0.7050\n",
      "[244/1762] D loss: 1.3872, G loss: 0.6565\n",
      "[324/1762] D loss: 1.4007, G loss: 0.7167\n",
      "[404/1762] D loss: 1.0537, G loss: 0.8409\n",
      "[484/1762] D loss: 1.3913, G loss: 0.7718\n",
      "[564/1762] D loss: 1.3889, G loss: 0.7301\n",
      "[644/1762] D loss: 1.4027, G loss: 0.6413\n",
      "[724/1762] D loss: 1.2438, G loss: 0.7282\n",
      "[804/1762] D loss: 1.3965, G loss: 0.6583\n",
      "[884/1762] D loss: 1.3882, G loss: 0.6715\n",
      "[964/1762] D loss: 1.3475, G loss: 0.7685\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.6776\n",
      "[1124/1762] D loss: 1.3985, G loss: 0.8185\n",
      "[1204/1762] D loss: 1.4011, G loss: 0.8446\n",
      "[1284/1762] D loss: 1.3908, G loss: 0.7845\n",
      "[1364/1762] D loss: 1.3917, G loss: 0.7217\n",
      "[1444/1762] D loss: 1.3966, G loss: 0.6308\n",
      "[1524/1762] D loss: 1.4025, G loss: 0.7435\n",
      "[1604/1762] D loss: 1.1964, G loss: 0.8105\n",
      "[1684/1762] D loss: 1.2768, G loss: 0.7313\n",
      "[1762/1762] D loss: 1.3874, G loss: 0.6819\n",
      "train error: \n",
      " D loss: 1.345293, G loss: 0.645309, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 89.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.330838, G loss: 0.657283, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4100, G loss: 0.5960\n",
      "[84/1762] D loss: 1.3950, G loss: 0.7051\n",
      "[164/1762] D loss: 1.4176, G loss: 0.8063\n",
      "[244/1762] D loss: 1.4453, G loss: 0.6915\n",
      "[324/1762] D loss: 1.3938, G loss: 0.7158\n",
      "[404/1762] D loss: 1.3893, G loss: 0.6991\n",
      "[484/1762] D loss: 1.4045, G loss: 0.7839\n",
      "[564/1762] D loss: 1.1936, G loss: 0.8639\n",
      "[644/1762] D loss: 1.3886, G loss: 0.6808\n",
      "[724/1762] D loss: 1.3890, G loss: 0.6590\n",
      "[804/1762] D loss: 1.1600, G loss: 0.8980\n",
      "[884/1762] D loss: 1.3965, G loss: 0.7167\n",
      "[964/1762] D loss: 1.1814, G loss: 0.8769\n",
      "[1044/1762] D loss: 1.3982, G loss: 0.7542\n",
      "[1124/1762] D loss: 1.3762, G loss: 0.6773\n",
      "[1204/1762] D loss: 1.3993, G loss: 0.5732\n",
      "[1284/1762] D loss: 1.3876, G loss: 0.6625\n",
      "[1364/1762] D loss: 1.2502, G loss: 0.8582\n",
      "[1444/1762] D loss: 1.4020, G loss: 0.6869\n",
      "[1524/1762] D loss: 0.9896, G loss: 0.9051\n",
      "[1604/1762] D loss: 1.3958, G loss: 0.7049\n",
      "[1684/1762] D loss: 1.4344, G loss: 0.8015\n",
      "[1762/1762] D loss: 1.0953, G loss: 1.0281\n",
      "train error: \n",
      " D loss: 1.362917, G loss: 0.943958, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 89.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.349339, G loss: 0.954566, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 85.9% \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2053, G loss: 0.9919\n",
      "[84/1762] D loss: 1.1730, G loss: 0.9775\n",
      "[164/1762] D loss: 1.4315, G loss: 0.6663\n",
      "[244/1762] D loss: 1.4066, G loss: 0.5743\n",
      "[324/1762] D loss: 1.3929, G loss: 0.6569\n",
      "[404/1762] D loss: 1.1502, G loss: 0.9202\n",
      "[484/1762] D loss: 1.4172, G loss: 0.5713\n",
      "[564/1762] D loss: 1.2191, G loss: 0.6799\n",
      "[644/1762] D loss: 1.1950, G loss: 0.7355\n",
      "[724/1762] D loss: 1.1573, G loss: 0.8565\n",
      "[804/1762] D loss: 1.3794, G loss: 0.7112\n",
      "[884/1762] D loss: 1.8748, G loss: 0.6442\n",
      "[964/1762] D loss: 1.7672, G loss: 0.7004\n",
      "[1044/1762] D loss: 1.7499, G loss: 0.7974\n",
      "[1124/1762] D loss: 1.3564, G loss: 0.8276\n",
      "[1204/1762] D loss: 1.1802, G loss: 0.7818\n",
      "[1284/1762] D loss: 1.1937, G loss: 0.8827\n",
      "[1364/1762] D loss: 1.1289, G loss: 0.7708\n",
      "[1444/1762] D loss: 1.1933, G loss: 0.6399\n",
      "[1524/1762] D loss: 1.0712, G loss: 1.0244\n",
      "[1604/1762] D loss: 1.5211, G loss: 0.5884\n",
      "[1684/1762] D loss: 1.5597, G loss: 0.7476\n",
      "[1762/1762] D loss: 1.5232, G loss: 0.7386\n",
      "train error: \n",
      " D loss: 1.433542, G loss: 0.727795, D accuracy: 50.5%, cell accuracy: 99.3%, board accuracy: 17.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.449425, G loss: 0.736482, D accuracy: 49.9%, cell accuracy: 99.3%, board accuracy: 19.8% \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4179, G loss: 0.7041\n",
      "[84/1762] D loss: 1.5325, G loss: 0.7021\n",
      "[164/1762] D loss: 1.5257, G loss: 0.5463\n",
      "[244/1762] D loss: 1.4073, G loss: 0.6259\n",
      "[324/1762] D loss: 1.5532, G loss: 0.7887\n",
      "[404/1762] D loss: 1.3577, G loss: 0.6942\n",
      "[484/1762] D loss: 1.3925, G loss: 0.7271\n",
      "[564/1762] D loss: 1.4336, G loss: 0.5497\n",
      "[644/1762] D loss: 1.4528, G loss: 0.6339\n",
      "[724/1762] D loss: 1.3814, G loss: 0.6806\n",
      "[804/1762] D loss: 1.3934, G loss: 0.7301\n",
      "[884/1762] D loss: 1.3932, G loss: 0.7085\n",
      "[964/1762] D loss: 1.3899, G loss: 0.8013\n",
      "[1044/1762] D loss: 1.3772, G loss: 0.6456\n",
      "[1124/1762] D loss: 1.3792, G loss: 0.7406\n",
      "[1204/1762] D loss: 1.3775, G loss: 0.7520\n",
      "[1284/1762] D loss: 1.3974, G loss: 0.6248\n",
      "[1364/1762] D loss: 1.4006, G loss: 0.7606\n",
      "[1444/1762] D loss: 1.3990, G loss: 0.6697\n",
      "[1524/1762] D loss: 1.4152, G loss: 0.6051\n",
      "[1604/1762] D loss: 1.3931, G loss: 0.7611\n",
      "[1684/1762] D loss: 1.3945, G loss: 0.6592\n",
      "[1762/1762] D loss: 1.3972, G loss: 0.7588\n",
      "train error: \n",
      " D loss: 1.378187, G loss: 0.705832, D accuracy: 52.8%, cell accuracy: 99.8%, board accuracy: 85.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.379234, G loss: 0.711950, D accuracy: 53.1%, cell accuracy: 99.8%, board accuracy: 83.9% \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3953, G loss: 0.7109\n",
      "[84/1762] D loss: 1.3797, G loss: 0.6625\n",
      "[164/1762] D loss: 1.3892, G loss: 0.7151\n",
      "[244/1762] D loss: 1.3929, G loss: 0.5966\n",
      "[324/1762] D loss: 1.3950, G loss: 0.7017\n",
      "[404/1762] D loss: 1.3407, G loss: 0.7210\n",
      "[484/1762] D loss: 1.3943, G loss: 0.7466\n",
      "[564/1762] D loss: 1.3058, G loss: 0.7142\n",
      "[644/1762] D loss: 1.3907, G loss: 0.8146\n",
      "[724/1762] D loss: 1.3869, G loss: 0.6898\n",
      "[804/1762] D loss: 1.3882, G loss: 0.6819\n",
      "[884/1762] D loss: 1.3881, G loss: 0.6926\n",
      "[964/1762] D loss: 1.3876, G loss: 0.7150\n",
      "[1044/1762] D loss: 1.3883, G loss: 0.7047\n",
      "[1124/1762] D loss: 1.3888, G loss: 0.7124\n",
      "[1204/1762] D loss: 1.4064, G loss: 0.6252\n",
      "[1284/1762] D loss: 1.3092, G loss: 0.7616\n",
      "[1364/1762] D loss: 1.3894, G loss: 0.7187\n",
      "[1444/1762] D loss: 1.3903, G loss: 0.7198\n",
      "[1524/1762] D loss: 1.2716, G loss: 0.7724\n",
      "[1604/1762] D loss: 1.3771, G loss: 0.7630\n",
      "[1684/1762] D loss: 1.1376, G loss: 0.8331\n",
      "[1762/1762] D loss: 1.3891, G loss: 0.7398\n",
      "train error: \n",
      " D loss: 1.359217, G loss: 0.771989, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 90.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.352262, G loss: 0.780537, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3074, G loss: 0.8125\n",
      "[84/1762] D loss: 1.3625, G loss: 0.7232\n",
      "[164/1762] D loss: 1.3891, G loss: 0.6979\n",
      "[244/1762] D loss: 1.3873, G loss: 0.7167\n",
      "[324/1762] D loss: 1.3832, G loss: 0.7095\n",
      "[404/1762] D loss: 1.3875, G loss: 0.7215\n",
      "[484/1762] D loss: 1.3977, G loss: 0.7562\n",
      "[564/1762] D loss: 1.3885, G loss: 0.6871\n",
      "[644/1762] D loss: 1.3871, G loss: 0.7045\n",
      "[724/1762] D loss: 1.3964, G loss: 0.7609\n",
      "[804/1762] D loss: 1.2535, G loss: 0.7623\n",
      "[884/1762] D loss: 1.1408, G loss: 0.7591\n",
      "[964/1762] D loss: 1.3872, G loss: 0.6952\n",
      "[1044/1762] D loss: 1.3904, G loss: 0.7221\n",
      "[1124/1762] D loss: 1.4073, G loss: 0.8141\n",
      "[1204/1762] D loss: 1.3870, G loss: 0.7241\n",
      "[1284/1762] D loss: 1.3996, G loss: 0.6403\n",
      "[1364/1762] D loss: 1.1844, G loss: 0.7613\n",
      "[1444/1762] D loss: 1.2043, G loss: 0.8090\n",
      "[1524/1762] D loss: 1.3870, G loss: 0.7023\n",
      "[1604/1762] D loss: 1.2287, G loss: 0.7402\n",
      "[1684/1762] D loss: 1.3896, G loss: 0.6825\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.6326\n",
      "train error: \n",
      " D loss: 1.345217, G loss: 0.669979, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 88.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.334719, G loss: 0.676922, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3870, G loss: 0.6280\n",
      "[84/1762] D loss: 1.3912, G loss: 0.6530\n",
      "[164/1762] D loss: 1.3961, G loss: 0.6054\n",
      "[244/1762] D loss: 1.3912, G loss: 0.6593\n",
      "[324/1762] D loss: 1.1926, G loss: 0.8418\n",
      "[404/1762] D loss: 1.3948, G loss: 0.7333\n",
      "[484/1762] D loss: 1.3935, G loss: 0.7281\n",
      "[564/1762] D loss: 1.3889, G loss: 0.6263\n",
      "[644/1762] D loss: 1.1827, G loss: 0.7776\n",
      "[724/1762] D loss: 1.4203, G loss: 0.6160\n",
      "[804/1762] D loss: 1.2129, G loss: 0.7729\n",
      "[884/1762] D loss: 1.3965, G loss: 0.7239\n",
      "[964/1762] D loss: 1.3879, G loss: 0.6832\n",
      "[1044/1762] D loss: 1.2036, G loss: 0.9513\n",
      "[1124/1762] D loss: 1.3917, G loss: 0.6875\n",
      "[1204/1762] D loss: 1.3704, G loss: 0.6991\n",
      "[1284/1762] D loss: 1.3950, G loss: 0.7238\n",
      "[1364/1762] D loss: 1.3918, G loss: 0.7091\n",
      "[1444/1762] D loss: 1.3929, G loss: 0.6557\n",
      "[1524/1762] D loss: 1.4112, G loss: 0.7866\n",
      "[1604/1762] D loss: 1.3930, G loss: 0.7780\n",
      "[1684/1762] D loss: 1.4002, G loss: 0.6233\n",
      "[1762/1762] D loss: 0.9967, G loss: 0.8147\n",
      "train error: \n",
      " D loss: 1.334294, G loss: 0.722196, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 87.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.321091, G loss: 0.733709, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 84.5% \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3880, G loss: 0.7099\n",
      "[84/1762] D loss: 1.3566, G loss: 0.7709\n",
      "[164/1762] D loss: 1.3905, G loss: 0.7132\n",
      "[244/1762] D loss: 1.3907, G loss: 0.7609\n",
      "[324/1762] D loss: 1.3917, G loss: 0.7827\n",
      "[404/1762] D loss: 1.3881, G loss: 0.7102\n",
      "[484/1762] D loss: 1.2368, G loss: 0.7118\n",
      "[564/1762] D loss: 1.2417, G loss: 0.7623\n",
      "[644/1762] D loss: 1.3942, G loss: 0.7118\n",
      "[724/1762] D loss: 1.1982, G loss: 0.8251\n",
      "[804/1762] D loss: 1.3913, G loss: 0.7796\n",
      "[884/1762] D loss: 1.4214, G loss: 0.7875\n",
      "[964/1762] D loss: 1.3937, G loss: 0.6965\n",
      "[1044/1762] D loss: 1.3669, G loss: 0.6698\n",
      "[1124/1762] D loss: 1.3902, G loss: 0.6224\n",
      "[1204/1762] D loss: 1.3925, G loss: 0.6528\n",
      "[1284/1762] D loss: 1.3892, G loss: 0.6783\n",
      "[1364/1762] D loss: 1.1448, G loss: 0.9363\n",
      "[1444/1762] D loss: 1.1839, G loss: 0.8047\n",
      "[1524/1762] D loss: 1.2017, G loss: 0.7507\n",
      "[1604/1762] D loss: 1.3891, G loss: 0.7389\n",
      "[1684/1762] D loss: 1.4037, G loss: 0.8015\n",
      "[1762/1762] D loss: 1.3253, G loss: 0.7362\n",
      "train error: \n",
      " D loss: 1.335398, G loss: 0.808450, D accuracy: 53.8%, cell accuracy: 99.7%, board accuracy: 76.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.320901, G loss: 0.821003, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 77.0% \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3862, G loss: 0.7005\n",
      "[84/1762] D loss: 1.3329, G loss: 0.6499\n",
      "[164/1762] D loss: 1.1477, G loss: 0.7790\n",
      "[244/1762] D loss: 1.3904, G loss: 0.7097\n",
      "[324/1762] D loss: 1.2083, G loss: 0.7916\n",
      "[404/1762] D loss: 1.3477, G loss: 0.7129\n",
      "[484/1762] D loss: 1.3411, G loss: 0.7638\n",
      "[564/1762] D loss: 1.3206, G loss: 1.0391\n",
      "[644/1762] D loss: 1.4252, G loss: 0.7292\n",
      "[724/1762] D loss: 1.4328, G loss: 0.6297\n",
      "[804/1762] D loss: 1.2118, G loss: 0.7669\n",
      "[884/1762] D loss: 1.2680, G loss: 0.8649\n",
      "[964/1762] D loss: 1.2001, G loss: 0.8845\n",
      "[1044/1762] D loss: 1.3943, G loss: 0.7588\n",
      "[1124/1762] D loss: 1.4016, G loss: 0.8131\n",
      "[1204/1762] D loss: 1.1751, G loss: 0.8845\n",
      "[1284/1762] D loss: 1.3911, G loss: 0.7668\n",
      "[1364/1762] D loss: 1.4444, G loss: 0.5132\n",
      "[1444/1762] D loss: 1.1779, G loss: 0.7739\n",
      "[1524/1762] D loss: 1.4013, G loss: 0.7782\n",
      "[1604/1762] D loss: 1.4097, G loss: 0.7440\n",
      "[1684/1762] D loss: 1.3928, G loss: 0.7058\n",
      "[1762/1762] D loss: 1.4216, G loss: 0.7960\n",
      "train error: \n",
      " D loss: 1.332651, G loss: 0.739158, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 87.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.317637, G loss: 0.750464, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 84.8% \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4001, G loss: 0.7334\n",
      "[84/1762] D loss: 1.3707, G loss: 0.6204\n",
      "[164/1762] D loss: 1.3897, G loss: 0.7832\n",
      "[244/1762] D loss: 0.9879, G loss: 0.9230\n",
      "[324/1762] D loss: 1.7523, G loss: 0.4879\n",
      "[404/1762] D loss: 1.7358, G loss: 0.8429\n",
      "[484/1762] D loss: 1.3070, G loss: 0.6957\n",
      "[564/1762] D loss: 1.3261, G loss: 0.8885\n",
      "[644/1762] D loss: 1.1422, G loss: 0.6506\n",
      "[724/1762] D loss: 1.2870, G loss: 1.2579\n",
      "[804/1762] D loss: 1.4013, G loss: 0.7109\n",
      "[884/1762] D loss: 1.4313, G loss: 0.8744\n",
      "[964/1762] D loss: 1.4555, G loss: 0.8183\n",
      "[1044/1762] D loss: 1.3932, G loss: 0.8557\n",
      "[1124/1762] D loss: 1.3917, G loss: 0.5404\n",
      "[1204/1762] D loss: 1.4000, G loss: 0.7106\n",
      "[1284/1762] D loss: 1.2832, G loss: 0.7668\n",
      "[1364/1762] D loss: 1.3904, G loss: 0.7351\n",
      "[1444/1762] D loss: 1.3875, G loss: 0.6967\n",
      "[1524/1762] D loss: 1.3884, G loss: 0.6875\n",
      "[1604/1762] D loss: 1.3929, G loss: 0.7501\n",
      "[1684/1762] D loss: 1.3933, G loss: 0.6205\n",
      "[1762/1762] D loss: 1.3862, G loss: 0.7289\n",
      "train error: \n",
      " D loss: 1.362283, G loss: 0.746879, D accuracy: 53.1%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.356475, G loss: 0.753534, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3929, G loss: 0.7137\n",
      "[84/1762] D loss: 1.3845, G loss: 0.7548\n",
      "[164/1762] D loss: 1.3793, G loss: 0.6888\n",
      "[244/1762] D loss: 1.3925, G loss: 0.6455\n",
      "[324/1762] D loss: 1.4098, G loss: 0.6017\n",
      "[404/1762] D loss: 1.2737, G loss: 0.7990\n",
      "[484/1762] D loss: 1.2379, G loss: 0.7332\n",
      "[564/1762] D loss: 1.2312, G loss: 0.7202\n",
      "[644/1762] D loss: 1.2544, G loss: 0.7570\n",
      "[724/1762] D loss: 1.3906, G loss: 0.7287\n",
      "[804/1762] D loss: 1.3878, G loss: 0.7026\n",
      "[884/1762] D loss: 1.3871, G loss: 0.7031\n",
      "[964/1762] D loss: 1.3880, G loss: 0.6973\n",
      "[1044/1762] D loss: 1.3034, G loss: 0.7056\n",
      "[1124/1762] D loss: 1.3867, G loss: 0.7015\n",
      "[1204/1762] D loss: 1.3893, G loss: 0.7110\n",
      "[1284/1762] D loss: 1.3866, G loss: 0.6507\n",
      "[1364/1762] D loss: 1.3875, G loss: 0.7109\n",
      "[1444/1762] D loss: 1.3874, G loss: 0.7164\n",
      "[1524/1762] D loss: 1.3882, G loss: 0.7020\n",
      "[1604/1762] D loss: 1.2391, G loss: 0.7500\n",
      "[1684/1762] D loss: 1.3897, G loss: 0.7268\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6806\n",
      "train error: \n",
      " D loss: 1.343887, G loss: 0.680196, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 90.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.331952, G loss: 0.686994, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3917, G loss: 0.6572\n",
      "[84/1762] D loss: 1.3888, G loss: 0.7331\n",
      "[164/1762] D loss: 1.1968, G loss: 0.7777\n",
      "[244/1762] D loss: 1.1876, G loss: 0.7740\n",
      "[324/1762] D loss: 1.3886, G loss: 0.7291\n",
      "[404/1762] D loss: 1.3874, G loss: 0.7126\n",
      "[484/1762] D loss: 1.3895, G loss: 0.6777\n",
      "[564/1762] D loss: 1.3944, G loss: 0.6214\n",
      "[644/1762] D loss: 1.3948, G loss: 0.7675\n",
      "[724/1762] D loss: 1.3885, G loss: 0.6673\n",
      "[804/1762] D loss: 1.2004, G loss: 0.7346\n",
      "[884/1762] D loss: 1.3950, G loss: 0.6181\n",
      "[964/1762] D loss: 1.3991, G loss: 0.7782\n",
      "[1044/1762] D loss: 1.3952, G loss: 0.7866\n",
      "[1124/1762] D loss: 1.3948, G loss: 0.7540\n",
      "[1204/1762] D loss: 1.3906, G loss: 0.7521\n",
      "[1284/1762] D loss: 1.3912, G loss: 0.6696\n",
      "[1364/1762] D loss: 1.1916, G loss: 0.7213\n",
      "[1444/1762] D loss: 1.3949, G loss: 0.6041\n",
      "[1524/1762] D loss: 1.1754, G loss: 0.8605\n",
      "[1604/1762] D loss: 1.3886, G loss: 0.7231\n",
      "[1684/1762] D loss: 1.3895, G loss: 0.7006\n",
      "[1762/1762] D loss: 1.3876, G loss: 0.6720\n",
      "train error: \n",
      " D loss: 1.335040, G loss: 0.692520, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 89.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.320508, G loss: 0.702255, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2025, G loss: 0.8006\n",
      "[84/1762] D loss: 1.3913, G loss: 0.7118\n",
      "[164/1762] D loss: 1.3921, G loss: 0.7035\n",
      "[244/1762] D loss: 1.3897, G loss: 0.6583\n",
      "[324/1762] D loss: 1.2421, G loss: 0.6921\n",
      "[404/1762] D loss: 1.3952, G loss: 0.6112\n",
      "[484/1762] D loss: 1.3960, G loss: 0.6912\n",
      "[564/1762] D loss: 1.4080, G loss: 0.8050\n",
      "[644/1762] D loss: 1.3907, G loss: 0.7673\n",
      "[724/1762] D loss: 1.3906, G loss: 0.6504\n",
      "[804/1762] D loss: 1.3958, G loss: 0.6420\n",
      "[884/1762] D loss: 1.3884, G loss: 0.6641\n",
      "[964/1762] D loss: 1.3719, G loss: 0.7542\n",
      "[1044/1762] D loss: 1.1515, G loss: 0.8717\n",
      "[1124/1762] D loss: 1.1780, G loss: 0.8018\n",
      "[1204/1762] D loss: 1.1559, G loss: 0.8139\n",
      "[1284/1762] D loss: 1.1604, G loss: 0.8971\n",
      "[1364/1762] D loss: 1.3937, G loss: 0.6212\n",
      "[1444/1762] D loss: 1.3899, G loss: 0.6872\n",
      "[1524/1762] D loss: 0.9903, G loss: 0.9514\n",
      "[1604/1762] D loss: 1.3992, G loss: 0.6828\n",
      "[1684/1762] D loss: 1.4305, G loss: 0.8876\n",
      "[1762/1762] D loss: 1.3881, G loss: 0.7399\n",
      "train error: \n",
      " D loss: 1.334085, G loss: 0.798279, D accuracy: 52.9%, cell accuracy: 99.8%, board accuracy: 89.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.317706, G loss: 0.811989, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1531, G loss: 0.8894\n",
      "[84/1762] D loss: 1.3982, G loss: 0.6374\n",
      "[164/1762] D loss: 1.4021, G loss: 0.5582\n",
      "[244/1762] D loss: 1.1660, G loss: 0.8971\n",
      "[324/1762] D loss: 1.4059, G loss: 0.7431\n",
      "[404/1762] D loss: 1.3948, G loss: 0.6309\n",
      "[484/1762] D loss: 1.1472, G loss: 0.8305\n",
      "[564/1762] D loss: 1.3861, G loss: 0.6590\n",
      "[644/1762] D loss: 1.1438, G loss: 0.8598\n",
      "[724/1762] D loss: 1.4126, G loss: 0.8151\n",
      "[804/1762] D loss: 1.4017, G loss: 0.7762\n",
      "[884/1762] D loss: 1.3896, G loss: 0.7179\n",
      "[964/1762] D loss: 1.1558, G loss: 0.8728\n",
      "[1044/1762] D loss: 1.3901, G loss: 0.7046\n",
      "[1124/1762] D loss: 1.3921, G loss: 0.6625\n",
      "[1204/1762] D loss: 1.4049, G loss: 0.7507\n",
      "[1284/1762] D loss: 1.1245, G loss: 0.9082\n",
      "[1364/1762] D loss: 1.1432, G loss: 0.8980\n",
      "[1444/1762] D loss: 1.3987, G loss: 0.7101\n",
      "[1524/1762] D loss: 1.3939, G loss: 0.7298\n",
      "[1604/1762] D loss: 1.4029, G loss: 0.7074\n",
      "[1684/1762] D loss: 1.4019, G loss: 0.7074\n",
      "[1762/1762] D loss: 1.3968, G loss: 0.8116\n",
      "train error: \n",
      " D loss: 1.327855, G loss: 0.774418, D accuracy: 53.1%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.311253, G loss: 0.787073, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3970, G loss: 0.7667\n",
      "[84/1762] D loss: 1.4136, G loss: 0.7046\n",
      "[164/1762] D loss: 1.1523, G loss: 0.8181\n",
      "[244/1762] D loss: 1.1541, G loss: 0.7782\n",
      "[324/1762] D loss: 1.3898, G loss: 0.6401\n",
      "[404/1762] D loss: 1.1321, G loss: 0.9191\n",
      "[484/1762] D loss: 1.3904, G loss: 0.7918\n",
      "[564/1762] D loss: 1.1669, G loss: 0.7698\n",
      "[644/1762] D loss: 1.3938, G loss: 0.5788\n",
      "[724/1762] D loss: 1.1539, G loss: 0.7394\n",
      "[804/1762] D loss: 1.3954, G loss: 0.6707\n",
      "[884/1762] D loss: 1.3997, G loss: 0.7525\n",
      "[964/1762] D loss: 1.1462, G loss: 1.0451\n",
      "[1044/1762] D loss: 1.1534, G loss: 0.9238\n",
      "[1124/1762] D loss: 1.3896, G loss: 0.6530\n",
      "[1204/1762] D loss: 1.1287, G loss: 0.8400\n",
      "[1284/1762] D loss: 1.4297, G loss: 0.8813\n",
      "[1364/1762] D loss: 1.1423, G loss: 0.8510\n",
      "[1444/1762] D loss: 1.1265, G loss: 0.9110\n",
      "[1524/1762] D loss: 1.4001, G loss: 0.7331\n",
      "[1604/1762] D loss: 1.4031, G loss: 0.7996\n",
      "[1684/1762] D loss: 1.1431, G loss: 0.8513\n",
      "[1762/1762] D loss: 0.9243, G loss: 0.9087\n",
      "train error: \n",
      " D loss: 1.324270, G loss: 0.741288, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 83.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.305334, G loss: 0.753921, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 80.2% \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3832, G loss: 0.7488\n",
      "[84/1762] D loss: 1.4027, G loss: 0.7319\n",
      "[164/1762] D loss: 1.3940, G loss: 0.7442\n",
      "[244/1762] D loss: 1.3915, G loss: 0.6651\n",
      "[324/1762] D loss: 1.4035, G loss: 0.7772\n",
      "[404/1762] D loss: 1.4031, G loss: 0.6556\n",
      "[484/1762] D loss: 0.9402, G loss: 0.8609\n",
      "[564/1762] D loss: 1.3813, G loss: 0.6807\n",
      "[644/1762] D loss: 1.3872, G loss: 0.7641\n",
      "[724/1762] D loss: 1.3929, G loss: 0.6290\n",
      "[804/1762] D loss: 0.8697, G loss: 1.1046\n",
      "[884/1762] D loss: 1.3922, G loss: 0.8184\n",
      "[964/1762] D loss: 1.3921, G loss: 0.7080\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.7001\n",
      "[1124/1762] D loss: 1.3906, G loss: 0.6798\n",
      "[1204/1762] D loss: 1.3959, G loss: 0.7593\n",
      "[1284/1762] D loss: 1.3886, G loss: 0.7715\n",
      "[1364/1762] D loss: 1.3912, G loss: 0.7619\n",
      "[1444/1762] D loss: 1.3962, G loss: 0.7385\n",
      "[1524/1762] D loss: 1.1652, G loss: 0.8837\n",
      "[1604/1762] D loss: 1.3985, G loss: 0.6275\n",
      "[1684/1762] D loss: 1.4347, G loss: 0.6245\n",
      "[1762/1762] D loss: 1.4115, G loss: 0.5249\n",
      "train error: \n",
      " D loss: 1.343362, G loss: 0.619217, D accuracy: 54.2%, cell accuracy: 99.7%, board accuracy: 77.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.325434, G loss: 0.631870, D accuracy: 54.9%, cell accuracy: 99.7%, board accuracy: 72.7% \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3909, G loss: 0.5981\n",
      "[84/1762] D loss: 1.3973, G loss: 0.6749\n",
      "[164/1762] D loss: 1.4260, G loss: 0.9016\n",
      "[244/1762] D loss: 1.3820, G loss: 0.6660\n",
      "[324/1762] D loss: 1.1310, G loss: 0.9772\n",
      "[404/1762] D loss: 1.3710, G loss: 0.7067\n",
      "[484/1762] D loss: 0.8800, G loss: 1.1514\n",
      "[564/1762] D loss: 1.3881, G loss: 0.6651\n",
      "[644/1762] D loss: 1.3978, G loss: 0.6929\n",
      "[724/1762] D loss: 1.3921, G loss: 0.7493\n",
      "[804/1762] D loss: 1.3756, G loss: 0.8270\n",
      "[884/1762] D loss: 1.3843, G loss: 0.7128\n",
      "[964/1762] D loss: 1.3979, G loss: 0.7043\n",
      "[1044/1762] D loss: 1.4283, G loss: 0.7021\n",
      "[1124/1762] D loss: 2.3832, G loss: 0.3460\n",
      "[1204/1762] D loss: 1.4417, G loss: 0.8289\n",
      "[1284/1762] D loss: 1.8118, G loss: 0.4850\n",
      "[1364/1762] D loss: 1.3657, G loss: 0.7116\n",
      "[1444/1762] D loss: 1.1880, G loss: 0.7563\n",
      "[1524/1762] D loss: 1.3200, G loss: 1.1045\n",
      "[1604/1762] D loss: 1.0958, G loss: 1.0313\n",
      "[1684/1762] D loss: 1.1050, G loss: 0.8111\n",
      "[1762/1762] D loss: 1.7880, G loss: 0.9229\n",
      "train error: \n",
      " D loss: 1.518224, G loss: 0.673055, D accuracy: 47.3%, cell accuracy: 99.7%, board accuracy: 66.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.549864, G loss: 0.679569, D accuracy: 45.6%, cell accuracy: 99.7%, board accuracy: 61.4% \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4051, G loss: 0.6139\n",
      "[84/1762] D loss: 1.3796, G loss: 0.7178\n",
      "[164/1762] D loss: 1.7232, G loss: 0.8069\n",
      "[244/1762] D loss: 1.6925, G loss: 0.9118\n",
      "[324/1762] D loss: 1.4441, G loss: 0.5091\n",
      "[404/1762] D loss: 1.4529, G loss: 0.7657\n",
      "[484/1762] D loss: 1.4159, G loss: 0.5850\n",
      "[564/1762] D loss: 1.5737, G loss: 0.8681\n",
      "[644/1762] D loss: 1.3738, G loss: 0.7235\n",
      "[724/1762] D loss: 1.5297, G loss: 0.6316\n",
      "[804/1762] D loss: 1.5488, G loss: 0.6223\n",
      "[884/1762] D loss: 1.3932, G loss: 0.7206\n",
      "[964/1762] D loss: 1.4140, G loss: 0.6059\n",
      "[1044/1762] D loss: 1.2673, G loss: 0.7958\n",
      "[1124/1762] D loss: 1.4072, G loss: 0.6364\n",
      "[1204/1762] D loss: 1.3913, G loss: 0.7735\n",
      "[1284/1762] D loss: 1.3941, G loss: 0.7042\n",
      "[1364/1762] D loss: 1.3927, G loss: 0.6906\n",
      "[1444/1762] D loss: 1.4062, G loss: 0.6793\n",
      "[1524/1762] D loss: 1.4016, G loss: 0.7798\n",
      "[1604/1762] D loss: 1.3908, G loss: 0.6245\n",
      "[1684/1762] D loss: 1.4016, G loss: 0.6320\n",
      "[1762/1762] D loss: 1.3899, G loss: 0.7166\n",
      "train error: \n",
      " D loss: 1.397221, G loss: 0.725198, D accuracy: 49.5%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.404858, G loss: 0.730513, D accuracy: 48.3%, cell accuracy: 99.8%, board accuracy: 84.3% \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3909, G loss: 0.6746\n",
      "[84/1762] D loss: 1.3901, G loss: 0.7095\n",
      "[164/1762] D loss: 1.3512, G loss: 0.7431\n",
      "[244/1762] D loss: 1.4531, G loss: 0.7161\n",
      "[324/1762] D loss: 1.4048, G loss: 0.6032\n",
      "[404/1762] D loss: 1.4022, G loss: 0.6324\n",
      "[484/1762] D loss: 1.3946, G loss: 0.7690\n",
      "[564/1762] D loss: 1.3543, G loss: 0.5988\n",
      "[644/1762] D loss: 1.3352, G loss: 0.6872\n",
      "[724/1762] D loss: 1.3998, G loss: 0.7300\n",
      "[804/1762] D loss: 1.3199, G loss: 0.7110\n",
      "[884/1762] D loss: 1.3971, G loss: 0.6835\n",
      "[964/1762] D loss: 1.3909, G loss: 0.7436\n",
      "[1044/1762] D loss: 1.3870, G loss: 0.7131\n",
      "[1124/1762] D loss: 1.3892, G loss: 0.6646\n",
      "[1204/1762] D loss: 1.3952, G loss: 0.7075\n",
      "[1284/1762] D loss: 1.3925, G loss: 0.7047\n",
      "[1364/1762] D loss: 1.3812, G loss: 0.7912\n",
      "[1444/1762] D loss: 1.3026, G loss: 0.7126\n",
      "[1524/1762] D loss: 1.3853, G loss: 0.7005\n",
      "[1604/1762] D loss: 1.3699, G loss: 0.6877\n",
      "[1684/1762] D loss: 1.3942, G loss: 0.6852\n",
      "[1762/1762] D loss: 1.3903, G loss: 0.7436\n",
      "train error: \n",
      " D loss: 1.370452, G loss: 0.698810, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 88.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.369045, G loss: 0.702562, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3916, G loss: 0.6555\n",
      "[84/1762] D loss: 1.3871, G loss: 0.7152\n",
      "[164/1762] D loss: 1.3868, G loss: 0.7097\n",
      "[244/1762] D loss: 1.3680, G loss: 0.7880\n",
      "[324/1762] D loss: 1.2863, G loss: 0.7406\n",
      "[404/1762] D loss: 1.3906, G loss: 0.6430\n",
      "[484/1762] D loss: 1.3081, G loss: 0.7058\n",
      "[564/1762] D loss: 1.3872, G loss: 0.6868\n",
      "[644/1762] D loss: 1.3872, G loss: 0.6982\n",
      "[724/1762] D loss: 1.3633, G loss: 0.7306\n",
      "[804/1762] D loss: 1.4093, G loss: 0.7120\n",
      "[884/1762] D loss: 1.3918, G loss: 0.7375\n",
      "[964/1762] D loss: 1.3853, G loss: 0.6821\n",
      "[1044/1762] D loss: 1.2507, G loss: 0.7685\n",
      "[1124/1762] D loss: 1.1697, G loss: 0.8197\n",
      "[1204/1762] D loss: 1.3952, G loss: 0.6878\n",
      "[1284/1762] D loss: 1.3871, G loss: 0.7133\n",
      "[1364/1762] D loss: 1.3926, G loss: 0.7141\n",
      "[1444/1762] D loss: 1.3905, G loss: 0.7374\n",
      "[1524/1762] D loss: 1.2408, G loss: 0.8021\n",
      "[1604/1762] D loss: 1.3871, G loss: 0.6799\n",
      "[1684/1762] D loss: 1.3900, G loss: 0.7073\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.7016\n",
      "train error: \n",
      " D loss: 1.353929, G loss: 0.729408, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 90.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.347328, G loss: 0.733023, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3908, G loss: 0.7356\n",
      "[84/1762] D loss: 1.3901, G loss: 0.7105\n",
      "[164/1762] D loss: 1.3889, G loss: 0.7226\n",
      "[244/1762] D loss: 1.3981, G loss: 0.7094\n",
      "[324/1762] D loss: 1.2505, G loss: 0.6709\n",
      "[404/1762] D loss: 1.3904, G loss: 0.6433\n",
      "[484/1762] D loss: 1.3936, G loss: 0.7051\n",
      "[564/1762] D loss: 1.3868, G loss: 0.7218\n",
      "[644/1762] D loss: 1.3854, G loss: 0.6692\n",
      "[724/1762] D loss: 1.2230, G loss: 0.7643\n",
      "[804/1762] D loss: 1.6557, G loss: 0.6055\n",
      "[884/1762] D loss: 1.5003, G loss: 0.6715\n",
      "[964/1762] D loss: 1.4475, G loss: 0.7228\n",
      "[1044/1762] D loss: 1.3693, G loss: 0.7099\n",
      "[1124/1762] D loss: 1.2736, G loss: 0.6785\n",
      "[1204/1762] D loss: 1.1624, G loss: 0.8668\n",
      "[1284/1762] D loss: 1.2711, G loss: 0.7958\n",
      "[1364/1762] D loss: 1.4392, G loss: 0.8080\n",
      "[1444/1762] D loss: 1.4060, G loss: 0.6301\n",
      "[1524/1762] D loss: 1.3922, G loss: 0.6706\n",
      "[1604/1762] D loss: 1.3696, G loss: 0.7470\n",
      "[1684/1762] D loss: 1.4027, G loss: 0.6269\n",
      "[1762/1762] D loss: 1.3584, G loss: 0.7378\n",
      "train error: \n",
      " D loss: 1.398463, G loss: 0.671701, D accuracy: 51.1%, cell accuracy: 99.9%, board accuracy: 90.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.402407, G loss: 0.675505, D accuracy: 51.0%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3890, G loss: 0.6758\n",
      "[84/1762] D loss: 1.4307, G loss: 0.8201\n",
      "[164/1762] D loss: 1.3913, G loss: 0.6939\n",
      "[244/1762] D loss: 1.3892, G loss: 0.7145\n",
      "[324/1762] D loss: 1.3961, G loss: 0.6655\n",
      "[404/1762] D loss: 1.3689, G loss: 0.7693\n",
      "[484/1762] D loss: 1.3914, G loss: 0.7345\n",
      "[564/1762] D loss: 1.3951, G loss: 0.7859\n",
      "[644/1762] D loss: 1.4011, G loss: 0.6031\n",
      "[724/1762] D loss: 1.3401, G loss: 0.7448\n",
      "[804/1762] D loss: 1.3892, G loss: 0.6682\n",
      "[884/1762] D loss: 1.3887, G loss: 0.7180\n",
      "[964/1762] D loss: 1.3934, G loss: 0.6885\n",
      "[1044/1762] D loss: 1.3914, G loss: 0.6139\n",
      "[1124/1762] D loss: 1.3948, G loss: 0.7666\n",
      "[1204/1762] D loss: 1.3873, G loss: 0.6973\n",
      "[1284/1762] D loss: 1.3926, G loss: 0.6538\n",
      "[1364/1762] D loss: 1.4081, G loss: 0.5673\n",
      "[1444/1762] D loss: 1.3920, G loss: 0.7374\n",
      "[1524/1762] D loss: 1.3886, G loss: 0.6847\n",
      "[1604/1762] D loss: 1.2652, G loss: 0.8000\n",
      "[1684/1762] D loss: 1.3875, G loss: 0.7033\n",
      "[1762/1762] D loss: 1.3907, G loss: 0.6229\n",
      "train error: \n",
      " D loss: 1.365007, G loss: 0.659693, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 91.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.360559, G loss: 0.663721, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3905, G loss: 0.6549\n",
      "[84/1762] D loss: 1.3876, G loss: 0.6740\n",
      "[164/1762] D loss: 1.4014, G loss: 0.6479\n",
      "[244/1762] D loss: 1.4106, G loss: 0.5975\n",
      "[324/1762] D loss: 1.2385, G loss: 0.9249\n",
      "[404/1762] D loss: 1.3893, G loss: 0.7002\n",
      "[484/1762] D loss: 1.3909, G loss: 0.6674\n",
      "[564/1762] D loss: 1.3993, G loss: 0.7303\n",
      "[644/1762] D loss: 1.3917, G loss: 0.7321\n",
      "[724/1762] D loss: 1.3935, G loss: 0.6292\n",
      "[804/1762] D loss: 1.3843, G loss: 0.7275\n",
      "[884/1762] D loss: 1.2381, G loss: 0.7335\n",
      "[964/1762] D loss: 1.3927, G loss: 0.6804\n",
      "[1044/1762] D loss: 1.3922, G loss: 0.6503\n",
      "[1124/1762] D loss: 1.2863, G loss: 0.8406\n",
      "[1204/1762] D loss: 1.3945, G loss: 0.6494\n",
      "[1284/1762] D loss: 1.3893, G loss: 0.6912\n",
      "[1364/1762] D loss: 1.2357, G loss: 0.7760\n",
      "[1444/1762] D loss: 1.3878, G loss: 0.6984\n",
      "[1524/1762] D loss: 1.3981, G loss: 0.7536\n",
      "[1604/1762] D loss: 1.3995, G loss: 0.7688\n",
      "[1684/1762] D loss: 1.3948, G loss: 0.7566\n",
      "[1762/1762] D loss: 1.4034, G loss: 0.7585\n",
      "train error: \n",
      " D loss: 1.345776, G loss: 0.702789, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 91.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.335854, G loss: 0.707035, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2576, G loss: 0.7488\n",
      "[84/1762] D loss: 1.3953, G loss: 0.6243\n",
      "[164/1762] D loss: 1.3867, G loss: 0.6704\n",
      "[244/1762] D loss: 1.3901, G loss: 0.7342\n",
      "[324/1762] D loss: 1.4006, G loss: 0.7771\n",
      "[404/1762] D loss: 1.2105, G loss: 0.9453\n",
      "[484/1762] D loss: 1.1996, G loss: 0.7123\n",
      "[564/1762] D loss: 1.4001, G loss: 0.6508\n",
      "[644/1762] D loss: 1.1958, G loss: 0.7560\n",
      "[724/1762] D loss: 1.1918, G loss: 0.7663\n",
      "[804/1762] D loss: 1.2811, G loss: 0.8682\n",
      "[884/1762] D loss: 1.2717, G loss: 0.7120\n",
      "[964/1762] D loss: 1.3903, G loss: 0.6637\n",
      "[1044/1762] D loss: 1.2800, G loss: 0.8728\n",
      "[1124/1762] D loss: 1.3938, G loss: 0.6415\n",
      "[1204/1762] D loss: 1.1792, G loss: 0.9418\n",
      "[1284/1762] D loss: 1.1865, G loss: 0.9132\n",
      "[1364/1762] D loss: 1.3999, G loss: 0.7494\n",
      "[1444/1762] D loss: 1.4485, G loss: 0.8850\n",
      "[1524/1762] D loss: 1.3876, G loss: 0.7012\n",
      "[1604/1762] D loss: 1.3931, G loss: 0.6767\n",
      "[1684/1762] D loss: 1.3915, G loss: 0.6721\n",
      "[1762/1762] D loss: 1.3970, G loss: 0.7755\n",
      "train error: \n",
      " D loss: 1.341143, G loss: 0.838400, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 91.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.325966, G loss: 0.845993, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3939, G loss: 0.7353\n",
      "[84/1762] D loss: 1.1892, G loss: 0.7086\n",
      "[164/1762] D loss: 1.3867, G loss: 0.6495\n",
      "[244/1762] D loss: 1.3898, G loss: 0.7833\n",
      "[324/1762] D loss: 1.3893, G loss: 0.6362\n",
      "[404/1762] D loss: 1.4034, G loss: 0.7478\n",
      "[484/1762] D loss: 1.3969, G loss: 0.7785\n",
      "[564/1762] D loss: 1.4099, G loss: 0.6241\n",
      "[644/1762] D loss: 1.3939, G loss: 0.6252\n",
      "[724/1762] D loss: 1.1774, G loss: 0.7103\n",
      "[804/1762] D loss: 1.3949, G loss: 0.5847\n",
      "[884/1762] D loss: 1.3890, G loss: 0.7232\n",
      "[964/1762] D loss: 1.3867, G loss: 0.7121\n",
      "[1044/1762] D loss: 1.3920, G loss: 0.7133\n",
      "[1124/1762] D loss: 1.4017, G loss: 0.8098\n",
      "[1204/1762] D loss: 1.3947, G loss: 0.6650\n",
      "[1284/1762] D loss: 1.1690, G loss: 0.8238\n",
      "[1364/1762] D loss: 1.1509, G loss: 0.9103\n",
      "[1444/1762] D loss: 1.3937, G loss: 0.7287\n",
      "[1524/1762] D loss: 0.8890, G loss: 1.0601\n",
      "[1604/1762] D loss: 1.4021, G loss: 0.7796\n",
      "[1684/1762] D loss: 1.3935, G loss: 0.6993\n",
      "[1762/1762] D loss: 1.3903, G loss: 0.7207\n",
      "train error: \n",
      " D loss: 1.329157, G loss: 0.730997, D accuracy: 53.4%, cell accuracy: 99.9%, board accuracy: 91.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.313164, G loss: 0.740347, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1464, G loss: 0.8930\n",
      "[84/1762] D loss: 1.3937, G loss: 0.7075\n",
      "[164/1762] D loss: 1.3901, G loss: 0.6627\n",
      "[244/1762] D loss: 1.1486, G loss: 0.8771\n",
      "[324/1762] D loss: 1.3924, G loss: 0.7224\n",
      "[404/1762] D loss: 1.4072, G loss: 0.6088\n",
      "[484/1762] D loss: 1.4207, G loss: 0.5564\n",
      "[564/1762] D loss: 1.1513, G loss: 0.8786\n",
      "[644/1762] D loss: 1.3688, G loss: 0.7419\n",
      "[724/1762] D loss: 1.3890, G loss: 0.7624\n",
      "[804/1762] D loss: 1.4050, G loss: 0.7806\n",
      "[884/1762] D loss: 1.3954, G loss: 0.7729\n",
      "[964/1762] D loss: 1.1583, G loss: 0.8772\n",
      "[1044/1762] D loss: 1.3901, G loss: 0.6516\n",
      "[1124/1762] D loss: 1.3902, G loss: 0.6564\n",
      "[1204/1762] D loss: 1.3982, G loss: 0.6891\n",
      "[1284/1762] D loss: 1.3895, G loss: 0.7287\n",
      "[1364/1762] D loss: 1.3950, G loss: 0.6326\n",
      "[1444/1762] D loss: 0.9098, G loss: 0.9544\n",
      "[1524/1762] D loss: 1.3925, G loss: 0.6416\n",
      "[1604/1762] D loss: 1.4036, G loss: 0.7531\n",
      "[1684/1762] D loss: 1.4174, G loss: 0.7931\n",
      "[1762/1762] D loss: 1.3957, G loss: 0.7485\n",
      "train error: \n",
      " D loss: 1.326671, G loss: 0.730078, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 88.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.309688, G loss: 0.739410, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 85.5% \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3918, G loss: 0.6771\n",
      "[84/1762] D loss: 1.4178, G loss: 0.7824\n",
      "[164/1762] D loss: 1.4185, G loss: 0.8382\n",
      "[244/1762] D loss: 1.4113, G loss: 0.6493\n",
      "[324/1762] D loss: 1.3956, G loss: 0.7814\n",
      "[404/1762] D loss: 1.1285, G loss: 0.8298\n",
      "[484/1762] D loss: 1.3881, G loss: 0.7043\n",
      "[564/1762] D loss: 1.1128, G loss: 0.9082\n",
      "[644/1762] D loss: 1.3914, G loss: 0.6635\n",
      "[724/1762] D loss: 1.1625, G loss: 0.8711\n",
      "[804/1762] D loss: 1.3921, G loss: 0.7469\n",
      "[884/1762] D loss: 1.3768, G loss: 0.7259\n",
      "[964/1762] D loss: 1.1541, G loss: 0.9470\n",
      "[1044/1762] D loss: 1.4126, G loss: 0.8502\n",
      "[1124/1762] D loss: 1.8555, G loss: 0.5288\n",
      "[1204/1762] D loss: 1.5018, G loss: 0.6903\n",
      "[1284/1762] D loss: 1.3502, G loss: 0.7354\n",
      "[1364/1762] D loss: 1.2241, G loss: 0.9393\n",
      "[1444/1762] D loss: 1.2069, G loss: 1.0200\n",
      "[1524/1762] D loss: 1.3254, G loss: 0.9071\n",
      "[1604/1762] D loss: 1.0825, G loss: 0.9472\n",
      "[1684/1762] D loss: 1.4387, G loss: 0.6822\n",
      "[1762/1762] D loss: 1.1842, G loss: 0.8859\n",
      "train error: \n",
      " D loss: 1.169285, G loss: 1.056352, D accuracy: 79.7%, cell accuracy: 98.7%, board accuracy: 16.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.194663, G loss: 1.079014, D accuracy: 78.9%, cell accuracy: 98.6%, board accuracy: 16.6% \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1934, G loss: 0.8889\n",
      "[84/1762] D loss: 1.6201, G loss: 0.8673\n",
      "[164/1762] D loss: 1.7315, G loss: 0.4614\n",
      "[244/1762] D loss: 1.3931, G loss: 0.7539\n",
      "[324/1762] D loss: 1.5867, G loss: 0.5501\n",
      "[404/1762] D loss: 1.6233, G loss: 0.7162\n",
      "[484/1762] D loss: 1.4112, G loss: 0.7641\n",
      "[564/1762] D loss: 1.4150, G loss: 0.8483\n",
      "[644/1762] D loss: 1.3844, G loss: 0.9170\n",
      "[724/1762] D loss: 1.3157, G loss: 0.6642\n",
      "[804/1762] D loss: 1.3909, G loss: 0.5948\n",
      "[884/1762] D loss: 1.5061, G loss: 0.6255\n",
      "[964/1762] D loss: 1.3832, G loss: 0.7024\n",
      "[1044/1762] D loss: 1.3766, G loss: 0.7122\n",
      "[1124/1762] D loss: 1.4139, G loss: 0.5731\n",
      "[1204/1762] D loss: 1.3295, G loss: 0.6837\n",
      "[1284/1762] D loss: 1.3916, G loss: 0.7167\n",
      "[1364/1762] D loss: 1.4060, G loss: 0.6408\n",
      "[1444/1762] D loss: 1.3883, G loss: 0.6645\n",
      "[1524/1762] D loss: 1.3884, G loss: 0.7520\n",
      "[1604/1762] D loss: 1.3961, G loss: 0.7966\n",
      "[1684/1762] D loss: 1.3301, G loss: 0.6832\n",
      "[1762/1762] D loss: 1.3840, G loss: 0.6280\n",
      "train error: \n",
      " D loss: 1.394542, G loss: 0.670593, D accuracy: 50.3%, cell accuracy: 99.8%, board accuracy: 82.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.396319, G loss: 0.678994, D accuracy: 51.0%, cell accuracy: 99.8%, board accuracy: 80.5% \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3933, G loss: 0.6741\n",
      "[84/1762] D loss: 1.4050, G loss: 0.7038\n",
      "[164/1762] D loss: 1.4302, G loss: 0.6452\n",
      "[244/1762] D loss: 1.3352, G loss: 0.7084\n",
      "[324/1762] D loss: 1.3900, G loss: 0.7895\n",
      "[404/1762] D loss: 1.3909, G loss: 0.7053\n",
      "[484/1762] D loss: 1.3879, G loss: 0.6782\n",
      "[564/1762] D loss: 1.3099, G loss: 0.7026\n",
      "[644/1762] D loss: 1.3373, G loss: 0.7212\n",
      "[724/1762] D loss: 1.3888, G loss: 0.7311\n",
      "[804/1762] D loss: 1.3041, G loss: 0.6884\n",
      "[884/1762] D loss: 1.5411, G loss: 0.7966\n",
      "[964/1762] D loss: 1.3916, G loss: 0.6684\n",
      "[1044/1762] D loss: 1.4007, G loss: 0.6550\n",
      "[1124/1762] D loss: 1.3925, G loss: 0.6319\n",
      "[1204/1762] D loss: 1.3085, G loss: 0.7840\n",
      "[1284/1762] D loss: 1.3275, G loss: 0.6971\n",
      "[1364/1762] D loss: 1.4088, G loss: 0.8231\n",
      "[1444/1762] D loss: 1.3883, G loss: 0.6946\n",
      "[1524/1762] D loss: 1.3930, G loss: 0.7548\n",
      "[1604/1762] D loss: 1.3896, G loss: 0.6510\n",
      "[1684/1762] D loss: 1.4024, G loss: 0.6442\n",
      "[1762/1762] D loss: 1.3930, G loss: 0.6573\n",
      "train error: \n",
      " D loss: 1.361763, G loss: 0.683506, D accuracy: 52.3%, cell accuracy: 99.8%, board accuracy: 77.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.357756, G loss: 0.686277, D accuracy: 53.2%, cell accuracy: 99.7%, board accuracy: 74.3% \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3962, G loss: 0.6653\n",
      "[84/1762] D loss: 1.5083, G loss: 0.9226\n",
      "[164/1762] D loss: 1.3881, G loss: 0.7328\n",
      "[244/1762] D loss: 1.3762, G loss: 0.7347\n",
      "[324/1762] D loss: 1.3992, G loss: 0.7485\n",
      "[404/1762] D loss: 1.3493, G loss: 0.7314\n",
      "[484/1762] D loss: 1.3994, G loss: 0.6715\n",
      "[564/1762] D loss: 1.4394, G loss: 0.8932\n",
      "[644/1762] D loss: 1.3858, G loss: 0.6302\n",
      "[724/1762] D loss: 1.3433, G loss: 0.7736\n",
      "[804/1762] D loss: 1.3524, G loss: 0.7532\n",
      "[884/1762] D loss: 1.3599, G loss: 0.8248\n",
      "[964/1762] D loss: 1.3474, G loss: 0.7463\n",
      "[1044/1762] D loss: 1.2268, G loss: 0.7276\n",
      "[1124/1762] D loss: 1.3868, G loss: 0.7323\n",
      "[1204/1762] D loss: 1.0500, G loss: 0.8339\n",
      "[1284/1762] D loss: 1.2374, G loss: 0.7097\n",
      "[1364/1762] D loss: 1.0661, G loss: 0.7691\n",
      "[1444/1762] D loss: 1.2385, G loss: 0.7170\n",
      "[1524/1762] D loss: 1.0873, G loss: 0.8549\n",
      "[1604/1762] D loss: 1.3913, G loss: 0.6908\n",
      "[1684/1762] D loss: 1.3888, G loss: 0.6914\n",
      "[1762/1762] D loss: 1.3885, G loss: 0.7109\n",
      "train error: \n",
      " D loss: 1.348206, G loss: 0.789952, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 89.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.336927, G loss: 0.794264, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0458, G loss: 0.8775\n",
      "[84/1762] D loss: 1.2045, G loss: 0.8243\n",
      "[164/1762] D loss: 1.3943, G loss: 0.7760\n",
      "[244/1762] D loss: 1.3914, G loss: 0.6868\n",
      "[324/1762] D loss: 1.0326, G loss: 0.9527\n",
      "[404/1762] D loss: 1.3914, G loss: 0.6645\n",
      "[484/1762] D loss: 1.3900, G loss: 0.7180\n",
      "[564/1762] D loss: 1.3207, G loss: 0.7276\n",
      "[644/1762] D loss: 1.2085, G loss: 0.8077\n",
      "[724/1762] D loss: 1.3937, G loss: 0.6566\n",
      "[804/1762] D loss: 1.3905, G loss: 0.7554\n",
      "[884/1762] D loss: 1.4067, G loss: 0.7406\n",
      "[964/1762] D loss: 1.3878, G loss: 0.7278\n",
      "[1044/1762] D loss: 1.1864, G loss: 0.7802\n",
      "[1124/1762] D loss: 1.1932, G loss: 0.8614\n",
      "[1204/1762] D loss: 1.3885, G loss: 0.6812\n",
      "[1284/1762] D loss: 1.3936, G loss: 0.7080\n",
      "[1364/1762] D loss: 1.3909, G loss: 0.7168\n",
      "[1444/1762] D loss: 1.3931, G loss: 0.7978\n",
      "[1524/1762] D loss: 1.3900, G loss: 0.7196\n",
      "[1604/1762] D loss: 1.3935, G loss: 0.7804\n",
      "[1684/1762] D loss: 1.3953, G loss: 0.6558\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.7094\n",
      "train error: \n",
      " D loss: 1.336053, G loss: 0.737182, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.321524, G loss: 0.743329, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4096, G loss: 0.7735\n",
      "[84/1762] D loss: 1.1918, G loss: 0.8616\n",
      "[164/1762] D loss: 1.3941, G loss: 0.6397\n",
      "[244/1762] D loss: 1.1371, G loss: 0.8910\n",
      "[324/1762] D loss: 1.4277, G loss: 0.8416\n",
      "[404/1762] D loss: 1.1712, G loss: 0.8005\n",
      "[484/1762] D loss: 1.0643, G loss: 0.7910\n",
      "[564/1762] D loss: 1.1576, G loss: 0.9029\n",
      "[644/1762] D loss: 1.3896, G loss: 0.7620\n",
      "[724/1762] D loss: 1.3962, G loss: 0.6955\n",
      "[804/1762] D loss: 1.4029, G loss: 0.7393\n",
      "[884/1762] D loss: 1.1739, G loss: 0.8330\n",
      "[964/1762] D loss: 1.1758, G loss: 0.8049\n",
      "[1044/1762] D loss: 1.4012, G loss: 0.6933\n",
      "[1124/1762] D loss: 1.3979, G loss: 0.7704\n",
      "[1204/1762] D loss: 1.4132, G loss: 0.8251\n",
      "[1284/1762] D loss: 0.9506, G loss: 0.9326\n",
      "[1364/1762] D loss: 1.4025, G loss: 0.5940\n",
      "[1444/1762] D loss: 1.6059, G loss: 0.7515\n",
      "[1524/1762] D loss: 1.6030, G loss: 0.4438\n",
      "[1604/1762] D loss: 1.5976, G loss: 0.6702\n",
      "[1684/1762] D loss: 1.3304, G loss: 0.7031\n",
      "[1762/1762] D loss: 0.9787, G loss: 0.8794\n",
      "train error: \n",
      " D loss: 1.060597, G loss: 0.939498, D accuracy: 84.6%, cell accuracy: 98.5%, board accuracy: 16.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.080875, G loss: 0.947508, D accuracy: 82.6%, cell accuracy: 98.5%, board accuracy: 16.8% \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Unfreeze after 50 epochs as that seems to be when a discriminator with learning rate 1e-4 starts to tell the difference between block spawns and other types of cells.\n",
    "train(run_name=\"freeze_glob_50_epochs\", frozen_epochs=50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temporarily freezing the `glob` module doesn't improve the board accuracy or its stability.\n",
    "\n",
    "In the discriminator score histograms, we no longer see a separate peak around 0.0 / 1.0, which suggests that freezing the `glob` module of the generator hampers its ability to learn, so it no longer forces the discriminator to learn as much. Perhaps this is because the activations from the `glob` module act like noise which \"confuses\" the generator. We could avoid this by setting all the `glob` activations to be zero when the module is frozen.\n",
    "\n",
    "Interestingly, the generator has no zero gradients at all when the `glob` module is frozen. It only starts having zero gradients when the `glob` module is unfrozen. The discriminator seems to have a large number of zero gradients for the start and the number barely changes (even without freezing the generator `glob` module), which suggests that the discriminator could benefit from a different weight initialization scheme to minimise the number of zero gradients at the start of the training run."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Freeze and zero activation\n",
    "\n",
    "When we freeze the `glob` module, we're also going to set the activations to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TetrisModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.loc = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.glob = nn.Sequential(\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(160, 10)\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Conv2d(26, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 2, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        self.glob_frozen = False\n",
    "\n",
    "    def forward(self, x, z):\n",
    "        batch_size, channels, height, width = x.shape\n",
    "        \n",
    "        z = z[:, :, None, None] # Expand dims to match x\n",
    "        z = z.repeat(1, 1, height, width) # Upscale to image size\n",
    "        x = torch.cat((x, z), dim=1)\n",
    "\n",
    "        x = self.loc(x)\n",
    "\n",
    "        if self.glob_frozen:\n",
    "            x_glob = torch.zeros(batch_size, 10, height, width)\n",
    "        else:\n",
    "            x_glob = self.glob(x)\n",
    "            x_glob = x_glob[:, :, None, None] # Expand dims\n",
    "            x_glob = x_glob.repeat(1, 1, height, width) # Upscale to image size\n",
    "\n",
    "        x = torch.cat((x, x_glob), dim=1)\n",
    "\n",
    "        y = self.head(x)\n",
    "        return y\n",
    "    \n",
    "    def freeze_glob(self):\n",
    "        self.glob.requires_grad_(False)\n",
    "        self.glob_frozen = True\n",
    "\n",
    "    def unfreeze_glob(self):\n",
    "        self.glob.requires_grad_(True)\n",
    "        self.glob_frozen = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(run_name=\"\", learning_rate=1e-4, epochs=100, frozen_epochs=0):\n",
    "    gen = TetrisModel().to(device)\n",
    "    gen.freeze_glob()\n",
    "    disc = TetrisDiscriminator().to(device)\n",
    "\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer_gen = torch.optim.Adam(gen.parameters(), lr=learning_rate)\n",
    "    optimizer_disc = torch.optim.Adam(disc.parameters(), lr=learning_rate)\n",
    "\n",
    "    log_dir = os.path.join(\"runs\", \"experiment_023\")\n",
    "    log_subdir = os.path.join(log_dir, run_name + \"_\" + datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"))\n",
    "    tb_writer = SummaryWriter(log_subdir)\n",
    "\n",
    "    train_examples = find_interesting_examples(train_dataset)\n",
    "    test_examples = find_interesting_examples(test_dataset)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch}\\n-------------------------------\")\n",
    "        if epoch == frozen_epochs:\n",
    "            gen.unfreeze_glob()\n",
    "        train_loop(train_dataloader, gen, disc, loss_fn, optimizer_gen, optimizer_disc)\n",
    "        test_loop(\"train\", train_dataloader, gen, disc, loss_fn, tb_writer, epoch, train_examples)\n",
    "        test_loop(\"test\", test_dataloader, gen, disc, loss_fn, tb_writer, epoch, test_examples)\n",
    "        gen_zero_grads = 0\n",
    "        for name, weight in gen.named_parameters():\n",
    "            tb_writer.add_histogram(f\"Weights/{name}\", weight, epoch)\n",
    "            if weight.grad is not None:\n",
    "                tb_writer.add_histogram(f\"Gradients/{name}\", weight.grad, epoch)\n",
    "                gen_zero_grads += weight.grad.numel() - weight.grad.count_nonzero().item()\n",
    "        tb_writer.add_scalar(f\"Zero gradients\", gen_zero_grads, epoch)\n",
    "        disc_zero_grads = 0\n",
    "        for name, weight in disc.named_parameters():\n",
    "            tb_writer.add_histogram(f\"Discriminator weights/{name}\", weight, epoch)\n",
    "            tb_writer.add_histogram(f\"Discriminator gradients/{name}\", weight.grad, epoch)\n",
    "            disc_zero_grads += weight.grad.numel() - weight.grad.count_nonzero().item()\n",
    "        tb_writer.add_scalar(f\"Discriminator zero gradients\", disc_zero_grads, epoch)\n",
    "\n",
    "    tb_writer.close()\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4068, G loss: 0.5629\n",
      "[84/1762] D loss: 1.3982, G loss: 0.5750\n",
      "[164/1762] D loss: 1.3865, G loss: 0.5861\n",
      "[244/1762] D loss: 1.3771, G loss: 0.5956\n",
      "[324/1762] D loss: 1.3663, G loss: 0.6037\n",
      "[404/1762] D loss: 1.3463, G loss: 0.6135\n",
      "[484/1762] D loss: 1.2974, G loss: 0.6456\n",
      "[564/1762] D loss: 1.2405, G loss: 0.6611\n",
      "[644/1762] D loss: 1.1912, G loss: 0.7521\n",
      "[724/1762] D loss: 1.0760, G loss: 0.8288\n",
      "[804/1762] D loss: 0.9780, G loss: 0.8973\n",
      "[884/1762] D loss: 0.8278, G loss: 1.1957\n",
      "[964/1762] D loss: 0.7280, G loss: 1.2265\n",
      "[1044/1762] D loss: 0.5631, G loss: 1.3184\n",
      "[1124/1762] D loss: 0.5320, G loss: 1.6420\n",
      "[1204/1762] D loss: 0.4743, G loss: 1.8135\n",
      "[1284/1762] D loss: 0.4994, G loss: 1.5267\n",
      "[1364/1762] D loss: 0.6006, G loss: 1.2240\n",
      "[1444/1762] D loss: 0.3987, G loss: 1.7015\n",
      "[1524/1762] D loss: 0.3345, G loss: 2.1064\n",
      "[1604/1762] D loss: 0.3849, G loss: 1.5596\n",
      "[1684/1762] D loss: 0.3055, G loss: 1.9586\n",
      "[1762/1762] D loss: 0.3826, G loss: 1.9314\n",
      "train error: \n",
      " D loss: 0.341756, G loss: 2.011349, D accuracy: 100.0%, cell accuracy: 95.4%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.342894, G loss: 2.010594, D accuracy: 100.0%, cell accuracy: 95.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3128, G loss: 2.1421\n",
      "[84/1762] D loss: 0.3191, G loss: 1.8525\n",
      "[164/1762] D loss: 0.3625, G loss: 1.4802\n",
      "[244/1762] D loss: 0.2570, G loss: 2.4579\n",
      "[324/1762] D loss: 0.2548, G loss: 2.0879\n",
      "[404/1762] D loss: 0.3361, G loss: 1.9073\n",
      "[484/1762] D loss: 0.3527, G loss: 2.2021\n",
      "[564/1762] D loss: 0.3048, G loss: 2.0661\n",
      "[644/1762] D loss: 0.3736, G loss: 1.8413\n",
      "[724/1762] D loss: 0.3394, G loss: 2.2726\n",
      "[804/1762] D loss: 0.4416, G loss: 2.2433\n",
      "[884/1762] D loss: 0.3242, G loss: 2.6024\n",
      "[964/1762] D loss: 0.3424, G loss: 1.6569\n",
      "[1044/1762] D loss: 0.3486, G loss: 1.7607\n",
      "[1124/1762] D loss: 0.3622, G loss: 1.5689\n",
      "[1204/1762] D loss: 0.5584, G loss: 1.0102\n",
      "[1284/1762] D loss: 0.4939, G loss: 1.5043\n",
      "[1364/1762] D loss: 0.3614, G loss: 1.8606\n",
      "[1444/1762] D loss: 0.3781, G loss: 2.0625\n",
      "[1524/1762] D loss: 0.5512, G loss: 2.0666\n",
      "[1604/1762] D loss: 0.3382, G loss: 2.2297\n",
      "[1684/1762] D loss: 0.4570, G loss: 2.1841\n",
      "[1762/1762] D loss: 0.3274, G loss: 2.1922\n",
      "train error: \n",
      " D loss: 0.476235, G loss: 1.528618, D accuracy: 98.6%, cell accuracy: 97.2%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.475831, G loss: 1.552310, D accuracy: 98.2%, cell accuracy: 97.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4055, G loss: 1.7077\n",
      "[84/1762] D loss: 0.5216, G loss: 1.4090\n",
      "[164/1762] D loss: 0.4452, G loss: 1.8297\n",
      "[244/1762] D loss: 0.5556, G loss: 1.8376\n",
      "[324/1762] D loss: 0.4008, G loss: 2.5675\n",
      "[404/1762] D loss: 0.4274, G loss: 1.4967\n",
      "[484/1762] D loss: 0.5866, G loss: 1.8134\n",
      "[564/1762] D loss: 0.6326, G loss: 2.2831\n",
      "[644/1762] D loss: 0.6227, G loss: 1.3171\n",
      "[724/1762] D loss: 0.4640, G loss: 2.1743\n",
      "[804/1762] D loss: 0.5917, G loss: 1.4175\n",
      "[884/1762] D loss: 0.5270, G loss: 1.9462\n",
      "[964/1762] D loss: 0.8191, G loss: 1.5346\n",
      "[1044/1762] D loss: 0.9212, G loss: 1.6462\n",
      "[1124/1762] D loss: 0.7420, G loss: 1.0162\n",
      "[1204/1762] D loss: 0.7674, G loss: 1.1882\n",
      "[1284/1762] D loss: 1.0900, G loss: 0.8714\n",
      "[1364/1762] D loss: 0.6544, G loss: 1.4435\n",
      "[1444/1762] D loss: 0.5909, G loss: 1.0855\n",
      "[1524/1762] D loss: 0.5610, G loss: 1.2984\n",
      "[1604/1762] D loss: 0.7746, G loss: 1.3358\n",
      "[1684/1762] D loss: 0.6156, G loss: 1.3699\n",
      "[1762/1762] D loss: 0.5129, G loss: 0.9156\n",
      "train error: \n",
      " D loss: 0.889264, G loss: 0.902600, D accuracy: 78.4%, cell accuracy: 98.1%, board accuracy: 2.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.911478, G loss: 0.944149, D accuracy: 76.7%, cell accuracy: 98.1%, board accuracy: 3.6% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7779, G loss: 0.8511\n",
      "[84/1762] D loss: 0.7074, G loss: 1.3326\n",
      "[164/1762] D loss: 0.7836, G loss: 1.9053\n",
      "[244/1762] D loss: 0.9354, G loss: 2.2583\n",
      "[324/1762] D loss: 0.9703, G loss: 0.9386\n",
      "[404/1762] D loss: 0.7937, G loss: 0.9344\n",
      "[484/1762] D loss: 1.6773, G loss: 0.4579\n",
      "[564/1762] D loss: 0.8612, G loss: 1.3853\n",
      "[644/1762] D loss: 0.6306, G loss: 1.3949\n",
      "[724/1762] D loss: 0.8206, G loss: 0.9365\n",
      "[804/1762] D loss: 1.0032, G loss: 1.2630\n",
      "[884/1762] D loss: 0.8864, G loss: 1.0940\n",
      "[964/1762] D loss: 1.1814, G loss: 0.9954\n",
      "[1044/1762] D loss: 1.3405, G loss: 1.4751\n",
      "[1124/1762] D loss: 1.0486, G loss: 1.2639\n",
      "[1204/1762] D loss: 0.9913, G loss: 1.1213\n",
      "[1284/1762] D loss: 0.7413, G loss: 1.1617\n",
      "[1364/1762] D loss: 1.0064, G loss: 0.8226\n",
      "[1444/1762] D loss: 1.0525, G loss: 0.9709\n",
      "[1524/1762] D loss: 1.0693, G loss: 1.4043\n",
      "[1604/1762] D loss: 0.9726, G loss: 0.7981\n",
      "[1684/1762] D loss: 0.9949, G loss: 1.1140\n",
      "[1762/1762] D loss: 1.1445, G loss: 1.2655\n",
      "train error: \n",
      " D loss: 1.100675, G loss: 0.984631, D accuracy: 71.8%, cell accuracy: 98.8%, board accuracy: 11.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.115430, G loss: 1.043138, D accuracy: 73.6%, cell accuracy: 98.7%, board accuracy: 11.6% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2012, G loss: 0.8936\n",
      "[84/1762] D loss: 1.0115, G loss: 0.9778\n",
      "[164/1762] D loss: 1.2645, G loss: 1.0513\n",
      "[244/1762] D loss: 1.2294, G loss: 1.2618\n",
      "[324/1762] D loss: 0.8815, G loss: 0.9496\n",
      "[404/1762] D loss: 1.0262, G loss: 0.7373\n",
      "[484/1762] D loss: 0.9298, G loss: 1.1682\n",
      "[564/1762] D loss: 1.4981, G loss: 1.7427\n",
      "[644/1762] D loss: 0.9328, G loss: 0.9623\n",
      "[724/1762] D loss: 0.9767, G loss: 1.0835\n",
      "[804/1762] D loss: 1.2188, G loss: 0.9516\n",
      "[884/1762] D loss: 1.3571, G loss: 0.6266\n",
      "[964/1762] D loss: 1.1098, G loss: 0.7170\n",
      "[1044/1762] D loss: 1.0659, G loss: 0.7821\n",
      "[1124/1762] D loss: 1.3919, G loss: 1.1389\n",
      "[1204/1762] D loss: 1.1655, G loss: 1.5506\n",
      "[1284/1762] D loss: 1.1339, G loss: 0.8436\n",
      "[1364/1762] D loss: 1.0685, G loss: 1.2551\n",
      "[1444/1762] D loss: 1.3205, G loss: 0.8377\n",
      "[1524/1762] D loss: 1.2187, G loss: 1.1512\n",
      "[1604/1762] D loss: 1.1822, G loss: 0.8719\n",
      "[1684/1762] D loss: 0.9652, G loss: 1.1260\n",
      "[1762/1762] D loss: 1.0766, G loss: 0.9798\n",
      "train error: \n",
      " D loss: 1.336464, G loss: 1.505786, D accuracy: 62.2%, cell accuracy: 98.9%, board accuracy: 19.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.371937, G loss: 1.563098, D accuracy: 61.9%, cell accuracy: 98.8%, board accuracy: 16.6% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.6817, G loss: 1.3212\n",
      "[84/1762] D loss: 1.0948, G loss: 1.3472\n",
      "[164/1762] D loss: 1.1000, G loss: 0.9615\n",
      "[244/1762] D loss: 1.1994, G loss: 1.2831\n",
      "[324/1762] D loss: 1.2530, G loss: 1.3887\n",
      "[404/1762] D loss: 0.9840, G loss: 1.0705\n",
      "[484/1762] D loss: 1.1531, G loss: 0.6982\n",
      "[564/1762] D loss: 1.0568, G loss: 1.4810\n",
      "[644/1762] D loss: 1.2878, G loss: 0.4677\n",
      "[724/1762] D loss: 1.0643, G loss: 0.9722\n",
      "[804/1762] D loss: 1.4472, G loss: 0.5196\n",
      "[884/1762] D loss: 1.1387, G loss: 1.0777\n",
      "[964/1762] D loss: 1.3205, G loss: 0.8224\n",
      "[1044/1762] D loss: 1.1164, G loss: 1.1299\n",
      "[1124/1762] D loss: 1.0905, G loss: 1.0510\n",
      "[1204/1762] D loss: 1.0304, G loss: 0.8641\n",
      "[1284/1762] D loss: 1.1726, G loss: 0.7408\n",
      "[1364/1762] D loss: 1.2082, G loss: 0.8647\n",
      "[1444/1762] D loss: 1.2840, G loss: 0.5788\n",
      "[1524/1762] D loss: 1.7652, G loss: 1.9010\n",
      "[1604/1762] D loss: 1.1808, G loss: 0.8363\n",
      "[1684/1762] D loss: 0.9465, G loss: 0.9852\n",
      "[1762/1762] D loss: 0.9443, G loss: 1.2775\n",
      "train error: \n",
      " D loss: 1.252686, G loss: 1.124510, D accuracy: 66.8%, cell accuracy: 98.9%, board accuracy: 20.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.265413, G loss: 1.163109, D accuracy: 67.6%, cell accuracy: 98.8%, board accuracy: 17.7% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2175, G loss: 1.2387\n",
      "[84/1762] D loss: 1.4349, G loss: 0.7133\n",
      "[164/1762] D loss: 1.0408, G loss: 0.8800\n",
      "[244/1762] D loss: 1.6303, G loss: 1.6601\n",
      "[324/1762] D loss: 1.0412, G loss: 0.8674\n",
      "[404/1762] D loss: 1.3082, G loss: 1.4855\n",
      "[484/1762] D loss: 1.3639, G loss: 0.5056\n",
      "[564/1762] D loss: 1.2225, G loss: 0.6824\n",
      "[644/1762] D loss: 1.4463, G loss: 1.0126\n",
      "[724/1762] D loss: 1.1420, G loss: 1.1611\n",
      "[804/1762] D loss: 1.2156, G loss: 0.6968\n",
      "[884/1762] D loss: 1.5056, G loss: 0.7102\n",
      "[964/1762] D loss: 1.4104, G loss: 0.5788\n",
      "[1044/1762] D loss: 1.0565, G loss: 0.7645\n",
      "[1124/1762] D loss: 1.3541, G loss: 0.3681\n",
      "[1204/1762] D loss: 1.1966, G loss: 1.2401\n",
      "[1284/1762] D loss: 1.2245, G loss: 0.7671\n",
      "[1364/1762] D loss: 1.0124, G loss: 0.9463\n",
      "[1444/1762] D loss: 1.2942, G loss: 1.0442\n",
      "[1524/1762] D loss: 1.2617, G loss: 0.5441\n",
      "[1604/1762] D loss: 1.2254, G loss: 0.7282\n",
      "[1684/1762] D loss: 1.1911, G loss: 0.7375\n",
      "[1762/1762] D loss: 1.2509, G loss: 0.8107\n",
      "train error: \n",
      " D loss: 1.431051, G loss: 0.553845, D accuracy: 57.1%, cell accuracy: 99.0%, board accuracy: 27.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.424757, G loss: 0.579124, D accuracy: 55.2%, cell accuracy: 99.0%, board accuracy: 24.8% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1483, G loss: 0.6571\n",
      "[84/1762] D loss: 1.4476, G loss: 0.7966\n",
      "[164/1762] D loss: 1.6202, G loss: 0.5019\n",
      "[244/1762] D loss: 1.5156, G loss: 1.2609\n",
      "[324/1762] D loss: 1.3047, G loss: 0.5392\n",
      "[404/1762] D loss: 1.3528, G loss: 0.6909\n",
      "[484/1762] D loss: 1.1109, G loss: 0.7363\n",
      "[564/1762] D loss: 1.3280, G loss: 1.2362\n",
      "[644/1762] D loss: 1.2604, G loss: 0.9485\n",
      "[724/1762] D loss: 1.5565, G loss: 1.4209\n",
      "[804/1762] D loss: 1.3488, G loss: 0.6182\n",
      "[884/1762] D loss: 1.3127, G loss: 0.6876\n",
      "[964/1762] D loss: 1.2844, G loss: 0.6865\n",
      "[1044/1762] D loss: 1.1462, G loss: 1.0264\n",
      "[1124/1762] D loss: 1.1970, G loss: 0.7625\n",
      "[1204/1762] D loss: 1.6040, G loss: 1.1382\n",
      "[1284/1762] D loss: 1.2351, G loss: 1.0783\n",
      "[1364/1762] D loss: 1.3581, G loss: 0.7255\n",
      "[1444/1762] D loss: 1.2983, G loss: 0.7636\n",
      "[1524/1762] D loss: 1.4525, G loss: 0.5910\n",
      "[1604/1762] D loss: 1.3359, G loss: 0.6034\n",
      "[1684/1762] D loss: 1.6513, G loss: 1.4391\n",
      "[1762/1762] D loss: 1.2883, G loss: 0.6317\n",
      "train error: \n",
      " D loss: 1.353570, G loss: 0.742585, D accuracy: 59.2%, cell accuracy: 99.1%, board accuracy: 35.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.349665, G loss: 0.763020, D accuracy: 59.5%, cell accuracy: 99.1%, board accuracy: 30.0% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4433, G loss: 0.6429\n",
      "[84/1762] D loss: 1.3320, G loss: 0.9244\n",
      "[164/1762] D loss: 1.2853, G loss: 0.7741\n",
      "[244/1762] D loss: 1.3530, G loss: 0.6886\n",
      "[324/1762] D loss: 1.4305, G loss: 0.9166\n",
      "[404/1762] D loss: 1.3665, G loss: 0.6345\n",
      "[484/1762] D loss: 1.6359, G loss: 0.7316\n",
      "[564/1762] D loss: 1.1872, G loss: 0.8096\n",
      "[644/1762] D loss: 1.3293, G loss: 0.8835\n",
      "[724/1762] D loss: 1.2424, G loss: 0.7898\n",
      "[804/1762] D loss: 1.3017, G loss: 0.6592\n",
      "[884/1762] D loss: 1.5186, G loss: 0.6829\n",
      "[964/1762] D loss: 1.6333, G loss: 0.8618\n",
      "[1044/1762] D loss: 1.3511, G loss: 0.6757\n",
      "[1124/1762] D loss: 1.4060, G loss: 0.9218\n",
      "[1204/1762] D loss: 1.3186, G loss: 0.7121\n",
      "[1284/1762] D loss: 1.3462, G loss: 0.5324\n",
      "[1364/1762] D loss: 1.4169, G loss: 0.6324\n",
      "[1444/1762] D loss: 1.2400, G loss: 1.2440\n",
      "[1524/1762] D loss: 1.1389, G loss: 0.8411\n",
      "[1604/1762] D loss: 1.2943, G loss: 1.1374\n",
      "[1684/1762] D loss: 1.2782, G loss: 0.6516\n",
      "[1762/1762] D loss: 1.2583, G loss: 0.6793\n",
      "train error: \n",
      " D loss: 1.363024, G loss: 0.926910, D accuracy: 57.1%, cell accuracy: 99.1%, board accuracy: 36.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.366358, G loss: 0.947060, D accuracy: 58.9%, cell accuracy: 99.1%, board accuracy: 33.0% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3451, G loss: 0.9685\n",
      "[84/1762] D loss: 1.3899, G loss: 0.6402\n",
      "[164/1762] D loss: 1.2541, G loss: 0.8824\n",
      "[244/1762] D loss: 1.4059, G loss: 0.8361\n",
      "[324/1762] D loss: 1.3578, G loss: 0.8982\n",
      "[404/1762] D loss: 1.2470, G loss: 0.8586\n",
      "[484/1762] D loss: 1.3483, G loss: 0.7294\n",
      "[564/1762] D loss: 1.4749, G loss: 0.7856\n",
      "[644/1762] D loss: 1.2646, G loss: 0.8076\n",
      "[724/1762] D loss: 1.3488, G loss: 0.8620\n",
      "[804/1762] D loss: 1.3445, G loss: 0.5889\n",
      "[884/1762] D loss: 1.2635, G loss: 0.7580\n",
      "[964/1762] D loss: 1.3723, G loss: 0.9132\n",
      "[1044/1762] D loss: 1.2818, G loss: 0.7557\n",
      "[1124/1762] D loss: 1.5258, G loss: 1.3379\n",
      "[1204/1762] D loss: 1.5172, G loss: 1.1665\n",
      "[1284/1762] D loss: 1.3844, G loss: 0.9673\n",
      "[1364/1762] D loss: 1.3867, G loss: 0.5609\n",
      "[1444/1762] D loss: 1.2115, G loss: 0.8855\n",
      "[1524/1762] D loss: 1.3476, G loss: 0.7278\n",
      "[1604/1762] D loss: 1.2625, G loss: 0.7677\n",
      "[1684/1762] D loss: 1.3223, G loss: 0.7522\n",
      "[1762/1762] D loss: 1.3466, G loss: 0.8944\n",
      "train error: \n",
      " D loss: 1.370608, G loss: 0.985931, D accuracy: 56.8%, cell accuracy: 99.2%, board accuracy: 37.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.377057, G loss: 0.996664, D accuracy: 58.1%, cell accuracy: 99.1%, board accuracy: 33.4% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3528, G loss: 0.8195\n",
      "[84/1762] D loss: 1.1759, G loss: 0.7788\n",
      "[164/1762] D loss: 1.3235, G loss: 1.0296\n",
      "[244/1762] D loss: 1.3402, G loss: 0.6760\n",
      "[324/1762] D loss: 1.3077, G loss: 1.1036\n",
      "[404/1762] D loss: 1.4836, G loss: 0.7139\n",
      "[484/1762] D loss: 1.3625, G loss: 0.8158\n",
      "[564/1762] D loss: 1.2485, G loss: 0.7550\n",
      "[644/1762] D loss: 1.2281, G loss: 0.7988\n",
      "[724/1762] D loss: 1.3789, G loss: 1.0359\n",
      "[804/1762] D loss: 1.3057, G loss: 1.0429\n",
      "[884/1762] D loss: 1.3766, G loss: 0.8453\n",
      "[964/1762] D loss: 1.2184, G loss: 0.5137\n",
      "[1044/1762] D loss: 1.3230, G loss: 0.9446\n",
      "[1124/1762] D loss: 1.4033, G loss: 0.4784\n",
      "[1204/1762] D loss: 1.2910, G loss: 0.8732\n",
      "[1284/1762] D loss: 1.2147, G loss: 0.7880\n",
      "[1364/1762] D loss: 1.3551, G loss: 0.7203\n",
      "[1444/1762] D loss: 1.3797, G loss: 0.7028\n",
      "[1524/1762] D loss: 1.4257, G loss: 0.5946\n",
      "[1604/1762] D loss: 1.3934, G loss: 0.7970\n",
      "[1684/1762] D loss: 1.3741, G loss: 1.0493\n",
      "[1762/1762] D loss: 1.3404, G loss: 0.7792\n",
      "train error: \n",
      " D loss: 1.329611, G loss: 0.824535, D accuracy: 59.1%, cell accuracy: 99.2%, board accuracy: 45.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.331481, G loss: 0.833042, D accuracy: 59.3%, cell accuracy: 99.2%, board accuracy: 40.2% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3078, G loss: 0.7239\n",
      "[84/1762] D loss: 1.3522, G loss: 0.6679\n",
      "[164/1762] D loss: 1.3841, G loss: 0.6785\n",
      "[244/1762] D loss: 1.2382, G loss: 0.7241\n",
      "[324/1762] D loss: 1.3214, G loss: 0.8850\n",
      "[404/1762] D loss: 1.4308, G loss: 0.9034\n",
      "[484/1762] D loss: 1.3682, G loss: 0.9010\n",
      "[564/1762] D loss: 1.4076, G loss: 0.5826\n",
      "[644/1762] D loss: 1.2432, G loss: 0.8208\n",
      "[724/1762] D loss: 1.4737, G loss: 0.5140\n",
      "[804/1762] D loss: 1.3545, G loss: 1.0638\n",
      "[884/1762] D loss: 1.3459, G loss: 0.7443\n",
      "[964/1762] D loss: 1.1248, G loss: 0.8346\n",
      "[1044/1762] D loss: 1.3066, G loss: 0.5952\n",
      "[1124/1762] D loss: 1.3191, G loss: 0.8419\n",
      "[1204/1762] D loss: 1.6123, G loss: 0.3646\n",
      "[1284/1762] D loss: 1.4073, G loss: 0.7426\n",
      "[1364/1762] D loss: 1.2876, G loss: 0.6174\n",
      "[1444/1762] D loss: 1.4665, G loss: 0.7438\n",
      "[1524/1762] D loss: 1.4567, G loss: 0.8180\n",
      "[1604/1762] D loss: 1.2912, G loss: 0.7843\n",
      "[1684/1762] D loss: 1.4103, G loss: 0.8998\n",
      "[1762/1762] D loss: 0.9729, G loss: 1.3232\n",
      "train error: \n",
      " D loss: 1.368455, G loss: 0.809676, D accuracy: 56.3%, cell accuracy: 99.4%, board accuracy: 49.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.366575, G loss: 0.824030, D accuracy: 56.4%, cell accuracy: 99.4%, board accuracy: 46.4% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3884, G loss: 0.8587\n",
      "[84/1762] D loss: 1.3728, G loss: 0.6264\n",
      "[164/1762] D loss: 1.3714, G loss: 0.5713\n",
      "[244/1762] D loss: 1.3724, G loss: 0.7058\n",
      "[324/1762] D loss: 1.3711, G loss: 0.8377\n",
      "[404/1762] D loss: 1.3714, G loss: 0.6417\n",
      "[484/1762] D loss: 1.4799, G loss: 0.8825\n",
      "[564/1762] D loss: 1.4050, G loss: 0.6153\n",
      "[644/1762] D loss: 1.4632, G loss: 0.9479\n",
      "[724/1762] D loss: 1.4917, G loss: 1.0278\n",
      "[804/1762] D loss: 1.3071, G loss: 0.6500\n",
      "[884/1762] D loss: 1.3569, G loss: 0.7238\n",
      "[964/1762] D loss: 1.3224, G loss: 0.6165\n",
      "[1044/1762] D loss: 1.5442, G loss: 0.8335\n",
      "[1124/1762] D loss: 1.5109, G loss: 0.7653\n",
      "[1204/1762] D loss: 1.4400, G loss: 0.6252\n",
      "[1284/1762] D loss: 1.3198, G loss: 0.7334\n",
      "[1364/1762] D loss: 1.4390, G loss: 0.6335\n",
      "[1444/1762] D loss: 1.4888, G loss: 0.7099\n",
      "[1524/1762] D loss: 1.2858, G loss: 0.6950\n",
      "[1604/1762] D loss: 1.3672, G loss: 0.6396\n",
      "[1684/1762] D loss: 1.3315, G loss: 0.8327\n",
      "[1762/1762] D loss: 1.3930, G loss: 0.6022\n",
      "train error: \n",
      " D loss: 1.382879, G loss: 0.628707, D accuracy: 53.5%, cell accuracy: 99.5%, board accuracy: 50.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.375690, G loss: 0.645118, D accuracy: 53.5%, cell accuracy: 99.4%, board accuracy: 47.0% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3972, G loss: 0.7507\n",
      "[84/1762] D loss: 1.3590, G loss: 0.5812\n",
      "[164/1762] D loss: 1.2617, G loss: 0.8212\n",
      "[244/1762] D loss: 1.3831, G loss: 0.6127\n",
      "[324/1762] D loss: 1.3480, G loss: 0.7677\n",
      "[404/1762] D loss: 1.4296, G loss: 0.8017\n",
      "[484/1762] D loss: 1.3682, G loss: 0.6551\n",
      "[564/1762] D loss: 1.3731, G loss: 0.8104\n",
      "[644/1762] D loss: 1.4035, G loss: 0.7111\n",
      "[724/1762] D loss: 1.3846, G loss: 0.7076\n",
      "[804/1762] D loss: 1.4118, G loss: 0.6655\n",
      "[884/1762] D loss: 1.4206, G loss: 0.8266\n",
      "[964/1762] D loss: 1.3606, G loss: 0.7179\n",
      "[1044/1762] D loss: 1.3062, G loss: 0.7016\n",
      "[1124/1762] D loss: 1.4756, G loss: 0.5742\n",
      "[1204/1762] D loss: 1.3723, G loss: 0.9426\n",
      "[1284/1762] D loss: 1.3325, G loss: 0.7166\n",
      "[1364/1762] D loss: 1.3457, G loss: 0.6694\n",
      "[1444/1762] D loss: 1.3598, G loss: 0.7417\n",
      "[1524/1762] D loss: 1.3924, G loss: 0.8082\n",
      "[1604/1762] D loss: 1.3870, G loss: 0.6840\n",
      "[1684/1762] D loss: 1.3702, G loss: 0.7837\n",
      "[1762/1762] D loss: 1.5944, G loss: 0.6193\n",
      "train error: \n",
      " D loss: 1.409588, G loss: 0.600027, D accuracy: 52.3%, cell accuracy: 99.6%, board accuracy: 64.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.411091, G loss: 0.603835, D accuracy: 51.0%, cell accuracy: 99.6%, board accuracy: 62.5% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3646, G loss: 0.6837\n",
      "[84/1762] D loss: 1.4259, G loss: 0.5694\n",
      "[164/1762] D loss: 1.3834, G loss: 0.8205\n",
      "[244/1762] D loss: 1.3851, G loss: 0.6471\n",
      "[324/1762] D loss: 1.3757, G loss: 0.7657\n",
      "[404/1762] D loss: 1.4960, G loss: 0.5292\n",
      "[484/1762] D loss: 1.3570, G loss: 0.6941\n",
      "[564/1762] D loss: 1.3883, G loss: 0.7587\n",
      "[644/1762] D loss: 1.3665, G loss: 0.6953\n",
      "[724/1762] D loss: 1.4275, G loss: 0.5454\n",
      "[804/1762] D loss: 1.5245, G loss: 0.8570\n",
      "[884/1762] D loss: 1.3640, G loss: 0.9822\n",
      "[964/1762] D loss: 1.3900, G loss: 0.6229\n",
      "[1044/1762] D loss: 1.4340, G loss: 0.8531\n",
      "[1124/1762] D loss: 1.4234, G loss: 0.6268\n",
      "[1204/1762] D loss: 1.3893, G loss: 0.7860\n",
      "[1284/1762] D loss: 1.3455, G loss: 0.6758\n",
      "[1364/1762] D loss: 1.4073, G loss: 0.6216\n",
      "[1444/1762] D loss: 1.3912, G loss: 0.6047\n",
      "[1524/1762] D loss: 1.3702, G loss: 0.6604\n",
      "[1604/1762] D loss: 1.3612, G loss: 0.7479\n",
      "[1684/1762] D loss: 1.4004, G loss: 0.7053\n",
      "[1762/1762] D loss: 1.3527, G loss: 0.8312\n",
      "train error: \n",
      " D loss: 1.388856, G loss: 0.750645, D accuracy: 52.6%, cell accuracy: 99.6%, board accuracy: 64.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.389791, G loss: 0.758684, D accuracy: 52.4%, cell accuracy: 99.6%, board accuracy: 63.4% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3931, G loss: 0.7992\n",
      "[84/1762] D loss: 1.4854, G loss: 0.7954\n",
      "[164/1762] D loss: 1.2733, G loss: 0.6568\n",
      "[244/1762] D loss: 1.3589, G loss: 0.7622\n",
      "[324/1762] D loss: 1.4178, G loss: 0.9080\n",
      "[404/1762] D loss: 1.3933, G loss: 0.7167\n",
      "[484/1762] D loss: 1.3746, G loss: 0.7229\n",
      "[564/1762] D loss: 1.4255, G loss: 0.5961\n",
      "[644/1762] D loss: 1.3646, G loss: 0.8971\n",
      "[724/1762] D loss: 1.3558, G loss: 0.5749\n",
      "[804/1762] D loss: 1.3934, G loss: 0.7479\n",
      "[884/1762] D loss: 1.3947, G loss: 0.7028\n",
      "[964/1762] D loss: 1.4115, G loss: 0.6263\n",
      "[1044/1762] D loss: 1.3759, G loss: 0.6111\n",
      "[1124/1762] D loss: 1.3930, G loss: 0.5904\n",
      "[1204/1762] D loss: 1.4011, G loss: 0.8011\n",
      "[1284/1762] D loss: 1.3775, G loss: 0.6921\n",
      "[1364/1762] D loss: 1.3909, G loss: 0.8242\n",
      "[1444/1762] D loss: 1.3825, G loss: 0.7597\n",
      "[1524/1762] D loss: 1.3777, G loss: 0.7512\n",
      "[1604/1762] D loss: 1.4418, G loss: 0.8209\n",
      "[1684/1762] D loss: 1.4052, G loss: 0.7979\n",
      "[1762/1762] D loss: 1.4318, G loss: 0.7300\n",
      "train error: \n",
      " D loss: 1.386052, G loss: 0.674178, D accuracy: 52.8%, cell accuracy: 99.6%, board accuracy: 63.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.386043, G loss: 0.680518, D accuracy: 51.6%, cell accuracy: 99.6%, board accuracy: 61.6% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3883, G loss: 0.6039\n",
      "[84/1762] D loss: 1.3491, G loss: 0.8529\n",
      "[164/1762] D loss: 1.2788, G loss: 0.6728\n",
      "[244/1762] D loss: 1.4500, G loss: 0.5876\n",
      "[324/1762] D loss: 1.3160, G loss: 0.7659\n",
      "[404/1762] D loss: 1.3798, G loss: 0.7568\n",
      "[484/1762] D loss: 1.3430, G loss: 0.7563\n",
      "[564/1762] D loss: 1.4032, G loss: 0.5766\n",
      "[644/1762] D loss: 1.3337, G loss: 0.7236\n",
      "[724/1762] D loss: 1.4043, G loss: 0.9281\n",
      "[804/1762] D loss: 1.4367, G loss: 0.9623\n",
      "[884/1762] D loss: 1.3876, G loss: 0.6213\n",
      "[964/1762] D loss: 1.3907, G loss: 0.8831\n",
      "[1044/1762] D loss: 1.3687, G loss: 0.7520\n",
      "[1124/1762] D loss: 1.3769, G loss: 0.7163\n",
      "[1204/1762] D loss: 1.3301, G loss: 0.6200\n",
      "[1284/1762] D loss: 1.3782, G loss: 0.6776\n",
      "[1364/1762] D loss: 1.3900, G loss: 0.7167\n",
      "[1444/1762] D loss: 1.4077, G loss: 0.6104\n",
      "[1524/1762] D loss: 1.3984, G loss: 0.7531\n",
      "[1604/1762] D loss: 1.3436, G loss: 0.6828\n",
      "[1684/1762] D loss: 1.3840, G loss: 0.8129\n",
      "[1762/1762] D loss: 1.3791, G loss: 0.8109\n",
      "train error: \n",
      " D loss: 1.414190, G loss: 0.923396, D accuracy: 51.0%, cell accuracy: 99.6%, board accuracy: 64.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.413710, G loss: 0.930920, D accuracy: 51.4%, cell accuracy: 99.6%, board accuracy: 63.2% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4230, G loss: 0.9223\n",
      "[84/1762] D loss: 1.4247, G loss: 0.7226\n",
      "[164/1762] D loss: 1.3213, G loss: 0.7671\n",
      "[244/1762] D loss: 1.3444, G loss: 0.9395\n",
      "[324/1762] D loss: 1.4831, G loss: 0.6455\n",
      "[404/1762] D loss: 1.3473, G loss: 0.8564\n",
      "[484/1762] D loss: 1.4132, G loss: 0.8226\n",
      "[564/1762] D loss: 1.3422, G loss: 0.7930\n",
      "[644/1762] D loss: 1.3767, G loss: 0.6907\n",
      "[724/1762] D loss: 1.4056, G loss: 0.6861\n",
      "[804/1762] D loss: 1.4114, G loss: 0.5940\n",
      "[884/1762] D loss: 1.3759, G loss: 0.7789\n",
      "[964/1762] D loss: 1.4138, G loss: 0.6571\n",
      "[1044/1762] D loss: 1.3119, G loss: 0.8784\n",
      "[1124/1762] D loss: 1.3707, G loss: 0.6253\n",
      "[1204/1762] D loss: 1.3108, G loss: 0.7559\n",
      "[1284/1762] D loss: 1.3815, G loss: 0.6769\n",
      "[1364/1762] D loss: 1.3514, G loss: 0.6920\n",
      "[1444/1762] D loss: 1.4588, G loss: 0.5826\n",
      "[1524/1762] D loss: 1.4220, G loss: 0.7635\n",
      "[1604/1762] D loss: 1.4060, G loss: 0.7086\n",
      "[1684/1762] D loss: 1.3283, G loss: 0.6990\n",
      "[1762/1762] D loss: 1.3895, G loss: 0.6906\n",
      "train error: \n",
      " D loss: 1.392920, G loss: 0.851922, D accuracy: 52.3%, cell accuracy: 99.6%, board accuracy: 67.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.390648, G loss: 0.859930, D accuracy: 52.5%, cell accuracy: 99.6%, board accuracy: 66.4% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4068, G loss: 0.9058\n",
      "[84/1762] D loss: 1.3959, G loss: 0.6775\n",
      "[164/1762] D loss: 1.3835, G loss: 0.7184\n",
      "[244/1762] D loss: 1.4807, G loss: 0.4229\n",
      "[324/1762] D loss: 1.3783, G loss: 0.7683\n",
      "[404/1762] D loss: 1.3362, G loss: 0.7088\n",
      "[484/1762] D loss: 1.3865, G loss: 0.6701\n",
      "[564/1762] D loss: 1.3955, G loss: 0.7851\n",
      "[644/1762] D loss: 1.3935, G loss: 0.6849\n",
      "[724/1762] D loss: 1.3868, G loss: 0.7023\n",
      "[804/1762] D loss: 1.3996, G loss: 0.8709\n",
      "[884/1762] D loss: 1.4050, G loss: 0.9174\n",
      "[964/1762] D loss: 1.3749, G loss: 0.7683\n",
      "[1044/1762] D loss: 1.4240, G loss: 0.7208\n",
      "[1124/1762] D loss: 1.3858, G loss: 0.6903\n",
      "[1204/1762] D loss: 1.3908, G loss: 0.7503\n",
      "[1284/1762] D loss: 1.3849, G loss: 0.6608\n",
      "[1364/1762] D loss: 1.4004, G loss: 0.7856\n",
      "[1444/1762] D loss: 1.2709, G loss: 0.7781\n",
      "[1524/1762] D loss: 1.4096, G loss: 0.9085\n",
      "[1604/1762] D loss: 1.4203, G loss: 0.5940\n",
      "[1684/1762] D loss: 1.3053, G loss: 0.7692\n",
      "[1762/1762] D loss: 1.3897, G loss: 0.6296\n",
      "train error: \n",
      " D loss: 1.372390, G loss: 0.712546, D accuracy: 53.7%, cell accuracy: 99.6%, board accuracy: 67.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.368158, G loss: 0.718515, D accuracy: 54.1%, cell accuracy: 99.6%, board accuracy: 65.7% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2951, G loss: 0.7848\n",
      "[84/1762] D loss: 1.3886, G loss: 0.6536\n",
      "[164/1762] D loss: 1.4183, G loss: 0.7962\n",
      "[244/1762] D loss: 1.3264, G loss: 0.6936\n",
      "[324/1762] D loss: 1.3882, G loss: 0.7525\n",
      "[404/1762] D loss: 1.3901, G loss: 0.8175\n",
      "[484/1762] D loss: 1.3681, G loss: 0.6147\n",
      "[564/1762] D loss: 1.3936, G loss: 0.7781\n",
      "[644/1762] D loss: 1.3075, G loss: 0.7804\n",
      "[724/1762] D loss: 1.3800, G loss: 0.7632\n",
      "[804/1762] D loss: 1.3558, G loss: 0.8623\n",
      "[884/1762] D loss: 1.3989, G loss: 0.7394\n",
      "[964/1762] D loss: 1.3923, G loss: 0.6043\n",
      "[1044/1762] D loss: 1.4650, G loss: 0.5428\n",
      "[1124/1762] D loss: 1.3065, G loss: 0.6452\n",
      "[1204/1762] D loss: 1.3033, G loss: 0.7576\n",
      "[1284/1762] D loss: 1.3023, G loss: 0.6951\n",
      "[1364/1762] D loss: 1.2985, G loss: 0.7136\n",
      "[1444/1762] D loss: 1.3138, G loss: 0.7230\n",
      "[1524/1762] D loss: 1.4076, G loss: 0.7429\n",
      "[1604/1762] D loss: 1.3819, G loss: 0.7382\n",
      "[1684/1762] D loss: 1.4002, G loss: 0.7523\n",
      "[1762/1762] D loss: 1.3964, G loss: 0.8598\n",
      "train error: \n",
      " D loss: 1.398255, G loss: 0.916073, D accuracy: 52.5%, cell accuracy: 99.6%, board accuracy: 67.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.394346, G loss: 0.922977, D accuracy: 52.8%, cell accuracy: 99.6%, board accuracy: 65.5% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4371, G loss: 0.8880\n",
      "[84/1762] D loss: 1.3526, G loss: 0.8208\n",
      "[164/1762] D loss: 1.2982, G loss: 0.8611\n",
      "[244/1762] D loss: 1.2709, G loss: 0.8851\n",
      "[324/1762] D loss: 1.3836, G loss: 0.7209\n",
      "[404/1762] D loss: 1.3745, G loss: 0.7139\n",
      "[484/1762] D loss: 1.4106, G loss: 0.7375\n",
      "[564/1762] D loss: 1.4211, G loss: 0.8586\n",
      "[644/1762] D loss: 1.3028, G loss: 0.9431\n",
      "[724/1762] D loss: 1.2526, G loss: 0.7807\n",
      "[804/1762] D loss: 1.4160, G loss: 0.6144\n",
      "[884/1762] D loss: 1.3893, G loss: 0.6975\n",
      "[964/1762] D loss: 1.3964, G loss: 0.7461\n",
      "[1044/1762] D loss: 1.4081, G loss: 0.7871\n",
      "[1124/1762] D loss: 1.4045, G loss: 0.5913\n",
      "[1204/1762] D loss: 1.3858, G loss: 0.7786\n",
      "[1284/1762] D loss: 1.5873, G loss: 0.6013\n",
      "[1364/1762] D loss: 1.5582, G loss: 0.5922\n",
      "[1444/1762] D loss: 1.3990, G loss: 0.7259\n",
      "[1524/1762] D loss: 1.3762, G loss: 0.7516\n",
      "[1604/1762] D loss: 1.2694, G loss: 0.8431\n",
      "[1684/1762] D loss: 1.3132, G loss: 0.6157\n",
      "[1762/1762] D loss: 1.3747, G loss: 0.6532\n",
      "train error: \n",
      " D loss: 1.390607, G loss: 0.740864, D accuracy: 51.0%, cell accuracy: 99.7%, board accuracy: 71.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.389197, G loss: 0.746274, D accuracy: 50.7%, cell accuracy: 99.6%, board accuracy: 68.4% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4170, G loss: 0.6237\n",
      "[84/1762] D loss: 1.4481, G loss: 0.7480\n",
      "[164/1762] D loss: 1.3467, G loss: 0.6740\n",
      "[244/1762] D loss: 1.4106, G loss: 0.7398\n",
      "[324/1762] D loss: 1.4391, G loss: 0.5291\n",
      "[404/1762] D loss: 1.3831, G loss: 0.6475\n",
      "[484/1762] D loss: 1.4229, G loss: 0.7884\n",
      "[564/1762] D loss: 1.3998, G loss: 0.6996\n",
      "[644/1762] D loss: 1.3644, G loss: 0.7580\n",
      "[724/1762] D loss: 1.4569, G loss: 0.5565\n",
      "[804/1762] D loss: 1.4069, G loss: 0.6336\n",
      "[884/1762] D loss: 1.4522, G loss: 0.7992\n",
      "[964/1762] D loss: 1.3887, G loss: 0.7022\n",
      "[1044/1762] D loss: 1.4304, G loss: 0.7943\n",
      "[1124/1762] D loss: 1.3903, G loss: 0.7525\n",
      "[1204/1762] D loss: 1.4107, G loss: 0.8423\n",
      "[1284/1762] D loss: 1.4182, G loss: 0.6909\n",
      "[1364/1762] D loss: 1.3765, G loss: 0.6210\n",
      "[1444/1762] D loss: 1.4075, G loss: 0.7507\n",
      "[1524/1762] D loss: 1.3903, G loss: 0.7306\n",
      "[1604/1762] D loss: 1.3936, G loss: 0.6731\n",
      "[1684/1762] D loss: 1.3921, G loss: 0.6280\n",
      "[1762/1762] D loss: 1.3848, G loss: 0.6689\n",
      "train error: \n",
      " D loss: 1.389037, G loss: 0.695134, D accuracy: 50.8%, cell accuracy: 99.7%, board accuracy: 69.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.386506, G loss: 0.698007, D accuracy: 53.1%, cell accuracy: 99.6%, board accuracy: 68.2% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3051, G loss: 0.6956\n",
      "[84/1762] D loss: 1.3854, G loss: 0.7111\n",
      "[164/1762] D loss: 1.4428, G loss: 0.6845\n",
      "[244/1762] D loss: 1.4181, G loss: 0.6171\n",
      "[324/1762] D loss: 1.3791, G loss: 0.6330\n",
      "[404/1762] D loss: 1.3779, G loss: 0.7158\n",
      "[484/1762] D loss: 1.3558, G loss: 0.6266\n",
      "[564/1762] D loss: 1.3865, G loss: 0.7232\n",
      "[644/1762] D loss: 1.3906, G loss: 0.7068\n",
      "[724/1762] D loss: 1.4071, G loss: 0.7631\n",
      "[804/1762] D loss: 1.4010, G loss: 0.6315\n",
      "[884/1762] D loss: 1.3902, G loss: 0.6720\n",
      "[964/1762] D loss: 1.3898, G loss: 0.7724\n",
      "[1044/1762] D loss: 1.4063, G loss: 0.6099\n",
      "[1124/1762] D loss: 1.3524, G loss: 0.6891\n",
      "[1204/1762] D loss: 1.3846, G loss: 0.7059\n",
      "[1284/1762] D loss: 1.3633, G loss: 0.6653\n",
      "[1364/1762] D loss: 1.3109, G loss: 0.6921\n",
      "[1444/1762] D loss: 1.3513, G loss: 0.6581\n",
      "[1524/1762] D loss: 1.3753, G loss: 0.7220\n",
      "[1604/1762] D loss: 1.4103, G loss: 0.7071\n",
      "[1684/1762] D loss: 1.4144, G loss: 0.6478\n",
      "[1762/1762] D loss: 1.3947, G loss: 0.7331\n",
      "train error: \n",
      " D loss: 1.387590, G loss: 0.765701, D accuracy: 51.2%, cell accuracy: 99.7%, board accuracy: 70.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.386061, G loss: 0.770718, D accuracy: 51.8%, cell accuracy: 99.6%, board accuracy: 69.1% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3783, G loss: 0.7092\n",
      "[84/1762] D loss: 1.3500, G loss: 0.8609\n",
      "[164/1762] D loss: 1.3921, G loss: 0.7247\n",
      "[244/1762] D loss: 1.3964, G loss: 0.5774\n",
      "[324/1762] D loss: 1.3853, G loss: 0.6032\n",
      "[404/1762] D loss: 1.4066, G loss: 0.6842\n",
      "[484/1762] D loss: 1.3876, G loss: 0.6618\n",
      "[564/1762] D loss: 1.3560, G loss: 0.8166\n",
      "[644/1762] D loss: 1.3718, G loss: 0.7303\n",
      "[724/1762] D loss: 1.4033, G loss: 0.6496\n",
      "[804/1762] D loss: 1.3484, G loss: 0.7455\n",
      "[884/1762] D loss: 1.3919, G loss: 0.6365\n",
      "[964/1762] D loss: 1.4183, G loss: 0.6606\n",
      "[1044/1762] D loss: 1.4251, G loss: 0.7462\n",
      "[1124/1762] D loss: 1.4147, G loss: 0.6389\n",
      "[1204/1762] D loss: 1.3473, G loss: 0.8232\n",
      "[1284/1762] D loss: 1.3911, G loss: 0.7367\n",
      "[1364/1762] D loss: 1.3310, G loss: 0.7041\n",
      "[1444/1762] D loss: 1.4414, G loss: 0.7576\n",
      "[1524/1762] D loss: 1.3962, G loss: 0.7227\n",
      "[1604/1762] D loss: 1.3990, G loss: 0.7227\n",
      "[1684/1762] D loss: 1.3977, G loss: 0.7660\n",
      "[1762/1762] D loss: 1.3923, G loss: 0.7120\n",
      "train error: \n",
      " D loss: 1.381200, G loss: 0.761412, D accuracy: 52.0%, cell accuracy: 99.7%, board accuracy: 68.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.378278, G loss: 0.769290, D accuracy: 51.7%, cell accuracy: 99.6%, board accuracy: 66.1% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3935, G loss: 0.7229\n",
      "[84/1762] D loss: 1.4109, G loss: 0.8706\n",
      "[164/1762] D loss: 1.3915, G loss: 0.7266\n",
      "[244/1762] D loss: 1.3429, G loss: 0.6727\n",
      "[324/1762] D loss: 1.3613, G loss: 0.6524\n",
      "[404/1762] D loss: 1.4049, G loss: 0.5974\n",
      "[484/1762] D loss: 1.3200, G loss: 0.7060\n",
      "[564/1762] D loss: 1.3874, G loss: 0.6999\n",
      "[644/1762] D loss: 1.3406, G loss: 0.7155\n",
      "[724/1762] D loss: 1.3989, G loss: 0.6439\n",
      "[804/1762] D loss: 1.3996, G loss: 0.6226\n",
      "[884/1762] D loss: 1.3880, G loss: 0.7023\n",
      "[964/1762] D loss: 1.3993, G loss: 0.6476\n",
      "[1044/1762] D loss: 1.3330, G loss: 0.7320\n",
      "[1124/1762] D loss: 1.3874, G loss: 0.7002\n",
      "[1204/1762] D loss: 1.3184, G loss: 0.7548\n",
      "[1284/1762] D loss: 1.3064, G loss: 0.7204\n",
      "[1364/1762] D loss: 1.4568, G loss: 0.6612\n",
      "[1444/1762] D loss: 1.3396, G loss: 0.7525\n",
      "[1524/1762] D loss: 1.3881, G loss: 0.7367\n",
      "[1604/1762] D loss: 1.3953, G loss: 0.7878\n",
      "[1684/1762] D loss: 1.3138, G loss: 0.6743\n",
      "[1762/1762] D loss: 1.3879, G loss: 0.6930\n",
      "train error: \n",
      " D loss: 1.374944, G loss: 0.668265, D accuracy: 53.1%, cell accuracy: 99.7%, board accuracy: 69.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.369553, G loss: 0.675370, D accuracy: 53.6%, cell accuracy: 99.6%, board accuracy: 68.2% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3392, G loss: 0.7226\n",
      "[84/1762] D loss: 1.3887, G loss: 0.7172\n",
      "[164/1762] D loss: 1.3051, G loss: 0.6739\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6878\n",
      "[324/1762] D loss: 1.4059, G loss: 0.6201\n",
      "[404/1762] D loss: 1.3864, G loss: 0.7048\n",
      "[484/1762] D loss: 1.4501, G loss: 0.6402\n",
      "[564/1762] D loss: 1.3962, G loss: 0.6446\n",
      "[644/1762] D loss: 1.4353, G loss: 0.6120\n",
      "[724/1762] D loss: 1.3883, G loss: 0.6656\n",
      "[804/1762] D loss: 1.2571, G loss: 0.8468\n",
      "[884/1762] D loss: 1.2410, G loss: 0.7418\n",
      "[964/1762] D loss: 1.4091, G loss: 0.6689\n",
      "[1044/1762] D loss: 1.2353, G loss: 0.8134\n",
      "[1124/1762] D loss: 1.2138, G loss: 0.8796\n",
      "[1204/1762] D loss: 1.3888, G loss: 0.6950\n",
      "[1284/1762] D loss: 1.2912, G loss: 0.8170\n",
      "[1364/1762] D loss: 1.3877, G loss: 0.7515\n",
      "[1444/1762] D loss: 1.3096, G loss: 0.8370\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.7431\n",
      "[1604/1762] D loss: 1.2682, G loss: 0.7323\n",
      "[1684/1762] D loss: 1.3881, G loss: 0.7480\n",
      "[1762/1762] D loss: 1.3882, G loss: 0.6842\n",
      "train error: \n",
      " D loss: 1.369924, G loss: 0.752956, D accuracy: 52.0%, cell accuracy: 99.7%, board accuracy: 70.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.364522, G loss: 0.762454, D accuracy: 53.1%, cell accuracy: 99.7%, board accuracy: 69.1% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2318, G loss: 0.8696\n",
      "[84/1762] D loss: 1.3013, G loss: 0.6225\n",
      "[164/1762] D loss: 1.3905, G loss: 0.6853\n",
      "[244/1762] D loss: 1.3956, G loss: 0.7259\n",
      "[324/1762] D loss: 1.4308, G loss: 0.6198\n",
      "[404/1762] D loss: 1.3932, G loss: 0.6275\n",
      "[484/1762] D loss: 1.3851, G loss: 0.7181\n",
      "[564/1762] D loss: 1.4419, G loss: 0.6747\n",
      "[644/1762] D loss: 1.4217, G loss: 0.6189\n",
      "[724/1762] D loss: 1.3061, G loss: 0.6913\n",
      "[804/1762] D loss: 1.2932, G loss: 0.6960\n",
      "[884/1762] D loss: 1.3136, G loss: 0.7188\n",
      "[964/1762] D loss: 1.3839, G loss: 0.6891\n",
      "[1044/1762] D loss: 1.3867, G loss: 0.7986\n",
      "[1124/1762] D loss: 1.3942, G loss: 0.7493\n",
      "[1204/1762] D loss: 1.3912, G loss: 0.6326\n",
      "[1284/1762] D loss: 1.4322, G loss: 0.6861\n",
      "[1364/1762] D loss: 1.3838, G loss: 0.7194\n",
      "[1444/1762] D loss: 1.3897, G loss: 0.6236\n",
      "[1524/1762] D loss: 1.3615, G loss: 0.6957\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.7232\n",
      "[1684/1762] D loss: 1.3916, G loss: 0.7066\n",
      "[1762/1762] D loss: 1.4131, G loss: 0.8287\n",
      "train error: \n",
      " D loss: 1.380561, G loss: 0.724302, D accuracy: 52.8%, cell accuracy: 99.7%, board accuracy: 75.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.379886, G loss: 0.728061, D accuracy: 53.2%, cell accuracy: 99.7%, board accuracy: 73.6% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3674, G loss: 0.7218\n",
      "[84/1762] D loss: 1.3889, G loss: 0.6199\n",
      "[164/1762] D loss: 1.3973, G loss: 0.7201\n",
      "[244/1762] D loss: 1.3993, G loss: 0.7036\n",
      "[324/1762] D loss: 1.3951, G loss: 0.6846\n",
      "[404/1762] D loss: 1.4396, G loss: 0.6887\n",
      "[484/1762] D loss: 1.3888, G loss: 0.7301\n",
      "[564/1762] D loss: 1.3975, G loss: 0.7664\n",
      "[644/1762] D loss: 1.3155, G loss: 0.7390\n",
      "[724/1762] D loss: 1.3557, G loss: 0.7193\n",
      "[804/1762] D loss: 1.3947, G loss: 0.7327\n",
      "[884/1762] D loss: 1.3127, G loss: 0.7570\n",
      "[964/1762] D loss: 1.3736, G loss: 0.6916\n",
      "[1044/1762] D loss: 1.3896, G loss: 0.7600\n",
      "[1124/1762] D loss: 1.3468, G loss: 0.7809\n",
      "[1204/1762] D loss: 1.3359, G loss: 0.7525\n",
      "[1284/1762] D loss: 1.4156, G loss: 0.7275\n",
      "[1364/1762] D loss: 1.3928, G loss: 0.7327\n",
      "[1444/1762] D loss: 1.3883, G loss: 0.6550\n",
      "[1524/1762] D loss: 1.3203, G loss: 0.6730\n",
      "[1604/1762] D loss: 1.4168, G loss: 0.6115\n",
      "[1684/1762] D loss: 1.3952, G loss: 0.6631\n",
      "[1762/1762] D loss: 1.3895, G loss: 0.6406\n",
      "train error: \n",
      " D loss: 1.367975, G loss: 0.659452, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 77.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.364453, G loss: 0.666531, D accuracy: 55.3%, cell accuracy: 99.7%, board accuracy: 74.5% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2970, G loss: 0.8365\n",
      "[84/1762] D loss: 1.3240, G loss: 0.6740\n",
      "[164/1762] D loss: 1.3849, G loss: 0.6561\n",
      "[244/1762] D loss: 1.3035, G loss: 0.8092\n",
      "[324/1762] D loss: 1.4038, G loss: 0.6806\n",
      "[404/1762] D loss: 1.3919, G loss: 0.6875\n",
      "[484/1762] D loss: 1.4393, G loss: 0.5646\n",
      "[564/1762] D loss: 1.3216, G loss: 0.6613\n",
      "[644/1762] D loss: 1.3970, G loss: 0.8049\n",
      "[724/1762] D loss: 1.3589, G loss: 0.7327\n",
      "[804/1762] D loss: 1.3859, G loss: 0.6294\n",
      "[884/1762] D loss: 1.4164, G loss: 0.5768\n",
      "[964/1762] D loss: 1.3934, G loss: 0.6927\n",
      "[1044/1762] D loss: 1.4047, G loss: 0.7290\n",
      "[1124/1762] D loss: 1.3929, G loss: 0.7913\n",
      "[1204/1762] D loss: 1.3993, G loss: 0.7210\n",
      "[1284/1762] D loss: 1.3881, G loss: 0.6983\n",
      "[1364/1762] D loss: 1.3908, G loss: 0.6661\n",
      "[1444/1762] D loss: 1.4203, G loss: 0.6372\n",
      "[1524/1762] D loss: 1.3952, G loss: 0.6627\n",
      "[1604/1762] D loss: 1.3867, G loss: 0.7294\n",
      "[1684/1762] D loss: 1.4057, G loss: 0.6442\n",
      "[1762/1762] D loss: 1.4113, G loss: 0.6581\n",
      "train error: \n",
      " D loss: 1.356460, G loss: 0.725691, D accuracy: 53.5%, cell accuracy: 99.7%, board accuracy: 77.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.351580, G loss: 0.733487, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 73.6% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3957, G loss: 0.7769\n",
      "[84/1762] D loss: 1.3904, G loss: 0.6967\n",
      "[164/1762] D loss: 1.2727, G loss: 0.8955\n",
      "[244/1762] D loss: 1.4402, G loss: 0.7389\n",
      "[324/1762] D loss: 1.4029, G loss: 0.7952\n",
      "[404/1762] D loss: 1.3919, G loss: 0.7029\n",
      "[484/1762] D loss: 1.3989, G loss: 0.7035\n",
      "[564/1762] D loss: 1.3888, G loss: 0.6503\n",
      "[644/1762] D loss: 1.3905, G loss: 0.6968\n",
      "[724/1762] D loss: 1.3381, G loss: 0.8210\n",
      "[804/1762] D loss: 1.3896, G loss: 0.7775\n",
      "[884/1762] D loss: 1.3917, G loss: 0.6902\n",
      "[964/1762] D loss: 1.2459, G loss: 0.7349\n",
      "[1044/1762] D loss: 1.3911, G loss: 0.6906\n",
      "[1124/1762] D loss: 1.2592, G loss: 0.7094\n",
      "[1204/1762] D loss: 1.2491, G loss: 0.7191\n",
      "[1284/1762] D loss: 1.3884, G loss: 0.6379\n",
      "[1364/1762] D loss: 1.4135, G loss: 0.7198\n",
      "[1444/1762] D loss: 1.3420, G loss: 0.7388\n",
      "[1524/1762] D loss: 1.4191, G loss: 0.7798\n",
      "[1604/1762] D loss: 1.3889, G loss: 0.7046\n",
      "[1684/1762] D loss: 1.3888, G loss: 0.7082\n",
      "[1762/1762] D loss: 1.3949, G loss: 0.8163\n",
      "train error: \n",
      " D loss: 1.370803, G loss: 0.889467, D accuracy: 53.4%, cell accuracy: 99.7%, board accuracy: 74.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.363037, G loss: 0.895814, D accuracy: 54.3%, cell accuracy: 99.6%, board accuracy: 71.6% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4050, G loss: 0.8247\n",
      "[84/1762] D loss: 1.4016, G loss: 0.7950\n",
      "[164/1762] D loss: 1.3951, G loss: 0.7081\n",
      "[244/1762] D loss: 1.4038, G loss: 0.6266\n",
      "[324/1762] D loss: 1.3918, G loss: 0.6909\n",
      "[404/1762] D loss: 1.3647, G loss: 0.8684\n",
      "[484/1762] D loss: 1.4129, G loss: 0.8255\n",
      "[564/1762] D loss: 1.3977, G loss: 0.7203\n",
      "[644/1762] D loss: 1.4097, G loss: 0.6022\n",
      "[724/1762] D loss: 1.3906, G loss: 0.6812\n",
      "[804/1762] D loss: 1.3948, G loss: 0.6122\n",
      "[884/1762] D loss: 1.4020, G loss: 0.7052\n",
      "[964/1762] D loss: 1.3946, G loss: 0.5951\n",
      "[1044/1762] D loss: 1.3872, G loss: 0.6647\n",
      "[1124/1762] D loss: 1.3558, G loss: 0.6332\n",
      "[1204/1762] D loss: 1.4585, G loss: 0.7276\n",
      "[1284/1762] D loss: 1.4043, G loss: 0.8492\n",
      "[1364/1762] D loss: 1.3896, G loss: 0.8336\n",
      "[1444/1762] D loss: 1.3999, G loss: 0.7972\n",
      "[1524/1762] D loss: 1.3621, G loss: 0.8530\n",
      "[1604/1762] D loss: 1.2066, G loss: 0.7608\n",
      "[1684/1762] D loss: 1.3988, G loss: 0.6351\n",
      "[1762/1762] D loss: 1.4612, G loss: 0.5112\n",
      "train error: \n",
      " D loss: 1.368758, G loss: 0.577187, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 77.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.359853, G loss: 0.583259, D accuracy: 55.2%, cell accuracy: 99.7%, board accuracy: 74.8% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2339, G loss: 0.7611\n",
      "[84/1762] D loss: 1.4541, G loss: 0.5062\n",
      "[164/1762] D loss: 1.4111, G loss: 0.6387\n",
      "[244/1762] D loss: 1.3876, G loss: 0.6761\n",
      "[324/1762] D loss: 1.3929, G loss: 0.6327\n",
      "[404/1762] D loss: 1.2341, G loss: 0.7407\n",
      "[484/1762] D loss: 1.3931, G loss: 0.7019\n",
      "[564/1762] D loss: 1.7155, G loss: 0.4578\n",
      "[644/1762] D loss: 1.5024, G loss: 0.6346\n",
      "[724/1762] D loss: 1.3212, G loss: 0.7362\n",
      "[804/1762] D loss: 1.5557, G loss: 0.6126\n",
      "[884/1762] D loss: 1.3993, G loss: 0.9470\n",
      "[964/1762] D loss: 1.3432, G loss: 0.7265\n",
      "[1044/1762] D loss: 1.4273, G loss: 0.6082\n",
      "[1124/1762] D loss: 1.4400, G loss: 0.8831\n",
      "[1204/1762] D loss: 1.4325, G loss: 0.6749\n",
      "[1284/1762] D loss: 1.4224, G loss: 0.7753\n",
      "[1364/1762] D loss: 1.4056, G loss: 0.6320\n",
      "[1444/1762] D loss: 1.4155, G loss: 0.7562\n",
      "[1524/1762] D loss: 1.3992, G loss: 0.6829\n",
      "[1604/1762] D loss: 1.3861, G loss: 0.6692\n",
      "[1684/1762] D loss: 1.3951, G loss: 0.6161\n",
      "[1762/1762] D loss: 1.4013, G loss: 0.6882\n",
      "train error: \n",
      " D loss: 1.391945, G loss: 0.612500, D accuracy: 51.3%, cell accuracy: 99.4%, board accuracy: 4.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.393411, G loss: 0.617000, D accuracy: 50.7%, cell accuracy: 99.3%, board accuracy: 2.3% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4137, G loss: 0.6066\n",
      "[84/1762] D loss: 1.4124, G loss: 0.8556\n",
      "[164/1762] D loss: 1.3813, G loss: 0.6422\n",
      "[244/1762] D loss: 1.3874, G loss: 0.7631\n",
      "[324/1762] D loss: 1.3720, G loss: 0.7407\n",
      "[404/1762] D loss: 1.3624, G loss: 0.6114\n",
      "[484/1762] D loss: 1.3622, G loss: 0.7786\n",
      "[564/1762] D loss: 1.3681, G loss: 0.7535\n",
      "[644/1762] D loss: 1.3600, G loss: 0.7066\n",
      "[724/1762] D loss: 1.3193, G loss: 0.7350\n",
      "[804/1762] D loss: 1.3478, G loss: 0.7119\n",
      "[884/1762] D loss: 1.3904, G loss: 0.7456\n",
      "[964/1762] D loss: 1.3911, G loss: 0.6935\n",
      "[1044/1762] D loss: 1.3827, G loss: 0.6735\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.6674\n",
      "[1204/1762] D loss: 1.3755, G loss: 0.7458\n",
      "[1284/1762] D loss: 1.3865, G loss: 0.7008\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6781\n",
      "[1444/1762] D loss: 1.3640, G loss: 0.7400\n",
      "[1524/1762] D loss: 1.3887, G loss: 0.7391\n",
      "[1604/1762] D loss: 1.3856, G loss: 0.7005\n",
      "[1684/1762] D loss: 1.3964, G loss: 0.7523\n",
      "[1762/1762] D loss: 1.3958, G loss: 0.6315\n",
      "train error: \n",
      " D loss: 1.379396, G loss: 0.686946, D accuracy: 53.0%, cell accuracy: 99.8%, board accuracy: 80.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.379021, G loss: 0.693372, D accuracy: 52.3%, cell accuracy: 99.7%, board accuracy: 76.8% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3826, G loss: 0.7354\n",
      "[84/1762] D loss: 1.3232, G loss: 0.6776\n",
      "[164/1762] D loss: 1.3508, G loss: 0.7176\n",
      "[244/1762] D loss: 1.3881, G loss: 0.6923\n",
      "[324/1762] D loss: 1.3815, G loss: 0.7226\n",
      "[404/1762] D loss: 1.3787, G loss: 0.7073\n",
      "[484/1762] D loss: 1.3742, G loss: 0.7297\n",
      "[564/1762] D loss: 1.3874, G loss: 0.6680\n",
      "[644/1762] D loss: 1.3875, G loss: 0.6787\n",
      "[724/1762] D loss: 1.3877, G loss: 0.7148\n",
      "[804/1762] D loss: 1.3201, G loss: 0.6903\n",
      "[884/1762] D loss: 1.3858, G loss: 0.7131\n",
      "[964/1762] D loss: 1.3875, G loss: 0.6864\n",
      "[1044/1762] D loss: 1.3929, G loss: 0.6554\n",
      "[1124/1762] D loss: 1.3901, G loss: 0.6840\n",
      "[1204/1762] D loss: 1.3527, G loss: 0.7668\n",
      "[1284/1762] D loss: 1.3881, G loss: 0.6858\n",
      "[1364/1762] D loss: 1.3429, G loss: 0.6928\n",
      "[1444/1762] D loss: 1.3925, G loss: 0.7725\n",
      "[1524/1762] D loss: 1.4018, G loss: 0.6492\n",
      "[1604/1762] D loss: 1.3858, G loss: 0.6829\n",
      "[1684/1762] D loss: 1.3916, G loss: 0.7114\n",
      "[1762/1762] D loss: 1.3906, G loss: 0.7491\n",
      "train error: \n",
      " D loss: 1.373359, G loss: 0.726608, D accuracy: 52.4%, cell accuracy: 99.8%, board accuracy: 78.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.369650, G loss: 0.736863, D accuracy: 53.6%, cell accuracy: 99.7%, board accuracy: 77.5% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4196, G loss: 0.6911\n",
      "[84/1762] D loss: 1.3896, G loss: 0.6925\n",
      "[164/1762] D loss: 1.3886, G loss: 0.6643\n",
      "[244/1762] D loss: 1.3900, G loss: 0.7343\n",
      "[324/1762] D loss: 1.3837, G loss: 0.7389\n",
      "[404/1762] D loss: 1.3885, G loss: 0.7606\n",
      "[484/1762] D loss: 1.3888, G loss: 0.7067\n",
      "[564/1762] D loss: 1.3183, G loss: 0.7267\n",
      "[644/1762] D loss: 1.4043, G loss: 0.5949\n",
      "[724/1762] D loss: 1.3899, G loss: 0.6942\n",
      "[804/1762] D loss: 1.3944, G loss: 0.6666\n",
      "[884/1762] D loss: 1.3883, G loss: 0.7296\n",
      "[964/1762] D loss: 1.3025, G loss: 0.7658\n",
      "[1044/1762] D loss: 1.3907, G loss: 0.6976\n",
      "[1124/1762] D loss: 1.4037, G loss: 0.6867\n",
      "[1204/1762] D loss: 1.3963, G loss: 0.7747\n",
      "[1284/1762] D loss: 1.3915, G loss: 0.7054\n",
      "[1364/1762] D loss: 1.3813, G loss: 0.7024\n",
      "[1444/1762] D loss: 1.3157, G loss: 0.7459\n",
      "[1524/1762] D loss: 1.3643, G loss: 0.7649\n",
      "[1604/1762] D loss: 1.5586, G loss: 0.6971\n",
      "[1684/1762] D loss: 1.3431, G loss: 0.7964\n",
      "[1762/1762] D loss: 1.3457, G loss: 0.6233\n",
      "train error: \n",
      " D loss: 1.340685, G loss: 0.672194, D accuracy: 56.9%, cell accuracy: 98.9%, board accuracy: 13.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.340324, G loss: 0.684711, D accuracy: 56.4%, cell accuracy: 98.9%, board accuracy: 15.2% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3840, G loss: 0.7105\n",
      "[84/1762] D loss: 1.3880, G loss: 0.7005\n",
      "[164/1762] D loss: 1.3925, G loss: 0.6362\n",
      "[244/1762] D loss: 1.3911, G loss: 0.6540\n",
      "[324/1762] D loss: 1.4040, G loss: 0.7032\n",
      "[404/1762] D loss: 1.3817, G loss: 0.6962\n",
      "[484/1762] D loss: 1.3949, G loss: 0.6945\n",
      "[564/1762] D loss: 1.4003, G loss: 0.6240\n",
      "[644/1762] D loss: 1.3895, G loss: 0.6673\n",
      "[724/1762] D loss: 1.3610, G loss: 0.7637\n",
      "[804/1762] D loss: 1.3699, G loss: 0.6841\n",
      "[884/1762] D loss: 1.3971, G loss: 0.6301\n",
      "[964/1762] D loss: 1.3802, G loss: 0.6978\n",
      "[1044/1762] D loss: 1.3533, G loss: 0.7294\n",
      "[1124/1762] D loss: 1.3923, G loss: 0.7865\n",
      "[1204/1762] D loss: 1.4017, G loss: 0.6447\n",
      "[1284/1762] D loss: 1.3799, G loss: 0.7348\n",
      "[1364/1762] D loss: 1.3893, G loss: 0.6698\n",
      "[1444/1762] D loss: 1.3883, G loss: 0.6941\n",
      "[1524/1762] D loss: 1.3820, G loss: 0.7538\n",
      "[1604/1762] D loss: 1.3858, G loss: 0.6734\n",
      "[1684/1762] D loss: 1.3866, G loss: 0.7084\n",
      "[1762/1762] D loss: 1.3903, G loss: 0.6756\n",
      "train error: \n",
      " D loss: 1.371448, G loss: 0.700605, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 82.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.368697, G loss: 0.708356, D accuracy: 53.6%, cell accuracy: 99.7%, board accuracy: 78.9% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3879, G loss: 0.7092\n",
      "[84/1762] D loss: 1.3143, G loss: 0.7883\n",
      "[164/1762] D loss: 1.2981, G loss: 0.7814\n",
      "[244/1762] D loss: 1.3974, G loss: 0.7940\n",
      "[324/1762] D loss: 1.3791, G loss: 0.6978\n",
      "[404/1762] D loss: 1.3868, G loss: 0.7333\n",
      "[484/1762] D loss: 1.3683, G loss: 0.7369\n",
      "[564/1762] D loss: 1.3716, G loss: 0.6996\n",
      "[644/1762] D loss: 1.3134, G loss: 0.6934\n",
      "[724/1762] D loss: 1.3917, G loss: 0.6528\n",
      "[804/1762] D loss: 1.3887, G loss: 0.7368\n",
      "[884/1762] D loss: 1.3915, G loss: 0.6481\n",
      "[964/1762] D loss: 1.3906, G loss: 0.6808\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6929\n",
      "[1124/1762] D loss: 1.3920, G loss: 0.6983\n",
      "[1204/1762] D loss: 1.2856, G loss: 0.7344\n",
      "[1284/1762] D loss: 1.3936, G loss: 0.7656\n",
      "[1364/1762] D loss: 1.3956, G loss: 0.7572\n",
      "[1444/1762] D loss: 1.3960, G loss: 0.7693\n",
      "[1524/1762] D loss: 1.3911, G loss: 0.7676\n",
      "[1604/1762] D loss: 1.3885, G loss: 0.7729\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.7015\n",
      "[1762/1762] D loss: 1.3907, G loss: 0.6899\n",
      "train error: \n",
      " D loss: 1.360468, G loss: 0.732040, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 86.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.354722, G loss: 0.739896, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 83.4% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3935, G loss: 0.7536\n",
      "[84/1762] D loss: 1.3935, G loss: 0.7566\n",
      "[164/1762] D loss: 1.1882, G loss: 0.7690\n",
      "[244/1762] D loss: 1.3944, G loss: 0.6581\n",
      "[324/1762] D loss: 1.2717, G loss: 0.7043\n",
      "[404/1762] D loss: 1.3892, G loss: 0.7297\n",
      "[484/1762] D loss: 1.3921, G loss: 0.7435\n",
      "[564/1762] D loss: 1.3940, G loss: 0.5995\n",
      "[644/1762] D loss: 1.3928, G loss: 0.6474\n",
      "[724/1762] D loss: 1.2627, G loss: 0.8566\n",
      "[804/1762] D loss: 1.2532, G loss: 0.8753\n",
      "[884/1762] D loss: 1.3921, G loss: 0.7218\n",
      "[964/1762] D loss: 1.3984, G loss: 0.7005\n",
      "[1044/1762] D loss: 1.3867, G loss: 0.6786\n",
      "[1124/1762] D loss: 1.2825, G loss: 0.7100\n",
      "[1204/1762] D loss: 1.3879, G loss: 0.6898\n",
      "[1284/1762] D loss: 1.3910, G loss: 0.6989\n",
      "[1364/1762] D loss: 1.3871, G loss: 0.6823\n",
      "[1444/1762] D loss: 1.3967, G loss: 0.6386\n",
      "[1524/1762] D loss: 1.3872, G loss: 0.7166\n",
      "[1604/1762] D loss: 1.3562, G loss: 0.7889\n",
      "[1684/1762] D loss: 1.2440, G loss: 0.7068\n",
      "[1762/1762] D loss: 1.1234, G loss: 0.8130\n",
      "train error: \n",
      " D loss: 1.353750, G loss: 0.750122, D accuracy: 53.0%, cell accuracy: 99.8%, board accuracy: 82.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.345320, G loss: 0.760626, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 82.0% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.7553\n",
      "[84/1762] D loss: 1.4089, G loss: 0.6214\n",
      "[164/1762] D loss: 1.4125, G loss: 0.6410\n",
      "[244/1762] D loss: 1.3922, G loss: 0.6723\n",
      "[324/1762] D loss: 1.4031, G loss: 0.6754\n",
      "[404/1762] D loss: 1.3957, G loss: 0.8268\n",
      "[484/1762] D loss: 1.3874, G loss: 0.7126\n",
      "[564/1762] D loss: 1.3937, G loss: 0.6971\n",
      "[644/1762] D loss: 1.1130, G loss: 0.8385\n",
      "[724/1762] D loss: 1.2459, G loss: 0.7682\n",
      "[804/1762] D loss: 1.3773, G loss: 0.6522\n",
      "[884/1762] D loss: 1.3884, G loss: 0.7228\n",
      "[964/1762] D loss: 1.3969, G loss: 0.6961\n",
      "[1044/1762] D loss: 1.4117, G loss: 0.5629\n",
      "[1124/1762] D loss: 1.4816, G loss: 0.6277\n",
      "[1204/1762] D loss: 1.3861, G loss: 0.7986\n",
      "[1284/1762] D loss: 1.9262, G loss: 0.4888\n",
      "[1364/1762] D loss: 1.6183, G loss: 0.4703\n",
      "[1444/1762] D loss: 1.3609, G loss: 0.7332\n",
      "[1524/1762] D loss: 1.3071, G loss: 0.6578\n",
      "[1604/1762] D loss: 1.3293, G loss: 0.5731\n",
      "[1684/1762] D loss: 1.5174, G loss: 0.9822\n",
      "[1762/1762] D loss: 1.3539, G loss: 0.7471\n",
      "train error: \n",
      " D loss: 1.408511, G loss: 0.729006, D accuracy: 49.7%, cell accuracy: 99.7%, board accuracy: 79.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.412579, G loss: 0.734678, D accuracy: 48.5%, cell accuracy: 99.7%, board accuracy: 78.4% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4132, G loss: 0.7976\n",
      "[84/1762] D loss: 1.4045, G loss: 0.6525\n",
      "[164/1762] D loss: 1.4081, G loss: 0.8647\n",
      "[244/1762] D loss: 1.3731, G loss: 0.6707\n",
      "[324/1762] D loss: 1.4009, G loss: 0.7001\n",
      "[404/1762] D loss: 1.3947, G loss: 0.7129\n",
      "[484/1762] D loss: 1.3973, G loss: 0.7320\n",
      "[564/1762] D loss: 1.3724, G loss: 0.6975\n",
      "[644/1762] D loss: 1.3760, G loss: 0.7276\n",
      "[724/1762] D loss: 1.3916, G loss: 0.6534\n",
      "[804/1762] D loss: 1.3888, G loss: 0.6642\n",
      "[884/1762] D loss: 1.3911, G loss: 0.6786\n",
      "[964/1762] D loss: 1.3875, G loss: 0.7266\n",
      "[1044/1762] D loss: 1.3927, G loss: 0.6767\n",
      "[1124/1762] D loss: 1.3885, G loss: 0.6287\n",
      "[1204/1762] D loss: 1.3279, G loss: 0.7098\n",
      "[1284/1762] D loss: 1.4025, G loss: 0.6500\n",
      "[1364/1762] D loss: 1.3886, G loss: 0.6918\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.6913\n",
      "[1524/1762] D loss: 1.3200, G loss: 0.7552\n",
      "[1604/1762] D loss: 1.3528, G loss: 0.7761\n",
      "[1684/1762] D loss: 1.3878, G loss: 0.7070\n",
      "[1762/1762] D loss: 1.3860, G loss: 0.6778\n",
      "train error: \n",
      " D loss: 1.374744, G loss: 0.657767, D accuracy: 52.4%, cell accuracy: 99.8%, board accuracy: 85.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.371570, G loss: 0.663800, D accuracy: 52.6%, cell accuracy: 99.8%, board accuracy: 83.2% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3849, G loss: 0.6435\n",
      "[84/1762] D loss: 1.3886, G loss: 0.7127\n",
      "[164/1762] D loss: 1.3871, G loss: 0.7037\n",
      "[244/1762] D loss: 1.3881, G loss: 0.7383\n",
      "[324/1762] D loss: 1.3408, G loss: 0.7207\n",
      "[404/1762] D loss: 1.3764, G loss: 0.6801\n",
      "[484/1762] D loss: 1.3880, G loss: 0.6929\n",
      "[564/1762] D loss: 1.3238, G loss: 0.7444\n",
      "[644/1762] D loss: 1.3906, G loss: 0.7080\n",
      "[724/1762] D loss: 1.3895, G loss: 0.7484\n",
      "[804/1762] D loss: 1.3901, G loss: 0.6360\n",
      "[884/1762] D loss: 1.3871, G loss: 0.6793\n",
      "[964/1762] D loss: 1.3890, G loss: 0.7184\n",
      "[1044/1762] D loss: 1.3904, G loss: 0.7245\n",
      "[1124/1762] D loss: 1.4072, G loss: 0.7043\n",
      "[1204/1762] D loss: 1.3872, G loss: 0.6867\n",
      "[1284/1762] D loss: 1.3857, G loss: 0.7452\n",
      "[1364/1762] D loss: 1.3851, G loss: 0.7426\n",
      "[1444/1762] D loss: 1.2923, G loss: 0.8093\n",
      "[1524/1762] D loss: 1.3839, G loss: 0.7177\n",
      "[1604/1762] D loss: 1.3883, G loss: 0.7181\n",
      "[1684/1762] D loss: 1.4126, G loss: 0.7675\n",
      "[1762/1762] D loss: 1.4596, G loss: 0.6605\n",
      "train error: \n",
      " D loss: 1.367802, G loss: 0.738164, D accuracy: 51.9%, cell accuracy: 99.8%, board accuracy: 83.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.362671, G loss: 0.746416, D accuracy: 52.7%, cell accuracy: 99.8%, board accuracy: 81.4% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2839, G loss: 0.7757\n",
      "[84/1762] D loss: 1.3746, G loss: 0.7426\n",
      "[164/1762] D loss: 1.3008, G loss: 0.7505\n",
      "[244/1762] D loss: 1.3867, G loss: 0.6927\n",
      "[324/1762] D loss: 1.3228, G loss: 0.7123\n",
      "[404/1762] D loss: 1.4340, G loss: 0.8129\n",
      "[484/1762] D loss: 1.2486, G loss: 0.7688\n",
      "[564/1762] D loss: 1.1409, G loss: 0.8112\n",
      "[644/1762] D loss: 1.1709, G loss: 0.8418\n",
      "[724/1762] D loss: 1.4195, G loss: 0.6527\n",
      "[804/1762] D loss: 1.4482, G loss: 0.6260\n",
      "[884/1762] D loss: 1.4014, G loss: 0.6396\n",
      "[964/1762] D loss: 1.3916, G loss: 0.7306\n",
      "[1044/1762] D loss: 1.3987, G loss: 0.6610\n",
      "[1124/1762] D loss: 1.3882, G loss: 0.6669\n",
      "[1204/1762] D loss: 1.4169, G loss: 0.7878\n",
      "[1284/1762] D loss: 1.3911, G loss: 0.6834\n",
      "[1364/1762] D loss: 1.3625, G loss: 0.6775\n",
      "[1444/1762] D loss: 1.3971, G loss: 0.7106\n",
      "[1524/1762] D loss: 1.3887, G loss: 0.7100\n",
      "[1604/1762] D loss: 1.3876, G loss: 0.6353\n",
      "[1684/1762] D loss: 1.3885, G loss: 0.6998\n",
      "[1762/1762] D loss: 1.3228, G loss: 0.7060\n",
      "train error: \n",
      " D loss: 1.381399, G loss: 0.740044, D accuracy: 52.4%, cell accuracy: 99.8%, board accuracy: 83.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.381065, G loss: 0.745804, D accuracy: 52.6%, cell accuracy: 99.7%, board accuracy: 78.9% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3881, G loss: 0.7315\n",
      "[84/1762] D loss: 1.3801, G loss: 0.6748\n",
      "[164/1762] D loss: 1.3871, G loss: 0.6504\n",
      "[244/1762] D loss: 1.3872, G loss: 0.7088\n",
      "[324/1762] D loss: 1.3851, G loss: 0.7459\n",
      "[404/1762] D loss: 1.3105, G loss: 0.7059\n",
      "[484/1762] D loss: 1.3902, G loss: 0.7513\n",
      "[564/1762] D loss: 1.3880, G loss: 0.6848\n",
      "[644/1762] D loss: 1.3879, G loss: 0.6821\n",
      "[724/1762] D loss: 1.3875, G loss: 0.7061\n",
      "[804/1762] D loss: 1.3869, G loss: 0.7191\n",
      "[884/1762] D loss: 1.3894, G loss: 0.6597\n",
      "[964/1762] D loss: 1.3918, G loss: 0.6357\n",
      "[1044/1762] D loss: 1.3929, G loss: 0.7217\n",
      "[1124/1762] D loss: 1.2913, G loss: 0.7570\n",
      "[1204/1762] D loss: 1.3844, G loss: 0.6485\n",
      "[1284/1762] D loss: 1.3850, G loss: 0.7680\n",
      "[1364/1762] D loss: 1.2929, G loss: 0.7357\n",
      "[1444/1762] D loss: 1.3916, G loss: 0.6844\n",
      "[1524/1762] D loss: 1.3701, G loss: 0.6999\n",
      "[1604/1762] D loss: 1.3712, G loss: 0.6721\n",
      "[1684/1762] D loss: 1.3933, G loss: 0.7472\n",
      "[1762/1762] D loss: 1.3903, G loss: 0.6164\n",
      "train error: \n",
      " D loss: 1.368211, G loss: 0.618187, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 85.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.360810, G loss: 0.624965, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 81.6% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2581, G loss: 0.6915\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6510\n",
      "[164/1762] D loss: 1.3888, G loss: 0.6527\n",
      "[244/1762] D loss: 1.2573, G loss: 0.8084\n",
      "[324/1762] D loss: 1.2662, G loss: 0.7684\n",
      "[404/1762] D loss: 1.3832, G loss: 0.7477\n",
      "[484/1762] D loss: 1.2733, G loss: 0.7562\n",
      "[564/1762] D loss: 1.3942, G loss: 0.6631\n",
      "[644/1762] D loss: 1.0125, G loss: 0.9726\n",
      "[724/1762] D loss: 1.2451, G loss: 0.7960\n",
      "[804/1762] D loss: 1.3770, G loss: 0.7427\n",
      "[884/1762] D loss: 1.3884, G loss: 0.6668\n",
      "[964/1762] D loss: 1.4027, G loss: 0.7615\n",
      "[1044/1762] D loss: 1.2546, G loss: 0.6858\n",
      "[1124/1762] D loss: 1.3800, G loss: 0.7175\n",
      "[1204/1762] D loss: 1.2246, G loss: 0.8140\n",
      "[1284/1762] D loss: 1.3835, G loss: 0.7144\n",
      "[1364/1762] D loss: 1.4006, G loss: 0.7653\n",
      "[1444/1762] D loss: 1.2167, G loss: 0.7679\n",
      "[1524/1762] D loss: 1.3933, G loss: 0.7403\n",
      "[1604/1762] D loss: 1.2235, G loss: 0.7903\n",
      "[1684/1762] D loss: 1.3774, G loss: 0.6799\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.7307\n",
      "train error: \n",
      " D loss: 1.344662, G loss: 0.729417, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 85.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.333728, G loss: 0.739286, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 80.7% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3890, G loss: 0.7376\n",
      "[84/1762] D loss: 1.3884, G loss: 0.7951\n",
      "[164/1762] D loss: 1.2325, G loss: 0.9904\n",
      "[244/1762] D loss: 1.2106, G loss: 0.8554\n",
      "[324/1762] D loss: 1.4029, G loss: 0.6959\n",
      "[404/1762] D loss: 1.3918, G loss: 0.6807\n",
      "[484/1762] D loss: 1.3897, G loss: 0.7165\n",
      "[564/1762] D loss: 1.3818, G loss: 0.6923\n",
      "[644/1762] D loss: 1.3863, G loss: 0.7178\n",
      "[724/1762] D loss: 1.3876, G loss: 0.7515\n",
      "[804/1762] D loss: 1.3621, G loss: 0.6879\n",
      "[884/1762] D loss: 1.3834, G loss: 0.6681\n",
      "[964/1762] D loss: 1.3921, G loss: 0.6739\n",
      "[1044/1762] D loss: 1.2000, G loss: 0.8651\n",
      "[1124/1762] D loss: 1.2035, G loss: 0.7203\n",
      "[1204/1762] D loss: 1.3654, G loss: 0.7628\n",
      "[1284/1762] D loss: 1.4353, G loss: 0.8407\n",
      "[1364/1762] D loss: 1.4046, G loss: 0.6775\n",
      "[1444/1762] D loss: 1.1870, G loss: 0.8772\n",
      "[1524/1762] D loss: 1.3907, G loss: 0.6790\n",
      "[1604/1762] D loss: 1.3895, G loss: 0.7516\n",
      "[1684/1762] D loss: 1.3884, G loss: 0.7019\n",
      "[1762/1762] D loss: 1.2125, G loss: 0.8409\n",
      "train error: \n",
      " D loss: 1.339606, G loss: 0.753859, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 87.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.328091, G loss: 0.763184, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 83.0% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4313, G loss: 0.7490\n",
      "[84/1762] D loss: 1.3903, G loss: 0.6412\n",
      "[164/1762] D loss: 1.4062, G loss: 0.9290\n",
      "[244/1762] D loss: 1.2203, G loss: 0.7357\n",
      "[324/1762] D loss: 1.1943, G loss: 0.7645\n",
      "[404/1762] D loss: 1.2056, G loss: 0.7375\n",
      "[484/1762] D loss: 1.3884, G loss: 0.6680\n",
      "[564/1762] D loss: 1.2001, G loss: 0.6812\n",
      "[644/1762] D loss: 1.3889, G loss: 0.7289\n",
      "[724/1762] D loss: 1.2168, G loss: 0.7902\n",
      "[804/1762] D loss: 1.3912, G loss: 0.7112\n",
      "[884/1762] D loss: 1.3910, G loss: 0.7859\n",
      "[964/1762] D loss: 1.3951, G loss: 0.6708\n",
      "[1044/1762] D loss: 1.3893, G loss: 0.7930\n",
      "[1124/1762] D loss: 1.3963, G loss: 0.6394\n",
      "[1204/1762] D loss: 1.3842, G loss: 0.7751\n",
      "[1284/1762] D loss: 1.3881, G loss: 0.7240\n",
      "[1364/1762] D loss: 1.2202, G loss: 0.6958\n",
      "[1444/1762] D loss: 1.1840, G loss: 0.7599\n",
      "[1524/1762] D loss: 1.4016, G loss: 0.6296\n",
      "[1604/1762] D loss: 1.1461, G loss: 0.8857\n",
      "[1684/1762] D loss: 1.4003, G loss: 0.8080\n",
      "[1762/1762] D loss: 1.3455, G loss: 0.7533\n",
      "train error: \n",
      " D loss: 1.337822, G loss: 0.806903, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 83.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.325229, G loss: 0.816594, D accuracy: 54.9%, cell accuracy: 99.7%, board accuracy: 79.5% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3987, G loss: 0.7699\n",
      "[84/1762] D loss: 1.4286, G loss: 0.8055\n",
      "[164/1762] D loss: 1.3919, G loss: 0.7005\n",
      "[244/1762] D loss: 1.3765, G loss: 0.8388\n",
      "[324/1762] D loss: 1.3872, G loss: 0.7133\n",
      "[404/1762] D loss: 0.9637, G loss: 0.9000\n",
      "[484/1762] D loss: 1.3873, G loss: 0.7263\n",
      "[564/1762] D loss: 1.3872, G loss: 0.6550\n",
      "[644/1762] D loss: 1.2052, G loss: 0.9078\n",
      "[724/1762] D loss: 1.3955, G loss: 0.6378\n",
      "[804/1762] D loss: 1.3944, G loss: 0.7007\n",
      "[884/1762] D loss: 1.3961, G loss: 0.6898\n",
      "[964/1762] D loss: 1.1680, G loss: 0.7280\n",
      "[1044/1762] D loss: 1.3167, G loss: 0.8877\n",
      "[1124/1762] D loss: 1.3967, G loss: 0.7547\n",
      "[1204/1762] D loss: 1.3920, G loss: 0.6251\n",
      "[1284/1762] D loss: 1.3558, G loss: 0.7611\n",
      "[1364/1762] D loss: 1.3939, G loss: 0.7098\n",
      "[1444/1762] D loss: 1.3955, G loss: 0.7120\n",
      "[1524/1762] D loss: 1.3887, G loss: 0.6980\n",
      "[1604/1762] D loss: 1.1853, G loss: 0.8527\n",
      "[1684/1762] D loss: 1.1865, G loss: 0.9988\n",
      "[1762/1762] D loss: 0.9336, G loss: 1.1207\n",
      "train error: \n",
      " D loss: 1.351985, G loss: 0.916757, D accuracy: 53.6%, cell accuracy: 99.7%, board accuracy: 75.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.339260, G loss: 0.926056, D accuracy: 54.7%, cell accuracy: 99.6%, board accuracy: 74.1% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3757, G loss: 0.8403\n",
      "[84/1762] D loss: 1.4692, G loss: 0.6313\n",
      "[164/1762] D loss: 1.3834, G loss: 0.7235\n",
      "[244/1762] D loss: 1.2302, G loss: 0.7088\n",
      "[324/1762] D loss: 1.1449, G loss: 0.8497\n",
      "[404/1762] D loss: 1.3848, G loss: 0.6590\n",
      "[484/1762] D loss: 1.3803, G loss: 0.6562\n",
      "[564/1762] D loss: 1.1573, G loss: 0.8524\n",
      "[644/1762] D loss: 1.3885, G loss: 0.6607\n",
      "[724/1762] D loss: 1.1611, G loss: 0.9775\n",
      "[804/1762] D loss: 1.3972, G loss: 0.7954\n",
      "[884/1762] D loss: 1.3916, G loss: 0.6902\n",
      "[964/1762] D loss: 1.3919, G loss: 0.6785\n",
      "[1044/1762] D loss: 1.1837, G loss: 0.6703\n",
      "[1124/1762] D loss: 1.3975, G loss: 0.7164\n",
      "[1204/1762] D loss: 1.3615, G loss: 0.7366\n",
      "[1284/1762] D loss: 1.4012, G loss: 0.6026\n",
      "[1364/1762] D loss: 1.1694, G loss: 0.7492\n",
      "[1444/1762] D loss: 1.3984, G loss: 0.7697\n",
      "[1524/1762] D loss: 1.3878, G loss: 0.7315\n",
      "[1604/1762] D loss: 1.1668, G loss: 0.8983\n",
      "[1684/1762] D loss: 1.3998, G loss: 0.6801\n",
      "[1762/1762] D loss: 1.4130, G loss: 0.7856\n",
      "train error: \n",
      " D loss: 1.331941, G loss: 0.780379, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 87.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.317284, G loss: 0.789525, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 83.0% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3983, G loss: 0.6462\n",
      "[84/1762] D loss: 1.3999, G loss: 0.7350\n",
      "[164/1762] D loss: 1.4008, G loss: 0.7646\n",
      "[244/1762] D loss: 1.3918, G loss: 0.7260\n",
      "[324/1762] D loss: 1.3917, G loss: 0.6771\n",
      "[404/1762] D loss: 1.1930, G loss: 0.7666\n",
      "[484/1762] D loss: 1.3330, G loss: 0.7794\n",
      "[564/1762] D loss: 1.2232, G loss: 0.6662\n",
      "[644/1762] D loss: 1.1395, G loss: 0.9839\n",
      "[724/1762] D loss: 1.4762, G loss: 1.0229\n",
      "[804/1762] D loss: 1.4124, G loss: 0.6746\n",
      "[884/1762] D loss: 1.3844, G loss: 0.7900\n",
      "[964/1762] D loss: 1.3779, G loss: 0.7010\n",
      "[1044/1762] D loss: 1.2642, G loss: 0.8484\n",
      "[1124/1762] D loss: 1.3916, G loss: 0.6495\n",
      "[1204/1762] D loss: 1.4154, G loss: 0.7568\n",
      "[1284/1762] D loss: 1.3928, G loss: 0.6776\n",
      "[1364/1762] D loss: 1.3972, G loss: 0.7238\n",
      "[1444/1762] D loss: 1.3985, G loss: 0.8023\n",
      "[1524/1762] D loss: 1.2187, G loss: 0.7145\n",
      "[1604/1762] D loss: 1.4101, G loss: 0.7514\n",
      "[1684/1762] D loss: 1.4105, G loss: 0.6789\n",
      "[1762/1762] D loss: 1.0129, G loss: 0.9497\n",
      "train error: \n",
      " D loss: 1.362245, G loss: 0.857149, D accuracy: 52.9%, cell accuracy: 99.8%, board accuracy: 84.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.349931, G loss: 0.864560, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 81.8% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4220, G loss: 0.9090\n",
      "[84/1762] D loss: 1.3899, G loss: 0.6229\n",
      "[164/1762] D loss: 1.3995, G loss: 0.7784\n",
      "[244/1762] D loss: 1.2438, G loss: 0.7928\n",
      "[324/1762] D loss: 1.3980, G loss: 0.6383\n",
      "[404/1762] D loss: 1.2284, G loss: 0.7822\n",
      "[484/1762] D loss: 1.1910, G loss: 0.8570\n",
      "[564/1762] D loss: 1.3887, G loss: 0.6758\n",
      "[644/1762] D loss: 1.3957, G loss: 0.8207\n",
      "[724/1762] D loss: 1.1960, G loss: 0.8449\n",
      "[804/1762] D loss: 1.3208, G loss: 0.9317\n",
      "[884/1762] D loss: 1.5517, G loss: 0.5586\n",
      "[964/1762] D loss: 1.7328, G loss: 0.4934\n",
      "[1044/1762] D loss: 1.5499, G loss: 0.5958\n",
      "[1124/1762] D loss: 1.3819, G loss: 0.7896\n",
      "[1204/1762] D loss: 1.5247, G loss: 0.7575\n",
      "[1284/1762] D loss: 1.3848, G loss: 1.1779\n",
      "[1364/1762] D loss: 1.1912, G loss: 0.6964\n",
      "[1444/1762] D loss: 1.1516, G loss: 0.9585\n",
      "[1524/1762] D loss: 1.2001, G loss: 0.5741\n",
      "[1604/1762] D loss: 1.3990, G loss: 1.0670\n",
      "[1684/1762] D loss: 0.8726, G loss: 0.8277\n",
      "[1762/1762] D loss: 0.6963, G loss: 1.1103\n",
      "train error: \n",
      " D loss: 0.953048, G loss: 1.066114, D accuracy: 85.9%, cell accuracy: 98.7%, board accuracy: 20.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.982796, G loss: 1.066299, D accuracy: 85.0%, cell accuracy: 98.7%, board accuracy: 21.4% \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7142, G loss: 1.1112\n",
      "[84/1762] D loss: 1.4226, G loss: 0.5812\n",
      "[164/1762] D loss: 1.5729, G loss: 1.0671\n",
      "[244/1762] D loss: 1.5602, G loss: 0.6788\n",
      "[324/1762] D loss: 1.4671, G loss: 0.7971\n",
      "[404/1762] D loss: 1.3972, G loss: 0.7806\n",
      "[484/1762] D loss: 1.4045, G loss: 0.6248\n",
      "[564/1762] D loss: 1.3952, G loss: 0.6423\n",
      "[644/1762] D loss: 1.3971, G loss: 0.7329\n",
      "[724/1762] D loss: 1.3948, G loss: 0.6245\n",
      "[804/1762] D loss: 1.4010, G loss: 0.6087\n",
      "[884/1762] D loss: 1.4103, G loss: 0.7232\n",
      "[964/1762] D loss: 1.3937, G loss: 0.5993\n",
      "[1044/1762] D loss: 1.3891, G loss: 0.6211\n",
      "[1124/1762] D loss: 1.4320, G loss: 0.7963\n",
      "[1204/1762] D loss: 1.3938, G loss: 0.5971\n",
      "[1284/1762] D loss: 1.4830, G loss: 0.7340\n",
      "[1364/1762] D loss: 1.3892, G loss: 0.7040\n",
      "[1444/1762] D loss: 1.3902, G loss: 0.7415\n",
      "[1524/1762] D loss: 1.3991, G loss: 0.6411\n",
      "[1604/1762] D loss: 1.4016, G loss: 0.6137\n",
      "[1684/1762] D loss: 1.3955, G loss: 0.6874\n",
      "[1762/1762] D loss: 1.3871, G loss: 0.7053\n",
      "train error: \n",
      " D loss: 1.401951, G loss: 0.733418, D accuracy: 48.8%, cell accuracy: 99.8%, board accuracy: 83.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.408611, G loss: 0.737343, D accuracy: 47.6%, cell accuracy: 99.7%, board accuracy: 79.5% \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4063, G loss: 0.8176\n",
      "[84/1762] D loss: 1.4313, G loss: 0.6394\n",
      "[164/1762] D loss: 1.3870, G loss: 0.6713\n",
      "[244/1762] D loss: 1.4095, G loss: 0.7650\n",
      "[324/1762] D loss: 1.3908, G loss: 0.6486\n",
      "[404/1762] D loss: 1.3906, G loss: 0.6663\n",
      "[484/1762] D loss: 1.3954, G loss: 0.6906\n",
      "[564/1762] D loss: 1.3908, G loss: 0.7667\n",
      "[644/1762] D loss: 1.3889, G loss: 0.7207\n",
      "[724/1762] D loss: 1.3880, G loss: 0.6962\n",
      "[804/1762] D loss: 1.3902, G loss: 0.6713\n",
      "[884/1762] D loss: 1.3898, G loss: 0.7555\n",
      "[964/1762] D loss: 1.3909, G loss: 0.6979\n",
      "[1044/1762] D loss: 1.3433, G loss: 0.6618\n",
      "[1124/1762] D loss: 1.3518, G loss: 0.6680\n",
      "[1204/1762] D loss: 1.4073, G loss: 0.6958\n",
      "[1284/1762] D loss: 1.3843, G loss: 0.7018\n",
      "[1364/1762] D loss: 1.2818, G loss: 0.7452\n",
      "[1444/1762] D loss: 1.3925, G loss: 0.7644\n",
      "[1524/1762] D loss: 1.3885, G loss: 0.6502\n",
      "[1604/1762] D loss: 1.3875, G loss: 0.6828\n",
      "[1684/1762] D loss: 1.3878, G loss: 0.6968\n",
      "[1762/1762] D loss: 1.3547, G loss: 0.7217\n",
      "train error: \n",
      " D loss: 1.381698, G loss: 0.702914, D accuracy: 51.4%, cell accuracy: 99.8%, board accuracy: 84.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.382913, G loss: 0.707357, D accuracy: 50.8%, cell accuracy: 99.7%, board accuracy: 78.2% \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3893, G loss: 0.7263\n",
      "[84/1762] D loss: 1.3796, G loss: 0.7123\n",
      "[164/1762] D loss: 1.3943, G loss: 0.6661\n",
      "[244/1762] D loss: 1.3792, G loss: 0.7086\n",
      "[324/1762] D loss: 1.3692, G loss: 0.7229\n",
      "[404/1762] D loss: 1.3705, G loss: 0.7033\n",
      "[484/1762] D loss: 1.3846, G loss: 0.6689\n",
      "[564/1762] D loss: 1.3946, G loss: 0.6390\n",
      "[644/1762] D loss: 1.3065, G loss: 0.6882\n",
      "[724/1762] D loss: 1.3837, G loss: 0.6660\n",
      "[804/1762] D loss: 1.3886, G loss: 0.6926\n",
      "[884/1762] D loss: 1.3927, G loss: 0.7486\n",
      "[964/1762] D loss: 1.3783, G loss: 0.6762\n",
      "[1044/1762] D loss: 1.3892, G loss: 0.6934\n",
      "[1124/1762] D loss: 1.3872, G loss: 0.6788\n",
      "[1204/1762] D loss: 1.3876, G loss: 0.6958\n",
      "[1284/1762] D loss: 1.3362, G loss: 0.7710\n",
      "[1364/1762] D loss: 1.3915, G loss: 0.6933\n",
      "[1444/1762] D loss: 1.2849, G loss: 0.6996\n",
      "[1524/1762] D loss: 1.4106, G loss: 0.8199\n",
      "[1604/1762] D loss: 1.3898, G loss: 0.6536\n",
      "[1684/1762] D loss: 1.4204, G loss: 0.6467\n",
      "[1762/1762] D loss: 1.3908, G loss: 0.7550\n",
      "train error: \n",
      " D loss: 1.367291, G loss: 0.705125, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 85.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.365601, G loss: 0.708890, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 82.5% \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3831, G loss: 0.6745\n",
      "[84/1762] D loss: 1.4212, G loss: 0.7335\n",
      "[164/1762] D loss: 1.3865, G loss: 0.7117\n",
      "[244/1762] D loss: 1.3123, G loss: 0.7889\n",
      "[324/1762] D loss: 1.3900, G loss: 0.7264\n",
      "[404/1762] D loss: 1.3876, G loss: 0.6943\n",
      "[484/1762] D loss: 1.3929, G loss: 0.7689\n",
      "[564/1762] D loss: 1.3896, G loss: 0.6856\n",
      "[644/1762] D loss: 1.3920, G loss: 0.7055\n",
      "[724/1762] D loss: 1.3918, G loss: 0.7492\n",
      "[804/1762] D loss: 1.4080, G loss: 0.6780\n",
      "[884/1762] D loss: 1.3891, G loss: 0.6951\n",
      "[964/1762] D loss: 1.3883, G loss: 0.7181\n",
      "[1044/1762] D loss: 1.3884, G loss: 0.7391\n",
      "[1124/1762] D loss: 1.3880, G loss: 0.7180\n",
      "[1204/1762] D loss: 1.3999, G loss: 0.7894\n",
      "[1284/1762] D loss: 1.3906, G loss: 0.7336\n",
      "[1364/1762] D loss: 1.3877, G loss: 0.6860\n",
      "[1444/1762] D loss: 1.2416, G loss: 0.7606\n",
      "[1524/1762] D loss: 1.3868, G loss: 0.6705\n",
      "[1604/1762] D loss: 1.3908, G loss: 0.7124\n",
      "[1684/1762] D loss: 1.2677, G loss: 0.7635\n",
      "[1762/1762] D loss: 1.4015, G loss: 0.7940\n",
      "train error: \n",
      " D loss: 1.356186, G loss: 0.690684, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 89.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.350043, G loss: 0.696730, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 85.9% \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3889, G loss: 0.6552\n",
      "[84/1762] D loss: 1.3932, G loss: 0.7695\n",
      "[164/1762] D loss: 1.3931, G loss: 0.6358\n",
      "[244/1762] D loss: 1.3964, G loss: 0.6739\n",
      "[324/1762] D loss: 1.4016, G loss: 0.5898\n",
      "[404/1762] D loss: 1.3991, G loss: 0.8126\n",
      "[484/1762] D loss: 1.3910, G loss: 0.6620\n",
      "[564/1762] D loss: 1.3903, G loss: 0.7800\n",
      "[644/1762] D loss: 1.3906, G loss: 0.7039\n",
      "[724/1762] D loss: 1.2512, G loss: 0.8966\n",
      "[804/1762] D loss: 1.3953, G loss: 0.6739\n",
      "[884/1762] D loss: 1.3873, G loss: 0.6977\n",
      "[964/1762] D loss: 1.3931, G loss: 0.6913\n",
      "[1044/1762] D loss: 1.3880, G loss: 0.7011\n",
      "[1124/1762] D loss: 1.3886, G loss: 0.6779\n",
      "[1204/1762] D loss: 1.3868, G loss: 0.6481\n",
      "[1284/1762] D loss: 1.3878, G loss: 0.7405\n",
      "[1364/1762] D loss: 1.3912, G loss: 0.7460\n",
      "[1444/1762] D loss: 1.3788, G loss: 0.7561\n",
      "[1524/1762] D loss: 1.3905, G loss: 0.7011\n",
      "[1604/1762] D loss: 1.3940, G loss: 0.7517\n",
      "[1684/1762] D loss: 1.3888, G loss: 0.7246\n",
      "[1762/1762] D loss: 1.3894, G loss: 0.6885\n",
      "train error: \n",
      " D loss: 1.352423, G loss: 0.660694, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.342468, G loss: 0.667348, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 84.1% \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4321, G loss: 0.5548\n",
      "[84/1762] D loss: 1.3881, G loss: 0.6665\n",
      "[164/1762] D loss: 1.3874, G loss: 0.7017\n",
      "[244/1762] D loss: 1.6022, G loss: 0.7749\n",
      "[324/1762] D loss: 1.4491, G loss: 0.6323\n",
      "[404/1762] D loss: 1.2438, G loss: 0.7410\n",
      "[484/1762] D loss: 1.3964, G loss: 0.5874\n",
      "[564/1762] D loss: 1.3857, G loss: 0.7288\n",
      "[644/1762] D loss: 1.4469, G loss: 0.7642\n",
      "[724/1762] D loss: 1.3213, G loss: 0.7977\n",
      "[804/1762] D loss: 1.3889, G loss: 0.7084\n",
      "[884/1762] D loss: 1.4413, G loss: 0.8269\n",
      "[964/1762] D loss: 1.3910, G loss: 0.7075\n",
      "[1044/1762] D loss: 1.2802, G loss: 0.7612\n",
      "[1124/1762] D loss: 1.3896, G loss: 0.6736\n",
      "[1204/1762] D loss: 1.3915, G loss: 0.6656\n",
      "[1284/1762] D loss: 1.3945, G loss: 0.7721\n",
      "[1364/1762] D loss: 1.3904, G loss: 0.6934\n",
      "[1444/1762] D loss: 1.3876, G loss: 0.8008\n",
      "[1524/1762] D loss: 1.3875, G loss: 0.6978\n",
      "[1604/1762] D loss: 1.3948, G loss: 0.6756\n",
      "[1684/1762] D loss: 1.4012, G loss: 0.8009\n",
      "[1762/1762] D loss: 1.4111, G loss: 0.5941\n",
      "train error: \n",
      " D loss: 1.359789, G loss: 0.643108, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 87.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.354456, G loss: 0.650034, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 82.7% \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3886, G loss: 0.7338\n",
      "[84/1762] D loss: 1.3871, G loss: 0.6479\n",
      "[164/1762] D loss: 1.3989, G loss: 0.7566\n",
      "[244/1762] D loss: 1.3899, G loss: 0.7662\n",
      "[324/1762] D loss: 1.3990, G loss: 0.5991\n",
      "[404/1762] D loss: 1.2913, G loss: 0.8010\n",
      "[484/1762] D loss: 1.3911, G loss: 0.7343\n",
      "[564/1762] D loss: 1.3942, G loss: 0.5991\n",
      "[644/1762] D loss: 1.3907, G loss: 0.7057\n",
      "[724/1762] D loss: 1.2331, G loss: 0.7952\n",
      "[804/1762] D loss: 1.3714, G loss: 0.6833\n",
      "[884/1762] D loss: 1.3874, G loss: 0.6996\n",
      "[964/1762] D loss: 1.3899, G loss: 0.6749\n",
      "[1044/1762] D loss: 1.4264, G loss: 0.8531\n",
      "[1124/1762] D loss: 1.3961, G loss: 0.5998\n",
      "[1204/1762] D loss: 1.3872, G loss: 0.7023\n",
      "[1284/1762] D loss: 1.3880, G loss: 0.6914\n",
      "[1364/1762] D loss: 1.3935, G loss: 0.6492\n",
      "[1444/1762] D loss: 1.3916, G loss: 0.7241\n",
      "[1524/1762] D loss: 1.3938, G loss: 0.7291\n",
      "[1604/1762] D loss: 1.3890, G loss: 0.7595\n",
      "[1684/1762] D loss: 1.3907, G loss: 0.6810\n",
      "[1762/1762] D loss: 1.3870, G loss: 0.7253\n",
      "train error: \n",
      " D loss: 1.340875, G loss: 0.779334, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.330770, G loss: 0.789451, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 84.1% \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3841, G loss: 0.7667\n",
      "[84/1762] D loss: 1.3929, G loss: 0.6728\n",
      "[164/1762] D loss: 1.3932, G loss: 0.7658\n",
      "[244/1762] D loss: 1.3901, G loss: 0.6479\n",
      "[324/1762] D loss: 1.3945, G loss: 0.7859\n",
      "[404/1762] D loss: 1.3920, G loss: 0.6482\n",
      "[484/1762] D loss: 1.3850, G loss: 0.5985\n",
      "[564/1762] D loss: 1.1706, G loss: 0.8033\n",
      "[644/1762] D loss: 1.3972, G loss: 0.7460\n",
      "[724/1762] D loss: 1.3954, G loss: 0.8140\n",
      "[804/1762] D loss: 1.3937, G loss: 0.6513\n",
      "[884/1762] D loss: 1.3952, G loss: 0.6677\n",
      "[964/1762] D loss: 1.4014, G loss: 0.7308\n",
      "[1044/1762] D loss: 1.3983, G loss: 0.7687\n",
      "[1124/1762] D loss: 1.3872, G loss: 0.7192\n",
      "[1204/1762] D loss: 1.4090, G loss: 0.7601\n",
      "[1284/1762] D loss: 1.3948, G loss: 0.6818\n",
      "[1364/1762] D loss: 1.1918, G loss: 0.7126\n",
      "[1444/1762] D loss: 1.1801, G loss: 0.7291\n",
      "[1524/1762] D loss: 1.3961, G loss: 0.7978\n",
      "[1604/1762] D loss: 1.3902, G loss: 0.7632\n",
      "[1684/1762] D loss: 1.3702, G loss: 0.7506\n",
      "[1762/1762] D loss: 1.3948, G loss: 0.6302\n",
      "train error: \n",
      " D loss: 1.332399, G loss: 0.748136, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 85.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.318231, G loss: 0.759684, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 83.0% \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3916, G loss: 0.7506\n",
      "[84/1762] D loss: 1.3888, G loss: 0.7147\n",
      "[164/1762] D loss: 1.3841, G loss: 0.6991\n",
      "[244/1762] D loss: 0.9480, G loss: 1.0696\n",
      "[324/1762] D loss: 1.3952, G loss: 0.7707\n",
      "[404/1762] D loss: 1.3962, G loss: 0.7652\n",
      "[484/1762] D loss: 1.3806, G loss: 0.7725\n",
      "[564/1762] D loss: 1.1747, G loss: 0.8078\n",
      "[644/1762] D loss: 1.3951, G loss: 0.6925\n",
      "[724/1762] D loss: 1.3897, G loss: 0.6450\n",
      "[804/1762] D loss: 1.4086, G loss: 0.7153\n",
      "[884/1762] D loss: 1.3900, G loss: 0.7743\n",
      "[964/1762] D loss: 0.9477, G loss: 0.8746\n",
      "[1044/1762] D loss: 1.3948, G loss: 0.7774\n",
      "[1124/1762] D loss: 1.3883, G loss: 0.7172\n",
      "[1204/1762] D loss: 1.3884, G loss: 0.6953\n",
      "[1284/1762] D loss: 1.3817, G loss: 0.6277\n",
      "[1364/1762] D loss: 1.1487, G loss: 1.0036\n",
      "[1444/1762] D loss: 1.3885, G loss: 0.6357\n",
      "[1524/1762] D loss: 1.3922, G loss: 0.6871\n",
      "[1604/1762] D loss: 1.4059, G loss: 0.7259\n",
      "[1684/1762] D loss: 1.3952, G loss: 0.7533\n",
      "[1762/1762] D loss: 1.3871, G loss: 0.6958\n",
      "train error: \n",
      " D loss: 1.329151, G loss: 0.731000, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 85.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.313805, G loss: 0.741570, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 81.8% \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3928, G loss: 0.7689\n",
      "[84/1762] D loss: 1.3876, G loss: 0.6871\n",
      "[164/1762] D loss: 1.3925, G loss: 0.7358\n",
      "[244/1762] D loss: 1.3968, G loss: 0.7136\n",
      "[324/1762] D loss: 1.3917, G loss: 0.7166\n",
      "[404/1762] D loss: 1.3944, G loss: 0.7166\n",
      "[484/1762] D loss: 1.2449, G loss: 0.8031\n",
      "[564/1762] D loss: 1.3960, G loss: 0.6240\n",
      "[644/1762] D loss: 1.3972, G loss: 0.6868\n",
      "[724/1762] D loss: 1.1785, G loss: 0.8711\n",
      "[804/1762] D loss: 1.3955, G loss: 0.7382\n",
      "[884/1762] D loss: 1.3872, G loss: 0.7488\n",
      "[964/1762] D loss: 1.1770, G loss: 0.7593\n",
      "[1044/1762] D loss: 1.3886, G loss: 0.7299\n",
      "[1124/1762] D loss: 1.3949, G loss: 0.7502\n",
      "[1204/1762] D loss: 1.4169, G loss: 0.8262\n",
      "[1284/1762] D loss: 1.2348, G loss: 0.7091\n",
      "[1364/1762] D loss: 1.3933, G loss: 0.6400\n",
      "[1444/1762] D loss: 0.9250, G loss: 1.2144\n",
      "[1524/1762] D loss: 1.3918, G loss: 0.6191\n",
      "[1604/1762] D loss: 1.3554, G loss: 0.7224\n",
      "[1684/1762] D loss: 1.3673, G loss: 0.7667\n",
      "[1762/1762] D loss: 1.4340, G loss: 0.6740\n",
      "train error: \n",
      " D loss: 1.318230, G loss: 0.789071, D accuracy: 55.4%, cell accuracy: 99.3%, board accuracy: 56.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.303920, G loss: 0.798357, D accuracy: 55.7%, cell accuracy: 99.3%, board accuracy: 51.4% \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4207, G loss: 0.7618\n",
      "[84/1762] D loss: 1.1567, G loss: 0.8375\n",
      "[164/1762] D loss: 1.3921, G loss: 0.6386\n",
      "[244/1762] D loss: 1.1582, G loss: 0.8092\n",
      "[324/1762] D loss: 1.2061, G loss: 1.0948\n",
      "[404/1762] D loss: 1.3990, G loss: 0.6454\n",
      "[484/1762] D loss: 1.4068, G loss: 0.5869\n",
      "[564/1762] D loss: 1.3901, G loss: 0.7082\n",
      "[644/1762] D loss: 1.4041, G loss: 0.7362\n",
      "[724/1762] D loss: 1.3879, G loss: 0.6122\n",
      "[804/1762] D loss: 1.3870, G loss: 0.6801\n",
      "[884/1762] D loss: 1.4038, G loss: 0.6187\n",
      "[964/1762] D loss: 1.4287, G loss: 0.7951\n",
      "[1044/1762] D loss: 1.3956, G loss: 0.7784\n",
      "[1124/1762] D loss: 1.3882, G loss: 0.6848\n",
      "[1204/1762] D loss: 1.4022, G loss: 0.8058\n",
      "[1284/1762] D loss: 1.1381, G loss: 0.9428\n",
      "[1364/1762] D loss: 1.3870, G loss: 0.7080\n",
      "[1444/1762] D loss: 1.3947, G loss: 0.7106\n",
      "[1524/1762] D loss: 1.3925, G loss: 0.6957\n",
      "[1604/1762] D loss: 1.3874, G loss: 0.7106\n",
      "[1684/1762] D loss: 1.3903, G loss: 0.7296\n",
      "[1762/1762] D loss: 1.3890, G loss: 0.6574\n",
      "train error: \n",
      " D loss: 1.334083, G loss: 0.667118, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 85.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.317136, G loss: 0.677582, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 85.2% \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3921, G loss: 0.6463\n",
      "[84/1762] D loss: 1.4126, G loss: 0.7777\n",
      "[164/1762] D loss: 1.3881, G loss: 0.7156\n",
      "[244/1762] D loss: 1.3875, G loss: 0.7008\n",
      "[324/1762] D loss: 1.3672, G loss: 0.7409\n",
      "[404/1762] D loss: 1.3969, G loss: 0.5789\n",
      "[484/1762] D loss: 1.4085, G loss: 0.8130\n",
      "[564/1762] D loss: 1.4042, G loss: 0.7685\n",
      "[644/1762] D loss: 1.3947, G loss: 0.7597\n",
      "[724/1762] D loss: 1.2037, G loss: 0.9140\n",
      "[804/1762] D loss: 1.2062, G loss: 0.8173\n",
      "[884/1762] D loss: 1.3921, G loss: 0.7219\n",
      "[964/1762] D loss: 1.3907, G loss: 0.7613\n",
      "[1044/1762] D loss: 1.3856, G loss: 0.7783\n",
      "[1124/1762] D loss: 1.3867, G loss: 0.7411\n",
      "[1204/1762] D loss: 1.1378, G loss: 0.8246\n",
      "[1284/1762] D loss: 1.3877, G loss: 0.6703\n",
      "[1364/1762] D loss: 1.3910, G loss: 0.6482\n",
      "[1444/1762] D loss: 1.3890, G loss: 0.6359\n",
      "[1524/1762] D loss: 1.1383, G loss: 0.8973\n",
      "[1604/1762] D loss: 1.4135, G loss: 0.8774\n",
      "[1684/1762] D loss: 1.1215, G loss: 0.9810\n",
      "[1762/1762] D loss: 1.3910, G loss: 0.7830\n",
      "train error: \n",
      " D loss: 1.329883, G loss: 0.839261, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 89.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.311875, G loss: 0.853233, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3923, G loss: 0.7665\n",
      "[84/1762] D loss: 1.3940, G loss: 0.6441\n",
      "[164/1762] D loss: 1.3954, G loss: 0.7473\n",
      "[244/1762] D loss: 1.4059, G loss: 0.7132\n",
      "[324/1762] D loss: 1.1566, G loss: 0.8894\n",
      "[404/1762] D loss: 1.3878, G loss: 0.6868\n",
      "[484/1762] D loss: 1.3979, G loss: 0.7489\n",
      "[564/1762] D loss: 2.0218, G loss: 0.8452\n",
      "[644/1762] D loss: 1.8828, G loss: 0.5087\n",
      "[724/1762] D loss: 2.5396, G loss: 0.2696\n",
      "[804/1762] D loss: 1.5718, G loss: 0.4763\n",
      "[884/1762] D loss: 1.3103, G loss: 0.7445\n",
      "[964/1762] D loss: 1.4493, G loss: 0.8617\n",
      "[1044/1762] D loss: 1.1630, G loss: 0.6319\n",
      "[1124/1762] D loss: 1.5121, G loss: 1.0315\n",
      "[1204/1762] D loss: 1.1020, G loss: 0.8064\n",
      "[1284/1762] D loss: 1.1483, G loss: 1.0008\n",
      "[1364/1762] D loss: 1.4303, G loss: 1.1349\n",
      "[1444/1762] D loss: 1.6623, G loss: 0.8247\n",
      "[1524/1762] D loss: 1.5786, G loss: 0.8595\n",
      "[1604/1762] D loss: 1.3904, G loss: 0.7641\n",
      "[1684/1762] D loss: 1.3857, G loss: 0.7761\n",
      "[1762/1762] D loss: 1.4164, G loss: 0.6292\n",
      "train error: \n",
      " D loss: 1.441972, G loss: 0.691406, D accuracy: 47.8%, cell accuracy: 99.8%, board accuracy: 83.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.451908, G loss: 0.693978, D accuracy: 46.7%, cell accuracy: 99.7%, board accuracy: 77.5% \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4038, G loss: 0.6903\n",
      "[84/1762] D loss: 1.3944, G loss: 0.6664\n",
      "[164/1762] D loss: 1.3894, G loss: 0.6831\n",
      "[244/1762] D loss: 1.4310, G loss: 0.7904\n",
      "[324/1762] D loss: 1.3967, G loss: 0.7900\n",
      "[404/1762] D loss: 1.3749, G loss: 0.7049\n",
      "[484/1762] D loss: 1.5041, G loss: 0.7191\n",
      "[564/1762] D loss: 1.3870, G loss: 0.7042\n",
      "[644/1762] D loss: 1.3916, G loss: 0.6760\n",
      "[724/1762] D loss: 1.4781, G loss: 0.6841\n",
      "[804/1762] D loss: 1.3877, G loss: 0.6935\n",
      "[884/1762] D loss: 1.3889, G loss: 0.6962\n",
      "[964/1762] D loss: 1.4096, G loss: 0.7587\n",
      "[1044/1762] D loss: 1.3808, G loss: 0.6739\n",
      "[1124/1762] D loss: 1.3938, G loss: 0.7160\n",
      "[1204/1762] D loss: 1.3912, G loss: 0.7024\n",
      "[1284/1762] D loss: 1.3882, G loss: 0.7425\n",
      "[1364/1762] D loss: 1.3929, G loss: 0.7488\n",
      "[1444/1762] D loss: 1.3929, G loss: 0.7639\n",
      "[1524/1762] D loss: 1.3880, G loss: 0.6853\n",
      "[1604/1762] D loss: 1.3937, G loss: 0.6845\n",
      "[1684/1762] D loss: 1.3868, G loss: 0.6824\n",
      "[1762/1762] D loss: 1.3880, G loss: 0.7099\n",
      "train error: \n",
      " D loss: 1.385451, G loss: 0.692125, D accuracy: 51.3%, cell accuracy: 99.8%, board accuracy: 84.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.388168, G loss: 0.698232, D accuracy: 50.2%, cell accuracy: 99.8%, board accuracy: 81.4% \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3867, G loss: 0.7090\n",
      "[84/1762] D loss: 1.4047, G loss: 0.6684\n",
      "[164/1762] D loss: 1.3590, G loss: 0.6944\n",
      "[244/1762] D loss: 1.3885, G loss: 0.7029\n",
      "[324/1762] D loss: 1.3360, G loss: 0.6951\n",
      "[404/1762] D loss: 1.3860, G loss: 0.6784\n",
      "[484/1762] D loss: 1.3940, G loss: 0.6443\n",
      "[564/1762] D loss: 1.3922, G loss: 0.7021\n",
      "[644/1762] D loss: 1.3883, G loss: 0.6629\n",
      "[724/1762] D loss: 1.3960, G loss: 0.7156\n",
      "[804/1762] D loss: 1.3230, G loss: 0.6992\n",
      "[884/1762] D loss: 1.3922, G loss: 0.7187\n",
      "[964/1762] D loss: 1.3865, G loss: 0.7022\n",
      "[1044/1762] D loss: 1.3886, G loss: 0.6802\n",
      "[1124/1762] D loss: 1.3886, G loss: 0.6803\n",
      "[1204/1762] D loss: 1.3879, G loss: 0.6657\n",
      "[1284/1762] D loss: 1.3983, G loss: 0.6006\n",
      "[1364/1762] D loss: 1.3897, G loss: 0.6933\n",
      "[1444/1762] D loss: 1.3867, G loss: 0.6959\n",
      "[1524/1762] D loss: 1.2982, G loss: 0.6952\n",
      "[1604/1762] D loss: 1.3890, G loss: 0.7343\n",
      "[1684/1762] D loss: 1.3876, G loss: 0.6914\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.7055\n",
      "train error: \n",
      " D loss: 1.371019, G loss: 0.690546, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 85.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.370938, G loss: 0.695695, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 80.5% \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3956, G loss: 0.6944\n",
      "[84/1762] D loss: 1.3893, G loss: 0.6770\n",
      "[164/1762] D loss: 1.3887, G loss: 0.6979\n",
      "[244/1762] D loss: 1.3891, G loss: 0.7268\n",
      "[324/1762] D loss: 1.3587, G loss: 0.7023\n",
      "[404/1762] D loss: 1.3870, G loss: 0.7224\n",
      "[484/1762] D loss: 1.3787, G loss: 0.7521\n",
      "[564/1762] D loss: 1.4001, G loss: 0.7064\n",
      "[644/1762] D loss: 1.3876, G loss: 0.7094\n",
      "[724/1762] D loss: 1.3888, G loss: 0.6594\n",
      "[804/1762] D loss: 1.3870, G loss: 0.6585\n",
      "[884/1762] D loss: 1.3896, G loss: 0.7373\n",
      "[964/1762] D loss: 1.3977, G loss: 0.7441\n",
      "[1044/1762] D loss: 1.4109, G loss: 0.7309\n",
      "[1124/1762] D loss: 1.2981, G loss: 0.7436\n",
      "[1204/1762] D loss: 1.3903, G loss: 0.6968\n",
      "[1284/1762] D loss: 1.3879, G loss: 0.7276\n",
      "[1364/1762] D loss: 1.3893, G loss: 0.7043\n",
      "[1444/1762] D loss: 1.2674, G loss: 0.7223\n",
      "[1524/1762] D loss: 1.2542, G loss: 0.7530\n",
      "[1604/1762] D loss: 1.3879, G loss: 0.6923\n",
      "[1684/1762] D loss: 1.3900, G loss: 0.7483\n",
      "[1762/1762] D loss: 1.3858, G loss: 0.6849\n",
      "train error: \n",
      " D loss: 1.357396, G loss: 0.711030, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 87.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.353403, G loss: 0.716680, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 82.7% \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3905, G loss: 0.6901\n",
      "[84/1762] D loss: 1.3871, G loss: 0.7224\n",
      "[164/1762] D loss: 1.3827, G loss: 0.7139\n",
      "[244/1762] D loss: 1.3911, G loss: 0.7582\n",
      "[324/1762] D loss: 1.3869, G loss: 0.6668\n",
      "[404/1762] D loss: 1.3870, G loss: 0.7162\n",
      "[484/1762] D loss: 1.3923, G loss: 0.7465\n",
      "[564/1762] D loss: 1.3687, G loss: 0.6436\n",
      "[644/1762] D loss: 1.3884, G loss: 0.7089\n",
      "[724/1762] D loss: 1.2694, G loss: 0.7166\n",
      "[804/1762] D loss: 1.2766, G loss: 0.7825\n",
      "[884/1762] D loss: 1.3882, G loss: 0.6959\n",
      "[964/1762] D loss: 1.3602, G loss: 0.6789\n",
      "[1044/1762] D loss: 1.2844, G loss: 0.7734\n",
      "[1124/1762] D loss: 1.3888, G loss: 0.6599\n",
      "[1204/1762] D loss: 1.3558, G loss: 0.7366\n",
      "[1284/1762] D loss: 1.2149, G loss: 0.8032\n",
      "[1364/1762] D loss: 1.3940, G loss: 0.6534\n",
      "[1444/1762] D loss: 1.3921, G loss: 0.7045\n",
      "[1524/1762] D loss: 1.3874, G loss: 0.7190\n",
      "[1604/1762] D loss: 1.2250, G loss: 0.7356\n",
      "[1684/1762] D loss: 1.3894, G loss: 0.7328\n",
      "[1762/1762] D loss: 1.3891, G loss: 0.7254\n",
      "train error: \n",
      " D loss: 1.342948, G loss: 0.730907, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 87.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.332880, G loss: 0.738692, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 83.0% \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2456, G loss: 0.7393\n",
      "[84/1762] D loss: 1.2430, G loss: 0.7230\n",
      "[164/1762] D loss: 1.3929, G loss: 0.7178\n",
      "[244/1762] D loss: 1.3842, G loss: 0.6925\n",
      "[324/1762] D loss: 1.3883, G loss: 0.7042\n",
      "[404/1762] D loss: 1.3916, G loss: 0.6517\n",
      "[484/1762] D loss: 1.3886, G loss: 0.6727\n",
      "[564/1762] D loss: 1.3966, G loss: 0.6843\n",
      "[644/1762] D loss: 1.1838, G loss: 0.8610\n",
      "[724/1762] D loss: 1.3882, G loss: 0.6743\n",
      "[804/1762] D loss: 1.3922, G loss: 0.6698\n",
      "[884/1762] D loss: 1.2220, G loss: 0.6972\n",
      "[964/1762] D loss: 1.2082, G loss: 0.7061\n",
      "[1044/1762] D loss: 1.3897, G loss: 0.7517\n",
      "[1124/1762] D loss: 1.2812, G loss: 0.8144\n",
      "[1204/1762] D loss: 1.3881, G loss: 0.7259\n",
      "[1284/1762] D loss: 1.3564, G loss: 0.6525\n",
      "[1364/1762] D loss: 1.3541, G loss: 0.7886\n",
      "[1444/1762] D loss: 1.3910, G loss: 0.7011\n",
      "[1524/1762] D loss: 1.3887, G loss: 0.6668\n",
      "[1604/1762] D loss: 1.1952, G loss: 0.8538\n",
      "[1684/1762] D loss: 1.1644, G loss: 0.7982\n",
      "[1762/1762] D loss: 1.3874, G loss: 0.6801\n",
      "train error: \n",
      " D loss: 1.329688, G loss: 0.732956, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 88.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.314295, G loss: 0.743262, D accuracy: 56.1%, cell accuracy: 99.8%, board accuracy: 83.9% \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3182, G loss: 0.7362\n",
      "[84/1762] D loss: 1.4025, G loss: 0.7864\n",
      "[164/1762] D loss: 1.3253, G loss: 0.7471\n",
      "[244/1762] D loss: 1.3876, G loss: 0.7385\n",
      "[324/1762] D loss: 1.4108, G loss: 0.7975\n",
      "[404/1762] D loss: 1.3880, G loss: 0.6602\n",
      "[484/1762] D loss: 1.3951, G loss: 0.7486\n",
      "[564/1762] D loss: 1.3997, G loss: 0.8084\n",
      "[644/1762] D loss: 1.1922, G loss: 0.7605\n",
      "[724/1762] D loss: 1.1632, G loss: 0.8570\n",
      "[804/1762] D loss: 0.9664, G loss: 0.9293\n",
      "[884/1762] D loss: 1.1956, G loss: 0.7594\n",
      "[964/1762] D loss: 1.3922, G loss: 0.7302\n",
      "[1044/1762] D loss: 1.3535, G loss: 0.7615\n",
      "[1124/1762] D loss: 1.3907, G loss: 0.7082\n",
      "[1204/1762] D loss: 1.1872, G loss: 0.7912\n",
      "[1284/1762] D loss: 1.3931, G loss: 0.6157\n",
      "[1364/1762] D loss: 1.4083, G loss: 0.6432\n",
      "[1444/1762] D loss: 1.4018, G loss: 0.7556\n",
      "[1524/1762] D loss: 1.4464, G loss: 0.7473\n",
      "[1604/1762] D loss: 1.3838, G loss: 0.7001\n",
      "[1684/1762] D loss: 2.1379, G loss: 0.6557\n",
      "[1762/1762] D loss: 1.1738, G loss: 0.6639\n",
      "train error: \n",
      " D loss: 1.261965, G loss: 0.682934, D accuracy: 59.0%, cell accuracy: 98.5%, board accuracy: 7.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.258916, G loss: 0.702835, D accuracy: 58.9%, cell accuracy: 98.4%, board accuracy: 6.4% \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2626, G loss: 0.6256\n",
      "[84/1762] D loss: 1.5534, G loss: 0.9216\n",
      "[164/1762] D loss: 1.4711, G loss: 0.4842\n",
      "[244/1762] D loss: 1.4966, G loss: 0.8449\n",
      "[324/1762] D loss: 1.4062, G loss: 0.6851\n",
      "[404/1762] D loss: 1.3962, G loss: 0.7319\n",
      "[484/1762] D loss: 1.4254, G loss: 0.9302\n",
      "[564/1762] D loss: 1.3684, G loss: 0.7968\n",
      "[644/1762] D loss: 1.3913, G loss: 0.6642\n",
      "[724/1762] D loss: 1.3945, G loss: 0.8608\n",
      "[804/1762] D loss: 1.3981, G loss: 0.6636\n",
      "[884/1762] D loss: 1.2582, G loss: 0.8005\n",
      "[964/1762] D loss: 1.3912, G loss: 0.6806\n",
      "[1044/1762] D loss: 1.3943, G loss: 0.7233\n",
      "[1124/1762] D loss: 1.3120, G loss: 0.7057\n",
      "[1204/1762] D loss: 1.3884, G loss: 0.7315\n",
      "[1284/1762] D loss: 1.3928, G loss: 0.6653\n",
      "[1364/1762] D loss: 1.2131, G loss: 0.7836\n",
      "[1444/1762] D loss: 1.3908, G loss: 0.7399\n",
      "[1524/1762] D loss: 1.0621, G loss: 0.8234\n",
      "[1604/1762] D loss: 1.2243, G loss: 0.7777\n",
      "[1684/1762] D loss: 1.3878, G loss: 0.6696\n",
      "[1762/1762] D loss: 1.0000, G loss: 0.9913\n",
      "train error: \n",
      " D loss: 1.343970, G loss: 0.709460, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 84.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.336540, G loss: 0.717673, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 81.1% \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3901, G loss: 0.7073\n",
      "[84/1762] D loss: 1.3871, G loss: 0.6748\n",
      "[164/1762] D loss: 1.3872, G loss: 0.7186\n",
      "[244/1762] D loss: 1.3877, G loss: 0.6434\n",
      "[324/1762] D loss: 1.3880, G loss: 0.6592\n",
      "[404/1762] D loss: 1.2144, G loss: 0.7985\n",
      "[484/1762] D loss: 1.3958, G loss: 0.7509\n",
      "[564/1762] D loss: 1.3876, G loss: 0.6699\n",
      "[644/1762] D loss: 1.3905, G loss: 0.7368\n",
      "[724/1762] D loss: 1.3892, G loss: 0.6691\n",
      "[804/1762] D loss: 1.1972, G loss: 0.8018\n",
      "[884/1762] D loss: 1.3920, G loss: 0.6705\n",
      "[964/1762] D loss: 1.3867, G loss: 0.7013\n",
      "[1044/1762] D loss: 1.3850, G loss: 0.7292\n",
      "[1124/1762] D loss: 1.3903, G loss: 0.6631\n",
      "[1204/1762] D loss: 1.3865, G loss: 0.7383\n",
      "[1284/1762] D loss: 1.3699, G loss: 0.8118\n",
      "[1364/1762] D loss: 1.3884, G loss: 0.7609\n",
      "[1444/1762] D loss: 1.3787, G loss: 0.6470\n",
      "[1524/1762] D loss: 1.3891, G loss: 0.7392\n",
      "[1604/1762] D loss: 1.3799, G loss: 0.6892\n",
      "[1684/1762] D loss: 1.1652, G loss: 0.8172\n",
      "[1762/1762] D loss: 1.4178, G loss: 0.7939\n",
      "train error: \n",
      " D loss: 1.333773, G loss: 0.751020, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 83.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.322121, G loss: 0.760437, D accuracy: 54.1%, cell accuracy: 99.7%, board accuracy: 79.1% \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1710, G loss: 0.8083\n",
      "[84/1762] D loss: 1.3974, G loss: 0.6494\n",
      "[164/1762] D loss: 1.3860, G loss: 0.7055\n",
      "[244/1762] D loss: 1.3965, G loss: 0.6522\n",
      "[324/1762] D loss: 1.4054, G loss: 0.6314\n",
      "[404/1762] D loss: 1.3901, G loss: 0.7767\n",
      "[484/1762] D loss: 1.2118, G loss: 0.8583\n",
      "[564/1762] D loss: 1.1650, G loss: 0.7776\n",
      "[644/1762] D loss: 1.1748, G loss: 0.7932\n",
      "[724/1762] D loss: 1.3863, G loss: 0.7218\n",
      "[804/1762] D loss: 1.3896, G loss: 0.6724\n",
      "[884/1762] D loss: 1.3873, G loss: 0.6652\n",
      "[964/1762] D loss: 1.3989, G loss: 0.6594\n",
      "[1044/1762] D loss: 1.3921, G loss: 0.6992\n",
      "[1124/1762] D loss: 1.4086, G loss: 0.8133\n",
      "[1204/1762] D loss: 1.3896, G loss: 0.7418\n",
      "[1284/1762] D loss: 1.3849, G loss: 0.8062\n",
      "[1364/1762] D loss: 1.3931, G loss: 0.7306\n",
      "[1444/1762] D loss: 1.1700, G loss: 0.8266\n",
      "[1524/1762] D loss: 0.9379, G loss: 0.9222\n",
      "[1604/1762] D loss: 1.4482, G loss: 0.8270\n",
      "[1684/1762] D loss: 1.3989, G loss: 0.7936\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.7193\n",
      "train error: \n",
      " D loss: 1.331161, G loss: 0.741232, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 80.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.317452, G loss: 0.748825, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 77.0% \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1628, G loss: 0.8415\n",
      "[84/1762] D loss: 1.3987, G loss: 0.8050\n",
      "[164/1762] D loss: 1.3967, G loss: 0.7137\n",
      "[244/1762] D loss: 1.4095, G loss: 0.8128\n",
      "[324/1762] D loss: 1.3944, G loss: 0.7570\n",
      "[404/1762] D loss: 1.2730, G loss: 0.8156\n",
      "[484/1762] D loss: 1.3916, G loss: 0.7800\n",
      "[564/1762] D loss: 1.3915, G loss: 0.5903\n",
      "[644/1762] D loss: 1.3854, G loss: 0.7324\n",
      "[724/1762] D loss: 1.3969, G loss: 0.6866\n",
      "[804/1762] D loss: 1.4073, G loss: 0.8029\n",
      "[884/1762] D loss: 1.3946, G loss: 0.6739\n",
      "[964/1762] D loss: 1.3877, G loss: 0.6942\n",
      "[1044/1762] D loss: 1.3885, G loss: 0.7137\n",
      "[1124/1762] D loss: 1.1484, G loss: 0.8977\n",
      "[1204/1762] D loss: 1.1721, G loss: 0.8810\n",
      "[1284/1762] D loss: 1.3900, G loss: 0.7167\n",
      "[1364/1762] D loss: 1.3802, G loss: 0.7435\n",
      "[1444/1762] D loss: 1.3884, G loss: 0.7354\n",
      "[1524/1762] D loss: 1.4082, G loss: 0.6183\n",
      "[1604/1762] D loss: 1.4036, G loss: 0.5836\n",
      "[1684/1762] D loss: 1.4189, G loss: 0.8469\n",
      "[1762/1762] D loss: 1.4022, G loss: 0.7283\n",
      "train error: \n",
      " D loss: 1.328412, G loss: 0.704733, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 87.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.313791, G loss: 0.712896, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 83.9% \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3882, G loss: 0.6807\n",
      "[84/1762] D loss: 1.3872, G loss: 0.6648\n",
      "[164/1762] D loss: 1.1656, G loss: 0.8367\n",
      "[244/1762] D loss: 1.3870, G loss: 0.7141\n",
      "[324/1762] D loss: 1.3841, G loss: 0.7238\n",
      "[404/1762] D loss: 1.3888, G loss: 0.7800\n",
      "[484/1762] D loss: 1.4060, G loss: 0.7695\n",
      "[564/1762] D loss: 1.3897, G loss: 0.6800\n",
      "[644/1762] D loss: 1.4041, G loss: 0.7476\n",
      "[724/1762] D loss: 0.6629, G loss: 1.1015\n",
      "[804/1762] D loss: 1.3914, G loss: 0.7476\n",
      "[884/1762] D loss: 1.3956, G loss: 0.6215\n",
      "[964/1762] D loss: 1.4040, G loss: 0.8473\n",
      "[1044/1762] D loss: 1.4019, G loss: 0.5941\n",
      "[1124/1762] D loss: 1.4140, G loss: 0.8877\n",
      "[1204/1762] D loss: 1.3888, G loss: 0.7166\n",
      "[1284/1762] D loss: 1.3939, G loss: 0.7923\n",
      "[1364/1762] D loss: 1.4213, G loss: 0.8170\n",
      "[1444/1762] D loss: 1.1140, G loss: 0.9529\n",
      "[1524/1762] D loss: 1.1527, G loss: 0.8672\n",
      "[1604/1762] D loss: 1.1563, G loss: 1.0573\n",
      "[1684/1762] D loss: 1.3901, G loss: 0.6400\n",
      "[1762/1762] D loss: 1.3968, G loss: 0.7999\n",
      "train error: \n",
      " D loss: 1.335695, G loss: 0.871848, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.317907, G loss: 0.884472, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 84.8% \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4174, G loss: 0.8537\n",
      "[84/1762] D loss: 0.9139, G loss: 0.9391\n",
      "[164/1762] D loss: 1.3956, G loss: 0.8023\n",
      "[244/1762] D loss: 1.3934, G loss: 0.7371\n",
      "[324/1762] D loss: 1.3888, G loss: 0.7696\n",
      "[404/1762] D loss: 1.3966, G loss: 0.8014\n",
      "[484/1762] D loss: 1.3962, G loss: 0.7926\n",
      "[564/1762] D loss: 1.4051, G loss: 0.7919\n",
      "[644/1762] D loss: 1.3913, G loss: 0.7654\n",
      "[724/1762] D loss: 1.4109, G loss: 0.7711\n",
      "[804/1762] D loss: 1.3913, G loss: 0.7336\n",
      "[884/1762] D loss: 1.3881, G loss: 0.6426\n",
      "[964/1762] D loss: 1.3873, G loss: 0.7428\n",
      "[1044/1762] D loss: 1.1406, G loss: 0.8604\n",
      "[1124/1762] D loss: 1.3885, G loss: 0.7234\n",
      "[1204/1762] D loss: 1.3901, G loss: 0.6626\n",
      "[1284/1762] D loss: 1.3906, G loss: 0.6856\n",
      "[1364/1762] D loss: 1.4018, G loss: 0.7334\n",
      "[1444/1762] D loss: 1.3905, G loss: 0.6513\n",
      "[1524/1762] D loss: 1.3904, G loss: 0.7109\n",
      "[1604/1762] D loss: 1.3250, G loss: 0.8530\n",
      "[1684/1762] D loss: 1.3893, G loss: 0.7414\n",
      "[1762/1762] D loss: 1.3918, G loss: 0.8018\n",
      "train error: \n",
      " D loss: 1.321755, G loss: 0.787714, D accuracy: 53.9%, cell accuracy: 99.7%, board accuracy: 80.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.305868, G loss: 0.797771, D accuracy: 55.2%, cell accuracy: 99.7%, board accuracy: 75.9% \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4233, G loss: 0.7619\n",
      "[84/1762] D loss: 1.1617, G loss: 0.8208\n",
      "[164/1762] D loss: 1.3907, G loss: 0.6838\n",
      "[244/1762] D loss: 1.3868, G loss: 0.6910\n",
      "[324/1762] D loss: 1.4119, G loss: 0.7219\n",
      "[404/1762] D loss: 1.3871, G loss: 0.6542\n",
      "[484/1762] D loss: 1.4061, G loss: 0.7991\n",
      "[564/1762] D loss: 1.3865, G loss: 0.6683\n",
      "[644/1762] D loss: 1.3886, G loss: 0.7627\n",
      "[724/1762] D loss: 1.3905, G loss: 0.7025\n",
      "[804/1762] D loss: 1.9323, G loss: 0.7263\n",
      "[884/1762] D loss: 1.2783, G loss: 0.8586\n",
      "[964/1762] D loss: 1.0511, G loss: 0.9174\n",
      "[1044/1762] D loss: 1.3860, G loss: 0.5673\n",
      "[1124/1762] D loss: 1.4640, G loss: 0.8263\n",
      "[1204/1762] D loss: 1.4590, G loss: 0.8649\n",
      "[1284/1762] D loss: 1.3917, G loss: 0.6884\n",
      "[1364/1762] D loss: 1.4446, G loss: 0.9366\n",
      "[1444/1762] D loss: 1.3970, G loss: 0.7782\n",
      "[1524/1762] D loss: 1.1820, G loss: 0.7862\n",
      "[1604/1762] D loss: 1.3877, G loss: 0.6943\n",
      "[1684/1762] D loss: 1.4002, G loss: 0.7686\n",
      "[1762/1762] D loss: 1.3859, G loss: 0.6862\n",
      "train error: \n",
      " D loss: 1.351839, G loss: 0.665004, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 84.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.345391, G loss: 0.667113, D accuracy: 55.0%, cell accuracy: 99.7%, board accuracy: 79.5% \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4021, G loss: 0.6119\n",
      "[84/1762] D loss: 1.3905, G loss: 0.7380\n",
      "[164/1762] D loss: 1.3446, G loss: 0.7889\n",
      "[244/1762] D loss: 1.3925, G loss: 0.7587\n",
      "[324/1762] D loss: 1.3317, G loss: 0.7145\n",
      "[404/1762] D loss: 1.2137, G loss: 0.8077\n",
      "[484/1762] D loss: 1.3864, G loss: 0.7085\n",
      "[564/1762] D loss: 1.4344, G loss: 0.8796\n",
      "[644/1762] D loss: 1.3881, G loss: 0.6893\n",
      "[724/1762] D loss: 1.2091, G loss: 0.7665\n",
      "[804/1762] D loss: 1.3921, G loss: 0.7444\n",
      "[884/1762] D loss: 1.3918, G loss: 0.7513\n",
      "[964/1762] D loss: 1.3896, G loss: 0.7344\n",
      "[1044/1762] D loss: 1.3913, G loss: 0.7751\n",
      "[1124/1762] D loss: 1.3919, G loss: 0.7745\n",
      "[1204/1762] D loss: 1.3891, G loss: 0.7361\n",
      "[1284/1762] D loss: 1.2033, G loss: 0.7205\n",
      "[1364/1762] D loss: 1.3895, G loss: 0.7241\n",
      "[1444/1762] D loss: 1.3882, G loss: 0.7276\n",
      "[1524/1762] D loss: 1.1723, G loss: 0.8161\n",
      "[1604/1762] D loss: 1.3963, G loss: 0.8016\n",
      "[1684/1762] D loss: 1.3952, G loss: 0.7422\n",
      "[1762/1762] D loss: 0.8615, G loss: 1.0876\n",
      "train error: \n",
      " D loss: 1.332910, G loss: 0.760446, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 87.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.321641, G loss: 0.765829, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 83.2% \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3893, G loss: 0.7233\n",
      "[84/1762] D loss: 1.3877, G loss: 0.6553\n",
      "[164/1762] D loss: 1.1617, G loss: 0.7749\n",
      "[244/1762] D loss: 1.1871, G loss: 0.8467\n",
      "[324/1762] D loss: 1.1508, G loss: 0.8839\n",
      "[404/1762] D loss: 1.3885, G loss: 0.6815\n",
      "[484/1762] D loss: 1.3939, G loss: 0.6445\n",
      "[564/1762] D loss: 1.3876, G loss: 0.7458\n",
      "[644/1762] D loss: 1.3878, G loss: 0.6594\n",
      "[724/1762] D loss: 1.1684, G loss: 0.7640\n",
      "[804/1762] D loss: 1.3879, G loss: 0.6963\n",
      "[884/1762] D loss: 1.3977, G loss: 0.6331\n",
      "[964/1762] D loss: 1.3972, G loss: 0.7975\n",
      "[1044/1762] D loss: 1.3969, G loss: 0.7832\n",
      "[1124/1762] D loss: 1.3909, G loss: 0.7677\n",
      "[1204/1762] D loss: 1.2651, G loss: 0.6954\n",
      "[1284/1762] D loss: 1.3986, G loss: 0.6303\n",
      "[1364/1762] D loss: 1.4115, G loss: 0.8461\n",
      "[1444/1762] D loss: 1.3891, G loss: 0.6457\n",
      "[1524/1762] D loss: 0.9839, G loss: 0.9344\n",
      "[1604/1762] D loss: 1.3929, G loss: 0.6757\n",
      "[1684/1762] D loss: 1.3933, G loss: 0.6316\n",
      "[1762/1762] D loss: 1.3814, G loss: 0.7360\n",
      "train error: \n",
      " D loss: 1.328644, G loss: 0.786898, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 87.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.315745, G loss: 0.791016, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 84.3% \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3899, G loss: 0.7450\n",
      "[84/1762] D loss: 1.3805, G loss: 0.6763\n",
      "[164/1762] D loss: 1.3948, G loss: 0.7714\n",
      "[244/1762] D loss: 1.3878, G loss: 0.6702\n",
      "[324/1762] D loss: 1.3801, G loss: 0.6829\n",
      "[404/1762] D loss: 1.3811, G loss: 0.6756\n",
      "[484/1762] D loss: 1.3964, G loss: 0.7800\n",
      "[564/1762] D loss: 1.1440, G loss: 0.8183\n",
      "[644/1762] D loss: 1.3922, G loss: 0.7506\n",
      "[724/1762] D loss: 1.3907, G loss: 0.7386\n",
      "[804/1762] D loss: 1.1404, G loss: 0.7685\n",
      "[884/1762] D loss: 0.9333, G loss: 1.0586\n",
      "[964/1762] D loss: 1.3787, G loss: 0.7473\n",
      "[1044/1762] D loss: 1.3899, G loss: 0.6729\n",
      "[1124/1762] D loss: 1.3907, G loss: 0.7268\n",
      "[1204/1762] D loss: 1.1380, G loss: 0.8476\n",
      "[1284/1762] D loss: 1.3868, G loss: 0.6630\n",
      "[1364/1762] D loss: 1.4002, G loss: 0.7722\n",
      "[1444/1762] D loss: 1.3910, G loss: 0.6253\n",
      "[1524/1762] D loss: 1.4041, G loss: 0.5681\n",
      "[1604/1762] D loss: 1.3889, G loss: 0.7306\n",
      "[1684/1762] D loss: 1.3962, G loss: 0.7441\n",
      "[1762/1762] D loss: 1.3898, G loss: 0.7021\n",
      "train error: \n",
      " D loss: 1.325157, G loss: 0.751692, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.308823, G loss: 0.760147, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 85.9% \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3160, G loss: 0.8113\n",
      "[84/1762] D loss: 1.3906, G loss: 0.7946\n",
      "[164/1762] D loss: 1.3739, G loss: 0.6937\n",
      "[244/1762] D loss: 1.4243, G loss: 0.8344\n",
      "[324/1762] D loss: 1.1525, G loss: 0.7622\n",
      "[404/1762] D loss: 0.8944, G loss: 1.0061\n",
      "[484/1762] D loss: 1.4100, G loss: 0.7432\n",
      "[564/1762] D loss: 1.3943, G loss: 0.5995\n",
      "[644/1762] D loss: 1.3992, G loss: 0.6841\n",
      "[724/1762] D loss: 1.1334, G loss: 0.9203\n",
      "[804/1762] D loss: 1.4032, G loss: 0.7537\n",
      "[884/1762] D loss: 1.4125, G loss: 0.8123\n",
      "[964/1762] D loss: 1.4051, G loss: 0.6492\n",
      "[1044/1762] D loss: 1.1797, G loss: 0.7404\n",
      "[1124/1762] D loss: 1.3897, G loss: 0.7079\n",
      "[1204/1762] D loss: 1.1091, G loss: 0.9023\n",
      "[1284/1762] D loss: 1.3987, G loss: 0.6838\n",
      "[1364/1762] D loss: 1.1221, G loss: 0.8807\n",
      "[1444/1762] D loss: 1.1363, G loss: 0.8380\n",
      "[1524/1762] D loss: 1.1384, G loss: 0.8868\n",
      "[1604/1762] D loss: 1.1516, G loss: 0.7567\n",
      "[1684/1762] D loss: 1.2092, G loss: 0.7914\n",
      "[1762/1762] D loss: 1.3876, G loss: 0.6700\n",
      "train error: \n",
      " D loss: 1.324659, G loss: 0.780649, D accuracy: 53.1%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.308618, G loss: 0.790326, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 85.2% \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.7165\n",
      "[84/1762] D loss: 1.3927, G loss: 0.6680\n",
      "[164/1762] D loss: 1.3911, G loss: 0.7195\n",
      "[244/1762] D loss: 1.3937, G loss: 0.7122\n",
      "[324/1762] D loss: 1.1736, G loss: 0.8309\n",
      "[404/1762] D loss: 1.3907, G loss: 0.6988\n",
      "[484/1762] D loss: 1.4007, G loss: 0.6218\n",
      "[564/1762] D loss: 1.1379, G loss: 0.8387\n",
      "[644/1762] D loss: 1.1622, G loss: 0.8757\n",
      "[724/1762] D loss: 1.3982, G loss: 0.7562\n",
      "[804/1762] D loss: 1.3886, G loss: 0.6927\n",
      "[884/1762] D loss: 1.3980, G loss: 0.7277\n",
      "[964/1762] D loss: 1.3933, G loss: 0.6557\n",
      "[1044/1762] D loss: 1.1317, G loss: 0.8620\n",
      "[1124/1762] D loss: 1.3900, G loss: 0.6458\n",
      "[1204/1762] D loss: 1.3866, G loss: 0.7112\n",
      "[1284/1762] D loss: 1.3972, G loss: 0.7950\n",
      "[1364/1762] D loss: 1.3907, G loss: 0.6306\n",
      "[1444/1762] D loss: 1.3690, G loss: 0.7362\n",
      "[1524/1762] D loss: 1.3887, G loss: 0.6735\n",
      "[1604/1762] D loss: 1.3868, G loss: 0.7200\n",
      "[1684/1762] D loss: 1.3893, G loss: 0.6636\n",
      "[1762/1762] D loss: 1.4274, G loss: 0.8601\n",
      "train error: \n",
      " D loss: 1.323272, G loss: 0.751701, D accuracy: 53.2%, cell accuracy: 99.7%, board accuracy: 73.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.306960, G loss: 0.761736, D accuracy: 54.3%, cell accuracy: 99.7%, board accuracy: 72.0% \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1405, G loss: 0.8250\n",
      "[84/1762] D loss: 1.3999, G loss: 0.7654\n",
      "[164/1762] D loss: 1.3918, G loss: 0.6801\n",
      "[244/1762] D loss: 1.3926, G loss: 0.6748\n",
      "[324/1762] D loss: 1.3914, G loss: 0.6959\n",
      "[404/1762] D loss: 1.3936, G loss: 0.6732\n",
      "[484/1762] D loss: 1.3898, G loss: 0.6768\n",
      "[564/1762] D loss: 1.3926, G loss: 0.6307\n",
      "[644/1762] D loss: 1.4162, G loss: 0.8912\n",
      "[724/1762] D loss: 1.3906, G loss: 0.6491\n",
      "[804/1762] D loss: 1.1652, G loss: 0.9763\n",
      "[884/1762] D loss: 1.3899, G loss: 0.7426\n",
      "[964/1762] D loss: 1.3951, G loss: 0.6545\n",
      "[1044/1762] D loss: 1.3880, G loss: 0.7270\n",
      "[1124/1762] D loss: 1.3943, G loss: 0.6646\n",
      "[1204/1762] D loss: 1.3883, G loss: 0.7388\n",
      "[1284/1762] D loss: 1.3882, G loss: 0.6341\n",
      "[1364/1762] D loss: 0.8678, G loss: 1.0912\n",
      "[1444/1762] D loss: 1.3870, G loss: 0.6765\n",
      "[1524/1762] D loss: 1.1571, G loss: 0.9151\n",
      "[1604/1762] D loss: 1.1749, G loss: 0.9822\n",
      "[1684/1762] D loss: 1.3894, G loss: 0.6665\n",
      "[1762/1762] D loss: 1.3891, G loss: 0.7348\n",
      "train error: \n",
      " D loss: 1.321833, G loss: 0.726501, D accuracy: 53.7%, cell accuracy: 99.6%, board accuracy: 59.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.306001, G loss: 0.737558, D accuracy: 54.1%, cell accuracy: 99.6%, board accuracy: 60.9% \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3890, G loss: 0.6763\n",
      "[84/1762] D loss: 1.3817, G loss: 0.7012\n",
      "[164/1762] D loss: 1.4009, G loss: 0.6449\n",
      "[244/1762] D loss: 1.1532, G loss: 0.7492\n",
      "[324/1762] D loss: 1.3925, G loss: 0.7896\n",
      "[404/1762] D loss: 1.3905, G loss: 0.7746\n",
      "[484/1762] D loss: 1.3946, G loss: 0.6383\n",
      "[564/1762] D loss: 1.3880, G loss: 0.6745\n",
      "[644/1762] D loss: 1.4088, G loss: 0.6704\n",
      "[724/1762] D loss: 1.3998, G loss: 0.7599\n",
      "[804/1762] D loss: 1.1367, G loss: 0.9278\n",
      "[884/1762] D loss: 1.3892, G loss: 0.6989\n",
      "[964/1762] D loss: 1.3944, G loss: 0.6922\n",
      "[1044/1762] D loss: 0.8707, G loss: 1.0284\n",
      "[1124/1762] D loss: 1.3906, G loss: 0.6686\n",
      "[1204/1762] D loss: 1.1668, G loss: 0.7375\n",
      "[1284/1762] D loss: 1.3877, G loss: 0.7951\n",
      "[1364/1762] D loss: 1.1416, G loss: 0.8797\n",
      "[1444/1762] D loss: 1.3924, G loss: 0.6799\n",
      "[1524/1762] D loss: 1.6982, G loss: 0.5190\n",
      "[1604/1762] D loss: 1.8728, G loss: 0.7347\n",
      "[1684/1762] D loss: 1.1922, G loss: 1.4322\n",
      "[1762/1762] D loss: 1.2498, G loss: 0.6670\n",
      "train error: \n",
      " D loss: 1.165864, G loss: 0.940435, D accuracy: 79.5%, cell accuracy: 99.4%, board accuracy: 24.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.158599, G loss: 0.962944, D accuracy: 78.0%, cell accuracy: 99.4%, board accuracy: 23.6% \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2136, G loss: 0.7846\n",
      "[84/1762] D loss: 1.3943, G loss: 0.8921\n",
      "[164/1762] D loss: 1.4529, G loss: 0.7591\n",
      "[244/1762] D loss: 1.3493, G loss: 0.7689\n",
      "[324/1762] D loss: 1.4104, G loss: 0.8852\n",
      "[404/1762] D loss: 1.4062, G loss: 0.7463\n",
      "[484/1762] D loss: 1.3843, G loss: 0.7636\n",
      "[564/1762] D loss: 1.4019, G loss: 0.6951\n",
      "[644/1762] D loss: 1.4192, G loss: 0.8630\n",
      "[724/1762] D loss: 1.3923, G loss: 0.6593\n",
      "[804/1762] D loss: 1.1685, G loss: 0.7983\n",
      "[884/1762] D loss: 1.3886, G loss: 0.7293\n",
      "[964/1762] D loss: 1.1903, G loss: 0.8608\n",
      "[1044/1762] D loss: 1.4263, G loss: 0.8159\n",
      "[1124/1762] D loss: 1.2844, G loss: 0.7003\n",
      "[1204/1762] D loss: 1.3829, G loss: 0.7258\n",
      "[1284/1762] D loss: 1.3882, G loss: 0.6867\n",
      "[1364/1762] D loss: 1.1876, G loss: 0.7201\n",
      "[1444/1762] D loss: 1.3837, G loss: 0.6958\n",
      "[1524/1762] D loss: 1.3940, G loss: 0.7337\n",
      "[1604/1762] D loss: 1.3905, G loss: 0.7101\n",
      "[1684/1762] D loss: 1.3874, G loss: 0.6728\n",
      "[1762/1762] D loss: 1.3889, G loss: 0.6918\n",
      "train error: \n",
      " D loss: 1.331851, G loss: 0.753040, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.319520, G loss: 0.760742, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3908, G loss: 0.7402\n",
      "[84/1762] D loss: 1.1606, G loss: 0.8610\n",
      "[164/1762] D loss: 1.3882, G loss: 0.6760\n",
      "[244/1762] D loss: 1.3790, G loss: 0.7809\n",
      "[324/1762] D loss: 1.4870, G loss: 0.7450\n",
      "[404/1762] D loss: 1.5648, G loss: 0.7123\n",
      "[484/1762] D loss: 1.4224, G loss: 0.7034\n",
      "[564/1762] D loss: 1.1786, G loss: 0.7640\n",
      "[644/1762] D loss: 1.0039, G loss: 0.9748\n",
      "[724/1762] D loss: 1.2918, G loss: 0.7886\n",
      "[804/1762] D loss: 1.3878, G loss: 0.7405\n",
      "[884/1762] D loss: 1.4085, G loss: 0.7648\n",
      "[964/1762] D loss: 1.4001, G loss: 0.7625\n",
      "[1044/1762] D loss: 1.3854, G loss: 0.7015\n",
      "[1124/1762] D loss: 1.3877, G loss: 0.6771\n",
      "[1204/1762] D loss: 1.3841, G loss: 0.7952\n",
      "[1284/1762] D loss: 1.2045, G loss: 0.8030\n",
      "[1364/1762] D loss: 1.3694, G loss: 0.6461\n",
      "[1444/1762] D loss: 1.3795, G loss: 0.6977\n",
      "[1524/1762] D loss: 1.1923, G loss: 0.7801\n",
      "[1604/1762] D loss: 1.3902, G loss: 0.6582\n",
      "[1684/1762] D loss: 1.4024, G loss: 0.7135\n",
      "[1762/1762] D loss: 1.3955, G loss: 0.5904\n",
      "train error: \n",
      " D loss: 1.357362, G loss: 0.652600, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 88.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.355375, G loss: 0.659801, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3894, G loss: 0.6451\n",
      "[84/1762] D loss: 1.3450, G loss: 0.7050\n",
      "[164/1762] D loss: 1.3940, G loss: 0.6489\n",
      "[244/1762] D loss: 1.3888, G loss: 0.8103\n",
      "[324/1762] D loss: 1.3941, G loss: 0.7777\n",
      "[404/1762] D loss: 1.3940, G loss: 0.6319\n",
      "[484/1762] D loss: 1.1812, G loss: 1.0256\n",
      "[564/1762] D loss: 1.2168, G loss: 0.8145\n",
      "[644/1762] D loss: 1.2187, G loss: 0.7504\n",
      "[724/1762] D loss: 1.3940, G loss: 0.7558\n",
      "[804/1762] D loss: 1.3879, G loss: 0.7430\n",
      "[884/1762] D loss: 1.3866, G loss: 0.6941\n",
      "[964/1762] D loss: 1.3862, G loss: 0.7590\n",
      "[1044/1762] D loss: 1.1813, G loss: 0.8872\n",
      "[1124/1762] D loss: 1.1896, G loss: 0.7353\n",
      "[1204/1762] D loss: 1.3894, G loss: 0.7275\n",
      "[1284/1762] D loss: 1.3899, G loss: 0.7165\n",
      "[1364/1762] D loss: 1.4068, G loss: 0.6762\n",
      "[1444/1762] D loss: 1.3895, G loss: 0.7526\n",
      "[1524/1762] D loss: 1.3941, G loss: 0.6247\n",
      "[1604/1762] D loss: 1.3933, G loss: 0.7263\n",
      "[1684/1762] D loss: 1.2491, G loss: 0.7854\n",
      "[1762/1762] D loss: 1.3890, G loss: 0.6606\n",
      "train error: \n",
      " D loss: 1.335502, G loss: 0.728937, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 87.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.328863, G loss: 0.734855, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 84.3% \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3893, G loss: 0.7285\n",
      "[84/1762] D loss: 1.3855, G loss: 0.7596\n",
      "[164/1762] D loss: 1.1645, G loss: 0.7916\n",
      "[244/1762] D loss: 1.3790, G loss: 0.8484\n",
      "[324/1762] D loss: 1.3849, G loss: 0.6730\n",
      "[404/1762] D loss: 1.3878, G loss: 0.7191\n",
      "[484/1762] D loss: 1.1943, G loss: 0.7900\n",
      "[564/1762] D loss: 1.3910, G loss: 0.7710\n",
      "[644/1762] D loss: 1.1793, G loss: 0.7836\n",
      "[724/1762] D loss: 1.3897, G loss: 0.6757\n",
      "[804/1762] D loss: 1.3962, G loss: 0.7911\n",
      "[884/1762] D loss: 1.3822, G loss: 0.7301\n",
      "[964/1762] D loss: 1.3867, G loss: 0.6669\n",
      "[1044/1762] D loss: 1.3880, G loss: 0.7003\n",
      "[1124/1762] D loss: 1.3917, G loss: 0.6146\n",
      "[1204/1762] D loss: 1.1459, G loss: 0.8407\n",
      "[1284/1762] D loss: 1.3896, G loss: 0.6661\n",
      "[1364/1762] D loss: 1.4063, G loss: 0.8286\n",
      "[1444/1762] D loss: 1.4018, G loss: 0.6118\n",
      "[1524/1762] D loss: 1.1584, G loss: 0.9430\n",
      "[1604/1762] D loss: 1.1777, G loss: 0.7307\n",
      "[1684/1762] D loss: 1.4069, G loss: 0.6690\n",
      "[1762/1762] D loss: 1.3787, G loss: 0.7656\n",
      "train error: \n",
      " D loss: 1.335997, G loss: 0.747136, D accuracy: 53.3%, cell accuracy: 99.7%, board accuracy: 76.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.318024, G loss: 0.760799, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 73.6% \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3474, G loss: 0.8247\n",
      "[84/1762] D loss: 1.3919, G loss: 0.8245\n",
      "[164/1762] D loss: 1.3909, G loss: 0.6747\n",
      "[244/1762] D loss: 1.3920, G loss: 0.6840\n",
      "[324/1762] D loss: 1.3907, G loss: 0.6591\n",
      "[404/1762] D loss: 1.3479, G loss: 0.7505\n",
      "[484/1762] D loss: 1.3922, G loss: 0.7260\n",
      "[564/1762] D loss: 1.3785, G loss: 0.6117\n",
      "[644/1762] D loss: 1.3920, G loss: 0.7072\n",
      "[724/1762] D loss: 0.6403, G loss: 1.0731\n",
      "[804/1762] D loss: 1.3951, G loss: 0.7461\n",
      "[884/1762] D loss: 1.3908, G loss: 0.7362\n",
      "[964/1762] D loss: 1.1469, G loss: 0.8057\n",
      "[1044/1762] D loss: 1.3881, G loss: 0.7051\n",
      "[1124/1762] D loss: 1.3963, G loss: 0.7100\n",
      "[1204/1762] D loss: 1.1472, G loss: 0.8310\n",
      "[1284/1762] D loss: 1.4017, G loss: 0.7556\n",
      "[1364/1762] D loss: 0.8970, G loss: 0.9197\n",
      "[1444/1762] D loss: 1.4239, G loss: 0.8397\n",
      "[1524/1762] D loss: 1.1334, G loss: 0.8156\n",
      "[1604/1762] D loss: 1.3910, G loss: 0.7075\n",
      "[1684/1762] D loss: 1.3892, G loss: 0.6764\n",
      "[1762/1762] D loss: 1.4577, G loss: 0.9404\n",
      "train error: \n",
      " D loss: 1.329659, G loss: 0.721254, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 80.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.314028, G loss: 0.732326, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 79.5% \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4397, G loss: 0.5623\n",
      "[84/1762] D loss: 1.4793, G loss: 0.6901\n",
      "[164/1762] D loss: 1.0943, G loss: 0.9318\n",
      "[244/1762] D loss: 1.3917, G loss: 0.6909\n",
      "[324/1762] D loss: 1.3919, G loss: 0.6602\n",
      "[404/1762] D loss: 1.3968, G loss: 0.7814\n",
      "[484/1762] D loss: 1.3891, G loss: 0.6821\n",
      "[564/1762] D loss: 1.3932, G loss: 0.7680\n",
      "[644/1762] D loss: 1.3891, G loss: 0.6367\n",
      "[724/1762] D loss: 1.3866, G loss: 0.6716\n",
      "[804/1762] D loss: 1.3913, G loss: 0.7679\n",
      "[884/1762] D loss: 1.3547, G loss: 0.7229\n",
      "[964/1762] D loss: 1.1111, G loss: 0.9079\n",
      "[1044/1762] D loss: 1.3913, G loss: 0.6905\n",
      "[1124/1762] D loss: 1.3896, G loss: 0.6611\n",
      "[1204/1762] D loss: 1.4189, G loss: 0.8259\n",
      "[1284/1762] D loss: 1.3536, G loss: 0.8527\n",
      "[1364/1762] D loss: 1.1443, G loss: 0.8009\n",
      "[1444/1762] D loss: 1.3900, G loss: 0.7168\n",
      "[1524/1762] D loss: 1.4070, G loss: 0.6772\n",
      "[1604/1762] D loss: 1.4203, G loss: 0.7764\n",
      "[1684/1762] D loss: 1.4159, G loss: 0.8068\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.7303\n",
      "train error: \n",
      " D loss: 1.318746, G loss: 0.782792, D accuracy: 55.2%, cell accuracy: 99.7%, board accuracy: 76.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.306237, G loss: 0.792977, D accuracy: 55.1%, cell accuracy: 99.7%, board accuracy: 74.3% \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4047, G loss: 0.7643\n",
      "[84/1762] D loss: 1.0627, G loss: 0.9225\n",
      "[164/1762] D loss: 1.3898, G loss: 0.7085\n",
      "[244/1762] D loss: 1.3475, G loss: 0.6798\n",
      "[324/1762] D loss: 1.3552, G loss: 0.7405\n",
      "[404/1762] D loss: 1.3986, G loss: 0.7718\n",
      "[484/1762] D loss: 1.3812, G loss: 0.7438\n",
      "[564/1762] D loss: 1.3745, G loss: 0.7146\n",
      "[644/1762] D loss: 1.0710, G loss: 0.9071\n",
      "[724/1762] D loss: 1.2385, G loss: 0.7634\n",
      "[804/1762] D loss: 1.3852, G loss: 0.7023\n",
      "[884/1762] D loss: 1.3851, G loss: 0.7143\n",
      "[964/1762] D loss: 1.3871, G loss: 0.7373\n",
      "[1044/1762] D loss: 1.3939, G loss: 0.6822\n",
      "[1124/1762] D loss: 1.3750, G loss: 0.7616\n",
      "[1204/1762] D loss: 1.4050, G loss: 0.6699\n",
      "[1284/1762] D loss: 1.3749, G loss: 0.6964\n",
      "[1364/1762] D loss: 1.3648, G loss: 0.7767\n",
      "[1444/1762] D loss: 1.3746, G loss: 0.6722\n",
      "[1524/1762] D loss: 1.4019, G loss: 0.7272\n",
      "[1604/1762] D loss: 1.3908, G loss: 0.6866\n",
      "[1684/1762] D loss: 1.1838, G loss: 0.8625\n",
      "[1762/1762] D loss: 1.3779, G loss: 0.6292\n",
      "train error: \n",
      " D loss: 1.327289, G loss: 0.681079, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 86.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.312085, G loss: 0.689250, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 82.3% \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3933, G loss: 0.6290\n",
      "[84/1762] D loss: 1.3928, G loss: 0.6498\n",
      "[164/1762] D loss: 1.1209, G loss: 0.9297\n",
      "[244/1762] D loss: 1.1541, G loss: 0.8491\n",
      "[324/1762] D loss: 1.3941, G loss: 0.7733\n",
      "[404/1762] D loss: 1.3938, G loss: 0.7231\n",
      "[484/1762] D loss: 1.3894, G loss: 0.6434\n",
      "[564/1762] D loss: 1.1645, G loss: 0.8574\n",
      "[644/1762] D loss: 1.4846, G loss: 0.7159\n",
      "[724/1762] D loss: 1.4460, G loss: 0.9195\n",
      "[804/1762] D loss: 1.3691, G loss: 0.6823\n",
      "[884/1762] D loss: 1.3274, G loss: 1.2096\n",
      "[964/1762] D loss: 1.3460, G loss: 0.8354\n",
      "[1044/1762] D loss: 1.3957, G loss: 0.7177\n",
      "[1124/1762] D loss: 1.4096, G loss: 0.6818\n",
      "[1204/1762] D loss: 1.3932, G loss: 0.7028\n",
      "[1284/1762] D loss: 1.4018, G loss: 0.7239\n",
      "[1364/1762] D loss: 1.5788, G loss: 0.8127\n",
      "[1444/1762] D loss: 1.3613, G loss: 0.6599\n",
      "[1524/1762] D loss: 1.3909, G loss: 0.6802\n",
      "[1604/1762] D loss: 1.3916, G loss: 0.7499\n",
      "[1684/1762] D loss: 1.1894, G loss: 0.7545\n",
      "[1762/1762] D loss: 1.3896, G loss: 0.7569\n",
      "train error: \n",
      " D loss: 1.339402, G loss: 0.773974, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.334773, G loss: 0.785761, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 82.7% \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1837, G loss: 0.8343\n",
      "[84/1762] D loss: 1.3923, G loss: 0.6140\n",
      "[164/1762] D loss: 1.1503, G loss: 0.8417\n",
      "[244/1762] D loss: 1.1909, G loss: 0.7292\n",
      "[324/1762] D loss: 1.3884, G loss: 0.7072\n",
      "[404/1762] D loss: 1.3885, G loss: 0.6498\n",
      "[484/1762] D loss: 1.3905, G loss: 0.7033\n",
      "[564/1762] D loss: 1.3896, G loss: 0.6582\n",
      "[644/1762] D loss: 1.3970, G loss: 0.6700\n",
      "[724/1762] D loss: 1.3861, G loss: 0.7474\n",
      "[804/1762] D loss: 1.3439, G loss: 0.6507\n",
      "[884/1762] D loss: 1.4216, G loss: 0.6701\n",
      "[964/1762] D loss: 0.9283, G loss: 1.0052\n",
      "[1044/1762] D loss: 1.4289, G loss: 0.8008\n",
      "[1124/1762] D loss: 1.2221, G loss: 0.7385\n",
      "[1204/1762] D loss: 1.4028, G loss: 0.7676\n",
      "[1284/1762] D loss: 1.3912, G loss: 0.6705\n",
      "[1364/1762] D loss: 1.3559, G loss: 0.7385\n",
      "[1444/1762] D loss: 1.1594, G loss: 0.9144\n",
      "[1524/1762] D loss: 1.1871, G loss: 0.8209\n",
      "[1604/1762] D loss: 1.4063, G loss: 0.7644\n",
      "[1684/1762] D loss: 1.3905, G loss: 0.7383\n",
      "[1762/1762] D loss: 1.4069, G loss: 0.5961\n",
      "train error: \n",
      " D loss: 1.328856, G loss: 0.721860, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 88.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.317674, G loss: 0.733170, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 85.2% \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1262, G loss: 0.8510\n",
      "[84/1762] D loss: 1.3982, G loss: 0.8325\n",
      "[164/1762] D loss: 1.3698, G loss: 0.7145\n",
      "[244/1762] D loss: 1.3990, G loss: 0.6043\n",
      "[324/1762] D loss: 1.3948, G loss: 0.7980\n",
      "[404/1762] D loss: 1.3978, G loss: 0.7294\n",
      "[484/1762] D loss: 1.1180, G loss: 0.8177\n",
      "[564/1762] D loss: 1.4061, G loss: 0.8436\n",
      "[644/1762] D loss: 1.4112, G loss: 0.6049\n",
      "[724/1762] D loss: 1.3918, G loss: 0.7631\n",
      "[804/1762] D loss: 1.3865, G loss: 0.6725\n",
      "[884/1762] D loss: 1.3838, G loss: 0.7103\n",
      "[964/1762] D loss: 0.8999, G loss: 1.1067\n",
      "[1044/1762] D loss: 1.3559, G loss: 0.6724\n",
      "[1124/1762] D loss: 1.3905, G loss: 0.7395\n",
      "[1204/1762] D loss: 1.3910, G loss: 0.7561\n",
      "[1284/1762] D loss: 1.3887, G loss: 0.6755\n",
      "[1364/1762] D loss: 1.3888, G loss: 0.7597\n",
      "[1444/1762] D loss: 1.3870, G loss: 0.6475\n",
      "[1524/1762] D loss: 1.3934, G loss: 0.6572\n",
      "[1604/1762] D loss: 1.1526, G loss: 0.9785\n",
      "[1684/1762] D loss: 1.1328, G loss: 0.7643\n",
      "[1762/1762] D loss: 1.3892, G loss: 0.6875\n",
      "train error: \n",
      " D loss: 1.327069, G loss: 0.804516, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 88.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.313052, G loss: 0.815168, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 85.9% \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3841, G loss: 0.8061\n",
      "[84/1762] D loss: 1.4044, G loss: 0.5882\n",
      "[164/1762] D loss: 1.1368, G loss: 0.8520\n",
      "[244/1762] D loss: 1.3882, G loss: 0.7437\n",
      "[324/1762] D loss: 1.3875, G loss: 0.6317\n",
      "[404/1762] D loss: 1.3935, G loss: 0.7034\n",
      "[484/1762] D loss: 1.3953, G loss: 0.7201\n",
      "[564/1762] D loss: 1.3938, G loss: 0.7727\n",
      "[644/1762] D loss: 1.3894, G loss: 0.7046\n",
      "[724/1762] D loss: 1.3184, G loss: 0.7800\n",
      "[804/1762] D loss: 1.3879, G loss: 0.7344\n",
      "[884/1762] D loss: 1.3964, G loss: 0.6027\n",
      "[964/1762] D loss: 1.3917, G loss: 0.6877\n",
      "[1044/1762] D loss: 1.4012, G loss: 0.8223\n",
      "[1124/1762] D loss: 1.3802, G loss: 0.6642\n",
      "[1204/1762] D loss: 1.1152, G loss: 0.8393\n",
      "[1284/1762] D loss: 1.3908, G loss: 0.6541\n",
      "[1364/1762] D loss: 1.3890, G loss: 0.7363\n",
      "[1444/1762] D loss: 0.9060, G loss: 0.8885\n",
      "[1524/1762] D loss: 1.3927, G loss: 0.7261\n",
      "[1604/1762] D loss: 1.3899, G loss: 0.7363\n",
      "[1684/1762] D loss: 1.3994, G loss: 0.7527\n",
      "[1762/1762] D loss: 1.3871, G loss: 0.7207\n",
      "train error: \n",
      " D loss: 1.321840, G loss: 0.741646, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.308165, G loss: 0.752123, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 85.2% \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3902, G loss: 0.7221\n",
      "[84/1762] D loss: 1.3900, G loss: 0.6995\n",
      "[164/1762] D loss: 1.3939, G loss: 0.7231\n",
      "[244/1762] D loss: 1.3934, G loss: 0.7624\n",
      "[324/1762] D loss: 1.4043, G loss: 0.7907\n",
      "[404/1762] D loss: 1.3880, G loss: 0.7284\n",
      "[484/1762] D loss: 1.3918, G loss: 0.6806\n",
      "[564/1762] D loss: 1.1515, G loss: 0.7518\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6957\n",
      "[724/1762] D loss: 1.3904, G loss: 0.6807\n",
      "[804/1762] D loss: 1.3878, G loss: 0.7441\n",
      "[884/1762] D loss: 1.1444, G loss: 0.7888\n",
      "[964/1762] D loss: 1.4022, G loss: 0.6385\n",
      "[1044/1762] D loss: 1.3979, G loss: 0.6361\n",
      "[1124/1762] D loss: 1.3881, G loss: 0.7154\n",
      "[1204/1762] D loss: 1.3977, G loss: 0.6862\n",
      "[1284/1762] D loss: 1.3817, G loss: 0.7684\n",
      "[1364/1762] D loss: 1.3753, G loss: 0.7715\n",
      "[1444/1762] D loss: 1.3990, G loss: 0.7731\n",
      "[1524/1762] D loss: 1.1648, G loss: 0.7823\n",
      "[1604/1762] D loss: 1.4060, G loss: 0.7776\n",
      "[1684/1762] D loss: 1.1119, G loss: 1.0028\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.6738\n",
      "train error: \n",
      " D loss: 1.321385, G loss: 0.737981, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.306187, G loss: 0.749268, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 84.8% \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4127, G loss: 0.7699\n",
      "[84/1762] D loss: 1.3887, G loss: 0.7621\n",
      "[164/1762] D loss: 1.3892, G loss: 0.6424\n",
      "[244/1762] D loss: 1.3984, G loss: 0.7690\n",
      "[324/1762] D loss: 0.7213, G loss: 1.1954\n",
      "[404/1762] D loss: 1.3966, G loss: 0.7099\n",
      "[484/1762] D loss: 1.3707, G loss: 0.7374\n",
      "[564/1762] D loss: 1.3945, G loss: 0.5750\n",
      "[644/1762] D loss: 1.3960, G loss: 0.8954\n",
      "[724/1762] D loss: 1.6584, G loss: 0.8209\n",
      "[804/1762] D loss: 1.0070, G loss: 0.9382\n",
      "[884/1762] D loss: 0.6227, G loss: 1.4842\n",
      "[964/1762] D loss: 2.1602, G loss: 1.5179\n",
      "[1044/1762] D loss: 1.4864, G loss: 0.8424\n",
      "[1124/1762] D loss: 1.4982, G loss: 0.8098\n",
      "[1204/1762] D loss: 1.3964, G loss: 0.6270\n",
      "[1284/1762] D loss: 1.4036, G loss: 0.6506\n",
      "[1364/1762] D loss: 1.3995, G loss: 0.6511\n",
      "[1444/1762] D loss: 1.1804, G loss: 0.8063\n",
      "[1524/1762] D loss: 1.3882, G loss: 0.7276\n",
      "[1604/1762] D loss: 1.3913, G loss: 0.6406\n",
      "[1684/1762] D loss: 1.1597, G loss: 0.8814\n",
      "[1762/1762] D loss: 1.3902, G loss: 0.7277\n",
      "train error: \n",
      " D loss: 1.335416, G loss: 0.748018, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 87.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.325621, G loss: 0.754809, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 83.4% \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3892, G loss: 0.7018\n",
      "[84/1762] D loss: 1.4054, G loss: 0.7182\n",
      "[164/1762] D loss: 1.4021, G loss: 0.6164\n",
      "[244/1762] D loss: 1.3926, G loss: 0.6933\n",
      "[324/1762] D loss: 1.3978, G loss: 0.7430\n",
      "[404/1762] D loss: 1.3927, G loss: 0.7631\n",
      "[484/1762] D loss: 1.4002, G loss: 0.7959\n",
      "[564/1762] D loss: 1.3899, G loss: 0.7070\n",
      "[644/1762] D loss: 1.1757, G loss: 0.7980\n",
      "[724/1762] D loss: 1.3998, G loss: 0.7409\n",
      "[804/1762] D loss: 1.3867, G loss: 0.7076\n",
      "[884/1762] D loss: 1.1550, G loss: 0.9088\n",
      "[964/1762] D loss: 1.3970, G loss: 0.6328\n",
      "[1044/1762] D loss: 1.4058, G loss: 0.7225\n",
      "[1124/1762] D loss: 1.3953, G loss: 0.6406\n",
      "[1204/1762] D loss: 1.3929, G loss: 0.7733\n",
      "[1284/1762] D loss: 1.4106, G loss: 0.6242\n",
      "[1364/1762] D loss: 1.3845, G loss: 0.7111\n",
      "[1444/1762] D loss: 1.3945, G loss: 0.5993\n",
      "[1524/1762] D loss: 1.2814, G loss: 0.9409\n",
      "[1604/1762] D loss: 1.3907, G loss: 0.7235\n",
      "[1684/1762] D loss: 0.9210, G loss: 0.9238\n",
      "[1762/1762] D loss: 1.3974, G loss: 0.6733\n",
      "train error: \n",
      " D loss: 1.324501, G loss: 0.785310, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.309573, G loss: 0.794800, D accuracy: 54.9%, cell accuracy: 99.7%, board accuracy: 82.5% \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4144, G loss: 0.8060\n",
      "[84/1762] D loss: 1.3895, G loss: 0.7088\n",
      "[164/1762] D loss: 1.3936, G loss: 0.6523\n",
      "[244/1762] D loss: 1.3864, G loss: 0.6727\n",
      "[324/1762] D loss: 1.3947, G loss: 0.7972\n",
      "[404/1762] D loss: 1.3882, G loss: 0.6970\n",
      "[484/1762] D loss: 1.3796, G loss: 0.7596\n",
      "[564/1762] D loss: 1.1732, G loss: 0.7136\n",
      "[644/1762] D loss: 1.3926, G loss: 0.7538\n",
      "[724/1762] D loss: 1.4007, G loss: 0.7388\n",
      "[804/1762] D loss: 1.3851, G loss: 0.7542\n",
      "[884/1762] D loss: 1.3985, G loss: 0.6513\n",
      "[964/1762] D loss: 1.4033, G loss: 0.8275\n",
      "[1044/1762] D loss: 1.3927, G loss: 0.5678\n",
      "[1124/1762] D loss: 1.3921, G loss: 0.6911\n",
      "[1204/1762] D loss: 1.3913, G loss: 0.6828\n",
      "[1284/1762] D loss: 1.3932, G loss: 0.6923\n",
      "[1364/1762] D loss: 1.4147, G loss: 0.7702\n",
      "[1444/1762] D loss: 1.3959, G loss: 0.7897\n",
      "[1524/1762] D loss: 1.3808, G loss: 0.7194\n",
      "[1604/1762] D loss: 1.3888, G loss: 0.7480\n",
      "[1684/1762] D loss: 1.3964, G loss: 0.7323\n",
      "[1762/1762] D loss: 1.3741, G loss: 0.7238\n",
      "train error: \n",
      " D loss: 1.318125, G loss: 0.768367, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 84.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.301157, G loss: 0.779191, D accuracy: 55.5%, cell accuracy: 99.7%, board accuracy: 80.2% \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4000, G loss: 0.7502\n",
      "[84/1762] D loss: 1.3954, G loss: 0.7597\n",
      "[164/1762] D loss: 1.3621, G loss: 0.7367\n",
      "[244/1762] D loss: 1.3955, G loss: 0.6196\n",
      "[324/1762] D loss: 1.1393, G loss: 0.8664\n",
      "[404/1762] D loss: 1.1443, G loss: 0.8297\n",
      "[484/1762] D loss: 1.3866, G loss: 0.6938\n",
      "[564/1762] D loss: 1.3810, G loss: 0.6777\n",
      "[644/1762] D loss: 1.3890, G loss: 0.7052\n",
      "[724/1762] D loss: 1.3967, G loss: 0.7294\n",
      "[804/1762] D loss: 1.3980, G loss: 0.8090\n",
      "[884/1762] D loss: 1.4188, G loss: 0.7999\n",
      "[964/1762] D loss: 1.3666, G loss: 0.7138\n",
      "[1044/1762] D loss: 1.1499, G loss: 0.8796\n",
      "[1124/1762] D loss: 1.3968, G loss: 0.6614\n",
      "[1204/1762] D loss: 1.4124, G loss: 0.6643\n",
      "[1284/1762] D loss: 1.3978, G loss: 0.8096\n",
      "[1364/1762] D loss: 1.0964, G loss: 0.9698\n",
      "[1444/1762] D loss: 1.3630, G loss: 0.7466\n",
      "[1524/1762] D loss: 1.3934, G loss: 0.7304\n",
      "[1604/1762] D loss: 1.0995, G loss: 1.0920\n",
      "[1684/1762] D loss: 1.3922, G loss: 0.6056\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.7295\n",
      "train error: \n",
      " D loss: 1.318221, G loss: 0.823308, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 81.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.299953, G loss: 0.834649, D accuracy: 55.9%, cell accuracy: 99.7%, board accuracy: 78.2% \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4184, G loss: 0.8576\n",
      "[84/1762] D loss: 1.3987, G loss: 0.7042\n",
      "[164/1762] D loss: 1.4120, G loss: 0.5745\n",
      "[244/1762] D loss: 0.8575, G loss: 1.0731\n",
      "[324/1762] D loss: 1.3901, G loss: 0.6907\n",
      "[404/1762] D loss: 1.3852, G loss: 0.8339\n",
      "[484/1762] D loss: 1.1399, G loss: 0.8476\n",
      "[564/1762] D loss: 1.1378, G loss: 0.8864\n",
      "[644/1762] D loss: 1.1474, G loss: 0.9538\n",
      "[724/1762] D loss: 1.3913, G loss: 0.8080\n",
      "[804/1762] D loss: 1.3887, G loss: 0.6757\n",
      "[884/1762] D loss: 1.0997, G loss: 1.0161\n",
      "[964/1762] D loss: 1.3824, G loss: 0.6199\n",
      "[1044/1762] D loss: 1.4174, G loss: 0.8872\n",
      "[1124/1762] D loss: 1.3881, G loss: 0.7087\n",
      "[1204/1762] D loss: 1.4007, G loss: 0.7028\n",
      "[1284/1762] D loss: 1.3842, G loss: 0.7807\n",
      "[1364/1762] D loss: 1.1336, G loss: 0.8915\n",
      "[1444/1762] D loss: 1.4131, G loss: 0.7865\n",
      "[1524/1762] D loss: 1.3569, G loss: 0.7609\n",
      "[1604/1762] D loss: 1.3907, G loss: 0.6794\n",
      "[1684/1762] D loss: 1.4049, G loss: 0.7873\n",
      "[1762/1762] D loss: 1.4033, G loss: 0.7765\n",
      "train error: \n",
      " D loss: 1.316571, G loss: 0.763026, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.297091, G loss: 0.776551, D accuracy: 55.8%, cell accuracy: 99.7%, board accuracy: 82.0% \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0729, G loss: 0.9430\n",
      "[84/1762] D loss: 1.3779, G loss: 0.7261\n",
      "[164/1762] D loss: 1.4264, G loss: 0.7679\n",
      "[244/1762] D loss: 1.3925, G loss: 0.6967\n",
      "[324/1762] D loss: 1.1389, G loss: 0.7975\n",
      "[404/1762] D loss: 1.3790, G loss: 0.8067\n",
      "[484/1762] D loss: 1.3941, G loss: 0.6181\n",
      "[564/1762] D loss: 1.0937, G loss: 0.9319\n",
      "[644/1762] D loss: 1.3900, G loss: 0.6983\n",
      "[724/1762] D loss: 1.3874, G loss: 0.7235\n",
      "[804/1762] D loss: 1.4115, G loss: 0.7493\n",
      "[884/1762] D loss: 1.3902, G loss: 0.7391\n",
      "[964/1762] D loss: 1.3821, G loss: 0.7738\n",
      "[1044/1762] D loss: 1.1221, G loss: 0.9085\n",
      "[1124/1762] D loss: 1.3886, G loss: 0.7962\n",
      "[1204/1762] D loss: 1.3914, G loss: 0.7265\n",
      "[1284/1762] D loss: 1.3644, G loss: 0.7039\n",
      "[1364/1762] D loss: 1.1349, G loss: 0.8071\n",
      "[1444/1762] D loss: 1.3773, G loss: 0.7502\n",
      "[1524/1762] D loss: 1.3924, G loss: 0.7244\n",
      "[1604/1762] D loss: 1.3873, G loss: 0.6520\n",
      "[1684/1762] D loss: 1.4078, G loss: 0.7819\n",
      "[1762/1762] D loss: 1.3881, G loss: 0.7423\n",
      "train error: \n",
      " D loss: 1.318281, G loss: 0.798738, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.302190, G loss: 0.807963, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 83.6% \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1405, G loss: 0.9337\n",
      "[84/1762] D loss: 1.3996, G loss: 0.7332\n",
      "[164/1762] D loss: 1.3896, G loss: 0.6803\n",
      "[244/1762] D loss: 1.4033, G loss: 0.8081\n",
      "[324/1762] D loss: 1.4013, G loss: 0.6535\n",
      "[404/1762] D loss: 1.3921, G loss: 0.7375\n",
      "[484/1762] D loss: 1.1241, G loss: 0.8060\n",
      "[564/1762] D loss: 1.3887, G loss: 0.7236\n",
      "[644/1762] D loss: 1.4020, G loss: 0.6216\n",
      "[724/1762] D loss: 1.3827, G loss: 0.8005\n",
      "[804/1762] D loss: 1.1013, G loss: 0.7508\n",
      "[884/1762] D loss: 1.0893, G loss: 0.9983\n",
      "[964/1762] D loss: 1.3830, G loss: 0.6652\n",
      "[1044/1762] D loss: 1.3614, G loss: 0.8020\n",
      "[1124/1762] D loss: 1.4056, G loss: 0.6000\n",
      "[1204/1762] D loss: 1.3605, G loss: 0.5897\n",
      "[1284/1762] D loss: 0.8667, G loss: 1.0859\n",
      "[1364/1762] D loss: 1.3957, G loss: 0.6349\n",
      "[1444/1762] D loss: 1.4058, G loss: 0.6550\n",
      "[1524/1762] D loss: 1.3888, G loss: 0.7245\n",
      "[1604/1762] D loss: 1.3793, G loss: 0.7866\n",
      "[1684/1762] D loss: 1.1161, G loss: 0.9539\n",
      "[1762/1762] D loss: 1.3698, G loss: 0.6423\n",
      "train error: \n",
      " D loss: 1.318746, G loss: 0.709688, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 83.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.302897, G loss: 0.721817, D accuracy: 55.1%, cell accuracy: 99.7%, board accuracy: 78.4% \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3931, G loss: 0.5984\n",
      "[84/1762] D loss: 1.3916, G loss: 0.7403\n",
      "[164/1762] D loss: 1.1368, G loss: 0.8466\n",
      "[244/1762] D loss: 1.3887, G loss: 0.6503\n",
      "[324/1762] D loss: 1.3905, G loss: 0.6925\n",
      "[404/1762] D loss: 1.4109, G loss: 0.7834\n",
      "[484/1762] D loss: 1.4138, G loss: 0.7592\n",
      "[564/1762] D loss: 1.3868, G loss: 0.6739\n",
      "[644/1762] D loss: 1.3768, G loss: 0.6866\n",
      "[724/1762] D loss: 1.1552, G loss: 0.9565\n",
      "[804/1762] D loss: 1.3861, G loss: 0.7434\n",
      "[884/1762] D loss: 1.1154, G loss: 0.9979\n",
      "[964/1762] D loss: 1.1737, G loss: 0.7444\n",
      "[1044/1762] D loss: 1.4003, G loss: 0.6419\n",
      "[1124/1762] D loss: 1.3659, G loss: 0.7488\n",
      "[1204/1762] D loss: 1.3871, G loss: 0.6682\n",
      "[1284/1762] D loss: 1.4305, G loss: 0.8019\n",
      "[1364/1762] D loss: 1.3704, G loss: 0.7080\n",
      "[1444/1762] D loss: 1.4144, G loss: 0.7322\n",
      "[1524/1762] D loss: 1.1206, G loss: 0.9149\n",
      "[1604/1762] D loss: 1.0982, G loss: 0.8449\n",
      "[1684/1762] D loss: 1.3908, G loss: 0.7399\n",
      "[1762/1762] D loss: 0.3360, G loss: 1.4184\n",
      "train error: \n",
      " D loss: 1.325049, G loss: 0.862127, D accuracy: 53.6%, cell accuracy: 99.7%, board accuracy: 81.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.307612, G loss: 0.876492, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 76.6% \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4161, G loss: 0.8854\n",
      "[84/1762] D loss: 1.3944, G loss: 0.6938\n",
      "[164/1762] D loss: 1.4038, G loss: 0.8087\n",
      "[244/1762] D loss: 1.1129, G loss: 0.7908\n",
      "[324/1762] D loss: 1.3918, G loss: 0.6410\n",
      "[404/1762] D loss: 1.3929, G loss: 0.7118\n",
      "[484/1762] D loss: 1.3055, G loss: 0.6519\n",
      "[564/1762] D loss: 1.3122, G loss: 0.7584\n",
      "[644/1762] D loss: 1.3944, G loss: 0.8069\n",
      "[724/1762] D loss: 1.3953, G loss: 0.5780\n",
      "[804/1762] D loss: 1.3879, G loss: 0.7293\n",
      "[884/1762] D loss: 1.1543, G loss: 0.7262\n",
      "[964/1762] D loss: 1.3874, G loss: 0.7179\n",
      "[1044/1762] D loss: 1.1335, G loss: 0.7877\n",
      "[1124/1762] D loss: 1.4191, G loss: 0.8025\n",
      "[1204/1762] D loss: 1.3884, G loss: 0.6908\n",
      "[1284/1762] D loss: 1.3816, G loss: 0.8269\n",
      "[1364/1762] D loss: 1.3388, G loss: 0.8332\n",
      "[1444/1762] D loss: 1.3924, G loss: 0.6554\n",
      "[1524/1762] D loss: 1.1313, G loss: 0.7690\n",
      "[1604/1762] D loss: 1.4030, G loss: 0.7247\n",
      "[1684/1762] D loss: 1.4020, G loss: 0.6660\n",
      "[1762/1762] D loss: 1.4177, G loss: 0.5287\n",
      "train error: \n",
      " D loss: 1.339841, G loss: 0.613427, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 86.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.324437, G loss: 0.625996, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 80.7% \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4042, G loss: 0.5923\n",
      "[84/1762] D loss: 1.1277, G loss: 0.7837\n",
      "[164/1762] D loss: 1.3888, G loss: 0.6903\n",
      "[244/1762] D loss: 1.3932, G loss: 0.6671\n",
      "[324/1762] D loss: 1.3906, G loss: 0.6220\n",
      "[404/1762] D loss: 1.1152, G loss: 0.9597\n",
      "[484/1762] D loss: 1.3865, G loss: 0.7004\n",
      "[564/1762] D loss: 1.4059, G loss: 0.8262\n",
      "[644/1762] D loss: 1.3937, G loss: 0.6652\n",
      "[724/1762] D loss: 1.1188, G loss: 0.8030\n",
      "[804/1762] D loss: 1.4009, G loss: 0.7776\n",
      "[884/1762] D loss: 0.8546, G loss: 1.0164\n",
      "[964/1762] D loss: 1.3902, G loss: 0.7113\n",
      "[1044/1762] D loss: 1.3898, G loss: 0.7025\n",
      "[1124/1762] D loss: 1.3890, G loss: 0.6759\n",
      "[1204/1762] D loss: 1.3870, G loss: 0.6967\n",
      "[1284/1762] D loss: 1.1115, G loss: 0.9838\n",
      "[1364/1762] D loss: 1.3908, G loss: 0.7034\n",
      "[1444/1762] D loss: 1.3897, G loss: 0.7013\n",
      "[1524/1762] D loss: 1.1101, G loss: 0.8364\n",
      "[1604/1762] D loss: 1.3880, G loss: 0.7127\n",
      "[1684/1762] D loss: 0.8327, G loss: 1.1943\n",
      "[1762/1762] D loss: 1.3972, G loss: 0.7095\n",
      "train error: \n",
      " D loss: 1.319748, G loss: 0.694012, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 84.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.303253, G loss: 0.709355, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 79.5% \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3896, G loss: 0.6596\n",
      "[84/1762] D loss: 1.4002, G loss: 0.7910\n",
      "[164/1762] D loss: 1.4151, G loss: 0.5914\n",
      "[244/1762] D loss: 1.3891, G loss: 0.6678\n",
      "[324/1762] D loss: 1.4084, G loss: 0.7819\n",
      "[404/1762] D loss: 1.4301, G loss: 0.8796\n",
      "[484/1762] D loss: 1.4062, G loss: 0.5983\n",
      "[564/1762] D loss: 1.1087, G loss: 0.9263\n",
      "[644/1762] D loss: 1.3914, G loss: 0.7600\n",
      "[724/1762] D loss: 1.3944, G loss: 0.5879\n",
      "[804/1762] D loss: 1.3972, G loss: 0.7933\n",
      "[884/1762] D loss: 1.3896, G loss: 0.6096\n",
      "[964/1762] D loss: 1.3920, G loss: 0.7535\n",
      "[1044/1762] D loss: 1.3920, G loss: 0.6479\n",
      "[1124/1762] D loss: 1.1051, G loss: 0.8310\n",
      "[1204/1762] D loss: 1.3936, G loss: 0.7781\n",
      "[1284/1762] D loss: 1.3967, G loss: 0.7289\n",
      "[1364/1762] D loss: 1.3985, G loss: 0.7376\n",
      "[1444/1762] D loss: 1.1253, G loss: 0.9303\n",
      "[1524/1762] D loss: 1.4427, G loss: 0.5439\n",
      "[1604/1762] D loss: 1.3629, G loss: 0.7851\n",
      "[1684/1762] D loss: 1.3904, G loss: 0.7337\n",
      "[1762/1762] D loss: 0.8336, G loss: 1.1280\n",
      "train error: \n",
      " D loss: 1.314514, G loss: 0.784702, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 81.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.296164, G loss: 0.804755, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 76.6% \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3865, G loss: 0.6834\n",
      "[84/1762] D loss: 1.4021, G loss: 0.6202\n",
      "[164/1762] D loss: 1.3634, G loss: 0.7015\n",
      "[244/1762] D loss: 1.3958, G loss: 0.7604\n",
      "[324/1762] D loss: 1.3915, G loss: 0.6629\n",
      "[404/1762] D loss: 1.3938, G loss: 0.7303\n",
      "[484/1762] D loss: 1.3899, G loss: 0.6728\n",
      "[564/1762] D loss: 1.3714, G loss: 0.7542\n",
      "[644/1762] D loss: 1.3791, G loss: 0.7596\n",
      "[724/1762] D loss: 1.3906, G loss: 0.6474\n",
      "[804/1762] D loss: 1.3960, G loss: 0.6955\n",
      "[884/1762] D loss: 1.1247, G loss: 0.9073\n",
      "[964/1762] D loss: 1.4046, G loss: 0.7551\n",
      "[1044/1762] D loss: 1.3668, G loss: 0.6795\n",
      "[1124/1762] D loss: 0.8285, G loss: 1.0925\n",
      "[1204/1762] D loss: 1.3917, G loss: 0.7393\n",
      "[1284/1762] D loss: 1.1253, G loss: 0.8478\n",
      "[1364/1762] D loss: 1.3541, G loss: 0.7364\n",
      "[1444/1762] D loss: 1.0991, G loss: 1.0335\n",
      "[1524/1762] D loss: 1.3883, G loss: 0.6681\n",
      "[1604/1762] D loss: 1.3965, G loss: 0.7464\n",
      "[1684/1762] D loss: 1.1246, G loss: 0.9202\n",
      "[1762/1762] D loss: 1.3551, G loss: 0.6828\n",
      "train error: \n",
      " D loss: 1.313637, G loss: 0.771435, D accuracy: 53.9%, cell accuracy: 99.7%, board accuracy: 79.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.294971, G loss: 0.790414, D accuracy: 55.6%, cell accuracy: 99.7%, board accuracy: 74.5% \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7720, G loss: 1.2427\n",
      "[84/1762] D loss: 1.1289, G loss: 0.9052\n",
      "[164/1762] D loss: 1.3767, G loss: 0.7828\n",
      "[244/1762] D loss: 1.1259, G loss: 0.9217\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6433\n",
      "[404/1762] D loss: 1.4062, G loss: 0.7468\n",
      "[484/1762] D loss: 1.3936, G loss: 0.6320\n",
      "[564/1762] D loss: 1.1351, G loss: 1.0227\n",
      "[644/1762] D loss: 1.1431, G loss: 1.0204\n",
      "[724/1762] D loss: 1.3871, G loss: 0.6971\n",
      "[804/1762] D loss: 1.3881, G loss: 0.6940\n",
      "[884/1762] D loss: 1.3910, G loss: 0.6207\n",
      "[964/1762] D loss: 1.1083, G loss: 0.8683\n",
      "[1044/1762] D loss: 1.3918, G loss: 0.6775\n",
      "[1124/1762] D loss: 1.3881, G loss: 0.6770\n",
      "[1204/1762] D loss: 1.3933, G loss: 0.7095\n",
      "[1284/1762] D loss: 1.1166, G loss: 0.9068\n",
      "[1364/1762] D loss: 1.3852, G loss: 0.7072\n",
      "[1444/1762] D loss: 1.3880, G loss: 0.6397\n",
      "[1524/1762] D loss: 1.3872, G loss: 0.6959\n",
      "[1604/1762] D loss: 1.1164, G loss: 0.9141\n",
      "[1684/1762] D loss: 1.3922, G loss: 0.7727\n",
      "[1762/1762] D loss: 1.3885, G loss: 0.6412\n",
      "train error: \n",
      " D loss: 1.312522, G loss: 0.772226, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 82.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.292706, G loss: 0.792006, D accuracy: 55.3%, cell accuracy: 99.7%, board accuracy: 77.5% \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3873, G loss: 0.7085\n",
      "[84/1762] D loss: 1.3986, G loss: 0.6244\n",
      "[164/1762] D loss: 1.0758, G loss: 1.0414\n",
      "[244/1762] D loss: 1.3896, G loss: 0.6776\n",
      "[324/1762] D loss: 1.3949, G loss: 0.7402\n",
      "[404/1762] D loss: 1.2415, G loss: 0.6920\n",
      "[484/1762] D loss: 1.3686, G loss: 0.7321\n",
      "[564/1762] D loss: 1.4218, G loss: 0.8999\n",
      "[644/1762] D loss: 1.1079, G loss: 0.9645\n",
      "[724/1762] D loss: 1.3875, G loss: 0.6837\n",
      "[804/1762] D loss: 1.0887, G loss: 0.9896\n",
      "[884/1762] D loss: 1.1014, G loss: 0.9850\n",
      "[964/1762] D loss: 1.4035, G loss: 0.5814\n",
      "[1044/1762] D loss: 1.4048, G loss: 0.7691\n",
      "[1124/1762] D loss: 1.3889, G loss: 0.6520\n",
      "[1204/1762] D loss: 1.3900, G loss: 0.7131\n",
      "[1284/1762] D loss: 1.1644, G loss: 0.7389\n",
      "[1364/1762] D loss: 1.1184, G loss: 0.8222\n",
      "[1444/1762] D loss: 1.3974, G loss: 0.7769\n",
      "[1524/1762] D loss: 1.3993, G loss: 0.8581\n",
      "[1604/1762] D loss: 1.1040, G loss: 0.9896\n",
      "[1684/1762] D loss: 1.3785, G loss: 0.6544\n",
      "[1762/1762] D loss: 0.7656, G loss: 1.3583\n",
      "train error: \n",
      " D loss: 1.313333, G loss: 0.800156, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 82.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.296745, G loss: 0.815068, D accuracy: 54.9%, cell accuracy: 99.7%, board accuracy: 77.0% \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3881, G loss: 0.7301\n",
      "[84/1762] D loss: 1.3968, G loss: 0.6296\n",
      "[164/1762] D loss: 1.3825, G loss: 0.8306\n",
      "[244/1762] D loss: 1.0979, G loss: 1.0818\n",
      "[324/1762] D loss: 1.4283, G loss: 0.6284\n",
      "[404/1762] D loss: 1.3827, G loss: 1.0587\n",
      "[484/1762] D loss: 0.8824, G loss: 1.3259\n",
      "[564/1762] D loss: 1.4104, G loss: 0.6393\n",
      "[644/1762] D loss: 1.4402, G loss: 0.7289\n",
      "[724/1762] D loss: 1.4022, G loss: 0.6843\n",
      "[804/1762] D loss: 1.3940, G loss: 0.7576\n",
      "[884/1762] D loss: 1.3867, G loss: 0.6839\n",
      "[964/1762] D loss: 1.3967, G loss: 0.6820\n",
      "[1044/1762] D loss: 1.3919, G loss: 0.7501\n",
      "[1124/1762] D loss: 1.3888, G loss: 0.6531\n",
      "[1204/1762] D loss: 1.3947, G loss: 0.7620\n",
      "[1284/1762] D loss: 1.3932, G loss: 0.7174\n",
      "[1364/1762] D loss: 1.1822, G loss: 0.7572\n",
      "[1444/1762] D loss: 1.1322, G loss: 0.9598\n",
      "[1524/1762] D loss: 1.3794, G loss: 0.6370\n",
      "[1604/1762] D loss: 1.3876, G loss: 0.7247\n",
      "[1684/1762] D loss: 1.2068, G loss: 0.8794\n",
      "[1762/1762] D loss: 1.4123, G loss: 0.8903\n",
      "train error: \n",
      " D loss: 1.345870, G loss: 0.941365, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 86.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.333372, G loss: 0.955917, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 84.5% \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4117, G loss: 0.8302\n",
      "[84/1762] D loss: 1.3928, G loss: 0.6201\n",
      "[164/1762] D loss: 1.3950, G loss: 0.7118\n",
      "[244/1762] D loss: 1.1267, G loss: 0.9302\n",
      "[324/1762] D loss: 1.4054, G loss: 0.7875\n",
      "[404/1762] D loss: 1.3909, G loss: 0.6664\n",
      "[484/1762] D loss: 1.3907, G loss: 0.6466\n",
      "[564/1762] D loss: 1.1293, G loss: 0.8391\n",
      "[644/1762] D loss: 1.3892, G loss: 0.7555\n",
      "[724/1762] D loss: 1.3774, G loss: 0.6947\n",
      "[804/1762] D loss: 1.3910, G loss: 0.7309\n",
      "[884/1762] D loss: 1.3893, G loss: 0.6525\n",
      "[964/1762] D loss: 1.2010, G loss: 0.9634\n",
      "[1044/1762] D loss: 1.4015, G loss: 0.8125\n",
      "[1124/1762] D loss: 1.3895, G loss: 0.6535\n",
      "[1204/1762] D loss: 1.3941, G loss: 0.7732\n",
      "[1284/1762] D loss: 1.1343, G loss: 0.9611\n",
      "[1364/1762] D loss: 1.3947, G loss: 0.6661\n",
      "[1444/1762] D loss: 1.4012, G loss: 0.7845\n",
      "[1524/1762] D loss: 1.1658, G loss: 0.8983\n",
      "[1604/1762] D loss: 1.3908, G loss: 0.6704\n",
      "[1684/1762] D loss: 1.3932, G loss: 0.7142\n",
      "[1762/1762] D loss: 1.3873, G loss: 0.6557\n",
      "train error: \n",
      " D loss: 1.314345, G loss: 0.733275, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.298263, G loss: 0.749460, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 84.3% \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3899, G loss: 0.6716\n",
      "[84/1762] D loss: 1.3919, G loss: 0.7950\n",
      "[164/1762] D loss: 1.3743, G loss: 0.8186\n",
      "[244/1762] D loss: 1.1160, G loss: 1.0214\n",
      "[324/1762] D loss: 1.4293, G loss: 0.8482\n",
      "[404/1762] D loss: 1.3808, G loss: 0.7316\n",
      "[484/1762] D loss: 1.4118, G loss: 0.8222\n",
      "[564/1762] D loss: 0.8581, G loss: 1.1592\n",
      "[644/1762] D loss: 1.1542, G loss: 0.9069\n",
      "[724/1762] D loss: 1.4020, G loss: 0.7281\n",
      "[804/1762] D loss: 1.3690, G loss: 0.8026\n",
      "[884/1762] D loss: 1.0962, G loss: 0.9514\n",
      "[964/1762] D loss: 1.3910, G loss: 0.7298\n",
      "[1044/1762] D loss: 1.3978, G loss: 0.7474\n",
      "[1124/1762] D loss: 1.3923, G loss: 0.7180\n",
      "[1204/1762] D loss: 1.3942, G loss: 0.6487\n",
      "[1284/1762] D loss: 1.1185, G loss: 0.9390\n",
      "[1364/1762] D loss: 1.3899, G loss: 0.6684\n",
      "[1444/1762] D loss: 1.1403, G loss: 0.8694\n",
      "[1524/1762] D loss: 1.3932, G loss: 0.6953\n",
      "[1604/1762] D loss: 1.3898, G loss: 0.7247\n",
      "[1684/1762] D loss: 1.3882, G loss: 0.7552\n",
      "[1762/1762] D loss: 1.3915, G loss: 0.6909\n",
      "train error: \n",
      " D loss: 1.313542, G loss: 0.774272, D accuracy: 53.8%, cell accuracy: 99.9%, board accuracy: 90.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.295318, G loss: 0.795961, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3909, G loss: 0.7204\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6744\n",
      "[164/1762] D loss: 1.3919, G loss: 0.7658\n",
      "[244/1762] D loss: 1.1046, G loss: 0.8847\n",
      "[324/1762] D loss: 1.3887, G loss: 0.7065\n",
      "[404/1762] D loss: 1.3923, G loss: 0.7332\n",
      "[484/1762] D loss: 1.3907, G loss: 0.6758\n",
      "[564/1762] D loss: 1.3918, G loss: 0.7294\n",
      "[644/1762] D loss: 1.3900, G loss: 0.7711\n",
      "[724/1762] D loss: 1.4162, G loss: 0.5692\n",
      "[804/1762] D loss: 1.3948, G loss: 0.7514\n",
      "[884/1762] D loss: 1.1088, G loss: 0.9154\n",
      "[964/1762] D loss: 1.4269, G loss: 0.5497\n",
      "[1044/1762] D loss: 1.3896, G loss: 0.7036\n",
      "[1124/1762] D loss: 1.1372, G loss: 0.8828\n",
      "[1204/1762] D loss: 1.3925, G loss: 0.7580\n",
      "[1284/1762] D loss: 1.1326, G loss: 0.8981\n",
      "[1364/1762] D loss: 1.3900, G loss: 0.7041\n",
      "[1444/1762] D loss: 1.4066, G loss: 0.7812\n",
      "[1524/1762] D loss: 1.4024, G loss: 0.8194\n",
      "[1604/1762] D loss: 1.3890, G loss: 0.6479\n",
      "[1684/1762] D loss: 1.3881, G loss: 0.7240\n",
      "[1762/1762] D loss: 1.3866, G loss: 0.6567\n",
      "train error: \n",
      " D loss: 1.312206, G loss: 0.769244, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.293279, G loss: 0.792063, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5083, G loss: 1.4868\n",
      "[84/1762] D loss: 1.3940, G loss: 0.7712\n",
      "[164/1762] D loss: 1.1039, G loss: 0.9608\n",
      "[244/1762] D loss: 1.1004, G loss: 0.9114\n",
      "[324/1762] D loss: 1.3898, G loss: 0.6957\n",
      "[404/1762] D loss: 1.3997, G loss: 0.7486\n",
      "[484/1762] D loss: 1.1139, G loss: 1.0433\n",
      "[564/1762] D loss: 1.3872, G loss: 0.6964\n",
      "[644/1762] D loss: 1.4173, G loss: 0.5823\n",
      "[724/1762] D loss: 1.3921, G loss: 0.7111\n",
      "[804/1762] D loss: 1.0893, G loss: 0.9696\n",
      "[884/1762] D loss: 1.3929, G loss: 0.6919\n",
      "[964/1762] D loss: 1.4051, G loss: 0.7418\n",
      "[1044/1762] D loss: 1.4007, G loss: 0.7614\n",
      "[1124/1762] D loss: 1.0872, G loss: 1.0381\n",
      "[1204/1762] D loss: 1.3988, G loss: 0.6362\n",
      "[1284/1762] D loss: 1.0923, G loss: 0.8867\n",
      "[1364/1762] D loss: 1.3977, G loss: 0.7634\n",
      "[1444/1762] D loss: 1.3962, G loss: 0.6508\n",
      "[1524/1762] D loss: 1.3923, G loss: 0.7311\n",
      "[1604/1762] D loss: 1.1109, G loss: 0.9576\n",
      "[1684/1762] D loss: 1.1019, G loss: 0.8731\n",
      "[1762/1762] D loss: 1.4354, G loss: 0.6636\n",
      "train error: \n",
      " D loss: 1.309880, G loss: 0.767398, D accuracy: 53.9%, cell accuracy: 99.9%, board accuracy: 91.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.288673, G loss: 0.794164, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4083, G loss: 0.6978\n",
      "[84/1762] D loss: 1.3957, G loss: 0.7749\n",
      "[164/1762] D loss: 1.3893, G loss: 0.7222\n",
      "[244/1762] D loss: 1.4202, G loss: 0.8520\n",
      "[324/1762] D loss: 1.3905, G loss: 0.6672\n",
      "[404/1762] D loss: 1.1187, G loss: 0.8928\n",
      "[484/1762] D loss: 1.1006, G loss: 1.0226\n",
      "[564/1762] D loss: 1.3990, G loss: 0.5761\n",
      "[644/1762] D loss: 1.0928, G loss: 0.9599\n",
      "[724/1762] D loss: 1.3893, G loss: 0.6299\n",
      "[804/1762] D loss: 1.3484, G loss: 0.7236\n",
      "[884/1762] D loss: 1.3974, G loss: 0.6923\n",
      "[964/1762] D loss: 1.3925, G loss: 0.7603\n",
      "[1044/1762] D loss: 1.3999, G loss: 0.7845\n",
      "[1124/1762] D loss: 1.4002, G loss: 0.6617\n",
      "[1204/1762] D loss: 1.3899, G loss: 0.6926\n",
      "[1284/1762] D loss: 1.1092, G loss: 0.9746\n",
      "[1364/1762] D loss: 1.1131, G loss: 0.8921\n",
      "[1444/1762] D loss: 1.0865, G loss: 0.9836\n",
      "[1524/1762] D loss: 1.3914, G loss: 0.7406\n",
      "[1604/1762] D loss: 1.3902, G loss: 0.7093\n",
      "[1684/1762] D loss: 1.3950, G loss: 0.6261\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.6450\n",
      "train error: \n",
      " D loss: 1.307890, G loss: 0.769449, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.287587, G loss: 0.795232, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0949, G loss: 0.9052\n",
      "[84/1762] D loss: 1.4330, G loss: 0.5978\n",
      "[164/1762] D loss: 1.3704, G loss: 0.7362\n",
      "[244/1762] D loss: 1.1005, G loss: 0.9026\n",
      "[324/1762] D loss: 1.3933, G loss: 0.6516\n",
      "[404/1762] D loss: 1.3882, G loss: 0.7111\n",
      "[484/1762] D loss: 1.0942, G loss: 1.0003\n",
      "[564/1762] D loss: 1.1185, G loss: 0.8449\n",
      "[644/1762] D loss: 1.3786, G loss: 0.7918\n",
      "[724/1762] D loss: 1.3882, G loss: 0.7988\n",
      "[804/1762] D loss: 1.4026, G loss: 0.5805\n",
      "[884/1762] D loss: 1.4181, G loss: 0.8515\n",
      "[964/1762] D loss: 0.8188, G loss: 1.2124\n",
      "[1044/1762] D loss: 1.3889, G loss: 0.5873\n",
      "[1124/1762] D loss: 1.3980, G loss: 0.8054\n",
      "[1204/1762] D loss: 1.0910, G loss: 0.9763\n",
      "[1284/1762] D loss: 0.7917, G loss: 1.3570\n",
      "[1364/1762] D loss: 1.4173, G loss: 0.5946\n",
      "[1444/1762] D loss: 1.4062, G loss: 0.7404\n",
      "[1524/1762] D loss: 1.1239, G loss: 0.9378\n",
      "[1604/1762] D loss: 1.1101, G loss: 0.8583\n",
      "[1684/1762] D loss: 1.4105, G loss: 0.7042\n",
      "[1762/1762] D loss: 1.3895, G loss: 0.7451\n",
      "train error: \n",
      " D loss: 1.310900, G loss: 0.805701, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.290122, G loss: 0.829257, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 85.0% \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4727, G loss: 0.8014\n",
      "[84/1762] D loss: 1.3922, G loss: 0.6205\n",
      "[164/1762] D loss: 1.3971, G loss: 0.6080\n",
      "[244/1762] D loss: 1.3935, G loss: 0.7176\n",
      "[324/1762] D loss: 1.3936, G loss: 0.6311\n",
      "[404/1762] D loss: 1.4169, G loss: 0.5906\n",
      "[484/1762] D loss: 1.0886, G loss: 1.1865\n",
      "[564/1762] D loss: 1.1238, G loss: 0.9436\n",
      "[644/1762] D loss: 1.3653, G loss: 0.6881\n",
      "[724/1762] D loss: 0.7919, G loss: 1.2939\n",
      "[804/1762] D loss: 1.3812, G loss: 0.7179\n",
      "[884/1762] D loss: 0.7830, G loss: 1.3235\n",
      "[964/1762] D loss: 1.1050, G loss: 0.8557\n",
      "[1044/1762] D loss: 1.3940, G loss: 0.7893\n",
      "[1124/1762] D loss: 1.1054, G loss: 0.8681\n",
      "[1204/1762] D loss: 1.4068, G loss: 0.6058\n",
      "[1284/1762] D loss: 1.3874, G loss: 0.6760\n",
      "[1364/1762] D loss: 1.3890, G loss: 0.7003\n",
      "[1444/1762] D loss: 1.3893, G loss: 0.6379\n",
      "[1524/1762] D loss: 1.3934, G loss: 0.7264\n",
      "[1604/1762] D loss: 1.4196, G loss: 0.6636\n",
      "[1684/1762] D loss: 1.1133, G loss: 0.9350\n",
      "[1762/1762] D loss: 1.4198, G loss: 0.7008\n",
      "train error: \n",
      " D loss: 1.311185, G loss: 0.732380, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.296090, G loss: 0.747499, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3907, G loss: 0.6415\n",
      "[84/1762] D loss: 1.3945, G loss: 0.7194\n",
      "[164/1762] D loss: 1.3892, G loss: 0.7291\n",
      "[244/1762] D loss: 1.3924, G loss: 0.7282\n",
      "[324/1762] D loss: 1.1071, G loss: 1.0008\n",
      "[404/1762] D loss: 1.3925, G loss: 0.7345\n",
      "[484/1762] D loss: 1.0912, G loss: 0.9998\n",
      "[564/1762] D loss: 1.0875, G loss: 1.1024\n",
      "[644/1762] D loss: 1.3859, G loss: 0.7018\n",
      "[724/1762] D loss: 1.0956, G loss: 1.1291\n",
      "[804/1762] D loss: 1.3914, G loss: 0.6097\n",
      "[884/1762] D loss: 1.3880, G loss: 0.6376\n",
      "[964/1762] D loss: 1.0980, G loss: 0.9516\n",
      "[1044/1762] D loss: 1.3885, G loss: 0.6849\n",
      "[1124/1762] D loss: 1.3869, G loss: 0.7021\n",
      "[1204/1762] D loss: 1.3926, G loss: 0.7322\n",
      "[1284/1762] D loss: 1.0970, G loss: 0.9142\n",
      "[1364/1762] D loss: 1.0789, G loss: 1.0487\n",
      "[1444/1762] D loss: 1.3988, G loss: 0.6032\n",
      "[1524/1762] D loss: 1.3977, G loss: 0.8355\n",
      "[1604/1762] D loss: 1.3893, G loss: 0.6625\n",
      "[1684/1762] D loss: 1.3492, G loss: 0.7823\n",
      "[1762/1762] D loss: 1.3893, G loss: 0.6935\n",
      "train error: \n",
      " D loss: 1.315438, G loss: 0.710935, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 86.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.295594, G loss: 0.731121, D accuracy: 55.2%, cell accuracy: 99.7%, board accuracy: 82.3% \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4007, G loss: 0.6510\n",
      "[84/1762] D loss: 1.1126, G loss: 1.0232\n",
      "[164/1762] D loss: 1.4189, G loss: 0.7315\n",
      "[244/1762] D loss: 1.3913, G loss: 0.7727\n",
      "[324/1762] D loss: 1.3879, G loss: 0.7109\n",
      "[404/1762] D loss: 1.3896, G loss: 0.7073\n",
      "[484/1762] D loss: 1.3878, G loss: 0.6737\n",
      "[564/1762] D loss: 0.8309, G loss: 1.2307\n",
      "[644/1762] D loss: 1.3908, G loss: 0.6588\n",
      "[724/1762] D loss: 1.3915, G loss: 0.6479\n",
      "[804/1762] D loss: 1.1064, G loss: 1.0654\n",
      "[884/1762] D loss: 1.4264, G loss: 0.6379\n",
      "[964/1762] D loss: 1.3960, G loss: 0.7704\n",
      "[1044/1762] D loss: 1.3836, G loss: 0.6410\n",
      "[1124/1762] D loss: 1.3923, G loss: 0.7327\n",
      "[1204/1762] D loss: 1.3913, G loss: 0.6839\n",
      "[1284/1762] D loss: 1.3906, G loss: 0.6523\n",
      "[1364/1762] D loss: 1.3900, G loss: 0.6543\n",
      "[1444/1762] D loss: 1.3952, G loss: 0.7741\n",
      "[1524/1762] D loss: 1.4024, G loss: 0.7809\n",
      "[1604/1762] D loss: 1.3395, G loss: 0.8086\n",
      "[1684/1762] D loss: 1.3932, G loss: 0.6640\n",
      "[1762/1762] D loss: 1.3933, G loss: 0.6329\n",
      "train error: \n",
      " D loss: 1.311012, G loss: 0.796090, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 85.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.290797, G loss: 0.823211, D accuracy: 54.9%, cell accuracy: 99.7%, board accuracy: 81.4% \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3878, G loss: 0.7025\n",
      "[84/1762] D loss: 1.1119, G loss: 0.9779\n",
      "[164/1762] D loss: 1.3751, G loss: 0.7177\n",
      "[244/1762] D loss: 1.1115, G loss: 0.8284\n",
      "[324/1762] D loss: 1.3886, G loss: 0.7071\n",
      "[404/1762] D loss: 1.3932, G loss: 0.7723\n",
      "[484/1762] D loss: 1.0982, G loss: 0.9860\n",
      "[564/1762] D loss: 1.3885, G loss: 0.6571\n",
      "[644/1762] D loss: 1.3869, G loss: 0.6606\n",
      "[724/1762] D loss: 1.3939, G loss: 0.7454\n",
      "[804/1762] D loss: 1.3890, G loss: 0.6854\n",
      "[884/1762] D loss: 1.4063, G loss: 0.7419\n",
      "[964/1762] D loss: 1.3951, G loss: 0.6544\n",
      "[1044/1762] D loss: 1.1088, G loss: 0.8484\n",
      "[1124/1762] D loss: 1.1036, G loss: 0.9513\n",
      "[1204/1762] D loss: 1.3869, G loss: 0.7317\n",
      "[1284/1762] D loss: 1.1139, G loss: 0.8975\n",
      "[1364/1762] D loss: 1.1085, G loss: 0.8993\n",
      "[1444/1762] D loss: 1.3858, G loss: 0.7273\n",
      "[1524/1762] D loss: 1.3966, G loss: 0.6750\n",
      "[1604/1762] D loss: 1.3973, G loss: 0.7433\n",
      "[1684/1762] D loss: 1.3922, G loss: 0.7855\n",
      "[1762/1762] D loss: 0.8098, G loss: 1.2190\n",
      "train error: \n",
      " D loss: 1.312286, G loss: 0.837920, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.293489, G loss: 0.862384, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 83.0% \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3901, G loss: 0.8142\n",
      "[84/1762] D loss: 1.4092, G loss: 0.6759\n",
      "[164/1762] D loss: 1.4053, G loss: 0.7244\n",
      "[244/1762] D loss: 1.3936, G loss: 0.7295\n",
      "[324/1762] D loss: 1.3467, G loss: 0.7468\n",
      "[404/1762] D loss: 1.1936, G loss: 0.6908\n",
      "[484/1762] D loss: 1.1362, G loss: 0.9811\n",
      "[564/1762] D loss: 1.0935, G loss: 0.9400\n",
      "[644/1762] D loss: 1.0940, G loss: 0.8778\n",
      "[724/1762] D loss: 1.3947, G loss: 0.6630\n",
      "[804/1762] D loss: 1.3913, G loss: 0.6642\n",
      "[884/1762] D loss: 1.1060, G loss: 1.1307\n",
      "[964/1762] D loss: 1.1008, G loss: 0.9030\n",
      "[1044/1762] D loss: 1.3791, G loss: 0.7485\n",
      "[1124/1762] D loss: 1.4007, G loss: 0.6267\n",
      "[1204/1762] D loss: 1.3717, G loss: 0.6731\n",
      "[1284/1762] D loss: 1.3922, G loss: 0.7150\n",
      "[1364/1762] D loss: 1.4061, G loss: 0.7391\n",
      "[1444/1762] D loss: 1.3997, G loss: 0.6199\n",
      "[1524/1762] D loss: 1.0975, G loss: 0.9960\n",
      "[1604/1762] D loss: 1.3645, G loss: 0.5996\n",
      "[1684/1762] D loss: 1.4230, G loss: 0.8517\n",
      "[1762/1762] D loss: 1.3965, G loss: 0.6151\n",
      "train error: \n",
      " D loss: 1.313444, G loss: 0.702093, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 86.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.296593, G loss: 0.720323, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 82.7% \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4006, G loss: 0.6094\n",
      "[84/1762] D loss: 1.3936, G loss: 0.8067\n",
      "[164/1762] D loss: 1.3718, G loss: 0.6034\n",
      "[244/1762] D loss: 1.0482, G loss: 1.0589\n",
      "[324/1762] D loss: 1.0736, G loss: 1.0657\n",
      "[404/1762] D loss: 0.7996, G loss: 1.2192\n",
      "[484/1762] D loss: 1.3887, G loss: 0.6434\n",
      "[564/1762] D loss: 1.1195, G loss: 0.9927\n",
      "[644/1762] D loss: 1.0951, G loss: 1.0765\n",
      "[724/1762] D loss: 1.4006, G loss: 0.6577\n",
      "[804/1762] D loss: 1.4692, G loss: 0.6154\n",
      "[884/1762] D loss: 0.7833, G loss: 1.2268\n",
      "[964/1762] D loss: 1.4127, G loss: 0.8464\n",
      "[1044/1762] D loss: 1.3687, G loss: 0.6801\n",
      "[1124/1762] D loss: 1.3750, G loss: 0.7743\n",
      "[1204/1762] D loss: 1.1029, G loss: 0.9118\n",
      "[1284/1762] D loss: 1.4000, G loss: 0.7533\n",
      "[1364/1762] D loss: 1.1000, G loss: 0.9786\n",
      "[1444/1762] D loss: 1.3884, G loss: 0.7037\n",
      "[1524/1762] D loss: 1.1007, G loss: 0.9697\n",
      "[1604/1762] D loss: 1.0769, G loss: 1.0420\n",
      "[1684/1762] D loss: 1.3511, G loss: 0.6691\n",
      "[1762/1762] D loss: 0.7769, G loss: 1.3597\n",
      "train error: \n",
      " D loss: 1.308882, G loss: 0.753623, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 86.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.292108, G loss: 0.770647, D accuracy: 55.1%, cell accuracy: 99.7%, board accuracy: 84.3% \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3948, G loss: 0.6438\n",
      "[84/1762] D loss: 1.3570, G loss: 0.6985\n",
      "[164/1762] D loss: 1.3703, G loss: 0.8237\n",
      "[244/1762] D loss: 1.3928, G loss: 0.6685\n",
      "[324/1762] D loss: 1.3898, G loss: 0.6285\n",
      "[404/1762] D loss: 1.1117, G loss: 0.9783\n",
      "[484/1762] D loss: 1.3976, G loss: 0.5667\n",
      "[564/1762] D loss: 1.3983, G loss: 0.7923\n",
      "[644/1762] D loss: 1.3956, G loss: 0.6228\n",
      "[724/1762] D loss: 1.1276, G loss: 1.1144\n",
      "[804/1762] D loss: 1.3895, G loss: 0.6952\n",
      "[884/1762] D loss: 1.0977, G loss: 0.9203\n",
      "[964/1762] D loss: 1.1631, G loss: 1.1785\n",
      "[1044/1762] D loss: 1.1549, G loss: 0.7337\n",
      "[1124/1762] D loss: 1.0919, G loss: 0.9389\n",
      "[1204/1762] D loss: 1.3985, G loss: 0.7380\n",
      "[1284/1762] D loss: 1.0662, G loss: 0.9391\n",
      "[1364/1762] D loss: 1.3903, G loss: 0.6619\n",
      "[1444/1762] D loss: 1.3941, G loss: 0.7112\n",
      "[1524/1762] D loss: 1.3882, G loss: 0.6982\n",
      "[1604/1762] D loss: 1.1433, G loss: 0.7821\n",
      "[1684/1762] D loss: 1.0917, G loss: 0.9817\n",
      "[1762/1762] D loss: 1.3981, G loss: 0.7355\n",
      "train error: \n",
      " D loss: 1.304241, G loss: 0.793338, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 85.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.289171, G loss: 0.813861, D accuracy: 55.9%, cell accuracy: 99.7%, board accuracy: 83.9% \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3865, G loss: 0.6389\n",
      "[84/1762] D loss: 1.3883, G loss: 0.6307\n",
      "[164/1762] D loss: 1.3946, G loss: 0.6643\n",
      "[244/1762] D loss: 1.3878, G loss: 0.6877\n",
      "[324/1762] D loss: 1.3709, G loss: 0.6101\n",
      "[404/1762] D loss: 1.0953, G loss: 0.9296\n",
      "[484/1762] D loss: 1.4129, G loss: 0.7745\n",
      "[564/1762] D loss: 1.0759, G loss: 1.1620\n",
      "[644/1762] D loss: 1.3995, G loss: 0.7594\n",
      "[724/1762] D loss: 1.3523, G loss: 0.6882\n",
      "[804/1762] D loss: 1.3964, G loss: 0.5672\n",
      "[884/1762] D loss: 1.3908, G loss: 0.6738\n",
      "[964/1762] D loss: 1.3877, G loss: 0.6911\n",
      "[1044/1762] D loss: 1.3981, G loss: 0.6610\n",
      "[1124/1762] D loss: 1.3897, G loss: 0.7193\n",
      "[1204/1762] D loss: 1.3554, G loss: 0.7298\n",
      "[1284/1762] D loss: 1.3946, G loss: 0.7798\n",
      "[1364/1762] D loss: 1.3888, G loss: 0.7078\n",
      "[1444/1762] D loss: 1.1114, G loss: 0.8293\n",
      "[1524/1762] D loss: 1.3889, G loss: 0.7709\n",
      "[1604/1762] D loss: 1.3931, G loss: 0.7109\n",
      "[1684/1762] D loss: 1.4131, G loss: 0.6709\n",
      "[1762/1762] D loss: 1.4018, G loss: 0.7748\n",
      "train error: \n",
      " D loss: 1.307466, G loss: 0.799943, D accuracy: 55.0%, cell accuracy: 99.7%, board accuracy: 84.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.289294, G loss: 0.821033, D accuracy: 55.9%, cell accuracy: 99.7%, board accuracy: 80.7% \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4211, G loss: 0.6063\n",
      "[84/1762] D loss: 1.1555, G loss: 1.0367\n",
      "[164/1762] D loss: 1.3903, G loss: 0.6654\n",
      "[244/1762] D loss: 1.3980, G loss: 0.7506\n",
      "[324/1762] D loss: 1.0908, G loss: 0.9988\n",
      "[404/1762] D loss: 1.1024, G loss: 1.0457\n",
      "[484/1762] D loss: 1.3882, G loss: 0.7371\n",
      "[564/1762] D loss: 1.3689, G loss: 0.7524\n",
      "[644/1762] D loss: 1.1012, G loss: 1.0267\n",
      "[724/1762] D loss: 1.3927, G loss: 0.7794\n",
      "[804/1762] D loss: 1.3877, G loss: 0.6691\n",
      "[884/1762] D loss: 1.3891, G loss: 0.7051\n",
      "[964/1762] D loss: 1.3934, G loss: 0.7465\n",
      "[1044/1762] D loss: 1.1177, G loss: 0.8554\n",
      "[1124/1762] D loss: 1.1117, G loss: 1.0765\n",
      "[1204/1762] D loss: 1.3947, G loss: 0.7356\n",
      "[1284/1762] D loss: 1.0241, G loss: 1.1557\n",
      "[1364/1762] D loss: 1.3911, G loss: 0.6601\n",
      "[1444/1762] D loss: 1.3877, G loss: 0.6928\n",
      "[1524/1762] D loss: 1.3994, G loss: 0.6180\n",
      "[1604/1762] D loss: 1.3955, G loss: 0.6359\n",
      "[1684/1762] D loss: 1.3916, G loss: 0.7265\n",
      "[1762/1762] D loss: 0.8014, G loss: 1.1897\n",
      "train error: \n",
      " D loss: 1.307250, G loss: 0.760746, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 86.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.288575, G loss: 0.784903, D accuracy: 55.2%, cell accuracy: 99.7%, board accuracy: 83.4% \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3942, G loss: 0.6948\n",
      "[84/1762] D loss: 1.3870, G loss: 0.7122\n",
      "[164/1762] D loss: 1.3964, G loss: 0.6090\n",
      "[244/1762] D loss: 1.0729, G loss: 1.1236\n",
      "[324/1762] D loss: 1.1296, G loss: 0.8214\n",
      "[404/1762] D loss: 1.3876, G loss: 0.6900\n",
      "[484/1762] D loss: 1.0927, G loss: 1.0121\n",
      "[564/1762] D loss: 1.3906, G loss: 0.6558\n",
      "[644/1762] D loss: 1.3906, G loss: 0.7068\n",
      "[724/1762] D loss: 1.3269, G loss: 0.8796\n",
      "[804/1762] D loss: 1.1018, G loss: 0.9973\n",
      "[884/1762] D loss: 1.3809, G loss: 0.6871\n",
      "[964/1762] D loss: 1.0878, G loss: 0.9992\n",
      "[1044/1762] D loss: 1.3940, G loss: 0.7243\n",
      "[1124/1762] D loss: 1.3964, G loss: 0.6070\n",
      "[1204/1762] D loss: 1.1794, G loss: 1.1133\n",
      "[1284/1762] D loss: 1.4124, G loss: 0.8535\n",
      "[1364/1762] D loss: 1.3848, G loss: 0.7463\n",
      "[1444/1762] D loss: 1.3924, G loss: 0.6158\n",
      "[1524/1762] D loss: 1.3894, G loss: 0.6899\n",
      "[1604/1762] D loss: 1.4008, G loss: 0.7534\n",
      "[1684/1762] D loss: 1.4068, G loss: 0.5650\n",
      "[1762/1762] D loss: 0.7888, G loss: 1.2296\n",
      "train error: \n",
      " D loss: 1.308886, G loss: 0.830557, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 88.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.293249, G loss: 0.850933, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3944, G loss: 0.7238\n",
      "[84/1762] D loss: 1.3924, G loss: 0.7109\n",
      "[164/1762] D loss: 1.0980, G loss: 0.8316\n",
      "[244/1762] D loss: 1.3874, G loss: 0.7403\n",
      "[324/1762] D loss: 1.3945, G loss: 0.7624\n",
      "[404/1762] D loss: 1.3972, G loss: 0.7545\n",
      "[484/1762] D loss: 1.1062, G loss: 0.8841\n",
      "[564/1762] D loss: 1.3868, G loss: 0.7168\n",
      "[644/1762] D loss: 1.4035, G loss: 0.6305\n",
      "[724/1762] D loss: 1.3969, G loss: 0.6433\n",
      "[804/1762] D loss: 1.0994, G loss: 0.9342\n",
      "[884/1762] D loss: 1.3890, G loss: 0.7172\n",
      "[964/1762] D loss: 1.4273, G loss: 0.5945\n",
      "[1044/1762] D loss: 1.3651, G loss: 0.6017\n",
      "[1124/1762] D loss: 1.3941, G loss: 0.7532\n",
      "[1204/1762] D loss: 1.0933, G loss: 1.0377\n",
      "[1284/1762] D loss: 1.0905, G loss: 0.9376\n",
      "[1364/1762] D loss: 1.3872, G loss: 0.6999\n",
      "[1444/1762] D loss: 1.0772, G loss: 1.1307\n",
      "[1524/1762] D loss: 1.3899, G loss: 0.6990\n",
      "[1604/1762] D loss: 1.3885, G loss: 0.6747\n",
      "[1684/1762] D loss: 1.3818, G loss: 0.6696\n",
      "[1762/1762] D loss: 1.3990, G loss: 0.7872\n",
      "train error: \n",
      " D loss: 1.312253, G loss: 0.874550, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.292755, G loss: 0.900777, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 85.5% \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3954, G loss: 0.7309\n",
      "[84/1762] D loss: 1.3868, G loss: 0.7350\n",
      "[164/1762] D loss: 1.3637, G loss: 0.7462\n",
      "[244/1762] D loss: 1.4132, G loss: 0.6064\n",
      "[324/1762] D loss: 1.4460, G loss: 0.8020\n",
      "[404/1762] D loss: 1.0673, G loss: 1.1738\n",
      "[484/1762] D loss: 1.3991, G loss: 0.7488\n",
      "[564/1762] D loss: 1.4098, G loss: 0.8258\n",
      "[644/1762] D loss: 1.3870, G loss: 0.7335\n",
      "[724/1762] D loss: 1.3901, G loss: 0.6119\n",
      "[804/1762] D loss: 1.4037, G loss: 0.8095\n",
      "[884/1762] D loss: 1.3944, G loss: 0.6379\n",
      "[964/1762] D loss: 1.3990, G loss: 0.8169\n",
      "[1044/1762] D loss: 1.4013, G loss: 0.6052\n",
      "[1124/1762] D loss: 1.3479, G loss: 0.6947\n",
      "[1204/1762] D loss: 1.3856, G loss: 0.6561\n",
      "[1284/1762] D loss: 1.3909, G loss: 0.6470\n",
      "[1364/1762] D loss: 1.3885, G loss: 0.6387\n",
      "[1444/1762] D loss: 1.4071, G loss: 0.7659\n",
      "[1524/1762] D loss: 1.3888, G loss: 0.7233\n",
      "[1604/1762] D loss: 1.3730, G loss: 0.6881\n",
      "[1684/1762] D loss: 1.3907, G loss: 0.7208\n",
      "[1762/1762] D loss: 1.3882, G loss: 0.7029\n",
      "train error: \n",
      " D loss: 1.294413, G loss: 0.860318, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 84.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.277435, G loss: 0.882832, D accuracy: 55.2%, cell accuracy: 99.7%, board accuracy: 81.4% \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0982, G loss: 1.0613\n",
      "[84/1762] D loss: 1.3895, G loss: 0.6336\n",
      "[164/1762] D loss: 1.3673, G loss: 0.6807\n",
      "[244/1762] D loss: 1.4005, G loss: 0.7842\n",
      "[324/1762] D loss: 1.3924, G loss: 0.6557\n",
      "[404/1762] D loss: 1.3966, G loss: 0.6132\n",
      "[484/1762] D loss: 1.3916, G loss: 0.7463\n",
      "[564/1762] D loss: 1.3874, G loss: 0.6924\n",
      "[644/1762] D loss: 1.3922, G loss: 0.7115\n",
      "[724/1762] D loss: 1.3873, G loss: 0.6650\n",
      "[804/1762] D loss: 1.3883, G loss: 0.6836\n",
      "[884/1762] D loss: 1.3903, G loss: 0.7486\n",
      "[964/1762] D loss: 1.3870, G loss: 0.6742\n",
      "[1044/1762] D loss: 1.0873, G loss: 1.0670\n",
      "[1124/1762] D loss: 1.3879, G loss: 0.6690\n",
      "[1204/1762] D loss: 1.3962, G loss: 0.6135\n",
      "[1284/1762] D loss: 1.1865, G loss: 1.3322\n",
      "[1364/1762] D loss: 1.4679, G loss: 0.9949\n",
      "[1444/1762] D loss: 1.4037, G loss: 0.5927\n",
      "[1524/1762] D loss: 1.3893, G loss: 0.6958\n",
      "[1604/1762] D loss: 1.3937, G loss: 0.7143\n",
      "[1684/1762] D loss: 1.4075, G loss: 0.8026\n",
      "[1762/1762] D loss: 0.7565, G loss: 1.4242\n",
      "train error: \n",
      " D loss: 1.308878, G loss: 0.798732, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 89.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.290040, G loss: 0.827070, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 85.5% \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3910, G loss: 0.6701\n",
      "[84/1762] D loss: 1.0852, G loss: 1.0581\n",
      "[164/1762] D loss: 1.4025, G loss: 0.7029\n",
      "[244/1762] D loss: 1.4024, G loss: 0.7691\n",
      "[324/1762] D loss: 1.0862, G loss: 0.9032\n",
      "[404/1762] D loss: 1.3959, G loss: 0.7235\n",
      "[484/1762] D loss: 1.3781, G loss: 0.7069\n",
      "[564/1762] D loss: 1.3904, G loss: 0.6464\n",
      "[644/1762] D loss: 1.3861, G loss: 0.6764\n",
      "[724/1762] D loss: 1.3878, G loss: 0.7185\n",
      "[804/1762] D loss: 1.3998, G loss: 0.6127\n",
      "[884/1762] D loss: 1.4459, G loss: 0.7040\n",
      "[964/1762] D loss: 1.0911, G loss: 0.9519\n",
      "[1044/1762] D loss: 1.1152, G loss: 1.0624\n",
      "[1124/1762] D loss: 1.3872, G loss: 0.6943\n",
      "[1204/1762] D loss: 1.3896, G loss: 0.7074\n",
      "[1284/1762] D loss: 1.3945, G loss: 0.7634\n",
      "[1364/1762] D loss: 1.3941, G loss: 0.6288\n",
      "[1444/1762] D loss: 1.4109, G loss: 0.7640\n",
      "[1524/1762] D loss: 1.3877, G loss: 0.6729\n",
      "[1604/1762] D loss: 1.4004, G loss: 0.6383\n",
      "[1684/1762] D loss: 1.3958, G loss: 0.7413\n",
      "[1762/1762] D loss: 0.7416, G loss: 1.6350\n",
      "train error: \n",
      " D loss: 1.308455, G loss: 0.821382, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.289183, G loss: 0.852561, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3892, G loss: 0.7664\n",
      "[84/1762] D loss: 1.0900, G loss: 0.9660\n",
      "[164/1762] D loss: 1.3882, G loss: 0.7322\n",
      "[244/1762] D loss: 1.1405, G loss: 0.9692\n",
      "[324/1762] D loss: 1.4045, G loss: 0.5830\n",
      "[404/1762] D loss: 1.3966, G loss: 0.7591\n",
      "[484/1762] D loss: 1.3913, G loss: 0.6685\n",
      "[564/1762] D loss: 1.4020, G loss: 0.7573\n",
      "[644/1762] D loss: 1.0126, G loss: 1.3973\n",
      "[724/1762] D loss: 1.3903, G loss: 0.6111\n",
      "[804/1762] D loss: 1.3963, G loss: 0.6499\n",
      "[884/1762] D loss: 1.4021, G loss: 0.5763\n",
      "[964/1762] D loss: 1.3907, G loss: 0.7452\n",
      "[1044/1762] D loss: 1.4045, G loss: 0.6611\n",
      "[1124/1762] D loss: 1.3948, G loss: 0.6256\n",
      "[1204/1762] D loss: 1.0956, G loss: 0.9271\n",
      "[1284/1762] D loss: 1.3961, G loss: 0.7437\n",
      "[1364/1762] D loss: 1.3927, G loss: 0.7402\n",
      "[1444/1762] D loss: 1.0784, G loss: 1.1382\n",
      "[1524/1762] D loss: 1.3921, G loss: 0.6380\n",
      "[1604/1762] D loss: 1.3930, G loss: 0.7434\n",
      "[1684/1762] D loss: 1.3872, G loss: 0.7020\n",
      "[1762/1762] D loss: 1.3886, G loss: 0.6826\n",
      "train error: \n",
      " D loss: 1.308570, G loss: 0.837855, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 89.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.289127, G loss: 0.867460, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 85.9% \n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3868, G loss: 0.7287\n",
      "[84/1762] D loss: 1.0869, G loss: 1.0477\n",
      "[164/1762] D loss: 1.3876, G loss: 0.6831\n",
      "[244/1762] D loss: 1.3847, G loss: 0.7155\n",
      "[324/1762] D loss: 1.3881, G loss: 0.6471\n",
      "[404/1762] D loss: 1.3865, G loss: 0.7505\n",
      "[484/1762] D loss: 1.4806, G loss: 0.5871\n",
      "[564/1762] D loss: 1.0784, G loss: 1.2338\n",
      "[644/1762] D loss: 1.3988, G loss: 0.7255\n",
      "[724/1762] D loss: 1.3894, G loss: 0.6461\n",
      "[804/1762] D loss: 1.4060, G loss: 0.5982\n",
      "[884/1762] D loss: 1.3892, G loss: 0.7506\n",
      "[964/1762] D loss: 1.3908, G loss: 0.6129\n",
      "[1044/1762] D loss: 1.3897, G loss: 0.7273\n",
      "[1124/1762] D loss: 1.4021, G loss: 0.7669\n",
      "[1204/1762] D loss: 1.3991, G loss: 0.6547\n",
      "[1284/1762] D loss: 1.0921, G loss: 0.9062\n",
      "[1364/1762] D loss: 1.0981, G loss: 1.0200\n",
      "[1444/1762] D loss: 1.4101, G loss: 0.6024\n",
      "[1524/1762] D loss: 1.0810, G loss: 1.0626\n",
      "[1604/1762] D loss: 1.0844, G loss: 0.9618\n",
      "[1684/1762] D loss: 1.4333, G loss: 0.8341\n",
      "[1762/1762] D loss: 1.3918, G loss: 0.7830\n",
      "train error: \n",
      " D loss: 1.307056, G loss: 0.866192, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 85.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.286895, G loss: 0.900165, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 84.3% \n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3916, G loss: 0.7591\n",
      "[84/1762] D loss: 1.3877, G loss: 0.6838\n",
      "[164/1762] D loss: 1.3897, G loss: 0.6737\n",
      "[244/1762] D loss: 1.3878, G loss: 0.7121\n",
      "[324/1762] D loss: 1.3925, G loss: 0.6422\n",
      "[404/1762] D loss: 1.3873, G loss: 0.7254\n",
      "[484/1762] D loss: 1.3876, G loss: 0.6851\n",
      "[564/1762] D loss: 1.0811, G loss: 1.1503\n",
      "[644/1762] D loss: 1.4369, G loss: 0.5893\n",
      "[724/1762] D loss: 1.1033, G loss: 0.9680\n",
      "[804/1762] D loss: 1.3932, G loss: 0.6916\n",
      "[884/1762] D loss: 1.0886, G loss: 1.0009\n",
      "[964/1762] D loss: 1.3884, G loss: 0.7040\n",
      "[1044/1762] D loss: 1.3920, G loss: 0.6946\n",
      "[1124/1762] D loss: 1.4007, G loss: 0.7852\n",
      "[1204/1762] D loss: 1.1044, G loss: 0.8344\n",
      "[1284/1762] D loss: 1.3917, G loss: 0.6665\n",
      "[1364/1762] D loss: 1.0885, G loss: 1.1486\n",
      "[1444/1762] D loss: 1.3868, G loss: 0.7346\n",
      "[1524/1762] D loss: 1.3877, G loss: 0.6946\n",
      "[1604/1762] D loss: 1.3900, G loss: 0.6821\n",
      "[1684/1762] D loss: 1.0951, G loss: 0.9256\n",
      "[1762/1762] D loss: 1.3870, G loss: 0.7309\n",
      "train error: \n",
      " D loss: 1.308546, G loss: 0.852228, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.288526, G loss: 0.884485, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0829, G loss: 1.0524\n",
      "[84/1762] D loss: 1.3887, G loss: 0.6897\n",
      "[164/1762] D loss: 1.1044, G loss: 1.1330\n",
      "[244/1762] D loss: 1.1409, G loss: 0.9153\n",
      "[324/1762] D loss: 1.4051, G loss: 0.7083\n",
      "[404/1762] D loss: 1.0895, G loss: 0.9726\n",
      "[484/1762] D loss: 1.0971, G loss: 1.0493\n",
      "[564/1762] D loss: 1.2054, G loss: 1.0728\n",
      "[644/1762] D loss: 1.4117, G loss: 0.8232\n",
      "[724/1762] D loss: 1.0977, G loss: 1.1039\n",
      "[804/1762] D loss: 1.3984, G loss: 0.6514\n",
      "[884/1762] D loss: 1.3890, G loss: 0.9532\n",
      "[964/1762] D loss: 1.3877, G loss: 0.6642\n",
      "[1044/1762] D loss: 1.3887, G loss: 0.7204\n",
      "[1124/1762] D loss: 1.3955, G loss: 0.7492\n",
      "[1204/1762] D loss: 1.3952, G loss: 0.6281\n",
      "[1284/1762] D loss: 1.3870, G loss: 0.6817\n",
      "[1364/1762] D loss: 1.3911, G loss: 0.6898\n",
      "[1444/1762] D loss: 1.3893, G loss: 0.6299\n",
      "[1524/1762] D loss: 1.0939, G loss: 0.9843\n",
      "[1604/1762] D loss: 1.4000, G loss: 0.6988\n",
      "[1684/1762] D loss: 1.3843, G loss: 0.7900\n",
      "[1762/1762] D loss: 0.7726, G loss: 1.3522\n",
      "train error: \n",
      " D loss: 1.310019, G loss: 0.860532, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 84.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.289735, G loss: 0.890083, D accuracy: 55.0%, cell accuracy: 99.7%, board accuracy: 79.8% \n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3607, G loss: 0.7474\n",
      "[84/1762] D loss: 1.1020, G loss: 0.8754\n",
      "[164/1762] D loss: 1.3916, G loss: 0.7421\n",
      "[244/1762] D loss: 1.4109, G loss: 0.7966\n",
      "[324/1762] D loss: 1.3876, G loss: 0.7124\n",
      "[404/1762] D loss: 1.3887, G loss: 0.6855\n",
      "[484/1762] D loss: 1.3880, G loss: 0.7424\n",
      "[564/1762] D loss: 1.4857, G loss: 0.8176\n",
      "[644/1762] D loss: 1.3941, G loss: 0.7592\n",
      "[724/1762] D loss: 1.0802, G loss: 1.0321\n",
      "[804/1762] D loss: 1.4056, G loss: 0.7501\n",
      "[884/1762] D loss: 1.4003, G loss: 0.7126\n",
      "[964/1762] D loss: 1.4268, G loss: 0.5932\n",
      "[1044/1762] D loss: 1.4160, G loss: 0.8149\n",
      "[1124/1762] D loss: 1.0811, G loss: 1.0779\n",
      "[1204/1762] D loss: 1.4300, G loss: 0.7007\n",
      "[1284/1762] D loss: 1.3870, G loss: 0.7217\n",
      "[1364/1762] D loss: 0.7806, G loss: 1.5127\n",
      "[1444/1762] D loss: 1.3630, G loss: 0.6170\n",
      "[1524/1762] D loss: 1.3751, G loss: 0.6627\n",
      "[1604/1762] D loss: 1.3872, G loss: 0.6860\n",
      "[1684/1762] D loss: 1.3892, G loss: 0.7049\n",
      "[1762/1762] D loss: 1.3792, G loss: 0.7018\n",
      "train error: \n",
      " D loss: 1.304604, G loss: 0.764567, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 87.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.284480, G loss: 0.795323, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 84.3% \n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3936, G loss: 0.6327\n",
      "[84/1762] D loss: 1.3889, G loss: 0.6851\n",
      "[164/1762] D loss: 1.4054, G loss: 0.8167\n",
      "[244/1762] D loss: 1.3878, G loss: 0.6473\n",
      "[324/1762] D loss: 1.0992, G loss: 1.0243\n",
      "[404/1762] D loss: 1.1056, G loss: 0.9028\n",
      "[484/1762] D loss: 1.4220, G loss: 0.8428\n",
      "[564/1762] D loss: 1.3873, G loss: 0.7351\n",
      "[644/1762] D loss: 1.0794, G loss: 1.0183\n",
      "[724/1762] D loss: 1.3894, G loss: 0.5881\n",
      "[804/1762] D loss: 1.3877, G loss: 0.6998\n",
      "[884/1762] D loss: 1.0930, G loss: 1.0104\n",
      "[964/1762] D loss: 1.4241, G loss: 0.6619\n",
      "[1044/1762] D loss: 1.3898, G loss: 0.6516\n",
      "[1124/1762] D loss: 1.0838, G loss: 1.1438\n",
      "[1204/1762] D loss: 1.3902, G loss: 0.7684\n",
      "[1284/1762] D loss: 1.0934, G loss: 1.0710\n",
      "[1364/1762] D loss: 1.3927, G loss: 0.6265\n",
      "[1444/1762] D loss: 1.0820, G loss: 0.9961\n",
      "[1524/1762] D loss: 1.4018, G loss: 0.7730\n",
      "[1604/1762] D loss: 1.3874, G loss: 0.6953\n",
      "[1684/1762] D loss: 1.3961, G loss: 0.7390\n",
      "[1762/1762] D loss: 0.7948, G loss: 1.2375\n",
      "train error: \n",
      " D loss: 1.303866, G loss: 0.823874, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 90.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.281598, G loss: 0.852657, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3887, G loss: 0.7270\n",
      "[84/1762] D loss: 1.3878, G loss: 0.7419\n",
      "[164/1762] D loss: 1.3915, G loss: 0.6481\n",
      "[244/1762] D loss: 1.3870, G loss: 0.7044\n",
      "[324/1762] D loss: 1.0964, G loss: 0.9779\n",
      "[404/1762] D loss: 1.0799, G loss: 1.0138\n",
      "[484/1762] D loss: 1.3955, G loss: 0.6182\n",
      "[564/1762] D loss: 1.3947, G loss: 0.7351\n",
      "[644/1762] D loss: 1.3901, G loss: 0.6686\n",
      "[724/1762] D loss: 1.0801, G loss: 1.0256\n",
      "[804/1762] D loss: 1.3931, G loss: 0.6685\n",
      "[884/1762] D loss: 1.3914, G loss: 0.6827\n",
      "[964/1762] D loss: 1.3820, G loss: 0.7279\n",
      "[1044/1762] D loss: 1.0808, G loss: 1.0084\n",
      "[1124/1762] D loss: 1.0660, G loss: 1.1812\n",
      "[1204/1762] D loss: 1.3920, G loss: 0.7265\n",
      "[1284/1762] D loss: 1.0880, G loss: 0.9264\n",
      "[1364/1762] D loss: 1.3911, G loss: 0.6642\n",
      "[1444/1762] D loss: 1.3960, G loss: 0.7828\n",
      "[1524/1762] D loss: 1.0800, G loss: 1.1401\n",
      "[1604/1762] D loss: 1.3974, G loss: 0.7399\n",
      "[1684/1762] D loss: 1.4136, G loss: 0.8007\n",
      "[1762/1762] D loss: 1.3908, G loss: 0.6386\n",
      "train error: \n",
      " D loss: 1.307092, G loss: 0.752634, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 89.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.286549, G loss: 0.788792, D accuracy: 55.0%, cell accuracy: 99.7%, board accuracy: 85.2% \n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3871, G loss: 0.6977\n",
      "[84/1762] D loss: 1.4225, G loss: 0.6268\n",
      "[164/1762] D loss: 1.3887, G loss: 0.6868\n",
      "[244/1762] D loss: 1.4145, G loss: 0.6928\n",
      "[324/1762] D loss: 1.3940, G loss: 0.7241\n",
      "[404/1762] D loss: 1.3932, G loss: 0.7386\n",
      "[484/1762] D loss: 1.3900, G loss: 0.7269\n",
      "[564/1762] D loss: 1.3987, G loss: 0.7798\n",
      "[644/1762] D loss: 1.3891, G loss: 0.7332\n",
      "[724/1762] D loss: 1.4000, G loss: 0.8245\n",
      "[804/1762] D loss: 1.3900, G loss: 0.6161\n",
      "[884/1762] D loss: 1.3942, G loss: 0.7499\n",
      "[964/1762] D loss: 1.0839, G loss: 1.0903\n",
      "[1044/1762] D loss: 1.3885, G loss: 0.7113\n",
      "[1124/1762] D loss: 1.0780, G loss: 0.9780\n",
      "[1204/1762] D loss: 1.4015, G loss: 0.6942\n",
      "[1284/1762] D loss: 1.3912, G loss: 0.7392\n",
      "[1364/1762] D loss: 1.3884, G loss: 0.6815\n",
      "[1444/1762] D loss: 1.0752, G loss: 1.2236\n",
      "[1524/1762] D loss: 1.3902, G loss: 0.6983\n",
      "[1604/1762] D loss: 1.0646, G loss: 1.2117\n",
      "[1684/1762] D loss: 1.3895, G loss: 0.6653\n",
      "[1762/1762] D loss: 0.7899, G loss: 1.2555\n",
      "train error: \n",
      " D loss: 1.305523, G loss: 0.840356, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.285013, G loss: 0.873646, D accuracy: 54.2%, cell accuracy: 99.7%, board accuracy: 84.8% \n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3877, G loss: 0.7469\n",
      "[84/1762] D loss: 1.3891, G loss: 0.7010\n",
      "[164/1762] D loss: 1.3922, G loss: 0.7400\n",
      "[244/1762] D loss: 1.3904, G loss: 0.6791\n",
      "[324/1762] D loss: 1.3868, G loss: 0.7083\n",
      "[404/1762] D loss: 1.3941, G loss: 0.6107\n",
      "[484/1762] D loss: 1.4004, G loss: 0.7929\n",
      "[564/1762] D loss: 1.3898, G loss: 0.7400\n",
      "[644/1762] D loss: 1.4092, G loss: 0.6763\n",
      "[724/1762] D loss: 1.0853, G loss: 1.0482\n",
      "[804/1762] D loss: 1.3916, G loss: 0.7256\n",
      "[884/1762] D loss: 1.4061, G loss: 0.7162\n",
      "[964/1762] D loss: 1.3909, G loss: 0.6874\n",
      "[1044/1762] D loss: 1.3967, G loss: 0.7353\n",
      "[1124/1762] D loss: 1.3893, G loss: 0.6691\n",
      "[1204/1762] D loss: 1.3915, G loss: 0.7306\n",
      "[1284/1762] D loss: 1.3872, G loss: 0.6866\n",
      "[1364/1762] D loss: 1.3887, G loss: 0.6355\n",
      "[1444/1762] D loss: 1.3953, G loss: 0.7990\n",
      "[1524/1762] D loss: 1.0781, G loss: 0.9791\n",
      "[1604/1762] D loss: 1.3958, G loss: 0.6446\n",
      "[1684/1762] D loss: 1.0627, G loss: 1.1476\n",
      "[1762/1762] D loss: 1.3875, G loss: 0.6225\n",
      "train error: \n",
      " D loss: 1.300717, G loss: 0.761596, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 85.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.282669, G loss: 0.786564, D accuracy: 55.7%, cell accuracy: 99.7%, board accuracy: 81.4% \n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3931, G loss: 0.6203\n",
      "[84/1762] D loss: 1.4055, G loss: 0.8286\n",
      "[164/1762] D loss: 1.3885, G loss: 0.6945\n",
      "[244/1762] D loss: 1.0897, G loss: 0.9395\n",
      "[324/1762] D loss: 1.3874, G loss: 0.7169\n",
      "[404/1762] D loss: 1.0690, G loss: 1.0546\n",
      "[484/1762] D loss: 1.0618, G loss: 1.0810\n",
      "[564/1762] D loss: 1.0871, G loss: 1.0681\n",
      "[644/1762] D loss: 1.0708, G loss: 1.1380\n",
      "[724/1762] D loss: 1.3888, G loss: 0.6293\n",
      "[804/1762] D loss: 1.3873, G loss: 0.6862\n",
      "[884/1762] D loss: 1.3879, G loss: 0.6921\n",
      "[964/1762] D loss: 1.3928, G loss: 0.7477\n",
      "[1044/1762] D loss: 1.0627, G loss: 1.0824\n",
      "[1124/1762] D loss: 1.0662, G loss: 1.2500\n",
      "[1204/1762] D loss: 1.3870, G loss: 0.6959\n",
      "[1284/1762] D loss: 1.3883, G loss: 0.6892\n",
      "[1364/1762] D loss: 1.3931, G loss: 0.6431\n",
      "[1444/1762] D loss: 1.3924, G loss: 0.6315\n",
      "[1524/1762] D loss: 1.0838, G loss: 1.0048\n",
      "[1604/1762] D loss: 1.3936, G loss: 0.6917\n",
      "[1684/1762] D loss: 0.8800, G loss: 1.5076\n",
      "[1762/1762] D loss: 1.3878, G loss: 0.7490\n",
      "train error: \n",
      " D loss: 1.304231, G loss: 0.830172, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.283129, G loss: 0.863710, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 85.5% \n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4017, G loss: 0.7278\n",
      "[84/1762] D loss: 1.3910, G loss: 0.7514\n",
      "[164/1762] D loss: 1.3885, G loss: 0.7149\n",
      "[244/1762] D loss: 1.3964, G loss: 0.6364\n",
      "[324/1762] D loss: 1.3934, G loss: 0.7517\n",
      "[404/1762] D loss: 1.4056, G loss: 0.7699\n",
      "[484/1762] D loss: 1.3952, G loss: 0.6523\n",
      "[564/1762] D loss: 1.3914, G loss: 0.5718\n",
      "[644/1762] D loss: 1.0732, G loss: 1.3312\n",
      "[724/1762] D loss: 1.0828, G loss: 1.0377\n",
      "[804/1762] D loss: 1.0600, G loss: 1.2932\n",
      "[884/1762] D loss: 1.3897, G loss: 0.7605\n",
      "[964/1762] D loss: 1.0779, G loss: 0.9989\n",
      "[1044/1762] D loss: 1.4017, G loss: 0.7718\n",
      "[1124/1762] D loss: 1.3903, G loss: 0.6878\n",
      "[1204/1762] D loss: 1.3947, G loss: 0.7636\n",
      "[1284/1762] D loss: 1.4010, G loss: 0.6406\n",
      "[1364/1762] D loss: 1.4071, G loss: 0.7451\n",
      "[1444/1762] D loss: 1.0807, G loss: 1.1061\n",
      "[1524/1762] D loss: 1.3928, G loss: 0.6307\n",
      "[1604/1762] D loss: 1.0642, G loss: 1.1931\n",
      "[1684/1762] D loss: 1.0694, G loss: 1.1968\n",
      "[1762/1762] D loss: 1.3878, G loss: 0.7425\n",
      "train error: \n",
      " D loss: 1.303104, G loss: 0.824447, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 89.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.281757, G loss: 0.862994, D accuracy: 54.2%, cell accuracy: 99.7%, board accuracy: 85.5% \n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3955, G loss: 0.7450\n",
      "[84/1762] D loss: 1.3998, G loss: 0.5849\n",
      "[164/1762] D loss: 1.3893, G loss: 0.6698\n",
      "[244/1762] D loss: 1.0852, G loss: 1.0534\n",
      "[324/1762] D loss: 1.4007, G loss: 0.5850\n",
      "[404/1762] D loss: 1.3914, G loss: 0.6624\n",
      "[484/1762] D loss: 1.0809, G loss: 1.0663\n",
      "[564/1762] D loss: 1.0871, G loss: 1.0766\n",
      "[644/1762] D loss: 1.3988, G loss: 0.7428\n",
      "[724/1762] D loss: 1.3949, G loss: 0.6487\n",
      "[804/1762] D loss: 1.3820, G loss: 0.7202\n",
      "[884/1762] D loss: 1.0649, G loss: 1.1276\n",
      "[964/1762] D loss: 1.4030, G loss: 0.8087\n",
      "[1044/1762] D loss: 1.3970, G loss: 0.7299\n",
      "[1124/1762] D loss: 1.3941, G loss: 0.7658\n",
      "[1204/1762] D loss: 1.3878, G loss: 0.7242\n",
      "[1284/1762] D loss: 1.4804, G loss: 0.9128\n",
      "[1364/1762] D loss: 1.0883, G loss: 0.9824\n",
      "[1444/1762] D loss: 1.3923, G loss: 0.6930\n",
      "[1524/1762] D loss: 1.0705, G loss: 1.0633\n",
      "[1604/1762] D loss: 1.0802, G loss: 1.0867\n",
      "[1684/1762] D loss: 1.3921, G loss: 0.6358\n",
      "[1762/1762] D loss: 1.4064, G loss: 0.7599\n",
      "train error: \n",
      " D loss: 1.302239, G loss: 0.749642, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 85.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.284731, G loss: 0.779068, D accuracy: 55.1%, cell accuracy: 99.7%, board accuracy: 82.7% \n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4007, G loss: 0.6454\n",
      "[84/1762] D loss: 1.0818, G loss: 0.9963\n",
      "[164/1762] D loss: 1.3938, G loss: 0.6831\n",
      "[244/1762] D loss: 1.4000, G loss: 0.5657\n",
      "[324/1762] D loss: 1.3997, G loss: 0.7725\n",
      "[404/1762] D loss: 0.7798, G loss: 1.4374\n",
      "[484/1762] D loss: 1.4010, G loss: 0.5968\n",
      "[564/1762] D loss: 1.3925, G loss: 0.6197\n",
      "[644/1762] D loss: 1.0777, G loss: 1.0123\n",
      "[724/1762] D loss: 1.0761, G loss: 1.0127\n",
      "[804/1762] D loss: 1.0755, G loss: 1.0470\n",
      "[884/1762] D loss: 1.0856, G loss: 1.0370\n",
      "[964/1762] D loss: 1.3881, G loss: 0.7092\n",
      "[1044/1762] D loss: 1.3905, G loss: 0.6983\n",
      "[1124/1762] D loss: 1.3923, G loss: 0.7123\n",
      "[1204/1762] D loss: 1.4013, G loss: 0.6694\n",
      "[1284/1762] D loss: 1.3962, G loss: 0.6234\n",
      "[1364/1762] D loss: 1.0852, G loss: 1.1569\n",
      "[1444/1762] D loss: 1.3902, G loss: 0.7655\n",
      "[1524/1762] D loss: 1.3871, G loss: 0.7082\n",
      "[1604/1762] D loss: 1.3899, G loss: 0.6954\n",
      "[1684/1762] D loss: 1.3889, G loss: 0.6956\n",
      "[1762/1762] D loss: 1.4233, G loss: 0.5454\n",
      "train error: \n",
      " D loss: 1.318526, G loss: 0.680125, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 90.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.293683, G loss: 0.719771, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0675, G loss: 1.2390\n",
      "[84/1762] D loss: 1.4091, G loss: 0.6481\n",
      "[164/1762] D loss: 1.3974, G loss: 0.7029\n",
      "[244/1762] D loss: 1.5000, G loss: 0.9148\n",
      "[324/1762] D loss: 1.0796, G loss: 1.1552\n",
      "[404/1762] D loss: 1.3865, G loss: 0.6865\n",
      "[484/1762] D loss: 1.3896, G loss: 0.6859\n",
      "[564/1762] D loss: 1.3793, G loss: 0.6322\n",
      "[644/1762] D loss: 1.3887, G loss: 0.6561\n",
      "[724/1762] D loss: 1.3865, G loss: 0.6677\n",
      "[804/1762] D loss: 1.3930, G loss: 0.7424\n",
      "[884/1762] D loss: 1.3882, G loss: 0.7376\n",
      "[964/1762] D loss: 1.3907, G loss: 0.6470\n",
      "[1044/1762] D loss: 1.3627, G loss: 0.9937\n",
      "[1124/1762] D loss: 1.3923, G loss: 0.6486\n",
      "[1204/1762] D loss: 1.0587, G loss: 1.2365\n",
      "[1284/1762] D loss: 1.3913, G loss: 0.6930\n",
      "[1364/1762] D loss: 1.3874, G loss: 0.6130\n",
      "[1444/1762] D loss: 1.3888, G loss: 0.6589\n",
      "[1524/1762] D loss: 1.3901, G loss: 0.7236\n",
      "[1604/1762] D loss: 1.3909, G loss: 0.7506\n",
      "[1684/1762] D loss: 1.3902, G loss: 0.7141\n",
      "[1762/1762] D loss: 1.3924, G loss: 0.6150\n",
      "train error: \n",
      " D loss: 1.301518, G loss: 0.802460, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 90.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.278574, G loss: 0.844612, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3903, G loss: 0.7240\n",
      "[84/1762] D loss: 1.0768, G loss: 1.0436\n",
      "[164/1762] D loss: 1.3954, G loss: 0.7052\n",
      "[244/1762] D loss: 1.3993, G loss: 0.8004\n",
      "[324/1762] D loss: 1.3905, G loss: 0.6757\n",
      "[404/1762] D loss: 1.3927, G loss: 0.6679\n",
      "[484/1762] D loss: 1.0930, G loss: 0.9385\n",
      "[564/1762] D loss: 1.3908, G loss: 0.6559\n",
      "[644/1762] D loss: 1.3881, G loss: 0.6795\n",
      "[724/1762] D loss: 1.4023, G loss: 0.6554\n",
      "[804/1762] D loss: 1.3958, G loss: 0.7798\n",
      "[884/1762] D loss: 1.3888, G loss: 0.7388\n",
      "[964/1762] D loss: 1.3891, G loss: 0.7810\n",
      "[1044/1762] D loss: 1.3890, G loss: 0.7260\n",
      "[1124/1762] D loss: 1.3970, G loss: 0.7475\n",
      "[1204/1762] D loss: 1.3934, G loss: 0.6553\n",
      "[1284/1762] D loss: 1.0772, G loss: 1.1246\n",
      "[1364/1762] D loss: 1.3942, G loss: 0.7487\n",
      "[1444/1762] D loss: 1.0758, G loss: 1.0711\n",
      "[1524/1762] D loss: 1.3919, G loss: 0.7333\n",
      "[1604/1762] D loss: 1.3976, G loss: 0.6171\n",
      "[1684/1762] D loss: 1.3919, G loss: 0.6453\n",
      "[1762/1762] D loss: 0.7525, G loss: 1.4592\n",
      "train error: \n",
      " D loss: 1.301217, G loss: 0.782704, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 91.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.278272, G loss: 0.820263, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3878, G loss: 0.6908\n",
      "[84/1762] D loss: 1.3915, G loss: 0.6836\n",
      "[164/1762] D loss: 1.3880, G loss: 0.7310\n",
      "[244/1762] D loss: 1.3986, G loss: 0.7473\n",
      "[324/1762] D loss: 1.3887, G loss: 0.6745\n",
      "[404/1762] D loss: 1.3936, G loss: 0.6628\n",
      "[484/1762] D loss: 1.4011, G loss: 0.8276\n",
      "[564/1762] D loss: 1.3876, G loss: 0.6571\n",
      "[644/1762] D loss: 1.3922, G loss: 0.6414\n",
      "[724/1762] D loss: 1.3882, G loss: 0.7414\n",
      "[804/1762] D loss: 1.3886, G loss: 0.6600\n",
      "[884/1762] D loss: 1.3881, G loss: 0.6640\n",
      "[964/1762] D loss: 1.3871, G loss: 0.6887\n",
      "[1044/1762] D loss: 1.0815, G loss: 1.1152\n",
      "[1124/1762] D loss: 1.3883, G loss: 0.7400\n",
      "[1204/1762] D loss: 1.3901, G loss: 0.7682\n",
      "[1284/1762] D loss: 1.3893, G loss: 0.6702\n",
      "[1364/1762] D loss: 1.3937, G loss: 0.7469\n",
      "[1444/1762] D loss: 1.3871, G loss: 0.6327\n",
      "[1524/1762] D loss: 1.3928, G loss: 0.7330\n",
      "[1604/1762] D loss: 1.0922, G loss: 0.9928\n",
      "[1684/1762] D loss: 1.3884, G loss: 0.6596\n",
      "[1762/1762] D loss: 0.7638, G loss: 1.4549\n",
      "train error: \n",
      " D loss: 1.301861, G loss: 0.860013, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.281271, G loss: 0.895476, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3880, G loss: 0.7373\n",
      "[84/1762] D loss: 1.3901, G loss: 0.6778\n",
      "[164/1762] D loss: 1.3920, G loss: 0.7232\n",
      "[244/1762] D loss: 1.3935, G loss: 0.7145\n",
      "[324/1762] D loss: 1.3901, G loss: 0.7101\n",
      "[404/1762] D loss: 1.3881, G loss: 0.6868\n",
      "[484/1762] D loss: 1.3909, G loss: 0.6789\n",
      "[564/1762] D loss: 1.3956, G loss: 0.7267\n",
      "[644/1762] D loss: 1.0634, G loss: 1.1679\n",
      "[724/1762] D loss: 1.0831, G loss: 1.0199\n",
      "[804/1762] D loss: 1.3096, G loss: 0.8809\n",
      "[884/1762] D loss: 1.1500, G loss: 0.9646\n",
      "[964/1762] D loss: 0.8907, G loss: 1.3121\n",
      "[1044/1762] D loss: 1.4926, G loss: 0.6421\n",
      "[1124/1762] D loss: 1.3150, G loss: 0.9792\n",
      "[1204/1762] D loss: 1.3951, G loss: 0.6393\n",
      "[1284/1762] D loss: 1.3902, G loss: 0.7133\n",
      "[1364/1762] D loss: 1.0963, G loss: 1.0129\n",
      "[1444/1762] D loss: 1.3872, G loss: 0.6820\n",
      "[1524/1762] D loss: 1.0861, G loss: 1.1097\n",
      "[1604/1762] D loss: 1.3954, G loss: 0.6609\n",
      "[1684/1762] D loss: 1.4024, G loss: 0.6251\n",
      "[1762/1762] D loss: 1.3934, G loss: 0.6399\n",
      "train error: \n",
      " D loss: 1.311748, G loss: 0.865628, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 90.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.292217, G loss: 0.894662, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3887, G loss: 0.7419\n",
      "[84/1762] D loss: 1.3910, G loss: 0.6920\n",
      "[164/1762] D loss: 1.3923, G loss: 0.6174\n",
      "[244/1762] D loss: 1.3958, G loss: 0.7513\n",
      "[324/1762] D loss: 1.3907, G loss: 0.7009\n",
      "[404/1762] D loss: 1.4011, G loss: 0.5745\n",
      "[484/1762] D loss: 1.0770, G loss: 0.8830\n",
      "[564/1762] D loss: 1.3905, G loss: 0.6946\n",
      "[644/1762] D loss: 0.7937, G loss: 1.2596\n",
      "[724/1762] D loss: 1.3862, G loss: 0.6624\n",
      "[804/1762] D loss: 1.1523, G loss: 1.1370\n",
      "[884/1762] D loss: 1.3940, G loss: 0.6316\n",
      "[964/1762] D loss: 1.3826, G loss: 0.6113\n",
      "[1044/1762] D loss: 1.0755, G loss: 1.0005\n",
      "[1124/1762] D loss: 1.3907, G loss: 0.7382\n",
      "[1204/1762] D loss: 1.3873, G loss: 0.7329\n",
      "[1284/1762] D loss: 0.7914, G loss: 1.2631\n",
      "[1364/1762] D loss: 1.0901, G loss: 1.0534\n",
      "[1444/1762] D loss: 1.3905, G loss: 0.6802\n",
      "[1524/1762] D loss: 1.3895, G loss: 0.7405\n",
      "[1604/1762] D loss: 1.1131, G loss: 0.9955\n",
      "[1684/1762] D loss: 1.3918, G loss: 0.6122\n",
      "[1762/1762] D loss: 1.3960, G loss: 0.7435\n",
      "train error: \n",
      " D loss: 1.301087, G loss: 0.847232, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 90.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.276104, G loss: 0.891826, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0656, G loss: 1.0779\n",
      "[84/1762] D loss: 1.0819, G loss: 1.1199\n",
      "[164/1762] D loss: 1.3878, G loss: 0.7433\n",
      "[244/1762] D loss: 1.3864, G loss: 0.6718\n",
      "[324/1762] D loss: 1.3892, G loss: 0.7033\n",
      "[404/1762] D loss: 1.0824, G loss: 0.9525\n",
      "[484/1762] D loss: 1.1091, G loss: 0.9823\n",
      "[564/1762] D loss: 1.3749, G loss: 0.5925\n",
      "[644/1762] D loss: 1.3932, G loss: 0.6173\n",
      "[724/1762] D loss: 1.3514, G loss: 0.8072\n",
      "[804/1762] D loss: 1.3966, G loss: 0.7732\n",
      "[884/1762] D loss: 1.3869, G loss: 0.7065\n",
      "[964/1762] D loss: 1.3999, G loss: 0.5963\n",
      "[1044/1762] D loss: 1.3911, G loss: 0.6341\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.6649\n",
      "[1204/1762] D loss: 1.3959, G loss: 0.6032\n",
      "[1284/1762] D loss: 1.3878, G loss: 0.6481\n",
      "[1364/1762] D loss: 1.0752, G loss: 1.0616\n",
      "[1444/1762] D loss: 1.3884, G loss: 0.7347\n",
      "[1524/1762] D loss: 1.0702, G loss: 1.0732\n",
      "[1604/1762] D loss: 1.3936, G loss: 0.7613\n",
      "[1684/1762] D loss: 1.3885, G loss: 0.7250\n",
      "[1762/1762] D loss: 1.3951, G loss: 0.6354\n",
      "train error: \n",
      " D loss: 1.298937, G loss: 0.803476, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.274672, G loss: 0.842951, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3879, G loss: 0.6877\n",
      "[84/1762] D loss: 1.3900, G loss: 0.6815\n",
      "[164/1762] D loss: 1.3876, G loss: 0.7196\n",
      "[244/1762] D loss: 1.3899, G loss: 0.6439\n",
      "[324/1762] D loss: 1.3898, G loss: 0.7104\n",
      "[404/1762] D loss: 1.3866, G loss: 0.6613\n",
      "[484/1762] D loss: 1.3877, G loss: 0.7043\n",
      "[564/1762] D loss: 1.3902, G loss: 0.7197\n",
      "[644/1762] D loss: 1.3884, G loss: 0.6624\n",
      "[724/1762] D loss: 1.0752, G loss: 1.0420\n",
      "[804/1762] D loss: 1.0781, G loss: 1.0534\n",
      "[884/1762] D loss: 1.3868, G loss: 0.7367\n",
      "[964/1762] D loss: 1.3957, G loss: 0.6675\n",
      "[1044/1762] D loss: 1.3967, G loss: 0.7936\n",
      "[1124/1762] D loss: 1.3908, G loss: 0.6722\n",
      "[1204/1762] D loss: 1.3657, G loss: 0.7566\n",
      "[1284/1762] D loss: 1.3876, G loss: 0.7244\n",
      "[1364/1762] D loss: 1.4289, G loss: 0.6787\n",
      "[1444/1762] D loss: 1.3874, G loss: 0.7246\n",
      "[1524/1762] D loss: 1.4042, G loss: 0.7778\n",
      "[1604/1762] D loss: 1.3694, G loss: 0.6746\n",
      "[1684/1762] D loss: 1.4121, G loss: 0.7898\n",
      "[1762/1762] D loss: 1.3870, G loss: 0.7550\n",
      "train error: \n",
      " D loss: 1.298380, G loss: 0.807482, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 86.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.277005, G loss: 0.843038, D accuracy: 55.3%, cell accuracy: 99.7%, board accuracy: 83.4% \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train(run_name=\"freeze_glob_and_zero_activation_50_epochs\", frozen_epochs=50, epochs=150)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even when zeroing out the contributions of the generator `glob` module when frozen, the discriminator still doesn't learn to distinguish block spawns until after the generator `glob` module is unfrozen, as can be seen by the discriminator score histograms. Correspondingly, the generator board accuracy, even after 150 epochs, is no better than the board accuracy without the freezing/unfreezing. The spawn recall behaves the same as before: mostly 0% with occasional jumps to near 100% having low precision. The generator cannot tell when to spawn blocks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Freezing the `glob` module of the generator for a number of epochs does not improve the performance over the whole training process. We won't be pursuing this strategy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
