{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Tetris emulator - GameGAN\n",
    "\n",
    "In this notebook, we train a Tetris emulator model inspired by GameGAN: https://nv-tlabs.github.io/gameGAN/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from models import TetrisModel, TetrisDiscriminator\n",
    "import metrics\n",
    "from recording import FileBasedDatabaseWithEvents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CELL_TYPES = 8\n",
    "NUM_EVENT_TYPES = 5\n",
    "\n",
    "class RecordingDataset(Dataset):\n",
    "    def __init__(self, path: str):\n",
    "        self._db = FileBasedDatabaseWithEvents(path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._db)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        boards, events = self._db[idx]\n",
    "        b = self._transform_board(boards[-2]) # Ignore all boards except the last two\n",
    "        e = self._transform_event(events[-1])\n",
    "        x = (b, e)\n",
    "        y = self._transform_board(boards[-1])\n",
    "        return x, y\n",
    "    \n",
    "    def _transform_board(self, board):\n",
    "        board = torch.tensor(board, dtype=torch.long)\n",
    "        board = F.one_hot(board, NUM_CELL_TYPES) # One-hot encode the cell types\n",
    "        board = board.type(torch.float) # Convert to floating-point\n",
    "        board = board.permute((2, 0, 1)) # Move channels/classes to dimension 0\n",
    "        return board\n",
    "    \n",
    "    def _transform_event(self, event):\n",
    "        event = torch.tensor(event, dtype=torch.long)\n",
    "        event = F.one_hot(event, NUM_EVENT_TYPES) # One-hot encode the event\n",
    "        event = event.type(torch.float) # Convert to floating-point\n",
    "        return event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: shape torch.Size([4, 8, 22, 10]), dtype torch.float32\n",
      "e: shape torch.Size([4, 5]), dtype torch.float32\n",
      "y: shape torch.Size([4, 8, 22, 10]), dtype torch.float32\n"
     ]
    }
   ],
   "source": [
    "train_dataset = RecordingDataset(os.path.join(\"data\", \"tetris_emulator\", \"train\"))\n",
    "test_dataset = RecordingDataset(os.path.join(\"data\", \"tetris_emulator\", \"test\"))\n",
    "batch_size = 4\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "(b, e), y = next(iter(train_dataloader))\n",
    "print(f\"x: shape {b.shape}, dtype {b.dtype}\")\n",
    "print(f\"e: shape {e.shape}, dtype {e.dtype}\")\n",
    "print(f\"y: shape {y.shape}, dtype {y.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metric_by_event(metric_cls, dataloader):\n",
    "    metrics = [metric_cls() for _ in range(NUM_EVENT_TYPES)]\n",
    "\n",
    "    with torch.no_grad():        \n",
    "        for ((b, e), y) in dataloader:\n",
    "            batch_size = b.size(0)\n",
    "\n",
    "            y_fake = gen(b, e)\n",
    "            \n",
    "            classes_b = torch.argmax(b, dim=1)\n",
    "            classes_e = torch.argmax(e, dim=1)\n",
    "            classes_y = torch.argmax(y, dim=1)\n",
    "            classes_y_fake = torch.argmax(y_fake, dim=1)\n",
    "\n",
    "            for idx in range(batch_size):\n",
    "                class_e = classes_e[idx]\n",
    "                metric = metrics[class_e]\n",
    "                metric.update_state(classes_x=classes_b[idx:idx+1], classes_y_pred=classes_y_fake[idx:idx+1], classes_y=classes_y[idx:idx+1])\n",
    "\n",
    "    return [metric.result() for metric in metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "from engines import EventTypes\n",
    "\n",
    "def find_interesting_examples(dataset, num=3):\n",
    "    num_spawns = num\n",
    "    \n",
    "    def inner():\n",
    "        num_spawns_left = num_spawns\n",
    "\n",
    "        for (b, e), y in dataset:\n",
    "            # Check for block spawn\n",
    "            if (e.argmax(0).item() == EventTypes.DROP) & (b.argmax(0)[0] == 0).all() & (y.argmax(0)[0] > 0).any():\n",
    "                if num_spawns_left > 0:\n",
    "                    num_spawns_left -= 1\n",
    "                    yield (b, e), y\n",
    "                else:\n",
    "                    continue\n",
    "            \n",
    "    return list(itertools.islice(inner(), num))\n",
    "from tetris import CELL_COLORS\n",
    "\n",
    "def render_board(board):\n",
    "    height, width = board.shape\n",
    "    img = np.zeros((3, height, width))\n",
    "    for row in range(height):\n",
    "        for col in range(width):\n",
    "            img[:, row, col] = CELL_COLORS[board[row, col]]\n",
    "    img /= 255.0\n",
    "    return img\n",
    "def render_prediction(b, e, pred, y):\n",
    "    \"\"\"Renders an example and prediction into a single-image array.\n",
    "    \n",
    "    Inputs:\n",
    "        b: Tensor of shape (height, width), the initial board state.\n",
    "        e: Tensor of shape (1,), the event type.\n",
    "        pred: Tensor of shape (height, width), the model prediction.\n",
    "        y: Tensor of shape (height, width), the next board state.\n",
    "    \"\"\"\n",
    "    assert len(b.shape) == 2, f\"Expected tensors of shape (width, height) but got {b.shape}\"\n",
    "    assert b.shape == pred.shape, f\"Shapes do not match: {b.shape} != {pred.shape}\"\n",
    "    assert b.shape == y.shape, f\"Shapes do not match: {b.shape} != {y.shape}\"\n",
    "    assert len(e.shape) == 0, f\"Expected e of shape () but got {e.shape}\"\n",
    "    height, width = b.shape\n",
    "    with torch.no_grad():\n",
    "        b = render_board(b)\n",
    "        pred = render_board(pred)\n",
    "        y = render_board(y)\n",
    "        separator = np.ones((3, height, 1))\n",
    "        return np.concatenate((b, separator, pred, separator, y), axis=-1)\n",
    "real_label = 1.0\n",
    "fake_label = 0.0\n",
    "\n",
    "def train_loop(dataloader, gen, disc, loss_fn, optimizer_gen, optimizer_disc):\n",
    "    gen.train()\n",
    "    disc.train()\n",
    "\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, ((b, e), y) in enumerate(dataloader):\n",
    "        ##################################################################\n",
    "        # (1) Update discriminator: minimize -log(D(x)) - log(1 - D(G(z)))\n",
    "        ##################################################################\n",
    "        disc.zero_grad()\n",
    "\n",
    "        ## Train with all-real batch\n",
    "        # Format batch\n",
    "        batch_size = b.size(0)\n",
    "        real_labels = torch.full((batch_size,), real_label, dtype=torch.float)\n",
    "        # Forward pass real batch through discriminator\n",
    "        output = torch.flatten(disc(b, e, y))\n",
    "        # Calculate loss on all-real batch\n",
    "        err_disc_real = loss_fn(output, real_labels)\n",
    "        # Calculate gradients for discriminator in backward pass\n",
    "        err_disc_real.backward()\n",
    "\n",
    "        ## Train with all-fake batch\n",
    "        # Generate fake image batch with generator\n",
    "        y_fake = gen(b, e)\n",
    "        fake_labels = torch.full((batch_size,), fake_label, dtype=torch.float)\n",
    "        # Classify all fake batch with discriminator\n",
    "        output = torch.flatten(disc(b, e, y_fake.detach()))\n",
    "        # Calculate discriminator's loss on the all-fake batch\n",
    "        err_disc_fake = loss_fn(output, fake_labels)\n",
    "        # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
    "        err_disc_fake.backward()\n",
    "\n",
    "        ## Update discriminator weights\n",
    "        # Compute error of discriminator as sum over the fake and the real batches\n",
    "        err_disc = err_disc_real + err_disc_fake\n",
    "        # Update discriminator\n",
    "        optimizer_disc.step()\n",
    "\n",
    "        ##############################################\n",
    "        # (2) Update generator: minimize -log(D(G(z)))\n",
    "        ##############################################\n",
    "        gen.zero_grad()\n",
    "        # Since we just updated the discriminator, perform another forward pass of the all-fake batch through it\n",
    "        output = torch.flatten(disc(b, e, y_fake))\n",
    "        # Calculate the generator's loss based on this output\n",
    "        # We use real labels because the generator wants to fool the discriminator\n",
    "        err_gen = loss_fn(output, real_labels)\n",
    "        # Calculate gradients for generator\n",
    "        err_gen.backward()\n",
    "        # Update generator\n",
    "        optimizer_gen.step()\n",
    "\n",
    "        # Output training stats\n",
    "        if batch % 30 == 0:\n",
    "            current = batch * dataloader.batch_size + batch_size\n",
    "            print(f\"[{current}/{size}] D loss: {err_disc.item():.4f}, G loss: {err_gen.item():.4f}\")\n",
    "\n",
    "\n",
    "def test_loop(split_name, dataloader, gen, disc, loss_fn, tb_writer, epoch, examples):\n",
    "    gen.eval()\n",
    "    disc.eval()\n",
    "\n",
    "    loss_disc = 0.0\n",
    "    loss_gen = 0.0\n",
    "    disc_accuracy = 0.0\n",
    "    cell_accuracy = metrics.CellAccuracy()\n",
    "    board_accuracy = metrics.BoardAccuracy()\n",
    "    board_plausibility = metrics.BoardPlausibility()\n",
    "    spawn_recall = metrics.SpawnRecall()\n",
    "    spawn_precision = metrics.SpawnPrecision()\n",
    "    spawn_validity = metrics.SpawnValidity()\n",
    "    scores_real = np.zeros(len(dataloader.dataset))\n",
    "    scores_fake = np.zeros(len(dataloader.dataset))\n",
    "    spawn_diversity = metrics.SpawnDiversity()\n",
    "\n",
    "    num_batches = len(dataloader)\n",
    "    with torch.no_grad():        \n",
    "        for batch, ((b, e), y) in enumerate(dataloader):\n",
    "            batch_size = b.size(0)\n",
    "            real_labels = torch.full((batch_size,), real_label, dtype=torch.float)\n",
    "            fake_labels = torch.full((batch_size,), fake_label, dtype=torch.float)\n",
    "\n",
    "            output_real = disc(b, e, y)\n",
    "            loss_disc += loss_fn(output_real, real_labels).item()\n",
    "\n",
    "            y_fake = gen(b, e)\n",
    "            output_fake = disc(b, e, y_fake)\n",
    "            \n",
    "            loss_disc += loss_fn(output_fake, fake_labels).item()\n",
    "            loss_gen += loss_fn(output_fake, real_labels).item()\n",
    "\n",
    "            pred_real = (output_real > 0.0)\n",
    "            pred_fake = (output_fake > 0.0)\n",
    "            disc_accuracy += pred_real.type(torch.float).mean().item()\n",
    "            disc_accuracy += (~pred_fake).type(torch.float).mean().item()\n",
    "\n",
    "            classes_b = torch.argmax(b, dim=1)\n",
    "            classes_e = torch.argmax(e, dim=1)\n",
    "            classes_y = torch.argmax(y, dim=1)\n",
    "            classes_y_fake = torch.argmax(y_fake, dim=1)\n",
    "            cell_accuracy.update_state(classes_y_fake, classes_y)\n",
    "            board_accuracy.update_state(classes_y_fake, classes_y)\n",
    "            board_plausibility.update_state(classes_b, classes_y_fake, classes_y)\n",
    "\n",
    "            spawn_recall.update_state(classes_b, classes_y_fake, classes_y)\n",
    "            spawn_precision.update_state(classes_b, classes_y_fake, classes_y)\n",
    "            spawn_validity.update_state(classes_b, classes_y_fake)\n",
    "\n",
    "            start_index = dataloader.batch_size * batch\n",
    "            end_index = start_index + batch_size\n",
    "            scores_real[start_index:end_index] = torch.sigmoid(output_real).numpy()\n",
    "            scores_fake[start_index:end_index] = torch.sigmoid(output_fake).numpy()\n",
    "\n",
    "            spawn_diversity.update_state(classes_b, classes_y_fake)\n",
    "\n",
    "    loss_disc /= num_batches\n",
    "    loss_gen /= num_batches\n",
    "    disc_accuracy /= (2.0 * num_batches)\n",
    "\n",
    "    print(f\"{split_name} error: \\n D loss: {loss_disc:>8f}, G loss: {loss_gen:>8f}, D accuracy: {(100*disc_accuracy):>0.1f}%, cell accuracy: {(cell_accuracy.result()):>0.1%}, board accuracy: {(board_accuracy.result()):>0.1%} \\n\")\n",
    "\n",
    "    tb_writer.add_scalar(f\"Discriminator loss/{split_name}\", loss_disc, epoch)\n",
    "    tb_writer.add_scalar(f\"Loss/{split_name}\", loss_gen, epoch)\n",
    "    tb_writer.add_scalar(f\"Discriminator accuracy/{split_name}\", disc_accuracy, epoch)\n",
    "    tb_writer.add_scalar(f\"Cell accuracy/{split_name}\", cell_accuracy.result(), epoch)\n",
    "    tb_writer.add_scalar(f\"Board accuracy/{split_name}\", board_accuracy.result(), epoch)\n",
    "    tb_writer.add_scalar(f\"Board plausibility/{split_name}\", board_plausibility.result(), epoch)\n",
    "    tb_writer.add_scalar(f\"Spawn recall/{split_name}\", spawn_recall.result(), epoch)\n",
    "    tb_writer.add_scalar(f\"Spawn precision/{split_name}\", spawn_precision.result(), epoch)\n",
    "    tb_writer.add_scalar(f\"Spawn validity/{split_name}\", spawn_validity.result(), epoch)\n",
    "    tb_writer.add_scalar(f\"Spawn diversity/{split_name}\", spawn_diversity.result(), epoch)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, ((b, e), y) in enumerate(examples):\n",
    "            b, e, y = b.unsqueeze(0), e.unsqueeze(0), y.unsqueeze(0)\n",
    "            y_fake = gen(b, e)\n",
    "            b, e, y, y_fake = b.squeeze(0), e.squeeze(0), y.squeeze(0), y_fake.squeeze(0)\n",
    "            b, e, y, y_fake = b.argmax(0), e.argmax(0), y.argmax(0), y_fake.argmax(0)\n",
    "            img = render_prediction(b, e, y_fake, y)\n",
    "            tb_writer.add_image(f\"Predictions/{split_name}/{i}\", img, epoch)\n",
    "    \n",
    "    tb_writer.add_histogram(f\"Discriminator scores/{split_name}/real\", scores_real, epoch)\n",
    "    tb_writer.add_histogram(f\"Discriminator scores/{split_name}/fake\", scores_fake, epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(gen_factory, epochs):\n",
    "\n",
    "    learning_rate = 1e-4\n",
    "\n",
    "    gen = gen_factory()\n",
    "    disc = TetrisDiscriminator()\n",
    "\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer_gen = torch.optim.Adam(gen.parameters(), lr=learning_rate)\n",
    "    optimizer_disc = torch.optim.Adam(disc.parameters(), lr=learning_rate)\n",
    "\n",
    "    log_dir = os.path.join(\"runs\", \"gamegan\")\n",
    "    log_subdir = os.path.join(log_dir, datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"))\n",
    "    tb_writer = SummaryWriter(log_subdir)\n",
    "\n",
    "    train_examples = find_interesting_examples(train_dataset)\n",
    "    test_examples = find_interesting_examples(test_dataset)\n",
    "\n",
    "    try:\n",
    "        for epoch in range(epochs):\n",
    "            print(f\"Epoch {epoch}\\n-------------------------------\")\n",
    "            train_loop(train_dataloader, gen, disc, loss_fn, optimizer_gen, optimizer_disc)\n",
    "            test_loop(\"train\", train_dataloader, gen, disc, loss_fn, tb_writer, epoch, train_examples)\n",
    "            test_loop(\"test\", test_dataloader, gen, disc, loss_fn, tb_writer, epoch, test_examples)\n",
    "            gen_zero_grads = 0\n",
    "            for name, weight in gen.named_parameters():\n",
    "                tb_writer.add_histogram(f\"Weights/{name}\", weight, epoch)\n",
    "                if weight.grad is not None:\n",
    "                    tb_writer.add_histogram(f\"Gradients/{name}\", weight.grad, epoch)\n",
    "                    gen_zero_grads += weight.grad.numel() - weight.grad.count_nonzero().item()\n",
    "            tb_writer.add_scalar(f\"Zero gradients\", gen_zero_grads, epoch)\n",
    "            disc_zero_grads = 0\n",
    "            for name, weight in disc.named_parameters():\n",
    "                tb_writer.add_histogram(f\"Discriminator weights/{name}\", weight, epoch)\n",
    "                if weight.grad is not None:\n",
    "                    tb_writer.add_histogram(f\"Discriminator gradients/{name}\", weight.grad, epoch)\n",
    "                    disc_zero_grads += weight.grad.numel() - weight.grad.count_nonzero().item()\n",
    "            tb_writer.add_scalar(f\"Discriminator zero gradients\", disc_zero_grads, epoch)\n",
    "    finally:\n",
    "        tb_writer.close()\n",
    "        \n",
    "    print(\"Done!\")\n",
    "    return gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: 746536\n",
      "Baseline: 19682\n"
     ]
    }
   ],
   "source": [
    "NUM_RANDOM_INPUTS = 4\n",
    "\n",
    "\n",
    "class Conv2dLeakyReLU(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, use_batch_norm=False, negative_slope=0.0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding, bias=(not use_batch_norm))\n",
    "        nn.init.kaiming_uniform_(self.conv.weight, a=negative_slope)\n",
    "        if not use_batch_norm:\n",
    "            nn.init.constant_(self.conv.bias, 0.01)\n",
    "\n",
    "        if use_batch_norm:\n",
    "            self.norm = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.relu = nn.LeakyReLU(negative_slope)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.use_batch_norm:\n",
    "            x = self.norm(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ConvTranspose2dLeakyReLU(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, output_padding=0, use_batch_norm=False, negative_slope=0.0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "\n",
    "        self.conv = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding, output_padding=output_padding, bias=(not use_batch_norm))\n",
    "        nn.init.kaiming_uniform_(self.conv.weight, a=negative_slope)\n",
    "        if not use_batch_norm:\n",
    "            nn.init.constant_(self.conv.bias, 0.01)\n",
    "\n",
    "        if use_batch_norm:\n",
    "            self.norm = nn.BatchNorm2d(out_channels)\n",
    "            \n",
    "        self.relu = nn.LeakyReLU(negative_slope)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.use_batch_norm:\n",
    "            x = self.norm(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class LinearLeakyReLU(nn.Module):\n",
    "    def __init__(self, in_features, out_features, negative_slope=0.0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "        nn.init.kaiming_uniform_(self.linear.weight, a=negative_slope)\n",
    "        nn.init.constant_(self.linear.bias, 0.01)\n",
    "\n",
    "        self.relu = nn.LeakyReLU(negative_slope)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class AltGenerator(nn.Module):\n",
    "    def __init__(self, use_batch_norm=False, leak=0.0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.use_batch_norm = use_batch_norm\n",
    "        self.leak = leak\n",
    "\n",
    "        self.board_encoder = nn.Sequential(\n",
    "            Conv2dLeakyReLU(NUM_CELL_TYPES, 32, kernel_size=3, padding=1, use_batch_norm=use_batch_norm, negative_slope=leak),\n",
    "            Conv2dLeakyReLU(32, 32, kernel_size=3, use_batch_norm=use_batch_norm, negative_slope=leak),\n",
    "            Conv2dLeakyReLU(32, 32, kernel_size=3, use_batch_norm=use_batch_norm, negative_slope=leak),\n",
    "            Conv2dLeakyReLU(32, 32, kernel_size=3, use_batch_norm=use_batch_norm, negative_slope=leak),\n",
    "            Conv2dLeakyReLU(32, 32, kernel_size=3, use_batch_norm=use_batch_norm, negative_slope=leak),\n",
    "            nn.Flatten(start_dim=1),\n",
    "            LinearLeakyReLU(896, 256, negative_slope=leak)\n",
    "        )\n",
    "\n",
    "        self.event_encoder = nn.Sequential(\n",
    "            LinearLeakyReLU(NUM_EVENT_TYPES + NUM_RANDOM_INPUTS, 32, negative_slope=leak),\n",
    "            LinearLeakyReLU(32, 32, negative_slope=leak),\n",
    "            LinearLeakyReLU(32, 32, negative_slope=leak),\n",
    "        )\n",
    "\n",
    "        self.dynamics = nn.Sequential(\n",
    "            LinearLeakyReLU(256 + 32, 256, negative_slope=leak),\n",
    "            LinearLeakyReLU(256, 256, negative_slope=leak),\n",
    "            LinearLeakyReLU(256, 256, negative_slope=leak),\n",
    "        )\n",
    "\n",
    "        self.renderer = nn.Sequential(\n",
    "            LinearLeakyReLU(256, 896, negative_slope=leak),\n",
    "            nn.Unflatten(dim=1, unflattened_size=(32, 14, 2)),\n",
    "            ConvTranspose2dLeakyReLU(32, 32, kernel_size=3, use_batch_norm=use_batch_norm, negative_slope=leak),\n",
    "            ConvTranspose2dLeakyReLU(32, 32, kernel_size=3, use_batch_norm=use_batch_norm, negative_slope=leak),\n",
    "            ConvTranspose2dLeakyReLU(32, 32, kernel_size=3, use_batch_norm=use_batch_norm, negative_slope=leak),\n",
    "            ConvTranspose2dLeakyReLU(32, 32, kernel_size=3, use_batch_norm=use_batch_norm, negative_slope=leak),\n",
    "            nn.ConvTranspose2d(32, NUM_CELL_TYPES, kernel_size=3, padding=1),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, b, e):\n",
    "        batch_size, cell_channels, height, width = b.shape\n",
    "\n",
    "        # Encode board state\n",
    "        s = self.board_encoder(b)\n",
    "\n",
    "        # Generate random inputs\n",
    "        z = torch.rand(batch_size, NUM_RANDOM_INPUTS)\n",
    "\n",
    "        # Encode events and random inputs\n",
    "        v = self.event_encoder(torch.cat((e, z), dim=1))\n",
    "\n",
    "        # Combine encodings\n",
    "        h = torch.cat((s, v), dim=1)\n",
    "\n",
    "        # Apply game dynamics\n",
    "        h = self.dynamics(h)\n",
    "\n",
    "        # Render new board\n",
    "        y = self.renderer(h)\n",
    "        return y\n",
    "\n",
    "\n",
    "print(f\"Parameters: {count_parameters(AltGenerator())}\")\n",
    "print(f\"Baseline: {count_parameters(TetrisModel())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4004, G loss: 0.8585\n",
      "[124/1600] D loss: 1.4034, G loss: 0.7698\n",
      "[244/1600] D loss: 1.3878, G loss: 0.8332\n",
      "[364/1600] D loss: 1.3410, G loss: 0.8705\n",
      "[484/1600] D loss: 1.1656, G loss: 1.0001\n",
      "[604/1600] D loss: 1.0309, G loss: 1.0559\n",
      "[724/1600] D loss: 1.0428, G loss: 0.9403\n",
      "[844/1600] D loss: 1.7486, G loss: 0.6002\n",
      "[964/1600] D loss: 1.5081, G loss: 0.6287\n",
      "[1084/1600] D loss: 1.4798, G loss: 0.6373\n",
      "[1204/1600] D loss: 1.3405, G loss: 0.7434\n",
      "[1324/1600] D loss: 1.4173, G loss: 0.6658\n",
      "[1444/1600] D loss: 1.3309, G loss: 0.6992\n",
      "[1564/1600] D loss: 1.4150, G loss: 0.7029\n",
      "train error: \n",
      " D loss: 1.339561, G loss: 0.686439, D accuracy: 55.6%, cell accuracy: 75.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.334270, G loss: 0.689536, D accuracy: 56.2%, cell accuracy: 75.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3317, G loss: 0.6390\n",
      "[124/1600] D loss: 1.3164, G loss: 0.7344\n",
      "[244/1600] D loss: 1.2917, G loss: 0.6827\n",
      "[364/1600] D loss: 1.3133, G loss: 0.6960\n",
      "[484/1600] D loss: 1.3437, G loss: 0.6971\n",
      "[604/1600] D loss: 1.3718, G loss: 0.6972\n",
      "[724/1600] D loss: 1.3232, G loss: 0.7421\n",
      "[844/1600] D loss: 1.2979, G loss: 0.6577\n",
      "[964/1600] D loss: 1.3331, G loss: 0.7350\n",
      "[1084/1600] D loss: 1.3151, G loss: 0.7845\n",
      "[1204/1600] D loss: 1.3123, G loss: 0.7577\n",
      "[1324/1600] D loss: 1.2068, G loss: 0.7043\n",
      "[1444/1600] D loss: 1.2232, G loss: 0.7207\n",
      "[1564/1600] D loss: 1.3047, G loss: 0.7642\n",
      "train error: \n",
      " D loss: 1.218964, G loss: 0.752977, D accuracy: 75.7%, cell accuracy: 77.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.217006, G loss: 0.754625, D accuracy: 73.9%, cell accuracy: 77.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2360, G loss: 0.7863\n",
      "[124/1600] D loss: 1.1532, G loss: 0.7600\n",
      "[244/1600] D loss: 1.2386, G loss: 0.8607\n",
      "[364/1600] D loss: 0.8562, G loss: 1.0786\n",
      "[484/1600] D loss: 1.0246, G loss: 0.8564\n",
      "[604/1600] D loss: 0.9550, G loss: 0.9020\n",
      "[724/1600] D loss: 0.9476, G loss: 1.0279\n",
      "[844/1600] D loss: 0.7838, G loss: 1.2678\n",
      "[964/1600] D loss: 0.9105, G loss: 0.9124\n",
      "[1084/1600] D loss: 0.5137, G loss: 1.6011\n",
      "[1204/1600] D loss: 0.8631, G loss: 1.4145\n",
      "[1324/1600] D loss: 1.1000, G loss: 1.0320\n",
      "[1444/1600] D loss: 0.6334, G loss: 1.0829\n",
      "[1564/1600] D loss: 0.5412, G loss: 1.6516\n",
      "train error: \n",
      " D loss: 0.658787, G loss: 1.452882, D accuracy: 95.0%, cell accuracy: 80.6%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.664900, G loss: 1.501509, D accuracy: 94.6%, cell accuracy: 80.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5734, G loss: 1.9295\n",
      "[124/1600] D loss: 0.8925, G loss: 1.1573\n",
      "[244/1600] D loss: 0.8590, G loss: 1.9002\n",
      "[364/1600] D loss: 0.6241, G loss: 1.2983\n",
      "[484/1600] D loss: 0.6045, G loss: 1.6875\n",
      "[604/1600] D loss: 0.5296, G loss: 1.5093\n",
      "[724/1600] D loss: 1.0840, G loss: 1.8663\n",
      "[844/1600] D loss: 0.5759, G loss: 1.6331\n",
      "[964/1600] D loss: 0.4532, G loss: 1.7974\n",
      "[1084/1600] D loss: 0.5600, G loss: 2.2412\n",
      "[1204/1600] D loss: 0.1996, G loss: 2.9854\n",
      "[1324/1600] D loss: 0.4096, G loss: 1.7868\n",
      "[1444/1600] D loss: 0.3250, G loss: 1.8888\n",
      "[1564/1600] D loss: 0.3408, G loss: 3.0245\n",
      "train error: \n",
      " D loss: 0.434121, G loss: 2.240736, D accuracy: 96.0%, cell accuracy: 82.4%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.463193, G loss: 2.354342, D accuracy: 95.5%, cell accuracy: 82.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6027, G loss: 1.6646\n",
      "[124/1600] D loss: 0.3757, G loss: 1.7767\n",
      "[244/1600] D loss: 0.2441, G loss: 2.1719\n",
      "[364/1600] D loss: 0.3814, G loss: 2.9642\n",
      "[484/1600] D loss: 0.2173, G loss: 2.9791\n",
      "[604/1600] D loss: 0.1879, G loss: 4.1409\n",
      "[724/1600] D loss: 0.6756, G loss: 1.3174\n",
      "[844/1600] D loss: 0.2983, G loss: 2.2745\n",
      "[964/1600] D loss: 0.4211, G loss: 2.6885\n",
      "[1084/1600] D loss: 0.3843, G loss: 2.1148\n",
      "[1204/1600] D loss: 0.4492, G loss: 2.4136\n",
      "[1324/1600] D loss: 0.2956, G loss: 2.2422\n",
      "[1444/1600] D loss: 0.7082, G loss: 0.9760\n",
      "[1564/1600] D loss: 0.1959, G loss: 3.4125\n",
      "train error: \n",
      " D loss: 0.407237, G loss: 2.306277, D accuracy: 95.0%, cell accuracy: 85.8%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.441274, G loss: 2.402888, D accuracy: 95.2%, cell accuracy: 85.5%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.0989, G loss: 3.6186\n",
      "[124/1600] D loss: 0.1663, G loss: 3.1690\n",
      "[244/1600] D loss: 0.2515, G loss: 3.5573\n",
      "[364/1600] D loss: 0.1482, G loss: 2.6920\n",
      "[484/1600] D loss: 0.1988, G loss: 3.0707\n",
      "[604/1600] D loss: 0.1877, G loss: 2.6408\n",
      "[724/1600] D loss: 0.1184, G loss: 3.5248\n",
      "[844/1600] D loss: 0.2659, G loss: 3.5306\n",
      "[964/1600] D loss: 0.7837, G loss: 2.3628\n",
      "[1084/1600] D loss: 0.4128, G loss: 2.9516\n",
      "[1204/1600] D loss: 0.2110, G loss: 4.1976\n",
      "[1324/1600] D loss: 0.1524, G loss: 3.3380\n",
      "[1444/1600] D loss: 0.0478, G loss: 3.8506\n",
      "[1564/1600] D loss: 0.2326, G loss: 3.1532\n",
      "train error: \n",
      " D loss: 0.375817, G loss: 3.123920, D accuracy: 95.7%, cell accuracy: 86.8%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.454331, G loss: 3.213015, D accuracy: 95.2%, cell accuracy: 86.5%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.2358, G loss: 3.2153\n",
      "[124/1600] D loss: 0.1332, G loss: 3.3225\n",
      "[244/1600] D loss: 0.3258, G loss: 1.9130\n",
      "[364/1600] D loss: 0.2420, G loss: 2.9380\n",
      "[484/1600] D loss: 0.4487, G loss: 1.8593\n",
      "[604/1600] D loss: 0.1039, G loss: 2.9693\n",
      "[724/1600] D loss: 0.2239, G loss: 3.5720\n",
      "[844/1600] D loss: 0.3162, G loss: 2.2180\n",
      "[964/1600] D loss: 0.3025, G loss: 1.9527\n",
      "[1084/1600] D loss: 0.1479, G loss: 4.4334\n",
      "[1204/1600] D loss: 0.4316, G loss: 1.7953\n",
      "[1324/1600] D loss: 0.1895, G loss: 3.6882\n",
      "[1444/1600] D loss: 0.1963, G loss: 2.7173\n",
      "[1564/1600] D loss: 0.2575, G loss: 2.7318\n",
      "train error: \n",
      " D loss: 0.377543, G loss: 2.576642, D accuracy: 94.3%, cell accuracy: 85.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.455316, G loss: 2.681211, D accuracy: 94.2%, cell accuracy: 85.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2834, G loss: 2.8939\n",
      "[124/1600] D loss: 0.1575, G loss: 2.8586\n",
      "[244/1600] D loss: 0.6206, G loss: 1.5238\n",
      "[364/1600] D loss: 0.3680, G loss: 2.3524\n",
      "[484/1600] D loss: 0.3058, G loss: 3.8151\n",
      "[604/1600] D loss: 0.3578, G loss: 2.0212\n",
      "[724/1600] D loss: 0.4192, G loss: 2.9194\n",
      "[844/1600] D loss: 0.1796, G loss: 3.5369\n",
      "[964/1600] D loss: 0.1761, G loss: 2.7621\n",
      "[1084/1600] D loss: 0.3238, G loss: 4.0052\n",
      "[1204/1600] D loss: 0.0865, G loss: 3.5511\n",
      "[1324/1600] D loss: 0.3721, G loss: 3.3495\n",
      "[1444/1600] D loss: 0.5752, G loss: 2.8393\n",
      "[1564/1600] D loss: 0.1621, G loss: 3.8721\n",
      "train error: \n",
      " D loss: 0.331765, G loss: 2.653139, D accuracy: 95.8%, cell accuracy: 87.4%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.418735, G loss: 2.816889, D accuracy: 95.2%, cell accuracy: 87.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.1477, G loss: 2.4040\n",
      "[124/1600] D loss: 0.1314, G loss: 3.6503\n",
      "[244/1600] D loss: 0.2029, G loss: 2.1374\n",
      "[364/1600] D loss: 0.2898, G loss: 4.1028\n",
      "[484/1600] D loss: 0.1324, G loss: 3.4247\n",
      "[604/1600] D loss: 0.0634, G loss: 4.2146\n",
      "[724/1600] D loss: 0.1737, G loss: 4.1839\n",
      "[844/1600] D loss: 0.2465, G loss: 1.9776\n",
      "[964/1600] D loss: 0.1108, G loss: 4.0741\n",
      "[1084/1600] D loss: 0.1354, G loss: 3.3310\n",
      "[1204/1600] D loss: 0.1371, G loss: 2.8258\n",
      "[1324/1600] D loss: 0.2118, G loss: 3.3595\n",
      "[1444/1600] D loss: 0.1315, G loss: 3.2984\n",
      "[1564/1600] D loss: 0.4838, G loss: 2.1213\n",
      "train error: \n",
      " D loss: 0.273872, G loss: 3.661590, D accuracy: 96.7%, cell accuracy: 85.8%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.372048, G loss: 3.809074, D accuracy: 95.2%, cell accuracy: 85.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.1325, G loss: 3.5133\n",
      "[124/1600] D loss: 0.2435, G loss: 3.0407\n",
      "[244/1600] D loss: 0.4527, G loss: 3.9244\n",
      "[364/1600] D loss: 0.0702, G loss: 3.4356\n",
      "[484/1600] D loss: 0.4546, G loss: 3.6216\n",
      "[604/1600] D loss: 0.1493, G loss: 2.6158\n",
      "[724/1600] D loss: 0.1511, G loss: 4.0608\n",
      "[844/1600] D loss: 0.1314, G loss: 3.9724\n",
      "[964/1600] D loss: 0.3438, G loss: 1.5790\n",
      "[1084/1600] D loss: 0.2770, G loss: 4.2558\n",
      "[1204/1600] D loss: 0.0434, G loss: 4.5383\n",
      "[1324/1600] D loss: 0.6342, G loss: 4.6348\n",
      "[1444/1600] D loss: 0.2015, G loss: 2.7684\n",
      "[1564/1600] D loss: 0.1824, G loss: 3.2360\n",
      "train error: \n",
      " D loss: 0.226323, G loss: 3.055253, D accuracy: 97.7%, cell accuracy: 87.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.311927, G loss: 3.223959, D accuracy: 96.5%, cell accuracy: 86.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4103, G loss: 3.6412\n",
      "[124/1600] D loss: 0.1422, G loss: 4.7721\n",
      "[244/1600] D loss: 0.0884, G loss: 4.9976\n",
      "[364/1600] D loss: 0.1754, G loss: 4.3745\n",
      "[484/1600] D loss: 0.2302, G loss: 3.5196\n",
      "[604/1600] D loss: 0.3356, G loss: 4.2586\n",
      "[724/1600] D loss: 0.1866, G loss: 4.2296\n",
      "[844/1600] D loss: 0.2849, G loss: 2.4359\n",
      "[964/1600] D loss: 0.2154, G loss: 2.3327\n",
      "[1084/1600] D loss: 0.0886, G loss: 3.1243\n",
      "[1204/1600] D loss: 0.3179, G loss: 3.3698\n",
      "[1324/1600] D loss: 0.3283, G loss: 2.2577\n",
      "[1444/1600] D loss: 0.1869, G loss: 3.9173\n",
      "[1564/1600] D loss: 0.2079, G loss: 2.4104\n",
      "train error: \n",
      " D loss: 0.285038, G loss: 2.961734, D accuracy: 96.9%, cell accuracy: 88.2%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.367524, G loss: 3.085376, D accuracy: 95.9%, cell accuracy: 87.8%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.2521, G loss: 2.2190\n",
      "[124/1600] D loss: 0.1952, G loss: 2.6529\n",
      "[244/1600] D loss: 0.0474, G loss: 4.0880\n",
      "[364/1600] D loss: 0.2568, G loss: 3.0846\n",
      "[484/1600] D loss: 0.1438, G loss: 3.1879\n",
      "[604/1600] D loss: 0.0831, G loss: 3.3747\n",
      "[724/1600] D loss: 0.1713, G loss: 2.8186\n",
      "[844/1600] D loss: 0.0849, G loss: 3.7517\n",
      "[964/1600] D loss: 0.3407, G loss: 3.6132\n",
      "[1084/1600] D loss: 0.1434, G loss: 2.5184\n",
      "[1204/1600] D loss: 0.1362, G loss: 3.1013\n",
      "[1324/1600] D loss: 0.1786, G loss: 2.5538\n",
      "[1444/1600] D loss: 0.1719, G loss: 2.9812\n",
      "[1564/1600] D loss: 0.4435, G loss: 3.5950\n",
      "train error: \n",
      " D loss: 0.324771, G loss: 2.855733, D accuracy: 96.5%, cell accuracy: 90.3%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.397303, G loss: 2.970029, D accuracy: 95.9%, cell accuracy: 90.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4303, G loss: 2.1050\n",
      "[124/1600] D loss: 0.2537, G loss: 3.0654\n",
      "[244/1600] D loss: 0.2193, G loss: 2.1234\n",
      "[364/1600] D loss: 0.1155, G loss: 2.6356\n",
      "[484/1600] D loss: 0.1742, G loss: 2.2056\n",
      "[604/1600] D loss: 0.3521, G loss: 2.7792\n",
      "[724/1600] D loss: 0.2034, G loss: 3.2237\n",
      "[844/1600] D loss: 0.4794, G loss: 1.9569\n",
      "[964/1600] D loss: 0.0391, G loss: 5.0248\n",
      "[1084/1600] D loss: 0.1874, G loss: 3.7598\n",
      "[1204/1600] D loss: 0.2502, G loss: 2.4724\n",
      "[1324/1600] D loss: 0.1369, G loss: 3.7625\n",
      "[1444/1600] D loss: 0.4116, G loss: 2.6587\n",
      "[1564/1600] D loss: 0.1365, G loss: 3.3968\n",
      "train error: \n",
      " D loss: 0.282138, G loss: 3.152659, D accuracy: 97.1%, cell accuracy: 90.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.360335, G loss: 3.248277, D accuracy: 96.1%, cell accuracy: 90.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.1108, G loss: 3.0673\n",
      "[124/1600] D loss: 0.2446, G loss: 3.1140\n",
      "[244/1600] D loss: 0.4555, G loss: 1.7202\n",
      "[364/1600] D loss: 0.2422, G loss: 1.9772\n",
      "[484/1600] D loss: 0.4184, G loss: 3.5844\n",
      "[604/1600] D loss: 0.2942, G loss: 3.9408\n",
      "[724/1600] D loss: 0.5108, G loss: 3.9610\n",
      "[844/1600] D loss: 0.2816, G loss: 2.5886\n",
      "[964/1600] D loss: 0.3663, G loss: 2.1954\n",
      "[1084/1600] D loss: 0.3437, G loss: 2.6981\n",
      "[1204/1600] D loss: 0.2416, G loss: 1.9594\n",
      "[1324/1600] D loss: 0.2845, G loss: 3.4375\n",
      "[1444/1600] D loss: 0.4956, G loss: 1.7142\n",
      "[1564/1600] D loss: 0.7418, G loss: 1.8863\n",
      "train error: \n",
      " D loss: 0.364272, G loss: 3.124408, D accuracy: 96.8%, cell accuracy: 92.2%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.437399, G loss: 3.206386, D accuracy: 95.8%, cell accuracy: 91.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4172, G loss: 2.6995\n",
      "[124/1600] D loss: 1.0895, G loss: 2.5745\n",
      "[244/1600] D loss: 0.1741, G loss: 2.4835\n",
      "[364/1600] D loss: 0.1729, G loss: 3.7322\n",
      "[484/1600] D loss: 0.4168, G loss: 1.6708\n",
      "[604/1600] D loss: 0.0491, G loss: 4.1898\n",
      "[724/1600] D loss: 0.2546, G loss: 1.7379\n",
      "[844/1600] D loss: 0.0955, G loss: 3.7051\n",
      "[964/1600] D loss: 0.1309, G loss: 3.3119\n",
      "[1084/1600] D loss: 0.8753, G loss: 1.2265\n",
      "[1204/1600] D loss: 0.3748, G loss: 3.0818\n",
      "[1324/1600] D loss: 0.2368, G loss: 2.2511\n",
      "[1444/1600] D loss: 0.2497, G loss: 2.1543\n",
      "[1564/1600] D loss: 0.4817, G loss: 2.3816\n",
      "train error: \n",
      " D loss: 0.425780, G loss: 2.244245, D accuracy: 94.1%, cell accuracy: 90.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.490225, G loss: 2.314796, D accuracy: 94.0%, cell accuracy: 90.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5882, G loss: 1.5173\n",
      "[124/1600] D loss: 0.2307, G loss: 2.9717\n",
      "[244/1600] D loss: 0.3344, G loss: 2.1273\n",
      "[364/1600] D loss: 0.2497, G loss: 2.9705\n",
      "[484/1600] D loss: 0.2923, G loss: 2.5175\n",
      "[604/1600] D loss: 0.9718, G loss: 1.4105\n",
      "[724/1600] D loss: 0.7457, G loss: 1.8738\n",
      "[844/1600] D loss: 1.9034, G loss: 1.9191\n",
      "[964/1600] D loss: 1.0844, G loss: 2.2810\n",
      "[1084/1600] D loss: 0.4593, G loss: 2.8113\n",
      "[1204/1600] D loss: 0.2121, G loss: 2.9769\n",
      "[1324/1600] D loss: 0.7403, G loss: 2.4178\n",
      "[1444/1600] D loss: 1.0208, G loss: 1.5724\n",
      "[1564/1600] D loss: 1.0891, G loss: 0.9227\n",
      "train error: \n",
      " D loss: 0.602580, G loss: 2.462752, D accuracy: 88.9%, cell accuracy: 92.7%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.643568, G loss: 2.580147, D accuracy: 89.5%, cell accuracy: 92.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7364, G loss: 1.3018\n",
      "[124/1600] D loss: 0.7118, G loss: 2.6919\n",
      "[244/1600] D loss: 0.6590, G loss: 2.7080\n",
      "[364/1600] D loss: 0.5105, G loss: 2.4635\n",
      "[484/1600] D loss: 0.1688, G loss: 2.5038\n",
      "[604/1600] D loss: 0.5682, G loss: 2.5868\n",
      "[724/1600] D loss: 0.6998, G loss: 2.3173\n",
      "[844/1600] D loss: 0.2129, G loss: 2.8087\n",
      "[964/1600] D loss: 0.2795, G loss: 2.2248\n",
      "[1084/1600] D loss: 1.5496, G loss: 3.4496\n",
      "[1204/1600] D loss: 0.7902, G loss: 2.3428\n",
      "[1324/1600] D loss: 0.3575, G loss: 2.0446\n",
      "[1444/1600] D loss: 0.4039, G loss: 2.7403\n",
      "[1564/1600] D loss: 1.6592, G loss: 2.2036\n",
      "train error: \n",
      " D loss: 0.623559, G loss: 2.602068, D accuracy: 88.6%, cell accuracy: 90.6%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.653439, G loss: 2.699455, D accuracy: 89.1%, cell accuracy: 90.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.2968, G loss: 2.5516\n",
      "[124/1600] D loss: 0.7492, G loss: 1.5199\n",
      "[244/1600] D loss: 0.6583, G loss: 2.4981\n",
      "[364/1600] D loss: 0.9103, G loss: 2.2046\n",
      "[484/1600] D loss: 0.8472, G loss: 2.2052\n",
      "[604/1600] D loss: 0.4792, G loss: 1.7503\n",
      "[724/1600] D loss: 0.4076, G loss: 2.3180\n",
      "[844/1600] D loss: 1.0540, G loss: 3.0103\n",
      "[964/1600] D loss: 0.6033, G loss: 2.2874\n",
      "[1084/1600] D loss: 0.5718, G loss: 1.5494\n",
      "[1204/1600] D loss: 0.3454, G loss: 2.7341\n",
      "[1324/1600] D loss: 0.2418, G loss: 1.8582\n",
      "[1444/1600] D loss: 0.5436, G loss: 1.8005\n",
      "[1564/1600] D loss: 1.4904, G loss: 2.3670\n",
      "train error: \n",
      " D loss: 0.648284, G loss: 2.543141, D accuracy: 85.8%, cell accuracy: 90.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.675069, G loss: 2.662373, D accuracy: 86.9%, cell accuracy: 90.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4665, G loss: 2.2926\n",
      "[124/1600] D loss: 0.3158, G loss: 3.3072\n",
      "[244/1600] D loss: 0.2627, G loss: 3.2381\n",
      "[364/1600] D loss: 0.1984, G loss: 2.3895\n",
      "[484/1600] D loss: 0.0854, G loss: 4.3882\n",
      "[604/1600] D loss: 0.4916, G loss: 2.7822\n",
      "[724/1600] D loss: 0.9697, G loss: 1.5358\n",
      "[844/1600] D loss: 0.5014, G loss: 2.2517\n",
      "[964/1600] D loss: 0.3037, G loss: 3.2035\n",
      "[1084/1600] D loss: 0.9455, G loss: 1.1772\n",
      "[1204/1600] D loss: 0.1412, G loss: 3.0921\n",
      "[1324/1600] D loss: 0.5839, G loss: 2.4484\n",
      "[1444/1600] D loss: 0.4344, G loss: 2.8050\n",
      "[1564/1600] D loss: 1.0654, G loss: 1.5395\n",
      "train error: \n",
      " D loss: 0.610973, G loss: 2.287245, D accuracy: 86.8%, cell accuracy: 90.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.620392, G loss: 2.387928, D accuracy: 87.1%, cell accuracy: 90.8%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7128, G loss: 2.3142\n",
      "[124/1600] D loss: 0.6973, G loss: 2.1063\n",
      "[244/1600] D loss: 0.3520, G loss: 2.5563\n",
      "[364/1600] D loss: 0.3257, G loss: 2.4479\n",
      "[484/1600] D loss: 0.2394, G loss: 2.5423\n",
      "[604/1600] D loss: 0.4401, G loss: 2.8045\n",
      "[724/1600] D loss: 0.1762, G loss: 3.2911\n",
      "[844/1600] D loss: 0.9082, G loss: 1.2414\n",
      "[964/1600] D loss: 1.6678, G loss: 1.8255\n",
      "[1084/1600] D loss: 0.7498, G loss: 1.1077\n",
      "[1204/1600] D loss: 1.4035, G loss: 1.7992\n",
      "[1324/1600] D loss: 0.6756, G loss: 1.5690\n",
      "[1444/1600] D loss: 0.5170, G loss: 1.1810\n",
      "[1564/1600] D loss: 0.2665, G loss: 2.4960\n",
      "train error: \n",
      " D loss: 0.706867, G loss: 3.016662, D accuracy: 82.7%, cell accuracy: 93.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.713891, G loss: 3.137764, D accuracy: 83.5%, cell accuracy: 92.8%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8424, G loss: 1.9963\n",
      "[124/1600] D loss: 0.9578, G loss: 3.4033\n",
      "[244/1600] D loss: 0.3237, G loss: 2.8047\n",
      "[364/1600] D loss: 0.5128, G loss: 2.8911\n",
      "[484/1600] D loss: 0.1146, G loss: 2.7023\n",
      "[604/1600] D loss: 0.4043, G loss: 2.3087\n",
      "[724/1600] D loss: 0.7053, G loss: 2.3859\n",
      "[844/1600] D loss: 0.0804, G loss: 3.3593\n",
      "[964/1600] D loss: 0.6921, G loss: 1.6023\n",
      "[1084/1600] D loss: 1.1226, G loss: 4.1804\n",
      "[1204/1600] D loss: 0.1228, G loss: 3.2316\n",
      "[1324/1600] D loss: 0.5020, G loss: 1.7957\n",
      "[1444/1600] D loss: 0.8367, G loss: 0.8647\n",
      "[1564/1600] D loss: 0.4584, G loss: 1.5430\n",
      "train error: \n",
      " D loss: 0.652293, G loss: 1.929025, D accuracy: 86.5%, cell accuracy: 91.6%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.666856, G loss: 2.053272, D accuracy: 85.1%, cell accuracy: 91.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0369, G loss: 1.7170\n",
      "[124/1600] D loss: 0.6650, G loss: 1.5253\n",
      "[244/1600] D loss: 1.0425, G loss: 1.5686\n",
      "[364/1600] D loss: 0.2807, G loss: 2.4048\n",
      "[484/1600] D loss: 0.1324, G loss: 2.9475\n",
      "[604/1600] D loss: 0.9027, G loss: 0.9514\n",
      "[724/1600] D loss: 0.5311, G loss: 2.0855\n",
      "[844/1600] D loss: 1.6907, G loss: 1.1278\n",
      "[964/1600] D loss: 1.1517, G loss: 1.1610\n",
      "[1084/1600] D loss: 0.3946, G loss: 3.1476\n",
      "[1204/1600] D loss: 0.3775, G loss: 2.7385\n",
      "[1324/1600] D loss: 0.1394, G loss: 3.3697\n",
      "[1444/1600] D loss: 1.1330, G loss: 1.8052\n",
      "[1564/1600] D loss: 0.3466, G loss: 3.3751\n",
      "train error: \n",
      " D loss: 0.632357, G loss: 2.172830, D accuracy: 86.5%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.644190, G loss: 2.267234, D accuracy: 87.6%, cell accuracy: 91.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6412, G loss: 1.6288\n",
      "[124/1600] D loss: 0.7095, G loss: 2.4406\n",
      "[244/1600] D loss: 0.4940, G loss: 4.4447\n",
      "[364/1600] D loss: 0.1658, G loss: 2.5617\n",
      "[484/1600] D loss: 0.2904, G loss: 2.7493\n",
      "[604/1600] D loss: 1.1296, G loss: 2.4068\n",
      "[724/1600] D loss: 0.0486, G loss: 4.0876\n",
      "[844/1600] D loss: 0.8238, G loss: 3.0901\n",
      "[964/1600] D loss: 0.1260, G loss: 2.6499\n",
      "[1084/1600] D loss: 0.2209, G loss: 2.4832\n",
      "[1204/1600] D loss: 0.1950, G loss: 2.5396\n",
      "[1324/1600] D loss: 0.6718, G loss: 1.7120\n",
      "[1444/1600] D loss: 0.4390, G loss: 1.7277\n",
      "[1564/1600] D loss: 0.4034, G loss: 2.7554\n",
      "train error: \n",
      " D loss: 0.584833, G loss: 2.101850, D accuracy: 88.5%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.594676, G loss: 2.233373, D accuracy: 89.4%, cell accuracy: 91.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.3684, G loss: 2.2884\n",
      "[124/1600] D loss: 0.6011, G loss: 1.7410\n",
      "[244/1600] D loss: 0.5349, G loss: 1.7215\n",
      "[364/1600] D loss: 1.0697, G loss: 3.1470\n",
      "[484/1600] D loss: 0.6952, G loss: 1.9635\n",
      "[604/1600] D loss: 0.4660, G loss: 2.5343\n",
      "[724/1600] D loss: 0.8526, G loss: 1.7515\n",
      "[844/1600] D loss: 0.3833, G loss: 3.3072\n",
      "[964/1600] D loss: 0.2424, G loss: 3.4808\n",
      "[1084/1600] D loss: 0.4375, G loss: 2.0605\n",
      "[1204/1600] D loss: 0.5404, G loss: 1.4420\n",
      "[1324/1600] D loss: 0.6457, G loss: 1.8749\n",
      "[1444/1600] D loss: 0.7625, G loss: 0.9334\n",
      "[1564/1600] D loss: 0.7506, G loss: 1.7404\n",
      "train error: \n",
      " D loss: 0.570884, G loss: 2.298087, D accuracy: 89.0%, cell accuracy: 92.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.584677, G loss: 2.411296, D accuracy: 90.1%, cell accuracy: 92.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4921, G loss: 2.2227\n",
      "[124/1600] D loss: 0.8993, G loss: 1.7304\n",
      "[244/1600] D loss: 0.0678, G loss: 3.7031\n",
      "[364/1600] D loss: 0.6048, G loss: 2.6325\n",
      "[484/1600] D loss: 0.4519, G loss: 1.9891\n",
      "[604/1600] D loss: 0.0800, G loss: 2.6971\n",
      "[724/1600] D loss: 0.2025, G loss: 3.3484\n",
      "[844/1600] D loss: 1.0401, G loss: 1.7415\n",
      "[964/1600] D loss: 1.4569, G loss: 2.0442\n",
      "[1084/1600] D loss: 0.5108, G loss: 1.5101\n",
      "[1204/1600] D loss: 0.0730, G loss: 3.4272\n",
      "[1324/1600] D loss: 0.1222, G loss: 2.4423\n",
      "[1444/1600] D loss: 0.0565, G loss: 3.9220\n",
      "[1564/1600] D loss: 0.5085, G loss: 2.2875\n",
      "train error: \n",
      " D loss: 0.584485, G loss: 2.244086, D accuracy: 88.0%, cell accuracy: 91.6%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.608335, G loss: 2.351929, D accuracy: 87.8%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7632, G loss: 1.5589\n",
      "[124/1600] D loss: 0.4323, G loss: 2.4822\n",
      "[244/1600] D loss: 0.5965, G loss: 1.3908\n",
      "[364/1600] D loss: 0.4769, G loss: 2.4166\n",
      "[484/1600] D loss: 0.4087, G loss: 3.1665\n",
      "[604/1600] D loss: 0.1461, G loss: 3.8234\n",
      "[724/1600] D loss: 0.4366, G loss: 1.7468\n",
      "[844/1600] D loss: 0.7640, G loss: 1.6542\n",
      "[964/1600] D loss: 0.7070, G loss: 2.1591\n",
      "[1084/1600] D loss: 1.1901, G loss: 2.7263\n",
      "[1204/1600] D loss: 0.2747, G loss: 2.8642\n",
      "[1324/1600] D loss: 0.4927, G loss: 2.4057\n",
      "[1444/1600] D loss: 0.2046, G loss: 2.1028\n",
      "[1564/1600] D loss: 1.0278, G loss: 2.5635\n",
      "train error: \n",
      " D loss: 0.679352, G loss: 1.895129, D accuracy: 84.4%, cell accuracy: 90.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.689963, G loss: 2.005401, D accuracy: 86.0%, cell accuracy: 90.5%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8786, G loss: 1.4518\n",
      "[124/1600] D loss: 0.4984, G loss: 1.6313\n",
      "[244/1600] D loss: 0.5014, G loss: 2.1371\n",
      "[364/1600] D loss: 0.9569, G loss: 1.6833\n",
      "[484/1600] D loss: 0.1043, G loss: 3.1553\n",
      "[604/1600] D loss: 0.8236, G loss: 1.3969\n",
      "[724/1600] D loss: 0.7511, G loss: 2.4199\n",
      "[844/1600] D loss: 0.6190, G loss: 2.1018\n",
      "[964/1600] D loss: 1.6362, G loss: 1.2744\n",
      "[1084/1600] D loss: 0.6378, G loss: 2.7451\n",
      "[1204/1600] D loss: 0.3073, G loss: 1.8828\n",
      "[1324/1600] D loss: 0.6115, G loss: 2.9214\n",
      "[1444/1600] D loss: 0.8713, G loss: 1.7459\n",
      "[1564/1600] D loss: 0.3077, G loss: 2.2075\n",
      "train error: \n",
      " D loss: 0.581672, G loss: 2.169838, D accuracy: 87.8%, cell accuracy: 92.8%, board accuracy: 0.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.600699, G loss: 2.290569, D accuracy: 86.9%, cell accuracy: 92.6%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.1310, G loss: 3.0598\n",
      "[124/1600] D loss: 0.1227, G loss: 2.6012\n",
      "[244/1600] D loss: 1.6728, G loss: 2.2891\n",
      "[364/1600] D loss: 0.1320, G loss: 3.1920\n",
      "[484/1600] D loss: 0.8881, G loss: 1.3653\n",
      "[604/1600] D loss: 0.3283, G loss: 2.9989\n",
      "[724/1600] D loss: 0.2470, G loss: 2.4642\n",
      "[844/1600] D loss: 0.5133, G loss: 1.5401\n",
      "[964/1600] D loss: 0.3479, G loss: 2.1703\n",
      "[1084/1600] D loss: 1.3737, G loss: 1.9935\n",
      "[1204/1600] D loss: 0.1786, G loss: 2.3554\n",
      "[1324/1600] D loss: 0.4963, G loss: 2.3288\n",
      "[1444/1600] D loss: 0.5550, G loss: 2.0306\n",
      "[1564/1600] D loss: 0.8363, G loss: 1.2356\n",
      "train error: \n",
      " D loss: 0.601446, G loss: 2.528678, D accuracy: 87.8%, cell accuracy: 93.3%, board accuracy: 0.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.618532, G loss: 2.663063, D accuracy: 86.6%, cell accuracy: 93.2%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7343, G loss: 1.9983\n",
      "[124/1600] D loss: 0.7400, G loss: 2.0925\n",
      "[244/1600] D loss: 0.3048, G loss: 2.4735\n",
      "[364/1600] D loss: 0.7153, G loss: 3.1638\n",
      "[484/1600] D loss: 0.4646, G loss: 2.0432\n",
      "[604/1600] D loss: 0.5187, G loss: 3.1462\n",
      "[724/1600] D loss: 0.3922, G loss: 2.1393\n",
      "[844/1600] D loss: 1.8387, G loss: 1.2674\n",
      "[964/1600] D loss: 0.8557, G loss: 2.8746\n",
      "[1084/1600] D loss: 0.8559, G loss: 2.2895\n",
      "[1204/1600] D loss: 1.0951, G loss: 1.7517\n",
      "[1324/1600] D loss: 0.2903, G loss: 2.7623\n",
      "[1444/1600] D loss: 0.3030, G loss: 2.5215\n",
      "[1564/1600] D loss: 0.2980, G loss: 2.3236\n",
      "train error: \n",
      " D loss: 0.658869, G loss: 2.068299, D accuracy: 85.1%, cell accuracy: 93.5%, board accuracy: 0.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.650189, G loss: 2.228733, D accuracy: 86.6%, cell accuracy: 93.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.1504, G loss: 2.9106\n",
      "[124/1600] D loss: 0.2265, G loss: 2.0286\n",
      "[244/1600] D loss: 1.0193, G loss: 1.0501\n",
      "[364/1600] D loss: 1.5420, G loss: 1.1470\n",
      "[484/1600] D loss: 0.9237, G loss: 2.3457\n",
      "[604/1600] D loss: 0.9484, G loss: 2.0137\n",
      "[724/1600] D loss: 0.2175, G loss: 2.5128\n",
      "[844/1600] D loss: 0.4906, G loss: 2.5267\n",
      "[964/1600] D loss: 0.2533, G loss: 3.0438\n",
      "[1084/1600] D loss: 1.4160, G loss: 1.6722\n",
      "[1204/1600] D loss: 0.6634, G loss: 3.7416\n",
      "[1324/1600] D loss: 0.9277, G loss: 2.0183\n",
      "[1444/1600] D loss: 0.5311, G loss: 1.6796\n",
      "[1564/1600] D loss: 0.8634, G loss: 1.3840\n",
      "train error: \n",
      " D loss: 0.626927, G loss: 1.916170, D accuracy: 86.8%, cell accuracy: 93.5%, board accuracy: 0.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.616563, G loss: 2.078470, D accuracy: 88.6%, cell accuracy: 93.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.1564, G loss: 2.5128\n",
      "[124/1600] D loss: 1.3259, G loss: 1.3955\n",
      "[244/1600] D loss: 0.3597, G loss: 2.6193\n",
      "[364/1600] D loss: 0.8755, G loss: 0.7768\n",
      "[484/1600] D loss: 1.0477, G loss: 1.7312\n",
      "[604/1600] D loss: 0.9110, G loss: 1.7350\n",
      "[724/1600] D loss: 0.7050, G loss: 1.2783\n",
      "[844/1600] D loss: 1.4580, G loss: 1.6061\n",
      "[964/1600] D loss: 0.6244, G loss: 1.7983\n",
      "[1084/1600] D loss: 0.2318, G loss: 2.7986\n",
      "[1204/1600] D loss: 0.6873, G loss: 1.2327\n",
      "[1324/1600] D loss: 0.5554, G loss: 2.0427\n",
      "[1444/1600] D loss: 0.3343, G loss: 2.5721\n",
      "[1564/1600] D loss: 0.0718, G loss: 3.6108\n",
      "train error: \n",
      " D loss: 0.594682, G loss: 2.273515, D accuracy: 88.6%, cell accuracy: 93.7%, board accuracy: 0.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.592907, G loss: 2.419661, D accuracy: 89.1%, cell accuracy: 93.6%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2122, G loss: 0.8671\n",
      "[124/1600] D loss: 0.0940, G loss: 3.1772\n",
      "[244/1600] D loss: 0.4759, G loss: 2.6120\n",
      "[364/1600] D loss: 0.8635, G loss: 2.2985\n",
      "[484/1600] D loss: 1.0873, G loss: 2.3783\n",
      "[604/1600] D loss: 0.3887, G loss: 2.2592\n",
      "[724/1600] D loss: 0.3708, G loss: 1.7362\n",
      "[844/1600] D loss: 1.0678, G loss: 2.3697\n",
      "[964/1600] D loss: 0.7033, G loss: 1.1295\n",
      "[1084/1600] D loss: 0.2529, G loss: 2.8172\n",
      "[1204/1600] D loss: 0.2749, G loss: 3.2167\n",
      "[1324/1600] D loss: 0.6845, G loss: 1.5307\n",
      "[1444/1600] D loss: 0.4176, G loss: 2.5265\n",
      "[1564/1600] D loss: 0.5006, G loss: 1.9410\n",
      "train error: \n",
      " D loss: 0.635444, G loss: 2.293739, D accuracy: 87.8%, cell accuracy: 93.7%, board accuracy: 0.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.629477, G loss: 2.414555, D accuracy: 88.5%, cell accuracy: 93.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6230, G loss: 1.5777\n",
      "[124/1600] D loss: 0.6556, G loss: 1.9069\n",
      "[244/1600] D loss: 1.1335, G loss: 1.0508\n",
      "[364/1600] D loss: 0.6145, G loss: 2.5473\n",
      "[484/1600] D loss: 0.7113, G loss: 1.4992\n",
      "[604/1600] D loss: 1.1567, G loss: 1.6759\n",
      "[724/1600] D loss: 0.5446, G loss: 1.6385\n",
      "[844/1600] D loss: 0.5904, G loss: 1.8959\n",
      "[964/1600] D loss: 0.9872, G loss: 0.9017\n",
      "[1084/1600] D loss: 0.4503, G loss: 2.1796\n",
      "[1204/1600] D loss: 0.4261, G loss: 2.7758\n",
      "[1324/1600] D loss: 0.0727, G loss: 4.1102\n",
      "[1444/1600] D loss: 0.5046, G loss: 1.6102\n",
      "[1564/1600] D loss: 0.1399, G loss: 2.8573\n",
      "train error: \n",
      " D loss: 0.681937, G loss: 2.197356, D accuracy: 86.9%, cell accuracy: 93.5%, board accuracy: 0.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.697843, G loss: 2.351722, D accuracy: 85.6%, cell accuracy: 93.5%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.1920, G loss: 2.8028\n",
      "[124/1600] D loss: 1.0857, G loss: 1.0301\n",
      "[244/1600] D loss: 0.7504, G loss: 2.2320\n",
      "[364/1600] D loss: 0.2667, G loss: 3.4475\n",
      "[484/1600] D loss: 1.3338, G loss: 1.9208\n",
      "[604/1600] D loss: 1.3003, G loss: 1.7466\n",
      "[724/1600] D loss: 0.5857, G loss: 1.8571\n",
      "[844/1600] D loss: 0.2421, G loss: 2.9844\n",
      "[964/1600] D loss: 0.6713, G loss: 1.5554\n",
      "[1084/1600] D loss: 0.3675, G loss: 2.2692\n",
      "[1204/1600] D loss: 0.3194, G loss: 2.1691\n",
      "[1324/1600] D loss: 0.2731, G loss: 2.3344\n",
      "[1444/1600] D loss: 0.1870, G loss: 2.3607\n",
      "[1564/1600] D loss: 0.4488, G loss: 1.9100\n",
      "train error: \n",
      " D loss: 0.641181, G loss: 1.838494, D accuracy: 85.5%, cell accuracy: 93.7%, board accuracy: 0.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.632910, G loss: 1.980032, D accuracy: 85.8%, cell accuracy: 93.6%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.3698, G loss: 2.1876\n",
      "[124/1600] D loss: 0.3449, G loss: 2.3829\n",
      "[244/1600] D loss: 0.4013, G loss: 1.7600\n",
      "[364/1600] D loss: 0.8191, G loss: 1.9419\n",
      "[484/1600] D loss: 1.0829, G loss: 3.0756\n",
      "[604/1600] D loss: 0.3200, G loss: 2.3207\n",
      "[724/1600] D loss: 0.5405, G loss: 1.8628\n",
      "[844/1600] D loss: 0.2714, G loss: 2.2162\n",
      "[964/1600] D loss: 0.2768, G loss: 2.1268\n",
      "[1084/1600] D loss: 0.1902, G loss: 2.6533\n",
      "[1204/1600] D loss: 0.4081, G loss: 2.5475\n",
      "[1324/1600] D loss: 0.8935, G loss: 1.7852\n",
      "[1444/1600] D loss: 0.9374, G loss: 1.8709\n",
      "[1564/1600] D loss: 0.4883, G loss: 2.0007\n",
      "train error: \n",
      " D loss: 0.625640, G loss: 2.233258, D accuracy: 87.9%, cell accuracy: 92.4%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.636335, G loss: 2.333635, D accuracy: 86.6%, cell accuracy: 92.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.3224, G loss: 2.8172\n",
      "[124/1600] D loss: 0.1470, G loss: 2.1233\n",
      "[244/1600] D loss: 0.8532, G loss: 1.9759\n",
      "[364/1600] D loss: 0.2308, G loss: 3.1874\n",
      "[484/1600] D loss: 0.2162, G loss: 2.3413\n",
      "[604/1600] D loss: 0.5370, G loss: 2.6734\n",
      "[724/1600] D loss: 0.3753, G loss: 1.7694\n",
      "[844/1600] D loss: 0.5758, G loss: 1.4926\n",
      "[964/1600] D loss: 1.1846, G loss: 1.8842\n",
      "[1084/1600] D loss: 0.6335, G loss: 1.9723\n",
      "[1204/1600] D loss: 0.2113, G loss: 3.1814\n",
      "[1324/1600] D loss: 0.8025, G loss: 2.0261\n",
      "[1444/1600] D loss: 0.3906, G loss: 2.4680\n",
      "[1564/1600] D loss: 0.3441, G loss: 3.1545\n",
      "train error: \n",
      " D loss: 0.599349, G loss: 2.179121, D accuracy: 88.6%, cell accuracy: 93.8%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.597101, G loss: 2.278086, D accuracy: 89.6%, cell accuracy: 93.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7560, G loss: 1.4344\n",
      "[124/1600] D loss: 0.4896, G loss: 2.0513\n",
      "[244/1600] D loss: 0.5356, G loss: 2.4603\n",
      "[364/1600] D loss: 0.8252, G loss: 2.7182\n",
      "[484/1600] D loss: 0.9958, G loss: 1.8075\n",
      "[604/1600] D loss: 0.8064, G loss: 1.3489\n",
      "[724/1600] D loss: 0.2011, G loss: 2.4278\n",
      "[844/1600] D loss: 0.3040, G loss: 2.9094\n",
      "[964/1600] D loss: 0.6000, G loss: 2.8019\n",
      "[1084/1600] D loss: 1.0148, G loss: 1.8447\n",
      "[1204/1600] D loss: 0.8178, G loss: 1.2284\n",
      "[1324/1600] D loss: 0.6101, G loss: 3.2077\n",
      "[1444/1600] D loss: 0.4339, G loss: 1.7800\n",
      "[1564/1600] D loss: 0.3861, G loss: 2.3241\n",
      "train error: \n",
      " D loss: 0.684728, G loss: 2.736628, D accuracy: 85.2%, cell accuracy: 93.4%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.696750, G loss: 2.894053, D accuracy: 85.9%, cell accuracy: 93.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6059, G loss: 2.5081\n",
      "[124/1600] D loss: 0.6916, G loss: 1.9038\n",
      "[244/1600] D loss: 0.4732, G loss: 1.7860\n",
      "[364/1600] D loss: 0.4049, G loss: 1.6811\n",
      "[484/1600] D loss: 1.0588, G loss: 2.5158\n",
      "[604/1600] D loss: 0.6586, G loss: 2.0013\n",
      "[724/1600] D loss: 0.4606, G loss: 3.2011\n",
      "[844/1600] D loss: 0.1485, G loss: 3.7653\n",
      "[964/1600] D loss: 0.5230, G loss: 2.0792\n",
      "[1084/1600] D loss: 0.3447, G loss: 2.3527\n",
      "[1204/1600] D loss: 0.7531, G loss: 1.8104\n",
      "[1324/1600] D loss: 1.2002, G loss: 2.3312\n",
      "[1444/1600] D loss: 0.6666, G loss: 2.6677\n",
      "[1564/1600] D loss: 0.2611, G loss: 2.2794\n",
      "train error: \n",
      " D loss: 0.620202, G loss: 1.956451, D accuracy: 87.9%, cell accuracy: 93.3%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.600409, G loss: 2.082174, D accuracy: 88.4%, cell accuracy: 93.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4950, G loss: 1.5237\n",
      "[124/1600] D loss: 0.4614, G loss: 3.2645\n",
      "[244/1600] D loss: 0.6546, G loss: 2.4603\n",
      "[364/1600] D loss: 0.8518, G loss: 2.7604\n",
      "[484/1600] D loss: 0.7541, G loss: 1.5184\n",
      "[604/1600] D loss: 0.5333, G loss: 2.2790\n",
      "[724/1600] D loss: 0.3795, G loss: 3.3954\n",
      "[844/1600] D loss: 0.4455, G loss: 3.0864\n",
      "[964/1600] D loss: 0.9750, G loss: 1.3328\n",
      "[1084/1600] D loss: 0.5394, G loss: 2.3002\n",
      "[1204/1600] D loss: 0.3193, G loss: 2.1902\n",
      "[1324/1600] D loss: 0.4579, G loss: 2.0045\n",
      "[1444/1600] D loss: 0.4311, G loss: 2.4172\n",
      "[1564/1600] D loss: 0.6378, G loss: 1.9820\n",
      "train error: \n",
      " D loss: 0.592212, G loss: 2.016569, D accuracy: 87.7%, cell accuracy: 93.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.589105, G loss: 2.143942, D accuracy: 88.1%, cell accuracy: 93.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8565, G loss: 1.5446\n",
      "[124/1600] D loss: 0.2385, G loss: 3.7542\n",
      "[244/1600] D loss: 1.2200, G loss: 2.1858\n",
      "[364/1600] D loss: 0.2040, G loss: 3.2390\n",
      "[484/1600] D loss: 0.5856, G loss: 2.1872\n",
      "[604/1600] D loss: 0.5868, G loss: 1.6883\n",
      "[724/1600] D loss: 0.5335, G loss: 1.5663\n",
      "[844/1600] D loss: 0.7079, G loss: 1.4106\n",
      "[964/1600] D loss: 0.6556, G loss: 2.1301\n",
      "[1084/1600] D loss: 0.2914, G loss: 3.0991\n",
      "[1204/1600] D loss: 0.7120, G loss: 1.8500\n",
      "[1324/1600] D loss: 0.1891, G loss: 3.3560\n",
      "[1444/1600] D loss: 0.4762, G loss: 1.6697\n",
      "[1564/1600] D loss: 0.6072, G loss: 2.0089\n",
      "train error: \n",
      " D loss: 0.615808, G loss: 2.040797, D accuracy: 86.3%, cell accuracy: 93.6%, board accuracy: 0.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.601226, G loss: 2.207251, D accuracy: 86.2%, cell accuracy: 93.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9607, G loss: 1.4962\n",
      "[124/1600] D loss: 0.3142, G loss: 2.6776\n",
      "[244/1600] D loss: 0.5449, G loss: 2.0982\n",
      "[364/1600] D loss: 0.5219, G loss: 1.4578\n",
      "[484/1600] D loss: 0.3996, G loss: 3.1775\n",
      "[604/1600] D loss: 1.0814, G loss: 2.9872\n",
      "[724/1600] D loss: 0.3857, G loss: 2.4603\n",
      "[844/1600] D loss: 0.8002, G loss: 1.1686\n",
      "[964/1600] D loss: 0.2858, G loss: 3.3738\n",
      "[1084/1600] D loss: 0.4112, G loss: 2.3569\n",
      "[1204/1600] D loss: 0.6901, G loss: 3.7132\n",
      "[1324/1600] D loss: 0.2694, G loss: 2.1444\n",
      "[1444/1600] D loss: 0.2459, G loss: 2.4283\n",
      "[1564/1600] D loss: 1.1700, G loss: 0.6769\n",
      "train error: \n",
      " D loss: 0.594282, G loss: 2.564257, D accuracy: 87.4%, cell accuracy: 93.9%, board accuracy: 0.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.607908, G loss: 2.719760, D accuracy: 88.1%, cell accuracy: 93.6%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.3874, G loss: 2.6684\n",
      "[124/1600] D loss: 0.6605, G loss: 1.5881\n",
      "[244/1600] D loss: 1.5953, G loss: 0.9731\n",
      "[364/1600] D loss: 0.2126, G loss: 2.9550\n",
      "[484/1600] D loss: 0.5766, G loss: 1.7486\n",
      "[604/1600] D loss: 0.4730, G loss: 2.1332\n",
      "[724/1600] D loss: 0.6991, G loss: 3.0198\n",
      "[844/1600] D loss: 0.2150, G loss: 2.8383\n",
      "[964/1600] D loss: 0.2465, G loss: 2.9559\n",
      "[1084/1600] D loss: 0.2780, G loss: 1.9909\n",
      "[1204/1600] D loss: 0.2326, G loss: 3.0017\n",
      "[1324/1600] D loss: 1.4595, G loss: 2.5496\n",
      "[1444/1600] D loss: 1.0224, G loss: 1.5620\n",
      "[1564/1600] D loss: 0.4212, G loss: 1.6947\n",
      "train error: \n",
      " D loss: 0.551343, G loss: 2.505251, D accuracy: 89.5%, cell accuracy: 93.5%, board accuracy: 0.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.560293, G loss: 2.694613, D accuracy: 88.8%, cell accuracy: 93.2%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.3495, G loss: 2.9113\n",
      "[124/1600] D loss: 0.4475, G loss: 2.5974\n",
      "[244/1600] D loss: 0.5616, G loss: 1.7587\n",
      "[364/1600] D loss: 0.8474, G loss: 1.4277\n",
      "[484/1600] D loss: 0.1168, G loss: 3.1171\n",
      "[604/1600] D loss: 0.1651, G loss: 2.6536\n",
      "[724/1600] D loss: 0.5613, G loss: 2.5502\n",
      "[844/1600] D loss: 0.8098, G loss: 1.8261\n",
      "[964/1600] D loss: 0.8065, G loss: 1.3191\n",
      "[1084/1600] D loss: 0.3102, G loss: 2.3019\n",
      "[1204/1600] D loss: 0.9431, G loss: 2.3597\n",
      "[1324/1600] D loss: 0.8400, G loss: 1.8581\n",
      "[1444/1600] D loss: 0.6832, G loss: 1.3768\n",
      "[1564/1600] D loss: 1.1167, G loss: 2.0320\n",
      "train error: \n",
      " D loss: 0.653470, G loss: 2.766143, D accuracy: 85.8%, cell accuracy: 93.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.667196, G loss: 2.992274, D accuracy: 85.4%, cell accuracy: 93.4%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6399, G loss: 2.1372\n",
      "[124/1600] D loss: 1.0973, G loss: 3.0778\n",
      "[244/1600] D loss: 0.2272, G loss: 3.2717\n",
      "[364/1600] D loss: 0.6430, G loss: 1.2259\n",
      "[484/1600] D loss: 0.5746, G loss: 3.0168\n",
      "[604/1600] D loss: 0.1540, G loss: 2.7177\n",
      "[724/1600] D loss: 0.8753, G loss: 1.8500\n",
      "[844/1600] D loss: 0.6299, G loss: 2.6857\n",
      "[964/1600] D loss: 0.4328, G loss: 1.5232\n",
      "[1084/1600] D loss: 1.2255, G loss: 1.6056\n",
      "[1204/1600] D loss: 0.4584, G loss: 2.6855\n",
      "[1324/1600] D loss: 0.3710, G loss: 2.5298\n",
      "[1444/1600] D loss: 0.4231, G loss: 3.1077\n",
      "[1564/1600] D loss: 0.3463, G loss: 2.4053\n",
      "train error: \n",
      " D loss: 0.584587, G loss: 2.406488, D accuracy: 88.3%, cell accuracy: 94.1%, board accuracy: 0.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.599531, G loss: 2.567945, D accuracy: 89.4%, cell accuracy: 93.8%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1346, G loss: 2.4631\n",
      "[124/1600] D loss: 0.6184, G loss: 2.9072\n",
      "[244/1600] D loss: 0.2423, G loss: 3.1566\n",
      "[364/1600] D loss: 0.0584, G loss: 3.6712\n",
      "[484/1600] D loss: 0.9668, G loss: 1.3450\n",
      "[604/1600] D loss: 0.2081, G loss: 2.5249\n",
      "[724/1600] D loss: 0.2627, G loss: 3.3630\n",
      "[844/1600] D loss: 0.2511, G loss: 2.5596\n",
      "[964/1600] D loss: 0.9267, G loss: 2.1420\n",
      "[1084/1600] D loss: 0.2397, G loss: 2.4275\n",
      "[1204/1600] D loss: 0.1028, G loss: 2.4701\n",
      "[1324/1600] D loss: 0.9065, G loss: 2.1348\n",
      "[1444/1600] D loss: 0.4821, G loss: 2.0358\n",
      "[1564/1600] D loss: 0.5422, G loss: 1.7931\n",
      "train error: \n",
      " D loss: 0.576216, G loss: 2.509404, D accuracy: 88.4%, cell accuracy: 94.3%, board accuracy: 0.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.606318, G loss: 2.709692, D accuracy: 88.4%, cell accuracy: 94.0%, board accuracy: 0.5% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4145, G loss: 1.8087\n",
      "[124/1600] D loss: 0.5544, G loss: 1.4451\n",
      "[244/1600] D loss: 0.4536, G loss: 2.0735\n",
      "[364/1600] D loss: 0.5126, G loss: 3.0848\n",
      "[484/1600] D loss: 1.0042, G loss: 2.7245\n",
      "[604/1600] D loss: 0.7876, G loss: 2.3305\n",
      "[724/1600] D loss: 0.8031, G loss: 2.0111\n",
      "[844/1600] D loss: 0.3130, G loss: 4.2819\n",
      "[964/1600] D loss: 0.4092, G loss: 1.7030\n",
      "[1084/1600] D loss: 0.8804, G loss: 2.2157\n",
      "[1204/1600] D loss: 0.7285, G loss: 1.4375\n",
      "[1324/1600] D loss: 0.2622, G loss: 3.0263\n",
      "[1444/1600] D loss: 0.4361, G loss: 3.6564\n",
      "[1564/1600] D loss: 0.6068, G loss: 1.5614\n",
      "train error: \n",
      " D loss: 0.590699, G loss: 2.792639, D accuracy: 87.3%, cell accuracy: 94.3%, board accuracy: 0.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.613502, G loss: 2.975370, D accuracy: 87.1%, cell accuracy: 94.0%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5129, G loss: 2.5440\n",
      "[124/1600] D loss: 0.1526, G loss: 2.8041\n",
      "[244/1600] D loss: 0.6145, G loss: 2.7943\n",
      "[364/1600] D loss: 0.4207, G loss: 2.7466\n",
      "[484/1600] D loss: 0.3977, G loss: 1.8258\n",
      "[604/1600] D loss: 0.3955, G loss: 2.4177\n",
      "[724/1600] D loss: 0.5072, G loss: 4.3149\n",
      "[844/1600] D loss: 0.4081, G loss: 3.0842\n",
      "[964/1600] D loss: 1.1514, G loss: 2.7226\n",
      "[1084/1600] D loss: 0.3424, G loss: 4.0025\n",
      "[1204/1600] D loss: 0.4042, G loss: 1.8218\n",
      "[1324/1600] D loss: 0.4728, G loss: 2.7748\n",
      "[1444/1600] D loss: 1.0122, G loss: 0.8443\n",
      "[1564/1600] D loss: 0.6288, G loss: 2.5919\n",
      "train error: \n",
      " D loss: 0.828317, G loss: 1.648147, D accuracy: 78.1%, cell accuracy: 94.2%, board accuracy: 0.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.777866, G loss: 1.874661, D accuracy: 80.8%, cell accuracy: 93.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8444, G loss: 1.5011\n",
      "[124/1600] D loss: 0.4432, G loss: 1.8280\n",
      "[244/1600] D loss: 0.5423, G loss: 2.0873\n",
      "[364/1600] D loss: 0.1150, G loss: 3.0205\n",
      "[484/1600] D loss: 0.7539, G loss: 2.3053\n",
      "[604/1600] D loss: 0.1954, G loss: 2.5322\n",
      "[724/1600] D loss: 0.5235, G loss: 3.1577\n",
      "[844/1600] D loss: 0.5239, G loss: 2.4683\n",
      "[964/1600] D loss: 0.2485, G loss: 2.8633\n",
      "[1084/1600] D loss: 0.7600, G loss: 2.5585\n",
      "[1204/1600] D loss: 0.4445, G loss: 2.8590\n",
      "[1324/1600] D loss: 0.3511, G loss: 1.6374\n",
      "[1444/1600] D loss: 0.1447, G loss: 2.3740\n",
      "[1564/1600] D loss: 0.7490, G loss: 2.3219\n",
      "train error: \n",
      " D loss: 0.622148, G loss: 1.976292, D accuracy: 84.9%, cell accuracy: 94.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.608402, G loss: 2.214677, D accuracy: 86.2%, cell accuracy: 93.8%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5690, G loss: 2.0713\n",
      "[124/1600] D loss: 0.6875, G loss: 2.3221\n",
      "[244/1600] D loss: 1.2172, G loss: 1.6271\n",
      "[364/1600] D loss: 0.3491, G loss: 2.8024\n",
      "[484/1600] D loss: 0.3053, G loss: 2.8278\n",
      "[604/1600] D loss: 0.1519, G loss: 3.3996\n",
      "[724/1600] D loss: 0.9764, G loss: 1.9788\n",
      "[844/1600] D loss: 0.4303, G loss: 2.6008\n",
      "[964/1600] D loss: 0.2428, G loss: 2.3986\n",
      "[1084/1600] D loss: 0.9179, G loss: 3.8141\n",
      "[1204/1600] D loss: 0.5346, G loss: 2.0565\n",
      "[1324/1600] D loss: 0.2619, G loss: 3.7230\n",
      "[1444/1600] D loss: 1.2969, G loss: 2.8517\n",
      "[1564/1600] D loss: 0.5579, G loss: 2.8297\n",
      "train error: \n",
      " D loss: 0.558043, G loss: 2.377430, D accuracy: 88.5%, cell accuracy: 94.3%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.574640, G loss: 2.622256, D accuracy: 88.2%, cell accuracy: 94.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.2296, G loss: 1.9393\n",
      "[124/1600] D loss: 0.2472, G loss: 2.7810\n",
      "[244/1600] D loss: 0.3307, G loss: 2.6669\n",
      "[364/1600] D loss: 0.5422, G loss: 1.5192\n",
      "[484/1600] D loss: 0.2795, G loss: 3.6875\n",
      "[604/1600] D loss: 0.7025, G loss: 2.3847\n",
      "[724/1600] D loss: 0.7366, G loss: 1.3880\n",
      "[844/1600] D loss: 0.9396, G loss: 3.0801\n",
      "[964/1600] D loss: 0.9077, G loss: 1.4601\n",
      "[1084/1600] D loss: 0.3189, G loss: 1.9678\n",
      "[1204/1600] D loss: 0.5237, G loss: 2.6971\n",
      "[1324/1600] D loss: 0.4140, G loss: 4.0990\n",
      "[1444/1600] D loss: 1.3478, G loss: 1.9617\n",
      "[1564/1600] D loss: 0.3090, G loss: 1.7170\n",
      "train error: \n",
      " D loss: 0.685004, G loss: 3.029517, D accuracy: 84.1%, cell accuracy: 93.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.740087, G loss: 3.256780, D accuracy: 83.8%, cell accuracy: 93.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1745, G loss: 2.9797\n",
      "[124/1600] D loss: 0.4402, G loss: 1.5690\n",
      "[244/1600] D loss: 0.5927, G loss: 3.0314\n",
      "[364/1600] D loss: 0.3258, G loss: 1.8253\n",
      "[484/1600] D loss: 1.0726, G loss: 2.1717\n",
      "[604/1600] D loss: 0.5992, G loss: 3.1422\n",
      "[724/1600] D loss: 0.6915, G loss: 2.2373\n",
      "[844/1600] D loss: 0.6743, G loss: 2.5729\n",
      "[964/1600] D loss: 0.7427, G loss: 1.9341\n",
      "[1084/1600] D loss: 0.2259, G loss: 2.2462\n",
      "[1204/1600] D loss: 0.2410, G loss: 2.2800\n",
      "[1324/1600] D loss: 0.3438, G loss: 3.5295\n",
      "[1444/1600] D loss: 1.4226, G loss: 1.4557\n",
      "[1564/1600] D loss: 0.1340, G loss: 3.7673\n",
      "train error: \n",
      " D loss: 0.570656, G loss: 2.890989, D accuracy: 87.9%, cell accuracy: 94.5%, board accuracy: 0.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.597692, G loss: 3.156082, D accuracy: 87.0%, cell accuracy: 94.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8409, G loss: 1.7537\n",
      "[124/1600] D loss: 0.8231, G loss: 0.9193\n",
      "[244/1600] D loss: 0.8340, G loss: 1.6163\n",
      "[364/1600] D loss: 0.7920, G loss: 1.9930\n",
      "[484/1600] D loss: 0.1971, G loss: 2.6632\n",
      "[604/1600] D loss: 0.5625, G loss: 2.0493\n",
      "[724/1600] D loss: 0.3746, G loss: 1.6129\n",
      "[844/1600] D loss: 0.4693, G loss: 1.8010\n",
      "[964/1600] D loss: 0.9191, G loss: 1.4004\n",
      "[1084/1600] D loss: 1.0128, G loss: 1.5371\n",
      "[1204/1600] D loss: 0.6414, G loss: 2.4367\n",
      "[1324/1600] D loss: 0.2592, G loss: 3.6003\n",
      "[1444/1600] D loss: 0.3467, G loss: 2.1272\n",
      "[1564/1600] D loss: 0.1005, G loss: 3.8317\n",
      "train error: \n",
      " D loss: 0.658160, G loss: 2.060213, D accuracy: 85.2%, cell accuracy: 94.4%, board accuracy: 0.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.637436, G loss: 2.305870, D accuracy: 85.5%, cell accuracy: 94.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.2616, G loss: 2.5991\n",
      "[124/1600] D loss: 0.8155, G loss: 3.6636\n",
      "[244/1600] D loss: 0.3617, G loss: 2.3731\n",
      "[364/1600] D loss: 0.3340, G loss: 2.1961\n",
      "[484/1600] D loss: 0.3710, G loss: 2.3933\n",
      "[604/1600] D loss: 0.4927, G loss: 1.4755\n",
      "[724/1600] D loss: 0.6917, G loss: 1.8703\n",
      "[844/1600] D loss: 2.0564, G loss: 0.5295\n",
      "[964/1600] D loss: 1.3325, G loss: 0.6088\n",
      "[1084/1600] D loss: 0.3515, G loss: 2.9865\n",
      "[1204/1600] D loss: 0.7921, G loss: 2.5977\n",
      "[1324/1600] D loss: 0.1669, G loss: 4.1275\n",
      "[1444/1600] D loss: 0.5407, G loss: 2.1528\n",
      "[1564/1600] D loss: 0.9982, G loss: 1.9516\n",
      "train error: \n",
      " D loss: 0.612200, G loss: 2.311030, D accuracy: 86.0%, cell accuracy: 93.9%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.616553, G loss: 2.535644, D accuracy: 87.8%, cell accuracy: 93.5%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1967, G loss: 1.6542\n",
      "[124/1600] D loss: 0.1220, G loss: 4.0204\n",
      "[244/1600] D loss: 1.1963, G loss: 2.9714\n",
      "[364/1600] D loss: 1.4524, G loss: 1.1094\n",
      "[484/1600] D loss: 0.0284, G loss: 4.4545\n",
      "[604/1600] D loss: 0.5087, G loss: 3.0055\n",
      "[724/1600] D loss: 0.1372, G loss: 2.9668\n",
      "[844/1600] D loss: 0.6335, G loss: 1.7423\n",
      "[964/1600] D loss: 0.3298, G loss: 2.7307\n",
      "[1084/1600] D loss: 1.3438, G loss: 1.3583\n",
      "[1204/1600] D loss: 0.3548, G loss: 3.9480\n",
      "[1324/1600] D loss: 2.1021, G loss: 0.6318\n",
      "[1444/1600] D loss: 0.2946, G loss: 2.7224\n",
      "[1564/1600] D loss: 0.5897, G loss: 3.1857\n",
      "train error: \n",
      " D loss: 0.553085, G loss: 2.397364, D accuracy: 88.1%, cell accuracy: 94.2%, board accuracy: 0.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.535330, G loss: 2.676165, D accuracy: 88.8%, cell accuracy: 93.9%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.3243, G loss: 2.4605\n",
      "[124/1600] D loss: 0.5669, G loss: 2.6020\n",
      "[244/1600] D loss: 0.7236, G loss: 1.6369\n",
      "[364/1600] D loss: 0.3316, G loss: 2.2469\n",
      "[484/1600] D loss: 0.2708, G loss: 1.8727\n",
      "[604/1600] D loss: 0.5852, G loss: 3.4789\n",
      "[724/1600] D loss: 0.7666, G loss: 2.7453\n",
      "[844/1600] D loss: 0.9291, G loss: 2.2184\n",
      "[964/1600] D loss: 0.5068, G loss: 3.2755\n",
      "[1084/1600] D loss: 0.7452, G loss: 2.7471\n",
      "[1204/1600] D loss: 0.6683, G loss: 1.8263\n",
      "[1324/1600] D loss: 0.6786, G loss: 1.9489\n",
      "[1444/1600] D loss: 0.0917, G loss: 3.3925\n",
      "[1564/1600] D loss: 1.0010, G loss: 2.0739\n",
      "train error: \n",
      " D loss: 0.540573, G loss: 2.231044, D accuracy: 87.9%, cell accuracy: 94.3%, board accuracy: 0.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.535157, G loss: 2.459074, D accuracy: 88.5%, cell accuracy: 94.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5514, G loss: 2.0298\n",
      "[124/1600] D loss: 1.1755, G loss: 1.8988\n",
      "[244/1600] D loss: 0.2371, G loss: 2.4111\n",
      "[364/1600] D loss: 0.4726, G loss: 2.3314\n",
      "[484/1600] D loss: 0.4063, G loss: 2.7681\n",
      "[604/1600] D loss: 0.6630, G loss: 2.2859\n",
      "[724/1600] D loss: 0.8365, G loss: 1.9384\n",
      "[844/1600] D loss: 0.4783, G loss: 1.7522\n",
      "[964/1600] D loss: 0.3867, G loss: 2.5168\n",
      "[1084/1600] D loss: 0.1143, G loss: 3.3387\n",
      "[1204/1600] D loss: 0.8366, G loss: 2.2586\n",
      "[1324/1600] D loss: 0.4747, G loss: 1.7953\n",
      "[1444/1600] D loss: 0.2479, G loss: 3.2143\n",
      "[1564/1600] D loss: 0.7411, G loss: 1.5097\n",
      "train error: \n",
      " D loss: 0.632810, G loss: 2.975833, D accuracy: 85.2%, cell accuracy: 94.4%, board accuracy: 0.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.647530, G loss: 3.281302, D accuracy: 86.0%, cell accuracy: 94.0%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7566, G loss: 4.0477\n",
      "[124/1600] D loss: 0.3748, G loss: 2.3573\n",
      "[244/1600] D loss: 0.9897, G loss: 0.8688\n",
      "[364/1600] D loss: 1.3545, G loss: 0.8427\n",
      "[484/1600] D loss: 0.9395, G loss: 1.0804\n",
      "[604/1600] D loss: 0.6583, G loss: 1.9126\n",
      "[724/1600] D loss: 0.6928, G loss: 2.5659\n",
      "[844/1600] D loss: 0.3437, G loss: 2.1714\n",
      "[964/1600] D loss: 1.1919, G loss: 1.8794\n",
      "[1084/1600] D loss: 0.3944, G loss: 1.9244\n",
      "[1204/1600] D loss: 0.3176, G loss: 2.1321\n",
      "[1324/1600] D loss: 0.5642, G loss: 2.1206\n",
      "[1444/1600] D loss: 0.3760, G loss: 3.5367\n",
      "[1564/1600] D loss: 0.5242, G loss: 1.4992\n",
      "train error: \n",
      " D loss: 0.586127, G loss: 2.215565, D accuracy: 87.9%, cell accuracy: 94.4%, board accuracy: 0.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.591901, G loss: 2.480660, D accuracy: 87.8%, cell accuracy: 94.0%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4588, G loss: 1.5436\n",
      "[124/1600] D loss: 0.5372, G loss: 1.7352\n",
      "[244/1600] D loss: 0.3984, G loss: 3.2279\n",
      "[364/1600] D loss: 1.0141, G loss: 1.4348\n",
      "[484/1600] D loss: 0.8858, G loss: 2.0166\n",
      "[604/1600] D loss: 1.3737, G loss: 1.2040\n",
      "[724/1600] D loss: 0.6654, G loss: 1.8869\n",
      "[844/1600] D loss: 0.2044, G loss: 3.3708\n",
      "[964/1600] D loss: 0.6452, G loss: 1.9605\n",
      "[1084/1600] D loss: 0.4499, G loss: 3.1997\n",
      "[1204/1600] D loss: 0.4798, G loss: 3.1843\n",
      "[1324/1600] D loss: 1.3365, G loss: 1.6903\n",
      "[1444/1600] D loss: 0.6228, G loss: 2.6918\n",
      "[1564/1600] D loss: 0.5067, G loss: 2.0998\n",
      "train error: \n",
      " D loss: 0.593338, G loss: 2.702736, D accuracy: 87.6%, cell accuracy: 94.5%, board accuracy: 0.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.621090, G loss: 2.995097, D accuracy: 87.2%, cell accuracy: 94.1%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.3638, G loss: 1.7359\n",
      "[124/1600] D loss: 0.4641, G loss: 2.7734\n",
      "[244/1600] D loss: 0.2741, G loss: 2.5792\n",
      "[364/1600] D loss: 0.8229, G loss: 1.6788\n",
      "[484/1600] D loss: 0.6278, G loss: 1.8710\n",
      "[604/1600] D loss: 0.7851, G loss: 2.1123\n",
      "[724/1600] D loss: 0.6529, G loss: 1.2978\n",
      "[844/1600] D loss: 1.5184, G loss: 1.5698\n",
      "[964/1600] D loss: 0.4702, G loss: 3.5452\n",
      "[1084/1600] D loss: 1.8372, G loss: 0.5698\n",
      "[1204/1600] D loss: 0.8823, G loss: 1.5927\n",
      "[1324/1600] D loss: 0.2932, G loss: 3.9792\n",
      "[1444/1600] D loss: 1.1583, G loss: 1.5399\n",
      "[1564/1600] D loss: 0.6240, G loss: 1.9058\n",
      "train error: \n",
      " D loss: 0.629143, G loss: 2.265507, D accuracy: 86.2%, cell accuracy: 94.4%, board accuracy: 0.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.611576, G loss: 2.577852, D accuracy: 86.0%, cell accuracy: 94.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.3269, G loss: 2.3437\n",
      "[124/1600] D loss: 0.3311, G loss: 3.5632\n",
      "[244/1600] D loss: 0.1458, G loss: 3.6863\n",
      "[364/1600] D loss: 0.2313, G loss: 2.7729\n",
      "[484/1600] D loss: 0.0782, G loss: 4.0126\n",
      "[604/1600] D loss: 0.8425, G loss: 1.3233\n",
      "[724/1600] D loss: 0.9577, G loss: 2.0456\n",
      "[844/1600] D loss: 1.1379, G loss: 1.4577\n",
      "[964/1600] D loss: 0.7653, G loss: 2.8029\n",
      "[1084/1600] D loss: 0.4152, G loss: 2.7251\n",
      "[1204/1600] D loss: 0.9434, G loss: 2.6567\n",
      "[1324/1600] D loss: 0.5983, G loss: 1.6986\n",
      "[1444/1600] D loss: 0.5129, G loss: 1.4900\n",
      "[1564/1600] D loss: 0.8181, G loss: 3.5138\n",
      "train error: \n",
      " D loss: 0.673973, G loss: 1.997126, D accuracy: 84.1%, cell accuracy: 94.6%, board accuracy: 0.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.626664, G loss: 2.345480, D accuracy: 85.9%, cell accuracy: 94.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9354, G loss: 1.2330\n",
      "[124/1600] D loss: 1.0490, G loss: 1.4948\n",
      "[244/1600] D loss: 0.2877, G loss: 2.1645\n",
      "[364/1600] D loss: 0.5051, G loss: 2.3352\n",
      "[484/1600] D loss: 0.2027, G loss: 2.8795\n",
      "[604/1600] D loss: 0.4914, G loss: 2.0784\n",
      "[724/1600] D loss: 0.5856, G loss: 2.2767\n",
      "[844/1600] D loss: 1.2245, G loss: 1.6792\n",
      "[964/1600] D loss: 0.4730, G loss: 1.9514\n",
      "[1084/1600] D loss: 0.6252, G loss: 1.3205\n",
      "[1204/1600] D loss: 0.9021, G loss: 1.3824\n",
      "[1324/1600] D loss: 0.2527, G loss: 2.1854\n",
      "[1444/1600] D loss: 0.1829, G loss: 2.8492\n",
      "[1564/1600] D loss: 1.2786, G loss: 1.8065\n",
      "train error: \n",
      " D loss: 0.718545, G loss: 1.939591, D accuracy: 82.8%, cell accuracy: 94.6%, board accuracy: 0.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.651075, G loss: 2.268053, D accuracy: 85.9%, cell accuracy: 94.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.0993, G loss: 3.4073\n",
      "[124/1600] D loss: 0.2682, G loss: 2.1053\n",
      "[244/1600] D loss: 0.4387, G loss: 3.5959\n",
      "[364/1600] D loss: 0.5394, G loss: 1.2440\n",
      "[484/1600] D loss: 0.8565, G loss: 2.7899\n",
      "[604/1600] D loss: 0.2494, G loss: 3.9404\n",
      "[724/1600] D loss: 1.2050, G loss: 1.9959\n",
      "[844/1600] D loss: 0.2622, G loss: 3.0002\n",
      "[964/1600] D loss: 0.6287, G loss: 1.3891\n",
      "[1084/1600] D loss: 0.7967, G loss: 2.7196\n",
      "[1204/1600] D loss: 0.4615, G loss: 2.7046\n",
      "[1324/1600] D loss: 0.2665, G loss: 1.8563\n",
      "[1444/1600] D loss: 0.5894, G loss: 2.3118\n",
      "[1564/1600] D loss: 0.3164, G loss: 1.8274\n",
      "train error: \n",
      " D loss: 0.655000, G loss: 2.628976, D accuracy: 84.5%, cell accuracy: 94.4%, board accuracy: 0.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.645327, G loss: 2.970050, D accuracy: 85.9%, cell accuracy: 94.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.3847, G loss: 2.2366\n",
      "[124/1600] D loss: 0.8936, G loss: 0.7007\n",
      "[244/1600] D loss: 1.3813, G loss: 2.1268\n",
      "[364/1600] D loss: 0.8824, G loss: 1.0424\n",
      "[484/1600] D loss: 0.9430, G loss: 1.6722\n",
      "[604/1600] D loss: 0.5839, G loss: 2.4051\n",
      "[724/1600] D loss: 0.2686, G loss: 3.1845\n",
      "[844/1600] D loss: 0.8781, G loss: 1.7650\n",
      "[964/1600] D loss: 0.3337, G loss: 2.3851\n",
      "[1084/1600] D loss: 1.2986, G loss: 1.2682\n",
      "[1204/1600] D loss: 0.8748, G loss: 3.1640\n",
      "[1324/1600] D loss: 0.2459, G loss: 1.9637\n",
      "[1444/1600] D loss: 0.4844, G loss: 3.2627\n",
      "[1564/1600] D loss: 0.6135, G loss: 1.7508\n",
      "train error: \n",
      " D loss: 0.629196, G loss: 2.190838, D accuracy: 85.3%, cell accuracy: 94.5%, board accuracy: 0.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.598322, G loss: 2.514701, D accuracy: 86.5%, cell accuracy: 94.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4079, G loss: 2.4262\n",
      "[124/1600] D loss: 0.8053, G loss: 3.2380\n",
      "[244/1600] D loss: 0.1923, G loss: 3.1436\n",
      "[364/1600] D loss: 0.5565, G loss: 2.2439\n",
      "[484/1600] D loss: 0.3550, G loss: 3.4214\n",
      "[604/1600] D loss: 0.4284, G loss: 2.3534\n",
      "[724/1600] D loss: 1.0944, G loss: 1.9518\n",
      "[844/1600] D loss: 0.8612, G loss: 1.8666\n",
      "[964/1600] D loss: 0.2804, G loss: 1.8789\n",
      "[1084/1600] D loss: 0.6744, G loss: 2.6957\n",
      "[1204/1600] D loss: 0.6704, G loss: 1.2244\n",
      "[1324/1600] D loss: 1.1585, G loss: 0.9338\n",
      "[1444/1600] D loss: 0.9169, G loss: 2.2401\n",
      "[1564/1600] D loss: 0.3637, G loss: 3.8334\n",
      "train error: \n",
      " D loss: 0.877528, G loss: 1.640446, D accuracy: 78.4%, cell accuracy: 94.5%, board accuracy: 0.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.768733, G loss: 1.950147, D accuracy: 81.0%, cell accuracy: 94.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6172, G loss: 1.4388\n",
      "[124/1600] D loss: 0.8528, G loss: 3.0642\n",
      "[244/1600] D loss: 0.3618, G loss: 3.4946\n",
      "[364/1600] D loss: 1.1306, G loss: 1.7739\n",
      "[484/1600] D loss: 0.7765, G loss: 2.8448\n",
      "[604/1600] D loss: 1.3598, G loss: 1.1405\n",
      "[724/1600] D loss: 0.6353, G loss: 1.5665\n",
      "[844/1600] D loss: 1.6800, G loss: 1.5683\n",
      "[964/1600] D loss: 0.5030, G loss: 3.8923\n",
      "[1084/1600] D loss: 1.1409, G loss: 1.1822\n",
      "[1204/1600] D loss: 0.6818, G loss: 1.1311\n",
      "[1324/1600] D loss: 0.5118, G loss: 2.2384\n",
      "[1444/1600] D loss: 0.7687, G loss: 2.5294\n",
      "[1564/1600] D loss: 0.1567, G loss: 2.9597\n",
      "train error: \n",
      " D loss: 0.679759, G loss: 2.768722, D accuracy: 84.3%, cell accuracy: 94.5%, board accuracy: 0.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.678148, G loss: 3.172002, D accuracy: 85.9%, cell accuracy: 94.2%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2374, G loss: 2.0927\n",
      "[124/1600] D loss: 0.3131, G loss: 2.4370\n",
      "[244/1600] D loss: 0.3912, G loss: 2.5738\n",
      "[364/1600] D loss: 0.6655, G loss: 2.0396\n",
      "[484/1600] D loss: 1.3419, G loss: 1.1483\n",
      "[604/1600] D loss: 0.5044, G loss: 2.6490\n",
      "[724/1600] D loss: 0.7235, G loss: 3.3003\n",
      "[844/1600] D loss: 0.7410, G loss: 1.4030\n",
      "[964/1600] D loss: 1.8181, G loss: 3.6302\n",
      "[1084/1600] D loss: 0.2767, G loss: 2.9924\n",
      "[1204/1600] D loss: 0.0948, G loss: 3.1291\n",
      "[1324/1600] D loss: 0.7912, G loss: 2.6010\n",
      "[1444/1600] D loss: 0.8961, G loss: 0.8901\n",
      "[1564/1600] D loss: 0.8655, G loss: 1.5862\n",
      "train error: \n",
      " D loss: 0.698814, G loss: 2.796493, D accuracy: 83.1%, cell accuracy: 94.7%, board accuracy: 0.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.690978, G loss: 3.152430, D accuracy: 84.6%, cell accuracy: 94.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6242, G loss: 2.8164\n",
      "[124/1600] D loss: 0.7129, G loss: 2.2814\n",
      "[244/1600] D loss: 0.8998, G loss: 1.0425\n",
      "[364/1600] D loss: 1.4791, G loss: 2.9688\n",
      "[484/1600] D loss: 1.0360, G loss: 1.6144\n",
      "[604/1600] D loss: 0.7308, G loss: 1.8227\n",
      "[724/1600] D loss: 0.6388, G loss: 1.4498\n",
      "[844/1600] D loss: 0.0762, G loss: 3.8337\n",
      "[964/1600] D loss: 0.3501, G loss: 4.0560\n",
      "[1084/1600] D loss: 0.7608, G loss: 1.8657\n",
      "[1204/1600] D loss: 1.2793, G loss: 1.6591\n",
      "[1324/1600] D loss: 0.4772, G loss: 3.9284\n",
      "[1444/1600] D loss: 0.8755, G loss: 1.7082\n",
      "[1564/1600] D loss: 0.5920, G loss: 1.8848\n",
      "train error: \n",
      " D loss: 0.709800, G loss: 2.819405, D accuracy: 83.2%, cell accuracy: 94.7%, board accuracy: 0.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.712777, G loss: 3.224048, D accuracy: 83.4%, cell accuracy: 94.4%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5217, G loss: 2.1261\n",
      "[124/1600] D loss: 1.0704, G loss: 1.0992\n",
      "[244/1600] D loss: 1.2001, G loss: 2.7101\n",
      "[364/1600] D loss: 0.9474, G loss: 2.3786\n",
      "[484/1600] D loss: 1.2642, G loss: 1.0764\n",
      "[604/1600] D loss: 0.2321, G loss: 4.7797\n",
      "[724/1600] D loss: 0.5009, G loss: 2.3122\n",
      "[844/1600] D loss: 0.4146, G loss: 2.0130\n",
      "[964/1600] D loss: 0.7194, G loss: 2.9835\n",
      "[1084/1600] D loss: 1.0112, G loss: 2.1335\n",
      "[1204/1600] D loss: 0.6929, G loss: 1.9860\n",
      "[1324/1600] D loss: 0.8525, G loss: 1.5762\n",
      "[1444/1600] D loss: 0.5573, G loss: 3.4667\n",
      "[1564/1600] D loss: 0.4688, G loss: 1.6450\n",
      "train error: \n",
      " D loss: 0.634359, G loss: 2.182881, D accuracy: 85.2%, cell accuracy: 94.6%, board accuracy: 0.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.583466, G loss: 2.586910, D accuracy: 88.2%, cell accuracy: 94.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1232, G loss: 1.9052\n",
      "[124/1600] D loss: 1.1147, G loss: 1.7859\n",
      "[244/1600] D loss: 0.4758, G loss: 1.7879\n",
      "[364/1600] D loss: 0.1859, G loss: 4.1611\n",
      "[484/1600] D loss: 0.8323, G loss: 1.9995\n",
      "[604/1600] D loss: 0.7667, G loss: 2.9383\n",
      "[724/1600] D loss: 0.3835, G loss: 1.5519\n",
      "[844/1600] D loss: 0.2290, G loss: 3.5973\n",
      "[964/1600] D loss: 0.2867, G loss: 3.4146\n",
      "[1084/1600] D loss: 0.6914, G loss: 3.3670\n",
      "[1204/1600] D loss: 0.8930, G loss: 1.0017\n",
      "[1324/1600] D loss: 0.5784, G loss: 1.8962\n",
      "[1444/1600] D loss: 0.6957, G loss: 2.5478\n",
      "[1564/1600] D loss: 1.2145, G loss: 2.9905\n",
      "train error: \n",
      " D loss: 0.688829, G loss: 2.142662, D accuracy: 82.5%, cell accuracy: 94.7%, board accuracy: 0.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.624853, G loss: 2.561768, D accuracy: 85.4%, cell accuracy: 94.3%, board accuracy: 0.5% \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.2988, G loss: 3.9637\n",
      "[124/1600] D loss: 1.1680, G loss: 2.3702\n",
      "[244/1600] D loss: 0.5120, G loss: 1.4619\n",
      "[364/1600] D loss: 0.8360, G loss: 2.4945\n",
      "[484/1600] D loss: 0.8846, G loss: 1.9726\n",
      "[604/1600] D loss: 0.2555, G loss: 2.5547\n",
      "[724/1600] D loss: 1.4626, G loss: 0.6020\n",
      "[844/1600] D loss: 0.4181, G loss: 2.0637\n",
      "[964/1600] D loss: 0.8606, G loss: 1.2402\n",
      "[1084/1600] D loss: 0.6684, G loss: 2.9457\n",
      "[1204/1600] D loss: 0.7789, G loss: 1.8103\n",
      "[1324/1600] D loss: 0.8914, G loss: 2.1619\n",
      "[1444/1600] D loss: 0.4572, G loss: 1.9813\n",
      "[1564/1600] D loss: 0.2872, G loss: 3.2233\n",
      "train error: \n",
      " D loss: 0.626308, G loss: 2.522067, D accuracy: 85.3%, cell accuracy: 94.8%, board accuracy: 0.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.613270, G loss: 2.985725, D accuracy: 86.9%, cell accuracy: 94.4%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4113, G loss: 2.5041\n",
      "[124/1600] D loss: 0.6292, G loss: 2.2309\n",
      "[244/1600] D loss: 0.9339, G loss: 1.3948\n",
      "[364/1600] D loss: 0.1772, G loss: 3.6946\n",
      "[484/1600] D loss: 0.5671, G loss: 1.6692\n",
      "[604/1600] D loss: 0.3041, G loss: 2.2357\n",
      "[724/1600] D loss: 0.3156, G loss: 2.4732\n",
      "[844/1600] D loss: 0.5544, G loss: 2.4854\n",
      "[964/1600] D loss: 0.0047, G loss: 5.6770\n",
      "[1084/1600] D loss: 0.7961, G loss: 2.8532\n",
      "[1204/1600] D loss: 0.2177, G loss: 2.4895\n",
      "[1324/1600] D loss: 0.6684, G loss: 2.2259\n",
      "[1444/1600] D loss: 0.0855, G loss: 3.5027\n",
      "[1564/1600] D loss: 0.3589, G loss: 3.9177\n",
      "train error: \n",
      " D loss: 0.741400, G loss: 2.257990, D accuracy: 81.0%, cell accuracy: 94.7%, board accuracy: 0.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.675715, G loss: 2.664272, D accuracy: 83.6%, cell accuracy: 94.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8310, G loss: 1.2628\n",
      "[124/1600] D loss: 0.0239, G loss: 4.3589\n",
      "[244/1600] D loss: 0.2651, G loss: 4.2285\n",
      "[364/1600] D loss: 0.5022, G loss: 1.5912\n",
      "[484/1600] D loss: 1.0447, G loss: 3.8573\n",
      "[604/1600] D loss: 0.2373, G loss: 2.8443\n",
      "[724/1600] D loss: 0.4072, G loss: 3.1048\n",
      "[844/1600] D loss: 0.3434, G loss: 2.3883\n",
      "[964/1600] D loss: 0.8178, G loss: 2.3654\n",
      "[1084/1600] D loss: 0.7226, G loss: 2.6758\n",
      "[1204/1600] D loss: 0.7394, G loss: 1.3312\n",
      "[1324/1600] D loss: 0.6788, G loss: 3.4706\n",
      "[1444/1600] D loss: 1.0167, G loss: 1.4100\n",
      "[1564/1600] D loss: 1.0267, G loss: 1.8513\n",
      "train error: \n",
      " D loss: 0.651472, G loss: 2.298627, D accuracy: 83.8%, cell accuracy: 94.7%, board accuracy: 0.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.605096, G loss: 2.722070, D accuracy: 86.5%, cell accuracy: 94.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4365, G loss: 1.5795\n",
      "[124/1600] D loss: 0.7864, G loss: 2.6227\n",
      "[244/1600] D loss: 0.6073, G loss: 2.2066\n",
      "[364/1600] D loss: 0.8510, G loss: 1.1900\n",
      "[484/1600] D loss: 1.0674, G loss: 1.1056\n",
      "[604/1600] D loss: 0.5373, G loss: 1.9592\n",
      "[724/1600] D loss: 0.1259, G loss: 3.6326\n",
      "[844/1600] D loss: 0.5003, G loss: 2.3755\n",
      "[964/1600] D loss: 0.5205, G loss: 2.8527\n",
      "[1084/1600] D loss: 0.7550, G loss: 2.0594\n",
      "[1204/1600] D loss: 0.4515, G loss: 1.9399\n",
      "[1324/1600] D loss: 0.1139, G loss: 3.1152\n",
      "[1444/1600] D loss: 0.0533, G loss: 3.9406\n",
      "[1564/1600] D loss: 0.4691, G loss: 1.7696\n",
      "train error: \n",
      " D loss: 0.627099, G loss: 2.492457, D accuracy: 85.0%, cell accuracy: 94.7%, board accuracy: 0.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.629415, G loss: 2.857266, D accuracy: 86.5%, cell accuracy: 94.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5965, G loss: 2.4537\n",
      "[124/1600] D loss: 1.0761, G loss: 1.1787\n",
      "[244/1600] D loss: 0.4063, G loss: 2.0506\n",
      "[364/1600] D loss: 1.0672, G loss: 2.2875\n",
      "[484/1600] D loss: 0.0785, G loss: 4.2482\n",
      "[604/1600] D loss: 1.1291, G loss: 2.0460\n",
      "[724/1600] D loss: 0.1523, G loss: 3.7396\n",
      "[844/1600] D loss: 0.0664, G loss: 3.5314\n",
      "[964/1600] D loss: 0.7505, G loss: 2.5125\n",
      "[1084/1600] D loss: 0.2509, G loss: 2.7791\n",
      "[1204/1600] D loss: 0.6529, G loss: 2.3388\n",
      "[1324/1600] D loss: 0.4465, G loss: 1.9705\n",
      "[1444/1600] D loss: 0.2493, G loss: 3.8028\n",
      "[1564/1600] D loss: 0.7448, G loss: 2.1398\n",
      "train error: \n",
      " D loss: 0.669373, G loss: 2.154272, D accuracy: 83.8%, cell accuracy: 94.6%, board accuracy: 0.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.627504, G loss: 2.548316, D accuracy: 85.9%, cell accuracy: 94.3%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4779, G loss: 0.7610\n",
      "[124/1600] D loss: 0.8330, G loss: 2.7033\n",
      "[244/1600] D loss: 0.4040, G loss: 2.3531\n",
      "[364/1600] D loss: 1.2686, G loss: 1.7360\n",
      "[484/1600] D loss: 1.6250, G loss: 0.8369\n",
      "[604/1600] D loss: 0.8108, G loss: 1.7285\n",
      "[724/1600] D loss: 1.3046, G loss: 0.7651\n",
      "[844/1600] D loss: 0.6236, G loss: 2.1915\n",
      "[964/1600] D loss: 0.2232, G loss: 5.0521\n",
      "[1084/1600] D loss: 0.3481, G loss: 2.7909\n",
      "[1204/1600] D loss: 1.5077, G loss: 1.6473\n",
      "[1324/1600] D loss: 0.9406, G loss: 2.9118\n",
      "[1444/1600] D loss: 0.0870, G loss: 4.6696\n",
      "[1564/1600] D loss: 0.9249, G loss: 1.9708\n",
      "train error: \n",
      " D loss: 0.643304, G loss: 2.492141, D accuracy: 85.2%, cell accuracy: 94.7%, board accuracy: 0.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.652495, G loss: 2.845913, D accuracy: 86.4%, cell accuracy: 94.4%, board accuracy: 0.5% \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.1992, G loss: 3.4418\n",
      "[124/1600] D loss: 0.4411, G loss: 5.5417\n",
      "[244/1600] D loss: 0.4826, G loss: 2.9828\n",
      "[364/1600] D loss: 0.1059, G loss: 2.9522\n",
      "[484/1600] D loss: 0.4508, G loss: 3.1786\n",
      "[604/1600] D loss: 0.1661, G loss: 4.1480\n",
      "[724/1600] D loss: 0.8465, G loss: 2.2597\n",
      "[844/1600] D loss: 0.4768, G loss: 2.6479\n",
      "[964/1600] D loss: 0.4091, G loss: 3.8085\n",
      "[1084/1600] D loss: 1.1880, G loss: 1.8971\n",
      "[1204/1600] D loss: 0.4569, G loss: 1.7516\n",
      "[1324/1600] D loss: 1.0445, G loss: 1.6732\n",
      "[1444/1600] D loss: 0.6849, G loss: 2.1176\n",
      "[1564/1600] D loss: 0.4647, G loss: 1.8496\n",
      "train error: \n",
      " D loss: 0.622958, G loss: 2.479471, D accuracy: 85.3%, cell accuracy: 94.7%, board accuracy: 0.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.622724, G loss: 2.926283, D accuracy: 86.2%, cell accuracy: 94.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.2076, G loss: 3.1282\n",
      "[124/1600] D loss: 0.4718, G loss: 2.9700\n",
      "[244/1600] D loss: 1.6751, G loss: 2.0105\n",
      "[364/1600] D loss: 0.9273, G loss: 2.2841\n",
      "[484/1600] D loss: 0.3917, G loss: 3.5182\n",
      "[604/1600] D loss: 1.5950, G loss: 1.1949\n",
      "[724/1600] D loss: 1.1280, G loss: 0.9995\n",
      "[844/1600] D loss: 0.8071, G loss: 2.7491\n",
      "[964/1600] D loss: 0.4436, G loss: 1.8212\n",
      "[1084/1600] D loss: 0.9114, G loss: 2.2487\n",
      "[1204/1600] D loss: 1.0058, G loss: 1.7775\n",
      "[1324/1600] D loss: 0.7097, G loss: 3.8876\n",
      "[1444/1600] D loss: 0.8086, G loss: 2.1062\n",
      "[1564/1600] D loss: 0.8420, G loss: 2.7157\n",
      "train error: \n",
      " D loss: 0.722725, G loss: 2.070563, D accuracy: 81.1%, cell accuracy: 94.6%, board accuracy: 0.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.666489, G loss: 2.512396, D accuracy: 83.0%, cell accuracy: 94.3%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7299, G loss: 2.7562\n",
      "[124/1600] D loss: 0.9084, G loss: 3.2410\n",
      "[244/1600] D loss: 0.9158, G loss: 2.0317\n",
      "[364/1600] D loss: 1.1472, G loss: 2.1817\n",
      "[484/1600] D loss: 0.5587, G loss: 1.6454\n",
      "[604/1600] D loss: 1.1788, G loss: 1.3428\n",
      "[724/1600] D loss: 0.7755, G loss: 2.7147\n",
      "[844/1600] D loss: 0.9316, G loss: 1.3958\n",
      "[964/1600] D loss: 0.8988, G loss: 1.9021\n",
      "[1084/1600] D loss: 0.4410, G loss: 2.4568\n",
      "[1204/1600] D loss: 0.4651, G loss: 2.7041\n",
      "[1324/1600] D loss: 0.5594, G loss: 3.0342\n",
      "[1444/1600] D loss: 0.7062, G loss: 4.0077\n",
      "[1564/1600] D loss: 0.5965, G loss: 3.4504\n",
      "train error: \n",
      " D loss: 0.693407, G loss: 2.127049, D accuracy: 81.6%, cell accuracy: 94.5%, board accuracy: 0.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.659613, G loss: 2.597848, D accuracy: 84.4%, cell accuracy: 94.2%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7804, G loss: 1.7000\n",
      "[124/1600] D loss: 0.1986, G loss: 2.8143\n",
      "[244/1600] D loss: 0.0904, G loss: 4.1015\n",
      "[364/1600] D loss: 0.3918, G loss: 3.2482\n",
      "[484/1600] D loss: 1.0976, G loss: 1.1805\n",
      "[604/1600] D loss: 0.4396, G loss: 2.6771\n",
      "[724/1600] D loss: 0.6476, G loss: 2.4661\n",
      "[844/1600] D loss: 1.5747, G loss: 2.3765\n",
      "[964/1600] D loss: 1.1782, G loss: 1.1353\n",
      "[1084/1600] D loss: 0.6675, G loss: 2.3344\n",
      "[1204/1600] D loss: 0.5880, G loss: 3.0920\n",
      "[1324/1600] D loss: 0.8173, G loss: 2.3438\n",
      "[1444/1600] D loss: 1.0098, G loss: 1.7765\n",
      "[1564/1600] D loss: 0.4922, G loss: 2.6168\n",
      "train error: \n",
      " D loss: 0.675781, G loss: 2.162285, D accuracy: 83.0%, cell accuracy: 94.6%, board accuracy: 0.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.640055, G loss: 2.677784, D accuracy: 85.5%, cell accuracy: 94.3%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5354, G loss: 1.6205\n",
      "[124/1600] D loss: 0.7471, G loss: 2.4540\n",
      "[244/1600] D loss: 0.6804, G loss: 2.2502\n",
      "[364/1600] D loss: 0.4963, G loss: 2.6865\n",
      "[484/1600] D loss: 0.2610, G loss: 2.2512\n",
      "[604/1600] D loss: 0.8661, G loss: 1.3643\n",
      "[724/1600] D loss: 0.7180, G loss: 3.0106\n",
      "[844/1600] D loss: 1.1221, G loss: 1.0889\n",
      "[964/1600] D loss: 0.8195, G loss: 1.8417\n",
      "[1084/1600] D loss: 0.9663, G loss: 1.2445\n",
      "[1204/1600] D loss: 0.6034, G loss: 1.6964\n",
      "[1324/1600] D loss: 0.4128, G loss: 2.3416\n",
      "[1444/1600] D loss: 1.0211, G loss: 2.5113\n",
      "[1564/1600] D loss: 0.2983, G loss: 3.7360\n",
      "train error: \n",
      " D loss: 0.674848, G loss: 2.126018, D accuracy: 83.8%, cell accuracy: 94.8%, board accuracy: 0.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.634840, G loss: 2.596753, D accuracy: 85.6%, cell accuracy: 94.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4631, G loss: 1.8819\n",
      "[124/1600] D loss: 1.1451, G loss: 0.7365\n",
      "[244/1600] D loss: 0.6789, G loss: 2.2595\n",
      "[364/1600] D loss: 0.4681, G loss: 4.0292\n",
      "[484/1600] D loss: 1.0271, G loss: 1.4070\n",
      "[604/1600] D loss: 1.1075, G loss: 2.8869\n",
      "[724/1600] D loss: 0.7342, G loss: 1.6437\n",
      "[844/1600] D loss: 0.7794, G loss: 1.8535\n",
      "[964/1600] D loss: 0.9962, G loss: 2.2668\n",
      "[1084/1600] D loss: 0.5404, G loss: 2.0416\n",
      "[1204/1600] D loss: 1.1803, G loss: 1.0011\n",
      "[1324/1600] D loss: 1.5202, G loss: 1.3568\n",
      "[1444/1600] D loss: 0.5398, G loss: 3.7613\n",
      "[1564/1600] D loss: 0.4565, G loss: 3.6722\n",
      "train error: \n",
      " D loss: 0.794070, G loss: 1.773676, D accuracy: 81.0%, cell accuracy: 94.6%, board accuracy: 0.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.723246, G loss: 2.233235, D accuracy: 82.8%, cell accuracy: 94.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.1960, G loss: 2.2016\n",
      "[124/1600] D loss: 0.4780, G loss: 1.8253\n",
      "[244/1600] D loss: 0.3853, G loss: 2.2580\n",
      "[364/1600] D loss: 0.4387, G loss: 2.5165\n",
      "[484/1600] D loss: 0.8080, G loss: 1.9596\n",
      "[604/1600] D loss: 0.4399, G loss: 2.5603\n",
      "[724/1600] D loss: 0.6617, G loss: 1.7027\n",
      "[844/1600] D loss: 0.1265, G loss: 3.3825\n",
      "[964/1600] D loss: 0.3768, G loss: 2.1051\n",
      "[1084/1600] D loss: 0.8754, G loss: 2.9542\n",
      "[1204/1600] D loss: 0.4940, G loss: 3.2044\n",
      "[1324/1600] D loss: 1.1801, G loss: 2.1614\n",
      "[1444/1600] D loss: 1.1215, G loss: 1.9413\n",
      "[1564/1600] D loss: 0.3356, G loss: 3.8681\n",
      "train error: \n",
      " D loss: 0.705481, G loss: 2.070688, D accuracy: 82.1%, cell accuracy: 94.8%, board accuracy: 0.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.664023, G loss: 2.577152, D accuracy: 84.6%, cell accuracy: 94.4%, board accuracy: 0.5% \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7932, G loss: 1.1259\n",
      "[124/1600] D loss: 0.4754, G loss: 2.3915\n",
      "[244/1600] D loss: 0.1491, G loss: 3.0053\n",
      "[364/1600] D loss: 1.0881, G loss: 1.9431\n",
      "[484/1600] D loss: 0.1682, G loss: 3.6232\n",
      "[604/1600] D loss: 0.8543, G loss: 2.6332\n",
      "[724/1600] D loss: 0.4413, G loss: 1.6396\n",
      "[844/1600] D loss: 0.8110, G loss: 1.3854\n",
      "[964/1600] D loss: 0.4648, G loss: 2.1883\n",
      "[1084/1600] D loss: 0.3399, G loss: 3.1401\n",
      "[1204/1600] D loss: 0.5021, G loss: 3.4674\n",
      "[1324/1600] D loss: 0.8070, G loss: 2.4326\n",
      "[1444/1600] D loss: 1.1447, G loss: 3.2920\n",
      "[1564/1600] D loss: 0.8714, G loss: 1.1551\n",
      "train error: \n",
      " D loss: 0.711833, G loss: 1.955847, D accuracy: 81.4%, cell accuracy: 94.7%, board accuracy: 1.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.658264, G loss: 2.451034, D accuracy: 83.6%, cell accuracy: 94.3%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8232, G loss: 1.0553\n",
      "[124/1600] D loss: 0.4385, G loss: 2.4949\n",
      "[244/1600] D loss: 0.9162, G loss: 1.1699\n",
      "[364/1600] D loss: 0.7501, G loss: 1.8975\n",
      "[484/1600] D loss: 0.6469, G loss: 1.2842\n",
      "[604/1600] D loss: 0.2530, G loss: 3.3681\n",
      "[724/1600] D loss: 1.4176, G loss: 1.8475\n",
      "[844/1600] D loss: 0.3058, G loss: 3.7890\n",
      "[964/1600] D loss: 0.5604, G loss: 2.4513\n",
      "[1084/1600] D loss: 0.4864, G loss: 3.2789\n",
      "[1204/1600] D loss: 0.8271, G loss: 1.6559\n",
      "[1324/1600] D loss: 0.4011, G loss: 2.7549\n",
      "[1444/1600] D loss: 0.7247, G loss: 2.0734\n",
      "[1564/1600] D loss: 0.4410, G loss: 3.9028\n",
      "train error: \n",
      " D loss: 0.727880, G loss: 2.293470, D accuracy: 81.0%, cell accuracy: 94.7%, board accuracy: 0.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.725474, G loss: 2.811046, D accuracy: 81.8%, cell accuracy: 94.3%, board accuracy: 0.2% \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7770, G loss: 1.8120\n",
      "[124/1600] D loss: 0.4098, G loss: 2.2010\n",
      "[244/1600] D loss: 0.2537, G loss: 4.0790\n",
      "[364/1600] D loss: 0.3016, G loss: 1.8583\n",
      "[484/1600] D loss: 0.2554, G loss: 2.7411\n",
      "[604/1600] D loss: 0.8367, G loss: 1.5432\n",
      "[724/1600] D loss: 0.3213, G loss: 3.2225\n",
      "[844/1600] D loss: 1.0402, G loss: 1.1221\n",
      "[964/1600] D loss: 0.2581, G loss: 3.1454\n",
      "[1084/1600] D loss: 1.3879, G loss: 2.2257\n",
      "[1204/1600] D loss: 0.4939, G loss: 2.7727\n",
      "[1324/1600] D loss: 0.8047, G loss: 2.2757\n",
      "[1444/1600] D loss: 0.5471, G loss: 1.8918\n",
      "[1564/1600] D loss: 0.8121, G loss: 1.6106\n",
      "train error: \n",
      " D loss: 0.692799, G loss: 2.149738, D accuracy: 83.0%, cell accuracy: 94.8%, board accuracy: 1.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.658127, G loss: 2.717378, D accuracy: 84.0%, cell accuracy: 94.4%, board accuracy: 0.8% \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1995, G loss: 1.2924\n",
      "[124/1600] D loss: 0.4837, G loss: 2.4069\n",
      "[244/1600] D loss: 0.0628, G loss: 4.0593\n",
      "[364/1600] D loss: 1.2630, G loss: 3.6863\n",
      "[484/1600] D loss: 1.2435, G loss: 2.2016\n",
      "[604/1600] D loss: 0.7575, G loss: 2.7301\n",
      "[724/1600] D loss: 0.3501, G loss: 3.3879\n",
      "[844/1600] D loss: 0.3834, G loss: 3.8480\n",
      "[964/1600] D loss: 0.7020, G loss: 1.3108\n",
      "[1084/1600] D loss: 0.9599, G loss: 2.3391\n",
      "[1204/1600] D loss: 1.0632, G loss: 3.0758\n",
      "[1324/1600] D loss: 0.4201, G loss: 3.2738\n",
      "[1444/1600] D loss: 0.2744, G loss: 3.7468\n",
      "[1564/1600] D loss: 0.4872, G loss: 3.3843\n",
      "train error: \n",
      " D loss: 0.649478, G loss: 2.299507, D accuracy: 84.6%, cell accuracy: 94.6%, board accuracy: 1.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.630264, G loss: 2.867764, D accuracy: 85.2%, cell accuracy: 94.2%, board accuracy: 1.5% \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.1895, G loss: 3.3927\n",
      "[124/1600] D loss: 0.0634, G loss: 3.8058\n",
      "[244/1600] D loss: 0.9289, G loss: 1.9116\n",
      "[364/1600] D loss: 0.5022, G loss: 2.8961\n",
      "[484/1600] D loss: 0.6387, G loss: 2.7555\n",
      "[604/1600] D loss: 0.4854, G loss: 3.0096\n",
      "[724/1600] D loss: 0.7384, G loss: 1.7786\n",
      "[844/1600] D loss: 0.8910, G loss: 1.1723\n",
      "[964/1600] D loss: 0.9108, G loss: 2.3610\n",
      "[1084/1600] D loss: 0.4304, G loss: 1.5557\n",
      "[1204/1600] D loss: 0.3916, G loss: 1.7661\n",
      "[1324/1600] D loss: 0.7257, G loss: 3.4124\n",
      "[1444/1600] D loss: 0.7822, G loss: 1.5434\n",
      "[1564/1600] D loss: 0.5064, G loss: 2.1664\n",
      "train error: \n",
      " D loss: 0.831043, G loss: 1.774015, D accuracy: 78.8%, cell accuracy: 94.7%, board accuracy: 2.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.730393, G loss: 2.282198, D accuracy: 82.8%, cell accuracy: 94.4%, board accuracy: 1.5% \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.3740, G loss: 2.0905\n",
      "[124/1600] D loss: 0.3954, G loss: 3.6443\n",
      "[244/1600] D loss: 1.1085, G loss: 1.0991\n",
      "[364/1600] D loss: 0.7827, G loss: 2.0156\n",
      "[484/1600] D loss: 0.4595, G loss: 2.9322\n",
      "[604/1600] D loss: 0.5519, G loss: 2.7309\n",
      "[724/1600] D loss: 1.0638, G loss: 1.3365\n",
      "[844/1600] D loss: 0.5406, G loss: 2.4155\n",
      "[964/1600] D loss: 0.8961, G loss: 1.3173\n",
      "[1084/1600] D loss: 0.3992, G loss: 2.4623\n",
      "[1204/1600] D loss: 0.5853, G loss: 3.4165\n",
      "[1324/1600] D loss: 0.3415, G loss: 2.8889\n",
      "[1444/1600] D loss: 0.6042, G loss: 2.4499\n",
      "[1564/1600] D loss: 0.5241, G loss: 1.7276\n",
      "train error: \n",
      " D loss: 0.694896, G loss: 2.352270, D accuracy: 82.8%, cell accuracy: 94.7%, board accuracy: 2.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.692559, G loss: 2.908220, D accuracy: 84.0%, cell accuracy: 94.4%, board accuracy: 1.8% \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8284, G loss: 1.3804\n",
      "[124/1600] D loss: 0.3345, G loss: 2.8290\n",
      "[244/1600] D loss: 0.5215, G loss: 3.0252\n",
      "[364/1600] D loss: 0.0788, G loss: 3.3640\n",
      "[484/1600] D loss: 0.6404, G loss: 2.5180\n",
      "[604/1600] D loss: 0.8395, G loss: 1.6221\n",
      "[724/1600] D loss: 0.5326, G loss: 2.8660\n",
      "[844/1600] D loss: 1.2645, G loss: 1.3463\n",
      "[964/1600] D loss: 0.8071, G loss: 2.7461\n",
      "[1084/1600] D loss: 0.8527, G loss: 1.8403\n",
      "[1204/1600] D loss: 0.4674, G loss: 3.8837\n",
      "[1324/1600] D loss: 0.3215, G loss: 3.7219\n",
      "[1444/1600] D loss: 0.5928, G loss: 2.2968\n",
      "[1564/1600] D loss: 1.2951, G loss: 0.7943\n",
      "train error: \n",
      " D loss: 0.673817, G loss: 2.174190, D accuracy: 83.2%, cell accuracy: 94.8%, board accuracy: 2.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.650092, G loss: 2.707798, D accuracy: 84.8%, cell accuracy: 94.4%, board accuracy: 1.2% \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.3459, G loss: 2.5779\n",
      "[124/1600] D loss: 0.5696, G loss: 2.9790\n",
      "[244/1600] D loss: 0.2230, G loss: 4.0704\n",
      "[364/1600] D loss: 1.0074, G loss: 1.2772\n",
      "[484/1600] D loss: 0.4988, G loss: 1.8788\n",
      "[604/1600] D loss: 0.7055, G loss: 1.7035\n",
      "[724/1600] D loss: 0.7593, G loss: 1.2396\n",
      "[844/1600] D loss: 1.6569, G loss: 1.1483\n",
      "[964/1600] D loss: 0.4118, G loss: 2.3383\n",
      "[1084/1600] D loss: 0.6164, G loss: 2.6747\n",
      "[1204/1600] D loss: 0.3944, G loss: 2.7266\n",
      "[1324/1600] D loss: 0.7406, G loss: 3.4636\n",
      "[1444/1600] D loss: 1.1314, G loss: 2.0821\n",
      "[1564/1600] D loss: 0.5557, G loss: 2.0523\n",
      "train error: \n",
      " D loss: 0.672517, G loss: 2.525140, D accuracy: 83.4%, cell accuracy: 94.7%, board accuracy: 2.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.702841, G loss: 3.059430, D accuracy: 83.4%, cell accuracy: 94.3%, board accuracy: 2.2% \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5617, G loss: 1.6910\n",
      "[124/1600] D loss: 0.4408, G loss: 1.9101\n",
      "[244/1600] D loss: 0.6030, G loss: 2.3621\n",
      "[364/1600] D loss: 0.4765, G loss: 3.0025\n",
      "[484/1600] D loss: 0.2843, G loss: 3.5921\n",
      "[604/1600] D loss: 1.0948, G loss: 0.9245\n",
      "[724/1600] D loss: 0.6895, G loss: 2.4270\n",
      "[844/1600] D loss: 0.7823, G loss: 2.1162\n",
      "[964/1600] D loss: 0.8765, G loss: 1.2211\n",
      "[1084/1600] D loss: 0.6081, G loss: 2.7930\n",
      "[1204/1600] D loss: 0.0956, G loss: 5.8703\n",
      "[1324/1600] D loss: 1.2046, G loss: 2.6214\n",
      "[1444/1600] D loss: 0.3852, G loss: 3.7701\n",
      "[1564/1600] D loss: 0.3832, G loss: 2.6772\n",
      "train error: \n",
      " D loss: 0.664419, G loss: 2.294348, D accuracy: 83.6%, cell accuracy: 94.8%, board accuracy: 2.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.645800, G loss: 2.818836, D accuracy: 85.0%, cell accuracy: 94.4%, board accuracy: 2.5% \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5430, G loss: 2.1710\n",
      "[124/1600] D loss: 0.7098, G loss: 2.0470\n",
      "[244/1600] D loss: 0.2458, G loss: 2.8565\n",
      "[364/1600] D loss: 0.7222, G loss: 3.5814\n",
      "[484/1600] D loss: 0.3345, G loss: 2.9140\n",
      "[604/1600] D loss: 0.2955, G loss: 4.2955\n",
      "[724/1600] D loss: 1.1003, G loss: 2.0406\n",
      "[844/1600] D loss: 0.8007, G loss: 1.2564\n",
      "[964/1600] D loss: 0.7156, G loss: 2.1231\n",
      "[1084/1600] D loss: 0.8246, G loss: 1.7397\n",
      "[1204/1600] D loss: 0.1776, G loss: 3.1276\n",
      "[1324/1600] D loss: 0.3734, G loss: 1.5839\n",
      "[1444/1600] D loss: 0.0738, G loss: 3.4016\n",
      "[1564/1600] D loss: 0.6879, G loss: 3.4197\n",
      "train error: \n",
      " D loss: 0.676893, G loss: 2.473826, D accuracy: 83.4%, cell accuracy: 94.8%, board accuracy: 2.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.668124, G loss: 3.092899, D accuracy: 84.9%, cell accuracy: 94.5%, board accuracy: 2.5% \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3787, G loss: 1.6781\n",
      "[124/1600] D loss: 1.1153, G loss: 2.8615\n",
      "[244/1600] D loss: 0.4843, G loss: 4.1307\n",
      "[364/1600] D loss: 0.9631, G loss: 1.5019\n",
      "[484/1600] D loss: 0.4886, G loss: 1.5754\n",
      "[604/1600] D loss: 0.2961, G loss: 2.9325\n",
      "[724/1600] D loss: 0.9905, G loss: 1.9392\n",
      "[844/1600] D loss: 1.0313, G loss: 2.9552\n",
      "[964/1600] D loss: 0.2324, G loss: 2.7459\n",
      "[1084/1600] D loss: 0.7050, G loss: 1.5439\n",
      "[1204/1600] D loss: 1.0517, G loss: 1.7341\n",
      "[1324/1600] D loss: 1.0786, G loss: 1.3373\n",
      "[1444/1600] D loss: 0.6855, G loss: 2.7809\n",
      "[1564/1600] D loss: 0.7858, G loss: 2.4413\n",
      "train error: \n",
      " D loss: 0.721810, G loss: 2.203341, D accuracy: 81.4%, cell accuracy: 94.7%, board accuracy: 2.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.654926, G loss: 2.803540, D accuracy: 85.4%, cell accuracy: 94.3%, board accuracy: 3.2% \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6908, G loss: 3.6212\n",
      "[124/1600] D loss: 1.3401, G loss: 0.8921\n",
      "[244/1600] D loss: 1.2794, G loss: 1.0351\n",
      "[364/1600] D loss: 1.1896, G loss: 1.2404\n",
      "[484/1600] D loss: 0.3438, G loss: 3.1083\n",
      "[604/1600] D loss: 0.2624, G loss: 2.3060\n",
      "[724/1600] D loss: 0.5308, G loss: 2.5680\n",
      "[844/1600] D loss: 0.6068, G loss: 2.4392\n",
      "[964/1600] D loss: 1.1505, G loss: 0.8328\n",
      "[1084/1600] D loss: 1.2515, G loss: 0.7950\n",
      "[1204/1600] D loss: 0.3798, G loss: 1.9305\n",
      "[1324/1600] D loss: 0.6593, G loss: 2.5768\n",
      "[1444/1600] D loss: 0.3119, G loss: 2.1198\n",
      "[1564/1600] D loss: 0.8585, G loss: 2.0261\n",
      "train error: \n",
      " D loss: 0.720016, G loss: 2.643977, D accuracy: 80.4%, cell accuracy: 94.8%, board accuracy: 2.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.731210, G loss: 3.204381, D accuracy: 80.9%, cell accuracy: 94.4%, board accuracy: 3.2% \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.1081, G loss: 4.5584\n",
      "[124/1600] D loss: 0.6484, G loss: 1.7815\n",
      "[244/1600] D loss: 0.7959, G loss: 2.4776\n",
      "[364/1600] D loss: 1.3633, G loss: 2.7525\n",
      "[484/1600] D loss: 1.0549, G loss: 1.3057\n",
      "[604/1600] D loss: 0.7482, G loss: 1.7696\n",
      "[724/1600] D loss: 0.3885, G loss: 3.0564\n",
      "[844/1600] D loss: 0.3198, G loss: 2.6673\n",
      "[964/1600] D loss: 1.0823, G loss: 1.6257\n",
      "[1084/1600] D loss: 0.6186, G loss: 1.6237\n",
      "[1204/1600] D loss: 0.8617, G loss: 3.2473\n",
      "[1324/1600] D loss: 0.7203, G loss: 4.0512\n",
      "[1444/1600] D loss: 0.0556, G loss: 3.3537\n",
      "[1564/1600] D loss: 0.7965, G loss: 1.7958\n",
      "train error: \n",
      " D loss: 0.668994, G loss: 2.333224, D accuracy: 83.8%, cell accuracy: 94.8%, board accuracy: 1.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.662519, G loss: 2.892482, D accuracy: 84.2%, cell accuracy: 94.4%, board accuracy: 1.8% \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.2811, G loss: 2.4589\n",
      "[124/1600] D loss: 0.2981, G loss: 2.7447\n",
      "[244/1600] D loss: 0.6622, G loss: 2.1808\n",
      "[364/1600] D loss: 0.7952, G loss: 1.6835\n",
      "[484/1600] D loss: 0.8769, G loss: 2.4295\n",
      "[604/1600] D loss: 0.4572, G loss: 3.8149\n",
      "[724/1600] D loss: 1.0240, G loss: 2.1389\n",
      "[844/1600] D loss: 0.7816, G loss: 1.1715\n",
      "[964/1600] D loss: 0.5682, G loss: 1.8038\n",
      "[1084/1600] D loss: 0.6395, G loss: 2.3168\n",
      "[1204/1600] D loss: 0.1368, G loss: 3.6871\n",
      "[1324/1600] D loss: 0.6092, G loss: 3.5083\n",
      "[1444/1600] D loss: 0.7075, G loss: 2.2905\n",
      "[1564/1600] D loss: 1.1438, G loss: 1.1390\n",
      "train error: \n",
      " D loss: 0.663278, G loss: 2.479108, D accuracy: 83.6%, cell accuracy: 94.8%, board accuracy: 2.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.658986, G loss: 3.100176, D accuracy: 83.8%, cell accuracy: 94.4%, board accuracy: 2.2% \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6774, G loss: 1.7579\n",
      "[124/1600] D loss: 1.0568, G loss: 4.0285\n",
      "[244/1600] D loss: 1.5028, G loss: 0.5664\n",
      "[364/1600] D loss: 0.3745, G loss: 3.8777\n",
      "[484/1600] D loss: 0.1569, G loss: 2.8669\n",
      "[604/1600] D loss: 0.3811, G loss: 2.3285\n",
      "[724/1600] D loss: 0.5187, G loss: 3.0818\n",
      "[844/1600] D loss: 0.3045, G loss: 3.9220\n",
      "[964/1600] D loss: 0.3576, G loss: 2.8696\n",
      "[1084/1600] D loss: 1.1761, G loss: 2.8106\n",
      "[1204/1600] D loss: 1.2969, G loss: 1.6278\n",
      "[1324/1600] D loss: 0.3814, G loss: 3.1632\n",
      "[1444/1600] D loss: 0.7604, G loss: 1.4098\n",
      "[1564/1600] D loss: 1.1709, G loss: 2.2573\n",
      "train error: \n",
      " D loss: 0.786732, G loss: 1.926860, D accuracy: 80.3%, cell accuracy: 94.8%, board accuracy: 2.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.693247, G loss: 2.576195, D accuracy: 84.1%, cell accuracy: 94.4%, board accuracy: 3.8% \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0644, G loss: 0.8277\n",
      "[124/1600] D loss: 1.5709, G loss: 1.6088\n",
      "[244/1600] D loss: 0.8547, G loss: 2.4637\n",
      "[364/1600] D loss: 0.9445, G loss: 1.2061\n",
      "[484/1600] D loss: 1.2165, G loss: 1.8995\n",
      "[604/1600] D loss: 0.4047, G loss: 1.8638\n",
      "[724/1600] D loss: 0.5974, G loss: 1.4748\n",
      "[844/1600] D loss: 0.6553, G loss: 1.8664\n",
      "[964/1600] D loss: 0.6994, G loss: 3.1307\n",
      "[1084/1600] D loss: 0.3118, G loss: 2.5430\n",
      "[1204/1600] D loss: 1.0271, G loss: 2.1646\n",
      "[1324/1600] D loss: 0.7376, G loss: 3.6578\n",
      "[1444/1600] D loss: 0.4751, G loss: 3.1577\n",
      "[1564/1600] D loss: 0.3416, G loss: 4.2326\n",
      "train error: \n",
      " D loss: 0.701487, G loss: 2.571907, D accuracy: 81.9%, cell accuracy: 94.8%, board accuracy: 3.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.694413, G loss: 3.230401, D accuracy: 83.5%, cell accuracy: 94.4%, board accuracy: 3.5% \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4048, G loss: 1.5689\n",
      "[124/1600] D loss: 0.3695, G loss: 2.4359\n",
      "[244/1600] D loss: 0.2896, G loss: 2.3895\n",
      "[364/1600] D loss: 0.3802, G loss: 2.0521\n",
      "[484/1600] D loss: 1.0315, G loss: 1.7004\n",
      "[604/1600] D loss: 0.8943, G loss: 2.4932\n",
      "[724/1600] D loss: 0.1110, G loss: 2.7820\n",
      "[844/1600] D loss: 1.1014, G loss: 2.0074\n",
      "[964/1600] D loss: 0.4163, G loss: 2.2508\n",
      "[1084/1600] D loss: 0.4330, G loss: 3.2464\n",
      "[1204/1600] D loss: 0.7807, G loss: 1.7416\n",
      "[1324/1600] D loss: 0.4070, G loss: 3.1935\n",
      "[1444/1600] D loss: 0.1107, G loss: 3.4275\n",
      "[1564/1600] D loss: 1.0149, G loss: 2.2905\n",
      "train error: \n",
      " D loss: 0.688623, G loss: 2.374186, D accuracy: 82.3%, cell accuracy: 94.7%, board accuracy: 2.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.652794, G loss: 3.051868, D accuracy: 85.5%, cell accuracy: 94.3%, board accuracy: 3.5% \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.2768, G loss: 3.7852\n",
      "[124/1600] D loss: 0.2103, G loss: 4.5522\n",
      "[244/1600] D loss: 0.8732, G loss: 1.3748\n",
      "[364/1600] D loss: 0.8968, G loss: 2.6813\n",
      "[484/1600] D loss: 0.7627, G loss: 1.5746\n",
      "[604/1600] D loss: 0.6136, G loss: 3.4288\n",
      "[724/1600] D loss: 0.9870, G loss: 1.0564\n",
      "[844/1600] D loss: 0.3499, G loss: 2.6679\n",
      "[964/1600] D loss: 0.5699, G loss: 1.7745\n",
      "[1084/1600] D loss: 0.9794, G loss: 2.3029\n",
      "[1204/1600] D loss: 1.0061, G loss: 1.9467\n",
      "[1324/1600] D loss: 1.1419, G loss: 1.5622\n",
      "[1444/1600] D loss: 0.3512, G loss: 2.4715\n",
      "[1564/1600] D loss: 0.4334, G loss: 1.6107\n",
      "train error: \n",
      " D loss: 0.661058, G loss: 2.515064, D accuracy: 83.5%, cell accuracy: 94.8%, board accuracy: 2.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.665600, G loss: 3.141674, D accuracy: 83.4%, cell accuracy: 94.5%, board accuracy: 2.8% \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.2633, G loss: 3.7172\n",
      "[124/1600] D loss: 1.2949, G loss: 1.4675\n",
      "[244/1600] D loss: 0.4316, G loss: 2.0420\n",
      "[364/1600] D loss: 0.6608, G loss: 2.4727\n",
      "[484/1600] D loss: 0.8108, G loss: 1.6137\n",
      "[604/1600] D loss: 1.2176, G loss: 3.1858\n",
      "[724/1600] D loss: 0.6244, G loss: 1.6649\n",
      "[844/1600] D loss: 0.9007, G loss: 1.8263\n",
      "[964/1600] D loss: 0.7771, G loss: 0.8478\n",
      "[1084/1600] D loss: 1.0738, G loss: 3.2666\n",
      "[1204/1600] D loss: 0.4460, G loss: 2.4368\n",
      "[1324/1600] D loss: 0.7742, G loss: 1.9308\n",
      "[1444/1600] D loss: 0.8191, G loss: 2.1608\n",
      "[1564/1600] D loss: 0.6133, G loss: 1.0513\n",
      "train error: \n",
      " D loss: 0.785742, G loss: 3.064330, D accuracy: 80.7%, cell accuracy: 94.7%, board accuracy: 2.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.825544, G loss: 3.698075, D accuracy: 79.5%, cell accuracy: 94.2%, board accuracy: 2.0% \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5566, G loss: 3.2211\n",
      "[124/1600] D loss: 1.3626, G loss: 2.3373\n",
      "[244/1600] D loss: 0.1789, G loss: 4.4144\n",
      "[364/1600] D loss: 0.5561, G loss: 3.1086\n",
      "[484/1600] D loss: 0.4313, G loss: 2.5920\n",
      "[604/1600] D loss: 0.7968, G loss: 2.2073\n",
      "[724/1600] D loss: 0.7928, G loss: 1.7191\n",
      "[844/1600] D loss: 0.7156, G loss: 2.9273\n",
      "[964/1600] D loss: 0.7611, G loss: 1.8583\n",
      "[1084/1600] D loss: 0.3645, G loss: 3.2116\n",
      "[1204/1600] D loss: 0.5964, G loss: 2.7658\n",
      "[1324/1600] D loss: 0.5213, G loss: 3.6956\n",
      "[1444/1600] D loss: 0.7963, G loss: 2.0918\n",
      "[1564/1600] D loss: 0.7867, G loss: 1.6418\n",
      "train error: \n",
      " D loss: 0.676350, G loss: 2.538654, D accuracy: 82.7%, cell accuracy: 94.8%, board accuracy: 2.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.680041, G loss: 3.240544, D accuracy: 83.1%, cell accuracy: 94.5%, board accuracy: 2.5% \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5647, G loss: 1.6030\n",
      "[124/1600] D loss: 1.0060, G loss: 1.2043\n",
      "[244/1600] D loss: 1.4246, G loss: 0.9749\n",
      "[364/1600] D loss: 0.4031, G loss: 3.5801\n",
      "[484/1600] D loss: 0.9447, G loss: 1.6196\n",
      "[604/1600] D loss: 0.9330, G loss: 1.2681\n",
      "[724/1600] D loss: 1.3844, G loss: 1.9554\n",
      "[844/1600] D loss: 0.5237, G loss: 3.0906\n",
      "[964/1600] D loss: 0.5618, G loss: 1.9992\n",
      "[1084/1600] D loss: 0.6137, G loss: 2.1763\n",
      "[1204/1600] D loss: 0.3036, G loss: 5.7635\n",
      "[1324/1600] D loss: 0.5251, G loss: 2.1613\n",
      "[1444/1600] D loss: 0.5491, G loss: 2.0328\n",
      "[1564/1600] D loss: 1.1653, G loss: 1.0891\n",
      "train error: \n",
      " D loss: 0.695481, G loss: 2.657688, D accuracy: 81.7%, cell accuracy: 94.8%, board accuracy: 2.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.714199, G loss: 3.273987, D accuracy: 82.4%, cell accuracy: 94.4%, board accuracy: 3.0% \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4753, G loss: 1.8562\n",
      "[124/1600] D loss: 1.3590, G loss: 1.8069\n",
      "[244/1600] D loss: 0.2827, G loss: 4.7580\n",
      "[364/1600] D loss: 0.3952, G loss: 1.4151\n",
      "[484/1600] D loss: 0.6877, G loss: 2.3008\n",
      "[604/1600] D loss: 0.7218, G loss: 2.6396\n",
      "[724/1600] D loss: 1.0996, G loss: 1.7658\n",
      "[844/1600] D loss: 0.9246, G loss: 1.7763\n",
      "[964/1600] D loss: 1.1893, G loss: 0.9367\n",
      "[1084/1600] D loss: 0.5107, G loss: 2.5731\n",
      "[1204/1600] D loss: 0.5562, G loss: 2.9830\n",
      "[1324/1600] D loss: 0.1758, G loss: 5.0093\n",
      "[1444/1600] D loss: 0.6162, G loss: 1.6579\n",
      "[1564/1600] D loss: 0.4581, G loss: 2.9111\n",
      "train error: \n",
      " D loss: 0.645698, G loss: 2.375545, D accuracy: 83.9%, cell accuracy: 94.7%, board accuracy: 2.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.605217, G loss: 3.127839, D accuracy: 85.6%, cell accuracy: 94.4%, board accuracy: 3.0% \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3916, G loss: 1.8320\n",
      "[124/1600] D loss: 0.3881, G loss: 3.0569\n",
      "[244/1600] D loss: 0.1303, G loss: 4.0260\n",
      "[364/1600] D loss: 0.9070, G loss: 0.9757\n",
      "[484/1600] D loss: 0.5537, G loss: 5.6087\n",
      "[604/1600] D loss: 0.6314, G loss: 2.4524\n",
      "[724/1600] D loss: 0.2358, G loss: 3.9979\n",
      "[844/1600] D loss: 0.2965, G loss: 2.7402\n",
      "[964/1600] D loss: 0.6746, G loss: 3.7719\n",
      "[1084/1600] D loss: 0.0455, G loss: 4.2778\n",
      "[1204/1600] D loss: 1.3605, G loss: 1.2166\n",
      "[1324/1600] D loss: 0.4332, G loss: 3.7112\n",
      "[1444/1600] D loss: 0.2645, G loss: 4.0882\n",
      "[1564/1600] D loss: 0.4088, G loss: 2.8324\n",
      "train error: \n",
      " D loss: 0.633220, G loss: 2.316405, D accuracy: 84.3%, cell accuracy: 94.8%, board accuracy: 3.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.599094, G loss: 3.036427, D accuracy: 85.9%, cell accuracy: 94.4%, board accuracy: 4.0% \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.2587, G loss: 3.1527\n",
      "[124/1600] D loss: 1.0488, G loss: 1.3485\n",
      "[244/1600] D loss: 1.1722, G loss: 1.5241\n",
      "[364/1600] D loss: 0.8060, G loss: 2.1826\n",
      "[484/1600] D loss: 0.7413, G loss: 1.6259\n",
      "[604/1600] D loss: 1.0803, G loss: 0.8180\n",
      "[724/1600] D loss: 0.6740, G loss: 2.9048\n",
      "[844/1600] D loss: 0.6311, G loss: 2.3723\n",
      "[964/1600] D loss: 0.1896, G loss: 3.4631\n",
      "[1084/1600] D loss: 0.6982, G loss: 2.5374\n",
      "[1204/1600] D loss: 0.4448, G loss: 4.1500\n",
      "[1324/1600] D loss: 0.6315, G loss: 1.5682\n",
      "[1444/1600] D loss: 0.6134, G loss: 3.1663\n",
      "[1564/1600] D loss: 0.6325, G loss: 2.4935\n",
      "train error: \n",
      " D loss: 0.823759, G loss: 3.039339, D accuracy: 78.7%, cell accuracy: 94.9%, board accuracy: 3.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.866920, G loss: 3.705913, D accuracy: 78.2%, cell accuracy: 94.6%, board accuracy: 4.0% \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7977, G loss: 2.5232\n",
      "[124/1600] D loss: 0.7947, G loss: 2.4417\n",
      "[244/1600] D loss: 0.9927, G loss: 1.0507\n",
      "[364/1600] D loss: 0.5750, G loss: 2.2724\n",
      "[484/1600] D loss: 0.0668, G loss: 3.0645\n",
      "[604/1600] D loss: 0.9266, G loss: 1.6784\n",
      "[724/1600] D loss: 0.8619, G loss: 1.6651\n",
      "[844/1600] D loss: 0.7144, G loss: 1.9537\n",
      "[964/1600] D loss: 0.7619, G loss: 1.8199\n",
      "[1084/1600] D loss: 1.1523, G loss: 0.6212\n",
      "[1204/1600] D loss: 0.4890, G loss: 2.1930\n",
      "[1324/1600] D loss: 0.9509, G loss: 2.6481\n",
      "[1444/1600] D loss: 0.8501, G loss: 2.3990\n",
      "[1564/1600] D loss: 0.3022, G loss: 3.0804\n",
      "train error: \n",
      " D loss: 0.659632, G loss: 2.267074, D accuracy: 83.3%, cell accuracy: 94.8%, board accuracy: 4.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.609946, G loss: 2.926107, D accuracy: 85.9%, cell accuracy: 94.4%, board accuracy: 4.2% \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.3192, G loss: 2.2406\n",
      "[124/1600] D loss: 0.2705, G loss: 3.6554\n",
      "[244/1600] D loss: 0.2661, G loss: 3.4132\n",
      "[364/1600] D loss: 0.5593, G loss: 1.9362\n",
      "[484/1600] D loss: 0.4004, G loss: 2.8513\n",
      "[604/1600] D loss: 0.6631, G loss: 1.8526\n",
      "[724/1600] D loss: 0.5549, G loss: 2.2129\n",
      "[844/1600] D loss: 0.2636, G loss: 3.9203\n",
      "[964/1600] D loss: 0.8501, G loss: 2.3530\n",
      "[1084/1600] D loss: 0.5021, G loss: 2.6348\n",
      "[1204/1600] D loss: 0.8485, G loss: 2.3564\n",
      "[1324/1600] D loss: 1.0858, G loss: 1.9004\n",
      "[1444/1600] D loss: 0.5154, G loss: 2.3164\n",
      "[1564/1600] D loss: 0.3869, G loss: 2.4316\n",
      "train error: \n",
      " D loss: 0.705769, G loss: 3.016299, D accuracy: 81.5%, cell accuracy: 94.8%, board accuracy: 3.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.730785, G loss: 3.769420, D accuracy: 81.1%, cell accuracy: 94.5%, board accuracy: 3.0% \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4507, G loss: 5.4104\n",
      "[124/1600] D loss: 1.0932, G loss: 2.8906\n",
      "[244/1600] D loss: 1.6419, G loss: 1.2812\n",
      "[364/1600] D loss: 0.9365, G loss: 1.7200\n",
      "[484/1600] D loss: 1.3150, G loss: 1.0281\n",
      "[604/1600] D loss: 0.0262, G loss: 4.7754\n",
      "[724/1600] D loss: 0.3764, G loss: 1.9314\n",
      "[844/1600] D loss: 1.1053, G loss: 2.4643\n",
      "[964/1600] D loss: 0.1893, G loss: 3.8140\n",
      "[1084/1600] D loss: 0.7274, G loss: 2.9959\n",
      "[1204/1600] D loss: 0.6513, G loss: 3.0490\n",
      "[1324/1600] D loss: 0.9522, G loss: 1.0973\n",
      "[1444/1600] D loss: 0.6765, G loss: 2.2786\n",
      "[1564/1600] D loss: 0.9367, G loss: 2.0774\n",
      "train error: \n",
      " D loss: 0.644948, G loss: 2.301564, D accuracy: 84.1%, cell accuracy: 94.8%, board accuracy: 3.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.617877, G loss: 3.001901, D accuracy: 84.9%, cell accuracy: 94.4%, board accuracy: 4.0% \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6114, G loss: 1.7725\n",
      "[124/1600] D loss: 0.6232, G loss: 2.0974\n",
      "[244/1600] D loss: 0.3198, G loss: 3.7209\n",
      "[364/1600] D loss: 0.4772, G loss: 1.8282\n",
      "[484/1600] D loss: 0.4293, G loss: 3.3408\n",
      "[604/1600] D loss: 0.3279, G loss: 3.5618\n",
      "[724/1600] D loss: 1.1103, G loss: 1.7004\n",
      "[844/1600] D loss: 0.5763, G loss: 3.5716\n",
      "[964/1600] D loss: 1.0651, G loss: 1.1817\n",
      "[1084/1600] D loss: 0.8425, G loss: 1.4814\n",
      "[1204/1600] D loss: 0.7952, G loss: 0.9116\n",
      "[1324/1600] D loss: 0.5135, G loss: 3.5343\n",
      "[1444/1600] D loss: 0.5581, G loss: 1.9610\n",
      "[1564/1600] D loss: 0.8207, G loss: 2.1657\n",
      "train error: \n",
      " D loss: 0.692536, G loss: 2.078780, D accuracy: 81.7%, cell accuracy: 94.8%, board accuracy: 3.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.594165, G loss: 2.801495, D accuracy: 87.1%, cell accuracy: 94.5%, board accuracy: 3.8% \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.3519, G loss: 2.7022\n",
      "[124/1600] D loss: 1.0389, G loss: 1.1667\n",
      "[244/1600] D loss: 0.0536, G loss: 4.0554\n",
      "[364/1600] D loss: 0.5376, G loss: 1.3122\n",
      "[484/1600] D loss: 0.7910, G loss: 2.4725\n",
      "[604/1600] D loss: 1.0912, G loss: 2.7269\n",
      "[724/1600] D loss: 0.2902, G loss: 3.9862\n",
      "[844/1600] D loss: 1.1895, G loss: 2.1368\n",
      "[964/1600] D loss: 0.5828, G loss: 2.4889\n",
      "[1084/1600] D loss: 0.2035, G loss: 3.7312\n",
      "[1204/1600] D loss: 1.0352, G loss: 1.4290\n",
      "[1324/1600] D loss: 0.9160, G loss: 1.1034\n",
      "[1444/1600] D loss: 0.0109, G loss: 5.8629\n",
      "[1564/1600] D loss: 0.2680, G loss: 1.8882\n",
      "train error: \n",
      " D loss: 0.626739, G loss: 2.378570, D accuracy: 84.8%, cell accuracy: 94.7%, board accuracy: 4.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.606974, G loss: 3.051064, D accuracy: 87.2%, cell accuracy: 94.3%, board accuracy: 4.2% \n",
      "\n",
      "Epoch 111\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6902, G loss: 3.3932\n",
      "[124/1600] D loss: 0.4760, G loss: 1.9658\n",
      "[244/1600] D loss: 0.5176, G loss: 2.6176\n",
      "[364/1600] D loss: 1.0994, G loss: 1.3619\n",
      "[484/1600] D loss: 1.4023, G loss: 1.9965\n",
      "[604/1600] D loss: 0.2793, G loss: 3.5279\n",
      "[724/1600] D loss: 0.7788, G loss: 1.4859\n",
      "[844/1600] D loss: 0.3389, G loss: 3.0482\n",
      "[964/1600] D loss: 0.3261, G loss: 2.2442\n",
      "[1084/1600] D loss: 0.7010, G loss: 1.8053\n",
      "[1204/1600] D loss: 1.1566, G loss: 2.0453\n",
      "[1324/1600] D loss: 0.4678, G loss: 3.2192\n",
      "[1444/1600] D loss: 0.4312, G loss: 2.3678\n",
      "[1564/1600] D loss: 0.2144, G loss: 3.0673\n",
      "train error: \n",
      " D loss: 0.660082, G loss: 2.560250, D accuracy: 83.1%, cell accuracy: 94.9%, board accuracy: 4.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.640191, G loss: 3.326468, D accuracy: 85.2%, cell accuracy: 94.6%, board accuracy: 2.5% \n",
      "\n",
      "Epoch 112\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.1676, G loss: 3.8802\n",
      "[124/1600] D loss: 0.5012, G loss: 2.5479\n",
      "[244/1600] D loss: 0.2533, G loss: 2.9574\n",
      "[364/1600] D loss: 1.1452, G loss: 1.5010\n",
      "[484/1600] D loss: 0.7402, G loss: 2.5914\n",
      "[604/1600] D loss: 0.9398, G loss: 2.2105\n",
      "[724/1600] D loss: 0.4664, G loss: 2.1637\n",
      "[844/1600] D loss: 0.3339, G loss: 2.7393\n",
      "[964/1600] D loss: 0.7566, G loss: 1.8446\n",
      "[1084/1600] D loss: 0.2163, G loss: 3.5564\n",
      "[1204/1600] D loss: 0.6367, G loss: 2.4946\n",
      "[1324/1600] D loss: 0.3720, G loss: 2.1232\n",
      "[1444/1600] D loss: 0.6905, G loss: 2.4326\n",
      "[1564/1600] D loss: 0.4046, G loss: 2.7775\n",
      "train error: \n",
      " D loss: 0.646416, G loss: 2.747255, D accuracy: 83.6%, cell accuracy: 94.8%, board accuracy: 4.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.659127, G loss: 3.449067, D accuracy: 83.6%, cell accuracy: 94.4%, board accuracy: 4.2% \n",
      "\n",
      "Epoch 113\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0944, G loss: 1.1577\n",
      "[124/1600] D loss: 0.4315, G loss: 3.7431\n",
      "[244/1600] D loss: 0.6526, G loss: 2.1782\n",
      "[364/1600] D loss: 0.5998, G loss: 2.1405\n",
      "[484/1600] D loss: 0.9222, G loss: 0.7860\n",
      "[604/1600] D loss: 0.3234, G loss: 2.0176\n",
      "[724/1600] D loss: 0.8735, G loss: 3.8427\n",
      "[844/1600] D loss: 0.4856, G loss: 2.5689\n",
      "[964/1600] D loss: 0.5578, G loss: 1.9004\n",
      "[1084/1600] D loss: 0.9400, G loss: 2.6641\n",
      "[1204/1600] D loss: 0.2943, G loss: 4.0303\n",
      "[1324/1600] D loss: 0.5237, G loss: 2.8631\n",
      "[1444/1600] D loss: 0.6037, G loss: 1.9996\n",
      "[1564/1600] D loss: 0.2850, G loss: 3.2100\n",
      "train error: \n",
      " D loss: 0.719339, G loss: 2.947258, D accuracy: 82.1%, cell accuracy: 94.8%, board accuracy: 3.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.752152, G loss: 3.664255, D accuracy: 83.2%, cell accuracy: 94.5%, board accuracy: 4.0% \n",
      "\n",
      "Epoch 114\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5755, G loss: 4.0788\n",
      "[124/1600] D loss: 0.1309, G loss: 3.1760\n",
      "[244/1600] D loss: 0.0435, G loss: 4.2878\n",
      "[364/1600] D loss: 0.0973, G loss: 5.7483\n",
      "[484/1600] D loss: 0.9323, G loss: 3.0329\n",
      "[604/1600] D loss: 0.2867, G loss: 2.5973\n",
      "[724/1600] D loss: 0.9274, G loss: 1.4418\n",
      "[844/1600] D loss: 0.9022, G loss: 1.5544\n",
      "[964/1600] D loss: 0.4983, G loss: 2.7905\n",
      "[1084/1600] D loss: 0.6740, G loss: 2.3093\n",
      "[1204/1600] D loss: 0.5687, G loss: 2.4579\n",
      "[1324/1600] D loss: 0.2182, G loss: 4.1402\n",
      "[1444/1600] D loss: 0.4475, G loss: 2.2655\n",
      "[1564/1600] D loss: 1.0964, G loss: 1.3393\n",
      "train error: \n",
      " D loss: 0.821301, G loss: 1.894747, D accuracy: 79.8%, cell accuracy: 94.8%, board accuracy: 3.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.682058, G loss: 2.642821, D accuracy: 83.9%, cell accuracy: 94.4%, board accuracy: 3.8% \n",
      "\n",
      "Epoch 115\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9157, G loss: 1.4063\n",
      "[124/1600] D loss: 0.5402, G loss: 3.2144\n",
      "[244/1600] D loss: 0.6388, G loss: 1.7064\n",
      "[364/1600] D loss: 0.5925, G loss: 4.0525\n",
      "[484/1600] D loss: 0.5860, G loss: 2.1995\n",
      "[604/1600] D loss: 0.4255, G loss: 2.8870\n",
      "[724/1600] D loss: 0.4045, G loss: 4.5887\n",
      "[844/1600] D loss: 0.3895, G loss: 3.1686\n",
      "[964/1600] D loss: 0.1651, G loss: 3.0506\n",
      "[1084/1600] D loss: 0.9707, G loss: 1.2042\n",
      "[1204/1600] D loss: 0.1839, G loss: 4.5335\n",
      "[1324/1600] D loss: 0.3669, G loss: 2.9426\n",
      "[1444/1600] D loss: 0.7792, G loss: 1.2093\n",
      "[1564/1600] D loss: 0.5860, G loss: 2.1994\n",
      "train error: \n",
      " D loss: 0.615897, G loss: 2.272675, D accuracy: 84.8%, cell accuracy: 94.8%, board accuracy: 3.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.568197, G loss: 3.073880, D accuracy: 86.8%, cell accuracy: 94.5%, board accuracy: 3.8% \n",
      "\n",
      "Epoch 116\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.1366, G loss: 2.2732\n",
      "[124/1600] D loss: 0.9165, G loss: 2.4269\n",
      "[244/1600] D loss: 0.5731, G loss: 3.1711\n",
      "[364/1600] D loss: 0.5936, G loss: 3.5563\n",
      "[484/1600] D loss: 0.7307, G loss: 1.8165\n",
      "[604/1600] D loss: 0.2959, G loss: 4.6086\n",
      "[724/1600] D loss: 0.8664, G loss: 1.3870\n",
      "[844/1600] D loss: 1.0177, G loss: 1.5877\n",
      "[964/1600] D loss: 0.6463, G loss: 3.4780\n",
      "[1084/1600] D loss: 0.3407, G loss: 4.8864\n",
      "[1204/1600] D loss: 0.7387, G loss: 1.2090\n",
      "[1324/1600] D loss: 0.6079, G loss: 2.3254\n",
      "[1444/1600] D loss: 0.6618, G loss: 1.8933\n",
      "[1564/1600] D loss: 0.4844, G loss: 2.6277\n",
      "train error: \n",
      " D loss: 0.643061, G loss: 2.664012, D accuracy: 83.8%, cell accuracy: 94.8%, board accuracy: 2.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.647074, G loss: 3.408737, D accuracy: 84.5%, cell accuracy: 94.4%, board accuracy: 3.0% \n",
      "\n",
      "Epoch 117\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4996, G loss: 1.9037\n",
      "[124/1600] D loss: 0.1518, G loss: 4.1829\n",
      "[244/1600] D loss: 0.7465, G loss: 2.7169\n",
      "[364/1600] D loss: 0.6174, G loss: 1.8952\n",
      "[484/1600] D loss: 0.7879, G loss: 2.6462\n",
      "[604/1600] D loss: 0.0182, G loss: 5.0553\n",
      "[724/1600] D loss: 0.6175, G loss: 2.1476\n",
      "[844/1600] D loss: 0.2436, G loss: 2.8529\n",
      "[964/1600] D loss: 0.0803, G loss: 3.8221\n",
      "[1084/1600] D loss: 0.8690, G loss: 2.2679\n",
      "[1204/1600] D loss: 0.5450, G loss: 2.9056\n",
      "[1324/1600] D loss: 0.6061, G loss: 1.8558\n",
      "[1444/1600] D loss: 1.2850, G loss: 0.8537\n",
      "[1564/1600] D loss: 1.1969, G loss: 1.6042\n",
      "train error: \n",
      " D loss: 0.609548, G loss: 2.754909, D accuracy: 84.9%, cell accuracy: 94.8%, board accuracy: 4.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.628179, G loss: 3.595540, D accuracy: 84.0%, cell accuracy: 94.4%, board accuracy: 4.0% \n",
      "\n",
      "Epoch 118\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.2919, G loss: 2.2534\n",
      "[124/1600] D loss: 0.7873, G loss: 2.3670\n",
      "[244/1600] D loss: 0.7686, G loss: 2.5632\n",
      "[364/1600] D loss: 0.7536, G loss: 1.4819\n",
      "[484/1600] D loss: 0.8945, G loss: 2.1467\n",
      "[604/1600] D loss: 0.7587, G loss: 1.4402\n",
      "[724/1600] D loss: 0.8993, G loss: 2.0042\n",
      "[844/1600] D loss: 0.9797, G loss: 1.7498\n",
      "[964/1600] D loss: 0.5453, G loss: 2.6679\n",
      "[1084/1600] D loss: 0.7273, G loss: 3.1460\n",
      "[1204/1600] D loss: 1.3212, G loss: 1.4919\n",
      "[1324/1600] D loss: 0.2750, G loss: 4.7035\n",
      "[1444/1600] D loss: 0.4256, G loss: 2.8181\n",
      "[1564/1600] D loss: 0.4600, G loss: 2.3017\n",
      "train error: \n",
      " D loss: 0.630764, G loss: 2.195982, D accuracy: 83.9%, cell accuracy: 94.8%, board accuracy: 4.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.573518, G loss: 2.969378, D accuracy: 87.0%, cell accuracy: 94.4%, board accuracy: 4.0% \n",
      "\n",
      "Epoch 119\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5063, G loss: 2.4895\n",
      "[124/1600] D loss: 0.7087, G loss: 3.0753\n",
      "[244/1600] D loss: 0.6494, G loss: 2.8512\n",
      "[364/1600] D loss: 1.2738, G loss: 0.8429\n",
      "[484/1600] D loss: 0.4679, G loss: 2.9975\n",
      "[604/1600] D loss: 0.1885, G loss: 3.5322\n",
      "[724/1600] D loss: 0.1310, G loss: 3.7860\n",
      "[844/1600] D loss: 0.7781, G loss: 2.0611\n",
      "[964/1600] D loss: 0.5539, G loss: 2.6692\n",
      "[1084/1600] D loss: 0.1144, G loss: 3.2356\n",
      "[1204/1600] D loss: 0.3853, G loss: 2.6187\n",
      "[1324/1600] D loss: 0.9512, G loss: 2.3819\n",
      "[1444/1600] D loss: 0.5068, G loss: 2.6657\n",
      "[1564/1600] D loss: 0.1887, G loss: 3.0908\n",
      "train error: \n",
      " D loss: 0.636718, G loss: 2.234032, D accuracy: 84.8%, cell accuracy: 94.8%, board accuracy: 3.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.564760, G loss: 3.055491, D accuracy: 86.5%, cell accuracy: 94.5%, board accuracy: 2.2% \n",
      "\n",
      "Epoch 120\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.5283, G loss: 0.7232\n",
      "[124/1600] D loss: 0.5577, G loss: 3.1773\n",
      "[244/1600] D loss: 0.2644, G loss: 3.8124\n",
      "[364/1600] D loss: 0.6045, G loss: 1.1784\n",
      "[484/1600] D loss: 0.4683, G loss: 5.2628\n",
      "[604/1600] D loss: 0.9908, G loss: 1.9046\n",
      "[724/1600] D loss: 0.5492, G loss: 3.5595\n",
      "[844/1600] D loss: 1.2508, G loss: 0.7834\n",
      "[964/1600] D loss: 0.3110, G loss: 3.7972\n",
      "[1084/1600] D loss: 1.2191, G loss: 1.2455\n",
      "[1204/1600] D loss: 0.6522, G loss: 3.2233\n",
      "[1324/1600] D loss: 0.6170, G loss: 3.1161\n",
      "[1444/1600] D loss: 0.8549, G loss: 2.1568\n",
      "[1564/1600] D loss: 0.5928, G loss: 2.6079\n",
      "train error: \n",
      " D loss: 0.636557, G loss: 2.591999, D accuracy: 84.0%, cell accuracy: 94.9%, board accuracy: 3.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.626396, G loss: 3.443169, D accuracy: 85.1%, cell accuracy: 94.5%, board accuracy: 2.8% \n",
      "\n",
      "Epoch 121\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9478, G loss: 1.9092\n",
      "[124/1600] D loss: 0.2005, G loss: 3.7896\n",
      "[244/1600] D loss: 0.2301, G loss: 2.6646\n",
      "[364/1600] D loss: 0.2550, G loss: 3.2015\n",
      "[484/1600] D loss: 0.2055, G loss: 3.6548\n",
      "[604/1600] D loss: 0.7338, G loss: 2.9218\n",
      "[724/1600] D loss: 0.5192, G loss: 1.7099\n",
      "[844/1600] D loss: 0.1667, G loss: 3.3206\n",
      "[964/1600] D loss: 0.2882, G loss: 2.9182\n",
      "[1084/1600] D loss: 0.3744, G loss: 4.4279\n",
      "[1204/1600] D loss: 0.4295, G loss: 4.0443\n",
      "[1324/1600] D loss: 0.0406, G loss: 4.7693\n",
      "[1444/1600] D loss: 0.7113, G loss: 2.7033\n",
      "[1564/1600] D loss: 0.3844, G loss: 3.5931\n",
      "train error: \n",
      " D loss: 0.623793, G loss: 2.754337, D accuracy: 85.4%, cell accuracy: 94.9%, board accuracy: 3.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.612731, G loss: 3.621286, D accuracy: 86.0%, cell accuracy: 94.5%, board accuracy: 2.2% \n",
      "\n",
      "Epoch 122\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.1978, G loss: 4.3855\n",
      "[124/1600] D loss: 0.8985, G loss: 1.8158\n",
      "[244/1600] D loss: 0.6727, G loss: 1.8983\n",
      "[364/1600] D loss: 0.1834, G loss: 3.9174\n",
      "[484/1600] D loss: 0.5100, G loss: 3.5576\n",
      "[604/1600] D loss: 1.3690, G loss: 0.7777\n",
      "[724/1600] D loss: 0.6062, G loss: 1.4613\n",
      "[844/1600] D loss: 1.3214, G loss: 1.8346\n",
      "[964/1600] D loss: 0.8803, G loss: 1.3769\n",
      "[1084/1600] D loss: 0.5567, G loss: 1.6983\n",
      "[1204/1600] D loss: 1.5311, G loss: 2.2525\n",
      "[1324/1600] D loss: 0.3850, G loss: 3.2186\n",
      "[1444/1600] D loss: 0.4377, G loss: 2.5676\n",
      "[1564/1600] D loss: 1.5063, G loss: 3.4639\n",
      "train error: \n",
      " D loss: 0.691131, G loss: 2.209626, D accuracy: 82.1%, cell accuracy: 94.9%, board accuracy: 4.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.608662, G loss: 3.081552, D accuracy: 85.5%, cell accuracy: 94.5%, board accuracy: 3.0% \n",
      "\n",
      "Epoch 123\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2437, G loss: 0.8004\n",
      "[124/1600] D loss: 0.8162, G loss: 1.4444\n",
      "[244/1600] D loss: 0.3967, G loss: 2.6989\n",
      "[364/1600] D loss: 0.7911, G loss: 2.4096\n",
      "[484/1600] D loss: 0.4547, G loss: 3.1845\n",
      "[604/1600] D loss: 0.1856, G loss: 2.9672\n",
      "[724/1600] D loss: 0.3046, G loss: 2.1731\n",
      "[844/1600] D loss: 0.5517, G loss: 1.7664\n",
      "[964/1600] D loss: 0.6718, G loss: 2.9922\n",
      "[1084/1600] D loss: 0.1216, G loss: 3.5043\n",
      "[1204/1600] D loss: 0.9272, G loss: 1.9046\n",
      "[1324/1600] D loss: 1.3297, G loss: 0.8253\n",
      "[1444/1600] D loss: 0.5434, G loss: 2.7503\n",
      "[1564/1600] D loss: 0.4524, G loss: 3.4917\n",
      "train error: \n",
      " D loss: 0.605881, G loss: 2.596691, D accuracy: 85.3%, cell accuracy: 94.9%, board accuracy: 3.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.598006, G loss: 3.536235, D accuracy: 86.1%, cell accuracy: 94.6%, board accuracy: 3.0% \n",
      "\n",
      "Epoch 124\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.5712, G loss: 0.7872\n",
      "[124/1600] D loss: 0.7993, G loss: 2.9470\n",
      "[244/1600] D loss: 0.5330, G loss: 1.1760\n",
      "[364/1600] D loss: 0.0962, G loss: 4.9640\n",
      "[484/1600] D loss: 0.7559, G loss: 1.4231\n",
      "[604/1600] D loss: 1.2451, G loss: 2.3303\n",
      "[724/1600] D loss: 0.4296, G loss: 4.5387\n",
      "[844/1600] D loss: 0.3845, G loss: 3.2946\n",
      "[964/1600] D loss: 0.3907, G loss: 2.8734\n",
      "[1084/1600] D loss: 0.6753, G loss: 3.2151\n",
      "[1204/1600] D loss: 0.5016, G loss: 2.2300\n",
      "[1324/1600] D loss: 0.5662, G loss: 4.3843\n",
      "[1444/1600] D loss: 0.4144, G loss: 3.3646\n",
      "[1564/1600] D loss: 0.3110, G loss: 3.5409\n",
      "train error: \n",
      " D loss: 0.611374, G loss: 2.840508, D accuracy: 84.6%, cell accuracy: 94.9%, board accuracy: 3.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.622199, G loss: 3.783132, D accuracy: 85.0%, cell accuracy: 94.5%, board accuracy: 2.8% \n",
      "\n",
      "Epoch 125\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9091, G loss: 1.7232\n",
      "[124/1600] D loss: 0.6245, G loss: 1.9781\n",
      "[244/1600] D loss: 0.1796, G loss: 3.4409\n",
      "[364/1600] D loss: 0.4857, G loss: 2.9260\n",
      "[484/1600] D loss: 1.5184, G loss: 2.0699\n",
      "[604/1600] D loss: 0.1814, G loss: 2.3116\n",
      "[724/1600] D loss: 1.2448, G loss: 1.8794\n",
      "[844/1600] D loss: 0.2994, G loss: 3.4712\n",
      "[964/1600] D loss: 0.3162, G loss: 3.4929\n",
      "[1084/1600] D loss: 0.9500, G loss: 1.1208\n",
      "[1204/1600] D loss: 0.9250, G loss: 2.4570\n",
      "[1324/1600] D loss: 0.8781, G loss: 2.1256\n",
      "[1444/1600] D loss: 1.4808, G loss: 3.6563\n",
      "[1564/1600] D loss: 0.5342, G loss: 2.4841\n",
      "train error: \n",
      " D loss: 0.615767, G loss: 2.380453, D accuracy: 84.2%, cell accuracy: 94.9%, board accuracy: 3.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.547126, G loss: 3.366528, D accuracy: 86.6%, cell accuracy: 94.5%, board accuracy: 2.8% \n",
      "\n",
      "Epoch 126\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8767, G loss: 1.2417\n",
      "[124/1600] D loss: 0.6178, G loss: 1.3103\n",
      "[244/1600] D loss: 0.5200, G loss: 2.7185\n",
      "[364/1600] D loss: 0.9122, G loss: 1.8137\n",
      "[484/1600] D loss: 0.5976, G loss: 2.2493\n",
      "[604/1600] D loss: 0.4760, G loss: 2.8450\n",
      "[724/1600] D loss: 0.0565, G loss: 4.3290\n",
      "[844/1600] D loss: 0.3711, G loss: 3.7114\n",
      "[964/1600] D loss: 0.5815, G loss: 2.6508\n",
      "[1084/1600] D loss: 0.9466, G loss: 2.9294\n",
      "[1204/1600] D loss: 0.9719, G loss: 0.8333\n",
      "[1324/1600] D loss: 1.1824, G loss: 2.9089\n",
      "[1444/1600] D loss: 1.0508, G loss: 0.9303\n",
      "[1564/1600] D loss: 1.0391, G loss: 2.8331\n",
      "train error: \n",
      " D loss: 0.681577, G loss: 2.962315, D accuracy: 82.0%, cell accuracy: 95.0%, board accuracy: 3.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.692548, G loss: 3.884117, D accuracy: 82.8%, cell accuracy: 94.5%, board accuracy: 3.0% \n",
      "\n",
      "Epoch 127\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.2788, G loss: 3.4714\n",
      "[124/1600] D loss: 0.0868, G loss: 3.7528\n",
      "[244/1600] D loss: 0.8625, G loss: 1.4260\n",
      "[364/1600] D loss: 1.0337, G loss: 0.7773\n",
      "[484/1600] D loss: 0.6831, G loss: 2.7153\n",
      "[604/1600] D loss: 0.9038, G loss: 2.5754\n",
      "[724/1600] D loss: 0.3311, G loss: 3.3464\n",
      "[844/1600] D loss: 0.1470, G loss: 4.6700\n",
      "[964/1600] D loss: 0.5596, G loss: 3.1381\n",
      "[1084/1600] D loss: 0.4465, G loss: 1.6478\n",
      "[1204/1600] D loss: 0.7731, G loss: 2.8438\n",
      "[1324/1600] D loss: 0.1672, G loss: 3.8123\n",
      "[1444/1600] D loss: 0.6092, G loss: 2.3426\n",
      "[1564/1600] D loss: 1.3126, G loss: 2.4703\n",
      "train error: \n",
      " D loss: 0.653484, G loss: 2.191200, D accuracy: 82.8%, cell accuracy: 95.0%, board accuracy: 3.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.567049, G loss: 3.151680, D accuracy: 85.6%, cell accuracy: 94.5%, board accuracy: 1.5% \n",
      "\n",
      "Epoch 128\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8470, G loss: 1.7980\n",
      "[124/1600] D loss: 0.3585, G loss: 3.0134\n",
      "[244/1600] D loss: 0.6837, G loss: 2.5715\n",
      "[364/1600] D loss: 0.5171, G loss: 2.9088\n",
      "[484/1600] D loss: 0.5113, G loss: 3.1758\n",
      "[604/1600] D loss: 0.9381, G loss: 2.4175\n",
      "[724/1600] D loss: 0.2761, G loss: 2.7117\n",
      "[844/1600] D loss: 0.0736, G loss: 3.3345\n",
      "[964/1600] D loss: 0.3889, G loss: 3.5306\n",
      "[1084/1600] D loss: 0.2860, G loss: 3.2500\n",
      "[1204/1600] D loss: 0.5962, G loss: 2.1260\n",
      "[1324/1600] D loss: 0.8273, G loss: 1.8048\n",
      "[1444/1600] D loss: 0.2538, G loss: 2.5088\n",
      "[1564/1600] D loss: 0.2731, G loss: 3.3858\n",
      "train error: \n",
      " D loss: 0.600447, G loss: 2.531802, D accuracy: 85.5%, cell accuracy: 95.0%, board accuracy: 4.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.552964, G loss: 3.476917, D accuracy: 87.5%, cell accuracy: 94.6%, board accuracy: 3.0% \n",
      "\n",
      "Epoch 129\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.3876, G loss: 3.1665\n",
      "[124/1600] D loss: 0.5641, G loss: 1.6297\n",
      "[244/1600] D loss: 0.6761, G loss: 1.3988\n",
      "[364/1600] D loss: 0.7842, G loss: 2.5394\n",
      "[484/1600] D loss: 0.6392, G loss: 2.8377\n",
      "[604/1600] D loss: 0.7605, G loss: 1.9521\n",
      "[724/1600] D loss: 0.5824, G loss: 4.3676\n",
      "[844/1600] D loss: 0.5095, G loss: 3.3849\n",
      "[964/1600] D loss: 0.7842, G loss: 1.2027\n",
      "[1084/1600] D loss: 0.6904, G loss: 2.9027\n",
      "[1204/1600] D loss: 0.3284, G loss: 3.3111\n",
      "[1324/1600] D loss: 0.7718, G loss: 2.8241\n",
      "[1444/1600] D loss: 0.0702, G loss: 4.0828\n",
      "[1564/1600] D loss: 0.3707, G loss: 2.5044\n",
      "train error: \n",
      " D loss: 0.657668, G loss: 2.638110, D accuracy: 83.0%, cell accuracy: 95.0%, board accuracy: 3.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.610816, G loss: 3.567006, D accuracy: 84.8%, cell accuracy: 94.6%, board accuracy: 2.8% \n",
      "\n",
      "Epoch 130\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.2665, G loss: 3.6119\n",
      "[124/1600] D loss: 0.4927, G loss: 3.3781\n",
      "[244/1600] D loss: 1.1863, G loss: 1.3808\n",
      "[364/1600] D loss: 0.8905, G loss: 1.2787\n",
      "[484/1600] D loss: 0.8846, G loss: 1.7901\n",
      "[604/1600] D loss: 0.4689, G loss: 2.6380\n",
      "[724/1600] D loss: 0.5688, G loss: 3.2783\n",
      "[844/1600] D loss: 0.8825, G loss: 1.7153\n",
      "[964/1600] D loss: 1.1396, G loss: 1.4898\n",
      "[1084/1600] D loss: 0.3695, G loss: 2.9057\n",
      "[1204/1600] D loss: 0.5803, G loss: 3.0452\n",
      "[1324/1600] D loss: 0.3617, G loss: 2.1776\n",
      "[1444/1600] D loss: 0.2811, G loss: 4.0344\n",
      "[1564/1600] D loss: 0.6176, G loss: 1.9955\n",
      "train error: \n",
      " D loss: 0.626983, G loss: 2.867062, D accuracy: 85.0%, cell accuracy: 95.1%, board accuracy: 3.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.632656, G loss: 3.801678, D accuracy: 85.0%, cell accuracy: 94.6%, board accuracy: 1.8% \n",
      "\n",
      "Epoch 131\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.2372, G loss: 2.6598\n",
      "[124/1600] D loss: 0.7696, G loss: 2.2539\n",
      "[244/1600] D loss: 0.8102, G loss: 2.2751\n",
      "[364/1600] D loss: 0.6816, G loss: 3.0900\n",
      "[484/1600] D loss: 0.4818, G loss: 3.2794\n",
      "[604/1600] D loss: 0.4481, G loss: 3.0227\n",
      "[724/1600] D loss: 0.9401, G loss: 1.7817\n",
      "[844/1600] D loss: 0.5120, G loss: 3.7114\n",
      "[964/1600] D loss: 0.4214, G loss: 2.4411\n",
      "[1084/1600] D loss: 0.5350, G loss: 2.2203\n",
      "[1204/1600] D loss: 0.0874, G loss: 4.2208\n",
      "[1324/1600] D loss: 0.3796, G loss: 3.1596\n",
      "[1444/1600] D loss: 0.9042, G loss: 1.2870\n",
      "[1564/1600] D loss: 1.3261, G loss: 1.2757\n",
      "train error: \n",
      " D loss: 0.676630, G loss: 2.683755, D accuracy: 82.2%, cell accuracy: 95.0%, board accuracy: 4.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.613205, G loss: 3.732133, D accuracy: 85.5%, cell accuracy: 94.6%, board accuracy: 3.2% \n",
      "\n",
      "Epoch 132\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0908, G loss: 1.7275\n",
      "[124/1600] D loss: 0.3259, G loss: 2.9454\n",
      "[244/1600] D loss: 1.1342, G loss: 2.6284\n",
      "[364/1600] D loss: 1.2125, G loss: 3.6028\n",
      "[484/1600] D loss: 0.9693, G loss: 1.7206\n",
      "[604/1600] D loss: 0.8366, G loss: 1.7431\n",
      "[724/1600] D loss: 0.4253, G loss: 4.1437\n",
      "[844/1600] D loss: 0.4275, G loss: 4.3469\n",
      "[964/1600] D loss: 0.7903, G loss: 1.6631\n",
      "[1084/1600] D loss: 0.4756, G loss: 2.9566\n",
      "[1204/1600] D loss: 1.2625, G loss: 0.5037\n",
      "[1324/1600] D loss: 0.7833, G loss: 2.1150\n",
      "[1444/1600] D loss: 0.3366, G loss: 3.8833\n",
      "[1564/1600] D loss: 0.8917, G loss: 2.3246\n",
      "train error: \n",
      " D loss: 0.623669, G loss: 2.606302, D accuracy: 85.6%, cell accuracy: 95.0%, board accuracy: 4.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.593464, G loss: 3.620841, D accuracy: 86.1%, cell accuracy: 94.6%, board accuracy: 3.0% \n",
      "\n",
      "Epoch 133\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9320, G loss: 1.1215\n",
      "[124/1600] D loss: 0.3407, G loss: 3.9254\n",
      "[244/1600] D loss: 0.8417, G loss: 3.1919\n",
      "[364/1600] D loss: 0.8573, G loss: 2.7834\n",
      "[484/1600] D loss: 1.1880, G loss: 1.7413\n",
      "[604/1600] D loss: 0.9021, G loss: 2.7036\n",
      "[724/1600] D loss: 0.5792, G loss: 2.5514\n",
      "[844/1600] D loss: 0.7328, G loss: 2.5543\n",
      "[964/1600] D loss: 0.5319, G loss: 2.1365\n",
      "[1084/1600] D loss: 0.8062, G loss: 1.4781\n",
      "[1204/1600] D loss: 0.6320, G loss: 3.8244\n",
      "[1324/1600] D loss: 0.5142, G loss: 4.1268\n",
      "[1444/1600] D loss: 1.2220, G loss: 2.6263\n",
      "[1564/1600] D loss: 0.2894, G loss: 3.6575\n",
      "train error: \n",
      " D loss: 0.654413, G loss: 2.750964, D accuracy: 83.4%, cell accuracy: 95.2%, board accuracy: 4.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.645394, G loss: 3.766348, D accuracy: 84.5%, cell accuracy: 94.7%, board accuracy: 3.0% \n",
      "\n",
      "Epoch 134\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6345, G loss: 3.3850\n",
      "[124/1600] D loss: 0.8372, G loss: 1.5726\n",
      "[244/1600] D loss: 0.6380, G loss: 2.9735\n",
      "[364/1600] D loss: 0.8773, G loss: 1.1152\n",
      "[484/1600] D loss: 0.8731, G loss: 2.3005\n",
      "[604/1600] D loss: 0.7585, G loss: 1.9587\n",
      "[724/1600] D loss: 0.6956, G loss: 1.9569\n",
      "[844/1600] D loss: 0.2096, G loss: 4.2671\n",
      "[964/1600] D loss: 0.3061, G loss: 3.4910\n",
      "[1084/1600] D loss: 0.1898, G loss: 3.7571\n",
      "[1204/1600] D loss: 0.4787, G loss: 1.3621\n",
      "[1324/1600] D loss: 0.4973, G loss: 2.4011\n",
      "[1444/1600] D loss: 0.7227, G loss: 2.5199\n",
      "[1564/1600] D loss: 0.7323, G loss: 2.0263\n",
      "train error: \n",
      " D loss: 0.623876, G loss: 2.698889, D accuracy: 84.3%, cell accuracy: 95.1%, board accuracy: 3.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.585586, G loss: 3.758088, D accuracy: 86.4%, cell accuracy: 94.7%, board accuracy: 2.5% \n",
      "\n",
      "Epoch 135\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.1371, G loss: 3.9617\n",
      "[124/1600] D loss: 0.6115, G loss: 3.2548\n",
      "[244/1600] D loss: 0.9480, G loss: 1.1676\n",
      "[364/1600] D loss: 0.9141, G loss: 1.2503\n",
      "[484/1600] D loss: 0.5783, G loss: 1.4317\n",
      "[604/1600] D loss: 0.4286, G loss: 3.5066\n",
      "[724/1600] D loss: 1.6052, G loss: 1.4715\n",
      "[844/1600] D loss: 0.3741, G loss: 2.3104\n",
      "[964/1600] D loss: 0.6628, G loss: 2.5465\n",
      "[1084/1600] D loss: 0.8949, G loss: 1.7591\n",
      "[1204/1600] D loss: 0.4249, G loss: 1.6868\n",
      "[1324/1600] D loss: 1.0788, G loss: 0.8651\n",
      "[1444/1600] D loss: 0.5250, G loss: 2.6246\n",
      "[1564/1600] D loss: 0.9292, G loss: 1.2798\n",
      "train error: \n",
      " D loss: 0.614380, G loss: 2.581363, D accuracy: 84.9%, cell accuracy: 95.1%, board accuracy: 4.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.575463, G loss: 3.563256, D accuracy: 85.2%, cell accuracy: 94.7%, board accuracy: 2.5% \n",
      "\n",
      "Epoch 136\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.2561, G loss: 3.5768\n",
      "[124/1600] D loss: 0.2260, G loss: 3.5192\n",
      "[244/1600] D loss: 1.1215, G loss: 2.5383\n",
      "[364/1600] D loss: 0.4337, G loss: 2.1256\n",
      "[484/1600] D loss: 0.9719, G loss: 1.1999\n",
      "[604/1600] D loss: 0.5824, G loss: 3.5895\n",
      "[724/1600] D loss: 0.4591, G loss: 1.9110\n",
      "[844/1600] D loss: 0.7700, G loss: 2.0974\n",
      "[964/1600] D loss: 1.4789, G loss: 1.9122\n",
      "[1084/1600] D loss: 0.4351, G loss: 2.2899\n",
      "[1204/1600] D loss: 1.0146, G loss: 1.3778\n",
      "[1324/1600] D loss: 0.7358, G loss: 2.0195\n",
      "[1444/1600] D loss: 0.4740, G loss: 4.0706\n",
      "[1564/1600] D loss: 0.6606, G loss: 3.2984\n",
      "train error: \n",
      " D loss: 0.681019, G loss: 2.239690, D accuracy: 81.5%, cell accuracy: 95.1%, board accuracy: 3.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.551668, G loss: 3.308316, D accuracy: 86.8%, cell accuracy: 94.7%, board accuracy: 2.8% \n",
      "\n",
      "Epoch 137\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0440, G loss: 2.0202\n",
      "[124/1600] D loss: 1.1168, G loss: 1.1510\n",
      "[244/1600] D loss: 0.2593, G loss: 3.4836\n",
      "[364/1600] D loss: 0.5157, G loss: 2.5805\n",
      "[484/1600] D loss: 0.5687, G loss: 4.2203\n",
      "[604/1600] D loss: 0.4692, G loss: 2.7754\n",
      "[724/1600] D loss: 1.2996, G loss: 0.8682\n",
      "[844/1600] D loss: 1.1617, G loss: 1.5443\n",
      "[964/1600] D loss: 0.3465, G loss: 3.5842\n",
      "[1084/1600] D loss: 0.3017, G loss: 4.3438\n",
      "[1204/1600] D loss: 0.9014, G loss: 1.2217\n",
      "[1324/1600] D loss: 0.5370, G loss: 2.5528\n",
      "[1444/1600] D loss: 0.3912, G loss: 3.3443\n",
      "[1564/1600] D loss: 0.4546, G loss: 4.6654\n",
      "train error: \n",
      " D loss: 0.733302, G loss: 2.084998, D accuracy: 81.0%, cell accuracy: 95.1%, board accuracy: 4.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.595231, G loss: 3.104938, D accuracy: 85.6%, cell accuracy: 94.7%, board accuracy: 2.5% \n",
      "\n",
      "Epoch 138\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4046, G loss: 2.1283\n",
      "[124/1600] D loss: 0.8811, G loss: 1.9632\n",
      "[244/1600] D loss: 0.3819, G loss: 3.5043\n",
      "[364/1600] D loss: 0.4222, G loss: 3.3433\n",
      "[484/1600] D loss: 0.6415, G loss: 1.9193\n",
      "[604/1600] D loss: 0.4136, G loss: 2.3142\n",
      "[724/1600] D loss: 0.9282, G loss: 2.2136\n",
      "[844/1600] D loss: 1.0938, G loss: 1.2986\n",
      "[964/1600] D loss: 0.5109, G loss: 4.2625\n",
      "[1084/1600] D loss: 0.6071, G loss: 3.1116\n",
      "[1204/1600] D loss: 1.0393, G loss: 1.1983\n",
      "[1324/1600] D loss: 0.2311, G loss: 4.7691\n",
      "[1444/1600] D loss: 0.2926, G loss: 2.0630\n",
      "[1564/1600] D loss: 0.3263, G loss: 4.6604\n",
      "train error: \n",
      " D loss: 0.627759, G loss: 2.447742, D accuracy: 83.9%, cell accuracy: 95.2%, board accuracy: 4.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.544666, G loss: 3.497822, D accuracy: 86.5%, cell accuracy: 94.7%, board accuracy: 2.8% \n",
      "\n",
      "Epoch 139\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6996, G loss: 1.5475\n",
      "[124/1600] D loss: 0.8578, G loss: 1.6834\n",
      "[244/1600] D loss: 1.5190, G loss: 1.8391\n",
      "[364/1600] D loss: 1.4572, G loss: 1.2334\n",
      "[484/1600] D loss: 0.2086, G loss: 5.1341\n",
      "[604/1600] D loss: 1.0823, G loss: 0.8237\n",
      "[724/1600] D loss: 0.6264, G loss: 2.3781\n",
      "[844/1600] D loss: 0.3637, G loss: 2.6662\n",
      "[964/1600] D loss: 0.1151, G loss: 4.6839\n",
      "[1084/1600] D loss: 0.5232, G loss: 1.7999\n",
      "[1204/1600] D loss: 1.0240, G loss: 0.8209\n",
      "[1324/1600] D loss: 0.9263, G loss: 2.5564\n",
      "[1444/1600] D loss: 1.1004, G loss: 1.5168\n",
      "[1564/1600] D loss: 0.6805, G loss: 2.7932\n",
      "train error: \n",
      " D loss: 0.635307, G loss: 2.355202, D accuracy: 83.5%, cell accuracy: 95.1%, board accuracy: 4.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.543421, G loss: 3.418547, D accuracy: 86.4%, cell accuracy: 94.6%, board accuracy: 2.2% \n",
      "\n",
      "Epoch 140\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4366, G loss: 2.1141\n",
      "[124/1600] D loss: 0.3195, G loss: 3.8570\n",
      "[244/1600] D loss: 1.0430, G loss: 4.3428\n",
      "[364/1600] D loss: 0.5382, G loss: 3.1160\n",
      "[484/1600] D loss: 0.8288, G loss: 1.8736\n",
      "[604/1600] D loss: 0.3564, G loss: 1.6723\n",
      "[724/1600] D loss: 0.5708, G loss: 2.3565\n",
      "[844/1600] D loss: 0.8135, G loss: 1.8374\n",
      "[964/1600] D loss: 0.4490, G loss: 3.1555\n",
      "[1084/1600] D loss: 0.5345, G loss: 2.6118\n",
      "[1204/1600] D loss: 0.7895, G loss: 2.7291\n",
      "[1324/1600] D loss: 0.9329, G loss: 1.2999\n",
      "[1444/1600] D loss: 1.8488, G loss: 1.0137\n",
      "[1564/1600] D loss: 0.1072, G loss: 3.9959\n",
      "train error: \n",
      " D loss: 0.661763, G loss: 2.407978, D accuracy: 83.2%, cell accuracy: 95.1%, board accuracy: 4.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.572324, G loss: 3.459006, D accuracy: 86.5%, cell accuracy: 94.6%, board accuracy: 2.8% \n",
      "\n",
      "Epoch 141\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6735, G loss: 1.8973\n",
      "[124/1600] D loss: 0.9562, G loss: 3.0086\n",
      "[244/1600] D loss: 0.7850, G loss: 1.6161\n",
      "[364/1600] D loss: 1.0223, G loss: 2.5700\n",
      "[484/1600] D loss: 0.3814, G loss: 3.9292\n",
      "[604/1600] D loss: 0.4090, G loss: 1.8959\n",
      "[724/1600] D loss: 0.0545, G loss: 5.0439\n",
      "[844/1600] D loss: 0.4239, G loss: 2.5918\n",
      "[964/1600] D loss: 0.2511, G loss: 2.5073\n",
      "[1084/1600] D loss: 1.1962, G loss: 1.8906\n",
      "[1204/1600] D loss: 0.7982, G loss: 1.4390\n",
      "[1324/1600] D loss: 1.0520, G loss: 1.4035\n",
      "[1444/1600] D loss: 0.2659, G loss: 3.9497\n",
      "[1564/1600] D loss: 0.2002, G loss: 3.5946\n",
      "train error: \n",
      " D loss: 0.646261, G loss: 2.499147, D accuracy: 83.5%, cell accuracy: 95.1%, board accuracy: 4.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.566571, G loss: 3.548372, D accuracy: 86.1%, cell accuracy: 94.7%, board accuracy: 3.0% \n",
      "\n",
      "Epoch 142\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5010, G loss: 3.8665\n",
      "[124/1600] D loss: 0.2298, G loss: 4.3709\n",
      "[244/1600] D loss: 0.4755, G loss: 2.9564\n",
      "[364/1600] D loss: 0.6937, G loss: 4.0561\n",
      "[484/1600] D loss: 0.8177, G loss: 2.9049\n",
      "[604/1600] D loss: 0.4995, G loss: 3.6638\n",
      "[724/1600] D loss: 0.6828, G loss: 2.2540\n",
      "[844/1600] D loss: 0.7131, G loss: 2.2754\n",
      "[964/1600] D loss: 0.5147, G loss: 2.2036\n",
      "[1084/1600] D loss: 0.3960, G loss: 4.0893\n",
      "[1204/1600] D loss: 0.9460, G loss: 1.3057\n",
      "[1324/1600] D loss: 0.4580, G loss: 3.6700\n",
      "[1444/1600] D loss: 0.5993, G loss: 2.9829\n",
      "[1564/1600] D loss: 0.8955, G loss: 2.7224\n",
      "train error: \n",
      " D loss: 0.648055, G loss: 2.505372, D accuracy: 84.4%, cell accuracy: 95.2%, board accuracy: 4.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.556505, G loss: 3.672816, D accuracy: 87.4%, cell accuracy: 94.6%, board accuracy: 3.2% \n",
      "\n",
      "Epoch 143\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8505, G loss: 2.8808\n",
      "[124/1600] D loss: 0.5022, G loss: 2.4258\n",
      "[244/1600] D loss: 0.9566, G loss: 1.3760\n",
      "[364/1600] D loss: 0.5656, G loss: 4.2351\n",
      "[484/1600] D loss: 0.2338, G loss: 3.8149\n",
      "[604/1600] D loss: 1.1364, G loss: 1.5794\n",
      "[724/1600] D loss: 0.3130, G loss: 2.9180\n",
      "[844/1600] D loss: 0.3431, G loss: 2.3221\n",
      "[964/1600] D loss: 0.6330, G loss: 1.9916\n",
      "[1084/1600] D loss: 0.7963, G loss: 2.4649\n",
      "[1204/1600] D loss: 0.8678, G loss: 2.9701\n",
      "[1324/1600] D loss: 0.3229, G loss: 1.7927\n",
      "[1444/1600] D loss: 0.5684, G loss: 1.4536\n",
      "[1564/1600] D loss: 0.6210, G loss: 2.2137\n",
      "train error: \n",
      " D loss: 0.629917, G loss: 2.677783, D accuracy: 84.5%, cell accuracy: 95.2%, board accuracy: 3.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.578915, G loss: 3.756833, D accuracy: 86.1%, cell accuracy: 94.8%, board accuracy: 2.5% \n",
      "\n",
      "Epoch 144\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.4621, G loss: 1.1712\n",
      "[124/1600] D loss: 0.9441, G loss: 2.3031\n",
      "[244/1600] D loss: 0.3794, G loss: 3.8620\n",
      "[364/1600] D loss: 0.3929, G loss: 3.6826\n",
      "[484/1600] D loss: 0.7220, G loss: 3.2806\n",
      "[604/1600] D loss: 0.8520, G loss: 2.1392\n",
      "[724/1600] D loss: 0.9103, G loss: 1.7069\n",
      "[844/1600] D loss: 0.6887, G loss: 3.0227\n",
      "[964/1600] D loss: 0.1779, G loss: 3.9029\n",
      "[1084/1600] D loss: 0.5198, G loss: 2.8071\n",
      "[1204/1600] D loss: 0.6545, G loss: 4.3021\n",
      "[1324/1600] D loss: 0.3449, G loss: 2.4454\n",
      "[1444/1600] D loss: 0.7233, G loss: 2.8517\n",
      "[1564/1600] D loss: 0.0083, G loss: 7.1166\n",
      "train error: \n",
      " D loss: 0.607915, G loss: 2.568215, D accuracy: 85.5%, cell accuracy: 95.2%, board accuracy: 4.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.546618, G loss: 3.752936, D accuracy: 87.8%, cell accuracy: 94.7%, board accuracy: 2.0% \n",
      "\n",
      "Epoch 145\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0786, G loss: 0.9996\n",
      "[124/1600] D loss: 0.2671, G loss: 3.2886\n",
      "[244/1600] D loss: 0.4013, G loss: 1.7353\n",
      "[364/1600] D loss: 0.7577, G loss: 1.8072\n",
      "[484/1600] D loss: 0.7579, G loss: 3.6941\n",
      "[604/1600] D loss: 0.3581, G loss: 2.5252\n",
      "[724/1600] D loss: 0.9851, G loss: 1.7888\n",
      "[844/1600] D loss: 0.3951, G loss: 1.8652\n",
      "[964/1600] D loss: 0.4483, G loss: 1.8862\n",
      "[1084/1600] D loss: 0.6296, G loss: 1.2900\n",
      "[1204/1600] D loss: 0.2968, G loss: 2.2653\n",
      "[1324/1600] D loss: 0.7359, G loss: 2.7243\n",
      "[1444/1600] D loss: 0.5034, G loss: 2.6220\n",
      "[1564/1600] D loss: 0.7791, G loss: 1.7282\n",
      "train error: \n",
      " D loss: 0.754614, G loss: 2.275146, D accuracy: 80.7%, cell accuracy: 95.1%, board accuracy: 4.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.606435, G loss: 3.482863, D accuracy: 86.0%, cell accuracy: 94.6%, board accuracy: 2.2% \n",
      "\n",
      "Epoch 146\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4701, G loss: 2.9991\n",
      "[124/1600] D loss: 0.6475, G loss: 1.7367\n",
      "[244/1600] D loss: 0.5725, G loss: 2.3599\n",
      "[364/1600] D loss: 0.8201, G loss: 1.4726\n",
      "[484/1600] D loss: 0.3149, G loss: 5.7645\n",
      "[604/1600] D loss: 0.5536, G loss: 1.6392\n",
      "[724/1600] D loss: 0.1214, G loss: 5.2062\n",
      "[844/1600] D loss: 1.2434, G loss: 2.5359\n",
      "[964/1600] D loss: 0.1716, G loss: 5.1809\n",
      "[1084/1600] D loss: 0.5543, G loss: 2.4086\n",
      "[1204/1600] D loss: 0.7013, G loss: 1.7958\n",
      "[1324/1600] D loss: 1.2420, G loss: 1.5529\n",
      "[1444/1600] D loss: 0.9828, G loss: 2.8958\n",
      "[1564/1600] D loss: 1.1222, G loss: 0.9993\n",
      "train error: \n",
      " D loss: 0.632914, G loss: 2.715136, D accuracy: 84.4%, cell accuracy: 95.0%, board accuracy: 2.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.573024, G loss: 3.895141, D accuracy: 86.2%, cell accuracy: 94.4%, board accuracy: 2.2% \n",
      "\n",
      "Epoch 147\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6659, G loss: 1.6198\n",
      "[124/1600] D loss: 0.8271, G loss: 3.1327\n",
      "[244/1600] D loss: 0.8458, G loss: 2.4178\n",
      "[364/1600] D loss: 1.0213, G loss: 2.4805\n",
      "[484/1600] D loss: 0.8332, G loss: 2.3061\n",
      "[604/1600] D loss: 0.6858, G loss: 1.4029\n",
      "[724/1600] D loss: 0.5233, G loss: 2.8308\n",
      "[844/1600] D loss: 0.7596, G loss: 1.4156\n",
      "[964/1600] D loss: 0.6405, G loss: 1.7515\n",
      "[1084/1600] D loss: 0.5842, G loss: 1.4898\n",
      "[1204/1600] D loss: 0.7670, G loss: 4.0078\n",
      "[1324/1600] D loss: 0.1871, G loss: 3.7467\n",
      "[1444/1600] D loss: 0.9908, G loss: 0.9900\n",
      "[1564/1600] D loss: 0.5627, G loss: 2.0244\n",
      "train error: \n",
      " D loss: 0.665597, G loss: 2.408245, D accuracy: 83.2%, cell accuracy: 95.1%, board accuracy: 3.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.554902, G loss: 3.578486, D accuracy: 86.8%, cell accuracy: 94.6%, board accuracy: 0.5% \n",
      "\n",
      "Epoch 148\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.3059, G loss: 3.0477\n",
      "[124/1600] D loss: 1.1576, G loss: 0.9491\n",
      "[244/1600] D loss: 0.7793, G loss: 1.6027\n",
      "[364/1600] D loss: 0.3892, G loss: 2.6908\n",
      "[484/1600] D loss: 0.3697, G loss: 3.2775\n",
      "[604/1600] D loss: 0.5047, G loss: 3.7331\n",
      "[724/1600] D loss: 1.0099, G loss: 3.0468\n",
      "[844/1600] D loss: 0.8209, G loss: 1.9959\n",
      "[964/1600] D loss: 1.0546, G loss: 1.6089\n",
      "[1084/1600] D loss: 0.8734, G loss: 2.5746\n",
      "[1204/1600] D loss: 0.5725, G loss: 2.6676\n",
      "[1324/1600] D loss: 0.3113, G loss: 3.6179\n",
      "[1444/1600] D loss: 0.8338, G loss: 1.5684\n",
      "[1564/1600] D loss: 0.7988, G loss: 1.3920\n",
      "train error: \n",
      " D loss: 0.630950, G loss: 2.733348, D accuracy: 84.2%, cell accuracy: 95.1%, board accuracy: 2.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.573572, G loss: 3.897339, D accuracy: 85.1%, cell accuracy: 94.6%, board accuracy: 0.8% \n",
      "\n",
      "Epoch 149\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6194, G loss: 2.2620\n",
      "[124/1600] D loss: 0.3502, G loss: 5.8739\n",
      "[244/1600] D loss: 1.3732, G loss: 0.6268\n",
      "[364/1600] D loss: 1.4056, G loss: 1.6046\n",
      "[484/1600] D loss: 0.4650, G loss: 3.4100\n",
      "[604/1600] D loss: 0.0290, G loss: 5.6539\n",
      "[724/1600] D loss: 1.2128, G loss: 1.7580\n",
      "[844/1600] D loss: 0.8003, G loss: 3.1227\n",
      "[964/1600] D loss: 0.4234, G loss: 3.3790\n",
      "[1084/1600] D loss: 0.5267, G loss: 2.9243\n",
      "[1204/1600] D loss: 0.7575, G loss: 1.5795\n",
      "[1324/1600] D loss: 1.4664, G loss: 1.3747\n",
      "[1444/1600] D loss: 0.3969, G loss: 4.0186\n",
      "[1564/1600] D loss: 0.4580, G loss: 2.8063\n",
      "train error: \n",
      " D loss: 0.669225, G loss: 2.621183, D accuracy: 83.3%, cell accuracy: 95.2%, board accuracy: 3.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.634671, G loss: 3.731315, D accuracy: 84.1%, cell accuracy: 94.7%, board accuracy: 1.0% \n",
      "\n",
      "Epoch 150\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.1246, G loss: 3.3109\n",
      "[124/1600] D loss: 0.6195, G loss: 3.5108\n",
      "[244/1600] D loss: 0.7248, G loss: 1.0392\n",
      "[364/1600] D loss: 1.4181, G loss: 2.7587\n",
      "[484/1600] D loss: 0.4440, G loss: 2.4268\n",
      "[604/1600] D loss: 0.6489, G loss: 1.1503\n",
      "[724/1600] D loss: 1.0991, G loss: 1.1852\n",
      "[844/1600] D loss: 0.4512, G loss: 1.9762\n",
      "[964/1600] D loss: 0.8726, G loss: 1.2624\n",
      "[1084/1600] D loss: 1.2013, G loss: 1.9037\n",
      "[1204/1600] D loss: 0.4352, G loss: 3.0059\n",
      "[1324/1600] D loss: 0.8104, G loss: 1.8155\n",
      "[1444/1600] D loss: 0.7731, G loss: 1.8821\n",
      "[1564/1600] D loss: 0.8966, G loss: 2.3628\n",
      "train error: \n",
      " D loss: 0.793122, G loss: 3.281857, D accuracy: 79.1%, cell accuracy: 95.2%, board accuracy: 3.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.814635, G loss: 4.384611, D accuracy: 79.9%, cell accuracy: 94.7%, board accuracy: 2.5% \n",
      "\n",
      "Epoch 151\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5711, G loss: 3.4484\n",
      "[124/1600] D loss: 0.7241, G loss: 1.9474\n",
      "[244/1600] D loss: 0.5277, G loss: 2.6804\n",
      "[364/1600] D loss: 0.2005, G loss: 2.8813\n",
      "[484/1600] D loss: 1.2426, G loss: 1.1436\n",
      "[604/1600] D loss: 0.5519, G loss: 1.6505\n",
      "[724/1600] D loss: 0.8177, G loss: 2.7507\n",
      "[844/1600] D loss: 0.4144, G loss: 3.3116\n",
      "[964/1600] D loss: 0.9303, G loss: 1.2566\n",
      "[1084/1600] D loss: 0.4584, G loss: 3.3641\n",
      "[1204/1600] D loss: 1.4587, G loss: 2.1769\n",
      "[1324/1600] D loss: 0.5327, G loss: 2.1682\n",
      "[1444/1600] D loss: 0.2115, G loss: 3.2885\n",
      "[1564/1600] D loss: 0.3424, G loss: 3.2517\n",
      "train error: \n",
      " D loss: 0.686408, G loss: 2.269664, D accuracy: 83.8%, cell accuracy: 95.3%, board accuracy: 3.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.567654, G loss: 3.440763, D accuracy: 87.2%, cell accuracy: 94.8%, board accuracy: 3.2% \n",
      "\n",
      "Epoch 152\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7259, G loss: 1.6466\n",
      "[124/1600] D loss: 0.8427, G loss: 1.8369\n",
      "[244/1600] D loss: 0.7865, G loss: 2.4382\n",
      "[364/1600] D loss: 0.1382, G loss: 3.4843\n",
      "[484/1600] D loss: 0.4510, G loss: 3.3513\n",
      "[604/1600] D loss: 0.9137, G loss: 1.7517\n",
      "[724/1600] D loss: 1.1064, G loss: 1.3013\n",
      "[844/1600] D loss: 0.6453, G loss: 2.7832\n",
      "[964/1600] D loss: 0.7628, G loss: 1.4867\n",
      "[1084/1600] D loss: 0.3265, G loss: 3.3705\n",
      "[1204/1600] D loss: 1.0781, G loss: 1.7557\n",
      "[1324/1600] D loss: 0.4165, G loss: 2.2937\n",
      "[1444/1600] D loss: 0.2455, G loss: 1.7356\n",
      "[1564/1600] D loss: 0.4206, G loss: 3.2352\n",
      "train error: \n",
      " D loss: 0.632138, G loss: 2.664012, D accuracy: 84.2%, cell accuracy: 95.2%, board accuracy: 4.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.598140, G loss: 3.840625, D accuracy: 85.4%, cell accuracy: 94.7%, board accuracy: 4.0% \n",
      "\n",
      "Epoch 153\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1625, G loss: 1.8927\n",
      "[124/1600] D loss: 0.1834, G loss: 4.4850\n",
      "[244/1600] D loss: 0.6537, G loss: 3.5481\n",
      "[364/1600] D loss: 1.3659, G loss: 1.1239\n",
      "[484/1600] D loss: 0.8756, G loss: 2.1581\n",
      "[604/1600] D loss: 0.7292, G loss: 2.6179\n",
      "[724/1600] D loss: 0.0379, G loss: 5.4839\n",
      "[844/1600] D loss: 0.8897, G loss: 3.1434\n",
      "[964/1600] D loss: 0.6717, G loss: 3.9857\n",
      "[1084/1600] D loss: 0.9772, G loss: 1.7562\n",
      "[1204/1600] D loss: 1.1052, G loss: 1.6386\n",
      "[1324/1600] D loss: 0.6727, G loss: 2.4357\n",
      "[1444/1600] D loss: 0.5625, G loss: 3.9038\n",
      "[1564/1600] D loss: 0.1796, G loss: 4.1586\n",
      "train error: \n",
      " D loss: 0.644261, G loss: 2.933201, D accuracy: 84.3%, cell accuracy: 95.2%, board accuracy: 4.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.653329, G loss: 4.115170, D accuracy: 85.4%, cell accuracy: 94.7%, board accuracy: 3.2% \n",
      "\n",
      "Epoch 154\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4550, G loss: 2.5892\n",
      "[124/1600] D loss: 0.8143, G loss: 2.3636\n",
      "[244/1600] D loss: 0.4832, G loss: 1.9590\n",
      "[364/1600] D loss: 0.3738, G loss: 2.5636\n",
      "[484/1600] D loss: 1.1374, G loss: 2.0289\n",
      "[604/1600] D loss: 0.5886, G loss: 2.0484\n",
      "[724/1600] D loss: 0.2096, G loss: 4.3083\n",
      "[844/1600] D loss: 0.3703, G loss: 2.7813\n",
      "[964/1600] D loss: 0.6878, G loss: 1.3972\n",
      "[1084/1600] D loss: 0.2972, G loss: 2.4927\n",
      "[1204/1600] D loss: 0.7807, G loss: 2.9118\n",
      "[1324/1600] D loss: 0.7443, G loss: 3.0603\n",
      "[1444/1600] D loss: 0.1975, G loss: 3.8288\n",
      "[1564/1600] D loss: 0.5674, G loss: 2.5965\n",
      "train error: \n",
      " D loss: 0.690436, G loss: 2.217419, D accuracy: 82.7%, cell accuracy: 95.3%, board accuracy: 4.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.585384, G loss: 3.365341, D accuracy: 85.9%, cell accuracy: 94.9%, board accuracy: 3.2% \n",
      "\n",
      "Epoch 155\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.3503, G loss: 2.4809\n",
      "[124/1600] D loss: 0.6653, G loss: 4.1638\n",
      "[244/1600] D loss: 0.8183, G loss: 2.9797\n",
      "[364/1600] D loss: 1.2434, G loss: 2.4505\n",
      "[484/1600] D loss: 0.9443, G loss: 1.4114\n",
      "[604/1600] D loss: 0.3131, G loss: 3.3722\n",
      "[724/1600] D loss: 1.0245, G loss: 2.4713\n",
      "[844/1600] D loss: 0.3531, G loss: 2.5276\n",
      "[964/1600] D loss: 1.1808, G loss: 0.6468\n",
      "[1084/1600] D loss: 0.7107, G loss: 1.7259\n",
      "[1204/1600] D loss: 0.0404, G loss: 5.2969\n",
      "[1324/1600] D loss: 0.6368, G loss: 3.7756\n",
      "[1444/1600] D loss: 0.9485, G loss: 2.1657\n",
      "[1564/1600] D loss: 0.9855, G loss: 1.7437\n",
      "train error: \n",
      " D loss: 0.699845, G loss: 2.206996, D accuracy: 82.9%, cell accuracy: 95.3%, board accuracy: 5.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.547259, G loss: 3.471018, D accuracy: 86.1%, cell accuracy: 94.9%, board accuracy: 4.5% \n",
      "\n",
      "Epoch 156\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3617, G loss: 1.8458\n",
      "[124/1600] D loss: 0.5606, G loss: 4.3655\n",
      "[244/1600] D loss: 0.1128, G loss: 3.2312\n",
      "[364/1600] D loss: 0.1922, G loss: 4.0017\n",
      "[484/1600] D loss: 1.0591, G loss: 1.4373\n",
      "[604/1600] D loss: 0.5887, G loss: 2.6250\n",
      "[724/1600] D loss: 0.7290, G loss: 2.7210\n",
      "[844/1600] D loss: 0.6533, G loss: 3.1336\n",
      "[964/1600] D loss: 0.5371, G loss: 2.6433\n",
      "[1084/1600] D loss: 0.4105, G loss: 2.6395\n",
      "[1204/1600] D loss: 0.2845, G loss: 4.0573\n",
      "[1324/1600] D loss: 0.0302, G loss: 5.4894\n",
      "[1444/1600] D loss: 0.4741, G loss: 2.5494\n",
      "[1564/1600] D loss: 0.4193, G loss: 2.8425\n",
      "train error: \n",
      " D loss: 0.637820, G loss: 2.379572, D accuracy: 84.1%, cell accuracy: 95.4%, board accuracy: 4.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.546577, G loss: 3.577222, D accuracy: 86.9%, cell accuracy: 95.0%, board accuracy: 3.8% \n",
      "\n",
      "Epoch 157\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.2760, G loss: 4.1625\n",
      "[124/1600] D loss: 0.4143, G loss: 4.6262\n",
      "[244/1600] D loss: 0.4729, G loss: 3.9339\n",
      "[364/1600] D loss: 1.2735, G loss: 2.7472\n",
      "[484/1600] D loss: 0.1381, G loss: 6.2462\n",
      "[604/1600] D loss: 0.8813, G loss: 1.7172\n",
      "[724/1600] D loss: 0.2041, G loss: 3.4192\n",
      "[844/1600] D loss: 0.7685, G loss: 2.4027\n",
      "[964/1600] D loss: 0.5745, G loss: 4.0457\n",
      "[1084/1600] D loss: 0.6255, G loss: 1.8214\n",
      "[1204/1600] D loss: 0.5823, G loss: 3.0581\n",
      "[1324/1600] D loss: 0.9555, G loss: 2.1356\n",
      "[1444/1600] D loss: 0.4837, G loss: 2.0252\n",
      "[1564/1600] D loss: 0.4476, G loss: 2.9716\n",
      "train error: \n",
      " D loss: 0.720399, G loss: 2.650989, D accuracy: 81.1%, cell accuracy: 95.4%, board accuracy: 5.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.660356, G loss: 3.958898, D accuracy: 84.2%, cell accuracy: 94.9%, board accuracy: 4.0% \n",
      "\n",
      "Epoch 158\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9599, G loss: 2.0489\n",
      "[124/1600] D loss: 0.7023, G loss: 1.4080\n",
      "[244/1600] D loss: 0.5259, G loss: 1.5954\n",
      "[364/1600] D loss: 0.6813, G loss: 4.1227\n",
      "[484/1600] D loss: 0.4728, G loss: 2.3833\n",
      "[604/1600] D loss: 0.6423, G loss: 4.0115\n",
      "[724/1600] D loss: 0.6986, G loss: 2.6036\n",
      "[844/1600] D loss: 1.1722, G loss: 1.9098\n",
      "[964/1600] D loss: 0.6685, G loss: 1.5857\n",
      "[1084/1600] D loss: 0.9685, G loss: 1.1819\n",
      "[1204/1600] D loss: 1.0221, G loss: 2.3419\n",
      "[1324/1600] D loss: 0.4032, G loss: 2.3676\n",
      "[1444/1600] D loss: 0.8932, G loss: 2.2488\n",
      "[1564/1600] D loss: 0.1412, G loss: 4.3325\n",
      "train error: \n",
      " D loss: 0.621848, G loss: 2.753133, D accuracy: 85.3%, cell accuracy: 95.4%, board accuracy: 4.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.612447, G loss: 4.004091, D accuracy: 86.0%, cell accuracy: 94.9%, board accuracy: 3.8% \n",
      "\n",
      "Epoch 159\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0096, G loss: 1.8264\n",
      "[124/1600] D loss: 0.7003, G loss: 2.6016\n",
      "[244/1600] D loss: 0.4406, G loss: 5.0017\n",
      "[364/1600] D loss: 0.2764, G loss: 4.4100\n",
      "[484/1600] D loss: 0.1573, G loss: 6.0082\n",
      "[604/1600] D loss: 0.4580, G loss: 2.6087\n",
      "[724/1600] D loss: 1.1284, G loss: 3.5817\n",
      "[844/1600] D loss: 0.3772, G loss: 1.1648\n",
      "[964/1600] D loss: 0.2350, G loss: 3.3631\n",
      "[1084/1600] D loss: 0.8612, G loss: 1.7092\n",
      "[1204/1600] D loss: 0.6755, G loss: 3.0948\n",
      "[1324/1600] D loss: 0.8090, G loss: 2.8558\n",
      "[1444/1600] D loss: 0.5135, G loss: 3.3320\n",
      "[1564/1600] D loss: 1.1313, G loss: 0.8489\n",
      "train error: \n",
      " D loss: 0.612277, G loss: 2.714689, D accuracy: 85.3%, cell accuracy: 95.4%, board accuracy: 5.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.582747, G loss: 4.059572, D accuracy: 86.5%, cell accuracy: 94.9%, board accuracy: 4.0% \n",
      "\n",
      "Epoch 160\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8626, G loss: 1.6532\n",
      "[124/1600] D loss: 0.3094, G loss: 3.6703\n",
      "[244/1600] D loss: 0.0302, G loss: 5.6736\n",
      "[364/1600] D loss: 0.4076, G loss: 1.7756\n",
      "[484/1600] D loss: 0.7088, G loss: 1.3590\n",
      "[604/1600] D loss: 0.9933, G loss: 2.5732\n",
      "[724/1600] D loss: 1.0133, G loss: 2.8911\n",
      "[844/1600] D loss: 0.3344, G loss: 2.5564\n",
      "[964/1600] D loss: 0.4842, G loss: 2.2097\n",
      "[1084/1600] D loss: 1.3045, G loss: 1.1237\n",
      "[1204/1600] D loss: 0.5256, G loss: 3.3626\n",
      "[1324/1600] D loss: 0.2627, G loss: 3.9387\n",
      "[1444/1600] D loss: 0.5033, G loss: 1.9936\n",
      "[1564/1600] D loss: 0.4469, G loss: 3.1415\n",
      "train error: \n",
      " D loss: 0.692881, G loss: 2.304449, D accuracy: 82.5%, cell accuracy: 95.3%, board accuracy: 5.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.568159, G loss: 3.487581, D accuracy: 86.0%, cell accuracy: 94.8%, board accuracy: 4.0% \n",
      "\n",
      "Epoch 161\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6688, G loss: 3.2096\n",
      "[124/1600] D loss: 0.1244, G loss: 4.3935\n",
      "[244/1600] D loss: 0.3836, G loss: 4.0611\n",
      "[364/1600] D loss: 1.2276, G loss: 4.7568\n",
      "[484/1600] D loss: 1.2833, G loss: 2.6533\n",
      "[604/1600] D loss: 0.7820, G loss: 1.6019\n",
      "[724/1600] D loss: 0.4525, G loss: 2.5965\n",
      "[844/1600] D loss: 0.3555, G loss: 3.4397\n",
      "[964/1600] D loss: 1.1362, G loss: 2.5701\n",
      "[1084/1600] D loss: 0.2994, G loss: 4.6262\n",
      "[1204/1600] D loss: 0.5948, G loss: 3.3919\n",
      "[1324/1600] D loss: 0.4125, G loss: 1.7798\n",
      "[1444/1600] D loss: 0.7186, G loss: 3.0165\n",
      "[1564/1600] D loss: 0.6923, G loss: 1.9099\n",
      "train error: \n",
      " D loss: 0.661056, G loss: 2.288874, D accuracy: 83.2%, cell accuracy: 95.4%, board accuracy: 5.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.545543, G loss: 3.556413, D accuracy: 87.9%, cell accuracy: 94.9%, board accuracy: 4.0% \n",
      "\n",
      "Epoch 162\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8534, G loss: 1.6224\n",
      "[124/1600] D loss: 0.7146, G loss: 4.3842\n",
      "[244/1600] D loss: 0.7179, G loss: 1.2875\n",
      "[364/1600] D loss: 0.2309, G loss: 4.3072\n",
      "[484/1600] D loss: 0.1100, G loss: 3.0160\n",
      "[604/1600] D loss: 0.7534, G loss: 1.4395\n",
      "[724/1600] D loss: 0.5784, G loss: 1.7273\n",
      "[844/1600] D loss: 0.2299, G loss: 4.0678\n",
      "[964/1600] D loss: 0.6196, G loss: 3.1502\n",
      "[1084/1600] D loss: 0.7276, G loss: 3.7131\n",
      "[1204/1600] D loss: 0.3918, G loss: 3.2824\n",
      "[1324/1600] D loss: 1.0021, G loss: 1.4322\n",
      "[1444/1600] D loss: 0.5425, G loss: 1.2000\n",
      "[1564/1600] D loss: 0.3603, G loss: 5.2737\n",
      "train error: \n",
      " D loss: 0.627186, G loss: 2.461882, D accuracy: 85.2%, cell accuracy: 95.5%, board accuracy: 5.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.548903, G loss: 3.753981, D accuracy: 86.4%, cell accuracy: 95.0%, board accuracy: 4.8% \n",
      "\n",
      "Epoch 163\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8253, G loss: 1.6900\n",
      "[124/1600] D loss: 0.8497, G loss: 1.4276\n",
      "[244/1600] D loss: 0.3152, G loss: 2.1118\n",
      "[364/1600] D loss: 0.1414, G loss: 2.9837\n",
      "[484/1600] D loss: 0.9182, G loss: 1.2769\n",
      "[604/1600] D loss: 0.2779, G loss: 2.1919\n",
      "[724/1600] D loss: 0.6872, G loss: 2.2801\n",
      "[844/1600] D loss: 0.8040, G loss: 1.0556\n",
      "[964/1600] D loss: 0.9087, G loss: 1.4436\n",
      "[1084/1600] D loss: 0.9193, G loss: 2.4898\n",
      "[1204/1600] D loss: 0.7763, G loss: 3.1043\n",
      "[1324/1600] D loss: 0.4463, G loss: 3.7845\n",
      "[1444/1600] D loss: 0.7738, G loss: 1.8173\n",
      "[1564/1600] D loss: 0.6058, G loss: 3.8141\n",
      "train error: \n",
      " D loss: 0.615279, G loss: 3.045973, D accuracy: 85.6%, cell accuracy: 95.4%, board accuracy: 5.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.603620, G loss: 4.438206, D accuracy: 86.4%, cell accuracy: 94.9%, board accuracy: 3.8% \n",
      "\n",
      "Epoch 164\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6924, G loss: 2.5587\n",
      "[124/1600] D loss: 0.7670, G loss: 2.2840\n",
      "[244/1600] D loss: 0.3077, G loss: 2.7163\n",
      "[364/1600] D loss: 0.3044, G loss: 3.3255\n",
      "[484/1600] D loss: 0.3738, G loss: 2.7871\n",
      "[604/1600] D loss: 0.7188, G loss: 3.8261\n",
      "[724/1600] D loss: 0.3310, G loss: 3.1840\n",
      "[844/1600] D loss: 1.0670, G loss: 2.7086\n",
      "[964/1600] D loss: 0.9392, G loss: 2.6187\n",
      "[1084/1600] D loss: 0.8939, G loss: 3.5074\n",
      "[1204/1600] D loss: 0.3585, G loss: 6.8774\n",
      "[1324/1600] D loss: 0.7830, G loss: 1.9130\n",
      "[1444/1600] D loss: 0.0215, G loss: 5.1502\n",
      "[1564/1600] D loss: 0.2153, G loss: 3.2043\n",
      "train error: \n",
      " D loss: 0.692787, G loss: 2.284362, D accuracy: 82.4%, cell accuracy: 95.3%, board accuracy: 3.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.548673, G loss: 3.589081, D accuracy: 87.8%, cell accuracy: 94.8%, board accuracy: 3.5% \n",
      "\n",
      "Epoch 165\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5026, G loss: 2.5172\n",
      "[124/1600] D loss: 0.2994, G loss: 3.8079\n",
      "[244/1600] D loss: 1.2436, G loss: 2.5493\n",
      "[364/1600] D loss: 0.5046, G loss: 3.6424\n",
      "[484/1600] D loss: 0.2319, G loss: 4.9297\n",
      "[604/1600] D loss: 0.3818, G loss: 3.0588\n",
      "[724/1600] D loss: 0.1231, G loss: 4.4408\n",
      "[844/1600] D loss: 0.9550, G loss: 2.2191\n",
      "[964/1600] D loss: 0.5516, G loss: 3.1288\n",
      "[1084/1600] D loss: 0.6675, G loss: 3.8191\n",
      "[1204/1600] D loss: 0.5455, G loss: 6.9193\n",
      "[1324/1600] D loss: 0.4827, G loss: 1.9974\n",
      "[1444/1600] D loss: 1.5597, G loss: 1.2055\n",
      "[1564/1600] D loss: 0.3246, G loss: 2.4482\n",
      "train error: \n",
      " D loss: 0.617809, G loss: 2.570030, D accuracy: 84.7%, cell accuracy: 95.4%, board accuracy: 4.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.580419, G loss: 3.923423, D accuracy: 86.2%, cell accuracy: 94.9%, board accuracy: 3.5% \n",
      "\n",
      "Epoch 166\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8263, G loss: 1.1191\n",
      "[124/1600] D loss: 0.8286, G loss: 2.5268\n",
      "[244/1600] D loss: 0.2305, G loss: 2.0317\n",
      "[364/1600] D loss: 0.4427, G loss: 3.8575\n",
      "[484/1600] D loss: 0.4834, G loss: 2.2599\n",
      "[604/1600] D loss: 0.2639, G loss: 2.5218\n",
      "[724/1600] D loss: 0.6915, G loss: 1.5404\n",
      "[844/1600] D loss: 0.2766, G loss: 5.1316\n",
      "[964/1600] D loss: 0.3547, G loss: 2.4246\n",
      "[1084/1600] D loss: 0.4762, G loss: 4.6127\n",
      "[1204/1600] D loss: 0.6489, G loss: 1.4896\n",
      "[1324/1600] D loss: 0.6714, G loss: 1.4815\n",
      "[1444/1600] D loss: 0.1754, G loss: 2.6331\n",
      "[1564/1600] D loss: 0.9144, G loss: 3.3820\n",
      "train error: \n",
      " D loss: 0.702263, G loss: 2.184777, D accuracy: 81.8%, cell accuracy: 95.4%, board accuracy: 5.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.568079, G loss: 3.486093, D accuracy: 85.9%, cell accuracy: 94.9%, board accuracy: 3.2% \n",
      "\n",
      "Epoch 167\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6788, G loss: 1.1981\n",
      "[124/1600] D loss: 1.4692, G loss: 2.6168\n",
      "[244/1600] D loss: 0.6633, G loss: 1.6203\n",
      "[364/1600] D loss: 0.1920, G loss: 2.5475\n",
      "[484/1600] D loss: 0.0778, G loss: 4.8316\n",
      "[604/1600] D loss: 0.5563, G loss: 2.5797\n",
      "[724/1600] D loss: 0.5997, G loss: 2.8619\n",
      "[844/1600] D loss: 1.0392, G loss: 1.2608\n",
      "[964/1600] D loss: 0.7389, G loss: 3.8347\n",
      "[1084/1600] D loss: 0.3651, G loss: 1.8801\n",
      "[1204/1600] D loss: 0.7620, G loss: 1.5431\n",
      "[1324/1600] D loss: 0.3019, G loss: 3.5443\n",
      "[1444/1600] D loss: 0.2932, G loss: 3.2556\n",
      "[1564/1600] D loss: 0.7781, G loss: 2.1212\n",
      "train error: \n",
      " D loss: 0.611815, G loss: 2.797370, D accuracy: 84.8%, cell accuracy: 95.3%, board accuracy: 5.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.583084, G loss: 4.041982, D accuracy: 86.4%, cell accuracy: 94.9%, board accuracy: 4.8% \n",
      "\n",
      "Epoch 168\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5287, G loss: 2.5232\n",
      "[124/1600] D loss: 0.8784, G loss: 1.1054\n",
      "[244/1600] D loss: 0.9464, G loss: 0.8174\n",
      "[364/1600] D loss: 0.6480, G loss: 2.6070\n",
      "[484/1600] D loss: 0.4854, G loss: 3.2096\n",
      "[604/1600] D loss: 0.6741, G loss: 1.5800\n",
      "[724/1600] D loss: 1.0823, G loss: 0.7082\n",
      "[844/1600] D loss: 1.1953, G loss: 1.7818\n",
      "[964/1600] D loss: 0.4502, G loss: 3.4808\n",
      "[1084/1600] D loss: 0.9933, G loss: 3.9948\n",
      "[1204/1600] D loss: 0.3663, G loss: 3.1531\n",
      "[1324/1600] D loss: 0.6897, G loss: 1.7858\n",
      "[1444/1600] D loss: 1.1241, G loss: 1.1101\n",
      "[1564/1600] D loss: 1.1215, G loss: 2.2109\n",
      "train error: \n",
      " D loss: 0.639995, G loss: 2.957326, D accuracy: 84.3%, cell accuracy: 95.4%, board accuracy: 5.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.634027, G loss: 4.297523, D accuracy: 85.4%, cell accuracy: 94.9%, board accuracy: 4.2% \n",
      "\n",
      "Epoch 169\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.5573, G loss: 1.1832\n",
      "[124/1600] D loss: 0.5817, G loss: 4.0362\n",
      "[244/1600] D loss: 0.4435, G loss: 2.9576\n",
      "[364/1600] D loss: 1.3379, G loss: 1.5558\n",
      "[484/1600] D loss: 0.2568, G loss: 4.3239\n",
      "[604/1600] D loss: 0.8138, G loss: 2.9718\n",
      "[724/1600] D loss: 0.9542, G loss: 1.7191\n",
      "[844/1600] D loss: 0.7976, G loss: 3.0032\n",
      "[964/1600] D loss: 0.3393, G loss: 3.5980\n",
      "[1084/1600] D loss: 0.8665, G loss: 1.4586\n",
      "[1204/1600] D loss: 0.3474, G loss: 4.1253\n",
      "[1324/1600] D loss: 0.6702, G loss: 4.6994\n",
      "[1444/1600] D loss: 0.7992, G loss: 1.4761\n",
      "[1564/1600] D loss: 0.6168, G loss: 3.0040\n",
      "train error: \n",
      " D loss: 0.588117, G loss: 2.831317, D accuracy: 86.2%, cell accuracy: 95.4%, board accuracy: 4.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.589294, G loss: 4.120712, D accuracy: 87.0%, cell accuracy: 94.9%, board accuracy: 4.2% \n",
      "\n",
      "Epoch 170\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5897, G loss: 2.9061\n",
      "[124/1600] D loss: 0.2071, G loss: 2.8307\n",
      "[244/1600] D loss: 0.7243, G loss: 1.7538\n",
      "[364/1600] D loss: 0.3749, G loss: 4.9124\n",
      "[484/1600] D loss: 0.8229, G loss: 2.9935\n",
      "[604/1600] D loss: 0.4081, G loss: 3.2693\n",
      "[724/1600] D loss: 0.5942, G loss: 2.6447\n",
      "[844/1600] D loss: 0.5283, G loss: 3.3581\n",
      "[964/1600] D loss: 0.7497, G loss: 3.0352\n",
      "[1084/1600] D loss: 0.2204, G loss: 3.0624\n",
      "[1204/1600] D loss: 0.5756, G loss: 3.6122\n",
      "[1324/1600] D loss: 0.3022, G loss: 2.5412\n",
      "[1444/1600] D loss: 0.8463, G loss: 1.7282\n",
      "[1564/1600] D loss: 0.7203, G loss: 2.5715\n",
      "train error: \n",
      " D loss: 0.610786, G loss: 2.625747, D accuracy: 84.9%, cell accuracy: 95.4%, board accuracy: 5.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.557115, G loss: 4.019952, D accuracy: 86.9%, cell accuracy: 94.9%, board accuracy: 3.8% \n",
      "\n",
      "Epoch 171\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9942, G loss: 1.2553\n",
      "[124/1600] D loss: 0.4138, G loss: 2.8233\n",
      "[244/1600] D loss: 0.4878, G loss: 3.2857\n",
      "[364/1600] D loss: 0.4408, G loss: 2.5561\n",
      "[484/1600] D loss: 0.1221, G loss: 5.9900\n",
      "[604/1600] D loss: 0.4295, G loss: 6.2954\n",
      "[724/1600] D loss: 0.3679, G loss: 5.5213\n",
      "[844/1600] D loss: 0.7588, G loss: 3.1752\n",
      "[964/1600] D loss: 0.6639, G loss: 2.3636\n",
      "[1084/1600] D loss: 0.4479, G loss: 3.4292\n",
      "[1204/1600] D loss: 0.6762, G loss: 1.4204\n",
      "[1324/1600] D loss: 0.9684, G loss: 1.1819\n",
      "[1444/1600] D loss: 0.8535, G loss: 2.5952\n",
      "[1564/1600] D loss: 0.2391, G loss: 4.7177\n",
      "train error: \n",
      " D loss: 0.620447, G loss: 2.363887, D accuracy: 84.6%, cell accuracy: 95.4%, board accuracy: 4.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.491335, G loss: 3.677761, D accuracy: 88.5%, cell accuracy: 94.9%, board accuracy: 3.8% \n",
      "\n",
      "Epoch 172\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7190, G loss: 1.3679\n",
      "[124/1600] D loss: 0.9918, G loss: 0.8224\n",
      "[244/1600] D loss: 0.7122, G loss: 1.6499\n",
      "[364/1600] D loss: 0.7662, G loss: 3.0715\n",
      "[484/1600] D loss: 0.4533, G loss: 4.3474\n",
      "[604/1600] D loss: 0.1593, G loss: 5.9811\n",
      "[724/1600] D loss: 0.8039, G loss: 5.4727\n",
      "[844/1600] D loss: 0.1026, G loss: 4.5842\n",
      "[964/1600] D loss: 0.6356, G loss: 2.2423\n",
      "[1084/1600] D loss: 0.4597, G loss: 3.6617\n",
      "[1204/1600] D loss: 0.5534, G loss: 3.3948\n",
      "[1324/1600] D loss: 1.3087, G loss: 0.7937\n",
      "[1444/1600] D loss: 1.1873, G loss: 1.4107\n",
      "[1564/1600] D loss: 0.6894, G loss: 3.5056\n",
      "train error: \n",
      " D loss: 0.696236, G loss: 2.237456, D accuracy: 82.2%, cell accuracy: 95.4%, board accuracy: 5.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.546932, G loss: 3.639470, D accuracy: 87.1%, cell accuracy: 95.0%, board accuracy: 3.5% \n",
      "\n",
      "Epoch 173\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.3168, G loss: 4.3678\n",
      "[124/1600] D loss: 1.8483, G loss: 0.9492\n",
      "[244/1600] D loss: 1.2517, G loss: 2.1531\n",
      "[364/1600] D loss: 0.8517, G loss: 1.3919\n",
      "[484/1600] D loss: 0.5635, G loss: 2.1090\n",
      "[604/1600] D loss: 1.2039, G loss: 0.9479\n",
      "[724/1600] D loss: 0.8173, G loss: 2.3967\n",
      "[844/1600] D loss: 0.4333, G loss: 2.4311\n",
      "[964/1600] D loss: 0.2051, G loss: 3.2951\n",
      "[1084/1600] D loss: 0.9456, G loss: 2.7465\n",
      "[1204/1600] D loss: 1.0095, G loss: 2.3893\n",
      "[1324/1600] D loss: 0.3277, G loss: 2.2114\n",
      "[1444/1600] D loss: 0.4276, G loss: 4.2934\n",
      "[1564/1600] D loss: 0.2707, G loss: 2.6403\n",
      "train error: \n",
      " D loss: 0.638050, G loss: 2.812858, D accuracy: 84.2%, cell accuracy: 95.6%, board accuracy: 5.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.584682, G loss: 4.384834, D accuracy: 85.6%, cell accuracy: 95.0%, board accuracy: 4.2% \n",
      "\n",
      "Epoch 174\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8185, G loss: 2.0531\n",
      "[124/1600] D loss: 0.4458, G loss: 3.7564\n",
      "[244/1600] D loss: 0.8635, G loss: 1.6625\n",
      "[364/1600] D loss: 0.8230, G loss: 1.2943\n",
      "[484/1600] D loss: 0.2054, G loss: 3.7984\n",
      "[604/1600] D loss: 1.1578, G loss: 4.7934\n",
      "[724/1600] D loss: 0.5847, G loss: 1.3821\n",
      "[844/1600] D loss: 0.5845, G loss: 2.8730\n",
      "[964/1600] D loss: 0.8510, G loss: 4.1047\n",
      "[1084/1600] D loss: 1.0524, G loss: 3.4564\n",
      "[1204/1600] D loss: 0.7570, G loss: 4.0983\n",
      "[1324/1600] D loss: 1.0188, G loss: 1.0585\n",
      "[1444/1600] D loss: 0.9702, G loss: 2.4015\n",
      "[1564/1600] D loss: 0.6071, G loss: 1.8826\n",
      "train error: \n",
      " D loss: 0.652323, G loss: 3.144972, D accuracy: 83.9%, cell accuracy: 95.5%, board accuracy: 5.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.665852, G loss: 4.692382, D accuracy: 84.9%, cell accuracy: 95.0%, board accuracy: 4.8% \n",
      "\n",
      "Epoch 175\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8049, G loss: 2.5357\n",
      "[124/1600] D loss: 0.7426, G loss: 4.4888\n",
      "[244/1600] D loss: 0.9828, G loss: 2.7689\n",
      "[364/1600] D loss: 1.0547, G loss: 2.6695\n",
      "[484/1600] D loss: 0.4766, G loss: 2.2882\n",
      "[604/1600] D loss: 0.4291, G loss: 2.8300\n",
      "[724/1600] D loss: 0.6999, G loss: 3.6007\n",
      "[844/1600] D loss: 0.1233, G loss: 3.0537\n",
      "[964/1600] D loss: 0.9102, G loss: 1.8372\n",
      "[1084/1600] D loss: 0.8932, G loss: 1.5172\n",
      "[1204/1600] D loss: 1.0885, G loss: 2.1419\n",
      "[1324/1600] D loss: 0.2180, G loss: 3.4773\n",
      "[1444/1600] D loss: 0.6473, G loss: 3.5784\n",
      "[1564/1600] D loss: 0.8588, G loss: 1.7467\n",
      "train error: \n",
      " D loss: 0.631314, G loss: 3.135427, D accuracy: 84.2%, cell accuracy: 95.6%, board accuracy: 5.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.685383, G loss: 4.713135, D accuracy: 83.9%, cell accuracy: 95.1%, board accuracy: 4.5% \n",
      "\n",
      "Epoch 176\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6814, G loss: 3.1806\n",
      "[124/1600] D loss: 0.8333, G loss: 1.4937\n",
      "[244/1600] D loss: 0.7284, G loss: 2.7832\n",
      "[364/1600] D loss: 0.4483, G loss: 4.3555\n",
      "[484/1600] D loss: 0.2761, G loss: 4.1594\n",
      "[604/1600] D loss: 0.6087, G loss: 2.7056\n",
      "[724/1600] D loss: 0.3267, G loss: 2.9371\n",
      "[844/1600] D loss: 0.4189, G loss: 3.2743\n",
      "[964/1600] D loss: 0.4800, G loss: 3.3331\n",
      "[1084/1600] D loss: 0.5412, G loss: 2.3743\n",
      "[1204/1600] D loss: 0.6556, G loss: 2.7109\n",
      "[1324/1600] D loss: 0.7653, G loss: 1.4077\n",
      "[1444/1600] D loss: 0.8795, G loss: 0.8643\n",
      "[1564/1600] D loss: 0.6074, G loss: 1.6433\n",
      "train error: \n",
      " D loss: 0.729096, G loss: 3.532626, D accuracy: 80.8%, cell accuracy: 95.5%, board accuracy: 5.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.804947, G loss: 5.043050, D accuracy: 80.4%, cell accuracy: 95.1%, board accuracy: 4.5% \n",
      "\n",
      "Epoch 177\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8391, G loss: 2.4988\n",
      "[124/1600] D loss: 0.7108, G loss: 2.2742\n",
      "[244/1600] D loss: 1.0730, G loss: 1.4959\n",
      "[364/1600] D loss: 0.8960, G loss: 1.3159\n",
      "[484/1600] D loss: 0.7730, G loss: 3.0881\n",
      "[604/1600] D loss: 0.3029, G loss: 1.9261\n",
      "[724/1600] D loss: 0.8233, G loss: 1.7351\n",
      "[844/1600] D loss: 0.2551, G loss: 3.4233\n",
      "[964/1600] D loss: 0.4647, G loss: 5.2218\n",
      "[1084/1600] D loss: 1.5336, G loss: 0.6071\n",
      "[1204/1600] D loss: 0.8742, G loss: 2.7799\n",
      "[1324/1600] D loss: 0.6119, G loss: 2.9675\n",
      "[1444/1600] D loss: 0.5620, G loss: 3.7557\n",
      "[1564/1600] D loss: 0.0507, G loss: 4.7376\n",
      "train error: \n",
      " D loss: 0.637370, G loss: 3.245498, D accuracy: 84.2%, cell accuracy: 95.6%, board accuracy: 5.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.675235, G loss: 4.643320, D accuracy: 83.9%, cell accuracy: 95.1%, board accuracy: 4.5% \n",
      "\n",
      "Epoch 178\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.6673, G loss: 2.5976\n",
      "[124/1600] D loss: 0.5292, G loss: 4.3691\n",
      "[244/1600] D loss: 0.2551, G loss: 5.2421\n",
      "[364/1600] D loss: 0.4110, G loss: 3.6787\n",
      "[484/1600] D loss: 0.7160, G loss: 2.1040\n",
      "[604/1600] D loss: 0.2711, G loss: 4.3275\n",
      "[724/1600] D loss: 0.3741, G loss: 2.6978\n",
      "[844/1600] D loss: 1.1692, G loss: 1.0394\n",
      "[964/1600] D loss: 0.7813, G loss: 1.9679\n",
      "[1084/1600] D loss: 0.1589, G loss: 3.8646\n",
      "[1204/1600] D loss: 0.3958, G loss: 5.4025\n",
      "[1324/1600] D loss: 1.3303, G loss: 2.9605\n",
      "[1444/1600] D loss: 0.2423, G loss: 2.3260\n",
      "[1564/1600] D loss: 0.4177, G loss: 4.8133\n",
      "train error: \n",
      " D loss: 0.578989, G loss: 2.676450, D accuracy: 86.7%, cell accuracy: 95.5%, board accuracy: 5.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.507260, G loss: 4.264849, D accuracy: 89.2%, cell accuracy: 94.9%, board accuracy: 4.2% \n",
      "\n",
      "Epoch 179\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5997, G loss: 1.7930\n",
      "[124/1600] D loss: 0.5824, G loss: 2.0568\n",
      "[244/1600] D loss: 1.2452, G loss: 2.3634\n",
      "[364/1600] D loss: 0.3668, G loss: 2.2567\n",
      "[484/1600] D loss: 1.0241, G loss: 1.6854\n",
      "[604/1600] D loss: 0.8048, G loss: 1.4167\n",
      "[724/1600] D loss: 0.9103, G loss: 2.7127\n",
      "[844/1600] D loss: 0.1594, G loss: 3.9481\n",
      "[964/1600] D loss: 0.3950, G loss: 3.2250\n",
      "[1084/1600] D loss: 0.8269, G loss: 1.6160\n",
      "[1204/1600] D loss: 0.6271, G loss: 1.9347\n",
      "[1324/1600] D loss: 1.0943, G loss: 2.0277\n",
      "[1444/1600] D loss: 0.3557, G loss: 2.8048\n",
      "[1564/1600] D loss: 0.4779, G loss: 2.0060\n",
      "train error: \n",
      " D loss: 0.581760, G loss: 2.711429, D accuracy: 86.3%, cell accuracy: 95.5%, board accuracy: 5.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.544755, G loss: 4.352674, D accuracy: 87.4%, cell accuracy: 95.0%, board accuracy: 3.8% \n",
      "\n",
      "Epoch 180\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2205, G loss: 0.8041\n",
      "[124/1600] D loss: 1.2347, G loss: 0.8938\n",
      "[244/1600] D loss: 0.3077, G loss: 3.4859\n",
      "[364/1600] D loss: 0.8193, G loss: 2.0895\n",
      "[484/1600] D loss: 0.9569, G loss: 2.1543\n",
      "[604/1600] D loss: 0.1627, G loss: 4.5867\n",
      "[724/1600] D loss: 1.0875, G loss: 3.6646\n",
      "[844/1600] D loss: 0.6344, G loss: 1.7929\n",
      "[964/1600] D loss: 0.0969, G loss: 7.1395\n",
      "[1084/1600] D loss: 0.3022, G loss: 2.3110\n",
      "[1204/1600] D loss: 1.3527, G loss: 1.0403\n",
      "[1324/1600] D loss: 0.5052, G loss: 3.8611\n",
      "[1444/1600] D loss: 0.6656, G loss: 2.4291\n",
      "[1564/1600] D loss: 0.5336, G loss: 3.8715\n",
      "train error: \n",
      " D loss: 0.575323, G loss: 2.985278, D accuracy: 86.7%, cell accuracy: 95.5%, board accuracy: 6.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.569635, G loss: 4.514057, D accuracy: 86.9%, cell accuracy: 95.0%, board accuracy: 4.5% \n",
      "\n",
      "Epoch 181\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0167, G loss: 2.3199\n",
      "[124/1600] D loss: 1.2130, G loss: 2.6281\n",
      "[244/1600] D loss: 0.4469, G loss: 3.0837\n",
      "[364/1600] D loss: 0.2184, G loss: 5.5692\n",
      "[484/1600] D loss: 0.9172, G loss: 2.2444\n",
      "[604/1600] D loss: 0.5420, G loss: 2.2270\n",
      "[724/1600] D loss: 0.1374, G loss: 4.4410\n",
      "[844/1600] D loss: 0.5534, G loss: 3.5198\n",
      "[964/1600] D loss: 1.5822, G loss: 1.2640\n",
      "[1084/1600] D loss: 0.4249, G loss: 3.3817\n",
      "[1204/1600] D loss: 0.6241, G loss: 3.2699\n",
      "[1324/1600] D loss: 0.5531, G loss: 2.2490\n",
      "[1444/1600] D loss: 0.4084, G loss: 2.7559\n",
      "[1564/1600] D loss: 0.3602, G loss: 4.4015\n",
      "train error: \n",
      " D loss: 0.607580, G loss: 3.253811, D accuracy: 85.2%, cell accuracy: 95.6%, board accuracy: 6.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.627612, G loss: 4.927019, D accuracy: 85.1%, cell accuracy: 95.1%, board accuracy: 4.2% \n",
      "\n",
      "Epoch 182\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9996, G loss: 2.8004\n",
      "[124/1600] D loss: 0.4694, G loss: 2.4160\n",
      "[244/1600] D loss: 0.4361, G loss: 2.7343\n",
      "[364/1600] D loss: 0.6811, G loss: 2.6499\n",
      "[484/1600] D loss: 0.5679, G loss: 3.4484\n",
      "[604/1600] D loss: 0.6839, G loss: 2.5155\n",
      "[724/1600] D loss: 1.1363, G loss: 1.3113\n",
      "[844/1600] D loss: 0.4993, G loss: 1.6050\n",
      "[964/1600] D loss: 0.3183, G loss: 4.1345\n",
      "[1084/1600] D loss: 1.1600, G loss: 3.4110\n",
      "[1204/1600] D loss: 0.0775, G loss: 4.7362\n",
      "[1324/1600] D loss: 0.8090, G loss: 1.6392\n",
      "[1444/1600] D loss: 0.2010, G loss: 3.4694\n",
      "[1564/1600] D loss: 0.2887, G loss: 3.6031\n",
      "train error: \n",
      " D loss: 0.578068, G loss: 3.097921, D accuracy: 86.1%, cell accuracy: 95.6%, board accuracy: 5.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.608103, G loss: 4.778411, D accuracy: 86.1%, cell accuracy: 95.1%, board accuracy: 4.5% \n",
      "\n",
      "Epoch 183\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5113, G loss: 4.8509\n",
      "[124/1600] D loss: 0.6400, G loss: 3.1571\n",
      "[244/1600] D loss: 0.4507, G loss: 3.2938\n",
      "[364/1600] D loss: 0.6574, G loss: 3.6010\n",
      "[484/1600] D loss: 0.3130, G loss: 4.1324\n",
      "[604/1600] D loss: 0.8341, G loss: 4.0603\n",
      "[724/1600] D loss: 1.2648, G loss: 1.0801\n",
      "[844/1600] D loss: 1.0350, G loss: 1.3505\n",
      "[964/1600] D loss: 1.3062, G loss: 1.0064\n",
      "[1084/1600] D loss: 0.8304, G loss: 1.8970\n",
      "[1204/1600] D loss: 0.8421, G loss: 1.8419\n",
      "[1324/1600] D loss: 0.3227, G loss: 3.9826\n",
      "[1444/1600] D loss: 0.1418, G loss: 3.8942\n",
      "[1564/1600] D loss: 0.5520, G loss: 3.8108\n",
      "train error: \n",
      " D loss: 0.599196, G loss: 2.809247, D accuracy: 85.9%, cell accuracy: 95.6%, board accuracy: 6.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.563762, G loss: 4.455913, D accuracy: 86.2%, cell accuracy: 95.1%, board accuracy: 4.0% \n",
      "\n",
      "Epoch 184\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8688, G loss: 1.5484\n",
      "[124/1600] D loss: 0.7310, G loss: 1.5559\n",
      "[244/1600] D loss: 0.4882, G loss: 1.6511\n",
      "[364/1600] D loss: 0.4118, G loss: 3.6230\n",
      "[484/1600] D loss: 0.5228, G loss: 2.8337\n",
      "[604/1600] D loss: 0.0850, G loss: 4.7024\n",
      "[724/1600] D loss: 0.5221, G loss: 2.2182\n",
      "[844/1600] D loss: 0.7291, G loss: 3.1110\n",
      "[964/1600] D loss: 0.4445, G loss: 4.0647\n",
      "[1084/1600] D loss: 0.1716, G loss: 5.0308\n",
      "[1204/1600] D loss: 0.8181, G loss: 3.8947\n",
      "[1324/1600] D loss: 1.0144, G loss: 1.7608\n",
      "[1444/1600] D loss: 0.6298, G loss: 5.6366\n",
      "[1564/1600] D loss: 0.5649, G loss: 1.9709\n",
      "train error: \n",
      " D loss: 0.598637, G loss: 2.679626, D accuracy: 85.5%, cell accuracy: 95.6%, board accuracy: 6.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.528986, G loss: 4.294106, D accuracy: 87.8%, cell accuracy: 95.0%, board accuracy: 4.0% \n",
      "\n",
      "Epoch 185\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.2294, G loss: 2.3112\n",
      "[124/1600] D loss: 0.7606, G loss: 1.8819\n",
      "[244/1600] D loss: 0.7599, G loss: 1.7674\n",
      "[364/1600] D loss: 0.3841, G loss: 4.5543\n",
      "[484/1600] D loss: 0.0754, G loss: 6.8876\n",
      "[604/1600] D loss: 0.6345, G loss: 1.6495\n",
      "[724/1600] D loss: 0.2875, G loss: 2.0300\n",
      "[844/1600] D loss: 0.2545, G loss: 3.9518\n",
      "[964/1600] D loss: 0.4718, G loss: 3.7634\n",
      "[1084/1600] D loss: 0.4568, G loss: 2.5580\n",
      "[1204/1600] D loss: 0.7294, G loss: 2.0382\n",
      "[1324/1600] D loss: 1.1234, G loss: 2.7159\n",
      "[1444/1600] D loss: 0.4750, G loss: 2.0590\n",
      "[1564/1600] D loss: 0.0720, G loss: 5.8260\n",
      "train error: \n",
      " D loss: 0.587230, G loss: 2.783744, D accuracy: 85.8%, cell accuracy: 95.6%, board accuracy: 6.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.563615, G loss: 4.477387, D accuracy: 87.8%, cell accuracy: 95.1%, board accuracy: 4.5% \n",
      "\n",
      "Epoch 186\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8228, G loss: 1.5961\n",
      "[124/1600] D loss: 0.8542, G loss: 1.7918\n",
      "[244/1600] D loss: 0.4196, G loss: 4.6310\n",
      "[364/1600] D loss: 0.5960, G loss: 3.1835\n",
      "[484/1600] D loss: 0.8296, G loss: 2.4427\n",
      "[604/1600] D loss: 1.0416, G loss: 1.6527\n",
      "[724/1600] D loss: 0.5831, G loss: 3.8019\n",
      "[844/1600] D loss: 0.6124, G loss: 3.0748\n",
      "[964/1600] D loss: 0.7450, G loss: 1.5816\n",
      "[1084/1600] D loss: 0.9922, G loss: 1.4920\n",
      "[1204/1600] D loss: 0.2865, G loss: 3.0683\n",
      "[1324/1600] D loss: 1.1501, G loss: 2.2194\n",
      "[1444/1600] D loss: 0.5035, G loss: 2.2852\n",
      "[1564/1600] D loss: 0.9308, G loss: 1.7788\n",
      "train error: \n",
      " D loss: 0.616456, G loss: 3.346672, D accuracy: 84.9%, cell accuracy: 95.6%, board accuracy: 6.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.661103, G loss: 5.030558, D accuracy: 84.6%, cell accuracy: 95.1%, board accuracy: 4.0% \n",
      "\n",
      "Epoch 187\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4676, G loss: 4.2333\n",
      "[124/1600] D loss: 0.4270, G loss: 4.0452\n",
      "[244/1600] D loss: 0.4022, G loss: 2.5885\n",
      "[364/1600] D loss: 0.3639, G loss: 3.0060\n",
      "[484/1600] D loss: 0.7963, G loss: 1.9077\n",
      "[604/1600] D loss: 0.4432, G loss: 3.5356\n",
      "[724/1600] D loss: 0.5302, G loss: 1.4544\n",
      "[844/1600] D loss: 0.6553, G loss: 3.4365\n",
      "[964/1600] D loss: 0.2979, G loss: 3.0488\n",
      "[1084/1600] D loss: 0.3629, G loss: 3.8068\n",
      "[1204/1600] D loss: 0.7610, G loss: 2.3288\n",
      "[1324/1600] D loss: 0.7314, G loss: 1.7702\n",
      "[1444/1600] D loss: 1.2369, G loss: 1.3962\n",
      "[1564/1600] D loss: 0.9157, G loss: 4.2174\n",
      "train error: \n",
      " D loss: 0.618163, G loss: 2.472392, D accuracy: 85.1%, cell accuracy: 95.6%, board accuracy: 5.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.497959, G loss: 4.175840, D accuracy: 88.8%, cell accuracy: 95.1%, board accuracy: 3.5% \n",
      "\n",
      "Epoch 188\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6230, G loss: 2.2291\n",
      "[124/1600] D loss: 0.2650, G loss: 4.3336\n",
      "[244/1600] D loss: 1.2387, G loss: 1.1012\n",
      "[364/1600] D loss: 0.4238, G loss: 4.9562\n",
      "[484/1600] D loss: 1.0993, G loss: 1.0186\n",
      "[604/1600] D loss: 0.7613, G loss: 3.4788\n",
      "[724/1600] D loss: 0.5666, G loss: 4.5139\n",
      "[844/1600] D loss: 1.0092, G loss: 1.7746\n",
      "[964/1600] D loss: 1.0673, G loss: 6.1450\n",
      "[1084/1600] D loss: 1.0028, G loss: 1.6983\n",
      "[1204/1600] D loss: 0.6541, G loss: 2.9035\n",
      "[1324/1600] D loss: 0.5137, G loss: 1.7872\n",
      "[1444/1600] D loss: 0.4781, G loss: 2.5738\n",
      "[1564/1600] D loss: 0.1729, G loss: 3.6928\n",
      "train error: \n",
      " D loss: 0.672871, G loss: 2.412609, D accuracy: 83.2%, cell accuracy: 95.6%, board accuracy: 6.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.509211, G loss: 4.137310, D accuracy: 88.2%, cell accuracy: 95.1%, board accuracy: 4.2% \n",
      "\n",
      "Epoch 189\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4439, G loss: 2.1349\n",
      "[124/1600] D loss: 0.3187, G loss: 3.6130\n",
      "[244/1600] D loss: 0.0689, G loss: 7.6392\n",
      "[364/1600] D loss: 1.1655, G loss: 4.2130\n",
      "[484/1600] D loss: 0.6977, G loss: 5.4032\n",
      "[604/1600] D loss: 1.6140, G loss: 0.8937\n",
      "[724/1600] D loss: 0.0350, G loss: 5.8243\n",
      "[844/1600] D loss: 0.9594, G loss: 3.6413\n",
      "[964/1600] D loss: 0.7645, G loss: 3.1631\n",
      "[1084/1600] D loss: 0.0056, G loss: 6.5951\n",
      "[1204/1600] D loss: 0.5961, G loss: 3.7411\n",
      "[1324/1600] D loss: 0.4975, G loss: 2.9777\n",
      "[1444/1600] D loss: 0.5872, G loss: 6.6049\n",
      "[1564/1600] D loss: 0.8226, G loss: 2.6076\n",
      "train error: \n",
      " D loss: 0.598593, G loss: 3.160164, D accuracy: 85.5%, cell accuracy: 95.6%, board accuracy: 5.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.635376, G loss: 4.849007, D accuracy: 85.2%, cell accuracy: 95.1%, board accuracy: 4.2% \n",
      "\n",
      "Epoch 190\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6766, G loss: 4.8571\n",
      "[124/1600] D loss: 0.4911, G loss: 5.3038\n",
      "[244/1600] D loss: 0.4945, G loss: 3.0383\n",
      "[364/1600] D loss: 0.7127, G loss: 3.1145\n",
      "[484/1600] D loss: 0.3420, G loss: 4.2285\n",
      "[604/1600] D loss: 0.7311, G loss: 1.4511\n",
      "[724/1600] D loss: 0.2979, G loss: 2.4132\n",
      "[844/1600] D loss: 0.6381, G loss: 1.8954\n",
      "[964/1600] D loss: 0.4040, G loss: 3.0522\n",
      "[1084/1600] D loss: 0.9192, G loss: 1.2277\n",
      "[1204/1600] D loss: 0.1622, G loss: 3.8090\n",
      "[1324/1600] D loss: 0.9001, G loss: 1.2989\n",
      "[1444/1600] D loss: 0.1330, G loss: 4.2201\n",
      "[1564/1600] D loss: 0.6090, G loss: 2.6103\n",
      "train error: \n",
      " D loss: 0.623809, G loss: 2.878352, D accuracy: 84.6%, cell accuracy: 95.6%, board accuracy: 6.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.550473, G loss: 4.584531, D accuracy: 87.9%, cell accuracy: 95.0%, board accuracy: 3.8% \n",
      "\n",
      "Epoch 191\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6770, G loss: 2.0701\n",
      "[124/1600] D loss: 0.6614, G loss: 2.5585\n",
      "[244/1600] D loss: 1.2196, G loss: 1.2618\n",
      "[364/1600] D loss: 0.3937, G loss: 4.0454\n",
      "[484/1600] D loss: 0.1947, G loss: 3.1852\n",
      "[604/1600] D loss: 0.4468, G loss: 2.6628\n",
      "[724/1600] D loss: 0.8471, G loss: 2.3965\n",
      "[844/1600] D loss: 1.4214, G loss: 0.8570\n",
      "[964/1600] D loss: 0.1243, G loss: 5.6536\n",
      "[1084/1600] D loss: 0.4463, G loss: 4.0504\n",
      "[1204/1600] D loss: 0.5520, G loss: 2.5730\n",
      "[1324/1600] D loss: 0.4017, G loss: 3.6676\n",
      "[1444/1600] D loss: 1.4776, G loss: 0.7771\n",
      "[1564/1600] D loss: 0.6741, G loss: 2.5842\n",
      "train error: \n",
      " D loss: 0.591173, G loss: 2.925123, D accuracy: 86.0%, cell accuracy: 95.6%, board accuracy: 7.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.581629, G loss: 4.599071, D accuracy: 87.2%, cell accuracy: 95.1%, board accuracy: 4.5% \n",
      "\n",
      "Epoch 192\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1019, G loss: 2.5526\n",
      "[124/1600] D loss: 0.7185, G loss: 2.6010\n",
      "[244/1600] D loss: 0.1127, G loss: 4.7596\n",
      "[364/1600] D loss: 0.8707, G loss: 1.7601\n",
      "[484/1600] D loss: 0.2990, G loss: 5.5971\n",
      "[604/1600] D loss: 0.4342, G loss: 3.2140\n",
      "[724/1600] D loss: 0.1549, G loss: 3.6399\n",
      "[844/1600] D loss: 0.8186, G loss: 2.0818\n",
      "[964/1600] D loss: 0.9523, G loss: 2.8433\n",
      "[1084/1600] D loss: 0.8847, G loss: 1.0780\n",
      "[1204/1600] D loss: 0.9757, G loss: 1.3360\n",
      "[1324/1600] D loss: 0.9786, G loss: 3.7026\n",
      "[1444/1600] D loss: 1.3131, G loss: 3.3298\n",
      "[1564/1600] D loss: 1.3120, G loss: 0.9233\n",
      "train error: \n",
      " D loss: 0.609221, G loss: 2.694213, D accuracy: 85.6%, cell accuracy: 95.6%, board accuracy: 7.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.567031, G loss: 4.435830, D accuracy: 86.6%, cell accuracy: 95.1%, board accuracy: 5.0% \n",
      "\n",
      "Epoch 193\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5264, G loss: 1.9678\n",
      "[124/1600] D loss: 0.9139, G loss: 1.9951\n",
      "[244/1600] D loss: 0.4338, G loss: 4.2574\n",
      "[364/1600] D loss: 0.6744, G loss: 5.0987\n",
      "[484/1600] D loss: 0.2658, G loss: 2.4141\n",
      "[604/1600] D loss: 0.2293, G loss: 6.3894\n",
      "[724/1600] D loss: 0.4902, G loss: 2.7698\n",
      "[844/1600] D loss: 0.4768, G loss: 4.3317\n",
      "[964/1600] D loss: 0.6018, G loss: 3.1297\n",
      "[1084/1600] D loss: 0.2657, G loss: 4.0257\n",
      "[1204/1600] D loss: 0.4367, G loss: 3.8286\n",
      "[1324/1600] D loss: 1.0430, G loss: 2.7460\n",
      "[1444/1600] D loss: 1.5995, G loss: 2.2887\n",
      "[1564/1600] D loss: 0.4417, G loss: 2.9723\n",
      "train error: \n",
      " D loss: 0.584373, G loss: 2.845695, D accuracy: 85.3%, cell accuracy: 95.6%, board accuracy: 7.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.553798, G loss: 4.650011, D accuracy: 88.2%, cell accuracy: 95.1%, board accuracy: 5.2% \n",
      "\n",
      "Epoch 194\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9300, G loss: 2.4144\n",
      "[124/1600] D loss: 1.0120, G loss: 2.4371\n",
      "[244/1600] D loss: 0.6173, G loss: 2.4469\n",
      "[364/1600] D loss: 0.7321, G loss: 3.0071\n",
      "[484/1600] D loss: 0.5678, G loss: 3.3132\n",
      "[604/1600] D loss: 1.0356, G loss: 1.9611\n",
      "[724/1600] D loss: 0.2219, G loss: 5.3814\n",
      "[844/1600] D loss: 0.6422, G loss: 2.3919\n",
      "[964/1600] D loss: 0.5462, G loss: 1.7974\n",
      "[1084/1600] D loss: 0.6825, G loss: 3.3352\n",
      "[1204/1600] D loss: 0.3649, G loss: 4.6499\n",
      "[1324/1600] D loss: 0.3943, G loss: 3.6867\n",
      "[1444/1600] D loss: 0.9351, G loss: 2.0245\n",
      "[1564/1600] D loss: 0.3752, G loss: 3.0726\n",
      "train error: \n",
      " D loss: 0.583438, G loss: 3.379914, D accuracy: 85.8%, cell accuracy: 95.7%, board accuracy: 7.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.658702, G loss: 5.229863, D accuracy: 84.9%, cell accuracy: 95.2%, board accuracy: 5.5% \n",
      "\n",
      "Epoch 195\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4556, G loss: 2.6151\n",
      "[124/1600] D loss: 0.2053, G loss: 3.9311\n",
      "[244/1600] D loss: 0.3521, G loss: 4.8906\n",
      "[364/1600] D loss: 0.9247, G loss: 3.4898\n",
      "[484/1600] D loss: 0.5387, G loss: 3.0618\n",
      "[604/1600] D loss: 0.0732, G loss: 5.5359\n",
      "[724/1600] D loss: 0.9880, G loss: 1.0572\n",
      "[844/1600] D loss: 1.1374, G loss: 3.2550\n",
      "[964/1600] D loss: 0.4492, G loss: 3.4580\n",
      "[1084/1600] D loss: 0.5671, G loss: 3.3943\n",
      "[1204/1600] D loss: 0.9232, G loss: 3.1472\n",
      "[1324/1600] D loss: 0.4397, G loss: 3.3642\n",
      "[1444/1600] D loss: 0.6652, G loss: 2.8946\n",
      "[1564/1600] D loss: 0.5365, G loss: 1.9940\n",
      "train error: \n",
      " D loss: 0.591707, G loss: 3.029437, D accuracy: 84.8%, cell accuracy: 95.6%, board accuracy: 7.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.586945, G loss: 4.925489, D accuracy: 87.0%, cell accuracy: 95.1%, board accuracy: 5.5% \n",
      "\n",
      "Epoch 196\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.3309, G loss: 3.6220\n",
      "[124/1600] D loss: 0.5540, G loss: 4.3938\n",
      "[244/1600] D loss: 0.2492, G loss: 4.9868\n",
      "[364/1600] D loss: 0.6794, G loss: 1.5735\n",
      "[484/1600] D loss: 0.4416, G loss: 3.6963\n",
      "[604/1600] D loss: 0.1778, G loss: 3.6042\n",
      "[724/1600] D loss: 0.8591, G loss: 1.5257\n",
      "[844/1600] D loss: 0.5771, G loss: 1.2959\n",
      "[964/1600] D loss: 0.1577, G loss: 5.6830\n",
      "[1084/1600] D loss: 0.7550, G loss: 1.4633\n",
      "[1204/1600] D loss: 0.3800, G loss: 5.4423\n",
      "[1324/1600] D loss: 0.1976, G loss: 4.3016\n",
      "[1444/1600] D loss: 0.4829, G loss: 1.8960\n",
      "[1564/1600] D loss: 0.9492, G loss: 2.1504\n",
      "train error: \n",
      " D loss: 0.566339, G loss: 3.169193, D accuracy: 85.7%, cell accuracy: 95.6%, board accuracy: 6.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.576746, G loss: 5.093377, D accuracy: 87.0%, cell accuracy: 95.1%, board accuracy: 4.2% \n",
      "\n",
      "Epoch 197\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7875, G loss: 1.0995\n",
      "[124/1600] D loss: 0.6215, G loss: 2.5386\n",
      "[244/1600] D loss: 0.6920, G loss: 1.4373\n",
      "[364/1600] D loss: 0.5657, G loss: 2.0797\n",
      "[484/1600] D loss: 0.2043, G loss: 3.6425\n",
      "[604/1600] D loss: 0.3474, G loss: 3.1712\n",
      "[724/1600] D loss: 0.2773, G loss: 2.9399\n",
      "[844/1600] D loss: 0.5330, G loss: 2.2432\n",
      "[964/1600] D loss: 0.8945, G loss: 2.2365\n",
      "[1084/1600] D loss: 0.1239, G loss: 3.8046\n",
      "[1204/1600] D loss: 1.1793, G loss: 2.2431\n",
      "[1324/1600] D loss: 0.5101, G loss: 3.4982\n",
      "[1444/1600] D loss: 0.2020, G loss: 6.9192\n",
      "[1564/1600] D loss: 0.0733, G loss: 4.9915\n",
      "train error: \n",
      " D loss: 0.593424, G loss: 3.577000, D accuracy: 84.8%, cell accuracy: 95.6%, board accuracy: 6.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.675625, G loss: 5.295925, D accuracy: 85.5%, cell accuracy: 95.1%, board accuracy: 5.0% \n",
      "\n",
      "Epoch 198\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4828, G loss: 2.6584\n",
      "[124/1600] D loss: 0.8211, G loss: 1.6624\n",
      "[244/1600] D loss: 0.7104, G loss: 1.1816\n",
      "[364/1600] D loss: 0.9116, G loss: 1.3125\n",
      "[484/1600] D loss: 0.6027, G loss: 4.4789\n",
      "[604/1600] D loss: 0.3496, G loss: 2.9908\n",
      "[724/1600] D loss: 0.7908, G loss: 1.4254\n",
      "[844/1600] D loss: 0.5293, G loss: 2.3966\n",
      "[964/1600] D loss: 0.1692, G loss: 6.1576\n",
      "[1084/1600] D loss: 0.6693, G loss: 2.6174\n",
      "[1204/1600] D loss: 0.5574, G loss: 3.6204\n",
      "[1324/1600] D loss: 0.6690, G loss: 1.4208\n",
      "[1444/1600] D loss: 0.0226, G loss: 6.3498\n",
      "[1564/1600] D loss: 0.6447, G loss: 2.0104\n",
      "train error: \n",
      " D loss: 0.557991, G loss: 3.029042, D accuracy: 86.9%, cell accuracy: 95.6%, board accuracy: 7.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.587787, G loss: 4.913906, D accuracy: 85.8%, cell accuracy: 95.2%, board accuracy: 4.8% \n",
      "\n",
      "Epoch 199\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7133, G loss: 2.1631\n",
      "[124/1600] D loss: 1.0156, G loss: 1.2908\n",
      "[244/1600] D loss: 0.4882, G loss: 1.9000\n",
      "[364/1600] D loss: 0.9099, G loss: 0.8521\n",
      "[484/1600] D loss: 0.9854, G loss: 1.2575\n",
      "[604/1600] D loss: 1.0345, G loss: 1.1104\n",
      "[724/1600] D loss: 0.3113, G loss: 1.6584\n",
      "[844/1600] D loss: 1.3520, G loss: 0.8169\n",
      "[964/1600] D loss: 0.0286, G loss: 4.6848\n",
      "[1084/1600] D loss: 0.2716, G loss: 6.2290\n",
      "[1204/1600] D loss: 0.3865, G loss: 4.6128\n",
      "[1324/1600] D loss: 0.3348, G loss: 5.4725\n",
      "[1444/1600] D loss: 0.2856, G loss: 3.2385\n",
      "[1564/1600] D loss: 0.1202, G loss: 2.9001\n",
      "train error: \n",
      " D loss: 0.582736, G loss: 2.756515, D accuracy: 85.8%, cell accuracy: 95.6%, board accuracy: 7.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.517397, G loss: 4.586823, D accuracy: 88.1%, cell accuracy: 95.1%, board accuracy: 4.2% \n",
      "\n",
      "Epoch 200\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6834, G loss: 1.8316\n",
      "[124/1600] D loss: 1.2344, G loss: 3.1316\n",
      "[244/1600] D loss: 1.0108, G loss: 4.3148\n",
      "[364/1600] D loss: 0.8166, G loss: 1.9159\n",
      "[484/1600] D loss: 0.5658, G loss: 3.6190\n",
      "[604/1600] D loss: 0.5092, G loss: 4.1459\n",
      "[724/1600] D loss: 0.6022, G loss: 1.5216\n",
      "[844/1600] D loss: 0.0524, G loss: 6.4758\n",
      "[964/1600] D loss: 0.3315, G loss: 3.3844\n",
      "[1084/1600] D loss: 0.8836, G loss: 2.9626\n",
      "[1204/1600] D loss: 0.6386, G loss: 1.6600\n",
      "[1324/1600] D loss: 0.4486, G loss: 5.0395\n",
      "[1444/1600] D loss: 0.2343, G loss: 3.3870\n",
      "[1564/1600] D loss: 0.9045, G loss: 2.4084\n",
      "train error: \n",
      " D loss: 0.529106, G loss: 3.074038, D accuracy: 86.8%, cell accuracy: 95.6%, board accuracy: 7.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.546193, G loss: 4.913011, D accuracy: 87.9%, cell accuracy: 95.0%, board accuracy: 5.5% \n",
      "\n",
      "Epoch 201\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5441, G loss: 2.0165\n",
      "[124/1600] D loss: 0.5310, G loss: 2.8987\n",
      "[244/1600] D loss: 0.7113, G loss: 2.1899\n",
      "[364/1600] D loss: 1.2429, G loss: 1.2929\n",
      "[484/1600] D loss: 0.4046, G loss: 2.9455\n",
      "[604/1600] D loss: 0.4053, G loss: 2.3573\n",
      "[724/1600] D loss: 0.9704, G loss: 1.6942\n",
      "[844/1600] D loss: 0.0957, G loss: 5.4765\n",
      "[964/1600] D loss: 1.1023, G loss: 1.1032\n",
      "[1084/1600] D loss: 0.8731, G loss: 2.4994\n",
      "[1204/1600] D loss: 0.3709, G loss: 5.1094\n",
      "[1324/1600] D loss: 0.2218, G loss: 3.2391\n",
      "[1444/1600] D loss: 0.1536, G loss: 3.6745\n",
      "[1564/1600] D loss: 0.6310, G loss: 2.5257\n",
      "train error: \n",
      " D loss: 0.576864, G loss: 3.198456, D accuracy: 85.7%, cell accuracy: 95.6%, board accuracy: 7.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.575609, G loss: 5.122195, D accuracy: 85.9%, cell accuracy: 95.1%, board accuracy: 5.8% \n",
      "\n",
      "Epoch 202\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.2230, G loss: 4.1536\n",
      "[124/1600] D loss: 0.4903, G loss: 4.2666\n",
      "[244/1600] D loss: 0.5202, G loss: 4.1369\n",
      "[364/1600] D loss: 0.3951, G loss: 4.7215\n",
      "[484/1600] D loss: 0.7678, G loss: 3.4371\n",
      "[604/1600] D loss: 0.6024, G loss: 3.1097\n",
      "[724/1600] D loss: 1.3318, G loss: 1.2704\n",
      "[844/1600] D loss: 0.2995, G loss: 3.1896\n",
      "[964/1600] D loss: 0.8169, G loss: 2.0087\n",
      "[1084/1600] D loss: 0.3674, G loss: 4.6687\n",
      "[1204/1600] D loss: 0.4848, G loss: 4.2546\n",
      "[1324/1600] D loss: 0.4890, G loss: 3.9198\n",
      "[1444/1600] D loss: 0.9882, G loss: 2.8888\n",
      "[1564/1600] D loss: 0.4316, G loss: 1.8959\n",
      "train error: \n",
      " D loss: 0.623260, G loss: 3.491660, D accuracy: 84.7%, cell accuracy: 95.6%, board accuracy: 7.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.701703, G loss: 5.450003, D accuracy: 84.2%, cell accuracy: 95.1%, board accuracy: 5.8% \n",
      "\n",
      "Epoch 203\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.0589, G loss: 5.6408\n",
      "[124/1600] D loss: 0.3174, G loss: 3.4928\n",
      "[244/1600] D loss: 0.1783, G loss: 5.6430\n",
      "[364/1600] D loss: 0.6334, G loss: 3.1315\n",
      "[484/1600] D loss: 0.2210, G loss: 4.6277\n",
      "[604/1600] D loss: 0.4227, G loss: 2.0488\n",
      "[724/1600] D loss: 0.0596, G loss: 4.1548\n",
      "[844/1600] D loss: 0.7318, G loss: 1.9261\n",
      "[964/1600] D loss: 1.2283, G loss: 1.3904\n",
      "[1084/1600] D loss: 0.3947, G loss: 2.9954\n",
      "[1204/1600] D loss: 0.4858, G loss: 3.1710\n",
      "[1324/1600] D loss: 0.6885, G loss: 3.0757\n",
      "[1444/1600] D loss: 0.1151, G loss: 3.7113\n",
      "[1564/1600] D loss: 0.5554, G loss: 3.5785\n",
      "train error: \n",
      " D loss: 0.612948, G loss: 3.670185, D accuracy: 84.1%, cell accuracy: 95.5%, board accuracy: 7.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.719814, G loss: 5.542407, D accuracy: 84.6%, cell accuracy: 95.0%, board accuracy: 5.5% \n",
      "\n",
      "Epoch 204\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.3691, G loss: 3.8166\n",
      "[124/1600] D loss: 0.5425, G loss: 2.5728\n",
      "[244/1600] D loss: 0.2666, G loss: 2.0733\n",
      "[364/1600] D loss: 1.6088, G loss: 2.2612\n",
      "[484/1600] D loss: 1.2287, G loss: 0.7856\n",
      "[604/1600] D loss: 1.0319, G loss: 1.2496\n",
      "[724/1600] D loss: 1.0452, G loss: 5.3015\n",
      "[844/1600] D loss: 0.9055, G loss: 1.4247\n",
      "[964/1600] D loss: 0.7360, G loss: 1.9195\n",
      "[1084/1600] D loss: 0.9168, G loss: 2.0733\n",
      "[1204/1600] D loss: 0.2540, G loss: 2.4028\n",
      "[1324/1600] D loss: 0.9804, G loss: 1.1245\n",
      "[1444/1600] D loss: 0.1983, G loss: 4.3957\n",
      "[1564/1600] D loss: 0.0574, G loss: 6.0317\n",
      "train error: \n",
      " D loss: 0.587431, G loss: 2.921474, D accuracy: 85.2%, cell accuracy: 95.5%, board accuracy: 7.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.577151, G loss: 4.833652, D accuracy: 87.4%, cell accuracy: 95.0%, board accuracy: 5.2% \n",
      "\n",
      "Epoch 205\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.1022, G loss: 4.1312\n",
      "[124/1600] D loss: 0.4866, G loss: 2.9399\n",
      "[244/1600] D loss: 0.2910, G loss: 4.0492\n",
      "[364/1600] D loss: 0.1136, G loss: 5.2952\n",
      "[484/1600] D loss: 0.6644, G loss: 2.1064\n",
      "[604/1600] D loss: 0.6050, G loss: 2.2894\n",
      "[724/1600] D loss: 0.8724, G loss: 1.9640\n",
      "[844/1600] D loss: 0.1723, G loss: 2.0834\n",
      "[964/1600] D loss: 0.6859, G loss: 2.1488\n",
      "[1084/1600] D loss: 0.6849, G loss: 1.3270\n",
      "[1204/1600] D loss: 0.2069, G loss: 4.5670\n",
      "[1324/1600] D loss: 0.5567, G loss: 3.7561\n",
      "[1444/1600] D loss: 1.0586, G loss: 1.6602\n",
      "[1564/1600] D loss: 0.4825, G loss: 1.8269\n",
      "train error: \n",
      " D loss: 0.574664, G loss: 2.900205, D accuracy: 86.3%, cell accuracy: 95.6%, board accuracy: 7.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.554638, G loss: 4.841469, D accuracy: 88.4%, cell accuracy: 95.1%, board accuracy: 6.0% \n",
      "\n",
      "Epoch 206\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2043, G loss: 0.7858\n",
      "[124/1600] D loss: 0.4880, G loss: 2.6332\n",
      "[244/1600] D loss: 0.6471, G loss: 3.1846\n",
      "[364/1600] D loss: 0.6055, G loss: 1.3960\n",
      "[484/1600] D loss: 0.5489, G loss: 2.9532\n",
      "[604/1600] D loss: 1.0551, G loss: 1.8132\n",
      "[724/1600] D loss: 1.1028, G loss: 0.6878\n",
      "[844/1600] D loss: 1.0235, G loss: 3.9076\n",
      "[964/1600] D loss: 0.6121, G loss: 6.9119\n",
      "[1084/1600] D loss: 0.0526, G loss: 3.7412\n",
      "[1204/1600] D loss: 0.0929, G loss: 4.1762\n",
      "[1324/1600] D loss: 0.4763, G loss: 3.1426\n",
      "[1444/1600] D loss: 0.5596, G loss: 2.4153\n",
      "[1564/1600] D loss: 0.4267, G loss: 2.2827\n",
      "train error: \n",
      " D loss: 0.573659, G loss: 2.860760, D accuracy: 85.6%, cell accuracy: 95.6%, board accuracy: 7.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.529683, G loss: 4.835406, D accuracy: 89.1%, cell accuracy: 95.1%, board accuracy: 4.5% \n",
      "\n",
      "Epoch 207\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6278, G loss: 2.0369\n",
      "[124/1600] D loss: 0.5593, G loss: 1.6339\n",
      "[244/1600] D loss: 0.3510, G loss: 4.1695\n",
      "[364/1600] D loss: 0.7363, G loss: 1.8275\n",
      "[484/1600] D loss: 1.0600, G loss: 2.4870\n",
      "[604/1600] D loss: 0.2166, G loss: 2.8329\n",
      "[724/1600] D loss: 0.9193, G loss: 1.1575\n",
      "[844/1600] D loss: 0.4152, G loss: 3.6420\n",
      "[964/1600] D loss: 0.6746, G loss: 2.4318\n",
      "[1084/1600] D loss: 0.0770, G loss: 3.6970\n",
      "[1204/1600] D loss: 0.1082, G loss: 5.0042\n",
      "[1324/1600] D loss: 0.4202, G loss: 5.3329\n",
      "[1444/1600] D loss: 0.3709, G loss: 4.5181\n",
      "[1564/1600] D loss: 0.4268, G loss: 2.7705\n",
      "train error: \n",
      " D loss: 0.602806, G loss: 3.024239, D accuracy: 85.5%, cell accuracy: 95.6%, board accuracy: 7.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.584912, G loss: 5.031448, D accuracy: 86.1%, cell accuracy: 95.1%, board accuracy: 5.5% \n",
      "\n",
      "Epoch 208\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4976, G loss: 2.5441\n",
      "[124/1600] D loss: 0.2786, G loss: 6.4962\n",
      "[244/1600] D loss: 0.7923, G loss: 2.4268\n",
      "[364/1600] D loss: 0.3341, G loss: 2.5539\n",
      "[484/1600] D loss: 0.1580, G loss: 4.8827\n",
      "[604/1600] D loss: 0.3249, G loss: 4.6501\n",
      "[724/1600] D loss: 0.6539, G loss: 2.7249\n",
      "[844/1600] D loss: 0.4239, G loss: 2.6910\n",
      "[964/1600] D loss: 0.8309, G loss: 2.5443\n",
      "[1084/1600] D loss: 0.5672, G loss: 3.6335\n",
      "[1204/1600] D loss: 0.5441, G loss: 1.6194\n",
      "[1324/1600] D loss: 1.0500, G loss: 3.5939\n",
      "[1444/1600] D loss: 0.5049, G loss: 6.6962\n",
      "[1564/1600] D loss: 0.4912, G loss: 4.6640\n",
      "train error: \n",
      " D loss: 0.577702, G loss: 3.383802, D accuracy: 85.8%, cell accuracy: 95.6%, board accuracy: 8.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.640639, G loss: 5.156447, D accuracy: 85.9%, cell accuracy: 95.1%, board accuracy: 6.2% \n",
      "\n",
      "Epoch 209\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.2268, G loss: 3.7585\n",
      "[124/1600] D loss: 1.0565, G loss: 4.3936\n",
      "[244/1600] D loss: 0.4006, G loss: 5.3777\n",
      "[364/1600] D loss: 0.3699, G loss: 3.6213\n",
      "[484/1600] D loss: 0.4714, G loss: 2.9351\n",
      "[604/1600] D loss: 0.6667, G loss: 2.2509\n",
      "[724/1600] D loss: 0.8323, G loss: 1.7148\n",
      "[844/1600] D loss: 0.2731, G loss: 2.2774\n",
      "[964/1600] D loss: 0.4881, G loss: 2.2764\n",
      "[1084/1600] D loss: 1.4533, G loss: 2.8566\n",
      "[1204/1600] D loss: 0.2519, G loss: 2.8395\n",
      "[1324/1600] D loss: 0.3517, G loss: 6.5502\n",
      "[1444/1600] D loss: 0.4031, G loss: 4.2916\n",
      "[1564/1600] D loss: 0.6660, G loss: 1.5627\n",
      "train error: \n",
      " D loss: 0.521850, G loss: 3.298441, D accuracy: 87.5%, cell accuracy: 95.6%, board accuracy: 7.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.556847, G loss: 5.353132, D accuracy: 86.9%, cell accuracy: 95.0%, board accuracy: 5.2% \n",
      "\n",
      "Epoch 210\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0630, G loss: 3.3295\n",
      "[124/1600] D loss: 0.8327, G loss: 3.8836\n",
      "[244/1600] D loss: 0.0929, G loss: 3.3929\n",
      "[364/1600] D loss: 0.4654, G loss: 1.6745\n",
      "[484/1600] D loss: 0.5178, G loss: 3.0857\n",
      "[604/1600] D loss: 0.3086, G loss: 3.6548\n",
      "[724/1600] D loss: 0.6944, G loss: 3.2199\n",
      "[844/1600] D loss: 0.1156, G loss: 4.2076\n",
      "[964/1600] D loss: 0.6308, G loss: 2.1721\n",
      "[1084/1600] D loss: 0.4773, G loss: 1.8306\n",
      "[1204/1600] D loss: 1.0310, G loss: 3.8001\n",
      "[1324/1600] D loss: 0.6729, G loss: 2.9788\n",
      "[1444/1600] D loss: 0.7926, G loss: 1.5224\n",
      "[1564/1600] D loss: 0.1324, G loss: 4.5287\n",
      "train error: \n",
      " D loss: 0.565118, G loss: 2.922567, D accuracy: 86.0%, cell accuracy: 95.6%, board accuracy: 7.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.530930, G loss: 4.961830, D accuracy: 87.9%, cell accuracy: 95.1%, board accuracy: 6.0% \n",
      "\n",
      "Epoch 211\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6008, G loss: 2.3882\n",
      "[124/1600] D loss: 1.1950, G loss: 2.3952\n",
      "[244/1600] D loss: 0.1734, G loss: 4.3809\n",
      "[364/1600] D loss: 0.2485, G loss: 2.7244\n",
      "[484/1600] D loss: 1.2135, G loss: 0.7714\n",
      "[604/1600] D loss: 0.6296, G loss: 4.2614\n",
      "[724/1600] D loss: 0.0774, G loss: 3.6707\n",
      "[844/1600] D loss: 0.2132, G loss: 3.4157\n",
      "[964/1600] D loss: 0.0460, G loss: 5.8535\n",
      "[1084/1600] D loss: 0.1328, G loss: 2.9642\n",
      "[1204/1600] D loss: 0.4366, G loss: 2.8723\n",
      "[1324/1600] D loss: 1.2645, G loss: 1.8203\n",
      "[1444/1600] D loss: 0.8639, G loss: 1.1333\n",
      "[1564/1600] D loss: 0.4368, G loss: 3.4406\n",
      "train error: \n",
      " D loss: 0.534917, G loss: 3.500850, D accuracy: 87.4%, cell accuracy: 95.6%, board accuracy: 7.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.629969, G loss: 5.544284, D accuracy: 85.9%, cell accuracy: 95.1%, board accuracy: 5.5% \n",
      "\n",
      "Epoch 212\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.0741, G loss: 5.9563\n",
      "[124/1600] D loss: 0.8318, G loss: 2.5761\n",
      "[244/1600] D loss: 0.5181, G loss: 4.2254\n",
      "[364/1600] D loss: 0.2645, G loss: 5.6877\n",
      "[484/1600] D loss: 0.3538, G loss: 4.1250\n",
      "[604/1600] D loss: 0.2177, G loss: 4.5923\n",
      "[724/1600] D loss: 0.4611, G loss: 2.0292\n",
      "[844/1600] D loss: 0.4974, G loss: 3.6690\n",
      "[964/1600] D loss: 1.0330, G loss: 2.8335\n",
      "[1084/1600] D loss: 0.2005, G loss: 4.7984\n",
      "[1204/1600] D loss: 0.7158, G loss: 3.4592\n",
      "[1324/1600] D loss: 0.1239, G loss: 2.4497\n",
      "[1444/1600] D loss: 0.8507, G loss: 1.8168\n",
      "[1564/1600] D loss: 0.1219, G loss: 2.5282\n",
      "train error: \n",
      " D loss: 0.544101, G loss: 2.994077, D accuracy: 87.3%, cell accuracy: 95.6%, board accuracy: 7.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.543360, G loss: 4.966642, D accuracy: 88.6%, cell accuracy: 95.1%, board accuracy: 6.2% \n",
      "\n",
      "Epoch 213\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7408, G loss: 3.5025\n",
      "[124/1600] D loss: 0.6669, G loss: 1.9781\n",
      "[244/1600] D loss: 0.5424, G loss: 2.6611\n",
      "[364/1600] D loss: 0.5640, G loss: 3.5443\n",
      "[484/1600] D loss: 0.3057, G loss: 2.5515\n",
      "[604/1600] D loss: 0.0458, G loss: 3.9962\n",
      "[724/1600] D loss: 0.5540, G loss: 5.9020\n",
      "[844/1600] D loss: 0.4447, G loss: 4.4624\n",
      "[964/1600] D loss: 0.4170, G loss: 3.6328\n",
      "[1084/1600] D loss: 1.0768, G loss: 1.2469\n",
      "[1204/1600] D loss: 0.7952, G loss: 2.0569\n",
      "[1324/1600] D loss: 0.1256, G loss: 5.2197\n",
      "[1444/1600] D loss: 0.2947, G loss: 3.2788\n",
      "[1564/1600] D loss: 0.0815, G loss: 6.1462\n",
      "train error: \n",
      " D loss: 0.844400, G loss: 2.263902, D accuracy: 79.1%, cell accuracy: 95.7%, board accuracy: 8.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.608316, G loss: 4.262981, D accuracy: 88.4%, cell accuracy: 95.2%, board accuracy: 6.5% \n",
      "\n",
      "Epoch 214\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2081, G loss: 2.7936\n",
      "[124/1600] D loss: 0.4932, G loss: 3.3963\n",
      "[244/1600] D loss: 0.0353, G loss: 7.1946\n",
      "[364/1600] D loss: 0.2567, G loss: 5.8095\n",
      "[484/1600] D loss: 0.1559, G loss: 5.9332\n",
      "[604/1600] D loss: 0.2331, G loss: 5.5325\n",
      "[724/1600] D loss: 0.1062, G loss: 4.3617\n",
      "[844/1600] D loss: 0.0671, G loss: 5.1812\n",
      "[964/1600] D loss: 0.5372, G loss: 2.4100\n",
      "[1084/1600] D loss: 0.2916, G loss: 3.5992\n",
      "[1204/1600] D loss: 0.4504, G loss: 4.6164\n",
      "[1324/1600] D loss: 0.9855, G loss: 1.4876\n",
      "[1444/1600] D loss: 0.4847, G loss: 3.4718\n",
      "[1564/1600] D loss: 0.3635, G loss: 5.7135\n",
      "train error: \n",
      " D loss: 0.593723, G loss: 3.017680, D accuracy: 85.6%, cell accuracy: 95.6%, board accuracy: 9.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.602056, G loss: 5.125422, D accuracy: 86.5%, cell accuracy: 95.1%, board accuracy: 7.2% \n",
      "\n",
      "Epoch 215\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5448, G loss: 3.6397\n",
      "[124/1600] D loss: 0.3416, G loss: 4.1021\n",
      "[244/1600] D loss: 0.3647, G loss: 2.8127\n",
      "[364/1600] D loss: 0.5706, G loss: 3.5858\n",
      "[484/1600] D loss: 0.5239, G loss: 3.5987\n",
      "[604/1600] D loss: 1.0820, G loss: 3.7829\n",
      "[724/1600] D loss: 0.5527, G loss: 2.3487\n",
      "[844/1600] D loss: 1.2510, G loss: 1.3988\n",
      "[964/1600] D loss: 0.6467, G loss: 4.5103\n",
      "[1084/1600] D loss: 0.8203, G loss: 2.0341\n",
      "[1204/1600] D loss: 0.6682, G loss: 2.6361\n",
      "[1324/1600] D loss: 1.0554, G loss: 5.7775\n",
      "[1444/1600] D loss: 0.5280, G loss: 2.4340\n",
      "[1564/1600] D loss: 0.0398, G loss: 5.0139\n",
      "train error: \n",
      " D loss: 0.570685, G loss: 3.156192, D accuracy: 86.1%, cell accuracy: 95.7%, board accuracy: 9.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.616102, G loss: 5.383117, D accuracy: 86.4%, cell accuracy: 95.1%, board accuracy: 7.5% \n",
      "\n",
      "Epoch 216\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.3082, G loss: 2.5731\n",
      "[124/1600] D loss: 0.3979, G loss: 3.9461\n",
      "[244/1600] D loss: 1.3057, G loss: 0.8999\n",
      "[364/1600] D loss: 0.7612, G loss: 2.2628\n",
      "[484/1600] D loss: 0.4736, G loss: 2.1376\n",
      "[604/1600] D loss: 0.5082, G loss: 1.8803\n",
      "[724/1600] D loss: 0.7314, G loss: 3.0902\n",
      "[844/1600] D loss: 0.3632, G loss: 2.1968\n",
      "[964/1600] D loss: 0.5053, G loss: 2.4888\n",
      "[1084/1600] D loss: 0.4735, G loss: 5.1888\n",
      "[1204/1600] D loss: 1.3460, G loss: 0.8545\n",
      "[1324/1600] D loss: 0.8960, G loss: 2.9674\n",
      "[1444/1600] D loss: 1.6857, G loss: 0.6322\n",
      "[1564/1600] D loss: 0.5772, G loss: 5.2628\n",
      "train error: \n",
      " D loss: 0.575312, G loss: 3.678330, D accuracy: 85.9%, cell accuracy: 95.6%, board accuracy: 8.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.719006, G loss: 5.813228, D accuracy: 84.0%, cell accuracy: 95.1%, board accuracy: 6.2% \n",
      "\n",
      "Epoch 217\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5964, G loss: 3.4677\n",
      "[124/1600] D loss: 0.3286, G loss: 4.6383\n",
      "[244/1600] D loss: 0.2513, G loss: 4.7637\n",
      "[364/1600] D loss: 0.6742, G loss: 4.9686\n",
      "[484/1600] D loss: 0.7142, G loss: 4.0918\n",
      "[604/1600] D loss: 0.5348, G loss: 4.5830\n",
      "[724/1600] D loss: 0.2117, G loss: 2.6848\n",
      "[844/1600] D loss: 0.5133, G loss: 4.0850\n",
      "[964/1600] D loss: 0.3551, G loss: 3.0439\n",
      "[1084/1600] D loss: 0.5534, G loss: 3.6006\n",
      "[1204/1600] D loss: 0.5086, G loss: 5.0509\n",
      "[1324/1600] D loss: 0.0548, G loss: 6.9521\n",
      "[1444/1600] D loss: 1.0491, G loss: 3.9463\n",
      "[1564/1600] D loss: 0.3356, G loss: 3.2850\n",
      "train error: \n",
      " D loss: 0.634619, G loss: 2.996332, D accuracy: 84.1%, cell accuracy: 95.6%, board accuracy: 9.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.640982, G loss: 5.299471, D accuracy: 85.4%, cell accuracy: 95.0%, board accuracy: 7.0% \n",
      "\n",
      "Epoch 218\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4804, G loss: 1.9390\n",
      "[124/1600] D loss: 0.4023, G loss: 3.8665\n",
      "[244/1600] D loss: 0.3686, G loss: 4.8361\n",
      "[364/1600] D loss: 0.4074, G loss: 4.0964\n",
      "[484/1600] D loss: 1.2515, G loss: 1.4203\n",
      "[604/1600] D loss: 0.5135, G loss: 2.2476\n",
      "[724/1600] D loss: 1.0376, G loss: 1.2876\n",
      "[844/1600] D loss: 0.1082, G loss: 7.9030\n",
      "[964/1600] D loss: 0.3408, G loss: 5.0040\n",
      "[1084/1600] D loss: 0.0751, G loss: 2.8963\n",
      "[1204/1600] D loss: 0.3378, G loss: 5.1017\n",
      "[1324/1600] D loss: 0.8598, G loss: 1.8912\n",
      "[1444/1600] D loss: 0.0269, G loss: 5.1265\n",
      "[1564/1600] D loss: 0.7528, G loss: 2.1223\n",
      "train error: \n",
      " D loss: 0.546038, G loss: 3.013539, D accuracy: 86.7%, cell accuracy: 95.6%, board accuracy: 9.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.576955, G loss: 5.206669, D accuracy: 85.8%, cell accuracy: 95.1%, board accuracy: 7.2% \n",
      "\n",
      "Epoch 219\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6722, G loss: 1.0766\n",
      "[124/1600] D loss: 0.6797, G loss: 1.8410\n",
      "[244/1600] D loss: 0.1601, G loss: 3.7646\n",
      "[364/1600] D loss: 0.7046, G loss: 1.6527\n",
      "[484/1600] D loss: 0.3200, G loss: 6.2141\n",
      "[604/1600] D loss: 0.1568, G loss: 4.8606\n",
      "[724/1600] D loss: 0.7645, G loss: 1.1465\n",
      "[844/1600] D loss: 0.6776, G loss: 3.0589\n",
      "[964/1600] D loss: 0.1074, G loss: 6.7517\n",
      "[1084/1600] D loss: 0.8200, G loss: 2.6435\n",
      "[1204/1600] D loss: 0.3151, G loss: 4.2203\n",
      "[1324/1600] D loss: 1.2632, G loss: 1.5454\n",
      "[1444/1600] D loss: 0.5188, G loss: 3.8464\n",
      "[1564/1600] D loss: 0.1866, G loss: 4.0940\n",
      "train error: \n",
      " D loss: 0.581406, G loss: 2.833758, D accuracy: 85.8%, cell accuracy: 95.6%, board accuracy: 9.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.546156, G loss: 4.949960, D accuracy: 88.1%, cell accuracy: 95.0%, board accuracy: 7.2% \n",
      "\n",
      "Epoch 220\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4449, G loss: 4.9356\n",
      "[124/1600] D loss: 0.4013, G loss: 3.7626\n",
      "[244/1600] D loss: 0.3621, G loss: 3.6034\n",
      "[364/1600] D loss: 0.6045, G loss: 4.8296\n",
      "[484/1600] D loss: 0.4540, G loss: 3.3743\n",
      "[604/1600] D loss: 0.5785, G loss: 2.4512\n",
      "[724/1600] D loss: 0.4107, G loss: 1.8887\n",
      "[844/1600] D loss: 0.2413, G loss: 4.2641\n",
      "[964/1600] D loss: 0.4889, G loss: 3.3044\n",
      "[1084/1600] D loss: 0.5035, G loss: 4.0203\n",
      "[1204/1600] D loss: 1.4579, G loss: 3.4521\n",
      "[1324/1600] D loss: 0.7035, G loss: 2.6557\n",
      "[1444/1600] D loss: 0.6324, G loss: 4.8370\n",
      "[1564/1600] D loss: 0.4843, G loss: 1.9780\n",
      "train error: \n",
      " D loss: 0.555385, G loss: 3.444726, D accuracy: 86.4%, cell accuracy: 95.6%, board accuracy: 8.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.669532, G loss: 5.701300, D accuracy: 84.6%, cell accuracy: 95.1%, board accuracy: 6.2% \n",
      "\n",
      "Epoch 221\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.2487, G loss: 5.2033\n",
      "[124/1600] D loss: 0.8631, G loss: 1.6800\n",
      "[244/1600] D loss: 0.3642, G loss: 2.6408\n",
      "[364/1600] D loss: 0.2770, G loss: 2.9918\n",
      "[484/1600] D loss: 0.5915, G loss: 1.6006\n",
      "[604/1600] D loss: 0.2623, G loss: 2.8581\n",
      "[724/1600] D loss: 1.4827, G loss: 2.1654\n",
      "[844/1600] D loss: 0.9329, G loss: 2.4296\n",
      "[964/1600] D loss: 0.2125, G loss: 2.6238\n",
      "[1084/1600] D loss: 1.0218, G loss: 1.6010\n",
      "[1204/1600] D loss: 0.0861, G loss: 4.6281\n",
      "[1324/1600] D loss: 0.5498, G loss: 4.5121\n",
      "[1444/1600] D loss: 0.2389, G loss: 2.4713\n",
      "[1564/1600] D loss: 1.2325, G loss: 2.4111\n",
      "train error: \n",
      " D loss: 0.601124, G loss: 3.149488, D accuracy: 85.5%, cell accuracy: 95.6%, board accuracy: 9.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.668366, G loss: 5.325883, D accuracy: 85.2%, cell accuracy: 95.0%, board accuracy: 7.2% \n",
      "\n",
      "Epoch 222\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.3739, G loss: 1.3267\n",
      "[124/1600] D loss: 0.6267, G loss: 2.2422\n",
      "[244/1600] D loss: 0.6914, G loss: 2.5112\n",
      "[364/1600] D loss: 0.5956, G loss: 1.8070\n",
      "[484/1600] D loss: 0.5242, G loss: 2.0162\n",
      "[604/1600] D loss: 0.3472, G loss: 1.8916\n",
      "[724/1600] D loss: 0.4821, G loss: 5.6490\n",
      "[844/1600] D loss: 0.4637, G loss: 4.6704\n",
      "[964/1600] D loss: 1.1286, G loss: 1.0820\n",
      "[1084/1600] D loss: 1.1134, G loss: 2.1858\n",
      "[1204/1600] D loss: 0.4816, G loss: 2.8776\n",
      "[1324/1600] D loss: 0.3591, G loss: 4.5878\n",
      "[1444/1600] D loss: 1.1170, G loss: 1.5339\n",
      "[1564/1600] D loss: 0.1409, G loss: 5.0341\n",
      "train error: \n",
      " D loss: 0.572714, G loss: 3.509433, D accuracy: 85.8%, cell accuracy: 95.7%, board accuracy: 9.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.680322, G loss: 5.766925, D accuracy: 84.2%, cell accuracy: 95.1%, board accuracy: 7.5% \n",
      "\n",
      "Epoch 223\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4781, G loss: 1.6777\n",
      "[124/1600] D loss: 0.1651, G loss: 5.8491\n",
      "[244/1600] D loss: 0.4740, G loss: 3.8593\n",
      "[364/1600] D loss: 0.3581, G loss: 4.5124\n",
      "[484/1600] D loss: 0.9656, G loss: 1.8387\n",
      "[604/1600] D loss: 0.0299, G loss: 4.5143\n",
      "[724/1600] D loss: 0.0714, G loss: 6.2930\n",
      "[844/1600] D loss: 0.1126, G loss: 5.7690\n",
      "[964/1600] D loss: 0.2597, G loss: 4.8571\n",
      "[1084/1600] D loss: 0.3673, G loss: 2.8027\n",
      "[1204/1600] D loss: 0.8201, G loss: 2.3936\n",
      "[1324/1600] D loss: 0.2458, G loss: 1.9467\n",
      "[1444/1600] D loss: 0.6199, G loss: 2.8165\n",
      "[1564/1600] D loss: 0.5080, G loss: 4.4529\n",
      "train error: \n",
      " D loss: 0.599520, G loss: 2.960671, D accuracy: 85.4%, cell accuracy: 95.7%, board accuracy: 8.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.609200, G loss: 5.110258, D accuracy: 85.9%, cell accuracy: 95.0%, board accuracy: 6.0% \n",
      "\n",
      "Epoch 224\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5147, G loss: 2.3048\n",
      "[124/1600] D loss: 0.6869, G loss: 2.3175\n",
      "[244/1600] D loss: 0.4670, G loss: 3.4375\n",
      "[364/1600] D loss: 0.0889, G loss: 5.6863\n",
      "[484/1600] D loss: 0.3170, G loss: 4.1646\n",
      "[604/1600] D loss: 0.4636, G loss: 4.4111\n",
      "[724/1600] D loss: 0.8168, G loss: 1.4945\n",
      "[844/1600] D loss: 0.5069, G loss: 2.4256\n",
      "[964/1600] D loss: 0.8081, G loss: 3.3286\n",
      "[1084/1600] D loss: 0.0898, G loss: 3.7726\n",
      "[1204/1600] D loss: 0.2371, G loss: 4.9976\n",
      "[1324/1600] D loss: 0.7112, G loss: 3.3415\n",
      "[1444/1600] D loss: 0.4447, G loss: 2.4606\n",
      "[1564/1600] D loss: 0.7069, G loss: 3.1266\n",
      "train error: \n",
      " D loss: 0.562298, G loss: 3.258907, D accuracy: 85.8%, cell accuracy: 95.7%, board accuracy: 9.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.638204, G loss: 5.521219, D accuracy: 86.0%, cell accuracy: 95.1%, board accuracy: 6.8% \n",
      "\n",
      "Epoch 225\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.2876, G loss: 5.2105\n",
      "[124/1600] D loss: 0.5499, G loss: 4.6167\n",
      "[244/1600] D loss: 0.1692, G loss: 5.2796\n",
      "[364/1600] D loss: 0.7323, G loss: 2.5646\n",
      "[484/1600] D loss: 0.9342, G loss: 1.9937\n",
      "[604/1600] D loss: 0.9079, G loss: 2.6268\n",
      "[724/1600] D loss: 0.9356, G loss: 3.3882\n",
      "[844/1600] D loss: 0.8347, G loss: 2.8943\n",
      "[964/1600] D loss: 0.6729, G loss: 5.0589\n",
      "[1084/1600] D loss: 0.5199, G loss: 2.0804\n",
      "[1204/1600] D loss: 0.6297, G loss: 4.4095\n",
      "[1324/1600] D loss: 0.8815, G loss: 3.6348\n",
      "[1444/1600] D loss: 0.3787, G loss: 2.7637\n",
      "[1564/1600] D loss: 1.0359, G loss: 1.5936\n",
      "train error: \n",
      " D loss: 0.520412, G loss: 3.421477, D accuracy: 86.8%, cell accuracy: 95.7%, board accuracy: 9.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.623034, G loss: 5.855086, D accuracy: 85.4%, cell accuracy: 95.1%, board accuracy: 6.2% \n",
      "\n",
      "Epoch 226\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.2042, G loss: 2.6384\n",
      "[124/1600] D loss: 0.1252, G loss: 4.6068\n",
      "[244/1600] D loss: 0.2286, G loss: 7.6448\n",
      "[364/1600] D loss: 0.1613, G loss: 3.8249\n",
      "[484/1600] D loss: 1.2585, G loss: 1.0227\n",
      "[604/1600] D loss: 0.1499, G loss: 5.8014\n",
      "[724/1600] D loss: 0.6097, G loss: 3.1343\n",
      "[844/1600] D loss: 0.4194, G loss: 5.1060\n",
      "[964/1600] D loss: 0.2963, G loss: 5.2524\n",
      "[1084/1600] D loss: 0.6700, G loss: 4.6372\n",
      "[1204/1600] D loss: 0.4445, G loss: 4.4712\n",
      "[1324/1600] D loss: 0.7423, G loss: 3.2552\n",
      "[1444/1600] D loss: 0.7020, G loss: 4.4610\n",
      "[1564/1600] D loss: 1.5452, G loss: 1.4577\n",
      "train error: \n",
      " D loss: 0.572174, G loss: 2.996059, D accuracy: 85.5%, cell accuracy: 95.8%, board accuracy: 9.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.579217, G loss: 5.347653, D accuracy: 87.4%, cell accuracy: 95.1%, board accuracy: 6.5% \n",
      "\n",
      "Epoch 227\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5800, G loss: 2.5803\n",
      "[124/1600] D loss: 0.1853, G loss: 3.6871\n",
      "[244/1600] D loss: 1.1392, G loss: 3.1897\n",
      "[364/1600] D loss: 0.7351, G loss: 3.9227\n",
      "[484/1600] D loss: 0.5559, G loss: 2.1661\n",
      "[604/1600] D loss: 0.6575, G loss: 1.4238\n",
      "[724/1600] D loss: 0.7105, G loss: 4.7195\n",
      "[844/1600] D loss: 0.3666, G loss: 2.1380\n",
      "[964/1600] D loss: 0.8438, G loss: 2.5590\n",
      "[1084/1600] D loss: 0.6159, G loss: 2.3450\n",
      "[1204/1600] D loss: 0.9331, G loss: 1.4670\n",
      "[1324/1600] D loss: 1.5701, G loss: 1.6101\n",
      "[1444/1600] D loss: 0.2381, G loss: 3.0574\n",
      "[1564/1600] D loss: 1.2052, G loss: 1.1484\n",
      "train error: \n",
      " D loss: 0.578949, G loss: 3.159232, D accuracy: 85.5%, cell accuracy: 95.7%, board accuracy: 10.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.643636, G loss: 5.531740, D accuracy: 85.2%, cell accuracy: 95.0%, board accuracy: 7.5% \n",
      "\n",
      "Epoch 228\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8196, G loss: 2.5523\n",
      "[124/1600] D loss: 0.5279, G loss: 2.0196\n",
      "[244/1600] D loss: 0.9237, G loss: 2.4251\n",
      "[364/1600] D loss: 0.7049, G loss: 3.4333\n",
      "[484/1600] D loss: 0.4491, G loss: 3.9196\n",
      "[604/1600] D loss: 0.6207, G loss: 2.8294\n",
      "[724/1600] D loss: 0.4398, G loss: 4.9513\n",
      "[844/1600] D loss: 0.2793, G loss: 2.5538\n",
      "[964/1600] D loss: 1.5296, G loss: 2.5196\n",
      "[1084/1600] D loss: 0.7497, G loss: 1.2029\n",
      "[1204/1600] D loss: 0.7765, G loss: 3.7384\n",
      "[1324/1600] D loss: 0.3402, G loss: 5.9653\n",
      "[1444/1600] D loss: 0.2769, G loss: 5.2144\n",
      "[1564/1600] D loss: 0.5710, G loss: 3.5749\n",
      "train error: \n",
      " D loss: 0.596425, G loss: 3.080382, D accuracy: 85.8%, cell accuracy: 95.7%, board accuracy: 9.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.630435, G loss: 5.454011, D accuracy: 86.4%, cell accuracy: 95.0%, board accuracy: 7.5% \n",
      "\n",
      "Epoch 229\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9027, G loss: 0.8524\n",
      "[124/1600] D loss: 0.6159, G loss: 3.9069\n",
      "[244/1600] D loss: 0.5306, G loss: 3.0270\n",
      "[364/1600] D loss: 0.5053, G loss: 2.4906\n",
      "[484/1600] D loss: 0.5044, G loss: 1.7868\n",
      "[604/1600] D loss: 0.2023, G loss: 3.7634\n",
      "[724/1600] D loss: 0.3884, G loss: 4.2762\n",
      "[844/1600] D loss: 0.7239, G loss: 3.6674\n",
      "[964/1600] D loss: 0.7407, G loss: 1.8683\n",
      "[1084/1600] D loss: 0.6366, G loss: 4.8958\n",
      "[1204/1600] D loss: 0.5903, G loss: 2.5145\n",
      "[1324/1600] D loss: 0.4008, G loss: 2.8694\n",
      "[1444/1600] D loss: 0.8466, G loss: 3.1076\n",
      "[1564/1600] D loss: 0.2762, G loss: 2.4807\n",
      "train error: \n",
      " D loss: 0.541285, G loss: 3.187861, D accuracy: 86.8%, cell accuracy: 95.7%, board accuracy: 10.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.608724, G loss: 5.484122, D accuracy: 85.6%, cell accuracy: 95.0%, board accuracy: 8.0% \n",
      "\n",
      "Epoch 230\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.3130, G loss: 4.0806\n",
      "[124/1600] D loss: 0.4454, G loss: 3.0351\n",
      "[244/1600] D loss: 0.2411, G loss: 4.7139\n",
      "[364/1600] D loss: 0.8209, G loss: 2.0262\n",
      "[484/1600] D loss: 0.5310, G loss: 3.1110\n",
      "[604/1600] D loss: 0.5681, G loss: 2.2231\n",
      "[724/1600] D loss: 0.0537, G loss: 5.4635\n",
      "[844/1600] D loss: 0.1956, G loss: 4.2387\n",
      "[964/1600] D loss: 0.3838, G loss: 3.2127\n",
      "[1084/1600] D loss: 0.5518, G loss: 4.0999\n",
      "[1204/1600] D loss: 0.2957, G loss: 2.7585\n",
      "[1324/1600] D loss: 0.1778, G loss: 4.2031\n",
      "[1444/1600] D loss: 0.5647, G loss: 1.8581\n",
      "[1564/1600] D loss: 0.3333, G loss: 4.7670\n",
      "train error: \n",
      " D loss: 0.680726, G loss: 2.564694, D accuracy: 82.5%, cell accuracy: 95.6%, board accuracy: 9.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.551397, G loss: 4.871535, D accuracy: 88.0%, cell accuracy: 94.9%, board accuracy: 7.2% \n",
      "\n",
      "Epoch 231\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6206, G loss: 2.3458\n",
      "[124/1600] D loss: 1.1062, G loss: 4.2611\n",
      "[244/1600] D loss: 0.1690, G loss: 3.9885\n",
      "[364/1600] D loss: 0.4172, G loss: 2.6786\n",
      "[484/1600] D loss: 1.2583, G loss: 1.3025\n",
      "[604/1600] D loss: 1.0746, G loss: 1.6785\n",
      "[724/1600] D loss: 0.2642, G loss: 3.5158\n",
      "[844/1600] D loss: 0.3805, G loss: 2.5041\n",
      "[964/1600] D loss: 0.5028, G loss: 3.4442\n",
      "[1084/1600] D loss: 0.0549, G loss: 5.4329\n",
      "[1204/1600] D loss: 0.7244, G loss: 5.8788\n",
      "[1324/1600] D loss: 1.0353, G loss: 2.6747\n",
      "[1444/1600] D loss: 0.4106, G loss: 3.2634\n",
      "[1564/1600] D loss: 0.5917, G loss: 2.3862\n",
      "train error: \n",
      " D loss: 0.609376, G loss: 3.820582, D accuracy: 84.5%, cell accuracy: 95.7%, board accuracy: 9.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.788300, G loss: 6.187574, D accuracy: 83.5%, cell accuracy: 95.0%, board accuracy: 7.0% \n",
      "\n",
      "Epoch 232\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8362, G loss: 3.4345\n",
      "[124/1600] D loss: 0.3889, G loss: 4.5399\n",
      "[244/1600] D loss: 0.3596, G loss: 2.7932\n",
      "[364/1600] D loss: 1.2413, G loss: 3.0271\n",
      "[484/1600] D loss: 0.8951, G loss: 2.7596\n",
      "[604/1600] D loss: 0.1973, G loss: 4.5117\n",
      "[724/1600] D loss: 0.7112, G loss: 5.1390\n",
      "[844/1600] D loss: 0.5664, G loss: 3.1068\n",
      "[964/1600] D loss: 0.4247, G loss: 3.5438\n",
      "[1084/1600] D loss: 0.4682, G loss: 3.5688\n",
      "[1204/1600] D loss: 0.8358, G loss: 1.4380\n",
      "[1324/1600] D loss: 0.8532, G loss: 3.7841\n",
      "[1444/1600] D loss: 0.6515, G loss: 3.5610\n",
      "[1564/1600] D loss: 0.0723, G loss: 5.3083\n",
      "train error: \n",
      " D loss: 0.544653, G loss: 3.205193, D accuracy: 86.3%, cell accuracy: 95.7%, board accuracy: 10.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.609331, G loss: 5.508111, D accuracy: 85.9%, cell accuracy: 95.0%, board accuracy: 7.2% \n",
      "\n",
      "Epoch 233\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5457, G loss: 1.9889\n",
      "[124/1600] D loss: 0.4163, G loss: 4.6627\n",
      "[244/1600] D loss: 0.4913, G loss: 3.7704\n",
      "[364/1600] D loss: 0.0454, G loss: 5.7411\n",
      "[484/1600] D loss: 0.8021, G loss: 2.5050\n",
      "[604/1600] D loss: 0.7456, G loss: 3.7449\n",
      "[724/1600] D loss: 1.0960, G loss: 0.9410\n",
      "[844/1600] D loss: 0.2973, G loss: 3.6187\n",
      "[964/1600] D loss: 0.5930, G loss: 4.6919\n",
      "[1084/1600] D loss: 0.3514, G loss: 2.7836\n",
      "[1204/1600] D loss: 0.6095, G loss: 3.9277\n",
      "[1324/1600] D loss: 0.4832, G loss: 2.1290\n",
      "[1444/1600] D loss: 0.5902, G loss: 3.5962\n",
      "[1564/1600] D loss: 0.0393, G loss: 6.2959\n",
      "train error: \n",
      " D loss: 0.772216, G loss: 2.376331, D accuracy: 81.2%, cell accuracy: 95.7%, board accuracy: 10.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.596746, G loss: 4.640822, D accuracy: 88.1%, cell accuracy: 95.0%, board accuracy: 8.0% \n",
      "\n",
      "Epoch 234\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.1976, G loss: 4.8145\n",
      "[124/1600] D loss: 0.1815, G loss: 6.0104\n",
      "[244/1600] D loss: 0.0702, G loss: 5.9385\n",
      "[364/1600] D loss: 0.6304, G loss: 2.9129\n",
      "[484/1600] D loss: 0.5163, G loss: 2.6718\n",
      "[604/1600] D loss: 0.2798, G loss: 3.6319\n",
      "[724/1600] D loss: 0.1924, G loss: 6.2612\n",
      "[844/1600] D loss: 0.0941, G loss: 4.3817\n",
      "[964/1600] D loss: 0.8936, G loss: 1.4411\n",
      "[1084/1600] D loss: 0.4750, G loss: 2.7751\n",
      "[1204/1600] D loss: 0.4081, G loss: 4.5935\n",
      "[1324/1600] D loss: 0.3207, G loss: 5.7562\n",
      "[1444/1600] D loss: 2.0456, G loss: 0.6221\n",
      "[1564/1600] D loss: 0.5822, G loss: 4.4192\n",
      "train error: \n",
      " D loss: 0.564259, G loss: 3.113712, D accuracy: 85.7%, cell accuracy: 95.7%, board accuracy: 10.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.626191, G loss: 5.518654, D accuracy: 86.1%, cell accuracy: 95.1%, board accuracy: 7.5% \n",
      "\n",
      "Epoch 235\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9834, G loss: 4.1731\n",
      "[124/1600] D loss: 0.6764, G loss: 2.7738\n",
      "[244/1600] D loss: 0.0309, G loss: 6.7598\n",
      "[364/1600] D loss: 0.3928, G loss: 5.1142\n",
      "[484/1600] D loss: 0.8863, G loss: 2.5900\n",
      "[604/1600] D loss: 0.3017, G loss: 4.3398\n",
      "[724/1600] D loss: 0.4720, G loss: 3.2350\n",
      "[844/1600] D loss: 0.7915, G loss: 2.4045\n",
      "[964/1600] D loss: 0.1272, G loss: 4.5982\n",
      "[1084/1600] D loss: 0.2885, G loss: 3.9997\n",
      "[1204/1600] D loss: 1.0894, G loss: 2.2045\n",
      "[1324/1600] D loss: 0.0707, G loss: 6.1129\n",
      "[1444/1600] D loss: 0.0442, G loss: 4.8256\n",
      "[1564/1600] D loss: 0.7493, G loss: 1.7149\n",
      "train error: \n",
      " D loss: 0.542060, G loss: 3.658084, D accuracy: 86.6%, cell accuracy: 95.7%, board accuracy: 10.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.686309, G loss: 5.995205, D accuracy: 84.2%, cell accuracy: 95.1%, board accuracy: 6.5% \n",
      "\n",
      "Epoch 236\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7102, G loss: 2.2009\n",
      "[124/1600] D loss: 0.6461, G loss: 1.9379\n",
      "[244/1600] D loss: 0.7765, G loss: 2.3527\n",
      "[364/1600] D loss: 0.8861, G loss: 2.9240\n",
      "[484/1600] D loss: 0.8252, G loss: 3.4446\n",
      "[604/1600] D loss: 0.2135, G loss: 2.8414\n",
      "[724/1600] D loss: 0.8191, G loss: 3.9288\n",
      "[844/1600] D loss: 0.5772, G loss: 4.3537\n",
      "[964/1600] D loss: 0.4723, G loss: 3.3527\n",
      "[1084/1600] D loss: 0.8266, G loss: 2.8701\n",
      "[1204/1600] D loss: 0.4609, G loss: 2.1331\n",
      "[1324/1600] D loss: 0.1680, G loss: 2.4271\n",
      "[1444/1600] D loss: 0.8266, G loss: 2.0345\n",
      "[1564/1600] D loss: 0.1677, G loss: 5.6968\n",
      "train error: \n",
      " D loss: 0.584208, G loss: 3.028514, D accuracy: 85.4%, cell accuracy: 95.7%, board accuracy: 10.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.621907, G loss: 5.332547, D accuracy: 84.9%, cell accuracy: 95.1%, board accuracy: 7.5% \n",
      "\n",
      "Epoch 237\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2206, G loss: 1.1658\n",
      "[124/1600] D loss: 0.3560, G loss: 3.7976\n",
      "[244/1600] D loss: 0.6627, G loss: 4.2835\n",
      "[364/1600] D loss: 0.3959, G loss: 5.3263\n",
      "[484/1600] D loss: 0.0614, G loss: 4.0126\n",
      "[604/1600] D loss: 0.5213, G loss: 4.3939\n",
      "[724/1600] D loss: 0.5662, G loss: 3.4137\n",
      "[844/1600] D loss: 0.4310, G loss: 2.7687\n",
      "[964/1600] D loss: 0.2158, G loss: 4.2860\n",
      "[1084/1600] D loss: 0.5376, G loss: 3.2443\n",
      "[1204/1600] D loss: 0.4652, G loss: 3.7878\n",
      "[1324/1600] D loss: 0.2023, G loss: 4.5540\n",
      "[1444/1600] D loss: 0.4899, G loss: 3.1428\n",
      "[1564/1600] D loss: 0.6366, G loss: 3.4512\n",
      "train error: \n",
      " D loss: 0.658505, G loss: 2.640408, D accuracy: 83.6%, cell accuracy: 95.7%, board accuracy: 9.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.569351, G loss: 4.895179, D accuracy: 88.4%, cell accuracy: 95.1%, board accuracy: 6.8% \n",
      "\n",
      "Epoch 238\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0759, G loss: 3.3860\n",
      "[124/1600] D loss: 1.5207, G loss: 2.2419\n",
      "[244/1600] D loss: 0.4969, G loss: 5.2740\n",
      "[364/1600] D loss: 0.3669, G loss: 3.8058\n",
      "[484/1600] D loss: 0.5536, G loss: 3.0875\n",
      "[604/1600] D loss: 0.4656, G loss: 1.8477\n",
      "[724/1600] D loss: 0.0181, G loss: 6.4713\n",
      "[844/1600] D loss: 0.6243, G loss: 4.3230\n",
      "[964/1600] D loss: 0.7344, G loss: 2.7105\n",
      "[1084/1600] D loss: 0.0611, G loss: 5.2867\n",
      "[1204/1600] D loss: 0.2295, G loss: 5.3256\n",
      "[1324/1600] D loss: 0.6343, G loss: 4.1191\n",
      "[1444/1600] D loss: 0.2543, G loss: 3.6417\n",
      "[1564/1600] D loss: 0.4636, G loss: 4.2030\n",
      "train error: \n",
      " D loss: 0.556784, G loss: 2.942800, D accuracy: 86.3%, cell accuracy: 95.7%, board accuracy: 10.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.565649, G loss: 5.316974, D accuracy: 87.4%, cell accuracy: 95.0%, board accuracy: 7.0% \n",
      "\n",
      "Epoch 239\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7229, G loss: 1.7238\n",
      "[124/1600] D loss: 0.2979, G loss: 3.3973\n",
      "[244/1600] D loss: 0.4724, G loss: 2.4711\n",
      "[364/1600] D loss: 0.4367, G loss: 2.5529\n",
      "[484/1600] D loss: 1.1733, G loss: 2.3081\n",
      "[604/1600] D loss: 0.4524, G loss: 5.7771\n",
      "[724/1600] D loss: 0.2154, G loss: 4.9883\n",
      "[844/1600] D loss: 0.3258, G loss: 3.5025\n",
      "[964/1600] D loss: 0.6844, G loss: 1.6572\n",
      "[1084/1600] D loss: 0.1879, G loss: 2.8445\n",
      "[1204/1600] D loss: 0.8080, G loss: 2.5070\n",
      "[1324/1600] D loss: 0.9292, G loss: 2.8235\n",
      "[1444/1600] D loss: 0.3900, G loss: 3.6407\n",
      "[1564/1600] D loss: 0.3307, G loss: 4.6740\n",
      "train error: \n",
      " D loss: 0.552987, G loss: 3.516511, D accuracy: 86.5%, cell accuracy: 95.7%, board accuracy: 11.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.717169, G loss: 5.940977, D accuracy: 83.9%, cell accuracy: 95.2%, board accuracy: 7.8% \n",
      "\n",
      "Epoch 240\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.1029, G loss: 4.0902\n",
      "[124/1600] D loss: 0.0960, G loss: 2.9290\n",
      "[244/1600] D loss: 0.3129, G loss: 6.0457\n",
      "[364/1600] D loss: 0.3347, G loss: 3.5252\n",
      "[484/1600] D loss: 0.0246, G loss: 5.4178\n",
      "[604/1600] D loss: 0.9684, G loss: 5.4723\n",
      "[724/1600] D loss: 0.1520, G loss: 4.1423\n",
      "[844/1600] D loss: 0.1493, G loss: 3.6653\n",
      "[964/1600] D loss: 0.4526, G loss: 2.6452\n",
      "[1084/1600] D loss: 1.4340, G loss: 0.5873\n",
      "[1204/1600] D loss: 0.6333, G loss: 2.0457\n",
      "[1324/1600] D loss: 0.6133, G loss: 2.6127\n",
      "[1444/1600] D loss: 1.0623, G loss: 1.0342\n",
      "[1564/1600] D loss: 0.5719, G loss: 1.8184\n",
      "train error: \n",
      " D loss: 0.541523, G loss: 3.380157, D accuracy: 86.2%, cell accuracy: 95.7%, board accuracy: 11.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.663750, G loss: 5.735645, D accuracy: 84.5%, cell accuracy: 95.1%, board accuracy: 8.2% \n",
      "\n",
      "Epoch 241\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.3866, G loss: 3.5636\n",
      "[124/1600] D loss: 0.8834, G loss: 1.8644\n",
      "[244/1600] D loss: 0.2873, G loss: 2.0962\n",
      "[364/1600] D loss: 0.8565, G loss: 2.4682\n",
      "[484/1600] D loss: 0.6436, G loss: 6.1366\n",
      "[604/1600] D loss: 0.7859, G loss: 2.9423\n",
      "[724/1600] D loss: 0.1303, G loss: 5.0305\n",
      "[844/1600] D loss: 0.7117, G loss: 1.1074\n",
      "[964/1600] D loss: 1.1054, G loss: 3.9803\n",
      "[1084/1600] D loss: 0.1598, G loss: 3.4107\n",
      "[1204/1600] D loss: 0.4665, G loss: 2.1207\n",
      "[1324/1600] D loss: 0.6033, G loss: 2.2059\n",
      "[1444/1600] D loss: 0.2544, G loss: 4.8467\n",
      "[1564/1600] D loss: 1.0381, G loss: 1.1779\n",
      "train error: \n",
      " D loss: 0.610770, G loss: 3.693802, D accuracy: 84.6%, cell accuracy: 95.8%, board accuracy: 10.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.796450, G loss: 5.917910, D accuracy: 82.6%, cell accuracy: 95.1%, board accuracy: 7.2% \n",
      "\n",
      "Epoch 242\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.1949, G loss: 6.1038\n",
      "[124/1600] D loss: 0.7063, G loss: 4.9176\n",
      "[244/1600] D loss: 0.0708, G loss: 6.1926\n",
      "[364/1600] D loss: 0.5905, G loss: 1.7029\n",
      "[484/1600] D loss: 0.2667, G loss: 2.4371\n",
      "[604/1600] D loss: 0.3167, G loss: 3.3660\n",
      "[724/1600] D loss: 0.8371, G loss: 1.1763\n",
      "[844/1600] D loss: 0.6681, G loss: 1.2187\n",
      "[964/1600] D loss: 0.5271, G loss: 3.5067\n",
      "[1084/1600] D loss: 0.2789, G loss: 2.4311\n",
      "[1204/1600] D loss: 0.2150, G loss: 4.5919\n",
      "[1324/1600] D loss: 0.7224, G loss: 1.4065\n",
      "[1444/1600] D loss: 0.6700, G loss: 1.7873\n",
      "[1564/1600] D loss: 0.1821, G loss: 6.2904\n",
      "train error: \n",
      " D loss: 0.521814, G loss: 3.418049, D accuracy: 87.2%, cell accuracy: 95.8%, board accuracy: 9.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.645338, G loss: 5.832097, D accuracy: 85.6%, cell accuracy: 95.1%, board accuracy: 6.5% \n",
      "\n",
      "Epoch 243\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.0027, G loss: 2.4083\n",
      "[124/1600] D loss: 0.2867, G loss: 7.6186\n",
      "[244/1600] D loss: 0.3979, G loss: 3.7117\n",
      "[364/1600] D loss: 1.0308, G loss: 3.0064\n",
      "[484/1600] D loss: 0.8181, G loss: 1.0047\n",
      "[604/1600] D loss: 0.7151, G loss: 1.7695\n",
      "[724/1600] D loss: 1.1474, G loss: 1.1909\n",
      "[844/1600] D loss: 1.2147, G loss: 2.3545\n",
      "[964/1600] D loss: 0.9073, G loss: 1.7547\n",
      "[1084/1600] D loss: 0.6993, G loss: 2.0814\n",
      "[1204/1600] D loss: 0.3537, G loss: 5.2782\n",
      "[1324/1600] D loss: 0.3872, G loss: 2.0958\n",
      "[1444/1600] D loss: 0.0347, G loss: 4.4206\n",
      "[1564/1600] D loss: 0.5099, G loss: 3.5179\n",
      "train error: \n",
      " D loss: 0.532621, G loss: 3.636478, D accuracy: 86.4%, cell accuracy: 95.7%, board accuracy: 10.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.658246, G loss: 6.021746, D accuracy: 85.2%, cell accuracy: 95.0%, board accuracy: 7.5% \n",
      "\n",
      "Epoch 244\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.1415, G loss: 3.5919\n",
      "[124/1600] D loss: 0.4196, G loss: 3.7698\n",
      "[244/1600] D loss: 1.0716, G loss: 3.7116\n",
      "[364/1600] D loss: 0.9275, G loss: 2.8485\n",
      "[484/1600] D loss: 0.7553, G loss: 1.1651\n",
      "[604/1600] D loss: 0.5278, G loss: 2.6960\n",
      "[724/1600] D loss: 0.5854, G loss: 8.0128\n",
      "[844/1600] D loss: 0.1210, G loss: 4.3129\n",
      "[964/1600] D loss: 0.3671, G loss: 6.4858\n",
      "[1084/1600] D loss: 0.5098, G loss: 2.4461\n",
      "[1204/1600] D loss: 0.0936, G loss: 4.4042\n",
      "[1324/1600] D loss: 0.4737, G loss: 3.4047\n",
      "[1444/1600] D loss: 0.2359, G loss: 4.5660\n",
      "[1564/1600] D loss: 0.1184, G loss: 4.9935\n",
      "train error: \n",
      " D loss: 0.522706, G loss: 3.366318, D accuracy: 87.3%, cell accuracy: 95.7%, board accuracy: 10.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.632303, G loss: 5.670035, D accuracy: 85.8%, cell accuracy: 95.1%, board accuracy: 7.0% \n",
      "\n",
      "Epoch 245\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.0900, G loss: 3.5520\n",
      "[124/1600] D loss: 0.9427, G loss: 3.3515\n",
      "[244/1600] D loss: 0.3773, G loss: 3.3724\n",
      "[364/1600] D loss: 0.8405, G loss: 2.4059\n",
      "[484/1600] D loss: 0.5429, G loss: 3.3448\n",
      "[604/1600] D loss: 0.3090, G loss: 4.3058\n",
      "[724/1600] D loss: 0.2866, G loss: 3.3222\n",
      "[844/1600] D loss: 0.7381, G loss: 2.2169\n",
      "[964/1600] D loss: 0.0852, G loss: 5.4542\n",
      "[1084/1600] D loss: 0.0071, G loss: 8.3181\n",
      "[1204/1600] D loss: 0.4325, G loss: 2.5869\n",
      "[1324/1600] D loss: 0.6377, G loss: 4.4701\n",
      "[1444/1600] D loss: 1.0675, G loss: 1.5491\n",
      "[1564/1600] D loss: 1.8038, G loss: 1.5931\n",
      "train error: \n",
      " D loss: 0.599356, G loss: 2.765988, D accuracy: 85.3%, cell accuracy: 95.8%, board accuracy: 10.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.574650, G loss: 5.180560, D accuracy: 86.6%, cell accuracy: 95.2%, board accuracy: 6.5% \n",
      "\n",
      "Epoch 246\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6411, G loss: 2.0801\n",
      "[124/1600] D loss: 0.4315, G loss: 4.2774\n",
      "[244/1600] D loss: 0.5228, G loss: 2.0618\n",
      "[364/1600] D loss: 0.8336, G loss: 3.0418\n",
      "[484/1600] D loss: 0.4476, G loss: 4.0194\n",
      "[604/1600] D loss: 0.5117, G loss: 2.5004\n",
      "[724/1600] D loss: 0.7006, G loss: 2.0599\n",
      "[844/1600] D loss: 0.6280, G loss: 2.0350\n",
      "[964/1600] D loss: 0.1439, G loss: 6.3610\n",
      "[1084/1600] D loss: 0.2462, G loss: 6.0166\n",
      "[1204/1600] D loss: 0.0960, G loss: 3.5363\n",
      "[1324/1600] D loss: 0.5494, G loss: 1.7706\n",
      "[1444/1600] D loss: 1.0447, G loss: 2.2817\n",
      "[1564/1600] D loss: 0.6758, G loss: 1.4881\n",
      "train error: \n",
      " D loss: 0.537482, G loss: 3.709367, D accuracy: 86.4%, cell accuracy: 95.8%, board accuracy: 11.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.719439, G loss: 6.163474, D accuracy: 83.5%, cell accuracy: 95.1%, board accuracy: 7.5% \n",
      "\n",
      "Epoch 247\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9911, G loss: 2.9115\n",
      "[124/1600] D loss: 0.7265, G loss: 3.5458\n",
      "[244/1600] D loss: 0.6193, G loss: 2.3568\n",
      "[364/1600] D loss: 1.4336, G loss: 1.7640\n",
      "[484/1600] D loss: 0.2773, G loss: 4.2213\n",
      "[604/1600] D loss: 0.8057, G loss: 3.9591\n",
      "[724/1600] D loss: 0.4582, G loss: 4.7540\n",
      "[844/1600] D loss: 0.0716, G loss: 4.1004\n",
      "[964/1600] D loss: 0.3810, G loss: 4.0822\n",
      "[1084/1600] D loss: 1.1388, G loss: 2.7597\n",
      "[1204/1600] D loss: 0.1919, G loss: 4.5516\n",
      "[1324/1600] D loss: 0.5607, G loss: 2.7579\n",
      "[1444/1600] D loss: 0.1746, G loss: 5.2698\n",
      "[1564/1600] D loss: 0.8105, G loss: 3.2871\n",
      "train error: \n",
      " D loss: 0.603159, G loss: 2.847344, D accuracy: 84.7%, cell accuracy: 95.8%, board accuracy: 11.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.579922, G loss: 5.283706, D accuracy: 87.9%, cell accuracy: 95.2%, board accuracy: 7.2% \n",
      "\n",
      "Epoch 248\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7421, G loss: 1.2147\n",
      "[124/1600] D loss: 1.1849, G loss: 3.6955\n",
      "[244/1600] D loss: 0.7106, G loss: 2.9311\n",
      "[364/1600] D loss: 0.7397, G loss: 1.5480\n",
      "[484/1600] D loss: 0.8397, G loss: 1.7386\n",
      "[604/1600] D loss: 1.2419, G loss: 0.8774\n",
      "[724/1600] D loss: 0.3205, G loss: 5.5051\n",
      "[844/1600] D loss: 0.6375, G loss: 3.5639\n",
      "[964/1600] D loss: 0.8624, G loss: 2.1960\n",
      "[1084/1600] D loss: 0.4491, G loss: 2.8394\n",
      "[1204/1600] D loss: 0.0946, G loss: 3.7534\n",
      "[1324/1600] D loss: 1.4675, G loss: 0.6142\n",
      "[1444/1600] D loss: 0.9808, G loss: 2.0084\n",
      "[1564/1600] D loss: 0.1174, G loss: 3.9475\n",
      "train error: \n",
      " D loss: 0.577826, G loss: 3.470108, D accuracy: 85.6%, cell accuracy: 95.8%, board accuracy: 11.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.717450, G loss: 5.773079, D accuracy: 83.8%, cell accuracy: 95.1%, board accuracy: 8.0% \n",
      "\n",
      "Epoch 249\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5241, G loss: 2.7930\n",
      "[124/1600] D loss: 0.1475, G loss: 4.6083\n",
      "[244/1600] D loss: 0.4482, G loss: 4.6662\n",
      "[364/1600] D loss: 0.6146, G loss: 4.0401\n",
      "[484/1600] D loss: 0.7045, G loss: 3.2349\n",
      "[604/1600] D loss: 0.7459, G loss: 6.3529\n",
      "[724/1600] D loss: 0.1294, G loss: 4.2765\n",
      "[844/1600] D loss: 1.2862, G loss: 2.3941\n",
      "[964/1600] D loss: 0.4557, G loss: 3.9167\n",
      "[1084/1600] D loss: 1.2082, G loss: 2.8129\n",
      "[1204/1600] D loss: 0.6615, G loss: 2.1436\n",
      "[1324/1600] D loss: 0.0559, G loss: 4.9343\n",
      "[1444/1600] D loss: 0.5313, G loss: 2.0505\n",
      "[1564/1600] D loss: 0.2271, G loss: 3.0609\n",
      "train error: \n",
      " D loss: 0.570407, G loss: 2.814048, D accuracy: 86.1%, cell accuracy: 95.7%, board accuracy: 10.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.582900, G loss: 5.133609, D accuracy: 87.1%, cell accuracy: 95.0%, board accuracy: 6.5% \n",
      "\n",
      "Epoch 250\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.1566, G loss: 3.4754\n",
      "[124/1600] D loss: 0.7266, G loss: 4.0082\n",
      "[244/1600] D loss: 0.5032, G loss: 2.4222\n",
      "[364/1600] D loss: 0.7019, G loss: 2.8946\n",
      "[484/1600] D loss: 0.4395, G loss: 3.4889\n",
      "[604/1600] D loss: 0.8342, G loss: 1.4302\n",
      "[724/1600] D loss: 0.7269, G loss: 4.1662\n",
      "[844/1600] D loss: 0.3615, G loss: 3.7520\n",
      "[964/1600] D loss: 0.9544, G loss: 1.4683\n",
      "[1084/1600] D loss: 0.3893, G loss: 4.5234\n",
      "[1204/1600] D loss: 0.0990, G loss: 4.3217\n",
      "[1324/1600] D loss: 0.4436, G loss: 5.4156\n",
      "[1444/1600] D loss: 0.4145, G loss: 3.5290\n",
      "[1564/1600] D loss: 0.6333, G loss: 1.4810\n",
      "train error: \n",
      " D loss: 0.536030, G loss: 3.517545, D accuracy: 86.4%, cell accuracy: 95.7%, board accuracy: 10.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.693824, G loss: 6.073645, D accuracy: 84.9%, cell accuracy: 95.1%, board accuracy: 5.0% \n",
      "\n",
      "Epoch 251\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4700, G loss: 3.3848\n",
      "[124/1600] D loss: 0.8705, G loss: 3.7962\n",
      "[244/1600] D loss: 0.8419, G loss: 2.2347\n",
      "[364/1600] D loss: 0.1669, G loss: 4.9289\n",
      "[484/1600] D loss: 0.4906, G loss: 3.9267\n",
      "[604/1600] D loss: 0.4869, G loss: 4.0242\n",
      "[724/1600] D loss: 0.1911, G loss: 4.4249\n",
      "[844/1600] D loss: 0.4688, G loss: 3.0397\n",
      "[964/1600] D loss: 0.2833, G loss: 6.8437\n",
      "[1084/1600] D loss: 0.3134, G loss: 4.0396\n",
      "[1204/1600] D loss: 0.9444, G loss: 1.3860\n",
      "[1324/1600] D loss: 0.8233, G loss: 4.2432\n",
      "[1444/1600] D loss: 0.3934, G loss: 4.8000\n",
      "[1564/1600] D loss: 0.0746, G loss: 5.7155\n",
      "train error: \n",
      " D loss: 0.574874, G loss: 3.973333, D accuracy: 85.2%, cell accuracy: 95.7%, board accuracy: 10.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.760070, G loss: 6.409379, D accuracy: 83.4%, cell accuracy: 94.9%, board accuracy: 6.5% \n",
      "\n",
      "Epoch 252\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.2818, G loss: 3.3637\n",
      "[124/1600] D loss: 0.9114, G loss: 2.1398\n",
      "[244/1600] D loss: 0.1438, G loss: 4.1174\n",
      "[364/1600] D loss: 0.9288, G loss: 1.8075\n",
      "[484/1600] D loss: 0.9940, G loss: 1.1550\n",
      "[604/1600] D loss: 0.7689, G loss: 1.8492\n",
      "[724/1600] D loss: 0.2006, G loss: 4.4909\n",
      "[844/1600] D loss: 0.3798, G loss: 3.6643\n",
      "[964/1600] D loss: 0.0422, G loss: 4.7122\n",
      "[1084/1600] D loss: 0.4046, G loss: 4.7585\n",
      "[1204/1600] D loss: 0.2597, G loss: 5.0540\n",
      "[1324/1600] D loss: 0.5674, G loss: 2.2968\n",
      "[1444/1600] D loss: 0.2179, G loss: 4.3555\n",
      "[1564/1600] D loss: 0.6351, G loss: 3.7680\n",
      "train error: \n",
      " D loss: 0.640075, G loss: 4.117929, D accuracy: 84.7%, cell accuracy: 95.7%, board accuracy: 9.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.861082, G loss: 6.523593, D accuracy: 82.9%, cell accuracy: 95.1%, board accuracy: 6.8% \n",
      "\n",
      "Epoch 253\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6679, G loss: 3.0089\n",
      "[124/1600] D loss: 0.0589, G loss: 3.2983\n",
      "[244/1600] D loss: 0.4268, G loss: 3.2365\n",
      "[364/1600] D loss: 0.0795, G loss: 3.8145\n",
      "[484/1600] D loss: 1.5557, G loss: 1.9209\n",
      "[604/1600] D loss: 0.9545, G loss: 2.2154\n",
      "[724/1600] D loss: 0.2737, G loss: 5.8193\n",
      "[844/1600] D loss: 0.1881, G loss: 8.7669\n",
      "[964/1600] D loss: 0.8870, G loss: 3.2321\n",
      "[1084/1600] D loss: 0.1981, G loss: 5.3777\n",
      "[1204/1600] D loss: 0.6405, G loss: 3.7780\n",
      "[1324/1600] D loss: 0.2537, G loss: 1.9619\n",
      "[1444/1600] D loss: 0.4044, G loss: 3.3844\n",
      "[1564/1600] D loss: 0.4397, G loss: 3.0919\n",
      "train error: \n",
      " D loss: 0.518926, G loss: 3.350463, D accuracy: 86.8%, cell accuracy: 95.7%, board accuracy: 10.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.633038, G loss: 5.848907, D accuracy: 85.9%, cell accuracy: 95.0%, board accuracy: 6.2% \n",
      "\n",
      "Epoch 254\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9268, G loss: 1.3472\n",
      "[124/1600] D loss: 0.3227, G loss: 2.5659\n",
      "[244/1600] D loss: 1.1148, G loss: 3.4783\n",
      "[364/1600] D loss: 0.7862, G loss: 1.6300\n",
      "[484/1600] D loss: 0.3448, G loss: 5.0785\n",
      "[604/1600] D loss: 0.4572, G loss: 3.0372\n",
      "[724/1600] D loss: 0.6138, G loss: 1.7767\n",
      "[844/1600] D loss: 1.1081, G loss: 1.1941\n",
      "[964/1600] D loss: 0.9306, G loss: 1.3215\n",
      "[1084/1600] D loss: 0.5992, G loss: 5.5825\n",
      "[1204/1600] D loss: 0.1496, G loss: 3.8259\n",
      "[1324/1600] D loss: 0.8382, G loss: 2.7113\n",
      "[1444/1600] D loss: 0.4600, G loss: 5.9369\n",
      "[1564/1600] D loss: 0.2584, G loss: 6.5188\n",
      "train error: \n",
      " D loss: 0.599563, G loss: 2.781337, D accuracy: 85.6%, cell accuracy: 95.7%, board accuracy: 10.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.547275, G loss: 5.293404, D accuracy: 88.8%, cell accuracy: 95.1%, board accuracy: 7.0% \n",
      "\n",
      "Epoch 255\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.2404, G loss: 4.0997\n",
      "[124/1600] D loss: 0.2140, G loss: 2.9110\n",
      "[244/1600] D loss: 0.5736, G loss: 2.8387\n",
      "[364/1600] D loss: 0.2619, G loss: 5.0260\n",
      "[484/1600] D loss: 0.3010, G loss: 6.8998\n",
      "[604/1600] D loss: 1.0402, G loss: 2.3284\n",
      "[724/1600] D loss: 0.3222, G loss: 3.5390\n",
      "[844/1600] D loss: 0.4186, G loss: 3.3194\n",
      "[964/1600] D loss: 0.1510, G loss: 4.9566\n",
      "[1084/1600] D loss: 0.0910, G loss: 6.0652\n",
      "[1204/1600] D loss: 0.4773, G loss: 4.5040\n",
      "[1324/1600] D loss: 0.1896, G loss: 5.0253\n",
      "[1444/1600] D loss: 0.4274, G loss: 3.6131\n",
      "[1564/1600] D loss: 0.8894, G loss: 2.1335\n",
      "train error: \n",
      " D loss: 0.516847, G loss: 3.222362, D accuracy: 87.1%, cell accuracy: 95.8%, board accuracy: 10.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.615509, G loss: 5.674606, D accuracy: 86.4%, cell accuracy: 95.1%, board accuracy: 6.0% \n",
      "\n",
      "Epoch 256\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.0542, G loss: 4.1008\n",
      "[124/1600] D loss: 0.4131, G loss: 3.5217\n",
      "[244/1600] D loss: 0.7981, G loss: 1.6804\n",
      "[364/1600] D loss: 0.7267, G loss: 2.7210\n",
      "[484/1600] D loss: 0.9189, G loss: 1.4372\n",
      "[604/1600] D loss: 0.4089, G loss: 4.1664\n",
      "[724/1600] D loss: 0.7378, G loss: 3.7211\n",
      "[844/1600] D loss: 0.0728, G loss: 6.6433\n",
      "[964/1600] D loss: 0.0423, G loss: 4.8351\n",
      "[1084/1600] D loss: 0.8323, G loss: 1.2497\n",
      "[1204/1600] D loss: 0.4618, G loss: 2.9805\n",
      "[1324/1600] D loss: 0.5210, G loss: 4.4761\n",
      "[1444/1600] D loss: 0.5612, G loss: 3.8819\n",
      "[1564/1600] D loss: 0.3079, G loss: 3.2964\n",
      "train error: \n",
      " D loss: 0.523718, G loss: 3.526474, D accuracy: 86.9%, cell accuracy: 95.7%, board accuracy: 10.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.679152, G loss: 6.079705, D accuracy: 84.5%, cell accuracy: 95.0%, board accuracy: 5.8% \n",
      "\n",
      "Epoch 257\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4859, G loss: 2.5433\n",
      "[124/1600] D loss: 1.1102, G loss: 1.9755\n",
      "[244/1600] D loss: 0.4949, G loss: 8.1690\n",
      "[364/1600] D loss: 1.5356, G loss: 1.1396\n",
      "[484/1600] D loss: 0.1457, G loss: 4.0479\n",
      "[604/1600] D loss: 0.1185, G loss: 5.6190\n",
      "[724/1600] D loss: 0.7888, G loss: 3.4316\n",
      "[844/1600] D loss: 0.7097, G loss: 2.4525\n",
      "[964/1600] D loss: 1.0249, G loss: 3.7448\n",
      "[1084/1600] D loss: 0.4380, G loss: 2.7789\n",
      "[1204/1600] D loss: 0.3374, G loss: 4.0950\n",
      "[1324/1600] D loss: 0.5359, G loss: 5.3434\n",
      "[1444/1600] D loss: 0.6404, G loss: 1.7087\n",
      "[1564/1600] D loss: 0.0937, G loss: 3.0534\n",
      "train error: \n",
      " D loss: 0.523811, G loss: 3.805924, D accuracy: 86.4%, cell accuracy: 95.7%, board accuracy: 11.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.694268, G loss: 6.526216, D accuracy: 84.6%, cell accuracy: 95.0%, board accuracy: 6.8% \n",
      "\n",
      "Epoch 258\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.3916, G loss: 4.3983\n",
      "[124/1600] D loss: 0.6094, G loss: 1.4059\n",
      "[244/1600] D loss: 0.2476, G loss: 3.8171\n",
      "[364/1600] D loss: 1.1353, G loss: 1.4262\n",
      "[484/1600] D loss: 0.1801, G loss: 2.1811\n",
      "[604/1600] D loss: 0.0698, G loss: 3.8759\n",
      "[724/1600] D loss: 1.2218, G loss: 2.3537\n",
      "[844/1600] D loss: 0.4191, G loss: 2.5277\n",
      "[964/1600] D loss: 0.4242, G loss: 6.2770\n",
      "[1084/1600] D loss: 0.9694, G loss: 0.8711\n",
      "[1204/1600] D loss: 0.8379, G loss: 1.8680\n",
      "[1324/1600] D loss: 0.2862, G loss: 2.3994\n",
      "[1444/1600] D loss: 0.9549, G loss: 3.1966\n",
      "[1564/1600] D loss: 0.5012, G loss: 3.6186\n",
      "train error: \n",
      " D loss: 0.557997, G loss: 3.253937, D accuracy: 86.0%, cell accuracy: 95.8%, board accuracy: 12.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.624491, G loss: 5.878367, D accuracy: 85.9%, cell accuracy: 95.1%, board accuracy: 7.2% \n",
      "\n",
      "Epoch 259\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.0074, G loss: 7.0010\n",
      "[124/1600] D loss: 0.2633, G loss: 2.1816\n",
      "[244/1600] D loss: 0.4466, G loss: 5.1896\n",
      "[364/1600] D loss: 0.2484, G loss: 3.9467\n",
      "[484/1600] D loss: 0.3571, G loss: 5.1496\n",
      "[604/1600] D loss: 0.4494, G loss: 4.8152\n",
      "[724/1600] D loss: 0.1452, G loss: 4.2615\n",
      "[844/1600] D loss: 0.7054, G loss: 1.6535\n",
      "[964/1600] D loss: 0.8397, G loss: 2.3619\n",
      "[1084/1600] D loss: 0.9194, G loss: 2.1765\n",
      "[1204/1600] D loss: 0.2306, G loss: 6.8574\n",
      "[1324/1600] D loss: 0.6045, G loss: 2.1945\n",
      "[1444/1600] D loss: 1.0547, G loss: 3.5864\n",
      "[1564/1600] D loss: 0.1277, G loss: 3.4383\n",
      "train error: \n",
      " D loss: 0.501743, G loss: 3.297056, D accuracy: 87.7%, cell accuracy: 95.7%, board accuracy: 11.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.568686, G loss: 5.936979, D accuracy: 87.1%, cell accuracy: 95.0%, board accuracy: 7.5% \n",
      "\n",
      "Epoch 260\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9454, G loss: 0.8640\n",
      "[124/1600] D loss: 0.5951, G loss: 2.5329\n",
      "[244/1600] D loss: 0.5174, G loss: 4.4389\n",
      "[364/1600] D loss: 0.3318, G loss: 3.0089\n",
      "[484/1600] D loss: 0.8800, G loss: 2.2836\n",
      "[604/1600] D loss: 0.7899, G loss: 2.6609\n",
      "[724/1600] D loss: 0.6641, G loss: 2.3406\n",
      "[844/1600] D loss: 0.0265, G loss: 7.0647\n",
      "[964/1600] D loss: 0.4736, G loss: 4.8428\n",
      "[1084/1600] D loss: 0.8749, G loss: 2.0060\n",
      "[1204/1600] D loss: 0.4165, G loss: 2.4740\n",
      "[1324/1600] D loss: 1.0273, G loss: 1.7380\n",
      "[1444/1600] D loss: 0.2070, G loss: 4.0067\n",
      "[1564/1600] D loss: 0.9008, G loss: 3.6417\n",
      "train error: \n",
      " D loss: 0.534299, G loss: 3.367874, D accuracy: 86.6%, cell accuracy: 95.7%, board accuracy: 11.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.615989, G loss: 5.898735, D accuracy: 86.0%, cell accuracy: 95.0%, board accuracy: 7.0% \n",
      "\n",
      "Epoch 261\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.2756, G loss: 3.6296\n",
      "[124/1600] D loss: 0.8097, G loss: 0.9288\n",
      "[244/1600] D loss: 1.1709, G loss: 0.8664\n",
      "[364/1600] D loss: 0.6636, G loss: 1.9679\n",
      "[484/1600] D loss: 0.4150, G loss: 5.9438\n",
      "[604/1600] D loss: 0.7660, G loss: 4.2113\n",
      "[724/1600] D loss: 0.0422, G loss: 6.3926\n",
      "[844/1600] D loss: 0.2240, G loss: 2.5485\n",
      "[964/1600] D loss: 0.0598, G loss: 5.0909\n",
      "[1084/1600] D loss: 0.2972, G loss: 2.2389\n",
      "[1204/1600] D loss: 0.6420, G loss: 2.7650\n",
      "[1324/1600] D loss: 0.4215, G loss: 2.7725\n",
      "[1444/1600] D loss: 1.1981, G loss: 1.2276\n",
      "[1564/1600] D loss: 0.1308, G loss: 6.2509\n",
      "train error: \n",
      " D loss: 0.572297, G loss: 3.103941, D accuracy: 85.6%, cell accuracy: 95.8%, board accuracy: 12.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.573396, G loss: 5.736156, D accuracy: 86.4%, cell accuracy: 95.1%, board accuracy: 7.2% \n",
      "\n",
      "Epoch 262\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4340, G loss: 2.8246\n",
      "[124/1600] D loss: 0.0633, G loss: 4.6938\n",
      "[244/1600] D loss: 0.9179, G loss: 2.5886\n",
      "[364/1600] D loss: 0.8348, G loss: 4.3899\n",
      "[484/1600] D loss: 0.1600, G loss: 5.6610\n",
      "[604/1600] D loss: 0.4175, G loss: 3.2921\n",
      "[724/1600] D loss: 1.1868, G loss: 0.8869\n",
      "[844/1600] D loss: 0.4558, G loss: 2.2910\n",
      "[964/1600] D loss: 0.3669, G loss: 4.5600\n",
      "[1084/1600] D loss: 0.8505, G loss: 3.0831\n",
      "[1204/1600] D loss: 0.6744, G loss: 3.5052\n",
      "[1324/1600] D loss: 0.5074, G loss: 2.0036\n",
      "[1444/1600] D loss: 1.1189, G loss: 1.6709\n",
      "[1564/1600] D loss: 0.0521, G loss: 4.5186\n",
      "train error: \n",
      " D loss: 0.534742, G loss: 3.662269, D accuracy: 86.6%, cell accuracy: 95.8%, board accuracy: 11.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.648317, G loss: 6.323272, D accuracy: 86.0%, cell accuracy: 95.0%, board accuracy: 7.8% \n",
      "\n",
      "Epoch 263\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5749, G loss: 2.7473\n",
      "[124/1600] D loss: 0.2421, G loss: 5.4616\n",
      "[244/1600] D loss: 0.9773, G loss: 1.5827\n",
      "[364/1600] D loss: 0.6351, G loss: 2.0009\n",
      "[484/1600] D loss: 0.8528, G loss: 2.1266\n",
      "[604/1600] D loss: 0.1661, G loss: 4.7755\n",
      "[724/1600] D loss: 0.3410, G loss: 4.1602\n",
      "[844/1600] D loss: 0.1442, G loss: 4.6498\n",
      "[964/1600] D loss: 1.0697, G loss: 1.0072\n",
      "[1084/1600] D loss: 0.1778, G loss: 5.9203\n",
      "[1204/1600] D loss: 0.8371, G loss: 3.5516\n",
      "[1324/1600] D loss: 0.3928, G loss: 4.7029\n",
      "[1444/1600] D loss: 0.4177, G loss: 3.0360\n",
      "[1564/1600] D loss: 0.2541, G loss: 4.9285\n",
      "train error: \n",
      " D loss: 0.531557, G loss: 3.570414, D accuracy: 87.3%, cell accuracy: 95.8%, board accuracy: 12.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.670809, G loss: 6.232965, D accuracy: 85.8%, cell accuracy: 95.0%, board accuracy: 8.5% \n",
      "\n",
      "Epoch 264\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1807, G loss: 2.3625\n",
      "[124/1600] D loss: 0.1314, G loss: 2.5655\n",
      "[244/1600] D loss: 0.9456, G loss: 2.6833\n",
      "[364/1600] D loss: 0.1833, G loss: 2.3333\n",
      "[484/1600] D loss: 0.3537, G loss: 4.2914\n",
      "[604/1600] D loss: 0.8888, G loss: 3.5111\n",
      "[724/1600] D loss: 0.5132, G loss: 4.0074\n",
      "[844/1600] D loss: 0.4723, G loss: 3.3999\n",
      "[964/1600] D loss: 0.7317, G loss: 4.4798\n",
      "[1084/1600] D loss: 0.5696, G loss: 3.3335\n",
      "[1204/1600] D loss: 0.3255, G loss: 3.5021\n",
      "[1324/1600] D loss: 1.0886, G loss: 2.1290\n",
      "[1444/1600] D loss: 0.5288, G loss: 3.5700\n",
      "[1564/1600] D loss: 0.7872, G loss: 1.8778\n",
      "train error: \n",
      " D loss: 0.527101, G loss: 3.660752, D accuracy: 86.4%, cell accuracy: 95.7%, board accuracy: 12.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.662854, G loss: 6.451663, D accuracy: 84.9%, cell accuracy: 95.0%, board accuracy: 7.8% \n",
      "\n",
      "Epoch 265\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4939, G loss: 3.3408\n",
      "[124/1600] D loss: 0.1552, G loss: 6.2393\n",
      "[244/1600] D loss: 0.4274, G loss: 2.7641\n",
      "[364/1600] D loss: 1.0084, G loss: 2.6512\n",
      "[484/1600] D loss: 0.4816, G loss: 4.1029\n",
      "[604/1600] D loss: 0.5249, G loss: 3.5373\n",
      "[724/1600] D loss: 0.4184, G loss: 4.4361\n",
      "[844/1600] D loss: 0.4656, G loss: 3.2533\n",
      "[964/1600] D loss: 0.1797, G loss: 2.6889\n",
      "[1084/1600] D loss: 1.1971, G loss: 1.6395\n",
      "[1204/1600] D loss: 0.4270, G loss: 2.7544\n",
      "[1324/1600] D loss: 1.0981, G loss: 3.4398\n",
      "[1444/1600] D loss: 0.2114, G loss: 5.6028\n",
      "[1564/1600] D loss: 0.7146, G loss: 3.2462\n",
      "train error: \n",
      " D loss: 0.547662, G loss: 3.106501, D accuracy: 86.2%, cell accuracy: 95.8%, board accuracy: 12.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.551771, G loss: 5.731493, D accuracy: 87.9%, cell accuracy: 95.1%, board accuracy: 7.0% \n",
      "\n",
      "Epoch 266\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6454, G loss: 1.7272\n",
      "[124/1600] D loss: 0.2278, G loss: 4.7169\n",
      "[244/1600] D loss: 0.3596, G loss: 2.8865\n",
      "[364/1600] D loss: 0.5670, G loss: 2.2755\n",
      "[484/1600] D loss: 1.3830, G loss: 2.0836\n",
      "[604/1600] D loss: 0.0532, G loss: 5.7779\n",
      "[724/1600] D loss: 0.5420, G loss: 4.1961\n",
      "[844/1600] D loss: 0.3082, G loss: 4.3017\n",
      "[964/1600] D loss: 0.9322, G loss: 1.7780\n",
      "[1084/1600] D loss: 0.4664, G loss: 3.2329\n",
      "[1204/1600] D loss: 0.5691, G loss: 3.5941\n",
      "[1324/1600] D loss: 0.2361, G loss: 2.1529\n",
      "[1444/1600] D loss: 0.3842, G loss: 4.9213\n",
      "[1564/1600] D loss: 0.1202, G loss: 6.6126\n",
      "train error: \n",
      " D loss: 0.565884, G loss: 3.029030, D accuracy: 85.2%, cell accuracy: 95.8%, board accuracy: 12.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.556383, G loss: 5.840801, D accuracy: 87.9%, cell accuracy: 95.1%, board accuracy: 8.2% \n",
      "\n",
      "Epoch 267\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7428, G loss: 5.0283\n",
      "[124/1600] D loss: 1.0202, G loss: 1.8441\n",
      "[244/1600] D loss: 0.1781, G loss: 2.1471\n",
      "[364/1600] D loss: 0.4308, G loss: 3.1984\n",
      "[484/1600] D loss: 1.0756, G loss: 3.4589\n",
      "[604/1600] D loss: 0.2327, G loss: 3.5051\n",
      "[724/1600] D loss: 0.0099, G loss: 7.9523\n",
      "[844/1600] D loss: 0.2097, G loss: 3.0020\n",
      "[964/1600] D loss: 0.3766, G loss: 5.3890\n",
      "[1084/1600] D loss: 0.7807, G loss: 2.2072\n",
      "[1204/1600] D loss: 0.9659, G loss: 1.9806\n",
      "[1324/1600] D loss: 0.3975, G loss: 3.9692\n",
      "[1444/1600] D loss: 0.5593, G loss: 2.4541\n",
      "[1564/1600] D loss: 0.3341, G loss: 2.7921\n",
      "train error: \n",
      " D loss: 0.569331, G loss: 4.020316, D accuracy: 85.1%, cell accuracy: 95.8%, board accuracy: 12.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.798510, G loss: 6.727148, D accuracy: 83.1%, cell accuracy: 95.1%, board accuracy: 8.0% \n",
      "\n",
      "Epoch 268\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6457, G loss: 2.2007\n",
      "[124/1600] D loss: 0.7140, G loss: 5.7653\n",
      "[244/1600] D loss: 0.0517, G loss: 5.5125\n",
      "[364/1600] D loss: 0.6898, G loss: 3.5107\n",
      "[484/1600] D loss: 0.3874, G loss: 4.8677\n",
      "[604/1600] D loss: 0.5188, G loss: 2.4178\n",
      "[724/1600] D loss: 0.7096, G loss: 2.5052\n",
      "[844/1600] D loss: 0.8524, G loss: 1.0178\n",
      "[964/1600] D loss: 0.1635, G loss: 3.5065\n",
      "[1084/1600] D loss: 0.8202, G loss: 3.5673\n",
      "[1204/1600] D loss: 0.1332, G loss: 3.9210\n",
      "[1324/1600] D loss: 0.3838, G loss: 6.4923\n",
      "[1444/1600] D loss: 0.4341, G loss: 2.8741\n",
      "[1564/1600] D loss: 0.0794, G loss: 5.0534\n",
      "train error: \n",
      " D loss: 0.560582, G loss: 3.552176, D accuracy: 85.9%, cell accuracy: 95.8%, board accuracy: 13.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.678904, G loss: 6.308686, D accuracy: 84.4%, cell accuracy: 95.0%, board accuracy: 7.8% \n",
      "\n",
      "Epoch 269\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8906, G loss: 1.4770\n",
      "[124/1600] D loss: 0.1774, G loss: 5.2064\n",
      "[244/1600] D loss: 0.5565, G loss: 1.6873\n",
      "[364/1600] D loss: 0.6944, G loss: 3.5211\n",
      "[484/1600] D loss: 0.4676, G loss: 5.1324\n",
      "[604/1600] D loss: 1.0874, G loss: 2.6448\n",
      "[724/1600] D loss: 0.3230, G loss: 2.6589\n",
      "[844/1600] D loss: 0.6518, G loss: 2.1673\n",
      "[964/1600] D loss: 0.2210, G loss: 3.2779\n",
      "[1084/1600] D loss: 0.2105, G loss: 4.2472\n",
      "[1204/1600] D loss: 1.0682, G loss: 1.2862\n",
      "[1324/1600] D loss: 1.1816, G loss: 0.7747\n",
      "[1444/1600] D loss: 0.1227, G loss: 5.8469\n",
      "[1564/1600] D loss: 0.6621, G loss: 2.7339\n",
      "train error: \n",
      " D loss: 0.560359, G loss: 3.734985, D accuracy: 85.3%, cell accuracy: 95.7%, board accuracy: 12.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.729578, G loss: 6.409124, D accuracy: 83.4%, cell accuracy: 95.0%, board accuracy: 6.8% \n",
      "\n",
      "Epoch 270\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5325, G loss: 3.1644\n",
      "[124/1600] D loss: 1.1696, G loss: 0.8059\n",
      "[244/1600] D loss: 0.7226, G loss: 3.3565\n",
      "[364/1600] D loss: 0.9790, G loss: 1.1185\n",
      "[484/1600] D loss: 0.3594, G loss: 4.0683\n",
      "[604/1600] D loss: 0.4086, G loss: 2.5512\n",
      "[724/1600] D loss: 0.4200, G loss: 3.8756\n",
      "[844/1600] D loss: 0.7272, G loss: 2.8628\n",
      "[964/1600] D loss: 0.7227, G loss: 2.9653\n",
      "[1084/1600] D loss: 1.0524, G loss: 2.3538\n",
      "[1204/1600] D loss: 0.8850, G loss: 2.5313\n",
      "[1324/1600] D loss: 0.0764, G loss: 3.8147\n",
      "[1444/1600] D loss: 0.4031, G loss: 4.5309\n",
      "[1564/1600] D loss: 0.5914, G loss: 2.1890\n",
      "train error: \n",
      " D loss: 0.630855, G loss: 4.050604, D accuracy: 84.7%, cell accuracy: 95.7%, board accuracy: 13.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.767265, G loss: 6.786274, D accuracy: 83.1%, cell accuracy: 95.0%, board accuracy: 8.2% \n",
      "\n",
      "Epoch 271\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5909, G loss: 4.7087\n",
      "[124/1600] D loss: 0.8098, G loss: 5.9726\n",
      "[244/1600] D loss: 0.7811, G loss: 3.8939\n",
      "[364/1600] D loss: 0.5915, G loss: 4.3159\n",
      "[484/1600] D loss: 0.3501, G loss: 3.2505\n",
      "[604/1600] D loss: 0.3972, G loss: 5.1767\n",
      "[724/1600] D loss: 0.4273, G loss: 2.8877\n",
      "[844/1600] D loss: 0.9523, G loss: 2.7331\n",
      "[964/1600] D loss: 0.4303, G loss: 3.4817\n",
      "[1084/1600] D loss: 0.3897, G loss: 4.5384\n",
      "[1204/1600] D loss: 0.4707, G loss: 5.3258\n",
      "[1324/1600] D loss: 0.4944, G loss: 3.7082\n",
      "[1444/1600] D loss: 0.4059, G loss: 3.2321\n",
      "[1564/1600] D loss: 0.4376, G loss: 2.1718\n",
      "train error: \n",
      " D loss: 0.542561, G loss: 3.810653, D accuracy: 86.1%, cell accuracy: 95.8%, board accuracy: 13.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.709962, G loss: 6.634495, D accuracy: 83.6%, cell accuracy: 95.1%, board accuracy: 8.0% \n",
      "\n",
      "Epoch 272\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.1628, G loss: 3.6127\n",
      "[124/1600] D loss: 0.2222, G loss: 3.2714\n",
      "[244/1600] D loss: 0.2846, G loss: 4.8926\n",
      "[364/1600] D loss: 0.9311, G loss: 2.1690\n",
      "[484/1600] D loss: 0.5118, G loss: 2.8682\n",
      "[604/1600] D loss: 0.4497, G loss: 2.3052\n",
      "[724/1600] D loss: 1.0718, G loss: 1.7836\n",
      "[844/1600] D loss: 0.9645, G loss: 1.0858\n",
      "[964/1600] D loss: 0.2115, G loss: 5.6665\n",
      "[1084/1600] D loss: 1.1094, G loss: 1.2087\n",
      "[1204/1600] D loss: 0.9613, G loss: 3.2131\n",
      "[1324/1600] D loss: 0.4294, G loss: 7.3332\n",
      "[1444/1600] D loss: 0.6939, G loss: 3.1548\n",
      "[1564/1600] D loss: 0.0658, G loss: 3.6136\n",
      "train error: \n",
      " D loss: 0.580752, G loss: 3.847233, D accuracy: 85.4%, cell accuracy: 95.8%, board accuracy: 11.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.732357, G loss: 6.490952, D accuracy: 83.8%, cell accuracy: 95.1%, board accuracy: 6.5% \n",
      "\n",
      "Epoch 273\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.6707, G loss: 4.3613\n",
      "[124/1600] D loss: 0.7055, G loss: 3.4234\n",
      "[244/1600] D loss: 0.6365, G loss: 4.6742\n",
      "[364/1600] D loss: 0.4071, G loss: 6.6469\n",
      "[484/1600] D loss: 0.7290, G loss: 2.0242\n",
      "[604/1600] D loss: 0.4642, G loss: 2.4589\n",
      "[724/1600] D loss: 0.1603, G loss: 3.0832\n",
      "[844/1600] D loss: 0.1136, G loss: 4.7264\n",
      "[964/1600] D loss: 0.8598, G loss: 2.4232\n",
      "[1084/1600] D loss: 0.1310, G loss: 2.7369\n",
      "[1204/1600] D loss: 0.4872, G loss: 6.4614\n",
      "[1324/1600] D loss: 0.3880, G loss: 4.1112\n",
      "[1444/1600] D loss: 0.8474, G loss: 3.0747\n",
      "[1564/1600] D loss: 1.5865, G loss: 2.8568\n",
      "train error: \n",
      " D loss: 0.706063, G loss: 2.646987, D accuracy: 82.4%, cell accuracy: 95.8%, board accuracy: 13.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.607828, G loss: 5.384241, D accuracy: 88.0%, cell accuracy: 95.1%, board accuracy: 7.8% \n",
      "\n",
      "Epoch 274\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4643, G loss: 2.9877\n",
      "[124/1600] D loss: 0.5874, G loss: 2.6872\n",
      "[244/1600] D loss: 0.0426, G loss: 3.8447\n",
      "[364/1600] D loss: 1.0123, G loss: 1.1882\n",
      "[484/1600] D loss: 1.1351, G loss: 1.0768\n",
      "[604/1600] D loss: 0.6921, G loss: 2.8099\n",
      "[724/1600] D loss: 0.8370, G loss: 1.3076\n",
      "[844/1600] D loss: 0.6236, G loss: 1.4923\n",
      "[964/1600] D loss: 0.5742, G loss: 2.2141\n",
      "[1084/1600] D loss: 0.6266, G loss: 2.1124\n",
      "[1204/1600] D loss: 0.3109, G loss: 2.1679\n",
      "[1324/1600] D loss: 0.6086, G loss: 2.6873\n",
      "[1444/1600] D loss: 0.8123, G loss: 2.9223\n",
      "[1564/1600] D loss: 0.8104, G loss: 1.2620\n",
      "train error: \n",
      " D loss: 0.626565, G loss: 2.930412, D accuracy: 84.8%, cell accuracy: 95.7%, board accuracy: 13.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.624796, G loss: 5.547744, D accuracy: 86.2%, cell accuracy: 95.1%, board accuracy: 7.8% \n",
      "\n",
      "Epoch 275\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7242, G loss: 1.9797\n",
      "[124/1600] D loss: 0.0844, G loss: 8.6276\n",
      "[244/1600] D loss: 0.0231, G loss: 6.8660\n",
      "[364/1600] D loss: 0.1927, G loss: 3.7760\n",
      "[484/1600] D loss: 0.4408, G loss: 4.6047\n",
      "[604/1600] D loss: 1.5553, G loss: 0.5033\n",
      "[724/1600] D loss: 0.1826, G loss: 4.3636\n",
      "[844/1600] D loss: 0.3762, G loss: 3.7598\n",
      "[964/1600] D loss: 0.7651, G loss: 3.5078\n",
      "[1084/1600] D loss: 1.1227, G loss: 0.8409\n",
      "[1204/1600] D loss: 0.5738, G loss: 5.0857\n",
      "[1324/1600] D loss: 0.4234, G loss: 4.0648\n",
      "[1444/1600] D loss: 0.5762, G loss: 2.7264\n",
      "[1564/1600] D loss: 0.7344, G loss: 4.7966\n",
      "train error: \n",
      " D loss: 0.552262, G loss: 3.342428, D accuracy: 85.9%, cell accuracy: 95.8%, board accuracy: 12.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.608171, G loss: 6.242655, D accuracy: 85.8%, cell accuracy: 95.0%, board accuracy: 6.2% \n",
      "\n",
      "Epoch 276\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.0412, G loss: 6.9519\n",
      "[124/1600] D loss: 0.0727, G loss: 5.5719\n",
      "[244/1600] D loss: 0.5904, G loss: 2.4429\n",
      "[364/1600] D loss: 0.4081, G loss: 5.3426\n",
      "[484/1600] D loss: 0.2373, G loss: 3.9217\n",
      "[604/1600] D loss: 1.1437, G loss: 2.2508\n",
      "[724/1600] D loss: 0.5017, G loss: 4.6284\n",
      "[844/1600] D loss: 0.8866, G loss: 2.8289\n",
      "[964/1600] D loss: 0.4052, G loss: 3.0233\n",
      "[1084/1600] D loss: 0.5986, G loss: 3.5405\n",
      "[1204/1600] D loss: 0.4917, G loss: 3.6715\n",
      "[1324/1600] D loss: 0.2717, G loss: 3.4015\n",
      "[1444/1600] D loss: 0.8872, G loss: 3.1288\n",
      "[1564/1600] D loss: 1.1675, G loss: 1.1945\n",
      "train error: \n",
      " D loss: 0.570810, G loss: 3.247732, D accuracy: 85.5%, cell accuracy: 95.8%, board accuracy: 12.7% \n",
      "\n",
      "test error: \n",
      " D loss: 0.638137, G loss: 6.163366, D accuracy: 85.4%, cell accuracy: 95.0%, board accuracy: 6.5% \n",
      "\n",
      "Epoch 277\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5996, G loss: 5.2618\n",
      "[124/1600] D loss: 0.6405, G loss: 4.1886\n",
      "[244/1600] D loss: 0.4543, G loss: 2.9139\n",
      "[364/1600] D loss: 0.8644, G loss: 2.8218\n",
      "[484/1600] D loss: 0.5639, G loss: 2.5156\n",
      "[604/1600] D loss: 0.4049, G loss: 4.5460\n",
      "[724/1600] D loss: 0.7244, G loss: 2.9279\n",
      "[844/1600] D loss: 0.4616, G loss: 3.3377\n",
      "[964/1600] D loss: 0.5135, G loss: 4.1017\n",
      "[1084/1600] D loss: 0.4353, G loss: 6.1162\n",
      "[1204/1600] D loss: 0.4961, G loss: 6.1396\n",
      "[1324/1600] D loss: 1.1995, G loss: 1.8551\n",
      "[1444/1600] D loss: 0.0443, G loss: 5.2602\n",
      "[1564/1600] D loss: 0.4383, G loss: 3.4055\n",
      "train error: \n",
      " D loss: 0.579876, G loss: 3.108829, D accuracy: 85.4%, cell accuracy: 95.8%, board accuracy: 13.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.614915, G loss: 6.031675, D accuracy: 87.5%, cell accuracy: 95.1%, board accuracy: 7.2% \n",
      "\n",
      "Epoch 278\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.0741, G loss: 4.2469\n",
      "[124/1600] D loss: 0.8351, G loss: 2.9900\n",
      "[244/1600] D loss: 0.4446, G loss: 6.7327\n",
      "[364/1600] D loss: 0.2166, G loss: 6.3550\n",
      "[484/1600] D loss: 0.6544, G loss: 4.9780\n",
      "[604/1600] D loss: 1.0421, G loss: 2.9202\n",
      "[724/1600] D loss: 0.3981, G loss: 4.9254\n",
      "[844/1600] D loss: 0.6495, G loss: 2.3098\n",
      "[964/1600] D loss: 0.7479, G loss: 2.9959\n",
      "[1084/1600] D loss: 0.8655, G loss: 2.9581\n",
      "[1204/1600] D loss: 0.1089, G loss: 5.5083\n",
      "[1324/1600] D loss: 0.7867, G loss: 3.1065\n",
      "[1444/1600] D loss: 0.1949, G loss: 4.7688\n",
      "[1564/1600] D loss: 0.0494, G loss: 4.5758\n",
      "train error: \n",
      " D loss: 0.509696, G loss: 3.689995, D accuracy: 87.4%, cell accuracy: 95.7%, board accuracy: 12.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.633737, G loss: 6.644823, D accuracy: 87.1%, cell accuracy: 94.9%, board accuracy: 7.5% \n",
      "\n",
      "Epoch 279\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.4230, G loss: 1.6518\n",
      "[124/1600] D loss: 0.3226, G loss: 2.2568\n",
      "[244/1600] D loss: 0.1854, G loss: 2.1484\n",
      "[364/1600] D loss: 1.0865, G loss: 0.8027\n",
      "[484/1600] D loss: 0.1311, G loss: 5.0872\n",
      "[604/1600] D loss: 0.3717, G loss: 3.9594\n",
      "[724/1600] D loss: 0.6872, G loss: 4.7884\n",
      "[844/1600] D loss: 0.6806, G loss: 3.2511\n",
      "[964/1600] D loss: 0.0955, G loss: 4.3850\n",
      "[1084/1600] D loss: 0.9937, G loss: 2.6011\n",
      "[1204/1600] D loss: 0.2635, G loss: 3.4091\n",
      "[1324/1600] D loss: 0.7267, G loss: 3.1752\n",
      "[1444/1600] D loss: 0.5855, G loss: 3.9652\n",
      "[1564/1600] D loss: 0.0833, G loss: 4.1457\n",
      "train error: \n",
      " D loss: 0.541100, G loss: 3.398151, D accuracy: 86.3%, cell accuracy: 95.8%, board accuracy: 14.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.688224, G loss: 6.318535, D accuracy: 84.8%, cell accuracy: 95.0%, board accuracy: 7.2% \n",
      "\n",
      "Epoch 280\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.2094, G loss: 3.9594\n",
      "[124/1600] D loss: 1.1453, G loss: 2.1967\n",
      "[244/1600] D loss: 0.9423, G loss: 1.8425\n",
      "[364/1600] D loss: 0.8535, G loss: 3.3920\n",
      "[484/1600] D loss: 1.1687, G loss: 1.1631\n",
      "[604/1600] D loss: 0.8432, G loss: 2.2835\n",
      "[724/1600] D loss: 0.0261, G loss: 7.8629\n",
      "[844/1600] D loss: 0.3806, G loss: 5.8826\n",
      "[964/1600] D loss: 0.1750, G loss: 4.4351\n",
      "[1084/1600] D loss: 0.9808, G loss: 3.1169\n",
      "[1204/1600] D loss: 0.7559, G loss: 3.4249\n",
      "[1324/1600] D loss: 0.3287, G loss: 2.2027\n",
      "[1444/1600] D loss: 0.7636, G loss: 2.0011\n",
      "[1564/1600] D loss: 0.8388, G loss: 2.5849\n",
      "train error: \n",
      " D loss: 0.577407, G loss: 3.473022, D accuracy: 85.3%, cell accuracy: 95.8%, board accuracy: 13.5% \n",
      "\n",
      "test error: \n",
      " D loss: 0.741205, G loss: 6.354721, D accuracy: 83.6%, cell accuracy: 95.1%, board accuracy: 8.0% \n",
      "\n",
      "Epoch 281\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2355, G loss: 1.4963\n",
      "[124/1600] D loss: 0.5358, G loss: 4.4731\n",
      "[244/1600] D loss: 1.1501, G loss: 0.8804\n",
      "[364/1600] D loss: 0.1002, G loss: 4.0924\n",
      "[484/1600] D loss: 0.5093, G loss: 2.9467\n",
      "[604/1600] D loss: 0.6366, G loss: 4.6968\n",
      "[724/1600] D loss: 0.3649, G loss: 2.7519\n",
      "[844/1600] D loss: 0.4303, G loss: 3.7634\n",
      "[964/1600] D loss: 0.8841, G loss: 3.3680\n",
      "[1084/1600] D loss: 0.4184, G loss: 3.5686\n",
      "[1204/1600] D loss: 0.4972, G loss: 2.7425\n",
      "[1324/1600] D loss: 0.4203, G loss: 5.0635\n",
      "[1444/1600] D loss: 0.8439, G loss: 1.6492\n",
      "[1564/1600] D loss: 0.1490, G loss: 3.4105\n",
      "train error: \n",
      " D loss: 0.589646, G loss: 2.949282, D accuracy: 84.7%, cell accuracy: 95.8%, board accuracy: 13.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.560926, G loss: 5.957189, D accuracy: 88.1%, cell accuracy: 95.1%, board accuracy: 7.8% \n",
      "\n",
      "Epoch 282\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.9318, G loss: 4.3731\n",
      "[124/1600] D loss: 0.2499, G loss: 5.5566\n",
      "[244/1600] D loss: 0.4441, G loss: 6.7417\n",
      "[364/1600] D loss: 0.6952, G loss: 1.8236\n",
      "[484/1600] D loss: 0.9645, G loss: 1.6332\n",
      "[604/1600] D loss: 0.7809, G loss: 2.5424\n",
      "[724/1600] D loss: 0.8941, G loss: 3.6321\n",
      "[844/1600] D loss: 0.6463, G loss: 7.4606\n",
      "[964/1600] D loss: 0.8583, G loss: 1.9355\n",
      "[1084/1600] D loss: 0.8650, G loss: 4.0909\n",
      "[1204/1600] D loss: 0.4164, G loss: 4.6060\n",
      "[1324/1600] D loss: 0.7353, G loss: 2.8571\n",
      "[1444/1600] D loss: 0.7804, G loss: 4.1798\n",
      "[1564/1600] D loss: 0.8943, G loss: 3.5755\n",
      "train error: \n",
      " D loss: 0.574581, G loss: 3.058886, D accuracy: 85.2%, cell accuracy: 95.8%, board accuracy: 13.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.596820, G loss: 6.073473, D accuracy: 86.9%, cell accuracy: 95.0%, board accuracy: 7.8% \n",
      "\n",
      "Epoch 283\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.1805, G loss: 4.5710\n",
      "[124/1600] D loss: 0.3405, G loss: 3.2482\n",
      "[244/1600] D loss: 0.3969, G loss: 3.6096\n",
      "[364/1600] D loss: 0.8019, G loss: 5.5798\n",
      "[484/1600] D loss: 0.1902, G loss: 6.7649\n",
      "[604/1600] D loss: 0.4610, G loss: 2.2932\n",
      "[724/1600] D loss: 0.3047, G loss: 4.2554\n",
      "[844/1600] D loss: 0.4540, G loss: 4.0902\n",
      "[964/1600] D loss: 0.0454, G loss: 5.1501\n",
      "[1084/1600] D loss: 0.1643, G loss: 3.8819\n",
      "[1204/1600] D loss: 0.2426, G loss: 2.6045\n",
      "[1324/1600] D loss: 0.4211, G loss: 3.4045\n",
      "[1444/1600] D loss: 0.3188, G loss: 5.2501\n",
      "[1564/1600] D loss: 1.1782, G loss: 3.8523\n",
      "train error: \n",
      " D loss: 0.560695, G loss: 3.143153, D accuracy: 85.9%, cell accuracy: 95.8%, board accuracy: 12.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.601509, G loss: 6.058186, D accuracy: 87.6%, cell accuracy: 95.0%, board accuracy: 7.8% \n",
      "\n",
      "Epoch 284\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.3907, G loss: 4.1013\n",
      "[124/1600] D loss: 0.3361, G loss: 3.6556\n",
      "[244/1600] D loss: 0.9303, G loss: 2.5155\n",
      "[364/1600] D loss: 0.8877, G loss: 2.6986\n",
      "[484/1600] D loss: 0.8584, G loss: 1.4235\n",
      "[604/1600] D loss: 0.0428, G loss: 5.4759\n",
      "[724/1600] D loss: 0.5100, G loss: 5.2130\n",
      "[844/1600] D loss: 0.3404, G loss: 3.4283\n",
      "[964/1600] D loss: 0.2301, G loss: 3.3611\n",
      "[1084/1600] D loss: 0.3980, G loss: 5.0718\n",
      "[1204/1600] D loss: 0.4860, G loss: 9.1994\n",
      "[1324/1600] D loss: 0.5227, G loss: 3.2893\n",
      "[1444/1600] D loss: 0.2545, G loss: 5.3995\n",
      "[1564/1600] D loss: 1.0440, G loss: 1.7113\n",
      "train error: \n",
      " D loss: 0.539517, G loss: 3.565342, D accuracy: 86.1%, cell accuracy: 95.8%, board accuracy: 12.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.677215, G loss: 6.527776, D accuracy: 85.2%, cell accuracy: 95.1%, board accuracy: 7.0% \n",
      "\n",
      "Epoch 285\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8172, G loss: 1.3667\n",
      "[124/1600] D loss: 0.1459, G loss: 5.4245\n",
      "[244/1600] D loss: 1.1593, G loss: 3.8243\n",
      "[364/1600] D loss: 0.1641, G loss: 5.3651\n",
      "[484/1600] D loss: 1.1195, G loss: 2.3621\n",
      "[604/1600] D loss: 1.2201, G loss: 2.1656\n",
      "[724/1600] D loss: 0.4973, G loss: 5.2807\n",
      "[844/1600] D loss: 0.0742, G loss: 5.8973\n",
      "[964/1600] D loss: 0.8133, G loss: 1.4592\n",
      "[1084/1600] D loss: 0.6620, G loss: 4.8401\n",
      "[1204/1600] D loss: 0.2835, G loss: 2.0095\n",
      "[1324/1600] D loss: 0.5176, G loss: 2.8905\n",
      "[1444/1600] D loss: 0.5242, G loss: 4.6432\n",
      "[1564/1600] D loss: 0.5478, G loss: 3.9155\n",
      "train error: \n",
      " D loss: 0.535582, G loss: 3.463693, D accuracy: 86.1%, cell accuracy: 95.8%, board accuracy: 13.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.625899, G loss: 6.455577, D accuracy: 86.4%, cell accuracy: 95.1%, board accuracy: 7.8% \n",
      "\n",
      "Epoch 286\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.3709, G loss: 2.6684\n",
      "[124/1600] D loss: 0.5899, G loss: 1.7921\n",
      "[244/1600] D loss: 0.3798, G loss: 5.2038\n",
      "[364/1600] D loss: 0.8909, G loss: 3.6841\n",
      "[484/1600] D loss: 0.2000, G loss: 3.7799\n",
      "[604/1600] D loss: 1.4328, G loss: 0.9802\n",
      "[724/1600] D loss: 0.5500, G loss: 3.9012\n",
      "[844/1600] D loss: 0.3639, G loss: 4.2011\n",
      "[964/1600] D loss: 0.3916, G loss: 3.0413\n",
      "[1084/1600] D loss: 0.5615, G loss: 5.9163\n",
      "[1204/1600] D loss: 0.7907, G loss: 2.6134\n",
      "[1324/1600] D loss: 0.5660, G loss: 2.0587\n",
      "[1444/1600] D loss: 0.5786, G loss: 4.4842\n",
      "[1564/1600] D loss: 0.4970, G loss: 3.9257\n",
      "train error: \n",
      " D loss: 0.554576, G loss: 3.552003, D accuracy: 85.6%, cell accuracy: 95.8%, board accuracy: 13.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.730994, G loss: 6.555802, D accuracy: 84.4%, cell accuracy: 95.1%, board accuracy: 7.5% \n",
      "\n",
      "Epoch 287\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.2914, G loss: 6.2461\n",
      "[124/1600] D loss: 0.4155, G loss: 2.7544\n",
      "[244/1600] D loss: 0.5725, G loss: 2.5877\n",
      "[364/1600] D loss: 0.4681, G loss: 2.0534\n",
      "[484/1600] D loss: 0.1017, G loss: 4.1352\n",
      "[604/1600] D loss: 0.6523, G loss: 1.9892\n",
      "[724/1600] D loss: 0.2132, G loss: 6.3729\n",
      "[844/1600] D loss: 1.0382, G loss: 1.2454\n",
      "[964/1600] D loss: 0.5432, G loss: 3.4436\n",
      "[1084/1600] D loss: 0.9075, G loss: 1.2443\n",
      "[1204/1600] D loss: 0.4332, G loss: 2.9328\n",
      "[1324/1600] D loss: 0.6289, G loss: 3.1376\n",
      "[1444/1600] D loss: 0.1192, G loss: 4.3453\n",
      "[1564/1600] D loss: 0.8323, G loss: 1.2807\n",
      "train error: \n",
      " D loss: 0.665948, G loss: 2.759988, D accuracy: 83.5%, cell accuracy: 95.8%, board accuracy: 13.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.519961, G loss: 5.596755, D accuracy: 88.1%, cell accuracy: 95.0%, board accuracy: 6.0% \n",
      "\n",
      "Epoch 288\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.0480, G loss: 4.8499\n",
      "[124/1600] D loss: 0.8675, G loss: 2.0103\n",
      "[244/1600] D loss: 0.6487, G loss: 2.3058\n",
      "[364/1600] D loss: 0.3820, G loss: 6.1552\n",
      "[484/1600] D loss: 0.4705, G loss: 3.4661\n",
      "[604/1600] D loss: 0.1816, G loss: 4.7703\n",
      "[724/1600] D loss: 1.4461, G loss: 0.7095\n",
      "[844/1600] D loss: 0.5065, G loss: 1.9273\n",
      "[964/1600] D loss: 0.7311, G loss: 3.1850\n",
      "[1084/1600] D loss: 0.8019, G loss: 1.2495\n",
      "[1204/1600] D loss: 1.5142, G loss: 2.6424\n",
      "[1324/1600] D loss: 0.6950, G loss: 3.9307\n",
      "[1444/1600] D loss: 0.1751, G loss: 4.9039\n",
      "[1564/1600] D loss: 0.2445, G loss: 3.8563\n",
      "train error: \n",
      " D loss: 0.544478, G loss: 3.357004, D accuracy: 85.6%, cell accuracy: 95.8%, board accuracy: 14.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.632062, G loss: 6.256317, D accuracy: 85.1%, cell accuracy: 95.1%, board accuracy: 8.0% \n",
      "\n",
      "Epoch 289\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.2011, G loss: 1.5493\n",
      "[124/1600] D loss: 1.0662, G loss: 4.1811\n",
      "[244/1600] D loss: 0.4030, G loss: 2.9178\n",
      "[364/1600] D loss: 0.0274, G loss: 5.4648\n",
      "[484/1600] D loss: 0.4505, G loss: 2.6449\n",
      "[604/1600] D loss: 0.9811, G loss: 0.8569\n",
      "[724/1600] D loss: 0.5909, G loss: 1.5574\n",
      "[844/1600] D loss: 0.7071, G loss: 1.5298\n",
      "[964/1600] D loss: 0.3057, G loss: 4.6488\n",
      "[1084/1600] D loss: 0.0708, G loss: 4.5356\n",
      "[1204/1600] D loss: 0.8112, G loss: 2.6371\n",
      "[1324/1600] D loss: 0.5618, G loss: 1.7391\n",
      "[1444/1600] D loss: 0.5110, G loss: 2.9244\n",
      "[1564/1600] D loss: 0.4092, G loss: 4.5820\n",
      "train error: \n",
      " D loss: 0.541857, G loss: 3.326310, D accuracy: 86.0%, cell accuracy: 95.9%, board accuracy: 14.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.623683, G loss: 6.311888, D accuracy: 86.0%, cell accuracy: 95.2%, board accuracy: 7.8% \n",
      "\n",
      "Epoch 290\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.0426, G loss: 7.6789\n",
      "[124/1600] D loss: 0.4122, G loss: 3.0551\n",
      "[244/1600] D loss: 0.7400, G loss: 3.0637\n",
      "[364/1600] D loss: 0.6594, G loss: 1.7762\n",
      "[484/1600] D loss: 1.3818, G loss: 1.8664\n",
      "[604/1600] D loss: 0.7512, G loss: 3.2031\n",
      "[724/1600] D loss: 0.0377, G loss: 5.5406\n",
      "[844/1600] D loss: 0.4487, G loss: 3.2125\n",
      "[964/1600] D loss: 0.6025, G loss: 3.2815\n",
      "[1084/1600] D loss: 0.6242, G loss: 4.5922\n",
      "[1204/1600] D loss: 1.3080, G loss: 1.1586\n",
      "[1324/1600] D loss: 0.3698, G loss: 3.9837\n",
      "[1444/1600] D loss: 0.5126, G loss: 2.8308\n",
      "[1564/1600] D loss: 0.0315, G loss: 6.3223\n",
      "train error: \n",
      " D loss: 0.657846, G loss: 4.086064, D accuracy: 83.4%, cell accuracy: 95.9%, board accuracy: 14.6% \n",
      "\n",
      "test error: \n",
      " D loss: 0.900158, G loss: 7.072548, D accuracy: 82.1%, cell accuracy: 95.2%, board accuracy: 7.5% \n",
      "\n",
      "Epoch 291\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.8394, G loss: 2.4295\n",
      "[124/1600] D loss: 0.1092, G loss: 4.8055\n",
      "[244/1600] D loss: 0.6882, G loss: 2.7824\n",
      "[364/1600] D loss: 0.5749, G loss: 2.5870\n",
      "[484/1600] D loss: 0.4835, G loss: 6.1345\n",
      "[604/1600] D loss: 0.3409, G loss: 5.8851\n",
      "[724/1600] D loss: 0.3877, G loss: 2.9885\n",
      "[844/1600] D loss: 0.3200, G loss: 3.6735\n",
      "[964/1600] D loss: 0.3975, G loss: 3.7159\n",
      "[1084/1600] D loss: 0.7976, G loss: 1.2250\n",
      "[1204/1600] D loss: 0.7519, G loss: 2.1694\n",
      "[1324/1600] D loss: 0.5163, G loss: 2.6687\n",
      "[1444/1600] D loss: 0.0951, G loss: 4.0433\n",
      "[1564/1600] D loss: 1.1022, G loss: 1.2697\n",
      "train error: \n",
      " D loss: 0.599773, G loss: 3.013915, D accuracy: 85.3%, cell accuracy: 95.8%, board accuracy: 14.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.607284, G loss: 6.086400, D accuracy: 87.0%, cell accuracy: 95.0%, board accuracy: 7.8% \n",
      "\n",
      "Epoch 292\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5275, G loss: 3.7463\n",
      "[124/1600] D loss: 1.2687, G loss: 1.3653\n",
      "[244/1600] D loss: 0.2533, G loss: 5.4113\n",
      "[364/1600] D loss: 0.3877, G loss: 3.0411\n",
      "[484/1600] D loss: 0.3872, G loss: 4.0559\n",
      "[604/1600] D loss: 0.8462, G loss: 2.7339\n",
      "[724/1600] D loss: 0.4602, G loss: 5.1903\n",
      "[844/1600] D loss: 0.1455, G loss: 6.3070\n",
      "[964/1600] D loss: 1.0067, G loss: 1.1129\n",
      "[1084/1600] D loss: 0.4311, G loss: 2.0598\n",
      "[1204/1600] D loss: 1.1418, G loss: 1.6984\n",
      "[1324/1600] D loss: 0.5752, G loss: 2.2412\n",
      "[1444/1600] D loss: 0.0685, G loss: 5.5074\n",
      "[1564/1600] D loss: 0.6727, G loss: 4.4990\n",
      "train error: \n",
      " D loss: 0.536093, G loss: 3.689385, D accuracy: 86.0%, cell accuracy: 95.8%, board accuracy: 14.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.698523, G loss: 6.900922, D accuracy: 84.9%, cell accuracy: 95.0%, board accuracy: 7.8% \n",
      "\n",
      "Epoch 293\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7955, G loss: 1.0828\n",
      "[124/1600] D loss: 0.7739, G loss: 2.3374\n",
      "[244/1600] D loss: 0.0262, G loss: 3.8899\n",
      "[364/1600] D loss: 0.4673, G loss: 3.6841\n",
      "[484/1600] D loss: 0.1444, G loss: 8.5364\n",
      "[604/1600] D loss: 0.4686, G loss: 5.4980\n",
      "[724/1600] D loss: 0.0348, G loss: 5.9268\n",
      "[844/1600] D loss: 0.0202, G loss: 6.8962\n",
      "[964/1600] D loss: 0.1038, G loss: 7.7108\n",
      "[1084/1600] D loss: 0.4212, G loss: 4.2762\n",
      "[1204/1600] D loss: 0.7892, G loss: 1.4855\n",
      "[1324/1600] D loss: 1.5704, G loss: 0.8109\n",
      "[1444/1600] D loss: 0.9042, G loss: 2.1293\n",
      "[1564/1600] D loss: 0.2537, G loss: 2.9512\n",
      "train error: \n",
      " D loss: 0.539088, G loss: 3.318793, D accuracy: 86.3%, cell accuracy: 95.8%, board accuracy: 15.4% \n",
      "\n",
      "test error: \n",
      " D loss: 0.623816, G loss: 6.582772, D accuracy: 87.1%, cell accuracy: 95.1%, board accuracy: 8.2% \n",
      "\n",
      "Epoch 294\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.7449, G loss: 4.4028\n",
      "[124/1600] D loss: 0.2623, G loss: 3.3655\n",
      "[244/1600] D loss: 0.5650, G loss: 3.7685\n",
      "[364/1600] D loss: 0.6823, G loss: 2.3572\n",
      "[484/1600] D loss: 0.9982, G loss: 2.4173\n",
      "[604/1600] D loss: 0.6650, G loss: 2.4134\n",
      "[724/1600] D loss: 0.5889, G loss: 5.1571\n",
      "[844/1600] D loss: 0.1999, G loss: 4.7160\n",
      "[964/1600] D loss: 1.0448, G loss: 1.9165\n",
      "[1084/1600] D loss: 0.3879, G loss: 3.4816\n",
      "[1204/1600] D loss: 0.3682, G loss: 7.2029\n",
      "[1324/1600] D loss: 1.2921, G loss: 1.5174\n",
      "[1444/1600] D loss: 0.3761, G loss: 2.6235\n",
      "[1564/1600] D loss: 0.4124, G loss: 4.8229\n",
      "train error: \n",
      " D loss: 0.548360, G loss: 3.204788, D accuracy: 86.0%, cell accuracy: 95.8%, board accuracy: 15.1% \n",
      "\n",
      "test error: \n",
      " D loss: 0.584979, G loss: 6.347103, D accuracy: 87.5%, cell accuracy: 95.0%, board accuracy: 9.0% \n",
      "\n",
      "Epoch 295\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.2623, G loss: 4.1108\n",
      "[124/1600] D loss: 0.9036, G loss: 5.4275\n",
      "[244/1600] D loss: 0.1900, G loss: 4.7656\n",
      "[364/1600] D loss: 0.2940, G loss: 4.0099\n",
      "[484/1600] D loss: 0.2873, G loss: 5.2049\n",
      "[604/1600] D loss: 1.0589, G loss: 2.4792\n",
      "[724/1600] D loss: 1.2749, G loss: 0.8307\n",
      "[844/1600] D loss: 0.1686, G loss: 4.9397\n",
      "[964/1600] D loss: 0.0644, G loss: 6.6686\n",
      "[1084/1600] D loss: 0.3620, G loss: 5.3737\n",
      "[1204/1600] D loss: 0.8235, G loss: 1.2428\n",
      "[1324/1600] D loss: 0.8254, G loss: 2.1733\n",
      "[1444/1600] D loss: 0.2629, G loss: 5.0942\n",
      "[1564/1600] D loss: 0.5126, G loss: 1.4732\n",
      "train error: \n",
      " D loss: 0.583365, G loss: 4.236240, D accuracy: 85.3%, cell accuracy: 95.8%, board accuracy: 14.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.813256, G loss: 7.418142, D accuracy: 82.0%, cell accuracy: 95.0%, board accuracy: 8.0% \n",
      "\n",
      "Epoch 296\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.2803, G loss: 5.0615\n",
      "[124/1600] D loss: 0.8029, G loss: 2.8530\n",
      "[244/1600] D loss: 0.3506, G loss: 3.4200\n",
      "[364/1600] D loss: 1.1301, G loss: 2.0529\n",
      "[484/1600] D loss: 1.0198, G loss: 1.5281\n",
      "[604/1600] D loss: 0.9504, G loss: 1.3873\n",
      "[724/1600] D loss: 1.1728, G loss: 1.5048\n",
      "[844/1600] D loss: 0.3576, G loss: 5.4219\n",
      "[964/1600] D loss: 0.9594, G loss: 3.0056\n",
      "[1084/1600] D loss: 0.0521, G loss: 6.1121\n",
      "[1204/1600] D loss: 0.8899, G loss: 2.2587\n",
      "[1324/1600] D loss: 0.6298, G loss: 1.6247\n",
      "[1444/1600] D loss: 1.1183, G loss: 2.5419\n",
      "[1564/1600] D loss: 0.7314, G loss: 2.3680\n",
      "train error: \n",
      " D loss: 0.539292, G loss: 3.539929, D accuracy: 85.9%, cell accuracy: 95.9%, board accuracy: 15.8% \n",
      "\n",
      "test error: \n",
      " D loss: 0.686181, G loss: 6.849905, D accuracy: 85.4%, cell accuracy: 95.1%, board accuracy: 8.8% \n",
      "\n",
      "Epoch 297\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5509, G loss: 3.8705\n",
      "[124/1600] D loss: 0.1006, G loss: 3.7288\n",
      "[244/1600] D loss: 0.5502, G loss: 3.0713\n",
      "[364/1600] D loss: 0.5990, G loss: 7.2626\n",
      "[484/1600] D loss: 0.9079, G loss: 1.5336\n",
      "[604/1600] D loss: 0.0561, G loss: 7.5666\n",
      "[724/1600] D loss: 0.4724, G loss: 4.1630\n",
      "[844/1600] D loss: 0.5186, G loss: 2.7464\n",
      "[964/1600] D loss: 0.9123, G loss: 3.2228\n",
      "[1084/1600] D loss: 0.4165, G loss: 4.3568\n",
      "[1204/1600] D loss: 0.4979, G loss: 3.1567\n",
      "[1324/1600] D loss: 0.8513, G loss: 5.6440\n",
      "[1444/1600] D loss: 1.0468, G loss: 4.0588\n",
      "[1564/1600] D loss: 1.3072, G loss: 1.1050\n",
      "train error: \n",
      " D loss: 0.545784, G loss: 3.515423, D accuracy: 85.8%, cell accuracy: 95.8%, board accuracy: 15.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.722450, G loss: 6.622957, D accuracy: 83.5%, cell accuracy: 95.0%, board accuracy: 8.8% \n",
      "\n",
      "Epoch 298\n",
      "-------------------------------\n",
      "[4/1600] D loss: 1.1913, G loss: 1.1531\n",
      "[124/1600] D loss: 0.1087, G loss: 6.7572\n",
      "[244/1600] D loss: 1.0321, G loss: 3.4966\n",
      "[364/1600] D loss: 0.8669, G loss: 3.0254\n",
      "[484/1600] D loss: 0.3076, G loss: 3.5780\n",
      "[604/1600] D loss: 0.1823, G loss: 4.1347\n",
      "[724/1600] D loss: 0.4204, G loss: 3.5369\n",
      "[844/1600] D loss: 0.6120, G loss: 2.9777\n",
      "[964/1600] D loss: 0.3018, G loss: 3.7772\n",
      "[1084/1600] D loss: 0.0480, G loss: 5.4873\n",
      "[1204/1600] D loss: 0.5849, G loss: 1.8931\n",
      "[1324/1600] D loss: 1.1730, G loss: 0.9429\n",
      "[1444/1600] D loss: 0.0451, G loss: 6.4282\n",
      "[1564/1600] D loss: 0.8176, G loss: 1.6780\n",
      "train error: \n",
      " D loss: 0.542520, G loss: 3.839006, D accuracy: 85.4%, cell accuracy: 95.8%, board accuracy: 15.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.754312, G loss: 7.009873, D accuracy: 83.2%, cell accuracy: 95.1%, board accuracy: 8.2% \n",
      "\n",
      "Epoch 299\n",
      "-------------------------------\n",
      "[4/1600] D loss: 0.5218, G loss: 2.3728\n",
      "[124/1600] D loss: 0.7446, G loss: 1.7364\n",
      "[244/1600] D loss: 0.4372, G loss: 4.5534\n",
      "[364/1600] D loss: 0.4126, G loss: 1.6428\n",
      "[484/1600] D loss: 1.6554, G loss: 0.6287\n",
      "[604/1600] D loss: 0.5299, G loss: 1.9990\n",
      "[724/1600] D loss: 0.7347, G loss: 1.7282\n",
      "[844/1600] D loss: 0.5875, G loss: 3.2906\n",
      "[964/1600] D loss: 1.1633, G loss: 1.6822\n",
      "[1084/1600] D loss: 0.7452, G loss: 3.1604\n",
      "[1204/1600] D loss: 0.1096, G loss: 5.5174\n",
      "[1324/1600] D loss: 0.0869, G loss: 3.5094\n",
      "[1444/1600] D loss: 0.4373, G loss: 3.3693\n",
      "[1564/1600] D loss: 0.7069, G loss: 2.3507\n",
      "train error: \n",
      " D loss: 0.577838, G loss: 3.986805, D accuracy: 84.7%, cell accuracy: 95.8%, board accuracy: 15.2% \n",
      "\n",
      "test error: \n",
      " D loss: 0.821734, G loss: 7.107455, D accuracy: 82.9%, cell accuracy: 95.1%, board accuracy: 8.8% \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "gen = train(gen_factory=lambda: AltGenerator(use_batch_norm=True, leak=0.2), epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stats for event type 'Drop':\n",
      "  Cell accuracy (train): 95.24%\n",
      "  Cell accuracy (test): 94.80%\n",
      "  Board accuracy (train): 14.45%\n",
      "  Board accuracy (test): 0.68%\n",
      "\n",
      "Stats for event type 'Left':\n",
      "  Cell accuracy (train): 96.42%\n",
      "  Cell accuracy (test): 95.63%\n",
      "  Board accuracy (train): 18.18%\n",
      "  Board accuracy (test): 15.15%\n",
      "\n",
      "Stats for event type 'Right':\n",
      "  Cell accuracy (train): 96.20%\n",
      "  Cell accuracy (test): 95.59%\n",
      "  Board accuracy (train): 21.29%\n",
      "  Board accuracy (test): 22.12%\n",
      "\n",
      "Stats for event type 'Rotate':\n",
      "  Cell accuracy (train): 95.74%\n",
      "  Cell accuracy (test): 94.91%\n",
      "  Board accuracy (train): 6.63%\n",
      "  Board accuracy (test): 0.00%\n",
      "\n",
      "Stats for event type 'Insta-drop':\n",
      "  Cell accuracy (train): 96.36%\n",
      "  Cell accuracy (test): 94.02%\n",
      "  Board accuracy (train): 5.48%\n",
      "  Board accuracy (test): 2.63%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cell_accuracies_train = compute_metric_by_event(metrics.CellAccuracy, train_dataloader)\n",
    "cell_accuracies_test = compute_metric_by_event(metrics.CellAccuracy, test_dataloader)\n",
    "board_accuracies_train = compute_metric_by_event(metrics.BoardAccuracy, train_dataloader)\n",
    "board_accuracies_test = compute_metric_by_event(metrics.BoardAccuracy, test_dataloader)\n",
    "\n",
    "for event_type in range(NUM_EVENT_TYPES):\n",
    "    print(f\"Stats for event type '{EVENT_NAMES[event_type]}':\")\n",
    "    print(f\"  Cell accuracy (train): {cell_accuracies_train[event_type]:.2%}\")\n",
    "    print(f\"  Cell accuracy (test): {cell_accuracies_test[event_type]:.2%}\")\n",
    "    print(f\"  Board accuracy (train): {board_accuracies_train[event_type]:.2%}\")\n",
    "    print(f\"  Board accuracy (test): {board_accuracies_test[event_type]:.2%}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from engines import EVENT_NAMES\n",
    "\n",
    "\n",
    "def show_prediction(example):\n",
    "    (b, e), y = example\n",
    "    pred = gen(b.unsqueeze(0), e.unsqueeze(0)).squeeze(0)\n",
    "    b, e, y, pred = b.argmax(0), e.argmax(0), y.argmax(0), pred.argmax(0)\n",
    "\n",
    "    fig, axs = plt.subplots(1, 3)\n",
    "    fig.suptitle(f\"Prediction vs reality\\nEvent = {EVENT_NAMES[e]}\")\n",
    "\n",
    "    for ax in axs:\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.yaxis.set_visible(False)\n",
    "\n",
    "    axs[0].set_title(\"Input\")\n",
    "    axs[1].set_title(\"Predicted\")\n",
    "    axs[2].set_title(\"Reality\")\n",
    "\n",
    "    axs[0].imshow(render_board(b).transpose((1, 2, 0)), vmin=0, vmax=1)\n",
    "    axs[1].imshow(render_board(pred).transpose((1, 2, 0)), vmin=0, vmax=1)\n",
    "    axs[2].imshow(render_board(y).transpose((1, 2, 0)), vmin=0, vmax=1)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing prediction for training example 892\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show a random training prediction vs reality\n",
    "import random\n",
    "\n",
    "idx = random.randrange(len(train_dataset))\n",
    "print(f\"Showing prediction for training example {idx}\")\n",
    "show_prediction(train_dataset[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
