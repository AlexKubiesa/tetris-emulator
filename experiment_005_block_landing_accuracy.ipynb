{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 005\n",
    "\n",
    "In this experiment, we again try to improve the block landing model's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "import shutil\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# If running this from VS Code, launch a TensorBoard session on the folder runs/experiment_005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlockLandingDataset(Dataset):\n",
    "    def __init__(self, path: str):\n",
    "        self.path = path\n",
    "        if not os.path.exists(path):\n",
    "            raise FileNotFoundError()\n",
    "        with os.scandir(self.path) as it:\n",
    "            entry: os.DirEntry = next(iter(it))\n",
    "            _, self.ext = os.path.splitext(entry.name)\n",
    "            self.highest_index = max((int(Path(file.path).stem) for file in it))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.highest_index + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file = os.path.join(self.path, f\"{idx}{self.ext}\")\n",
    "        if not os.path.exists(file):\n",
    "            raise IndexError()\n",
    "        boards = np.load(file)\n",
    "        x = boards[:2] # Just take the first two frames as that's what will be input to the main model\n",
    "        b1 = boards[1] # We can identify a block landing by the fact that a block spawns in the next time step\n",
    "        b2 = boards[2]\n",
    "        y = (np.all(b1[0] == 0) & np.any(b2[0] == 1)).astype(np.float32)\n",
    "        x, y = torch.tensor(x), torch.tensor(y)\n",
    "        return x, y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2, 22, 10]) torch.int32\n",
      "torch.Size([4]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "train_dataset = BlockLandingDataset(os.path.join(\"data\", \"block_landing\", \"train\"))\n",
    "test_dataset = BlockLandingDataset(os.path.join(\"data\", \"block_landing\", \"test\"))\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "x, y = next(iter(train_dataloader))\n",
    "print(x.shape, x.dtype)\n",
    "print(y.shape, y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlockLandingModel(nn.Module):\n",
    "    \"\"\"Predicts whether a block has landed.\n",
    "\n",
    "    Inputs:\n",
    "        x: Tensor of int32 of shape (batch_size, seq_length, height, width). height = 22 and width = 10 are the dimensions of the game\n",
    "           board. seq_length = 2 is the number of game board inputs. The entries should be 0 for empty cells and 1 for blocks.\n",
    "    \n",
    "    Returns: float32 scalar, logit for block landing prediction.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(2, 5, 3)\n",
    "        self.rnn = nn.GRU(5, 5)\n",
    "        self.norm = nn.BatchNorm1d(5)\n",
    "        self.lin = nn.Linear(5, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.one_hot(x.long(), 2) # One-hot encode the two cell classes\n",
    "        x = x.type(torch.float) # Convert to floating-point\n",
    "        x = x.permute((1, 0, 4, 2, 3)) # Move sequence to dimension 0 and channels/classes to dimension 2\n",
    "        x1, x2 = x # Split up the two timesteps so we can apply convolution to them both separately\n",
    "\n",
    "        x1 = F.relu(self.conv(F.pad(x1, (1, 1, 1, 1)))) # Pad height and width (the last 2 dimensions) with zeroes to represent the board boundaries\n",
    "        x1 = F.avg_pool2d(x1, kernel_size=x.shape[-2:]).squeeze(-1).squeeze(-1)\n",
    "\n",
    "        x2 = F.relu(self.conv(F.pad(x2, (1, 1, 1, 1))))\n",
    "        x2 = F.avg_pool2d(x2, kernel_size=x.shape[-2:]).squeeze(-1).squeeze(-1)\n",
    "\n",
    "        x = torch.concat((x1.unsqueeze(0), x2.unsqueeze(0)))\n",
    "        x, rnn_state = self.rnn(x)\n",
    "        x = x[-1] # Just take last predicted state\n",
    "        x = self.norm(x)\n",
    "        logits = self.lin(x).squeeze(-1)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BlockLandingModel(\n",
      "  (conv): Conv2d(2, 5, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (rnn): GRU(5, 5)\n",
      "  (norm): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (lin): Linear(in_features=5, out_features=1, bias=True)\n",
      ")\n",
      "Predicted states: 0.46212175488471985\n"
     ]
    }
   ],
   "source": [
    "model = BlockLandingModel().to(device)\n",
    "print(model)\n",
    "\n",
    "with torch.no_grad():\n",
    "    X, y = next(iter(train_dataloader))\n",
    "    logits = model(X)[0]\n",
    "    preds = F.sigmoid(logits)\n",
    "    print(f\"Predicted states: {preds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    avg_loss = 0.0\n",
    "    correct = 0.0\n",
    "\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Metric calculations\n",
    "        avg_loss += loss.item()\n",
    "        classes = (pred >= 0).type(torch.float)\n",
    "        correct += (classes == y).type(torch.float).mean().item()\n",
    "\n",
    "        if batch % 20 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    \n",
    "    avg_loss /= num_batches\n",
    "    correct /= num_batches\n",
    "    print(f\"Training accuracy: {(100*correct):>0.1f}%\")\n",
    "    return {\n",
    "        \"loss\": avg_loss,\n",
    "        \"acc\": correct,\n",
    "    }\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    \n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            classes = (pred >= 0).type(torch.float)\n",
    "            correct += (classes == y).type(torch.float).mean().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= num_batches\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return {\n",
    "        \"loss\": test_loss,\n",
    "        \"acc\": correct,\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model architecture\n",
    "\n",
    "We'll try out a few simpler variations on the architecture to see if it improves the situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelWithSimpleRnn(nn.Module):\n",
    "    \"\"\"This model has a simple RNN instead of a GRU.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(2, 5, 3)\n",
    "        self.rnn = nn.RNN(5, 5)\n",
    "        self.norm = nn.BatchNorm1d(5)\n",
    "        self.lin = nn.Linear(5, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.one_hot(x.long(), 2) # One-hot encode the two cell classes\n",
    "        x = x.type(torch.float) # Convert to floating-point\n",
    "        x = x.permute((1, 0, 4, 2, 3)) # Move sequence to dimension 0 and channels/classes to dimension 2\n",
    "        x1, x2 = x # Split up the two timesteps so we can apply convolution to them both separately\n",
    "\n",
    "        x1 = F.relu(self.conv(F.pad(x1, (1, 1, 1, 1)))) # Pad height and width (the last 2 dimensions) with zeroes to represent the board boundaries\n",
    "        x1 = F.avg_pool2d(x1, kernel_size=x.shape[-2:]).squeeze(-1).squeeze(-1)\n",
    "\n",
    "        x2 = F.relu(self.conv(F.pad(x2, (1, 1, 1, 1))))\n",
    "        x2 = F.avg_pool2d(x2, kernel_size=x.shape[-2:]).squeeze(-1).squeeze(-1)\n",
    "\n",
    "        x = torch.concat((x1.unsqueeze(0), x2.unsqueeze(0)))\n",
    "        x, rnn_state = self.rnn(x)\n",
    "        x = x[-1] # Just take last predicted state\n",
    "        x = self.norm(x)\n",
    "        logits = self.lin(x).squeeze(-1)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelWithSkinnyGru(nn.Module):\n",
    "    \"\"\"This model has fewer hidden units in the GRU.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(2, 5, 3)\n",
    "        self.rnn = nn.GRU(5, 3)\n",
    "        self.norm = nn.BatchNorm1d(3)\n",
    "        self.lin = nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.one_hot(x.long(), 2) # One-hot encode the two cell classes\n",
    "        x = x.type(torch.float) # Convert to floating-point\n",
    "        x = x.permute((1, 0, 4, 2, 3)) # Move sequence to dimension 0 and channels/classes to dimension 2\n",
    "        x1, x2 = x # Split up the two timesteps so we can apply convolution to them both separately\n",
    "\n",
    "        x1 = F.relu(self.conv(F.pad(x1, (1, 1, 1, 1)))) # Pad height and width (the last 2 dimensions) with zeroes to represent the board boundaries\n",
    "        x1 = F.avg_pool2d(x1, kernel_size=x.shape[-2:]).squeeze(-1).squeeze(-1)\n",
    "\n",
    "        x2 = F.relu(self.conv(F.pad(x2, (1, 1, 1, 1))))\n",
    "        x2 = F.avg_pool2d(x2, kernel_size=x.shape[-2:]).squeeze(-1).squeeze(-1)\n",
    "\n",
    "        x = torch.concat((x1.unsqueeze(0), x2.unsqueeze(0)))\n",
    "        x, rnn_state = self.rnn(x)\n",
    "        x = x[-1] # Just take last predicted state\n",
    "        x = self.norm(x)\n",
    "        logits = self.lin(x).squeeze(-1)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelWithSimpleRnnAndRelu(nn.Module):\n",
    "    \"\"\"This model has a simple RNN instead of a GRU, and the nonlinearity for the RNN is ReLU instead of tanh.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(2, 5, 3)\n",
    "        self.rnn = nn.RNN(5, 5, nonlinearity=\"relu\")\n",
    "        self.norm = nn.BatchNorm1d(5)\n",
    "        self.lin = nn.Linear(5, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.one_hot(x.long(), 2) # One-hot encode the two cell classes\n",
    "        x = x.type(torch.float) # Convert to floating-point\n",
    "        x = x.permute((1, 0, 4, 2, 3)) # Move sequence to dimension 0 and channels/classes to dimension 2\n",
    "        x1, x2 = x # Split up the two timesteps so we can apply convolution to them both separately\n",
    "\n",
    "        x1 = F.relu(self.conv(F.pad(x1, (1, 1, 1, 1)))) # Pad height and width (the last 2 dimensions) with zeroes to represent the board boundaries\n",
    "        x1 = F.avg_pool2d(x1, kernel_size=x.shape[-2:]).squeeze(-1).squeeze(-1)\n",
    "\n",
    "        x2 = F.relu(self.conv(F.pad(x2, (1, 1, 1, 1))))\n",
    "        x2 = F.avg_pool2d(x2, kernel_size=x.shape[-2:]).squeeze(-1).squeeze(-1)\n",
    "\n",
    "        x = torch.concat((x1.unsqueeze(0), x2.unsqueeze(0)))\n",
    "        x, rnn_state = self.rnn(x)\n",
    "        x = x[-1] # Just take last predicted state\n",
    "        x = self.norm(x)\n",
    "        logits = self.lin(x).squeeze(-1)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 'baseline' has 291 parameters.\n",
      "Model 'simple_rnn' has 171 parameters.\n",
      "Model 'skinny_gru' has 195 parameters.\n",
      "Model 'simple_rnn_relu' has 171 parameters.\n",
      "Training model 'baseline'...\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "loss: 0.799639  [    4/  175]\n",
      "loss: 0.671255  [   84/  175]\n",
      "loss: 0.443264  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 0.709964 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.942837  [    4/  175]\n",
      "loss: 0.599771  [   84/  175]\n",
      "loss: 0.522847  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 57.6%, Avg loss: 0.714682 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.476864  [    4/  175]\n",
      "loss: 0.720447  [   84/  175]\n",
      "loss: 0.926171  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 61.4%, Avg loss: 0.690937 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.622770  [    4/  175]\n",
      "loss: 0.894930  [   84/  175]\n",
      "loss: 0.731230  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 0.780070 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.444828  [    4/  175]\n",
      "loss: 0.632115  [   84/  175]\n",
      "loss: 0.521552  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 0.889671 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.648076  [    4/  175]\n",
      "loss: 0.402625  [   84/  175]\n",
      "loss: 0.596689  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 59.8%, Avg loss: 0.767482 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.393113  [    4/  175]\n",
      "loss: 0.679999  [   84/  175]\n",
      "loss: 0.709055  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 0.714964 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.581763  [    4/  175]\n",
      "loss: 0.512888  [   84/  175]\n",
      "loss: 0.681436  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 0.691295 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.537233  [    4/  175]\n",
      "loss: 0.693948  [   84/  175]\n",
      "loss: 0.499400  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 0.834350 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.551619  [    4/  175]\n",
      "loss: 0.649329  [   84/  175]\n",
      "loss: 0.829335  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 5.932350 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.443059  [    4/  175]\n",
      "loss: 0.845779  [   84/  175]\n",
      "loss: 0.876882  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 0.788469 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.804587  [    4/  175]\n",
      "loss: 0.652339  [   84/  175]\n",
      "loss: 0.494649  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 64.4%, Avg loss: 0.679344 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.595122  [    4/  175]\n",
      "loss: 0.680467  [   84/  175]\n",
      "loss: 0.498741  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 0.570097 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.602654  [    4/  175]\n",
      "loss: 0.454193  [   84/  175]\n",
      "loss: 0.864222  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 1.278359 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.353048  [    4/  175]\n",
      "loss: 0.306822  [   84/  175]\n",
      "loss: 0.478155  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.177314 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.544545  [    4/  175]\n",
      "loss: 0.828914  [   84/  175]\n",
      "loss: 0.429748  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 59.1%, Avg loss: 0.603849 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.411873  [    4/  175]\n",
      "loss: 0.431705  [   84/  175]\n",
      "loss: 0.743240  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 5.214712 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.634811  [    4/  175]\n",
      "loss: 0.450197  [   84/  175]\n",
      "loss: 0.498367  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.459240 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.725795  [    4/  175]\n",
      "loss: 0.787826  [   84/  175]\n",
      "loss: 0.530329  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 65.9%, Avg loss: 0.501680 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.385842  [    4/  175]\n",
      "loss: 0.228250  [   84/  175]\n",
      "loss: 0.744036  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 55.3%, Avg loss: 1.028990 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.440644  [    4/  175]\n",
      "loss: 0.414387  [   84/  175]\n",
      "loss: 0.302621  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 69.7%, Avg loss: 0.569152 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.478213  [    4/  175]\n",
      "loss: 0.471894  [   84/  175]\n",
      "loss: 0.522162  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 1.388084 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.388864  [    4/  175]\n",
      "loss: 0.405944  [   84/  175]\n",
      "loss: 0.355046  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 66.7%, Avg loss: 0.672586 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.858794  [    4/  175]\n",
      "loss: 0.489294  [   84/  175]\n",
      "loss: 0.347174  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.352771 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.400682  [    4/  175]\n",
      "loss: 0.264436  [   84/  175]\n",
      "loss: 0.830535  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.346136 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.495611  [    4/  175]\n",
      "loss: 0.227473  [   84/  175]\n",
      "loss: 0.526548  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.365254 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.771294  [    4/  175]\n",
      "loss: 0.401237  [   84/  175]\n",
      "loss: 0.327740  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.358815 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.375242  [    4/  175]\n",
      "loss: 0.423413  [   84/  175]\n",
      "loss: 0.474853  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 4.479859 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.401017  [    4/  175]\n",
      "loss: 0.285264  [   84/  175]\n",
      "loss: 0.412652  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 0.454516 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.331482  [    4/  175]\n",
      "loss: 0.317177  [   84/  175]\n",
      "loss: 0.296771  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 94.7%, Avg loss: 0.281304 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.351499  [    4/  175]\n",
      "loss: 0.245193  [   84/  175]\n",
      "loss: 0.894914  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.065077 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.511747  [    4/  175]\n",
      "loss: 1.012972  [   84/  175]\n",
      "loss: 0.638522  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.254520 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.175622  [    4/  175]\n",
      "loss: 0.209157  [   84/  175]\n",
      "loss: 0.412825  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.311607 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.213374  [    4/  175]\n",
      "loss: 0.343703  [   84/  175]\n",
      "loss: 0.315792  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 52.3%, Avg loss: 18.434536 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.229610  [    4/  175]\n",
      "loss: 0.292868  [   84/  175]\n",
      "loss: 0.268483  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 94.7%, Avg loss: 0.238099 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.788543  [    4/  175]\n",
      "loss: 0.242641  [   84/  175]\n",
      "loss: 0.305442  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.370419 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.266259  [    4/  175]\n",
      "loss: 0.904447  [   84/  175]\n",
      "loss: 0.290845  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 65.2%, Avg loss: 1.078932 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 1.367593  [    4/  175]\n",
      "loss: 0.269879  [   84/  175]\n",
      "loss: 0.486397  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.257932 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.216248  [    4/  175]\n",
      "loss: 0.160390  [   84/  175]\n",
      "loss: 0.268380  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.201900 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.345847  [    4/  175]\n",
      "loss: 0.880499  [   84/  175]\n",
      "loss: 0.242224  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.202239 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.115155  [    4/  175]\n",
      "loss: 0.875317  [   84/  175]\n",
      "loss: 0.330553  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.152509 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.502048  [    4/  175]\n",
      "loss: 0.740272  [   84/  175]\n",
      "loss: 0.776034  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.285625 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.531187  [    4/  175]\n",
      "loss: 0.090463  [   84/  175]\n",
      "loss: 0.232676  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.219214 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.761674  [    4/  175]\n",
      "loss: 0.264820  [   84/  175]\n",
      "loss: 0.407092  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.131782 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.253171  [    4/  175]\n",
      "loss: 0.237523  [   84/  175]\n",
      "loss: 0.085773  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.138909 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.191706  [    4/  175]\n",
      "loss: 0.175914  [   84/  175]\n",
      "loss: 0.199667  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.148521 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.105311  [    4/  175]\n",
      "loss: 0.140091  [   84/  175]\n",
      "loss: 0.070856  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.130843 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.105196  [    4/  175]\n",
      "loss: 0.260196  [   84/  175]\n",
      "loss: 0.250612  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.104138 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.210096  [    4/  175]\n",
      "loss: 0.197873  [   84/  175]\n",
      "loss: 0.331984  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.080196 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.160712  [    4/  175]\n",
      "loss: 0.143562  [   84/  175]\n",
      "loss: 0.149455  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.088449 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.958278  [    4/  175]\n",
      "loss: 0.792995  [   84/  175]\n",
      "loss: 0.066239  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.155005 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.175453  [    4/  175]\n",
      "loss: 0.192756  [   84/  175]\n",
      "loss: 0.183621  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.070498 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.236338  [    4/  175]\n",
      "loss: 0.046806  [   84/  175]\n",
      "loss: 0.040090  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.073355 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.185253  [    4/  175]\n",
      "loss: 0.356365  [   84/  175]\n",
      "loss: 0.146467  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.059356 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.429252  [    4/  175]\n",
      "loss: 0.188611  [   84/  175]\n",
      "loss: 0.041615  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.061952 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.183987  [    4/  175]\n",
      "loss: 0.935407  [   84/  175]\n",
      "loss: 0.191084  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.120594 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.773474  [    4/  175]\n",
      "loss: 0.824947  [   84/  175]\n",
      "loss: 0.164408  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 57.6%, Avg loss: 0.586763 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 1.083157  [    4/  175]\n",
      "loss: 0.107240  [   84/  175]\n",
      "loss: 0.186447  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.058425 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.146227  [    4/  175]\n",
      "loss: 0.139521  [   84/  175]\n",
      "loss: 0.061595  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 57.6%, Avg loss: 0.738932 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.510734  [    4/  175]\n",
      "loss: 0.159968  [   84/  175]\n",
      "loss: 0.781371  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.187183 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.042301  [    4/  175]\n",
      "loss: 0.074280  [   84/  175]\n",
      "loss: 0.047395  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.060358 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.078311  [    4/  175]\n",
      "loss: 0.045817  [   84/  175]\n",
      "loss: 0.189244  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.087089 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.237127  [    4/  175]\n",
      "loss: 0.146868  [   84/  175]\n",
      "loss: 0.038558  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.042021 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.057547  [    4/  175]\n",
      "loss: 0.773564  [   84/  175]\n",
      "loss: 0.031059  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.073636 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.665567  [    4/  175]\n",
      "loss: 0.249975  [   84/  175]\n",
      "loss: 0.097662  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.043446 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.534350  [    4/  175]\n",
      "loss: 0.027142  [   84/  175]\n",
      "loss: 0.123723  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.033122 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.111207  [    4/  175]\n",
      "loss: 0.083382  [   84/  175]\n",
      "loss: 0.823439  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 92.4%, Avg loss: 0.184701 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.990352  [    4/  175]\n",
      "loss: 0.185076  [   84/  175]\n",
      "loss: 0.114694  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.041554 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.139993  [    4/  175]\n",
      "loss: 0.045513  [   84/  175]\n",
      "loss: 0.054257  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.095597 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.812736  [    4/  175]\n",
      "loss: 0.214881  [   84/  175]\n",
      "loss: 0.027703  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.082331 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.106888  [    4/  175]\n",
      "loss: 0.025860  [   84/  175]\n",
      "loss: 0.035403  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.058860 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.141275  [    4/  175]\n",
      "loss: 0.980491  [   84/  175]\n",
      "loss: 0.123170  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.029435 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.027978  [    4/  175]\n",
      "loss: 0.024339  [   84/  175]\n",
      "loss: 0.073895  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.048543 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.160097  [    4/  175]\n",
      "loss: 0.023893  [   84/  175]\n",
      "loss: 0.068307  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.047011 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.022724  [    4/  175]\n",
      "loss: 0.053527  [   84/  175]\n",
      "loss: 0.102894  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.037217 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.871064  [    4/  175]\n",
      "loss: 0.058425  [   84/  175]\n",
      "loss: 0.137741  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 94.7%, Avg loss: 0.107087 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.053729  [    4/  175]\n",
      "loss: 0.401030  [   84/  175]\n",
      "loss: 0.136107  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.137701 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.237507  [    4/  175]\n",
      "loss: 0.672987  [   84/  175]\n",
      "loss: 0.115340  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.215557 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.126369  [    4/  175]\n",
      "loss: 0.979744  [   84/  175]\n",
      "loss: 0.855522  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.083946 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.146300  [    4/  175]\n",
      "loss: 0.034761  [   84/  175]\n",
      "loss: 0.035711  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.029531 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.029372  [    4/  175]\n",
      "loss: 0.075759  [   84/  175]\n",
      "loss: 0.085512  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.047220 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.092371  [    4/  175]\n",
      "loss: 0.028774  [   84/  175]\n",
      "loss: 0.193685  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.044450 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.103414  [    4/  175]\n",
      "loss: 0.173803  [   84/  175]\n",
      "loss: 0.118885  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.038443 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.093590  [    4/  175]\n",
      "loss: 0.115569  [   84/  175]\n",
      "loss: 0.037795  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.055370 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.070624  [    4/  175]\n",
      "loss: 0.892811  [   84/  175]\n",
      "loss: 0.024250  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.056831 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.162241  [    4/  175]\n",
      "loss: 0.215025  [   84/  175]\n",
      "loss: 0.078379  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.096333 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.933288  [    4/  175]\n",
      "loss: 1.011272  [   84/  175]\n",
      "loss: 0.221587  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 2.897599 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.028901  [    4/  175]\n",
      "loss: 0.047516  [   84/  175]\n",
      "loss: 1.173514  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.045668 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.261139  [    4/  175]\n",
      "loss: 0.035305  [   84/  175]\n",
      "loss: 0.401093  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.281767 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.373225  [    4/  175]\n",
      "loss: 0.074931  [   84/  175]\n",
      "loss: 0.105543  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.042864 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.052444  [    4/  175]\n",
      "loss: 0.124228  [   84/  175]\n",
      "loss: 1.030480  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.082949 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.105916  [    4/  175]\n",
      "loss: 0.022229  [   84/  175]\n",
      "loss: 0.011186  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.033152 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.093891  [    4/  175]\n",
      "loss: 0.120140  [   84/  175]\n",
      "loss: 1.113266  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.056902 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.020828  [    4/  175]\n",
      "loss: 0.149326  [   84/  175]\n",
      "loss: 0.879352  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.075800 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.268998  [    4/  175]\n",
      "loss: 1.198390  [   84/  175]\n",
      "loss: 0.944909  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.027085 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.098994  [    4/  175]\n",
      "loss: 0.146859  [   84/  175]\n",
      "loss: 0.131289  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.131988 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.067699  [    4/  175]\n",
      "loss: 0.065268  [   84/  175]\n",
      "loss: 0.208374  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.025895 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.181833  [    4/  175]\n",
      "loss: 0.027093  [   84/  175]\n",
      "loss: 0.240058  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 2.391377 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.020282  [    4/  175]\n",
      "loss: 0.027461  [   84/  175]\n",
      "loss: 0.073685  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.041681 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.034933  [    4/  175]\n",
      "loss: 0.104813  [   84/  175]\n",
      "loss: 0.100314  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.111071 \n",
      "\n",
      "Done!\n",
      "Training model 'simple_rnn'...\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "loss: 0.755025  [    4/  175]\n",
      "loss: 0.505406  [   84/  175]\n",
      "loss: 0.638311  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 0.698370 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.837779  [    4/  175]\n",
      "loss: 0.839230  [   84/  175]\n",
      "loss: 0.725745  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 0.747852 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.692144  [    4/  175]\n",
      "loss: 0.514480  [   84/  175]\n",
      "loss: 0.781415  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 0.630959 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.528502  [    4/  175]\n",
      "loss: 0.447943  [   84/  175]\n",
      "loss: 0.772630  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 1.234581 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.571112  [    4/  175]\n",
      "loss: 0.586342  [   84/  175]\n",
      "loss: 0.805572  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 62.9%, Avg loss: 0.661776 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.440799  [    4/  175]\n",
      "loss: 0.574580  [   84/  175]\n",
      "loss: 0.511021  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.077755 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.653822  [    4/  175]\n",
      "loss: 0.650631  [   84/  175]\n",
      "loss: 0.392615  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 67.4%, Avg loss: 0.751076 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.871871  [    4/  175]\n",
      "loss: 0.353907  [   84/  175]\n",
      "loss: 0.477994  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 64.4%, Avg loss: 0.629655 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.609041  [    4/  175]\n",
      "loss: 0.386112  [   84/  175]\n",
      "loss: 0.612381  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 0.709153 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.491004  [    4/  175]\n",
      "loss: 0.372889  [   84/  175]\n",
      "loss: 0.377353  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 0.508430 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.452119  [    4/  175]\n",
      "loss: 0.406541  [   84/  175]\n",
      "loss: 0.403259  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.720243 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.694403  [    4/  175]\n",
      "loss: 0.942725  [   84/  175]\n",
      "loss: 0.453493  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 59.8%, Avg loss: 0.546791 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.267331  [    4/  175]\n",
      "loss: 0.343514  [   84/  175]\n",
      "loss: 0.288519  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 0.867334 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.705706  [    4/  175]\n",
      "loss: 0.281769  [   84/  175]\n",
      "loss: 0.212612  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 0.728828 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.240766  [    4/  175]\n",
      "loss: 0.267347  [   84/  175]\n",
      "loss: 0.337955  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 65.9%, Avg loss: 0.438009 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.739180  [    4/  175]\n",
      "loss: 0.831395  [   84/  175]\n",
      "loss: 0.614736  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 5.211095 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.320000  [    4/  175]\n",
      "loss: 0.220507  [   84/  175]\n",
      "loss: 0.142636  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 75.8%, Avg loss: 0.377864 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.266916  [    4/  175]\n",
      "loss: 0.124078  [   84/  175]\n",
      "loss: 0.122397  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.203156 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.203701  [    4/  175]\n",
      "loss: 0.126013  [   84/  175]\n",
      "loss: 0.235867  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.117379 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.323904  [    4/  175]\n",
      "loss: 0.228064  [   84/  175]\n",
      "loss: 0.418695  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.216651 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.190000  [    4/  175]\n",
      "loss: 0.393606  [   84/  175]\n",
      "loss: 0.112154  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 49.2%, Avg loss: 0.614298 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.167981  [    4/  175]\n",
      "loss: 0.164873  [   84/  175]\n",
      "loss: 0.177823  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.115278 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.199493  [    4/  175]\n",
      "loss: 0.138223  [   84/  175]\n",
      "loss: 0.165236  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.250963 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.225333  [    4/  175]\n",
      "loss: 0.255974  [   84/  175]\n",
      "loss: 0.361643  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.169359 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.127619  [    4/  175]\n",
      "loss: 0.905943  [   84/  175]\n",
      "loss: 0.210824  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.093806 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.129680  [    4/  175]\n",
      "loss: 0.938487  [   84/  175]\n",
      "loss: 0.118778  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.097433 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.143521  [    4/  175]\n",
      "loss: 0.156727  [   84/  175]\n",
      "loss: 0.093805  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.104923 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.079064  [    4/  175]\n",
      "loss: 0.918529  [   84/  175]\n",
      "loss: 0.538881  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.084993 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.125548  [    4/  175]\n",
      "loss: 0.176025  [   84/  175]\n",
      "loss: 0.158983  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.243908 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.063866  [    4/  175]\n",
      "loss: 0.087458  [   84/  175]\n",
      "loss: 0.041081  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.078880 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.135676  [    4/  175]\n",
      "loss: 0.655217  [   84/  175]\n",
      "loss: 0.157947  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.287166 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.193834  [    4/  175]\n",
      "loss: 0.149843  [   84/  175]\n",
      "loss: 0.154090  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 55.3%, Avg loss: 0.474226 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.148791  [    4/  175]\n",
      "loss: 0.769715  [   84/  175]\n",
      "loss: 0.170933  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.063097 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.704902  [    4/  175]\n",
      "loss: 0.191313  [   84/  175]\n",
      "loss: 0.039238  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.111823 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.146804  [    4/  175]\n",
      "loss: 0.122906  [   84/  175]\n",
      "loss: 0.120998  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.059550 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.078457  [    4/  175]\n",
      "loss: 0.031230  [   84/  175]\n",
      "loss: 0.056144  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.111864 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.168997  [    4/  175]\n",
      "loss: 0.777153  [   84/  175]\n",
      "loss: 0.031755  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.063406 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.031182  [    4/  175]\n",
      "loss: 0.048205  [   84/  175]\n",
      "loss: 0.151130  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.046031 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.137764  [    4/  175]\n",
      "loss: 0.108753  [   84/  175]\n",
      "loss: 0.075758  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.271129 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.100529  [    4/  175]\n",
      "loss: 0.086190  [   84/  175]\n",
      "loss: 0.028343  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.044255 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.109668  [    4/  175]\n",
      "loss: 0.026167  [   84/  175]\n",
      "loss: 0.084959  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 1.286088 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.951209  [    4/  175]\n",
      "loss: 0.796912  [   84/  175]\n",
      "loss: 0.071702  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.109949 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.024916  [    4/  175]\n",
      "loss: 0.100050  [   84/  175]\n",
      "loss: 0.020168  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.092510 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.024646  [    4/  175]\n",
      "loss: 0.045439  [   84/  175]\n",
      "loss: 0.966702  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 51.5%, Avg loss: 0.799100 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.100788  [    4/  175]\n",
      "loss: 0.079574  [   84/  175]\n",
      "loss: 0.026410  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.148663 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.792022  [    4/  175]\n",
      "loss: 0.028952  [   84/  175]\n",
      "loss: 0.094568  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.036265 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.091364  [    4/  175]\n",
      "loss: 0.032110  [   84/  175]\n",
      "loss: 0.087449  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.053968 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.030963  [    4/  175]\n",
      "loss: 0.020917  [   84/  175]\n",
      "loss: 0.024038  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 63.6%, Avg loss: 0.401927 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.021639  [    4/  175]\n",
      "loss: 0.148225  [   84/  175]\n",
      "loss: 1.199705  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 0.511885 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.130766  [    4/  175]\n",
      "loss: 0.149694  [   84/  175]\n",
      "loss: 0.120975  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.045264 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.119323  [    4/  175]\n",
      "loss: 0.074993  [   84/  175]\n",
      "loss: 0.156408  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.116694 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.076036  [    4/  175]\n",
      "loss: 0.016446  [   84/  175]\n",
      "loss: 0.098804  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.558223 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.070656  [    4/  175]\n",
      "loss: 1.124856  [   84/  175]\n",
      "loss: 0.015869  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.030953 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.903681  [    4/  175]\n",
      "loss: 0.032480  [   84/  175]\n",
      "loss: 0.073925  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.047720 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.039766  [    4/  175]\n",
      "loss: 0.040359  [   84/  175]\n",
      "loss: 0.806511  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.072138 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.122080  [    4/  175]\n",
      "loss: 0.076892  [   84/  175]\n",
      "loss: 0.033799  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.034719 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.163585  [    4/  175]\n",
      "loss: 0.060744  [   84/  175]\n",
      "loss: 0.087045  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.050866 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.407021  [    4/  175]\n",
      "loss: 0.027203  [   84/  175]\n",
      "loss: 0.099808  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.037798 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.015499  [    4/  175]\n",
      "loss: 0.016016  [   84/  175]\n",
      "loss: 0.132324  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.020901 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.093583  [    4/  175]\n",
      "loss: 0.067704  [   84/  175]\n",
      "loss: 0.113690  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.023085 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.767099  [    4/  175]\n",
      "loss: 0.797626  [   84/  175]\n",
      "loss: 0.011375  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.018727 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.063993  [    4/  175]\n",
      "loss: 0.059462  [   84/  175]\n",
      "loss: 0.674633  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.019122 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.091873  [    4/  175]\n",
      "loss: 0.104686  [   84/  175]\n",
      "loss: 0.365169  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.018537 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.090044  [    4/  175]\n",
      "loss: 0.772016  [   84/  175]\n",
      "loss: 0.071027  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.225415 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.336656  [    4/  175]\n",
      "loss: 0.207494  [   84/  175]\n",
      "loss: 0.070423  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.023861 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.029081  [    4/  175]\n",
      "loss: 0.050908  [   84/  175]\n",
      "loss: 0.050786  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 2.706529 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.009545  [    4/  175]\n",
      "loss: 0.074807  [   84/  175]\n",
      "loss: 0.085094  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.029852 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.012612  [    4/  175]\n",
      "loss: 0.008177  [   84/  175]\n",
      "loss: 0.126051  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.172224 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.077105  [    4/  175]\n",
      "loss: 0.008152  [   84/  175]\n",
      "loss: 0.031483  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.021131 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.035292  [    4/  175]\n",
      "loss: 0.118970  [   84/  175]\n",
      "loss: 0.069153  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.055441 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.010596  [    4/  175]\n",
      "loss: 0.184936  [   84/  175]\n",
      "loss: 0.011574  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.017043 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.058813  [    4/  175]\n",
      "loss: 0.006227  [   84/  175]\n",
      "loss: 0.049782  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.091930 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.307900  [    4/  175]\n",
      "loss: 0.007957  [   84/  175]\n",
      "loss: 0.263294  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.046981 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.072464  [    4/  175]\n",
      "loss: 0.006580  [   84/  175]\n",
      "loss: 0.081079  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.079531 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.885735  [    4/  175]\n",
      "loss: 0.016233  [   84/  175]\n",
      "loss: 0.118933  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.302031 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.081744  [    4/  175]\n",
      "loss: 0.086881  [   84/  175]\n",
      "loss: 0.092282  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.044855 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.173689  [    4/  175]\n",
      "loss: 0.073639  [   84/  175]\n",
      "loss: 0.009056  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.029808 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.068019  [    4/  175]\n",
      "loss: 0.102579  [   84/  175]\n",
      "loss: 0.065339  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 52.3%, Avg loss: 1.484012 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.850778  [    4/  175]\n",
      "loss: 0.037387  [   84/  175]\n",
      "loss: 0.101885  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.019191 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.064407  [    4/  175]\n",
      "loss: 0.103602  [   84/  175]\n",
      "loss: 0.005570  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.066492 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.052128  [    4/  175]\n",
      "loss: 0.084847  [   84/  175]\n",
      "loss: 0.653938  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.121716 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.051155  [    4/  175]\n",
      "loss: 0.047904  [   84/  175]\n",
      "loss: 0.017520  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.330901 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.562599  [    4/  175]\n",
      "loss: 0.008866  [   84/  175]\n",
      "loss: 0.686276  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.141376 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.007481  [    4/  175]\n",
      "loss: 0.062725  [   84/  175]\n",
      "loss: 0.568315  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 50.8%, Avg loss: 2.870013 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 1.710589  [    4/  175]\n",
      "loss: 0.076568  [   84/  175]\n",
      "loss: 0.009815  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.221489 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.047966  [    4/  175]\n",
      "loss: 0.105879  [   84/  175]\n",
      "loss: 0.073550  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.022665 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.145834  [    4/  175]\n",
      "loss: 0.850618  [   84/  175]\n",
      "loss: 0.168565  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.111684 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.046161  [    4/  175]\n",
      "loss: 0.089873  [   84/  175]\n",
      "loss: 0.072289  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 63.6%, Avg loss: 0.876428 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.230047  [    4/  175]\n",
      "loss: 0.054854  [   84/  175]\n",
      "loss: 0.064581  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008387 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.041864  [    4/  175]\n",
      "loss: 0.795356  [   84/  175]\n",
      "loss: 0.070222  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.165677 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.005321  [    4/  175]\n",
      "loss: 0.064480  [   84/  175]\n",
      "loss: 0.013135  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.028285 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.172563  [    4/  175]\n",
      "loss: 0.062419  [   84/  175]\n",
      "loss: 0.100702  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.146685 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.005390  [    4/  175]\n",
      "loss: 0.129789  [   84/  175]\n",
      "loss: 0.052637  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.047108 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.029992  [    4/  175]\n",
      "loss: 0.076247  [   84/  175]\n",
      "loss: 0.064111  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.009674 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.154398  [    4/  175]\n",
      "loss: 0.043807  [   84/  175]\n",
      "loss: 0.009878  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.011232 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.059429  [    4/  175]\n",
      "loss: 0.007528  [   84/  175]\n",
      "loss: 0.005692  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.119929 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.035299  [    4/  175]\n",
      "loss: 0.007159  [   84/  175]\n",
      "loss: 0.144699  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 65.9%, Avg loss: 0.539603 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.025007  [    4/  175]\n",
      "loss: 0.006172  [   84/  175]\n",
      "loss: 1.414724  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.189308 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.027081  [    4/  175]\n",
      "loss: 0.086091  [   84/  175]\n",
      "loss: 0.842740  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.027785 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 1.007087  [    4/  175]\n",
      "loss: 0.246050  [   84/  175]\n",
      "loss: 0.071967  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 0.765160 \n",
      "\n",
      "Done!\n",
      "Training model 'skinny_gru'...\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "loss: 0.685555  [    4/  175]\n",
      "loss: 0.431678  [   84/  175]\n",
      "loss: 1.008008  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.693403 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.759749  [    4/  175]\n",
      "loss: 0.746386  [   84/  175]\n",
      "loss: 0.624683  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 0.671808 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.680735  [    4/  175]\n",
      "loss: 0.566882  [   84/  175]\n",
      "loss: 0.649336  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 56.8%, Avg loss: 0.675649 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.617257  [    4/  175]\n",
      "loss: 0.726403  [   84/  175]\n",
      "loss: 0.681762  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 55.3%, Avg loss: 0.665539 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.625329  [    4/  175]\n",
      "loss: 0.541176  [   84/  175]\n",
      "loss: 0.605264  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 0.656806 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.817112  [    4/  175]\n",
      "loss: 0.664438  [   84/  175]\n",
      "loss: 0.668590  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 0.656158 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.498855  [    4/  175]\n",
      "loss: 0.674060  [   84/  175]\n",
      "loss: 0.842283  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 59.8%, Avg loss: 0.665767 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.467960  [    4/  175]\n",
      "loss: 0.761401  [   84/  175]\n",
      "loss: 0.532604  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 59.8%, Avg loss: 0.655071 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.475854  [    4/  175]\n",
      "loss: 0.602029  [   84/  175]\n",
      "loss: 0.524782  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 0.647422 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.802756  [    4/  175]\n",
      "loss: 0.700294  [   84/  175]\n",
      "loss: 0.454576  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 56.8%, Avg loss: 0.660125 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.518247  [    4/  175]\n",
      "loss: 0.742471  [   84/  175]\n",
      "loss: 0.790973  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 62.9%, Avg loss: 0.653792 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.523581  [    4/  175]\n",
      "loss: 0.568513  [   84/  175]\n",
      "loss: 0.463073  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 0.639819 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.748054  [    4/  175]\n",
      "loss: 0.477356  [   84/  175]\n",
      "loss: 0.513797  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 62.9%, Avg loss: 0.657843 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.350536  [    4/  175]\n",
      "loss: 0.365308  [   84/  175]\n",
      "loss: 0.603262  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 0.647270 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.566403  [    4/  175]\n",
      "loss: 0.680176  [   84/  175]\n",
      "loss: 0.412719  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 62.9%, Avg loss: 0.643733 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.660528  [    4/  175]\n",
      "loss: 0.453461  [   84/  175]\n",
      "loss: 0.550642  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 61.4%, Avg loss: 0.641489 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.579362  [    4/  175]\n",
      "loss: 0.591505  [   84/  175]\n",
      "loss: 0.918323  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 61.4%, Avg loss: 0.655762 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.444268  [    4/  175]\n",
      "loss: 0.468418  [   84/  175]\n",
      "loss: 0.630261  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 62.1%, Avg loss: 0.644936 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.762745  [    4/  175]\n",
      "loss: 0.980123  [   84/  175]\n",
      "loss: 0.669773  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 57.6%, Avg loss: 0.645374 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.703241  [    4/  175]\n",
      "loss: 0.714148  [   84/  175]\n",
      "loss: 0.792466  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 62.1%, Avg loss: 0.650989 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.797489  [    4/  175]\n",
      "loss: 0.551990  [   84/  175]\n",
      "loss: 0.654542  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 63.6%, Avg loss: 0.636447 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.770088  [    4/  175]\n",
      "loss: 0.518728  [   84/  175]\n",
      "loss: 0.449063  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 62.1%, Avg loss: 0.630492 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.504680  [    4/  175]\n",
      "loss: 0.674678  [   84/  175]\n",
      "loss: 0.492776  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 62.9%, Avg loss: 0.625844 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.570597  [    4/  175]\n",
      "loss: 0.740602  [   84/  175]\n",
      "loss: 0.798738  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 57.6%, Avg loss: 0.616446 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.536607  [    4/  175]\n",
      "loss: 0.466412  [   84/  175]\n",
      "loss: 0.502945  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 63.6%, Avg loss: 0.611549 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.566101  [    4/  175]\n",
      "loss: 0.526994  [   84/  175]\n",
      "loss: 0.442952  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 66.7%, Avg loss: 0.712286 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.775478  [    4/  175]\n",
      "loss: 0.909132  [   84/  175]\n",
      "loss: 0.685761  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 63.6%, Avg loss: 0.586325 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.741224  [    4/  175]\n",
      "loss: 0.731234  [   84/  175]\n",
      "loss: 0.395666  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 1.169742 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.471585  [    4/  175]\n",
      "loss: 0.430275  [   84/  175]\n",
      "loss: 0.357935  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 65.9%, Avg loss: 0.614731 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 1.032753  [    4/  175]\n",
      "loss: 0.708674  [   84/  175]\n",
      "loss: 0.808458  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 0.588451 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.703504  [    4/  175]\n",
      "loss: 0.421234  [   84/  175]\n",
      "loss: 0.360834  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 0.797919 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.704702  [    4/  175]\n",
      "loss: 0.463765  [   84/  175]\n",
      "loss: 0.522044  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.466947 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.412098  [    4/  175]\n",
      "loss: 0.369004  [   84/  175]\n",
      "loss: 0.543945  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 72.0%, Avg loss: 0.451875 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.361570  [    4/  175]\n",
      "loss: 0.389782  [   84/  175]\n",
      "loss: 0.270435  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 62.9%, Avg loss: 0.892431 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.393200  [    4/  175]\n",
      "loss: 0.357055  [   84/  175]\n",
      "loss: 0.171271  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 2.091341 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.438375  [    4/  175]\n",
      "loss: 0.234634  [   84/  175]\n",
      "loss: 0.542989  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.502237 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.304764  [    4/  175]\n",
      "loss: 0.207481  [   84/  175]\n",
      "loss: 0.283762  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 0.640572 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.356455  [    4/  175]\n",
      "loss: 0.777554  [   84/  175]\n",
      "loss: 0.234833  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 0.626783 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.352504  [    4/  175]\n",
      "loss: 0.323493  [   84/  175]\n",
      "loss: 0.863833  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.379899 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.741215  [    4/  175]\n",
      "loss: 0.627854  [   84/  175]\n",
      "loss: 0.201004  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.250686 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.401690  [    4/  175]\n",
      "loss: 0.443451  [   84/  175]\n",
      "loss: 0.798704  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 1.008691 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.164636  [    4/  175]\n",
      "loss: 1.324629  [   84/  175]\n",
      "loss: 0.320293  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.098683 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.262889  [    4/  175]\n",
      "loss: 0.318255  [   84/  175]\n",
      "loss: 0.130286  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.313145 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.330405  [    4/  175]\n",
      "loss: 0.258082  [   84/  175]\n",
      "loss: 0.253791  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 2.036813 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.290985  [    4/  175]\n",
      "loss: 0.257015  [   84/  175]\n",
      "loss: 0.765121  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.174094 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.150816  [    4/  175]\n",
      "loss: 0.249074  [   84/  175]\n",
      "loss: 0.140331  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.215395 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.198746  [    4/  175]\n",
      "loss: 0.255344  [   84/  175]\n",
      "loss: 0.309850  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 56.8%, Avg loss: 0.553916 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.263479  [    4/  175]\n",
      "loss: 0.777571  [   84/  175]\n",
      "loss: 0.821899  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.237079 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.272995  [    4/  175]\n",
      "loss: 0.128603  [   84/  175]\n",
      "loss: 0.202534  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.295109 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.165730  [    4/  175]\n",
      "loss: 1.166648  [   84/  175]\n",
      "loss: 0.202617  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.102219 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.252425  [    4/  175]\n",
      "loss: 0.280543  [   84/  175]\n",
      "loss: 0.815575  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.320638 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.082446  [    4/  175]\n",
      "loss: 0.158731  [   84/  175]\n",
      "loss: 0.514076  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.139887 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.166048  [    4/  175]\n",
      "loss: 0.070573  [   84/  175]\n",
      "loss: 0.060602  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 72.7%, Avg loss: 0.440153 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.072582  [    4/  175]\n",
      "loss: 0.191148  [   84/  175]\n",
      "loss: 0.215884  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 0.512371 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.067254  [    4/  175]\n",
      "loss: 0.224231  [   84/  175]\n",
      "loss: 0.090401  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 2.112293 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.218741  [    4/  175]\n",
      "loss: 0.102446  [   84/  175]\n",
      "loss: 0.161111  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 75.8%, Avg loss: 0.605526 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.807660  [    4/  175]\n",
      "loss: 0.137601  [   84/  175]\n",
      "loss: 0.585221  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.183226 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.116897  [    4/  175]\n",
      "loss: 0.121996  [   84/  175]\n",
      "loss: 0.214579  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.070542 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.094959  [    4/  175]\n",
      "loss: 0.055164  [   84/  175]\n",
      "loss: 0.848243  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.187242 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.134907  [    4/  175]\n",
      "loss: 0.050063  [   84/  175]\n",
      "loss: 0.877446  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.057893 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.173030  [    4/  175]\n",
      "loss: 0.516577  [   84/  175]\n",
      "loss: 0.885100  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 49.2%, Avg loss: 1.147276 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.519060  [    4/  175]\n",
      "loss: 0.542980  [   84/  175]\n",
      "loss: 0.258573  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 3.160692 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.458457  [    4/  175]\n",
      "loss: 0.493553  [   84/  175]\n",
      "loss: 0.756184  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 0.864558 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.256873  [    4/  175]\n",
      "loss: 0.390710  [   84/  175]\n",
      "loss: 0.406926  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.385900 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.265074  [    4/  175]\n",
      "loss: 0.582576  [   84/  175]\n",
      "loss: 0.327451  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 62.9%, Avg loss: 1.058763 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.630844  [    4/  175]\n",
      "loss: 0.274344  [   84/  175]\n",
      "loss: 0.279507  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 1.713346 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.370374  [    4/  175]\n",
      "loss: 0.257360  [   84/  175]\n",
      "loss: 0.098253  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.325229 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.798743  [    4/  175]\n",
      "loss: 0.188944  [   84/  175]\n",
      "loss: 0.200921  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 1.646316 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.175418  [    4/  175]\n",
      "loss: 0.279178  [   84/  175]\n",
      "loss: 0.265102  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 56.8%, Avg loss: 1.089897 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.283720  [    4/  175]\n",
      "loss: 0.269303  [   84/  175]\n",
      "loss: 0.665971  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 72.0%, Avg loss: 0.497582 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.197512  [    4/  175]\n",
      "loss: 1.143525  [   84/  175]\n",
      "loss: 0.310358  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.194323 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.199437  [    4/  175]\n",
      "loss: 0.706614  [   84/  175]\n",
      "loss: 0.473306  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 63.6%, Avg loss: 0.719976 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.244499  [    4/  175]\n",
      "loss: 0.586973  [   84/  175]\n",
      "loss: 0.237148  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 6.204623 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.131253  [    4/  175]\n",
      "loss: 0.799115  [   84/  175]\n",
      "loss: 0.107850  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 1.566324 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.224379  [    4/  175]\n",
      "loss: 0.499956  [   84/  175]\n",
      "loss: 0.071643  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.180893 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.089602  [    4/  175]\n",
      "loss: 0.155691  [   84/  175]\n",
      "loss: 0.230031  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 6.458639 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.035739  [    4/  175]\n",
      "loss: 0.058885  [   84/  175]\n",
      "loss: 0.096793  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 4.562538 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.886663  [    4/  175]\n",
      "loss: 0.069714  [   84/  175]\n",
      "loss: 0.196836  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 1.779142 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.249305  [    4/  175]\n",
      "loss: 0.217674  [   84/  175]\n",
      "loss: 0.168455  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 67.4%, Avg loss: 0.800243 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.059265  [    4/  175]\n",
      "loss: 0.303963  [   84/  175]\n",
      "loss: 0.163437  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 8.618463 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.239168  [    4/  175]\n",
      "loss: 0.086949  [   84/  175]\n",
      "loss: 0.579027  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.225135 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.172294  [    4/  175]\n",
      "loss: 0.069172  [   84/  175]\n",
      "loss: 0.360379  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 1.207568 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.143081  [    4/  175]\n",
      "loss: 0.235187  [   84/  175]\n",
      "loss: 0.243089  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 70.5%, Avg loss: 0.481817 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.190225  [    4/  175]\n",
      "loss: 0.212207  [   84/  175]\n",
      "loss: 0.255249  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 1.810252 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.231182  [    4/  175]\n",
      "loss: 0.577824  [   84/  175]\n",
      "loss: 1.365387  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 4.009821 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.210646  [    4/  175]\n",
      "loss: 0.095807  [   84/  175]\n",
      "loss: 0.158107  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 0.683731 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.318547  [    4/  175]\n",
      "loss: 0.325292  [   84/  175]\n",
      "loss: 0.255618  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 59.8%, Avg loss: 0.716164 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.291771  [    4/  175]\n",
      "loss: 0.197226  [   84/  175]\n",
      "loss: 0.763240  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 72.0%, Avg loss: 0.599358 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.167948  [    4/  175]\n",
      "loss: 0.201921  [   84/  175]\n",
      "loss: 0.054806  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 2.717113 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.037558  [    4/  175]\n",
      "loss: 0.090722  [   84/  175]\n",
      "loss: 0.220037  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 5.330605 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.201119  [    4/  175]\n",
      "loss: 0.280783  [   84/  175]\n",
      "loss: 0.228161  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 1.437699 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.529135  [    4/  175]\n",
      "loss: 0.212734  [   84/  175]\n",
      "loss: 0.073273  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 3.042683 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.090331  [    4/  175]\n",
      "loss: 0.424830  [   84/  175]\n",
      "loss: 0.171806  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.206833 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.158092  [    4/  175]\n",
      "loss: 0.204444  [   84/  175]\n",
      "loss: 0.411286  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.307190 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.044742  [    4/  175]\n",
      "loss: 0.276963  [   84/  175]\n",
      "loss: 0.143022  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 0.623323 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.157799  [    4/  175]\n",
      "loss: 0.924968  [   84/  175]\n",
      "loss: 0.161444  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 0.327456 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.092665  [    4/  175]\n",
      "loss: 0.245559  [   84/  175]\n",
      "loss: 0.183654  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.129427 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.376451  [    4/  175]\n",
      "loss: 0.057793  [   84/  175]\n",
      "loss: 0.650274  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 3.901942 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.077934  [    4/  175]\n",
      "loss: 0.962902  [   84/  175]\n",
      "loss: 0.115287  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.179420 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.073361  [    4/  175]\n",
      "loss: 0.113668  [   84/  175]\n",
      "loss: 0.083750  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 8.225343 \n",
      "\n",
      "Done!\n",
      "Training model 'simple_rnn_relu'...\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "loss: 0.779726  [    4/  175]\n",
      "loss: 0.683992  [   84/  175]\n",
      "loss: 0.674532  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.685095 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.743103  [    4/  175]\n",
      "loss: 0.819590  [   84/  175]\n",
      "loss: 0.634783  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 3.124573 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.791830  [    4/  175]\n",
      "loss: 0.696076  [   84/  175]\n",
      "loss: 0.684371  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 2.145673 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.703461  [    4/  175]\n",
      "loss: 0.628813  [   84/  175]\n",
      "loss: 0.951460  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 2.055669 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.620182  [    4/  175]\n",
      "loss: 0.669228  [   84/  175]\n",
      "loss: 0.712789  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 2.027523 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.469628  [    4/  175]\n",
      "loss: 0.387628  [   84/  175]\n",
      "loss: 0.481662  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 70.5%, Avg loss: 0.561218 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.488549  [    4/  175]\n",
      "loss: 0.544675  [   84/  175]\n",
      "loss: 0.851578  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 1.124760 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.442948  [    4/  175]\n",
      "loss: 0.506276  [   84/  175]\n",
      "loss: 0.488264  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 2.626959 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.761204  [    4/  175]\n",
      "loss: 1.006925  [   84/  175]\n",
      "loss: 0.383046  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.918183 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.078101  [    4/  175]\n",
      "loss: 0.345875  [   84/  175]\n",
      "loss: 0.642670  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 2.431122 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.446332  [    4/  175]\n",
      "loss: 0.907465  [   84/  175]\n",
      "loss: 0.503301  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 1.432169 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.425548  [    4/  175]\n",
      "loss: 0.262642  [   84/  175]\n",
      "loss: 0.380497  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 2.826289 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.421267  [    4/  175]\n",
      "loss: 0.419849  [   84/  175]\n",
      "loss: 0.340679  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 1.117439 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.302611  [    4/  175]\n",
      "loss: 0.262700  [   84/  175]\n",
      "loss: 0.442555  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 52.3%, Avg loss: 0.887807 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.366264  [    4/  175]\n",
      "loss: 0.328542  [   84/  175]\n",
      "loss: 0.258004  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 1.349245 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.375288  [    4/  175]\n",
      "loss: 0.335212  [   84/  175]\n",
      "loss: 0.430505  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.838199 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.211495  [    4/  175]\n",
      "loss: 0.212046  [   84/  175]\n",
      "loss: 0.282569  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 3.190437 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.147435  [    4/  175]\n",
      "loss: 0.199870  [   84/  175]\n",
      "loss: 0.325754  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 57.6%, Avg loss: 0.636307 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.144857  [    4/  175]\n",
      "loss: 0.219759  [   84/  175]\n",
      "loss: 0.148989  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 0.412680 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.176389  [    4/  175]\n",
      "loss: 0.315472  [   84/  175]\n",
      "loss: 0.236574  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 2.966443 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.329595  [    4/  175]\n",
      "loss: 0.119225  [   84/  175]\n",
      "loss: 0.250863  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 0.416027 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.211615  [    4/  175]\n",
      "loss: 0.232011  [   84/  175]\n",
      "loss: 0.288749  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.026564 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.126823  [    4/  175]\n",
      "loss: 0.161803  [   84/  175]\n",
      "loss: 0.098652  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 5.247461 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.279399  [    4/  175]\n",
      "loss: 0.094476  [   84/  175]\n",
      "loss: 0.084762  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 48.5%, Avg loss: 0.764136 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.099315  [    4/  175]\n",
      "loss: 0.796629  [   84/  175]\n",
      "loss: 0.521903  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.252452 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.943073  [    4/  175]\n",
      "loss: 0.064505  [   84/  175]\n",
      "loss: 0.137391  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.336980 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.267930  [    4/  175]\n",
      "loss: 0.068300  [   84/  175]\n",
      "loss: 0.165124  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 49.2%, Avg loss: 0.731107 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.361287  [    4/  175]\n",
      "loss: 0.131753  [   84/  175]\n",
      "loss: 0.055106  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 2.181718 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.054089  [    4/  175]\n",
      "loss: 0.146542  [   84/  175]\n",
      "loss: 0.035913  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.154738 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.150653  [    4/  175]\n",
      "loss: 0.059747  [   84/  175]\n",
      "loss: 0.079359  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.089871 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.036005  [    4/  175]\n",
      "loss: 0.049649  [   84/  175]\n",
      "loss: 0.038214  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.499990 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.043916  [    4/  175]\n",
      "loss: 0.049272  [   84/  175]\n",
      "loss: 0.184073  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 1.560107 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.049852  [    4/  175]\n",
      "loss: 0.034388  [   84/  175]\n",
      "loss: 0.376979  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.084889 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.140070  [    4/  175]\n",
      "loss: 0.207059  [   84/  175]\n",
      "loss: 0.051334  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 70.5%, Avg loss: 0.753085 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.143992  [    4/  175]\n",
      "loss: 0.138478  [   84/  175]\n",
      "loss: 0.055922  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.086215 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 1.127923  [    4/  175]\n",
      "loss: 0.761302  [   84/  175]\n",
      "loss: 0.093335  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.172885 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.073087  [    4/  175]\n",
      "loss: 0.023255  [   84/  175]\n",
      "loss: 0.090347  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.052344 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.965922  [    4/  175]\n",
      "loss: 0.039652  [   84/  175]\n",
      "loss: 0.039041  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.301109 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.079907  [    4/  175]\n",
      "loss: 0.130625  [   84/  175]\n",
      "loss: 0.095459  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.051101 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.028030  [    4/  175]\n",
      "loss: 0.189437  [   84/  175]\n",
      "loss: 0.083311  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.087569 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 1.049643  [    4/  175]\n",
      "loss: 0.156381  [   84/  175]\n",
      "loss: 0.023816  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.115181 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.126796  [    4/  175]\n",
      "loss: 0.090906  [   84/  175]\n",
      "loss: 0.020702  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.042536 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.118300  [    4/  175]\n",
      "loss: 0.024538  [   84/  175]\n",
      "loss: 0.018897  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.094636 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 1.043202  [    4/  175]\n",
      "loss: 0.214255  [   84/  175]\n",
      "loss: 0.104203  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.091476 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.145144  [    4/  175]\n",
      "loss: 0.115849  [   84/  175]\n",
      "loss: 0.095701  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.125527 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.091119  [    4/  175]\n",
      "loss: 0.017491  [   84/  175]\n",
      "loss: 0.077199  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.069313 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.326143  [    4/  175]\n",
      "loss: 0.026278  [   84/  175]\n",
      "loss: 0.026967  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.517760 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.520694  [    4/  175]\n",
      "loss: 0.176799  [   84/  175]\n",
      "loss: 0.035904  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.066377 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.544252  [    4/  175]\n",
      "loss: 0.155280  [   84/  175]\n",
      "loss: 0.016445  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.030719 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.281508  [    4/  175]\n",
      "loss: 1.236645  [   84/  175]\n",
      "loss: 0.084809  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.427919 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.073192  [    4/  175]\n",
      "loss: 1.682835  [   84/  175]\n",
      "loss: 0.191305  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 3.419810 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.024321  [    4/  175]\n",
      "loss: 0.025686  [   84/  175]\n",
      "loss: 0.019614  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.083486 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.024720  [    4/  175]\n",
      "loss: 0.045195  [   84/  175]\n",
      "loss: 0.025670  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 2.619258 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.073884  [    4/  175]\n",
      "loss: 0.085499  [   84/  175]\n",
      "loss: 0.870839  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 2.649485 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.016543  [    4/  175]\n",
      "loss: 0.064519  [   84/  175]\n",
      "loss: 0.093535  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.062229 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.083504  [    4/  175]\n",
      "loss: 0.035062  [   84/  175]\n",
      "loss: 0.123004  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.447071 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.145979  [    4/  175]\n",
      "loss: 0.130483  [   84/  175]\n",
      "loss: 0.014132  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.106155 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.020616  [    4/  175]\n",
      "loss: 1.093608  [   84/  175]\n",
      "loss: 0.130660  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.097753 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.070492  [    4/  175]\n",
      "loss: 0.016867  [   84/  175]\n",
      "loss: 0.010972  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.047163 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.275567  [    4/  175]\n",
      "loss: 0.125369  [   84/  175]\n",
      "loss: 0.337004  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.110196 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.058363  [    4/  175]\n",
      "loss: 0.540179  [   84/  175]\n",
      "loss: 0.075526  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.284241 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.012843  [    4/  175]\n",
      "loss: 0.085709  [   84/  175]\n",
      "loss: 0.019966  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 0.787689 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.107417  [    4/  175]\n",
      "loss: 0.012395  [   84/  175]\n",
      "loss: 0.009692  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.029782 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.049506  [    4/  175]\n",
      "loss: 0.014030  [   84/  175]\n",
      "loss: 0.853769  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.158217 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.114845  [    4/  175]\n",
      "loss: 0.458394  [   84/  175]\n",
      "loss: 0.055293  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.021390 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.068001  [    4/  175]\n",
      "loss: 0.068113  [   84/  175]\n",
      "loss: 0.022256  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.028146 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.015459  [    4/  175]\n",
      "loss: 0.125047  [   84/  175]\n",
      "loss: 0.077958  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.023853 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.061035  [    4/  175]\n",
      "loss: 0.036185  [   84/  175]\n",
      "loss: 0.274903  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.062811 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.082154  [    4/  175]\n",
      "loss: 0.009794  [   84/  175]\n",
      "loss: 0.018495  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 66.7%, Avg loss: 0.640745 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.009032  [    4/  175]\n",
      "loss: 0.428523  [   84/  175]\n",
      "loss: 0.924850  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 1.441168 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.382300  [    4/  175]\n",
      "loss: 0.305454  [   84/  175]\n",
      "loss: 0.815022  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.226357 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.495359  [    4/  175]\n",
      "loss: 0.468661  [   84/  175]\n",
      "loss: 0.303924  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 1.060410 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.759676  [    4/  175]\n",
      "loss: 0.576411  [   84/  175]\n",
      "loss: 0.459429  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.144291 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.279627  [    4/  175]\n",
      "loss: 0.531143  [   84/  175]\n",
      "loss: 0.339214  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 1.415768 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.383204  [    4/  175]\n",
      "loss: 0.865397  [   84/  175]\n",
      "loss: 0.417138  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.371819 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.582728  [    4/  175]\n",
      "loss: 0.888207  [   84/  175]\n",
      "loss: 1.336767  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 2.487181 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.602169  [    4/  175]\n",
      "loss: 0.909389  [   84/  175]\n",
      "loss: 0.342349  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 72.7%, Avg loss: 0.513163 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.391204  [    4/  175]\n",
      "loss: 0.308001  [   84/  175]\n",
      "loss: 0.369219  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.097235 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.387290  [    4/  175]\n",
      "loss: 0.413719  [   84/  175]\n",
      "loss: 0.665796  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 4.382408 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.287474  [    4/  175]\n",
      "loss: 0.197826  [   84/  175]\n",
      "loss: 0.194966  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 2.107642 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.346629  [    4/  175]\n",
      "loss: 0.722116  [   84/  175]\n",
      "loss: 0.134438  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 2.695939 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.984020  [    4/  175]\n",
      "loss: 0.831041  [   84/  175]\n",
      "loss: 0.491403  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 1.419201 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.549143  [    4/  175]\n",
      "loss: 0.457837  [   84/  175]\n",
      "loss: 0.416800  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 0.705687 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.419083  [    4/  175]\n",
      "loss: 0.469127  [   84/  175]\n",
      "loss: 0.265851  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 2.047217 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.397313  [    4/  175]\n",
      "loss: 0.449804  [   84/  175]\n",
      "loss: 0.310904  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.622897 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.246820  [    4/  175]\n",
      "loss: 0.238460  [   84/  175]\n",
      "loss: 0.204749  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.257795 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.292518  [    4/  175]\n",
      "loss: 0.325511  [   84/  175]\n",
      "loss: 0.382333  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.266499 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.796869  [    4/  175]\n",
      "loss: 0.775294  [   84/  175]\n",
      "loss: 0.167668  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 0.422565 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.147262  [    4/  175]\n",
      "loss: 0.564322  [   84/  175]\n",
      "loss: 0.146701  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 65.9%, Avg loss: 0.431078 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.160139  [    4/  175]\n",
      "loss: 0.860074  [   84/  175]\n",
      "loss: 0.179347  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 3.066001 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 1.060966  [    4/  175]\n",
      "loss: 0.227796  [   84/  175]\n",
      "loss: 0.231129  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 4.911957 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.341497  [    4/  175]\n",
      "loss: 0.320654  [   84/  175]\n",
      "loss: 0.196662  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 0.764771 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.097082  [    4/  175]\n",
      "loss: 0.101208  [   84/  175]\n",
      "loss: 0.090839  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.179880 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.896760  [    4/  175]\n",
      "loss: 0.225181  [   84/  175]\n",
      "loss: 0.192069  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 4.549421 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.239565  [    4/  175]\n",
      "loss: 0.255941  [   84/  175]\n",
      "loss: 0.070438  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.122575 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.919087  [    4/  175]\n",
      "loss: 0.073589  [   84/  175]\n",
      "loss: 0.162429  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.372358 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.247580  [    4/  175]\n",
      "loss: 0.840825  [   84/  175]\n",
      "loss: 0.168648  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 2.638765 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.085889  [    4/  175]\n",
      "loss: 0.486815  [   84/  175]\n",
      "loss: 0.067481  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 2.697201 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.825682  [    4/  175]\n",
      "loss: 0.860355  [   84/  175]\n",
      "loss: 0.172855  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.268567 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.091754  [    4/  175]\n",
      "loss: 0.139687  [   84/  175]\n",
      "loss: 0.133765  [  164/  175]\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 0.717199 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-2\n",
    "batch_size = 4\n",
    "epochs = 100\n",
    "\n",
    "models = {\n",
    "    \"baseline\": BlockLandingModel().to(device),\n",
    "    \"simple_rnn\": ModelWithSimpleRnn().to(device),\n",
    "    \"skinny_gru\": ModelWithSkinnyGru().to(device),\n",
    "    \"simple_rnn_relu\": ModelWithSimpleRnnAndRelu().to(device),\n",
    "}\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Model '{name}' has {count_parameters(model)} parameters.\")\n",
    "\n",
    "log_dir = os.path.join(\"runs\", \"experiment_005\")\n",
    "shutil.rmtree(log_dir, ignore_errors=True)\n",
    "\n",
    "for name, model in models.items():\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    print(f\"Training model '{name}'...\")\n",
    "    log_subdir = os.path.join(log_dir, name + \"_\" + datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"))\n",
    "    tb = SummaryWriter(log_subdir)\n",
    "\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t}\\n-------------------------------\")\n",
    "        train_metrics = train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "        test_metrics = test_loop(test_dataloader, model, loss_fn)\n",
    "        tb.add_scalar(\"Loss/train\", train_metrics[\"loss\"], t)\n",
    "        tb.add_scalar(\"Accuracy/train\", train_metrics[\"acc\"], t)\n",
    "        tb.add_scalar(\"Loss/test\", test_metrics[\"loss\"], t)\n",
    "        tb.add_scalar(\"Accuracy/test\", test_metrics[\"acc\"], t)\n",
    "        for name, weight in model.named_parameters():\n",
    "            tb.add_histogram(f\"Weights/{name}\", weight, t)\n",
    "            tb.add_histogram(f\"Gradients/{name}\", weight.grad, t)\n",
    "\n",
    "    tb.close()\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the \"skinny_gru\" model does slightly worse than the baseline, but the \"simple_rnn\" model trains faster and reaches the same accuracy as the baseline. Using ReLU nonlinearity as opposed to tanh in the simple RNN does not improve accuracy but it does make training more unstable, so we'll stick with the default of tanh nonlinearity.\n",
    "\n",
    "All the models seem to plateau in their training, suggesting they are stuck in a local minimum or saddle point."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning rate\n",
    "\n",
    "Let's try reducing the learning rate to see if this helps. We proceed with the simple RNN model because it trains faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with learning rate 0.01...\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "loss: 0.748359  [    4/  175]\n",
      "loss: 0.738353  [   84/  175]\n",
      "loss: 0.738133  [  164/  175]\n",
      "Training accuracy: 59.5%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 0.702984 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.593160  [    4/  175]\n",
      "loss: 0.672623  [   84/  175]\n",
      "loss: 0.837723  [  164/  175]\n",
      "Training accuracy: 61.4%\n",
      "Test Error: \n",
      " Accuracy: 57.6%, Avg loss: 0.671475 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.843340  [    4/  175]\n",
      "loss: 0.871983  [   84/  175]\n",
      "loss: 0.588309  [  164/  175]\n",
      "Training accuracy: 66.7%\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 0.699611 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.456989  [    4/  175]\n",
      "loss: 0.516979  [   84/  175]\n",
      "loss: 0.449448  [  164/  175]\n",
      "Training accuracy: 68.4%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 0.817994 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.653774  [    4/  175]\n",
      "loss: 0.815487  [   84/  175]\n",
      "loss: 0.554173  [  164/  175]\n",
      "Training accuracy: 61.7%\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 0.672039 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.635832  [    4/  175]\n",
      "loss: 0.632327  [   84/  175]\n",
      "loss: 0.625957  [  164/  175]\n",
      "Training accuracy: 67.0%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 0.902817 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.660938  [    4/  175]\n",
      "loss: 0.826160  [   84/  175]\n",
      "loss: 0.642461  [  164/  175]\n",
      "Training accuracy: 63.6%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 0.976079 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.607452  [    4/  175]\n",
      "loss: 0.697032  [   84/  175]\n",
      "loss: 0.653610  [  164/  175]\n",
      "Training accuracy: 73.3%\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.735439 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.517819  [    4/  175]\n",
      "loss: 0.696987  [   84/  175]\n",
      "loss: 0.562878  [  164/  175]\n",
      "Training accuracy: 76.1%\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 0.558764 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.695720  [    4/  175]\n",
      "loss: 0.502032  [   84/  175]\n",
      "loss: 0.427435  [  164/  175]\n",
      "Training accuracy: 77.8%\n",
      "Test Error: \n",
      " Accuracy: 62.9%, Avg loss: 0.603731 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.478709  [    4/  175]\n",
      "loss: 0.669419  [   84/  175]\n",
      "loss: 1.414099  [  164/  175]\n",
      "Training accuracy: 73.3%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 2.143749 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.509410  [    4/  175]\n",
      "loss: 0.658695  [   84/  175]\n",
      "loss: 0.392186  [  164/  175]\n",
      "Training accuracy: 73.7%\n",
      "Test Error: \n",
      " Accuracy: 62.9%, Avg loss: 0.613774 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.836640  [    4/  175]\n",
      "loss: 0.483633  [   84/  175]\n",
      "loss: 0.450833  [  164/  175]\n",
      "Training accuracy: 77.3%\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.441580 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.390326  [    4/  175]\n",
      "loss: 0.673950  [   84/  175]\n",
      "loss: 0.404889  [  164/  175]\n",
      "Training accuracy: 79.7%\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.412085 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.756052  [    4/  175]\n",
      "loss: 0.744750  [   84/  175]\n",
      "loss: 0.507791  [  164/  175]\n",
      "Training accuracy: 79.0%\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.444091 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.229182  [    4/  175]\n",
      "loss: 0.487768  [   84/  175]\n",
      "loss: 0.531073  [  164/  175]\n",
      "Training accuracy: 81.8%\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.407781 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.287227  [    4/  175]\n",
      "loss: 0.736831  [   84/  175]\n",
      "loss: 0.198293  [  164/  175]\n",
      "Training accuracy: 81.8%\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 0.710645 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.219949  [    4/  175]\n",
      "loss: 0.819643  [   84/  175]\n",
      "loss: 0.250600  [  164/  175]\n",
      "Training accuracy: 81.6%\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.304176 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.414256  [    4/  175]\n",
      "loss: 0.951134  [   84/  175]\n",
      "loss: 0.244644  [  164/  175]\n",
      "Training accuracy: 84.1%\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.272370 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.334635  [    4/  175]\n",
      "loss: 0.308820  [   84/  175]\n",
      "loss: 0.141907  [  164/  175]\n",
      "Training accuracy: 86.4%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.247673 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.301310  [    4/  175]\n",
      "loss: 0.366485  [   84/  175]\n",
      "loss: 0.399022  [  164/  175]\n",
      "Training accuracy: 84.7%\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.338396 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.437840  [    4/  175]\n",
      "loss: 0.171813  [   84/  175]\n",
      "loss: 0.151236  [  164/  175]\n",
      "Training accuracy: 84.5%\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.355647 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.722130  [    4/  175]\n",
      "loss: 0.309931  [   84/  175]\n",
      "loss: 0.247052  [  164/  175]\n",
      "Training accuracy: 81.1%\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.400508 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.270992  [    4/  175]\n",
      "loss: 0.201403  [   84/  175]\n",
      "loss: 0.348734  [  164/  175]\n",
      "Training accuracy: 87.5%\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 0.374923 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.162111  [    4/  175]\n",
      "loss: 0.310848  [   84/  175]\n",
      "loss: 0.238543  [  164/  175]\n",
      "Training accuracy: 89.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.144618 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.125593  [    4/  175]\n",
      "loss: 0.211375  [   84/  175]\n",
      "loss: 0.366406  [  164/  175]\n",
      "Training accuracy: 87.7%\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.216532 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.341352  [    4/  175]\n",
      "loss: 0.823936  [   84/  175]\n",
      "loss: 0.200874  [  164/  175]\n",
      "Training accuracy: 85.8%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.147733 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.217403  [    4/  175]\n",
      "loss: 0.286653  [   84/  175]\n",
      "loss: 0.393873  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.123934 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.330298  [    4/  175]\n",
      "loss: 0.295474  [   84/  175]\n",
      "loss: 0.111464  [  164/  175]\n",
      "Training accuracy: 88.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.121025 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.816093  [    4/  175]\n",
      "loss: 0.082723  [   84/  175]\n",
      "loss: 0.271046  [  164/  175]\n",
      "Training accuracy: 89.2%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.256006 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.329611  [    4/  175]\n",
      "loss: 0.079022  [   84/  175]\n",
      "loss: 0.791168  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.197666 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.067848  [    4/  175]\n",
      "loss: 0.248953  [   84/  175]\n",
      "loss: 0.045506  [  164/  175]\n",
      "Training accuracy: 88.1%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.190218 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.478704  [    4/  175]\n",
      "loss: 0.056482  [   84/  175]\n",
      "loss: 0.077576  [  164/  175]\n",
      "Training accuracy: 88.6%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.129871 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.195921  [    4/  175]\n",
      "loss: 0.054817  [   84/  175]\n",
      "loss: 0.190208  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.550299 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.230914  [    4/  175]\n",
      "loss: 0.057603  [   84/  175]\n",
      "loss: 0.040413  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 0.452213 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.124108  [    4/  175]\n",
      "loss: 0.258641  [   84/  175]\n",
      "loss: 0.217477  [  164/  175]\n",
      "Training accuracy: 89.8%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.117895 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.235127  [    4/  175]\n",
      "loss: 0.214619  [   84/  175]\n",
      "loss: 0.196032  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.110729 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.896689  [    4/  175]\n",
      "loss: 0.047748  [   84/  175]\n",
      "loss: 0.045802  [  164/  175]\n",
      "Training accuracy: 89.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.067661 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.153667  [    4/  175]\n",
      "loss: 0.030604  [   84/  175]\n",
      "loss: 0.122243  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.067162 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.095702  [    4/  175]\n",
      "loss: 0.119639  [   84/  175]\n",
      "loss: 0.885979  [  164/  175]\n",
      "Training accuracy: 89.0%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 3.017138 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.028519  [    4/  175]\n",
      "loss: 0.096705  [   84/  175]\n",
      "loss: 0.122552  [  164/  175]\n",
      "Training accuracy: 89.4%\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.078098 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.126839  [    4/  175]\n",
      "loss: 0.418872  [   84/  175]\n",
      "loss: 0.091240  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.057344 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.098561  [    4/  175]\n",
      "loss: 0.729636  [   84/  175]\n",
      "loss: 0.090370  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.047164 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.029690  [    4/  175]\n",
      "loss: 0.284571  [   84/  175]\n",
      "loss: 0.171733  [  164/  175]\n",
      "Training accuracy: 90.0%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.098869 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.046237  [    4/  175]\n",
      "loss: 0.033206  [   84/  175]\n",
      "loss: 0.079227  [  164/  175]\n",
      "Training accuracy: 89.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.045650 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.678697  [    4/  175]\n",
      "loss: 0.305782  [   84/  175]\n",
      "loss: 0.130843  [  164/  175]\n",
      "Training accuracy: 91.1%\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.289891 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.102763  [    4/  175]\n",
      "loss: 0.116920  [   84/  175]\n",
      "loss: 0.224700  [  164/  175]\n",
      "Training accuracy: 88.1%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.110312 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.087747  [    4/  175]\n",
      "loss: 0.109811  [   84/  175]\n",
      "loss: 0.044929  [  164/  175]\n",
      "Training accuracy: 83.3%\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.366868 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.053134  [    4/  175]\n",
      "loss: 0.130941  [   84/  175]\n",
      "loss: 0.141193  [  164/  175]\n",
      "Training accuracy: 90.7%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.097330 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.074228  [    4/  175]\n",
      "loss: 0.087382  [   84/  175]\n",
      "loss: 0.132204  [  164/  175]\n",
      "Training accuracy: 88.1%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.037349 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.157179  [    4/  175]\n",
      "loss: 0.080712  [   84/  175]\n",
      "loss: 0.119055  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.034234 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.033026  [    4/  175]\n",
      "loss: 0.082528  [   84/  175]\n",
      "loss: 1.490690  [  164/  175]\n",
      "Training accuracy: 88.8%\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 2.388909 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.030505  [    4/  175]\n",
      "loss: 0.076051  [   84/  175]\n",
      "loss: 0.097743  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.060439 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.196684  [    4/  175]\n",
      "loss: 0.140921  [   84/  175]\n",
      "loss: 0.073125  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.041083 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.089732  [    4/  175]\n",
      "loss: 0.080964  [   84/  175]\n",
      "loss: 0.077170  [  164/  175]\n",
      "Training accuracy: 91.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.046592 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.059367  [    4/  175]\n",
      "loss: 0.069477  [   84/  175]\n",
      "loss: 0.179376  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.076340 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.138414  [    4/  175]\n",
      "loss: 0.123543  [   84/  175]\n",
      "loss: 0.074352  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.042475 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.771237  [    4/  175]\n",
      "loss: 0.129753  [   84/  175]\n",
      "loss: 0.124939  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.078356 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.023352  [    4/  175]\n",
      "loss: 0.012260  [   84/  175]\n",
      "loss: 0.023580  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.052546 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.071618  [    4/  175]\n",
      "loss: 0.163302  [   84/  175]\n",
      "loss: 0.183764  [  164/  175]\n",
      "Training accuracy: 92.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.042540 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.014926  [    4/  175]\n",
      "loss: 0.072119  [   84/  175]\n",
      "loss: 0.115970  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.026710 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.137491  [    4/  175]\n",
      "loss: 0.018680  [   84/  175]\n",
      "loss: 0.165550  [  164/  175]\n",
      "Training accuracy: 96.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.031887 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.077883  [    4/  175]\n",
      "loss: 0.947770  [   84/  175]\n",
      "loss: 1.269301  [  164/  175]\n",
      "Training accuracy: 92.2%\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 3.476367 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.032499  [    4/  175]\n",
      "loss: 0.077126  [   84/  175]\n",
      "loss: 0.085088  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.030719 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.016953  [    4/  175]\n",
      "loss: 0.066941  [   84/  175]\n",
      "loss: 0.071628  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.019189 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.047248  [    4/  175]\n",
      "loss: 0.055152  [   84/  175]\n",
      "loss: 0.200144  [  164/  175]\n",
      "Training accuracy: 89.4%\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.275966 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.008830  [    4/  175]\n",
      "loss: 0.122786  [   84/  175]\n",
      "loss: 0.065269  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.019554 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.071845  [    4/  175]\n",
      "loss: 0.094233  [   84/  175]\n",
      "loss: 0.009442  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.014329 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.012397  [    4/  175]\n",
      "loss: 0.089646  [   84/  175]\n",
      "loss: 0.019193  [  164/  175]\n",
      "Training accuracy: 98.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.024168 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.022094  [    4/  175]\n",
      "loss: 0.077844  [   84/  175]\n",
      "loss: 0.147630  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.024928 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.349921  [    4/  175]\n",
      "loss: 0.015111  [   84/  175]\n",
      "loss: 0.011077  [  164/  175]\n",
      "Training accuracy: 97.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.025634 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.057320  [    4/  175]\n",
      "loss: 0.009243  [   84/  175]\n",
      "loss: 0.098226  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.026304 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 1.424824  [    4/  175]\n",
      "loss: 0.715390  [   84/  175]\n",
      "loss: 0.084266  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 94.7%, Avg loss: 0.181674 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 1.081784  [    4/  175]\n",
      "loss: 0.092371  [   84/  175]\n",
      "loss: 0.105489  [  164/  175]\n",
      "Training accuracy: 86.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.049145 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.059598  [    4/  175]\n",
      "loss: 0.071491  [   84/  175]\n",
      "loss: 0.898833  [  164/  175]\n",
      "Training accuracy: 93.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.037060 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.104762  [    4/  175]\n",
      "loss: 0.022601  [   84/  175]\n",
      "loss: 0.824947  [  164/  175]\n",
      "Training accuracy: 93.0%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.211453 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.014848  [    4/  175]\n",
      "loss: 0.113414  [   84/  175]\n",
      "loss: 0.013204  [  164/  175]\n",
      "Training accuracy: 97.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.020752 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.771016  [    4/  175]\n",
      "loss: 0.785731  [   84/  175]\n",
      "loss: 0.038757  [  164/  175]\n",
      "Training accuracy: 87.1%\n",
      "Test Error: \n",
      " Accuracy: 50.8%, Avg loss: 0.854671 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.008598  [    4/  175]\n",
      "loss: 0.051921  [   84/  175]\n",
      "loss: 0.009154  [  164/  175]\n",
      "Training accuracy: 89.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.047876 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.163624  [    4/  175]\n",
      "loss: 0.053982  [   84/  175]\n",
      "loss: 0.010001  [  164/  175]\n",
      "Training accuracy: 98.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.024750 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.013277  [    4/  175]\n",
      "loss: 0.059835  [   84/  175]\n",
      "loss: 0.087004  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.046224 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.074791  [    4/  175]\n",
      "loss: 0.008791  [   84/  175]\n",
      "loss: 0.221730  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.015906 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.110432  [    4/  175]\n",
      "loss: 0.217471  [   84/  175]\n",
      "loss: 0.056535  [  164/  175]\n",
      "Training accuracy: 89.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.020575 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.013611  [    4/  175]\n",
      "loss: 0.050774  [   84/  175]\n",
      "loss: 0.012576  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.022264 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.008743  [    4/  175]\n",
      "loss: 0.089943  [   84/  175]\n",
      "loss: 0.804456  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.027237 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.122256  [    4/  175]\n",
      "loss: 0.057198  [   84/  175]\n",
      "loss: 0.043121  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.108842 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.058212  [    4/  175]\n",
      "loss: 0.030062  [   84/  175]\n",
      "loss: 0.074431  [  164/  175]\n",
      "Training accuracy: 93.0%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.107845 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.965269  [    4/  175]\n",
      "loss: 0.010686  [   84/  175]\n",
      "loss: 0.046711  [  164/  175]\n",
      "Training accuracy: 93.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.031697 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.050646  [    4/  175]\n",
      "loss: 0.011309  [   84/  175]\n",
      "loss: 0.908526  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.080945 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.171009  [    4/  175]\n",
      "loss: 0.069684  [   84/  175]\n",
      "loss: 0.818002  [  164/  175]\n",
      "Training accuracy: 95.3%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 2.085006 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.109310  [    4/  175]\n",
      "loss: 0.008021  [   84/  175]\n",
      "loss: 0.039394  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.027800 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.051190  [    4/  175]\n",
      "loss: 0.126886  [   84/  175]\n",
      "loss: 0.032973  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.018268 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.022014  [    4/  175]\n",
      "loss: 0.043796  [   84/  175]\n",
      "loss: 0.195622  [  164/  175]\n",
      "Training accuracy: 95.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.034439 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.915915  [    4/  175]\n",
      "loss: 0.043464  [   84/  175]\n",
      "loss: 0.053017  [  164/  175]\n",
      "Training accuracy: 96.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.016922 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.004346  [    4/  175]\n",
      "loss: 0.129923  [   84/  175]\n",
      "loss: 0.004469  [  164/  175]\n",
      "Training accuracy: 89.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.032675 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.051277  [    4/  175]\n",
      "loss: 0.045616  [   84/  175]\n",
      "loss: 0.085680  [  164/  175]\n",
      "Training accuracy: 90.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.021233 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.008370  [    4/  175]\n",
      "loss: 0.056251  [   84/  175]\n",
      "loss: 0.057721  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.011510 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.041351  [    4/  175]\n",
      "loss: 0.013922  [   84/  175]\n",
      "loss: 0.064544  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.038064 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.023682  [    4/  175]\n",
      "loss: 0.073482  [   84/  175]\n",
      "loss: 0.938286  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.011259 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.773228  [    4/  175]\n",
      "loss: 0.027233  [   84/  175]\n",
      "loss: 0.109116  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.019133 \n",
      "\n",
      "Done!\n",
      "Training model with learning rate 0.007...\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "loss: 0.704032  [    4/  175]\n",
      "loss: 0.704822  [   84/  175]\n",
      "loss: 0.711780  [  164/  175]\n",
      "Training accuracy: 58.9%\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 0.698852 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.746910  [    4/  175]\n",
      "loss: 0.639283  [   84/  175]\n",
      "loss: 0.636418  [  164/  175]\n",
      "Training accuracy: 62.1%\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 0.679175 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.597894  [    4/  175]\n",
      "loss: 0.655112  [   84/  175]\n",
      "loss: 0.695824  [  164/  175]\n",
      "Training accuracy: 60.8%\n",
      "Test Error: \n",
      " Accuracy: 57.6%, Avg loss: 0.671768 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.791171  [    4/  175]\n",
      "loss: 0.472513  [   84/  175]\n",
      "loss: 0.533601  [  164/  175]\n",
      "Training accuracy: 64.8%\n",
      "Test Error: \n",
      " Accuracy: 57.6%, Avg loss: 0.676661 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.649138  [    4/  175]\n",
      "loss: 0.601899  [   84/  175]\n",
      "loss: 0.596757  [  164/  175]\n",
      "Training accuracy: 67.2%\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 0.663913 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.967195  [    4/  175]\n",
      "loss: 0.695304  [   84/  175]\n",
      "loss: 0.525240  [  164/  175]\n",
      "Training accuracy: 66.1%\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 0.669247 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.579402  [    4/  175]\n",
      "loss: 0.475454  [   84/  175]\n",
      "loss: 0.867231  [  164/  175]\n",
      "Training accuracy: 68.0%\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 0.756204 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.504339  [    4/  175]\n",
      "loss: 0.504627  [   84/  175]\n",
      "loss: 0.455529  [  164/  175]\n",
      "Training accuracy: 68.8%\n",
      "Test Error: \n",
      " Accuracy: 59.1%, Avg loss: 0.631945 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.588596  [    4/  175]\n",
      "loss: 0.748916  [   84/  175]\n",
      "loss: 0.748639  [  164/  175]\n",
      "Training accuracy: 69.1%\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 0.611321 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.774346  [    4/  175]\n",
      "loss: 0.511473  [   84/  175]\n",
      "loss: 0.652552  [  164/  175]\n",
      "Training accuracy: 73.9%\n",
      "Test Error: \n",
      " Accuracy: 65.9%, Avg loss: 0.584252 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.477031  [    4/  175]\n",
      "loss: 0.666129  [   84/  175]\n",
      "loss: 0.538233  [  164/  175]\n",
      "Training accuracy: 69.7%\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 0.557371 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.737116  [    4/  175]\n",
      "loss: 0.502144  [   84/  175]\n",
      "loss: 0.784456  [  164/  175]\n",
      "Training accuracy: 77.7%\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 0.587051 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.512141  [    4/  175]\n",
      "loss: 0.530177  [   84/  175]\n",
      "loss: 0.443524  [  164/  175]\n",
      "Training accuracy: 75.6%\n",
      "Test Error: \n",
      " Accuracy: 69.7%, Avg loss: 0.581746 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.488594  [    4/  175]\n",
      "loss: 0.667835  [   84/  175]\n",
      "loss: 0.541597  [  164/  175]\n",
      "Training accuracy: 82.2%\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 0.539990 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.396336  [    4/  175]\n",
      "loss: 0.380113  [   84/  175]\n",
      "loss: 0.432858  [  164/  175]\n",
      "Training accuracy: 80.7%\n",
      "Test Error: \n",
      " Accuracy: 69.7%, Avg loss: 0.595170 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.696063  [    4/  175]\n",
      "loss: 0.415463  [   84/  175]\n",
      "loss: 0.471334  [  164/  175]\n",
      "Training accuracy: 86.4%\n",
      "Test Error: \n",
      " Accuracy: 59.8%, Avg loss: 0.779434 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.346858  [    4/  175]\n",
      "loss: 0.560744  [   84/  175]\n",
      "loss: 0.278070  [  164/  175]\n",
      "Training accuracy: 89.2%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 1.336482 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.403237  [    4/  175]\n",
      "loss: 0.304385  [   84/  175]\n",
      "loss: 0.754758  [  164/  175]\n",
      "Training accuracy: 80.7%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.335770 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.781260  [    4/  175]\n",
      "loss: 0.359885  [   84/  175]\n",
      "loss: 0.475773  [  164/  175]\n",
      "Training accuracy: 89.0%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 0.683625 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.728592  [    4/  175]\n",
      "loss: 0.203832  [   84/  175]\n",
      "loss: 0.411091  [  164/  175]\n",
      "Training accuracy: 89.2%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.328083 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.327149  [    4/  175]\n",
      "loss: 0.274547  [   84/  175]\n",
      "loss: 0.194793  [  164/  175]\n",
      "Training accuracy: 89.8%\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.321070 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.180451  [    4/  175]\n",
      "loss: 0.230476  [   84/  175]\n",
      "loss: 0.301882  [  164/  175]\n",
      "Training accuracy: 88.3%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.241203 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.396292  [    4/  175]\n",
      "loss: 0.439115  [   84/  175]\n",
      "loss: 0.198197  [  164/  175]\n",
      "Training accuracy: 88.3%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.235730 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.141119  [    4/  175]\n",
      "loss: 0.118041  [   84/  175]\n",
      "loss: 0.291175  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.188652 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.307479  [    4/  175]\n",
      "loss: 0.104932  [   84/  175]\n",
      "loss: 0.330846  [  164/  175]\n",
      "Training accuracy: 88.6%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.226890 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.734701  [    4/  175]\n",
      "loss: 0.339488  [   84/  175]\n",
      "loss: 0.220861  [  164/  175]\n",
      "Training accuracy: 84.1%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.159592 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.760040  [    4/  175]\n",
      "loss: 0.094067  [   84/  175]\n",
      "loss: 0.809584  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.273514 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.770518  [    4/  175]\n",
      "loss: 0.106152  [   84/  175]\n",
      "loss: 0.069005  [  164/  175]\n",
      "Training accuracy: 86.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.220245 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.254651  [    4/  175]\n",
      "loss: 0.101227  [   84/  175]\n",
      "loss: 0.752983  [  164/  175]\n",
      "Training accuracy: 95.5%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.150391 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.080540  [    4/  175]\n",
      "loss: 0.066640  [   84/  175]\n",
      "loss: 0.059737  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.453025 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.272471  [    4/  175]\n",
      "loss: 0.208235  [   84/  175]\n",
      "loss: 0.350151  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.122616 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.212312  [    4/  175]\n",
      "loss: 0.201018  [   84/  175]\n",
      "loss: 0.160210  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.098077 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.157128  [    4/  175]\n",
      "loss: 0.195098  [   84/  175]\n",
      "loss: 0.140023  [  164/  175]\n",
      "Training accuracy: 87.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.136242 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.183183  [    4/  175]\n",
      "loss: 0.323762  [   84/  175]\n",
      "loss: 0.227213  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.174488 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.156884  [    4/  175]\n",
      "loss: 0.280181  [   84/  175]\n",
      "loss: 0.966015  [  164/  175]\n",
      "Training accuracy: 88.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.102794 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.218225  [    4/  175]\n",
      "loss: 0.065087  [   84/  175]\n",
      "loss: 0.159983  [  164/  175]\n",
      "Training accuracy: 88.1%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.114816 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.188566  [    4/  175]\n",
      "loss: 0.130882  [   84/  175]\n",
      "loss: 0.229756  [  164/  175]\n",
      "Training accuracy: 93.6%\n",
      "Test Error: \n",
      " Accuracy: 59.1%, Avg loss: 0.473325 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.044322  [    4/  175]\n",
      "loss: 0.272966  [   84/  175]\n",
      "loss: 0.766631  [  164/  175]\n",
      "Training accuracy: 97.7%\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.296740 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.562902  [    4/  175]\n",
      "loss: 0.469388  [   84/  175]\n",
      "loss: 0.123572  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.076656 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.176375  [    4/  175]\n",
      "loss: 0.043605  [   84/  175]\n",
      "loss: 0.031999  [  164/  175]\n",
      "Training accuracy: 91.1%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.063263 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.046328  [    4/  175]\n",
      "loss: 0.098117  [   84/  175]\n",
      "loss: 0.160315  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.065995 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.034874  [    4/  175]\n",
      "loss: 0.152283  [   84/  175]\n",
      "loss: 0.025152  [  164/  175]\n",
      "Training accuracy: 97.5%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 1.002410 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.281961  [    4/  175]\n",
      "loss: 0.906493  [   84/  175]\n",
      "loss: 0.121975  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.096998 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.028905  [    4/  175]\n",
      "loss: 0.039528  [   84/  175]\n",
      "loss: 0.070854  [  164/  175]\n",
      "Training accuracy: 89.8%\n",
      "Test Error: \n",
      " Accuracy: 49.2%, Avg loss: 1.426642 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.255529  [    4/  175]\n",
      "loss: 0.177720  [   84/  175]\n",
      "loss: 0.155042  [  164/  175]\n",
      "Training accuracy: 98.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.067302 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.135250  [    4/  175]\n",
      "loss: 0.158409  [   84/  175]\n",
      "loss: 0.109877  [  164/  175]\n",
      "Training accuracy: 98.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.055120 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.122246  [    4/  175]\n",
      "loss: 0.115490  [   84/  175]\n",
      "loss: 0.093739  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.052737 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.116215  [    4/  175]\n",
      "loss: 0.025230  [   84/  175]\n",
      "loss: 0.050681  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.043480 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.119879  [    4/  175]\n",
      "loss: 0.172308  [   84/  175]\n",
      "loss: 0.094134  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.082447 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.203710  [    4/  175]\n",
      "loss: 0.188392  [   84/  175]\n",
      "loss: 0.304981  [  164/  175]\n",
      "Training accuracy: 91.7%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.076877 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.033484  [    4/  175]\n",
      "loss: 0.089677  [   84/  175]\n",
      "loss: 0.102722  [  164/  175]\n",
      "Training accuracy: 88.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.060592 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.032503  [    4/  175]\n",
      "loss: 0.104905  [   84/  175]\n",
      "loss: 0.120779  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.042774 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.178636  [    4/  175]\n",
      "loss: 0.033773  [   84/  175]\n",
      "loss: 0.174640  [  164/  175]\n",
      "Training accuracy: 95.8%\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 1.135334 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.641757  [    4/  175]\n",
      "loss: 0.022552  [   84/  175]\n",
      "loss: 0.019321  [  164/  175]\n",
      "Training accuracy: 93.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.191809 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.033116  [    4/  175]\n",
      "loss: 0.017158  [   84/  175]\n",
      "loss: 0.164044  [  164/  175]\n",
      "Training accuracy: 99.4%\n",
      "Test Error: \n",
      " Accuracy: 73.5%, Avg loss: 0.367249 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.021871  [    4/  175]\n",
      "loss: 0.084581  [   84/  175]\n",
      "loss: 0.112150  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.033627 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.028398  [    4/  175]\n",
      "loss: 0.020771  [   84/  175]\n",
      "loss: 0.024525  [  164/  175]\n",
      "Training accuracy: 87.9%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.085864 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.016683  [    4/  175]\n",
      "loss: 0.714828  [   84/  175]\n",
      "loss: 0.135627  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.287714 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.100557  [    4/  175]\n",
      "loss: 0.084305  [   84/  175]\n",
      "loss: 0.136424  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.048824 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.092174  [    4/  175]\n",
      "loss: 0.149051  [   84/  175]\n",
      "loss: 0.034270  [  164/  175]\n",
      "Training accuracy: 98.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.037790 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.136656  [    4/  175]\n",
      "loss: 0.053828  [   84/  175]\n",
      "loss: 0.175225  [  164/  175]\n",
      "Training accuracy: 89.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.017849 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.020380  [    4/  175]\n",
      "loss: 0.023621  [   84/  175]\n",
      "loss: 0.097662  [  164/  175]\n",
      "Training accuracy: 94.7%\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.344533 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.071077  [    4/  175]\n",
      "loss: 0.376390  [   84/  175]\n",
      "loss: 0.189565  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.219828 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.070646  [    4/  175]\n",
      "loss: 0.033192  [   84/  175]\n",
      "loss: 0.109099  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.030178 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.022143  [    4/  175]\n",
      "loss: 0.017777  [   84/  175]\n",
      "loss: 0.024987  [  164/  175]\n",
      "Training accuracy: 88.1%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.138266 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.162441  [    4/  175]\n",
      "loss: 0.118547  [   84/  175]\n",
      "loss: 0.930747  [  164/  175]\n",
      "Training accuracy: 94.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.024127 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.078924  [    4/  175]\n",
      "loss: 0.258086  [   84/  175]\n",
      "loss: 0.016854  [  164/  175]\n",
      "Training accuracy: 92.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.034699 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.023284  [    4/  175]\n",
      "loss: 0.140591  [   84/  175]\n",
      "loss: 0.012575  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.034274 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.015647  [    4/  175]\n",
      "loss: 0.014820  [   84/  175]\n",
      "loss: 1.004824  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.025698 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.180021  [    4/  175]\n",
      "loss: 0.132717  [   84/  175]\n",
      "loss: 0.793012  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.030083 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.084194  [    4/  175]\n",
      "loss: 0.831422  [   84/  175]\n",
      "loss: 0.087443  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.076840 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.013924  [    4/  175]\n",
      "loss: 0.120827  [   84/  175]\n",
      "loss: 0.019212  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.045537 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.178875  [    4/  175]\n",
      "loss: 0.634566  [   84/  175]\n",
      "loss: 0.131267  [  164/  175]\n",
      "Training accuracy: 90.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.045149 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.123255  [    4/  175]\n",
      "loss: 0.047868  [   84/  175]\n",
      "loss: 0.074525  [  164/  175]\n",
      "Training accuracy: 88.1%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.022405 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.073073  [    4/  175]\n",
      "loss: 0.061322  [   84/  175]\n",
      "loss: 0.032120  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.028747 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.032714  [    4/  175]\n",
      "loss: 0.094151  [   84/  175]\n",
      "loss: 0.008675  [  164/  175]\n",
      "Training accuracy: 90.7%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.022055 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.143761  [    4/  175]\n",
      "loss: 0.776097  [   84/  175]\n",
      "loss: 0.074754  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.039778 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.016521  [    4/  175]\n",
      "loss: 0.058587  [   84/  175]\n",
      "loss: 0.109936  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.029231 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.064523  [    4/  175]\n",
      "loss: 0.012230  [   84/  175]\n",
      "loss: 0.089480  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.019365 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.011577  [    4/  175]\n",
      "loss: 0.017503  [   84/  175]\n",
      "loss: 0.012786  [  164/  175]\n",
      "Training accuracy: 95.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.030825 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.115595  [    4/  175]\n",
      "loss: 0.023268  [   84/  175]\n",
      "loss: 0.011307  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.019532 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.022737  [    4/  175]\n",
      "loss: 0.016949  [   84/  175]\n",
      "loss: 1.005385  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.023670 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.094804  [    4/  175]\n",
      "loss: 0.064583  [   84/  175]\n",
      "loss: 0.131228  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.017273 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.013780  [    4/  175]\n",
      "loss: 0.007681  [   84/  175]\n",
      "loss: 0.079673  [  164/  175]\n",
      "Training accuracy: 95.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.019320 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.011799  [    4/  175]\n",
      "loss: 0.081383  [   84/  175]\n",
      "loss: 0.076686  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.016437 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.080453  [    4/  175]\n",
      "loss: 0.060932  [   84/  175]\n",
      "loss: 0.009974  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.023935 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.083452  [    4/  175]\n",
      "loss: 0.112986  [   84/  175]\n",
      "loss: 0.091250  [  164/  175]\n",
      "Training accuracy: 89.4%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.073443 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.523305  [    4/  175]\n",
      "loss: 0.812873  [   84/  175]\n",
      "loss: 0.013628  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.018081 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.157794  [    4/  175]\n",
      "loss: 0.745813  [   84/  175]\n",
      "loss: 0.038939  [  164/  175]\n",
      "Training accuracy: 94.9%\n",
      "Test Error: \n",
      " Accuracy: 72.7%, Avg loss: 0.429515 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.061625  [    4/  175]\n",
      "loss: 0.100384  [   84/  175]\n",
      "loss: 0.075512  [  164/  175]\n",
      "Training accuracy: 95.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.017083 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.068392  [    4/  175]\n",
      "loss: 0.130796  [   84/  175]\n",
      "loss: 0.008024  [  164/  175]\n",
      "Training accuracy: 95.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.022287 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.010649  [    4/  175]\n",
      "loss: 0.171727  [   84/  175]\n",
      "loss: 0.023243  [  164/  175]\n",
      "Training accuracy: 91.3%\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 0.525333 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.089170  [    4/  175]\n",
      "loss: 0.016018  [   84/  175]\n",
      "loss: 0.103705  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.018435 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.014975  [    4/  175]\n",
      "loss: 0.061043  [   84/  175]\n",
      "loss: 0.070885  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.019222 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.075861  [    4/  175]\n",
      "loss: 0.010186  [   84/  175]\n",
      "loss: 0.036018  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.026842 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.009226  [    4/  175]\n",
      "loss: 0.009273  [   84/  175]\n",
      "loss: 0.052609  [  164/  175]\n",
      "Training accuracy: 100.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.018121 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.008112  [    4/  175]\n",
      "loss: 0.024129  [   84/  175]\n",
      "loss: 0.060446  [  164/  175]\n",
      "Training accuracy: 97.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.018236 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.067506  [    4/  175]\n",
      "loss: 0.092946  [   84/  175]\n",
      "loss: 0.419317  [  164/  175]\n",
      "Training accuracy: 89.4%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.089967 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.066283  [    4/  175]\n",
      "loss: 0.878793  [   84/  175]\n",
      "loss: 0.096234  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.064627 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.019346  [    4/  175]\n",
      "loss: 0.225186  [   84/  175]\n",
      "loss: 0.012570  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.016682 \n",
      "\n",
      "Done!\n",
      "Training model with learning rate 0.005...\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "loss: 0.674298  [    4/  175]\n",
      "loss: 0.644640  [   84/  175]\n",
      "loss: 0.802608  [  164/  175]\n",
      "Training accuracy: 52.3%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 0.700844 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.619225  [    4/  175]\n",
      "loss: 0.677434  [   84/  175]\n",
      "loss: 0.736311  [  164/  175]\n",
      "Training accuracy: 63.8%\n",
      "Test Error: \n",
      " Accuracy: 59.8%, Avg loss: 0.684422 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.619769  [    4/  175]\n",
      "loss: 0.530663  [   84/  175]\n",
      "loss: 0.632396  [  164/  175]\n",
      "Training accuracy: 62.3%\n",
      "Test Error: \n",
      " Accuracy: 57.6%, Avg loss: 0.687084 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.603585  [    4/  175]\n",
      "loss: 0.554408  [   84/  175]\n",
      "loss: 0.824859  [  164/  175]\n",
      "Training accuracy: 64.0%\n",
      "Test Error: \n",
      " Accuracy: 59.8%, Avg loss: 0.685058 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.764615  [    4/  175]\n",
      "loss: 0.616105  [   84/  175]\n",
      "loss: 0.657108  [  164/  175]\n",
      "Training accuracy: 59.3%\n",
      "Test Error: \n",
      " Accuracy: 57.6%, Avg loss: 0.695380 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.711189  [    4/  175]\n",
      "loss: 0.547450  [   84/  175]\n",
      "loss: 0.450819  [  164/  175]\n",
      "Training accuracy: 68.2%\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 0.680795 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.457340  [    4/  175]\n",
      "loss: 0.471392  [   84/  175]\n",
      "loss: 0.512486  [  164/  175]\n",
      "Training accuracy: 64.8%\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 0.683276 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.667683  [    4/  175]\n",
      "loss: 0.668330  [   84/  175]\n",
      "loss: 0.523789  [  164/  175]\n",
      "Training accuracy: 62.9%\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 0.686148 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.930451  [    4/  175]\n",
      "loss: 0.541118  [   84/  175]\n",
      "loss: 0.814243  [  164/  175]\n",
      "Training accuracy: 63.4%\n",
      "Test Error: \n",
      " Accuracy: 59.1%, Avg loss: 0.697818 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.815919  [    4/  175]\n",
      "loss: 0.503870  [   84/  175]\n",
      "loss: 0.896582  [  164/  175]\n",
      "Training accuracy: 62.3%\n",
      "Test Error: \n",
      " Accuracy: 57.6%, Avg loss: 0.685189 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.540983  [    4/  175]\n",
      "loss: 0.498957  [   84/  175]\n",
      "loss: 0.737472  [  164/  175]\n",
      "Training accuracy: 64.0%\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 0.688132 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.468847  [    4/  175]\n",
      "loss: 0.506931  [   84/  175]\n",
      "loss: 0.940154  [  164/  175]\n",
      "Training accuracy: 69.9%\n",
      "Test Error: \n",
      " Accuracy: 56.8%, Avg loss: 0.696355 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.521745  [    4/  175]\n",
      "loss: 0.930485  [   84/  175]\n",
      "loss: 0.436246  [  164/  175]\n",
      "Training accuracy: 64.0%\n",
      "Test Error: \n",
      " Accuracy: 61.4%, Avg loss: 0.679350 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.731891  [    4/  175]\n",
      "loss: 0.600645  [   84/  175]\n",
      "loss: 0.559497  [  164/  175]\n",
      "Training accuracy: 64.6%\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 0.688380 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.687798  [    4/  175]\n",
      "loss: 0.537034  [   84/  175]\n",
      "loss: 0.704799  [  164/  175]\n",
      "Training accuracy: 65.9%\n",
      "Test Error: \n",
      " Accuracy: 57.6%, Avg loss: 0.686596 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.476108  [    4/  175]\n",
      "loss: 0.781788  [   84/  175]\n",
      "loss: 0.630066  [  164/  175]\n",
      "Training accuracy: 61.9%\n",
      "Test Error: \n",
      " Accuracy: 57.6%, Avg loss: 0.681549 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.493324  [    4/  175]\n",
      "loss: 0.437228  [   84/  175]\n",
      "loss: 0.945070  [  164/  175]\n",
      "Training accuracy: 63.6%\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 0.682778 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.955046  [    4/  175]\n",
      "loss: 0.487133  [   84/  175]\n",
      "loss: 0.519943  [  164/  175]\n",
      "Training accuracy: 64.0%\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 0.715139 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.517376  [    4/  175]\n",
      "loss: 0.580556  [   84/  175]\n",
      "loss: 0.460157  [  164/  175]\n",
      "Training accuracy: 63.4%\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 0.677261 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.525644  [    4/  175]\n",
      "loss: 0.863218  [   84/  175]\n",
      "loss: 0.637703  [  164/  175]\n",
      "Training accuracy: 63.4%\n",
      "Test Error: \n",
      " Accuracy: 57.6%, Avg loss: 0.687565 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.828917  [    4/  175]\n",
      "loss: 0.710259  [   84/  175]\n",
      "loss: 0.739352  [  164/  175]\n",
      "Training accuracy: 65.5%\n",
      "Test Error: \n",
      " Accuracy: 61.4%, Avg loss: 0.687210 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.869939  [    4/  175]\n",
      "loss: 0.630135  [   84/  175]\n",
      "loss: 0.602807  [  164/  175]\n",
      "Training accuracy: 61.2%\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 0.676835 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.978434  [    4/  175]\n",
      "loss: 0.524791  [   84/  175]\n",
      "loss: 0.787939  [  164/  175]\n",
      "Training accuracy: 63.6%\n",
      "Test Error: \n",
      " Accuracy: 59.8%, Avg loss: 0.710184 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.441307  [    4/  175]\n",
      "loss: 0.545927  [   84/  175]\n",
      "loss: 0.712383  [  164/  175]\n",
      "Training accuracy: 67.4%\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 0.759962 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.723612  [    4/  175]\n",
      "loss: 0.853626  [   84/  175]\n",
      "loss: 0.530968  [  164/  175]\n",
      "Training accuracy: 63.6%\n",
      "Test Error: \n",
      " Accuracy: 55.3%, Avg loss: 0.723532 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.710831  [    4/  175]\n",
      "loss: 0.535909  [   84/  175]\n",
      "loss: 0.490447  [  164/  175]\n",
      "Training accuracy: 61.6%\n",
      "Test Error: \n",
      " Accuracy: 57.6%, Avg loss: 0.718495 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.612402  [    4/  175]\n",
      "loss: 0.675991  [   84/  175]\n",
      "loss: 0.807609  [  164/  175]\n",
      "Training accuracy: 64.6%\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 0.757035 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.528057  [    4/  175]\n",
      "loss: 0.437332  [   84/  175]\n",
      "loss: 0.423877  [  164/  175]\n",
      "Training accuracy: 68.6%\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 0.665288 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.730967  [    4/  175]\n",
      "loss: 0.705155  [   84/  175]\n",
      "loss: 0.451859  [  164/  175]\n",
      "Training accuracy: 68.2%\n",
      "Test Error: \n",
      " Accuracy: 55.3%, Avg loss: 0.760366 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.754455  [    4/  175]\n",
      "loss: 0.666115  [   84/  175]\n",
      "loss: 0.511931  [  164/  175]\n",
      "Training accuracy: 63.6%\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.276597 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.573425  [    4/  175]\n",
      "loss: 0.600460  [   84/  175]\n",
      "loss: 0.730717  [  164/  175]\n",
      "Training accuracy: 68.2%\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.938893 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.396340  [    4/  175]\n",
      "loss: 0.518816  [   84/  175]\n",
      "loss: 0.422949  [  164/  175]\n",
      "Training accuracy: 63.6%\n",
      "Test Error: \n",
      " Accuracy: 65.2%, Avg loss: 0.644344 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.648494  [    4/  175]\n",
      "loss: 0.719215  [   84/  175]\n",
      "loss: 0.746673  [  164/  175]\n",
      "Training accuracy: 71.4%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 3.938878 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.515722  [    4/  175]\n",
      "loss: 0.508694  [   84/  175]\n",
      "loss: 0.582765  [  164/  175]\n",
      "Training accuracy: 67.0%\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.285362 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.614109  [    4/  175]\n",
      "loss: 0.536059  [   84/  175]\n",
      "loss: 0.740019  [  164/  175]\n",
      "Training accuracy: 65.2%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 0.988742 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.473829  [    4/  175]\n",
      "loss: 0.652405  [   84/  175]\n",
      "loss: 0.523115  [  164/  175]\n",
      "Training accuracy: 70.5%\n",
      "Test Error: \n",
      " Accuracy: 66.7%, Avg loss: 0.639308 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.564200  [    4/  175]\n",
      "loss: 0.692330  [   84/  175]\n",
      "loss: 0.790407  [  164/  175]\n",
      "Training accuracy: 68.6%\n",
      "Test Error: \n",
      " Accuracy: 52.3%, Avg loss: 1.451622 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.477955  [    4/  175]\n",
      "loss: 0.409854  [   84/  175]\n",
      "loss: 0.499500  [  164/  175]\n",
      "Training accuracy: 73.1%\n",
      "Test Error: \n",
      " Accuracy: 59.8%, Avg loss: 0.618470 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.415447  [    4/  175]\n",
      "loss: 0.679102  [   84/  175]\n",
      "loss: 0.429659  [  164/  175]\n",
      "Training accuracy: 72.2%\n",
      "Test Error: \n",
      " Accuracy: 52.3%, Avg loss: 1.047361 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.386516  [    4/  175]\n",
      "loss: 0.553948  [   84/  175]\n",
      "loss: 0.548561  [  164/  175]\n",
      "Training accuracy: 78.4%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 1.104552 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.590320  [    4/  175]\n",
      "loss: 0.498916  [   84/  175]\n",
      "loss: 0.487409  [  164/  175]\n",
      "Training accuracy: 75.6%\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 1.346398 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.392467  [    4/  175]\n",
      "loss: 0.579159  [   84/  175]\n",
      "loss: 0.474535  [  164/  175]\n",
      "Training accuracy: 80.5%\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 3.291116 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.469998  [    4/  175]\n",
      "loss: 0.361919  [   84/  175]\n",
      "loss: 0.563158  [  164/  175]\n",
      "Training accuracy: 71.2%\n",
      "Test Error: \n",
      " Accuracy: 69.7%, Avg loss: 0.539611 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.720475  [    4/  175]\n",
      "loss: 0.527887  [   84/  175]\n",
      "loss: 0.266831  [  164/  175]\n",
      "Training accuracy: 78.8%\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 1.380672 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.405633  [    4/  175]\n",
      "loss: 0.286370  [   84/  175]\n",
      "loss: 0.473826  [  164/  175]\n",
      "Training accuracy: 83.5%\n",
      "Test Error: \n",
      " Accuracy: 52.3%, Avg loss: 1.745746 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.398274  [    4/  175]\n",
      "loss: 0.394587  [   84/  175]\n",
      "loss: 0.757641  [  164/  175]\n",
      "Training accuracy: 82.2%\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 5.351212 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.557212  [    4/  175]\n",
      "loss: 0.367203  [   84/  175]\n",
      "loss: 0.515939  [  164/  175]\n",
      "Training accuracy: 76.5%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 3.183906 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.318591  [    4/  175]\n",
      "loss: 0.344431  [   84/  175]\n",
      "loss: 0.346468  [  164/  175]\n",
      "Training accuracy: 77.1%\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.977615 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.418938  [    4/  175]\n",
      "loss: 0.925066  [   84/  175]\n",
      "loss: 0.260575  [  164/  175]\n",
      "Training accuracy: 81.1%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.173748 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.325385  [    4/  175]\n",
      "loss: 0.860405  [   84/  175]\n",
      "loss: 0.586943  [  164/  175]\n",
      "Training accuracy: 79.5%\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 1.283115 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.552395  [    4/  175]\n",
      "loss: 0.226227  [   84/  175]\n",
      "loss: 0.241533  [  164/  175]\n",
      "Training accuracy: 86.6%\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.390471 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.299222  [    4/  175]\n",
      "loss: 0.268114  [   84/  175]\n",
      "loss: 0.341678  [  164/  175]\n",
      "Training accuracy: 82.8%\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.362167 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.883817  [    4/  175]\n",
      "loss: 0.512165  [   84/  175]\n",
      "loss: 0.369385  [  164/  175]\n",
      "Training accuracy: 83.0%\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 0.780953 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.447672  [    4/  175]\n",
      "loss: 0.223189  [   84/  175]\n",
      "loss: 0.997208  [  164/  175]\n",
      "Training accuracy: 83.5%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 1.320438 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.293580  [    4/  175]\n",
      "loss: 0.299364  [   84/  175]\n",
      "loss: 0.239453  [  164/  175]\n",
      "Training accuracy: 83.1%\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 2.032913 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.221706  [    4/  175]\n",
      "loss: 0.332819  [   84/  175]\n",
      "loss: 0.358934  [  164/  175]\n",
      "Training accuracy: 89.6%\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 2.139871 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.469042  [    4/  175]\n",
      "loss: 0.951026  [   84/  175]\n",
      "loss: 0.263489  [  164/  175]\n",
      "Training accuracy: 88.1%\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 2.004813 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.120433  [    4/  175]\n",
      "loss: 0.325055  [   84/  175]\n",
      "loss: 0.227666  [  164/  175]\n",
      "Training accuracy: 82.2%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 5.092196 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.279735  [    4/  175]\n",
      "loss: 0.504283  [   84/  175]\n",
      "loss: 0.440246  [  164/  175]\n",
      "Training accuracy: 88.1%\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 0.432863 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.259803  [    4/  175]\n",
      "loss: 0.250451  [   84/  175]\n",
      "loss: 0.157912  [  164/  175]\n",
      "Training accuracy: 91.3%\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 3.758284 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.415035  [    4/  175]\n",
      "loss: 0.170747  [   84/  175]\n",
      "loss: 0.240848  [  164/  175]\n",
      "Training accuracy: 79.0%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 1.433223 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.333213  [    4/  175]\n",
      "loss: 0.380151  [   84/  175]\n",
      "loss: 0.961023  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 51.5%, Avg loss: 0.662970 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.270425  [    4/  175]\n",
      "loss: 0.138199  [   84/  175]\n",
      "loss: 0.222247  [  164/  175]\n",
      "Training accuracy: 90.7%\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 0.407700 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.719448  [    4/  175]\n",
      "loss: 0.290214  [   84/  175]\n",
      "loss: 0.138696  [  164/  175]\n",
      "Training accuracy: 85.2%\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 0.544708 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.283629  [    4/  175]\n",
      "loss: 0.307914  [   84/  175]\n",
      "loss: 0.100721  [  164/  175]\n",
      "Training accuracy: 89.6%\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 6.095892 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.629718  [    4/  175]\n",
      "loss: 0.301394  [   84/  175]\n",
      "loss: 0.207807  [  164/  175]\n",
      "Training accuracy: 84.7%\n",
      "Test Error: \n",
      " Accuracy: 50.8%, Avg loss: 0.768743 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.126497  [    4/  175]\n",
      "loss: 0.094527  [   84/  175]\n",
      "loss: 0.288108  [  164/  175]\n",
      "Training accuracy: 89.0%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 0.897447 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.381548  [    4/  175]\n",
      "loss: 0.265716  [   84/  175]\n",
      "loss: 0.815587  [  164/  175]\n",
      "Training accuracy: 89.2%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 0.719359 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.201968  [    4/  175]\n",
      "loss: 0.770501  [   84/  175]\n",
      "loss: 0.258018  [  164/  175]\n",
      "Training accuracy: 83.9%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 2.811024 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.191828  [    4/  175]\n",
      "loss: 1.232594  [   84/  175]\n",
      "loss: 0.198674  [  164/  175]\n",
      "Training accuracy: 86.6%\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.317492 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 1.118635  [    4/  175]\n",
      "loss: 0.189739  [   84/  175]\n",
      "loss: 0.224224  [  164/  175]\n",
      "Training accuracy: 89.2%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 2.003237 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.216779  [    4/  175]\n",
      "loss: 0.219523  [   84/  175]\n",
      "loss: 0.093928  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 51.5%, Avg loss: 0.913788 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.194911  [    4/  175]\n",
      "loss: 0.383699  [   84/  175]\n",
      "loss: 0.307944  [  164/  175]\n",
      "Training accuracy: 85.0%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 3.089739 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.469334  [    4/  175]\n",
      "loss: 0.229925  [   84/  175]\n",
      "loss: 0.402302  [  164/  175]\n",
      "Training accuracy: 83.0%\n",
      "Test Error: \n",
      " Accuracy: 50.8%, Avg loss: 0.836909 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.195787  [    4/  175]\n",
      "loss: 0.947668  [   84/  175]\n",
      "loss: 0.505342  [  164/  175]\n",
      "Training accuracy: 87.5%\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.295323 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.226713  [    4/  175]\n",
      "loss: 0.202420  [   84/  175]\n",
      "loss: 0.831188  [  164/  175]\n",
      "Training accuracy: 86.4%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 2.476233 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.134162  [    4/  175]\n",
      "loss: 0.728241  [   84/  175]\n",
      "loss: 0.147317  [  164/  175]\n",
      "Training accuracy: 86.4%\n",
      "Test Error: \n",
      " Accuracy: 94.7%, Avg loss: 0.290704 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.085297  [    4/  175]\n",
      "loss: 0.619562  [   84/  175]\n",
      "loss: 0.468866  [  164/  175]\n",
      "Training accuracy: 87.5%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 2.751688 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.550048  [    4/  175]\n",
      "loss: 0.082260  [   84/  175]\n",
      "loss: 0.345902  [  164/  175]\n",
      "Training accuracy: 89.8%\n",
      "Test Error: \n",
      " Accuracy: 62.1%, Avg loss: 0.684149 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 1.018921  [    4/  175]\n",
      "loss: 0.189316  [   84/  175]\n",
      "loss: 0.301013  [  164/  175]\n",
      "Training accuracy: 88.6%\n",
      "Test Error: \n",
      " Accuracy: 48.5%, Avg loss: 1.388476 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.269561  [    4/  175]\n",
      "loss: 0.076315  [   84/  175]\n",
      "loss: 0.125034  [  164/  175]\n",
      "Training accuracy: 88.1%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.148256 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.207692  [    4/  175]\n",
      "loss: 0.703268  [   84/  175]\n",
      "loss: 0.168062  [  164/  175]\n",
      "Training accuracy: 86.4%\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.253722 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.071987  [    4/  175]\n",
      "loss: 0.167014  [   84/  175]\n",
      "loss: 0.238842  [  164/  175]\n",
      "Training accuracy: 88.1%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.188488 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.243535  [    4/  175]\n",
      "loss: 0.125282  [   84/  175]\n",
      "loss: 0.871296  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 1.532479 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.473291  [    4/  175]\n",
      "loss: 0.060662  [   84/  175]\n",
      "loss: 0.072509  [  164/  175]\n",
      "Training accuracy: 90.5%\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 2.457782 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.242720  [    4/  175]\n",
      "loss: 0.125405  [   84/  175]\n",
      "loss: 0.228066  [  164/  175]\n",
      "Training accuracy: 89.2%\n",
      "Test Error: \n",
      " Accuracy: 62.9%, Avg loss: 0.419998 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.127666  [    4/  175]\n",
      "loss: 0.063167  [   84/  175]\n",
      "loss: 0.156143  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.209047 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.069791  [    4/  175]\n",
      "loss: 0.231510  [   84/  175]\n",
      "loss: 0.158663  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 1.558026 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.065308  [    4/  175]\n",
      "loss: 0.134400  [   84/  175]\n",
      "loss: 0.174629  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 3.999608 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 1.099674  [    4/  175]\n",
      "loss: 0.069514  [   84/  175]\n",
      "loss: 0.048736  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.326041 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.244586  [    4/  175]\n",
      "loss: 0.040841  [   84/  175]\n",
      "loss: 0.115547  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 65.2%, Avg loss: 0.501868 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.158812  [    4/  175]\n",
      "loss: 0.356457  [   84/  175]\n",
      "loss: 1.386493  [  164/  175]\n",
      "Training accuracy: 90.2%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.257638 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.199095  [    4/  175]\n",
      "loss: 0.130909  [   84/  175]\n",
      "loss: 0.045341  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.335554 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.134975  [    4/  175]\n",
      "loss: 0.053845  [   84/  175]\n",
      "loss: 0.066483  [  164/  175]\n",
      "Training accuracy: 89.8%\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.214718 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.165072  [    4/  175]\n",
      "loss: 0.782829  [   84/  175]\n",
      "loss: 0.091235  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 94.7%, Avg loss: 0.234108 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.065137  [    4/  175]\n",
      "loss: 0.287975  [   84/  175]\n",
      "loss: 0.122579  [  164/  175]\n",
      "Training accuracy: 89.4%\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 5.268187 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.082966  [    4/  175]\n",
      "loss: 0.043466  [   84/  175]\n",
      "loss: 0.053855  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.359726 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.194896  [    4/  175]\n",
      "loss: 0.117417  [   84/  175]\n",
      "loss: 1.376539  [  164/  175]\n",
      "Training accuracy: 88.3%\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.209368 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.176394  [    4/  175]\n",
      "loss: 0.174158  [   84/  175]\n",
      "loss: 0.224857  [  164/  175]\n",
      "Training accuracy: 91.9%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 2.544888 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.279335  [    4/  175]\n",
      "loss: 0.206937  [   84/  175]\n",
      "loss: 0.092099  [  164/  175]\n",
      "Training accuracy: 87.9%\n",
      "Test Error: \n",
      " Accuracy: 49.2%, Avg loss: 1.685721 \n",
      "\n",
      "Done!\n",
      "Training model with learning rate 0.003...\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "loss: 0.883791  [    4/  175]\n",
      "loss: 0.570917  [   84/  175]\n",
      "loss: 0.669093  [  164/  175]\n",
      "Training accuracy: 59.3%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 0.698135 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.065089  [    4/  175]\n",
      "loss: 0.594833  [   84/  175]\n",
      "loss: 0.430003  [  164/  175]\n",
      "Training accuracy: 59.3%\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 0.699832 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.921568  [    4/  175]\n",
      "loss: 0.987247  [   84/  175]\n",
      "loss: 0.802619  [  164/  175]\n",
      "Training accuracy: 63.1%\n",
      "Test Error: \n",
      " Accuracy: 59.8%, Avg loss: 0.691555 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.861941  [    4/  175]\n",
      "loss: 0.621551  [   84/  175]\n",
      "loss: 0.827702  [  164/  175]\n",
      "Training accuracy: 57.8%\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 0.696716 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.806265  [    4/  175]\n",
      "loss: 0.703523  [   84/  175]\n",
      "loss: 0.576454  [  164/  175]\n",
      "Training accuracy: 66.9%\n",
      "Test Error: \n",
      " Accuracy: 49.2%, Avg loss: 0.790770 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.649879  [    4/  175]\n",
      "loss: 1.004558  [   84/  175]\n",
      "loss: 0.934680  [  164/  175]\n",
      "Training accuracy: 63.3%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 0.803832 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.772663  [    4/  175]\n",
      "loss: 0.534575  [   84/  175]\n",
      "loss: 0.706931  [  164/  175]\n",
      "Training accuracy: 66.9%\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 0.668932 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.515502  [    4/  175]\n",
      "loss: 0.766706  [   84/  175]\n",
      "loss: 0.815738  [  164/  175]\n",
      "Training accuracy: 63.3%\n",
      "Test Error: \n",
      " Accuracy: 65.9%, Avg loss: 0.655776 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.774733  [    4/  175]\n",
      "loss: 0.343809  [   84/  175]\n",
      "loss: 0.600946  [  164/  175]\n",
      "Training accuracy: 66.5%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 0.892753 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.934105  [    4/  175]\n",
      "loss: 0.543346  [   84/  175]\n",
      "loss: 0.813350  [  164/  175]\n",
      "Training accuracy: 65.7%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 0.734869 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.437596  [    4/  175]\n",
      "loss: 0.590822  [   84/  175]\n",
      "loss: 0.461918  [  164/  175]\n",
      "Training accuracy: 67.2%\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 0.954583 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.840610  [    4/  175]\n",
      "loss: 0.564733  [   84/  175]\n",
      "loss: 0.425008  [  164/  175]\n",
      "Training accuracy: 69.5%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 0.737637 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.516953  [    4/  175]\n",
      "loss: 0.501427  [   84/  175]\n",
      "loss: 0.581722  [  164/  175]\n",
      "Training accuracy: 65.3%\n",
      "Test Error: \n",
      " Accuracy: 51.5%, Avg loss: 0.757982 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.590610  [    4/  175]\n",
      "loss: 0.658804  [   84/  175]\n",
      "loss: 0.675639  [  164/  175]\n",
      "Training accuracy: 68.2%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 0.748997 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.406659  [    4/  175]\n",
      "loss: 0.639461  [   84/  175]\n",
      "loss: 0.601252  [  164/  175]\n",
      "Training accuracy: 69.7%\n",
      "Test Error: \n",
      " Accuracy: 75.8%, Avg loss: 0.597093 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.465361  [    4/  175]\n",
      "loss: 0.802983  [   84/  175]\n",
      "loss: 0.819484  [  164/  175]\n",
      "Training accuracy: 75.4%\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 0.609042 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.575938  [    4/  175]\n",
      "loss: 0.636188  [   84/  175]\n",
      "loss: 0.798713  [  164/  175]\n",
      "Training accuracy: 69.7%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 0.708237 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.520462  [    4/  175]\n",
      "loss: 0.562678  [   84/  175]\n",
      "loss: 0.614774  [  164/  175]\n",
      "Training accuracy: 72.0%\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 0.727736 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.404725  [    4/  175]\n",
      "loss: 0.522321  [   84/  175]\n",
      "loss: 0.561582  [  164/  175]\n",
      "Training accuracy: 75.4%\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 0.589362 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.524273  [    4/  175]\n",
      "loss: 0.388801  [   84/  175]\n",
      "loss: 0.480689  [  164/  175]\n",
      "Training accuracy: 67.8%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.110415 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.578338  [    4/  175]\n",
      "loss: 0.455590  [   84/  175]\n",
      "loss: 0.910721  [  164/  175]\n",
      "Training accuracy: 74.1%\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 1.142991 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.460675  [    4/  175]\n",
      "loss: 0.849238  [   84/  175]\n",
      "loss: 0.457265  [  164/  175]\n",
      "Training accuracy: 74.8%\n",
      "Test Error: \n",
      " Accuracy: 72.7%, Avg loss: 0.563042 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.461216  [    4/  175]\n",
      "loss: 0.870714  [   84/  175]\n",
      "loss: 0.293866  [  164/  175]\n",
      "Training accuracy: 72.0%\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.545087 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.442242  [    4/  175]\n",
      "loss: 0.745338  [   84/  175]\n",
      "loss: 0.483230  [  164/  175]\n",
      "Training accuracy: 71.4%\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 0.938994 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.489417  [    4/  175]\n",
      "loss: 0.457438  [   84/  175]\n",
      "loss: 0.395318  [  164/  175]\n",
      "Training accuracy: 75.4%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 0.990038 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.419255  [    4/  175]\n",
      "loss: 0.665456  [   84/  175]\n",
      "loss: 0.423976  [  164/  175]\n",
      "Training accuracy: 75.4%\n",
      "Test Error: \n",
      " Accuracy: 63.6%, Avg loss: 0.810264 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.611537  [    4/  175]\n",
      "loss: 0.695999  [   84/  175]\n",
      "loss: 0.543345  [  164/  175]\n",
      "Training accuracy: 73.3%\n",
      "Test Error: \n",
      " Accuracy: 62.1%, Avg loss: 0.592561 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.358892  [    4/  175]\n",
      "loss: 0.284817  [   84/  175]\n",
      "loss: 0.412503  [  164/  175]\n",
      "Training accuracy: 79.4%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.314925 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.332057  [    4/  175]\n",
      "loss: 0.435384  [   84/  175]\n",
      "loss: 0.900229  [  164/  175]\n",
      "Training accuracy: 75.8%\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.767055 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.578857  [    4/  175]\n",
      "loss: 0.442446  [   84/  175]\n",
      "loss: 0.611784  [  164/  175]\n",
      "Training accuracy: 80.1%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 0.776415 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.504358  [    4/  175]\n",
      "loss: 0.836204  [   84/  175]\n",
      "loss: 0.506400  [  164/  175]\n",
      "Training accuracy: 79.5%\n",
      "Test Error: \n",
      " Accuracy: 59.8%, Avg loss: 0.784627 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.391383  [    4/  175]\n",
      "loss: 0.391701  [   84/  175]\n",
      "loss: 0.526650  [  164/  175]\n",
      "Training accuracy: 75.8%\n",
      "Test Error: \n",
      " Accuracy: 62.9%, Avg loss: 0.514390 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.499219  [    4/  175]\n",
      "loss: 0.483442  [   84/  175]\n",
      "loss: 0.629483  [  164/  175]\n",
      "Training accuracy: 77.8%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 5.255229 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.650367  [    4/  175]\n",
      "loss: 0.331380  [   84/  175]\n",
      "loss: 0.263569  [  164/  175]\n",
      "Training accuracy: 76.5%\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.465170 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.768072  [    4/  175]\n",
      "loss: 0.397425  [   84/  175]\n",
      "loss: 0.454554  [  164/  175]\n",
      "Training accuracy: 79.2%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.266712 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.601253  [    4/  175]\n",
      "loss: 0.362194  [   84/  175]\n",
      "loss: 0.330009  [  164/  175]\n",
      "Training accuracy: 74.8%\n",
      "Test Error: \n",
      " Accuracy: 72.0%, Avg loss: 0.506607 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.418611  [    4/  175]\n",
      "loss: 0.333718  [   84/  175]\n",
      "loss: 0.819069  [  164/  175]\n",
      "Training accuracy: 75.0%\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.473163 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.343292  [    4/  175]\n",
      "loss: 0.353547  [   84/  175]\n",
      "loss: 0.623291  [  164/  175]\n",
      "Training accuracy: 79.0%\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.479001 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.575162  [    4/  175]\n",
      "loss: 0.469245  [   84/  175]\n",
      "loss: 0.491932  [  164/  175]\n",
      "Training accuracy: 72.5%\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.459270 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.744921  [    4/  175]\n",
      "loss: 0.449462  [   84/  175]\n",
      "loss: 0.267745  [  164/  175]\n",
      "Training accuracy: 81.1%\n",
      "Test Error: \n",
      " Accuracy: 61.4%, Avg loss: 0.614158 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.471943  [    4/  175]\n",
      "loss: 0.422550  [   84/  175]\n",
      "loss: 0.440955  [  164/  175]\n",
      "Training accuracy: 79.9%\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 1.038391 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.644950  [    4/  175]\n",
      "loss: 0.499875  [   84/  175]\n",
      "loss: 0.440773  [  164/  175]\n",
      "Training accuracy: 76.7%\n",
      "Test Error: \n",
      " Accuracy: 62.1%, Avg loss: 0.642407 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.647814  [    4/  175]\n",
      "loss: 0.288644  [   84/  175]\n",
      "loss: 0.351059  [  164/  175]\n",
      "Training accuracy: 83.0%\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 0.501661 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.511676  [    4/  175]\n",
      "loss: 0.400165  [   84/  175]\n",
      "loss: 0.722087  [  164/  175]\n",
      "Training accuracy: 79.0%\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.362227 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 1.002327  [    4/  175]\n",
      "loss: 0.317048  [   84/  175]\n",
      "loss: 0.542819  [  164/  175]\n",
      "Training accuracy: 79.4%\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.368294 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.880901  [    4/  175]\n",
      "loss: 0.808981  [   84/  175]\n",
      "loss: 0.639336  [  164/  175]\n",
      "Training accuracy: 77.7%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.048993 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.216061  [    4/  175]\n",
      "loss: 0.718336  [   84/  175]\n",
      "loss: 0.987778  [  164/  175]\n",
      "Training accuracy: 76.5%\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.371132 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.895180  [    4/  175]\n",
      "loss: 0.321084  [   84/  175]\n",
      "loss: 0.321815  [  164/  175]\n",
      "Training accuracy: 77.3%\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.378918 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.331966  [    4/  175]\n",
      "loss: 0.430665  [   84/  175]\n",
      "loss: 0.232835  [  164/  175]\n",
      "Training accuracy: 83.0%\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.365222 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.250805  [    4/  175]\n",
      "loss: 0.869324  [   84/  175]\n",
      "loss: 0.731356  [  164/  175]\n",
      "Training accuracy: 81.2%\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.376329 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.438783  [    4/  175]\n",
      "loss: 0.221218  [   84/  175]\n",
      "loss: 0.298567  [  164/  175]\n",
      "Training accuracy: 79.0%\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.387933 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.345080  [    4/  175]\n",
      "loss: 0.275472  [   84/  175]\n",
      "loss: 0.287111  [  164/  175]\n",
      "Training accuracy: 80.1%\n",
      "Test Error: \n",
      " Accuracy: 49.2%, Avg loss: 1.485931 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.970170  [    4/  175]\n",
      "loss: 0.516496  [   84/  175]\n",
      "loss: 0.538744  [  164/  175]\n",
      "Training accuracy: 83.0%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.310913 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.445499  [    4/  175]\n",
      "loss: 0.242519  [   84/  175]\n",
      "loss: 0.353375  [  164/  175]\n",
      "Training accuracy: 81.6%\n",
      "Test Error: \n",
      " Accuracy: 65.2%, Avg loss: 0.524450 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.482953  [    4/  175]\n",
      "loss: 0.280487  [   84/  175]\n",
      "loss: 0.147558  [  164/  175]\n",
      "Training accuracy: 80.5%\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.345333 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.231233  [    4/  175]\n",
      "loss: 0.289228  [   84/  175]\n",
      "loss: 0.773245  [  164/  175]\n",
      "Training accuracy: 83.9%\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 0.397551 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.245690  [    4/  175]\n",
      "loss: 0.202041  [   84/  175]\n",
      "loss: 0.343861  [  164/  175]\n",
      "Training accuracy: 84.5%\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 0.395930 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.427922  [    4/  175]\n",
      "loss: 0.443323  [   84/  175]\n",
      "loss: 0.336799  [  164/  175]\n",
      "Training accuracy: 88.6%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.313787 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.859894  [    4/  175]\n",
      "loss: 0.422216  [   84/  175]\n",
      "loss: 0.256983  [  164/  175]\n",
      "Training accuracy: 85.8%\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.368326 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.260402  [    4/  175]\n",
      "loss: 0.268631  [   84/  175]\n",
      "loss: 0.793879  [  164/  175]\n",
      "Training accuracy: 78.2%\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.270756 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.481831  [    4/  175]\n",
      "loss: 0.315587  [   84/  175]\n",
      "loss: 0.432112  [  164/  175]\n",
      "Training accuracy: 81.8%\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 0.384674 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.232036  [    4/  175]\n",
      "loss: 0.627853  [   84/  175]\n",
      "loss: 0.343785  [  164/  175]\n",
      "Training accuracy: 86.0%\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.278515 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.870500  [    4/  175]\n",
      "loss: 0.150517  [   84/  175]\n",
      "loss: 0.645036  [  164/  175]\n",
      "Training accuracy: 84.5%\n",
      "Test Error: \n",
      " Accuracy: 62.1%, Avg loss: 0.720896 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.451757  [    4/  175]\n",
      "loss: 0.698103  [   84/  175]\n",
      "loss: 0.288061  [  164/  175]\n",
      "Training accuracy: 87.3%\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.355777 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.685299  [    4/  175]\n",
      "loss: 0.258477  [   84/  175]\n",
      "loss: 0.316446  [  164/  175]\n",
      "Training accuracy: 83.5%\n",
      "Test Error: \n",
      " Accuracy: 62.9%, Avg loss: 0.512012 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.170457  [    4/  175]\n",
      "loss: 0.421795  [   84/  175]\n",
      "loss: 0.456173  [  164/  175]\n",
      "Training accuracy: 84.1%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 1.283126 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.495367  [    4/  175]\n",
      "loss: 0.335244  [   84/  175]\n",
      "loss: 0.281177  [  164/  175]\n",
      "Training accuracy: 88.1%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.212142 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.331068  [    4/  175]\n",
      "loss: 0.241186  [   84/  175]\n",
      "loss: 0.244325  [  164/  175]\n",
      "Training accuracy: 90.7%\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.288920 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.332664  [    4/  175]\n",
      "loss: 0.211250  [   84/  175]\n",
      "loss: 0.747849  [  164/  175]\n",
      "Training accuracy: 82.6%\n",
      "Test Error: \n",
      " Accuracy: 92.4%, Avg loss: 0.236971 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.307781  [    4/  175]\n",
      "loss: 0.239202  [   84/  175]\n",
      "loss: 0.204876  [  164/  175]\n",
      "Training accuracy: 91.1%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.183174 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.124581  [    4/  175]\n",
      "loss: 0.283442  [   84/  175]\n",
      "loss: 0.269147  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.220736 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.359805  [    4/  175]\n",
      "loss: 0.228430  [   84/  175]\n",
      "loss: 0.223489  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.207270 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.107785  [    4/  175]\n",
      "loss: 0.158558  [   84/  175]\n",
      "loss: 0.287342  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.184756 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.232464  [    4/  175]\n",
      "loss: 0.221517  [   84/  175]\n",
      "loss: 0.266432  [  164/  175]\n",
      "Training accuracy: 88.6%\n",
      "Test Error: \n",
      " Accuracy: 65.9%, Avg loss: 0.458389 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.172805  [    4/  175]\n",
      "loss: 0.250141  [   84/  175]\n",
      "loss: 0.107692  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.146606 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.715536  [    4/  175]\n",
      "loss: 0.228678  [   84/  175]\n",
      "loss: 0.168388  [  164/  175]\n",
      "Training accuracy: 89.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.145978 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.184702  [    4/  175]\n",
      "loss: 0.879914  [   84/  175]\n",
      "loss: 0.232882  [  164/  175]\n",
      "Training accuracy: 86.4%\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 1.027044 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.755828  [    4/  175]\n",
      "loss: 0.235388  [   84/  175]\n",
      "loss: 0.129209  [  164/  175]\n",
      "Training accuracy: 89.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.156142 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.278566  [    4/  175]\n",
      "loss: 0.096063  [   84/  175]\n",
      "loss: 0.222040  [  164/  175]\n",
      "Training accuracy: 98.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.128944 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.091553  [    4/  175]\n",
      "loss: 0.106926  [   84/  175]\n",
      "loss: 0.396322  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.173230 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.119446  [    4/  175]\n",
      "loss: 0.210853  [   84/  175]\n",
      "loss: 0.241841  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.122932 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.789762  [    4/  175]\n",
      "loss: 0.196332  [   84/  175]\n",
      "loss: 0.238857  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.123816 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.107317  [    4/  175]\n",
      "loss: 0.287791  [   84/  175]\n",
      "loss: 0.192851  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.111705 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.194781  [    4/  175]\n",
      "loss: 0.189351  [   84/  175]\n",
      "loss: 0.149552  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.107714 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.737814  [    4/  175]\n",
      "loss: 0.092885  [   84/  175]\n",
      "loss: 0.083791  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.134707 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.292852  [    4/  175]\n",
      "loss: 0.145781  [   84/  175]\n",
      "loss: 0.212241  [  164/  175]\n",
      "Training accuracy: 89.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.109402 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.189820  [    4/  175]\n",
      "loss: 0.044313  [   84/  175]\n",
      "loss: 0.072087  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.134996 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.070378  [    4/  175]\n",
      "loss: 0.158393  [   84/  175]\n",
      "loss: 0.084929  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.103256 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.216776  [    4/  175]\n",
      "loss: 0.113405  [   84/  175]\n",
      "loss: 0.258273  [  164/  175]\n",
      "Training accuracy: 86.4%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.092151 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.338929  [    4/  175]\n",
      "loss: 0.148935  [   84/  175]\n",
      "loss: 0.182861  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.104617 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.706053  [    4/  175]\n",
      "loss: 0.158138  [   84/  175]\n",
      "loss: 0.290934  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 0.820004 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.136778  [    4/  175]\n",
      "loss: 0.286077  [   84/  175]\n",
      "loss: 0.219906  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.229596 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 1.078124  [    4/  175]\n",
      "loss: 0.146196  [   84/  175]\n",
      "loss: 0.190729  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.084194 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.803972  [    4/  175]\n",
      "loss: 0.803103  [   84/  175]\n",
      "loss: 0.148247  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.084912 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.044494  [    4/  175]\n",
      "loss: 0.227390  [   84/  175]\n",
      "loss: 0.061671  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.088994 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.165763  [    4/  175]\n",
      "loss: 0.445422  [   84/  175]\n",
      "loss: 0.236102  [  164/  175]\n",
      "Training accuracy: 92.4%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.081566 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.055311  [    4/  175]\n",
      "loss: 0.168929  [   84/  175]\n",
      "loss: 0.180649  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.085516 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.208733  [    4/  175]\n",
      "loss: 0.044572  [   84/  175]\n",
      "loss: 0.117251  [  164/  175]\n",
      "Training accuracy: 95.1%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.127828 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.255225  [    4/  175]\n",
      "loss: 0.073243  [   84/  175]\n",
      "loss: 0.106911  [  164/  175]\n",
      "Training accuracy: 89.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.081562 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.264069  [    4/  175]\n",
      "loss: 0.119472  [   84/  175]\n",
      "loss: 0.224516  [  164/  175]\n",
      "Training accuracy: 91.7%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.076058 \n",
      "\n",
      "Done!\n",
      "Training model with learning rate 0.002...\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "loss: 0.703949  [    4/  175]\n",
      "loss: 0.444318  [   84/  175]\n",
      "loss: 0.473756  [  164/  175]\n",
      "Training accuracy: 62.5%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 0.686930 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.893757  [    4/  175]\n",
      "loss: 0.662131  [   84/  175]\n",
      "loss: 0.599326  [  164/  175]\n",
      "Training accuracy: 64.2%\n",
      "Test Error: \n",
      " Accuracy: 61.4%, Avg loss: 0.663525 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.670003  [    4/  175]\n",
      "loss: 0.583739  [   84/  175]\n",
      "loss: 0.437884  [  164/  175]\n",
      "Training accuracy: 67.0%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 1.026293 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.621846  [    4/  175]\n",
      "loss: 0.512397  [   84/  175]\n",
      "loss: 0.669944  [  164/  175]\n",
      "Training accuracy: 65.3%\n",
      "Test Error: \n",
      " Accuracy: 55.3%, Avg loss: 0.645667 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.509897  [    4/  175]\n",
      "loss: 0.531396  [   84/  175]\n",
      "loss: 0.639748  [  164/  175]\n",
      "Training accuracy: 72.5%\n",
      "Test Error: \n",
      " Accuracy: 65.9%, Avg loss: 0.567165 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.814485  [    4/  175]\n",
      "loss: 0.516139  [   84/  175]\n",
      "loss: 0.669597  [  164/  175]\n",
      "Training accuracy: 72.2%\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.937157 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.453059  [    4/  175]\n",
      "loss: 0.550586  [   84/  175]\n",
      "loss: 0.760447  [  164/  175]\n",
      "Training accuracy: 72.0%\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.574794 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.581703  [    4/  175]\n",
      "loss: 0.601605  [   84/  175]\n",
      "loss: 0.862586  [  164/  175]\n",
      "Training accuracy: 74.6%\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.556252 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.602053  [    4/  175]\n",
      "loss: 0.476994  [   84/  175]\n",
      "loss: 0.387929  [  164/  175]\n",
      "Training accuracy: 77.3%\n",
      "Test Error: \n",
      " Accuracy: 64.4%, Avg loss: 0.696436 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.523245  [    4/  175]\n",
      "loss: 0.490973  [   84/  175]\n",
      "loss: 0.477932  [  164/  175]\n",
      "Training accuracy: 75.2%\n",
      "Test Error: \n",
      " Accuracy: 72.7%, Avg loss: 0.505808 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.667317  [    4/  175]\n",
      "loss: 0.439770  [   84/  175]\n",
      "loss: 0.621250  [  164/  175]\n",
      "Training accuracy: 72.7%\n",
      "Test Error: \n",
      " Accuracy: 70.5%, Avg loss: 0.583626 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.627628  [    4/  175]\n",
      "loss: 1.015223  [   84/  175]\n",
      "loss: 0.304271  [  164/  175]\n",
      "Training accuracy: 77.8%\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 0.715241 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.635471  [    4/  175]\n",
      "loss: 0.445923  [   84/  175]\n",
      "loss: 0.491099  [  164/  175]\n",
      "Training accuracy: 74.4%\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 0.593881 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.670608  [    4/  175]\n",
      "loss: 0.423115  [   84/  175]\n",
      "loss: 0.476782  [  164/  175]\n",
      "Training accuracy: 77.3%\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 0.505878 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.430935  [    4/  175]\n",
      "loss: 0.447249  [   84/  175]\n",
      "loss: 0.445780  [  164/  175]\n",
      "Training accuracy: 75.0%\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.500068 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 1.032775  [    4/  175]\n",
      "loss: 0.650740  [   84/  175]\n",
      "loss: 0.590888  [  164/  175]\n",
      "Training accuracy: 71.2%\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.444453 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.770954  [    4/  175]\n",
      "loss: 0.494201  [   84/  175]\n",
      "loss: 0.770259  [  164/  175]\n",
      "Training accuracy: 75.4%\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.496825 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.414644  [    4/  175]\n",
      "loss: 0.810397  [   84/  175]\n",
      "loss: 0.366522  [  164/  175]\n",
      "Training accuracy: 79.4%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 0.716938 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.804970  [    4/  175]\n",
      "loss: 0.591257  [   84/  175]\n",
      "loss: 0.381558  [  164/  175]\n",
      "Training accuracy: 79.9%\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.443393 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.838560  [    4/  175]\n",
      "loss: 0.321600  [   84/  175]\n",
      "loss: 0.320615  [  164/  175]\n",
      "Training accuracy: 81.2%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 0.860245 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.794559  [    4/  175]\n",
      "loss: 0.633067  [   84/  175]\n",
      "loss: 0.511574  [  164/  175]\n",
      "Training accuracy: 75.8%\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.427814 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.464847  [    4/  175]\n",
      "loss: 0.335551  [   84/  175]\n",
      "loss: 0.294706  [  164/  175]\n",
      "Training accuracy: 80.1%\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.412576 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.340596  [    4/  175]\n",
      "loss: 0.338766  [   84/  175]\n",
      "loss: 0.393180  [  164/  175]\n",
      "Training accuracy: 78.8%\n",
      "Test Error: \n",
      " Accuracy: 70.5%, Avg loss: 0.518068 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.357913  [    4/  175]\n",
      "loss: 0.851993  [   84/  175]\n",
      "loss: 0.760568  [  164/  175]\n",
      "Training accuracy: 79.9%\n",
      "Test Error: \n",
      " Accuracy: 57.6%, Avg loss: 0.654719 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.396991  [    4/  175]\n",
      "loss: 0.311803  [   84/  175]\n",
      "loss: 0.322996  [  164/  175]\n",
      "Training accuracy: 75.9%\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.444843 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.470355  [    4/  175]\n",
      "loss: 0.664249  [   84/  175]\n",
      "loss: 0.301863  [  164/  175]\n",
      "Training accuracy: 78.4%\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.401477 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.292984  [    4/  175]\n",
      "loss: 0.873285  [   84/  175]\n",
      "loss: 0.729098  [  164/  175]\n",
      "Training accuracy: 76.9%\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.376999 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.340735  [    4/  175]\n",
      "loss: 0.392472  [   84/  175]\n",
      "loss: 0.409736  [  164/  175]\n",
      "Training accuracy: 81.2%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 2.261992 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.332228  [    4/  175]\n",
      "loss: 0.300793  [   84/  175]\n",
      "loss: 0.280436  [  164/  175]\n",
      "Training accuracy: 84.5%\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.466688 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.484981  [    4/  175]\n",
      "loss: 0.370714  [   84/  175]\n",
      "loss: 0.423250  [  164/  175]\n",
      "Training accuracy: 81.6%\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.370615 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.365771  [    4/  175]\n",
      "loss: 0.262567  [   84/  175]\n",
      "loss: 0.742013  [  164/  175]\n",
      "Training accuracy: 76.5%\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.372186 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.318939  [    4/  175]\n",
      "loss: 0.768479  [   84/  175]\n",
      "loss: 0.511708  [  164/  175]\n",
      "Training accuracy: 73.9%\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 2.991963 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.233397  [    4/  175]\n",
      "loss: 0.280518  [   84/  175]\n",
      "loss: 0.373912  [  164/  175]\n",
      "Training accuracy: 83.5%\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.340198 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.275452  [    4/  175]\n",
      "loss: 0.432599  [   84/  175]\n",
      "loss: 0.564837  [  164/  175]\n",
      "Training accuracy: 81.6%\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.393426 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.288937  [    4/  175]\n",
      "loss: 0.358547  [   84/  175]\n",
      "loss: 0.294527  [  164/  175]\n",
      "Training accuracy: 81.2%\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.335353 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.243122  [    4/  175]\n",
      "loss: 0.590369  [   84/  175]\n",
      "loss: 0.316881  [  164/  175]\n",
      "Training accuracy: 83.5%\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 0.577158 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.719726  [    4/  175]\n",
      "loss: 0.459614  [   84/  175]\n",
      "loss: 0.311633  [  164/  175]\n",
      "Training accuracy: 84.1%\n",
      "Test Error: \n",
      " Accuracy: 69.7%, Avg loss: 0.468695 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.469223  [    4/  175]\n",
      "loss: 0.344118  [   84/  175]\n",
      "loss: 0.802276  [  164/  175]\n",
      "Training accuracy: 83.3%\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.350713 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.579112  [    4/  175]\n",
      "loss: 0.247229  [   84/  175]\n",
      "loss: 0.165772  [  164/  175]\n",
      "Training accuracy: 86.0%\n",
      "Test Error: \n",
      " Accuracy: 72.7%, Avg loss: 0.406704 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.360433  [    4/  175]\n",
      "loss: 0.260762  [   84/  175]\n",
      "loss: 0.245810  [  164/  175]\n",
      "Training accuracy: 80.1%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.279835 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.643256  [    4/  175]\n",
      "loss: 0.446448  [   84/  175]\n",
      "loss: 0.324718  [  164/  175]\n",
      "Training accuracy: 82.8%\n",
      "Test Error: \n",
      " Accuracy: 67.4%, Avg loss: 0.651002 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.420654  [    4/  175]\n",
      "loss: 0.487967  [   84/  175]\n",
      "loss: 0.315334  [  164/  175]\n",
      "Training accuracy: 80.5%\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.302067 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.718416  [    4/  175]\n",
      "loss: 0.382760  [   84/  175]\n",
      "loss: 0.241965  [  164/  175]\n",
      "Training accuracy: 80.7%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.296447 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.328201  [    4/  175]\n",
      "loss: 0.198348  [   84/  175]\n",
      "loss: 0.354441  [  164/  175]\n",
      "Training accuracy: 85.6%\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.293010 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.427014  [    4/  175]\n",
      "loss: 0.440118  [   84/  175]\n",
      "loss: 0.357338  [  164/  175]\n",
      "Training accuracy: 86.9%\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.281669 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.280683  [    4/  175]\n",
      "loss: 0.175935  [   84/  175]\n",
      "loss: 0.429934  [  164/  175]\n",
      "Training accuracy: 83.7%\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.306611 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.814450  [    4/  175]\n",
      "loss: 0.969976  [   84/  175]\n",
      "loss: 0.809476  [  164/  175]\n",
      "Training accuracy: 80.9%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.276455 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.568848  [    4/  175]\n",
      "loss: 0.657232  [   84/  175]\n",
      "loss: 0.282693  [  164/  175]\n",
      "Training accuracy: 85.8%\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.284512 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.287809  [    4/  175]\n",
      "loss: 0.192813  [   84/  175]\n",
      "loss: 0.729889  [  164/  175]\n",
      "Training accuracy: 84.5%\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 0.894784 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.208088  [    4/  175]\n",
      "loss: 0.235014  [   84/  175]\n",
      "loss: 0.323366  [  164/  175]\n",
      "Training accuracy: 84.7%\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 0.408719 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.789994  [    4/  175]\n",
      "loss: 0.390264  [   84/  175]\n",
      "loss: 0.498008  [  164/  175]\n",
      "Training accuracy: 82.2%\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 0.661188 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.299026  [    4/  175]\n",
      "loss: 0.783425  [   84/  175]\n",
      "loss: 0.411437  [  164/  175]\n",
      "Training accuracy: 83.9%\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.265538 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.145324  [    4/  175]\n",
      "loss: 0.311134  [   84/  175]\n",
      "loss: 0.183206  [  164/  175]\n",
      "Training accuracy: 85.8%\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.251163 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.240809  [    4/  175]\n",
      "loss: 0.320125  [   84/  175]\n",
      "loss: 0.721672  [  164/  175]\n",
      "Training accuracy: 83.7%\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 0.738209 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.249195  [    4/  175]\n",
      "loss: 0.285752  [   84/  175]\n",
      "loss: 0.188128  [  164/  175]\n",
      "Training accuracy: 86.7%\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.299684 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.322399  [    4/  175]\n",
      "loss: 0.224317  [   84/  175]\n",
      "loss: 0.295866  [  164/  175]\n",
      "Training accuracy: 89.8%\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.254222 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.268425  [    4/  175]\n",
      "loss: 0.724120  [   84/  175]\n",
      "loss: 0.178012  [  164/  175]\n",
      "Training accuracy: 83.5%\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.266549 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.336075  [    4/  175]\n",
      "loss: 0.340268  [   84/  175]\n",
      "loss: 0.173410  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 92.4%, Avg loss: 0.260487 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.390985  [    4/  175]\n",
      "loss: 0.260879  [   84/  175]\n",
      "loss: 0.134488  [  164/  175]\n",
      "Training accuracy: 88.1%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.243424 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.233803  [    4/  175]\n",
      "loss: 0.259273  [   84/  175]\n",
      "loss: 0.771869  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.229444 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.465163  [    4/  175]\n",
      "loss: 0.260383  [   84/  175]\n",
      "loss: 0.184864  [  164/  175]\n",
      "Training accuracy: 86.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.212436 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.303787  [    4/  175]\n",
      "loss: 1.042951  [   84/  175]\n",
      "loss: 0.290455  [  164/  175]\n",
      "Training accuracy: 86.4%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.245616 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.230871  [    4/  175]\n",
      "loss: 0.164316  [   84/  175]\n",
      "loss: 0.492747  [  164/  175]\n",
      "Training accuracy: 87.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.210538 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.429813  [    4/  175]\n",
      "loss: 0.270442  [   84/  175]\n",
      "loss: 0.185160  [  164/  175]\n",
      "Training accuracy: 87.5%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.211599 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.292674  [    4/  175]\n",
      "loss: 0.219023  [   84/  175]\n",
      "loss: 0.132933  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.319260 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.148985  [    4/  175]\n",
      "loss: 0.133439  [   84/  175]\n",
      "loss: 0.234469  [  164/  175]\n",
      "Training accuracy: 83.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.194409 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.278478  [    4/  175]\n",
      "loss: 0.375264  [   84/  175]\n",
      "loss: 0.261839  [  164/  175]\n",
      "Training accuracy: 87.3%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.205153 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.304995  [    4/  175]\n",
      "loss: 0.222864  [   84/  175]\n",
      "loss: 0.086675  [  164/  175]\n",
      "Training accuracy: 91.3%\n",
      "Test Error: \n",
      " Accuracy: 93.9%, Avg loss: 0.223207 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.742713  [    4/  175]\n",
      "loss: 0.223519  [   84/  175]\n",
      "loss: 0.345828  [  164/  175]\n",
      "Training accuracy: 87.3%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.184747 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.189935  [    4/  175]\n",
      "loss: 0.495323  [   84/  175]\n",
      "loss: 0.833761  [  164/  175]\n",
      "Training accuracy: 89.2%\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.261755 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.209540  [    4/  175]\n",
      "loss: 0.696864  [   84/  175]\n",
      "loss: 0.275785  [  164/  175]\n",
      "Training accuracy: 89.8%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.196929 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.114428  [    4/  175]\n",
      "loss: 0.373562  [   84/  175]\n",
      "loss: 0.250067  [  164/  175]\n",
      "Training accuracy: 92.2%\n",
      "Test Error: \n",
      " Accuracy: 64.4%, Avg loss: 0.787604 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.597812  [    4/  175]\n",
      "loss: 0.787749  [   84/  175]\n",
      "loss: 0.345851  [  164/  175]\n",
      "Training accuracy: 86.4%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.182723 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.456252  [    4/  175]\n",
      "loss: 0.797597  [   84/  175]\n",
      "loss: 0.402684  [  164/  175]\n",
      "Training accuracy: 88.6%\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.225978 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.808451  [    4/  175]\n",
      "loss: 0.192257  [   84/  175]\n",
      "loss: 0.110389  [  164/  175]\n",
      "Training accuracy: 86.6%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.214538 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.343395  [    4/  175]\n",
      "loss: 0.126278  [   84/  175]\n",
      "loss: 0.128566  [  164/  175]\n",
      "Training accuracy: 88.1%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.165670 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.180632  [    4/  175]\n",
      "loss: 0.224111  [   84/  175]\n",
      "loss: 0.241069  [  164/  175]\n",
      "Training accuracy: 87.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.151933 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.802476  [    4/  175]\n",
      "loss: 0.161933  [   84/  175]\n",
      "loss: 0.324654  [  164/  175]\n",
      "Training accuracy: 87.9%\n",
      "Test Error: \n",
      " Accuracy: 92.4%, Avg loss: 0.216329 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.180520  [    4/  175]\n",
      "loss: 0.110320  [   84/  175]\n",
      "loss: 0.258482  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.191575 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.105470  [    4/  175]\n",
      "loss: 0.246245  [   84/  175]\n",
      "loss: 0.171469  [  164/  175]\n",
      "Training accuracy: 87.5%\n",
      "Test Error: \n",
      " Accuracy: 72.7%, Avg loss: 0.474599 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.182156  [    4/  175]\n",
      "loss: 1.100088  [   84/  175]\n",
      "loss: 0.324028  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.137290 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.114018  [    4/  175]\n",
      "loss: 0.484323  [   84/  175]\n",
      "loss: 0.246748  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.169767 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.197581  [    4/  175]\n",
      "loss: 0.087802  [   84/  175]\n",
      "loss: 0.220050  [  164/  175]\n",
      "Training accuracy: 89.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.143664 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.142813  [    4/  175]\n",
      "loss: 0.942858  [   84/  175]\n",
      "loss: 0.194322  [  164/  175]\n",
      "Training accuracy: 88.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.153084 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.249532  [    4/  175]\n",
      "loss: 0.203869  [   84/  175]\n",
      "loss: 0.834201  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.136707 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.104190  [    4/  175]\n",
      "loss: 0.188948  [   84/  175]\n",
      "loss: 0.082084  [  164/  175]\n",
      "Training accuracy: 93.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.143797 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.085657  [    4/  175]\n",
      "loss: 0.233358  [   84/  175]\n",
      "loss: 0.376944  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.127741 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.158970  [    4/  175]\n",
      "loss: 0.204283  [   84/  175]\n",
      "loss: 0.130092  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.125854 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.327645  [    4/  175]\n",
      "loss: 0.331960  [   84/  175]\n",
      "loss: 0.173397  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.398848 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.154651  [    4/  175]\n",
      "loss: 0.149516  [   84/  175]\n",
      "loss: 0.456237  [  164/  175]\n",
      "Training accuracy: 93.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.119276 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.176423  [    4/  175]\n",
      "loss: 0.472784  [   84/  175]\n",
      "loss: 0.108763  [  164/  175]\n",
      "Training accuracy: 96.0%\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.313771 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.224040  [    4/  175]\n",
      "loss: 0.122004  [   84/  175]\n",
      "loss: 0.091098  [  164/  175]\n",
      "Training accuracy: 92.4%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.121736 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.763146  [    4/  175]\n",
      "loss: 0.093259  [   84/  175]\n",
      "loss: 0.143318  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.129494 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.135672  [    4/  175]\n",
      "loss: 0.085800  [   84/  175]\n",
      "loss: 0.125188  [  164/  175]\n",
      "Training accuracy: 92.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.116867 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.168369  [    4/  175]\n",
      "loss: 0.880026  [   84/  175]\n",
      "loss: 0.066421  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.113145 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.103295  [    4/  175]\n",
      "loss: 0.057740  [   84/  175]\n",
      "loss: 0.073303  [  164/  175]\n",
      "Training accuracy: 93.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.139986 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.886682  [    4/  175]\n",
      "loss: 0.171465  [   84/  175]\n",
      "loss: 0.302864  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.138696 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.182003  [    4/  175]\n",
      "loss: 0.064199  [   84/  175]\n",
      "loss: 0.193436  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.100937 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.183585  [    4/  175]\n",
      "loss: 0.787605  [   84/  175]\n",
      "loss: 0.698645  [  164/  175]\n",
      "Training accuracy: 89.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.090095 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.066546  [    4/  175]\n",
      "loss: 0.173449  [   84/  175]\n",
      "loss: 0.161007  [  164/  175]\n",
      "Training accuracy: 91.9%\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.422134 \n",
      "\n",
      "Done!\n",
      "Training model with learning rate 0.001...\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "loss: 0.922009  [    4/  175]\n",
      "loss: 0.798053  [   84/  175]\n",
      "loss: 0.817838  [  164/  175]\n",
      "Training accuracy: 35.2%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 0.692275 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.762778  [    4/  175]\n",
      "loss: 0.697252  [   84/  175]\n",
      "loss: 0.747468  [  164/  175]\n",
      "Training accuracy: 50.6%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 0.694295 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.674419  [    4/  175]\n",
      "loss: 0.602295  [   84/  175]\n",
      "loss: 0.915161  [  164/  175]\n",
      "Training accuracy: 61.2%\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 0.703857 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.496095  [    4/  175]\n",
      "loss: 0.510142  [   84/  175]\n",
      "loss: 0.797603  [  164/  175]\n",
      "Training accuracy: 59.8%\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 0.694668 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.585834  [    4/  175]\n",
      "loss: 0.755130  [   84/  175]\n",
      "loss: 0.622524  [  164/  175]\n",
      "Training accuracy: 66.5%\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 0.678352 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.472642  [    4/  175]\n",
      "loss: 0.545059  [   84/  175]\n",
      "loss: 0.818012  [  164/  175]\n",
      "Training accuracy: 56.1%\n",
      "Test Error: \n",
      " Accuracy: 56.8%, Avg loss: 0.673920 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.457861  [    4/  175]\n",
      "loss: 0.612876  [   84/  175]\n",
      "loss: 0.650342  [  164/  175]\n",
      "Training accuracy: 65.3%\n",
      "Test Error: \n",
      " Accuracy: 56.8%, Avg loss: 0.676812 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.586578  [    4/  175]\n",
      "loss: 0.549191  [   84/  175]\n",
      "loss: 0.614025  [  164/  175]\n",
      "Training accuracy: 65.7%\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.697244 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.627316  [    4/  175]\n",
      "loss: 0.706800  [   84/  175]\n",
      "loss: 0.637347  [  164/  175]\n",
      "Training accuracy: 63.3%\n",
      "Test Error: \n",
      " Accuracy: 55.3%, Avg loss: 0.676113 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.544431  [    4/  175]\n",
      "loss: 0.526119  [   84/  175]\n",
      "loss: 0.410501  [  164/  175]\n",
      "Training accuracy: 65.7%\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.686155 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.493865  [    4/  175]\n",
      "loss: 0.542901  [   84/  175]\n",
      "loss: 0.848700  [  164/  175]\n",
      "Training accuracy: 65.3%\n",
      "Test Error: \n",
      " Accuracy: 55.3%, Avg loss: 0.684340 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.617220  [    4/  175]\n",
      "loss: 0.908138  [   84/  175]\n",
      "loss: 0.814474  [  164/  175]\n",
      "Training accuracy: 65.3%\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 0.672428 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.456564  [    4/  175]\n",
      "loss: 0.399790  [   84/  175]\n",
      "loss: 0.648887  [  164/  175]\n",
      "Training accuracy: 61.7%\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 0.669512 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.711501  [    4/  175]\n",
      "loss: 0.552553  [   84/  175]\n",
      "loss: 0.499030  [  164/  175]\n",
      "Training accuracy: 67.4%\n",
      "Test Error: \n",
      " Accuracy: 55.3%, Avg loss: 0.676275 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.523595  [    4/  175]\n",
      "loss: 0.590816  [   84/  175]\n",
      "loss: 0.929626  [  164/  175]\n",
      "Training accuracy: 63.8%\n",
      "Test Error: \n",
      " Accuracy: 56.8%, Avg loss: 0.654909 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.567166  [    4/  175]\n",
      "loss: 0.535532  [   84/  175]\n",
      "loss: 0.648552  [  164/  175]\n",
      "Training accuracy: 66.9%\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 0.654060 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.620748  [    4/  175]\n",
      "loss: 0.592008  [   84/  175]\n",
      "loss: 0.667450  [  164/  175]\n",
      "Training accuracy: 60.6%\n",
      "Test Error: \n",
      " Accuracy: 61.4%, Avg loss: 0.646791 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.836351  [    4/  175]\n",
      "loss: 0.821884  [   84/  175]\n",
      "loss: 0.450190  [  164/  175]\n",
      "Training accuracy: 64.4%\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 0.648286 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.705463  [    4/  175]\n",
      "loss: 0.530894  [   84/  175]\n",
      "loss: 0.535940  [  164/  175]\n",
      "Training accuracy: 65.9%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 0.649630 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.593349  [    4/  175]\n",
      "loss: 0.575102  [   84/  175]\n",
      "loss: 0.616268  [  164/  175]\n",
      "Training accuracy: 67.2%\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 0.648567 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.478210  [    4/  175]\n",
      "loss: 0.599049  [   84/  175]\n",
      "loss: 0.643335  [  164/  175]\n",
      "Training accuracy: 64.0%\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 0.644021 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.709504  [    4/  175]\n",
      "loss: 0.443601  [   84/  175]\n",
      "loss: 0.626334  [  164/  175]\n",
      "Training accuracy: 68.8%\n",
      "Test Error: \n",
      " Accuracy: 62.9%, Avg loss: 0.643752 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.844824  [    4/  175]\n",
      "loss: 0.428879  [   84/  175]\n",
      "loss: 0.646186  [  164/  175]\n",
      "Training accuracy: 65.9%\n",
      "Test Error: \n",
      " Accuracy: 62.9%, Avg loss: 0.667404 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.580934  [    4/  175]\n",
      "loss: 0.529885  [   84/  175]\n",
      "loss: 0.740344  [  164/  175]\n",
      "Training accuracy: 68.8%\n",
      "Test Error: \n",
      " Accuracy: 62.9%, Avg loss: 0.647979 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.476132  [    4/  175]\n",
      "loss: 0.456362  [   84/  175]\n",
      "loss: 0.509214  [  164/  175]\n",
      "Training accuracy: 64.4%\n",
      "Test Error: \n",
      " Accuracy: 59.8%, Avg loss: 0.656811 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.667130  [    4/  175]\n",
      "loss: 0.620785  [   84/  175]\n",
      "loss: 0.729096  [  164/  175]\n",
      "Training accuracy: 67.0%\n",
      "Test Error: \n",
      " Accuracy: 65.2%, Avg loss: 0.644795 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.822288  [    4/  175]\n",
      "loss: 0.799803  [   84/  175]\n",
      "loss: 0.530479  [  164/  175]\n",
      "Training accuracy: 65.2%\n",
      "Test Error: \n",
      " Accuracy: 62.9%, Avg loss: 0.644904 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.833363  [    4/  175]\n",
      "loss: 0.743431  [   84/  175]\n",
      "loss: 0.567941  [  164/  175]\n",
      "Training accuracy: 68.6%\n",
      "Test Error: \n",
      " Accuracy: 52.3%, Avg loss: 0.637180 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.521173  [    4/  175]\n",
      "loss: 0.806399  [   84/  175]\n",
      "loss: 0.596705  [  164/  175]\n",
      "Training accuracy: 69.3%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 0.645062 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.694676  [    4/  175]\n",
      "loss: 0.531409  [   84/  175]\n",
      "loss: 0.617544  [  164/  175]\n",
      "Training accuracy: 66.9%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 0.626625 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.536912  [    4/  175]\n",
      "loss: 0.463421  [   84/  175]\n",
      "loss: 0.820191  [  164/  175]\n",
      "Training accuracy: 69.3%\n",
      "Test Error: \n",
      " Accuracy: 62.1%, Avg loss: 0.649505 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.489636  [    4/  175]\n",
      "loss: 0.638045  [   84/  175]\n",
      "loss: 0.714267  [  164/  175]\n",
      "Training accuracy: 66.3%\n",
      "Test Error: \n",
      " Accuracy: 65.2%, Avg loss: 0.647177 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.688939  [    4/  175]\n",
      "loss: 0.656373  [   84/  175]\n",
      "loss: 0.729181  [  164/  175]\n",
      "Training accuracy: 68.2%\n",
      "Test Error: \n",
      " Accuracy: 64.4%, Avg loss: 0.647779 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.696452  [    4/  175]\n",
      "loss: 0.483771  [   84/  175]\n",
      "loss: 0.574990  [  164/  175]\n",
      "Training accuracy: 71.4%\n",
      "Test Error: \n",
      " Accuracy: 62.9%, Avg loss: 0.630489 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.829113  [    4/  175]\n",
      "loss: 0.401927  [   84/  175]\n",
      "loss: 0.663762  [  164/  175]\n",
      "Training accuracy: 63.4%\n",
      "Test Error: \n",
      " Accuracy: 65.2%, Avg loss: 0.627162 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.479729  [    4/  175]\n",
      "loss: 0.596454  [   84/  175]\n",
      "loss: 0.561991  [  164/  175]\n",
      "Training accuracy: 68.9%\n",
      "Test Error: \n",
      " Accuracy: 65.9%, Avg loss: 0.616823 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.673512  [    4/  175]\n",
      "loss: 0.601905  [   84/  175]\n",
      "loss: 0.670511  [  164/  175]\n",
      "Training accuracy: 67.2%\n",
      "Test Error: \n",
      " Accuracy: 57.6%, Avg loss: 0.619192 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.649596  [    4/  175]\n",
      "loss: 0.580547  [   84/  175]\n",
      "loss: 0.407330  [  164/  175]\n",
      "Training accuracy: 68.8%\n",
      "Test Error: \n",
      " Accuracy: 56.8%, Avg loss: 0.610790 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.706824  [    4/  175]\n",
      "loss: 0.786842  [   84/  175]\n",
      "loss: 0.377542  [  164/  175]\n",
      "Training accuracy: 72.3%\n",
      "Test Error: \n",
      " Accuracy: 62.9%, Avg loss: 0.614955 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.579435  [    4/  175]\n",
      "loss: 0.548675  [   84/  175]\n",
      "loss: 0.532064  [  164/  175]\n",
      "Training accuracy: 65.0%\n",
      "Test Error: \n",
      " Accuracy: 66.7%, Avg loss: 0.628655 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.567440  [    4/  175]\n",
      "loss: 0.502956  [   84/  175]\n",
      "loss: 0.722594  [  164/  175]\n",
      "Training accuracy: 72.5%\n",
      "Test Error: \n",
      " Accuracy: 59.1%, Avg loss: 0.601743 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.483208  [    4/  175]\n",
      "loss: 0.701382  [   84/  175]\n",
      "loss: 0.663330  [  164/  175]\n",
      "Training accuracy: 69.9%\n",
      "Test Error: \n",
      " Accuracy: 57.6%, Avg loss: 0.606109 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.697141  [    4/  175]\n",
      "loss: 0.832183  [   84/  175]\n",
      "loss: 0.527420  [  164/  175]\n",
      "Training accuracy: 69.7%\n",
      "Test Error: \n",
      " Accuracy: 66.7%, Avg loss: 0.644461 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.457831  [    4/  175]\n",
      "loss: 0.432279  [   84/  175]\n",
      "loss: 0.704121  [  164/  175]\n",
      "Training accuracy: 73.1%\n",
      "Test Error: \n",
      " Accuracy: 63.6%, Avg loss: 0.620729 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.455105  [    4/  175]\n",
      "loss: 0.632922  [   84/  175]\n",
      "loss: 0.453985  [  164/  175]\n",
      "Training accuracy: 72.2%\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 0.608402 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.380037  [    4/  175]\n",
      "loss: 0.625812  [   84/  175]\n",
      "loss: 0.440739  [  164/  175]\n",
      "Training accuracy: 73.9%\n",
      "Test Error: \n",
      " Accuracy: 65.9%, Avg loss: 0.697513 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.619600  [    4/  175]\n",
      "loss: 0.497689  [   84/  175]\n",
      "loss: 0.639216  [  164/  175]\n",
      "Training accuracy: 73.1%\n",
      "Test Error: \n",
      " Accuracy: 63.6%, Avg loss: 0.583200 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.630112  [    4/  175]\n",
      "loss: 0.467101  [   84/  175]\n",
      "loss: 0.785504  [  164/  175]\n",
      "Training accuracy: 69.1%\n",
      "Test Error: \n",
      " Accuracy: 62.9%, Avg loss: 0.583657 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.462883  [    4/  175]\n",
      "loss: 0.709930  [   84/  175]\n",
      "loss: 0.571446  [  164/  175]\n",
      "Training accuracy: 68.2%\n",
      "Test Error: \n",
      " Accuracy: 67.4%, Avg loss: 0.585843 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.807768  [    4/  175]\n",
      "loss: 0.673892  [   84/  175]\n",
      "loss: 0.747253  [  164/  175]\n",
      "Training accuracy: 73.3%\n",
      "Test Error: \n",
      " Accuracy: 67.4%, Avg loss: 0.653776 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.484435  [    4/  175]\n",
      "loss: 0.525574  [   84/  175]\n",
      "loss: 0.495490  [  164/  175]\n",
      "Training accuracy: 68.8%\n",
      "Test Error: \n",
      " Accuracy: 65.2%, Avg loss: 0.589677 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.464603  [    4/  175]\n",
      "loss: 0.451025  [   84/  175]\n",
      "loss: 0.661749  [  164/  175]\n",
      "Training accuracy: 71.6%\n",
      "Test Error: \n",
      " Accuracy: 56.8%, Avg loss: 0.646232 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.489617  [    4/  175]\n",
      "loss: 0.740007  [   84/  175]\n",
      "loss: 0.456596  [  164/  175]\n",
      "Training accuracy: 74.8%\n",
      "Test Error: \n",
      " Accuracy: 64.4%, Avg loss: 0.581603 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.361659  [    4/  175]\n",
      "loss: 0.472952  [   84/  175]\n",
      "loss: 0.822488  [  164/  175]\n",
      "Training accuracy: 72.0%\n",
      "Test Error: \n",
      " Accuracy: 67.4%, Avg loss: 0.597112 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.378044  [    4/  175]\n",
      "loss: 0.487957  [   84/  175]\n",
      "loss: 0.729241  [  164/  175]\n",
      "Training accuracy: 75.0%\n",
      "Test Error: \n",
      " Accuracy: 72.0%, Avg loss: 0.561067 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.811016  [    4/  175]\n",
      "loss: 0.481306  [   84/  175]\n",
      "loss: 0.541998  [  164/  175]\n",
      "Training accuracy: 71.2%\n",
      "Test Error: \n",
      " Accuracy: 72.7%, Avg loss: 0.615790 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.802805  [    4/  175]\n",
      "loss: 0.810956  [   84/  175]\n",
      "loss: 0.450840  [  164/  175]\n",
      "Training accuracy: 73.9%\n",
      "Test Error: \n",
      " Accuracy: 66.7%, Avg loss: 0.693628 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.447284  [    4/  175]\n",
      "loss: 0.603789  [   84/  175]\n",
      "loss: 0.468444  [  164/  175]\n",
      "Training accuracy: 75.2%\n",
      "Test Error: \n",
      " Accuracy: 69.7%, Avg loss: 0.559279 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.466313  [    4/  175]\n",
      "loss: 0.836739  [   84/  175]\n",
      "loss: 0.472543  [  164/  175]\n",
      "Training accuracy: 75.9%\n",
      "Test Error: \n",
      " Accuracy: 67.4%, Avg loss: 0.561687 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.759287  [    4/  175]\n",
      "loss: 0.628243  [   84/  175]\n",
      "loss: 0.460355  [  164/  175]\n",
      "Training accuracy: 73.3%\n",
      "Test Error: \n",
      " Accuracy: 66.7%, Avg loss: 0.581043 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.515974  [    4/  175]\n",
      "loss: 0.959373  [   84/  175]\n",
      "loss: 0.777697  [  164/  175]\n",
      "Training accuracy: 72.0%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 0.920435 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.768807  [    4/  175]\n",
      "loss: 0.476172  [   84/  175]\n",
      "loss: 0.536744  [  164/  175]\n",
      "Training accuracy: 74.2%\n",
      "Test Error: \n",
      " Accuracy: 68.9%, Avg loss: 0.555634 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.781608  [    4/  175]\n",
      "loss: 0.635218  [   84/  175]\n",
      "loss: 0.458969  [  164/  175]\n",
      "Training accuracy: 72.2%\n",
      "Test Error: \n",
      " Accuracy: 66.7%, Avg loss: 0.689767 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.640003  [    4/  175]\n",
      "loss: 0.489512  [   84/  175]\n",
      "loss: 0.425369  [  164/  175]\n",
      "Training accuracy: 77.1%\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.546838 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.372726  [    4/  175]\n",
      "loss: 0.466337  [   84/  175]\n",
      "loss: 0.578919  [  164/  175]\n",
      "Training accuracy: 73.1%\n",
      "Test Error: \n",
      " Accuracy: 66.7%, Avg loss: 0.719598 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.897850  [    4/  175]\n",
      "loss: 0.681566  [   84/  175]\n",
      "loss: 0.455660  [  164/  175]\n",
      "Training accuracy: 72.7%\n",
      "Test Error: \n",
      " Accuracy: 72.0%, Avg loss: 0.529037 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.431521  [    4/  175]\n",
      "loss: 0.404740  [   84/  175]\n",
      "loss: 0.439766  [  164/  175]\n",
      "Training accuracy: 76.9%\n",
      "Test Error: \n",
      " Accuracy: 64.4%, Avg loss: 0.557133 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.482258  [    4/  175]\n",
      "loss: 0.341423  [   84/  175]\n",
      "loss: 0.490505  [  164/  175]\n",
      "Training accuracy: 78.8%\n",
      "Test Error: \n",
      " Accuracy: 56.8%, Avg loss: 0.615361 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.517469  [    4/  175]\n",
      "loss: 0.433869  [   84/  175]\n",
      "loss: 0.534909  [  164/  175]\n",
      "Training accuracy: 78.4%\n",
      "Test Error: \n",
      " Accuracy: 73.5%, Avg loss: 0.533996 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.825553  [    4/  175]\n",
      "loss: 0.825487  [   84/  175]\n",
      "loss: 0.617905  [  164/  175]\n",
      "Training accuracy: 76.3%\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 0.725466 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.475372  [    4/  175]\n",
      "loss: 0.751478  [   84/  175]\n",
      "loss: 0.342459  [  164/  175]\n",
      "Training accuracy: 71.8%\n",
      "Test Error: \n",
      " Accuracy: 69.7%, Avg loss: 0.600727 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.643486  [    4/  175]\n",
      "loss: 0.621835  [   84/  175]\n",
      "loss: 0.401867  [  164/  175]\n",
      "Training accuracy: 75.9%\n",
      "Test Error: \n",
      " Accuracy: 68.9%, Avg loss: 0.543904 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.650364  [    4/  175]\n",
      "loss: 0.337270  [   84/  175]\n",
      "loss: 0.322963  [  164/  175]\n",
      "Training accuracy: 78.2%\n",
      "Test Error: \n",
      " Accuracy: 72.7%, Avg loss: 0.518934 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.727777  [    4/  175]\n",
      "loss: 0.855907  [   84/  175]\n",
      "loss: 0.687939  [  164/  175]\n",
      "Training accuracy: 75.9%\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.513102 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.616178  [    4/  175]\n",
      "loss: 0.476027  [   84/  175]\n",
      "loss: 0.613681  [  164/  175]\n",
      "Training accuracy: 76.1%\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.512415 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.476625  [    4/  175]\n",
      "loss: 0.577824  [   84/  175]\n",
      "loss: 0.464851  [  164/  175]\n",
      "Training accuracy: 80.3%\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.551082 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.457660  [    4/  175]\n",
      "loss: 0.456271  [   84/  175]\n",
      "loss: 0.432899  [  164/  175]\n",
      "Training accuracy: 77.8%\n",
      "Test Error: \n",
      " Accuracy: 68.9%, Avg loss: 0.596874 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.617856  [    4/  175]\n",
      "loss: 0.416557  [   84/  175]\n",
      "loss: 0.403978  [  164/  175]\n",
      "Training accuracy: 78.2%\n",
      "Test Error: \n",
      " Accuracy: 70.5%, Avg loss: 0.551337 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.676190  [    4/  175]\n",
      "loss: 0.676585  [   84/  175]\n",
      "loss: 0.276465  [  164/  175]\n",
      "Training accuracy: 76.1%\n",
      "Test Error: \n",
      " Accuracy: 65.2%, Avg loss: 0.714237 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.537300  [    4/  175]\n",
      "loss: 0.643648  [   84/  175]\n",
      "loss: 0.775371  [  164/  175]\n",
      "Training accuracy: 75.4%\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 0.480548 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.399826  [    4/  175]\n",
      "loss: 0.624120  [   84/  175]\n",
      "loss: 0.777568  [  164/  175]\n",
      "Training accuracy: 76.3%\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.494436 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.455610  [    4/  175]\n",
      "loss: 0.375412  [   84/  175]\n",
      "loss: 0.587328  [  164/  175]\n",
      "Training accuracy: 76.7%\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.473669 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.377485  [    4/  175]\n",
      "loss: 0.531192  [   84/  175]\n",
      "loss: 0.484586  [  164/  175]\n",
      "Training accuracy: 76.7%\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.524415 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.486845  [    4/  175]\n",
      "loss: 0.378093  [   84/  175]\n",
      "loss: 0.688521  [  164/  175]\n",
      "Training accuracy: 76.9%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.608163 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.488328  [    4/  175]\n",
      "loss: 0.626784  [   84/  175]\n",
      "loss: 0.349916  [  164/  175]\n",
      "Training accuracy: 77.1%\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 0.466319 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.534828  [    4/  175]\n",
      "loss: 0.763459  [   84/  175]\n",
      "loss: 0.539408  [  164/  175]\n",
      "Training accuracy: 75.2%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 0.749911 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.451349  [    4/  175]\n",
      "loss: 0.873407  [   84/  175]\n",
      "loss: 0.355200  [  164/  175]\n",
      "Training accuracy: 79.0%\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.483850 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.360880  [    4/  175]\n",
      "loss: 0.615236  [   84/  175]\n",
      "loss: 0.473354  [  164/  175]\n",
      "Training accuracy: 78.8%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 0.735586 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.726844  [    4/  175]\n",
      "loss: 0.357210  [   84/  175]\n",
      "loss: 0.372506  [  164/  175]\n",
      "Training accuracy: 79.0%\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.648295 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.460811  [    4/  175]\n",
      "loss: 0.456087  [   84/  175]\n",
      "loss: 0.463769  [  164/  175]\n",
      "Training accuracy: 76.9%\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 0.566661 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.349544  [    4/  175]\n",
      "loss: 0.446116  [   84/  175]\n",
      "loss: 0.481920  [  164/  175]\n",
      "Training accuracy: 78.2%\n",
      "Test Error: \n",
      " Accuracy: 62.9%, Avg loss: 0.586730 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.506618  [    4/  175]\n",
      "loss: 0.377099  [   84/  175]\n",
      "loss: 0.546456  [  164/  175]\n",
      "Training accuracy: 79.9%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.114116 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.424944  [    4/  175]\n",
      "loss: 0.443247  [   84/  175]\n",
      "loss: 0.443343  [  164/  175]\n",
      "Training accuracy: 78.4%\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.253722 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.440134  [    4/  175]\n",
      "loss: 0.324805  [   84/  175]\n",
      "loss: 0.719209  [  164/  175]\n",
      "Training accuracy: 74.1%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 0.847953 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.475781  [    4/  175]\n",
      "loss: 0.369411  [   84/  175]\n",
      "loss: 0.950803  [  164/  175]\n",
      "Training accuracy: 75.8%\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.446960 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.536770  [    4/  175]\n",
      "loss: 0.444760  [   84/  175]\n",
      "loss: 0.445774  [  164/  175]\n",
      "Training accuracy: 80.5%\n",
      "Test Error: \n",
      " Accuracy: 67.4%, Avg loss: 0.550005 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.273744  [    4/  175]\n",
      "loss: 0.350989  [   84/  175]\n",
      "loss: 0.460399  [  164/  175]\n",
      "Training accuracy: 76.9%\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.419870 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.407602  [    4/  175]\n",
      "loss: 0.277451  [   84/  175]\n",
      "loss: 0.649654  [  164/  175]\n",
      "Training accuracy: 82.8%\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.500498 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.417684  [    4/  175]\n",
      "loss: 0.382973  [   84/  175]\n",
      "loss: 0.403721  [  164/  175]\n",
      "Training accuracy: 79.9%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.811592 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.511167  [    4/  175]\n",
      "loss: 0.527271  [   84/  175]\n",
      "loss: 0.379957  [  164/  175]\n",
      "Training accuracy: 77.7%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.039493 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [1e-2, 7e-3, 5e-3, 3e-3, 2e-3, 1e-3]\n",
    "batch_size = 4\n",
    "epochs = 100\n",
    "\n",
    "log_dir = os.path.join(\"runs\", \"experiment_005\")\n",
    "shutil.rmtree(log_dir, ignore_errors=True)\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    model = ModelWithSimpleRnn().to(device)\n",
    "\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    print(f\"Training model with learning rate {learning_rate}...\")\n",
    "    log_subdir = os.path.join(log_dir, \"learning_rate_\" + str(learning_rate).replace(\".\", \"_\") + \"_\" + datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"))\n",
    "    tb = SummaryWriter(log_subdir)\n",
    "\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t}\\n-------------------------------\")\n",
    "        train_metrics = train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "        test_metrics = test_loop(test_dataloader, model, loss_fn)\n",
    "        tb.add_scalar(\"Loss/train\", train_metrics[\"loss\"], t)\n",
    "        tb.add_scalar(\"Accuracy/train\", train_metrics[\"acc\"], t)\n",
    "        tb.add_scalar(\"Loss/test\", test_metrics[\"loss\"], t)\n",
    "        tb.add_scalar(\"Accuracy/test\", test_metrics[\"acc\"], t)\n",
    "        for name, weight in model.named_parameters():\n",
    "            tb.add_histogram(f\"Weights/{name}\", weight, t)\n",
    "            tb.add_histogram(f\"Gradients/{name}\", weight.grad, t)\n",
    "\n",
    "    tb.close()\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reducing the learning rate doesn't seem to help much. With the smaller learning rates, the model still hits a plateau, but it takes longer to do so.\n",
    "\n",
    "Let's train a model with the original learning rate up to high accuracy and see which examples it misclassifies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with learning rate 0.01...\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "loss: 0.783997  [    4/  175]\n",
      "loss: 0.772090  [   84/  175]\n",
      "loss: 0.696193  [  164/  175]\n",
      "Training accuracy: 50.9%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 0.711370 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.618617  [    4/  175]\n",
      "loss: 0.564194  [   84/  175]\n",
      "loss: 0.548184  [  164/  175]\n",
      "Training accuracy: 50.4%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 0.709814 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.576809  [    4/  175]\n",
      "loss: 0.537328  [   84/  175]\n",
      "loss: 0.615767  [  164/  175]\n",
      "Training accuracy: 56.4%\n",
      "Test Error: \n",
      " Accuracy: 59.8%, Avg loss: 0.726111 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.600720  [    4/  175]\n",
      "loss: 0.614087  [   84/  175]\n",
      "loss: 0.442822  [  164/  175]\n",
      "Training accuracy: 65.9%\n",
      "Test Error: \n",
      " Accuracy: 49.2%, Avg loss: 0.740103 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.826048  [    4/  175]\n",
      "loss: 0.565614  [   84/  175]\n",
      "loss: 0.638182  [  164/  175]\n",
      "Training accuracy: 69.7%\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 0.614871 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.650104  [    4/  175]\n",
      "loss: 0.643999  [   84/  175]\n",
      "loss: 0.664469  [  164/  175]\n",
      "Training accuracy: 70.8%\n",
      "Test Error: \n",
      " Accuracy: 67.4%, Avg loss: 0.580400 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.789251  [    4/  175]\n",
      "loss: 0.382584  [   84/  175]\n",
      "loss: 0.940872  [  164/  175]\n",
      "Training accuracy: 73.9%\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.795073 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.470534  [    4/  175]\n",
      "loss: 0.559084  [   84/  175]\n",
      "loss: 0.493446  [  164/  175]\n",
      "Training accuracy: 69.7%\n",
      "Test Error: \n",
      " Accuracy: 59.8%, Avg loss: 0.779508 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.620220  [    4/  175]\n",
      "loss: 0.352547  [   84/  175]\n",
      "loss: 0.510729  [  164/  175]\n",
      "Training accuracy: 72.7%\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 0.932338 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.393987  [    4/  175]\n",
      "loss: 0.625011  [   84/  175]\n",
      "loss: 0.871755  [  164/  175]\n",
      "Training accuracy: 68.0%\n",
      "Test Error: \n",
      " Accuracy: 59.8%, Avg loss: 0.635465 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.593122  [    4/  175]\n",
      "loss: 0.674510  [   84/  175]\n",
      "loss: 0.332344  [  164/  175]\n",
      "Training accuracy: 73.1%\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 0.817626 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.816066  [    4/  175]\n",
      "loss: 0.702095  [   84/  175]\n",
      "loss: 0.853101  [  164/  175]\n",
      "Training accuracy: 70.6%\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.476145 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.480841  [    4/  175]\n",
      "loss: 0.472568  [   84/  175]\n",
      "loss: 0.374865  [  164/  175]\n",
      "Training accuracy: 76.7%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.173635 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.740811  [    4/  175]\n",
      "loss: 0.389401  [   84/  175]\n",
      "loss: 0.797225  [  164/  175]\n",
      "Training accuracy: 78.6%\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 0.559551 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.509490  [    4/  175]\n",
      "loss: 0.679397  [   84/  175]\n",
      "loss: 0.752421  [  164/  175]\n",
      "Training accuracy: 71.6%\n",
      "Test Error: \n",
      " Accuracy: 63.6%, Avg loss: 0.952663 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.490960  [    4/  175]\n",
      "loss: 0.225930  [   84/  175]\n",
      "loss: 0.336447  [  164/  175]\n",
      "Training accuracy: 77.7%\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 0.500105 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.348909  [    4/  175]\n",
      "loss: 0.797308  [   84/  175]\n",
      "loss: 0.217809  [  164/  175]\n",
      "Training accuracy: 84.7%\n",
      "Test Error: \n",
      " Accuracy: 68.9%, Avg loss: 0.570726 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.631913  [    4/  175]\n",
      "loss: 0.369235  [   84/  175]\n",
      "loss: 0.289079  [  164/  175]\n",
      "Training accuracy: 82.2%\n",
      "Test Error: \n",
      " Accuracy: 64.4%, Avg loss: 1.029136 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.357406  [    4/  175]\n",
      "loss: 0.252493  [   84/  175]\n",
      "loss: 0.529122  [  164/  175]\n",
      "Training accuracy: 86.6%\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.290981 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.336124  [    4/  175]\n",
      "loss: 0.248744  [   84/  175]\n",
      "loss: 0.581971  [  164/  175]\n",
      "Training accuracy: 87.9%\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.785038 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.185259  [    4/  175]\n",
      "loss: 0.236433  [   84/  175]\n",
      "loss: 0.285197  [  164/  175]\n",
      "Training accuracy: 86.2%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.278839 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.372547  [    4/  175]\n",
      "loss: 0.321935  [   84/  175]\n",
      "loss: 0.231545  [  164/  175]\n",
      "Training accuracy: 83.5%\n",
      "Test Error: \n",
      " Accuracy: 94.7%, Avg loss: 0.234191 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.161621  [    4/  175]\n",
      "loss: 0.244392  [   84/  175]\n",
      "loss: 0.082313  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.210957 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.803667  [    4/  175]\n",
      "loss: 0.847183  [   84/  175]\n",
      "loss: 0.187305  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.167863 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.203718  [    4/  175]\n",
      "loss: 0.127409  [   84/  175]\n",
      "loss: 0.831764  [  164/  175]\n",
      "Training accuracy: 87.1%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.120527 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.419330  [    4/  175]\n",
      "loss: 0.252633  [   84/  175]\n",
      "loss: 0.093859  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.123287 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.093173  [    4/  175]\n",
      "loss: 0.062637  [   84/  175]\n",
      "loss: 0.083835  [  164/  175]\n",
      "Training accuracy: 89.8%\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.173940 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.182699  [    4/  175]\n",
      "loss: 0.192096  [   84/  175]\n",
      "loss: 0.139137  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.129223 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.292756  [    4/  175]\n",
      "loss: 0.249772  [   84/  175]\n",
      "loss: 0.084305  [  164/  175]\n",
      "Training accuracy: 94.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.084299 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.137103  [    4/  175]\n",
      "loss: 0.166954  [   84/  175]\n",
      "loss: 0.114656  [  164/  175]\n",
      "Training accuracy: 95.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.081433 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.129429  [    4/  175]\n",
      "loss: 0.044839  [   84/  175]\n",
      "loss: 0.037934  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.183639 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.209719  [    4/  175]\n",
      "loss: 0.123864  [   84/  175]\n",
      "loss: 0.116078  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.076302 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.068333  [    4/  175]\n",
      "loss: 0.077604  [   84/  175]\n",
      "loss: 0.274324  [  164/  175]\n",
      "Training accuracy: 89.6%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.199251 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.039963  [    4/  175]\n",
      "loss: 0.145107  [   84/  175]\n",
      "loss: 0.268530  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.167890 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.154149  [    4/  175]\n",
      "loss: 0.173528  [   84/  175]\n",
      "loss: 0.032810  [  164/  175]\n",
      "Training accuracy: 93.9%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.180007 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.075839  [    4/  175]\n",
      "loss: 0.060444  [   84/  175]\n",
      "loss: 0.108411  [  164/  175]\n",
      "Training accuracy: 90.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.074326 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.194704  [    4/  175]\n",
      "loss: 0.147602  [   84/  175]\n",
      "loss: 0.169117  [  164/  175]\n",
      "Training accuracy: 97.2%\n",
      "Test Error: \n",
      " Accuracy: 94.7%, Avg loss: 0.187903 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 1.034073  [    4/  175]\n",
      "loss: 0.027041  [   84/  175]\n",
      "loss: 0.111592  [  164/  175]\n",
      "Training accuracy: 89.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.076086 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.022016  [    4/  175]\n",
      "loss: 0.732423  [   84/  175]\n",
      "loss: 0.037932  [  164/  175]\n",
      "Training accuracy: 95.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.054551 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.299398  [    4/  175]\n",
      "loss: 0.146297  [   84/  175]\n",
      "loss: 0.113377  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.084180 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.152059  [    4/  175]\n",
      "loss: 0.020697  [   84/  175]\n",
      "loss: 0.100179  [  164/  175]\n",
      "Training accuracy: 95.5%\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 0.492980 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.077343  [    4/  175]\n",
      "loss: 0.109845  [   84/  175]\n",
      "loss: 1.014618  [  164/  175]\n",
      "Training accuracy: 88.6%\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.963704 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.140936  [    4/  175]\n",
      "loss: 0.036292  [   84/  175]\n",
      "loss: 0.075802  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.091456 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.803732  [    4/  175]\n",
      "loss: 0.064682  [   84/  175]\n",
      "loss: 0.193173  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.074480 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.220766  [    4/  175]\n",
      "loss: 0.086000  [   84/  175]\n",
      "loss: 0.125365  [  164/  175]\n",
      "Training accuracy: 93.4%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.033533 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.028848  [    4/  175]\n",
      "loss: 0.028170  [   84/  175]\n",
      "loss: 0.192763  [  164/  175]\n",
      "Training accuracy: 95.3%\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 2.288712 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.018902  [    4/  175]\n",
      "loss: 0.169775  [   84/  175]\n",
      "loss: 0.103570  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.042585 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.025262  [    4/  175]\n",
      "loss: 0.035929  [   84/  175]\n",
      "loss: 0.032629  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.025908 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.019571  [    4/  175]\n",
      "loss: 0.019814  [   84/  175]\n",
      "loss: 0.291412  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.179729 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.095357  [    4/  175]\n",
      "loss: 0.957183  [   84/  175]\n",
      "loss: 0.776994  [  164/  175]\n",
      "Training accuracy: 91.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.023039 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.086416  [    4/  175]\n",
      "loss: 0.161192  [   84/  175]\n",
      "loss: 0.011844  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.026704 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.392458  [    4/  175]\n",
      "loss: 0.096934  [   84/  175]\n",
      "loss: 0.051873  [  164/  175]\n",
      "Training accuracy: 94.1%\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 0.500555 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.022348  [    4/  175]\n",
      "loss: 0.084096  [   84/  175]\n",
      "loss: 0.103756  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.120676 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.117053  [    4/  175]\n",
      "loss: 0.236426  [   84/  175]\n",
      "loss: 0.023656  [  164/  175]\n",
      "Training accuracy: 89.8%\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 5.411217 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.170703  [    4/  175]\n",
      "loss: 0.011817  [   84/  175]\n",
      "loss: 0.021957  [  164/  175]\n",
      "Training accuracy: 87.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.051433 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.121251  [    4/  175]\n",
      "loss: 0.072626  [   84/  175]\n",
      "loss: 0.067805  [  164/  175]\n",
      "Training accuracy: 96.4%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.056257 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.054048  [    4/  175]\n",
      "loss: 0.010328  [   84/  175]\n",
      "loss: 0.066005  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.030265 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.149700  [    4/  175]\n",
      "loss: 0.170838  [   84/  175]\n",
      "loss: 0.008901  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.022505 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.053311  [    4/  175]\n",
      "loss: 0.073673  [   84/  175]\n",
      "loss: 0.180554  [  164/  175]\n",
      "Training accuracy: 97.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.076732 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.083864  [    4/  175]\n",
      "loss: 0.010024  [   84/  175]\n",
      "loss: 0.009212  [  164/  175]\n",
      "Training accuracy: 91.1%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.080086 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.158819  [    4/  175]\n",
      "loss: 0.051845  [   84/  175]\n",
      "loss: 0.777755  [  164/  175]\n",
      "Training accuracy: 89.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.017437 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.007903  [    4/  175]\n",
      "loss: 0.080642  [   84/  175]\n",
      "loss: 0.074864  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.025531 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.069874  [    4/  175]\n",
      "loss: 0.074836  [   84/  175]\n",
      "loss: 0.120418  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.035283 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.883331  [    4/  175]\n",
      "loss: 0.049974  [   84/  175]\n",
      "loss: 0.011515  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.172660 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.060388  [    4/  175]\n",
      "loss: 0.089063  [   84/  175]\n",
      "loss: 0.986057  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.156102 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.222881  [    4/  175]\n",
      "loss: 0.335449  [   84/  175]\n",
      "loss: 0.272523  [  164/  175]\n",
      "Training accuracy: 86.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.033704 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.057369  [    4/  175]\n",
      "loss: 0.112210  [   84/  175]\n",
      "loss: 0.009433  [  164/  175]\n",
      "Training accuracy: 95.1%\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.387002 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.011567  [    4/  175]\n",
      "loss: 0.901797  [   84/  175]\n",
      "loss: 0.009634  [  164/  175]\n",
      "Training accuracy: 89.8%\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.222950 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 1.026358  [    4/  175]\n",
      "loss: 0.181933  [   84/  175]\n",
      "loss: 0.095362  [  164/  175]\n",
      "Training accuracy: 91.9%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.119013 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.009695  [    4/  175]\n",
      "loss: 0.257340  [   84/  175]\n",
      "loss: 0.887268  [  164/  175]\n",
      "Training accuracy: 91.7%\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.242810 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.189405  [    4/  175]\n",
      "loss: 0.111605  [   84/  175]\n",
      "loss: 0.737590  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.018932 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.064753  [    4/  175]\n",
      "loss: 0.114350  [   84/  175]\n",
      "loss: 0.010265  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.028107 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.064841  [    4/  175]\n",
      "loss: 0.011128  [   84/  175]\n",
      "loss: 0.665784  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 0.617704 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.066470  [    4/  175]\n",
      "loss: 0.977426  [   84/  175]\n",
      "loss: 0.015648  [  164/  175]\n",
      "Training accuracy: 89.6%\n",
      "Test Error: \n",
      " Accuracy: 63.6%, Avg loss: 1.258424 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.801293  [    4/  175]\n",
      "loss: 1.103480  [   84/  175]\n",
      "loss: 0.235658  [  164/  175]\n",
      "Training accuracy: 87.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.029090 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.009096  [    4/  175]\n",
      "loss: 0.086234  [   84/  175]\n",
      "loss: 0.107668  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.025700 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.006165  [    4/  175]\n",
      "loss: 0.011145  [   84/  175]\n",
      "loss: 0.006794  [  164/  175]\n",
      "Training accuracy: 91.7%\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.285910 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 1.058802  [    4/  175]\n",
      "loss: 0.049768  [   84/  175]\n",
      "loss: 0.118440  [  164/  175]\n",
      "Training accuracy: 97.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.026784 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.019019  [    4/  175]\n",
      "loss: 0.070063  [   84/  175]\n",
      "loss: 0.005994  [  164/  175]\n",
      "Training accuracy: 96.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.013085 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.064946  [    4/  175]\n",
      "loss: 0.161841  [   84/  175]\n",
      "loss: 0.065571  [  164/  175]\n",
      "Training accuracy: 97.0%\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 5.540774 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.070850  [    4/  175]\n",
      "loss: 0.006035  [   84/  175]\n",
      "loss: 0.061507  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.170540 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.795058  [    4/  175]\n",
      "loss: 0.090918  [   84/  175]\n",
      "loss: 0.032492  [  164/  175]\n",
      "Training accuracy: 94.7%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 2.068575 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.052825  [    4/  175]\n",
      "loss: 0.011594  [   84/  175]\n",
      "loss: 0.005206  [  164/  175]\n",
      "Training accuracy: 94.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.012007 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.070631  [    4/  175]\n",
      "loss: 0.005795  [   84/  175]\n",
      "loss: 0.885151  [  164/  175]\n",
      "Training accuracy: 86.9%\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.332444 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.783591  [    4/  175]\n",
      "loss: 0.069339  [   84/  175]\n",
      "loss: 0.089550  [  164/  175]\n",
      "Training accuracy: 94.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.016407 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.005467  [    4/  175]\n",
      "loss: 0.074610  [   84/  175]\n",
      "loss: 0.124882  [  164/  175]\n",
      "Training accuracy: 88.3%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 0.810037 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.052390  [    4/  175]\n",
      "loss: 0.065394  [   84/  175]\n",
      "loss: 0.106114  [  164/  175]\n",
      "Training accuracy: 89.4%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.035477 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.070296  [    4/  175]\n",
      "loss: 0.065389  [   84/  175]\n",
      "loss: 0.015372  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 0.962441 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.968758  [    4/  175]\n",
      "loss: 0.020067  [   84/  175]\n",
      "loss: 0.008696  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.033783 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.074785  [    4/  175]\n",
      "loss: 0.012498  [   84/  175]\n",
      "loss: 0.008584  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.014068 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.944087  [    4/  175]\n",
      "loss: 0.037368  [   84/  175]\n",
      "loss: 0.106662  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 63.6%, Avg loss: 0.946814 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.009768  [    4/  175]\n",
      "loss: 0.107758  [   84/  175]\n",
      "loss: 0.954306  [  164/  175]\n",
      "Training accuracy: 97.2%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 0.960498 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.004848  [    4/  175]\n",
      "loss: 0.064946  [   84/  175]\n",
      "loss: 0.069761  [  164/  175]\n",
      "Training accuracy: 89.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.019063 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.159548  [    4/  175]\n",
      "loss: 1.265353  [   84/  175]\n",
      "loss: 1.091430  [  164/  175]\n",
      "Training accuracy: 90.5%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 3.814194 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.005537  [    4/  175]\n",
      "loss: 0.006285  [   84/  175]\n",
      "loss: 0.007742  [  164/  175]\n",
      "Training accuracy: 93.4%\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.364441 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.032814  [    4/  175]\n",
      "loss: 0.925456  [   84/  175]\n",
      "loss: 0.073170  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 0.607729 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.014548  [    4/  175]\n",
      "loss: 0.064110  [   84/  175]\n",
      "loss: 0.007389  [  164/  175]\n",
      "Training accuracy: 97.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.014378 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.045555  [    4/  175]\n",
      "loss: 0.067240  [   84/  175]\n",
      "loss: 0.009992  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.379738 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.007197  [    4/  175]\n",
      "loss: 0.039758  [   84/  175]\n",
      "loss: 0.841181  [  164/  175]\n",
      "Training accuracy: 95.5%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.123923 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.932349  [    4/  175]\n",
      "loss: 0.068365  [   84/  175]\n",
      "loss: 0.005539  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.181025 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-2\n",
    "batch_size = 4\n",
    "epochs = 100\n",
    "\n",
    "# log_dir = os.path.join(\"runs\", \"experiment_005\")\n",
    "# shutil.rmtree(log_dir, ignore_errors=True)\n",
    "\n",
    "model = ModelWithSimpleRnn().to(device)\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "print(f\"Training model with learning rate {learning_rate}...\")\n",
    "log_subdir = os.path.join(log_dir, \"check_failed_examples\" + \"_\" + datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"))\n",
    "tb = SummaryWriter(log_subdir)\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t}\\n-------------------------------\")\n",
    "    train_metrics = train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_metrics = test_loop(test_dataloader, model, loss_fn)\n",
    "    tb.add_scalar(\"Loss/train\", train_metrics[\"loss\"], t)\n",
    "    tb.add_scalar(\"Accuracy/train\", train_metrics[\"acc\"], t)\n",
    "    tb.add_scalar(\"Loss/test\", test_metrics[\"loss\"], t)\n",
    "    tb.add_scalar(\"Accuracy/test\", test_metrics[\"acc\"], t)\n",
    "    for name, weight in model.named_parameters():\n",
    "        tb.add_histogram(f\"Weights/{name}\", weight, t)\n",
    "        tb.add_histogram(f\"Gradients/{name}\", weight.grad, t)\n",
    "\n",
    "tb.close()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model failed on training examples [28, 35, 60, 65, 73, 138, 163].\n"
     ]
    }
   ],
   "source": [
    "# Find indices of all failed training predictions\n",
    "\n",
    "failed_train_idxs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx, (x, y) in enumerate(train_dataset):\n",
    "        pred = model(x.unsqueeze(0)).squeeze(0)\n",
    "        pred = (pred >= 0.0).type(torch.float)\n",
    "        correct = (pred == y).item()\n",
    "        if not correct:\n",
    "            failed_train_idxs.append(idx)\n",
    "\n",
    "print(f\"The model failed on training examples {failed_train_idxs}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct prediction: False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2670a4a7010>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = random.choice(failed_train_idxs)\n",
    "x, y = train_dataset[idx]\n",
    "print(f\"Correct prediction: {bool(y)}\")\n",
    "\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "axs = axs.flatten()\n",
    "\n",
    "axs[0].imshow(x[0])\n",
    "axs[1].imshow(x[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The failed training predictions are all when the block is fairly close to landing, but not quite there yet. This suggests that the model is starting to generalise correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model failed on test examples [2, 7, 21, 25].\n"
     ]
    }
   ],
   "source": [
    "# Find indices of all failed test predictions\n",
    "\n",
    "failed_test_idxs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx, (x, y) in enumerate(test_dataset):\n",
    "        pred = model(x.unsqueeze(0)).squeeze(0)\n",
    "        pred = (pred >= 0.0).type(torch.float)\n",
    "        correct = (pred == y).item()\n",
    "        if not correct:\n",
    "            failed_test_idxs.append(idx)\n",
    "\n",
    "print(f\"The model failed on test examples {failed_test_idxs}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct prediction: False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2670d39f880>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = random.choice(failed_test_idxs)\n",
    "x, y = test_dataset[idx]\n",
    "print(f\"Correct prediction: {bool(y)}\")\n",
    "\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "axs = axs.flatten()\n",
    "\n",
    "axs[0].imshow(x[0])\n",
    "axs[1].imshow(x[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Momentum\n",
    "\n",
    "Assuming the optimization is stuck in a local minimum, let's try and use momentum to help it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with momentum 0.0...\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "loss: 0.730849  [    4/  175]\n",
      "loss: 0.786646  [   84/  175]\n",
      "loss: 0.886391  [  164/  175]\n",
      "Training accuracy: 63.6%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 0.694215 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.564717  [    4/  175]\n",
      "loss: 0.471649  [   84/  175]\n",
      "loss: 0.493317  [  164/  175]\n",
      "Training accuracy: 65.0%\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 0.665658 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.779601  [    4/  175]\n",
      "loss: 0.653584  [   84/  175]\n",
      "loss: 0.680656  [  164/  175]\n",
      "Training accuracy: 67.0%\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 0.675457 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.569196  [    4/  175]\n",
      "loss: 0.503453  [   84/  175]\n",
      "loss: 0.791745  [  164/  175]\n",
      "Training accuracy: 68.2%\n",
      "Test Error: \n",
      " Accuracy: 64.4%, Avg loss: 0.724541 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.805988  [    4/  175]\n",
      "loss: 0.527514  [   84/  175]\n",
      "loss: 0.783933  [  164/  175]\n",
      "Training accuracy: 67.6%\n",
      "Test Error: \n",
      " Accuracy: 62.9%, Avg loss: 0.675165 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.708394  [    4/  175]\n",
      "loss: 0.557214  [   84/  175]\n",
      "loss: 0.516116  [  164/  175]\n",
      "Training accuracy: 69.9%\n",
      "Test Error: \n",
      " Accuracy: 65.2%, Avg loss: 0.669139 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.931804  [    4/  175]\n",
      "loss: 0.625836  [   84/  175]\n",
      "loss: 0.577757  [  164/  175]\n",
      "Training accuracy: 71.4%\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 0.724534 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.494270  [    4/  175]\n",
      "loss: 0.779247  [   84/  175]\n",
      "loss: 0.746504  [  164/  175]\n",
      "Training accuracy: 75.4%\n",
      "Test Error: \n",
      " Accuracy: 67.4%, Avg loss: 0.616360 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.691725  [    4/  175]\n",
      "loss: 0.617142  [   84/  175]\n",
      "loss: 0.777715  [  164/  175]\n",
      "Training accuracy: 77.3%\n",
      "Test Error: \n",
      " Accuracy: 67.4%, Avg loss: 0.580935 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.273282  [    4/  175]\n",
      "loss: 0.411427  [   84/  175]\n",
      "loss: 0.441004  [  164/  175]\n",
      "Training accuracy: 81.8%\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 0.501523 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.761349  [    4/  175]\n",
      "loss: 0.410381  [   84/  175]\n",
      "loss: 0.706701  [  164/  175]\n",
      "Training accuracy: 79.5%\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 0.452310 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.323721  [    4/  175]\n",
      "loss: 0.563046  [   84/  175]\n",
      "loss: 0.388691  [  164/  175]\n",
      "Training accuracy: 84.7%\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 0.470403 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.987031  [    4/  175]\n",
      "loss: 0.240054  [   84/  175]\n",
      "loss: 0.261659  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.403166 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.932638  [    4/  175]\n",
      "loss: 0.551939  [   84/  175]\n",
      "loss: 0.427271  [  164/  175]\n",
      "Training accuracy: 83.9%\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.374812 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.291453  [    4/  175]\n",
      "loss: 0.269220  [   84/  175]\n",
      "loss: 0.184354  [  164/  175]\n",
      "Training accuracy: 88.1%\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.375072 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.199722  [    4/  175]\n",
      "loss: 0.512077  [   84/  175]\n",
      "loss: 0.183345  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.329282 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.112373  [    4/  175]\n",
      "loss: 0.171636  [   84/  175]\n",
      "loss: 0.435386  [  164/  175]\n",
      "Training accuracy: 90.7%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.222479 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.297675  [    4/  175]\n",
      "loss: 0.721777  [   84/  175]\n",
      "loss: 0.279722  [  164/  175]\n",
      "Training accuracy: 88.3%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.305475 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.243139  [    4/  175]\n",
      "loss: 0.076374  [   84/  175]\n",
      "loss: 0.209692  [  164/  175]\n",
      "Training accuracy: 91.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.199265 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.112465  [    4/  175]\n",
      "loss: 0.217193  [   84/  175]\n",
      "loss: 0.209510  [  164/  175]\n",
      "Training accuracy: 89.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.159023 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.098757  [    4/  175]\n",
      "loss: 0.730030  [   84/  175]\n",
      "loss: 0.101832  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.239184 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.085974  [    4/  175]\n",
      "loss: 0.213164  [   84/  175]\n",
      "loss: 0.160005  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.154987 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.706573  [    4/  175]\n",
      "loss: 0.238530  [   84/  175]\n",
      "loss: 0.196889  [  164/  175]\n",
      "Training accuracy: 89.8%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.238516 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.224699  [    4/  175]\n",
      "loss: 0.798850  [   84/  175]\n",
      "loss: 0.257044  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.124560 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.134072  [    4/  175]\n",
      "loss: 0.222341  [   84/  175]\n",
      "loss: 0.087561  [  164/  175]\n",
      "Training accuracy: 88.3%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.183399 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.069258  [    4/  175]\n",
      "loss: 0.156967  [   84/  175]\n",
      "loss: 0.075124  [  164/  175]\n",
      "Training accuracy: 92.2%\n",
      "Test Error: \n",
      " Accuracy: 66.7%, Avg loss: 0.473253 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.072207  [    4/  175]\n",
      "loss: 0.782075  [   84/  175]\n",
      "loss: 0.128553  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.085364 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.046614  [    4/  175]\n",
      "loss: 0.262602  [   84/  175]\n",
      "loss: 0.211681  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.199985 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.190833  [    4/  175]\n",
      "loss: 0.190233  [   84/  175]\n",
      "loss: 0.072548  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.176704 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.760377  [    4/  175]\n",
      "loss: 0.129690  [   84/  175]\n",
      "loss: 0.710468  [  164/  175]\n",
      "Training accuracy: 84.5%\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.257829 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.413321  [    4/  175]\n",
      "loss: 0.050857  [   84/  175]\n",
      "loss: 0.088240  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.163505 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.137285  [    4/  175]\n",
      "loss: 0.140205  [   84/  175]\n",
      "loss: 0.307125  [  164/  175]\n",
      "Training accuracy: 92.4%\n",
      "Test Error: \n",
      " Accuracy: 57.6%, Avg loss: 0.615126 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.096264  [    4/  175]\n",
      "loss: 0.132187  [   84/  175]\n",
      "loss: 0.057856  [  164/  175]\n",
      "Training accuracy: 94.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.072662 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.213030  [    4/  175]\n",
      "loss: 0.062768  [   84/  175]\n",
      "loss: 0.363638  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.088150 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.170772  [    4/  175]\n",
      "loss: 0.993603  [   84/  175]\n",
      "loss: 0.103195  [  164/  175]\n",
      "Training accuracy: 85.2%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.489645 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.036464  [    4/  175]\n",
      "loss: 1.171165  [   84/  175]\n",
      "loss: 0.040754  [  164/  175]\n",
      "Training accuracy: 88.1%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.102195 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.052562  [    4/  175]\n",
      "loss: 0.707257  [   84/  175]\n",
      "loss: 1.530849  [  164/  175]\n",
      "Training accuracy: 85.0%\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 1.352726 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.155868  [    4/  175]\n",
      "loss: 0.115489  [   84/  175]\n",
      "loss: 0.245066  [  164/  175]\n",
      "Training accuracy: 86.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.246527 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.725036  [    4/  175]\n",
      "loss: 0.097293  [   84/  175]\n",
      "loss: 0.045119  [  164/  175]\n",
      "Training accuracy: 88.1%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.066150 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.214928  [    4/  175]\n",
      "loss: 0.186928  [   84/  175]\n",
      "loss: 0.029247  [  164/  175]\n",
      "Training accuracy: 94.9%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.056174 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.027457  [    4/  175]\n",
      "loss: 0.021583  [   84/  175]\n",
      "loss: 0.105340  [  164/  175]\n",
      "Training accuracy: 95.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.061795 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.063558  [    4/  175]\n",
      "loss: 0.234369  [   84/  175]\n",
      "loss: 0.016555  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.079918 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.036272  [    4/  175]\n",
      "loss: 0.114601  [   84/  175]\n",
      "loss: 0.018831  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.076553 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.084884  [    4/  175]\n",
      "loss: 0.060238  [   84/  175]\n",
      "loss: 0.016943  [  164/  175]\n",
      "Training accuracy: 89.8%\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.072475 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.086440  [    4/  175]\n",
      "loss: 0.018086  [   84/  175]\n",
      "loss: 0.097769  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.075741 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.100344  [    4/  175]\n",
      "loss: 0.016299  [   84/  175]\n",
      "loss: 0.027401  [  164/  175]\n",
      "Training accuracy: 98.3%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.210029 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.021402  [    4/  175]\n",
      "loss: 0.067851  [   84/  175]\n",
      "loss: 0.310308  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.043114 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.076551  [    4/  175]\n",
      "loss: 0.013609  [   84/  175]\n",
      "loss: 0.050844  [  164/  175]\n",
      "Training accuracy: 89.2%\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.075417 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.080952  [    4/  175]\n",
      "loss: 0.185075  [   84/  175]\n",
      "loss: 0.050255  [  164/  175]\n",
      "Training accuracy: 91.7%\n",
      "Test Error: \n",
      " Accuracy: 49.2%, Avg loss: 0.804660 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.021589  [    4/  175]\n",
      "loss: 0.023124  [   84/  175]\n",
      "loss: 0.464259  [  164/  175]\n",
      "Training accuracy: 92.8%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.097068 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.765750  [    4/  175]\n",
      "loss: 0.071170  [   84/  175]\n",
      "loss: 0.071628  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.067985 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.021718  [    4/  175]\n",
      "loss: 0.832670  [   84/  175]\n",
      "loss: 0.898201  [  164/  175]\n",
      "Training accuracy: 88.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.096582 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.087861  [    4/  175]\n",
      "loss: 0.039238  [   84/  175]\n",
      "loss: 0.087283  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.049728 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.080021  [    4/  175]\n",
      "loss: 0.075076  [   84/  175]\n",
      "loss: 0.104110  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.027621 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.066052  [    4/  175]\n",
      "loss: 0.045400  [   84/  175]\n",
      "loss: 0.011193  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.036697 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.072370  [    4/  175]\n",
      "loss: 0.007008  [   84/  175]\n",
      "loss: 0.112148  [  164/  175]\n",
      "Training accuracy: 89.0%\n",
      "Test Error: \n",
      " Accuracy: 57.6%, Avg loss: 0.468307 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.155319  [    4/  175]\n",
      "loss: 0.197573  [   84/  175]\n",
      "loss: 0.103854  [  164/  175]\n",
      "Training accuracy: 87.9%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.190254 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.040308  [    4/  175]\n",
      "loss: 0.108989  [   84/  175]\n",
      "loss: 0.040328  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.061309 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.029717  [    4/  175]\n",
      "loss: 0.078266  [   84/  175]\n",
      "loss: 0.068746  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.112297 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.151918  [    4/  175]\n",
      "loss: 0.073212  [   84/  175]\n",
      "loss: 0.139983  [  164/  175]\n",
      "Training accuracy: 89.8%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.137356 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.075442  [    4/  175]\n",
      "loss: 0.118596  [   84/  175]\n",
      "loss: 0.171630  [  164/  175]\n",
      "Training accuracy: 91.7%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.059439 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.941873  [    4/  175]\n",
      "loss: 0.043391  [   84/  175]\n",
      "loss: 0.024147  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.144966 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.043456  [    4/  175]\n",
      "loss: 0.112242  [   84/  175]\n",
      "loss: 0.119758  [  164/  175]\n",
      "Training accuracy: 88.6%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.131398 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.037328  [    4/  175]\n",
      "loss: 0.987361  [   84/  175]\n",
      "loss: 0.096999  [  164/  175]\n",
      "Training accuracy: 89.6%\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 2.470773 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.052776  [    4/  175]\n",
      "loss: 0.088196  [   84/  175]\n",
      "loss: 0.062815  [  164/  175]\n",
      "Training accuracy: 90.7%\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.039175 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.109930  [    4/  175]\n",
      "loss: 0.203011  [   84/  175]\n",
      "loss: 0.032953  [  164/  175]\n",
      "Training accuracy: 89.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.051397 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.156809  [    4/  175]\n",
      "loss: 1.101330  [   84/  175]\n",
      "loss: 0.027441  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.058767 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.048785  [    4/  175]\n",
      "loss: 0.136030  [   84/  175]\n",
      "loss: 0.092795  [  164/  175]\n",
      "Training accuracy: 93.4%\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 0.431241 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.025802  [    4/  175]\n",
      "loss: 0.852376  [   84/  175]\n",
      "loss: 0.089611  [  164/  175]\n",
      "Training accuracy: 91.1%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.093581 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.135005  [    4/  175]\n",
      "loss: 0.079369  [   84/  175]\n",
      "loss: 1.253567  [  164/  175]\n",
      "Training accuracy: 91.7%\n",
      "Test Error: \n",
      " Accuracy: 52.3%, Avg loss: 7.127409 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.354122  [    4/  175]\n",
      "loss: 0.010168  [   84/  175]\n",
      "loss: 0.038278  [  164/  175]\n",
      "Training accuracy: 89.8%\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.049520 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.092725  [    4/  175]\n",
      "loss: 0.013521  [   84/  175]\n",
      "loss: 0.076441  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 0.527851 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.018050  [    4/  175]\n",
      "loss: 1.395253  [   84/  175]\n",
      "loss: 0.037349  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.258200 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.030601  [    4/  175]\n",
      "loss: 0.010915  [   84/  175]\n",
      "loss: 0.019200  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.404105 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.012368  [    4/  175]\n",
      "loss: 0.085456  [   84/  175]\n",
      "loss: 0.358113  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.069615 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.165476  [    4/  175]\n",
      "loss: 0.797877  [   84/  175]\n",
      "loss: 0.007068  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.117270 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.152416  [    4/  175]\n",
      "loss: 0.014197  [   84/  175]\n",
      "loss: 0.343759  [  164/  175]\n",
      "Training accuracy: 94.9%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.720333 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.027528  [    4/  175]\n",
      "loss: 0.017018  [   84/  175]\n",
      "loss: 0.034838  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.035944 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.138666  [    4/  175]\n",
      "loss: 0.219835  [   84/  175]\n",
      "loss: 0.076677  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.034581 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.789653  [    4/  175]\n",
      "loss: 0.040235  [   84/  175]\n",
      "loss: 0.110848  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 3.983195 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.024041  [    4/  175]\n",
      "loss: 0.017401  [   84/  175]\n",
      "loss: 0.008593  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.025924 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 1.208219  [    4/  175]\n",
      "loss: 0.122071  [   84/  175]\n",
      "loss: 0.210892  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 62.1%, Avg loss: 0.917455 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.017236  [    4/  175]\n",
      "loss: 0.023883  [   84/  175]\n",
      "loss: 0.050094  [  164/  175]\n",
      "Training accuracy: 95.5%\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.059826 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.091664  [    4/  175]\n",
      "loss: 0.065255  [   84/  175]\n",
      "loss: 0.151835  [  164/  175]\n",
      "Training accuracy: 86.2%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 2.670989 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.097954  [    4/  175]\n",
      "loss: 0.013667  [   84/  175]\n",
      "loss: 0.838805  [  164/  175]\n",
      "Training accuracy: 89.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.030263 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.013846  [    4/  175]\n",
      "loss: 0.013206  [   84/  175]\n",
      "loss: 0.006090  [  164/  175]\n",
      "Training accuracy: 93.9%\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 3.416022 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.994548  [    4/  175]\n",
      "loss: 0.889398  [   84/  175]\n",
      "loss: 0.152096  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 2.994951 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.050513  [    4/  175]\n",
      "loss: 0.103357  [   84/  175]\n",
      "loss: 0.106847  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 3.588373 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.053126  [    4/  175]\n",
      "loss: 0.017275  [   84/  175]\n",
      "loss: 0.018947  [  164/  175]\n",
      "Training accuracy: 90.0%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.039341 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.047433  [    4/  175]\n",
      "loss: 0.013870  [   84/  175]\n",
      "loss: 0.297757  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.175205 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.037325  [    4/  175]\n",
      "loss: 0.011947  [   84/  175]\n",
      "loss: 0.097314  [  164/  175]\n",
      "Training accuracy: 96.0%\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.252239 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.795923  [    4/  175]\n",
      "loss: 0.029254  [   84/  175]\n",
      "loss: 0.067314  [  164/  175]\n",
      "Training accuracy: 89.2%\n",
      "Test Error: \n",
      " Accuracy: 67.4%, Avg loss: 0.758263 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.008271  [    4/  175]\n",
      "loss: 0.006347  [   84/  175]\n",
      "loss: 0.185483  [  164/  175]\n",
      "Training accuracy: 94.9%\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 1.476021 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.087861  [    4/  175]\n",
      "loss: 0.070587  [   84/  175]\n",
      "loss: 0.132300  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.302307 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.047929  [    4/  175]\n",
      "loss: 0.092125  [   84/  175]\n",
      "loss: 0.760225  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.043211 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.009753  [    4/  175]\n",
      "loss: 0.010638  [   84/  175]\n",
      "loss: 0.063528  [  164/  175]\n",
      "Training accuracy: 96.0%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.137924 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.061892  [    4/  175]\n",
      "loss: 0.058281  [   84/  175]\n",
      "loss: 0.031222  [  164/  175]\n",
      "Training accuracy: 94.1%\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 6.772711 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.151674  [    4/  175]\n",
      "loss: 0.024290  [   84/  175]\n",
      "loss: 0.011717  [  164/  175]\n",
      "Training accuracy: 92.8%\n",
      "Test Error: \n",
      " Accuracy: 72.7%, Avg loss: 0.422803 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.823656  [    4/  175]\n",
      "loss: 0.120995  [   84/  175]\n",
      "loss: 0.119928  [  164/  175]\n",
      "Training accuracy: 89.4%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 8.166576 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.050375  [    4/  175]\n",
      "loss: 0.103034  [   84/  175]\n",
      "loss: 0.193241  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.062879 \n",
      "\n",
      "Done!\n",
      "Training model with momentum 0.9...\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "loss: 0.545926  [    4/  175]\n",
      "loss: 0.886642  [   84/  175]\n",
      "loss: 0.702847  [  164/  175]\n",
      "Training accuracy: 66.5%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 0.696593 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.698224  [    4/  175]\n",
      "loss: 0.577822  [   84/  175]\n",
      "loss: 0.439254  [  164/  175]\n",
      "Training accuracy: 75.6%\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 1.184076 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.454507  [    4/  175]\n",
      "loss: 0.392493  [   84/  175]\n",
      "loss: 1.049498  [  164/  175]\n",
      "Training accuracy: 89.4%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.777358 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.147379  [    4/  175]\n",
      "loss: 0.176279  [   84/  175]\n",
      "loss: 0.204190  [  164/  175]\n",
      "Training accuracy: 89.8%\n",
      "Test Error: \n",
      " Accuracy: 56.8%, Avg loss: 0.865368 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.106590  [    4/  175]\n",
      "loss: 0.283631  [   84/  175]\n",
      "loss: 0.015101  [  164/  175]\n",
      "Training accuracy: 88.1%\n",
      "Test Error: \n",
      " Accuracy: 49.2%, Avg loss: 0.946514 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.087810  [    4/  175]\n",
      "loss: 0.891329  [   84/  175]\n",
      "loss: 0.073868  [  164/  175]\n",
      "Training accuracy: 85.0%\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 2.527000 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.259983  [    4/  175]\n",
      "loss: 0.403807  [   84/  175]\n",
      "loss: 0.309516  [  164/  175]\n",
      "Training accuracy: 83.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.192444 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.100394  [    4/  175]\n",
      "loss: 0.032569  [   84/  175]\n",
      "loss: 0.115385  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.309708 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.091236  [    4/  175]\n",
      "loss: 0.318494  [   84/  175]\n",
      "loss: 0.319028  [  164/  175]\n",
      "Training accuracy: 87.5%\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.018806 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.014170  [    4/  175]\n",
      "loss: 0.951647  [   84/  175]\n",
      "loss: 0.859157  [  164/  175]\n",
      "Training accuracy: 80.7%\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.260894 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.141254  [    4/  175]\n",
      "loss: 0.089685  [   84/  175]\n",
      "loss: 0.141307  [  164/  175]\n",
      "Training accuracy: 88.6%\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.153619 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.689917  [    4/  175]\n",
      "loss: 0.027724  [   84/  175]\n",
      "loss: 1.372288  [  164/  175]\n",
      "Training accuracy: 88.1%\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 4.020489 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.183174  [    4/  175]\n",
      "loss: 0.228659  [   84/  175]\n",
      "loss: 0.148921  [  164/  175]\n",
      "Training accuracy: 89.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.073233 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.396294  [    4/  175]\n",
      "loss: 0.030050  [   84/  175]\n",
      "loss: 1.279102  [  164/  175]\n",
      "Training accuracy: 88.6%\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.179810 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.159903  [    4/  175]\n",
      "loss: 0.026176  [   84/  175]\n",
      "loss: 0.141954  [  164/  175]\n",
      "Training accuracy: 89.2%\n",
      "Test Error: \n",
      " Accuracy: 52.3%, Avg loss: 2.105753 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.813385  [    4/  175]\n",
      "loss: 0.033128  [   84/  175]\n",
      "loss: 0.092357  [  164/  175]\n",
      "Training accuracy: 88.8%\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.306301 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 1.061691  [    4/  175]\n",
      "loss: 0.088831  [   84/  175]\n",
      "loss: 0.100576  [  164/  175]\n",
      "Training accuracy: 91.3%\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 3.001163 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.044688  [    4/  175]\n",
      "loss: 0.141299  [   84/  175]\n",
      "loss: 0.039288  [  164/  175]\n",
      "Training accuracy: 91.3%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 5.677019 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.162623  [    4/  175]\n",
      "loss: 1.181637  [   84/  175]\n",
      "loss: 0.089235  [  164/  175]\n",
      "Training accuracy: 87.3%\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 4.504805 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.037062  [    4/  175]\n",
      "loss: 0.151970  [   84/  175]\n",
      "loss: 0.119278  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.116165 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.038569  [    4/  175]\n",
      "loss: 1.578136  [   84/  175]\n",
      "loss: 0.058507  [  164/  175]\n",
      "Training accuracy: 85.8%\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 3.465490 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.146688  [    4/  175]\n",
      "loss: 0.064897  [   84/  175]\n",
      "loss: 0.038697  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.021996 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 1.084082  [    4/  175]\n",
      "loss: 0.095199  [   84/  175]\n",
      "loss: 0.110128  [  164/  175]\n",
      "Training accuracy: 83.3%\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.376019 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.099027  [    4/  175]\n",
      "loss: 0.158611  [   84/  175]\n",
      "loss: 0.084656  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.527119 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 1.130109  [    4/  175]\n",
      "loss: 0.154313  [   84/  175]\n",
      "loss: 0.007897  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 49.2%, Avg loss: 1.193277 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.013940  [    4/  175]\n",
      "loss: 1.048023  [   84/  175]\n",
      "loss: 0.025947  [  164/  175]\n",
      "Training accuracy: 88.3%\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.183822 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.004972  [    4/  175]\n",
      "loss: 0.053401  [   84/  175]\n",
      "loss: 0.113449  [  164/  175]\n",
      "Training accuracy: 89.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.025358 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.008076  [    4/  175]\n",
      "loss: 0.040718  [   84/  175]\n",
      "loss: 0.107086  [  164/  175]\n",
      "Training accuracy: 94.5%\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 1.050453 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.006664  [    4/  175]\n",
      "loss: 0.946000  [   84/  175]\n",
      "loss: 0.099738  [  164/  175]\n",
      "Training accuracy: 88.1%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 9.715009 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.040309  [    4/  175]\n",
      "loss: 0.017540  [   84/  175]\n",
      "loss: 0.142030  [  164/  175]\n",
      "Training accuracy: 91.7%\n",
      "Test Error: \n",
      " Accuracy: 62.9%, Avg loss: 0.519741 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.004305  [    4/  175]\n",
      "loss: 1.002611  [   84/  175]\n",
      "loss: 0.064022  [  164/  175]\n",
      "Training accuracy: 84.8%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.789697 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.105070  [    4/  175]\n",
      "loss: 0.066647  [   84/  175]\n",
      "loss: 0.037746  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.041272 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.696460  [    4/  175]\n",
      "loss: 0.162502  [   84/  175]\n",
      "loss: 0.006797  [  164/  175]\n",
      "Training accuracy: 91.1%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.097601 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.008656  [    4/  175]\n",
      "loss: 0.042737  [   84/  175]\n",
      "loss: 0.829026  [  164/  175]\n",
      "Training accuracy: 86.2%\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.831397 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.797262  [    4/  175]\n",
      "loss: 0.057319  [   84/  175]\n",
      "loss: 0.199814  [  164/  175]\n",
      "Training accuracy: 97.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007401 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.003053  [    4/  175]\n",
      "loss: 0.022918  [   84/  175]\n",
      "loss: 0.016994  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.102355 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 1.084857  [    4/  175]\n",
      "loss: 0.022399  [   84/  175]\n",
      "loss: 0.005258  [  164/  175]\n",
      "Training accuracy: 91.3%\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 3.188582 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.234225  [    4/  175]\n",
      "loss: 0.024834  [   84/  175]\n",
      "loss: 0.002975  [  164/  175]\n",
      "Training accuracy: 96.0%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.628287 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.054890  [    4/  175]\n",
      "loss: 0.004613  [   84/  175]\n",
      "loss: 0.721541  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 4.330376 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.834126  [    4/  175]\n",
      "loss: 0.824644  [   84/  175]\n",
      "loss: 0.106227  [  164/  175]\n",
      "Training accuracy: 88.1%\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 4.515438 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.031145  [    4/  175]\n",
      "loss: 0.113064  [   84/  175]\n",
      "loss: 0.003114  [  164/  175]\n",
      "Training accuracy: 92.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.037244 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.198744  [    4/  175]\n",
      "loss: 1.680964  [   84/  175]\n",
      "loss: 1.186168  [  164/  175]\n",
      "Training accuracy: 91.1%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.102698 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.004201  [    4/  175]\n",
      "loss: 0.012065  [   84/  175]\n",
      "loss: 0.079446  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.203986 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 1.271412  [    4/  175]\n",
      "loss: 0.033247  [   84/  175]\n",
      "loss: 0.003828  [  164/  175]\n",
      "Training accuracy: 94.5%\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.157137 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.017619  [    4/  175]\n",
      "loss: 0.004553  [   84/  175]\n",
      "loss: 0.101757  [  164/  175]\n",
      "Training accuracy: 89.4%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 4.482995 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.009332  [    4/  175]\n",
      "loss: 0.115781  [   84/  175]\n",
      "loss: 0.005144  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 2.249333 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.096785  [    4/  175]\n",
      "loss: 0.666632  [   84/  175]\n",
      "loss: 0.729628  [  164/  175]\n",
      "Training accuracy: 89.8%\n",
      "Test Error: \n",
      " Accuracy: 55.3%, Avg loss: 0.645540 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.067305  [    4/  175]\n",
      "loss: 0.369525  [   84/  175]\n",
      "loss: 0.059801  [  164/  175]\n",
      "Training accuracy: 94.9%\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.218169 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.035454  [    4/  175]\n",
      "loss: 0.361705  [   84/  175]\n",
      "loss: 0.053536  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.010886 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.021455  [    4/  175]\n",
      "loss: 0.101007  [   84/  175]\n",
      "loss: 0.002314  [  164/  175]\n",
      "Training accuracy: 90.5%\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.635925 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.044337  [    4/  175]\n",
      "loss: 0.047678  [   84/  175]\n",
      "loss: 0.904003  [  164/  175]\n",
      "Training accuracy: 91.9%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 2.626004 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.071253  [    4/  175]\n",
      "loss: 0.041217  [   84/  175]\n",
      "loss: 0.018355  [  164/  175]\n",
      "Training accuracy: 95.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.009214 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.041708  [    4/  175]\n",
      "loss: 0.009650  [   84/  175]\n",
      "loss: 0.002439  [  164/  175]\n",
      "Training accuracy: 95.6%\n",
      "Test Error: \n",
      " Accuracy: 49.2%, Avg loss: 0.817851 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.043358  [    4/  175]\n",
      "loss: 0.946282  [   84/  175]\n",
      "loss: 0.030317  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.074170 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.329942  [    4/  175]\n",
      "loss: 0.017397  [   84/  175]\n",
      "loss: 0.935664  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.240629 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.020319  [    4/  175]\n",
      "loss: 0.035230  [   84/  175]\n",
      "loss: 0.137050  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.877501 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 1.040861  [    4/  175]\n",
      "loss: 0.052210  [   84/  175]\n",
      "loss: 0.032829  [  164/  175]\n",
      "Training accuracy: 96.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.025003 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.013611  [    4/  175]\n",
      "loss: 0.001869  [   84/  175]\n",
      "loss: 0.046762  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.054859 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.000754  [    4/  175]\n",
      "loss: 0.744475  [   84/  175]\n",
      "loss: 0.013213  [  164/  175]\n",
      "Training accuracy: 86.0%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 3.496613 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.064372  [    4/  175]\n",
      "loss: 0.029711  [   84/  175]\n",
      "loss: 0.005341  [  164/  175]\n",
      "Training accuracy: 89.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.013258 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.067766  [    4/  175]\n",
      "loss: 0.007881  [   84/  175]\n",
      "loss: 0.021467  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.039654 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.021344  [    4/  175]\n",
      "loss: 0.041134  [   84/  175]\n",
      "loss: 0.007036  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 2.468358 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.036293  [    4/  175]\n",
      "loss: 0.002177  [   84/  175]\n",
      "loss: 1.261064  [  164/  175]\n",
      "Training accuracy: 93.0%\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 2.461558 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.012914  [    4/  175]\n",
      "loss: 0.009915  [   84/  175]\n",
      "loss: 0.009874  [  164/  175]\n",
      "Training accuracy: 91.1%\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 3.792127 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.093757  [    4/  175]\n",
      "loss: 0.993264  [   84/  175]\n",
      "loss: 0.054252  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.034149 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.015358  [    4/  175]\n",
      "loss: 0.045499  [   84/  175]\n",
      "loss: 0.879444  [  164/  175]\n",
      "Training accuracy: 92.2%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 5.039127 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.084235  [    4/  175]\n",
      "loss: 0.650048  [   84/  175]\n",
      "loss: 0.082814  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 1.460178 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.057773  [    4/  175]\n",
      "loss: 0.063206  [   84/  175]\n",
      "loss: 0.061960  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 6.048772 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.106244  [    4/  175]\n",
      "loss: 0.016534  [   84/  175]\n",
      "loss: 0.747844  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 1.822354 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.019546  [    4/  175]\n",
      "loss: 0.004406  [   84/  175]\n",
      "loss: 0.002997  [  164/  175]\n",
      "Training accuracy: 89.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.041895 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.004858  [    4/  175]\n",
      "loss: 1.102822  [   84/  175]\n",
      "loss: 0.007950  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.032002 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.002974  [    4/  175]\n",
      "loss: 0.024353  [   84/  175]\n",
      "loss: 0.004978  [  164/  175]\n",
      "Training accuracy: 92.4%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 12.629265 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.016691  [    4/  175]\n",
      "loss: 0.923472  [   84/  175]\n",
      "loss: 0.001522  [  164/  175]\n",
      "Training accuracy: 97.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003532 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.001473  [    4/  175]\n",
      "loss: 0.001006  [   84/  175]\n",
      "loss: 0.181540  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.049338 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.006155  [    4/  175]\n",
      "loss: 0.003638  [   84/  175]\n",
      "loss: 0.148164  [  164/  175]\n",
      "Training accuracy: 97.7%\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.245388 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.002102  [    4/  175]\n",
      "loss: 1.620030  [   84/  175]\n",
      "loss: 0.003636  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.094004 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.068983  [    4/  175]\n",
      "loss: 0.016559  [   84/  175]\n",
      "loss: 0.002013  [  164/  175]\n",
      "Training accuracy: 94.7%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.031091 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.005009  [    4/  175]\n",
      "loss: 0.007978  [   84/  175]\n",
      "loss: 0.042435  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.128571 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.866892  [    4/  175]\n",
      "loss: 0.003415  [   84/  175]\n",
      "loss: 0.002815  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.034811 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.049470  [    4/  175]\n",
      "loss: 0.025974  [   84/  175]\n",
      "loss: 0.000899  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 1.607738 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.029753  [    4/  175]\n",
      "loss: 1.433287  [   84/  175]\n",
      "loss: 0.001143  [  164/  175]\n",
      "Training accuracy: 95.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.012028 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.023650  [    4/  175]\n",
      "loss: 0.017105  [   84/  175]\n",
      "loss: 0.000544  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.002996 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.001532  [    4/  175]\n",
      "loss: 0.001145  [   84/  175]\n",
      "loss: 0.017730  [  164/  175]\n",
      "Training accuracy: 96.0%\n",
      "Test Error: \n",
      " Accuracy: 65.2%, Avg loss: 0.514624 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.011253  [    4/  175]\n",
      "loss: 0.872908  [   84/  175]\n",
      "loss: 0.000460  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 52.3%, Avg loss: 2.660800 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.003722  [    4/  175]\n",
      "loss: 0.070221  [   84/  175]\n",
      "loss: 0.003076  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.338671 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.003083  [    4/  175]\n",
      "loss: 0.028876  [   84/  175]\n",
      "loss: 0.017980  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 55.3%, Avg loss: 0.968650 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.009806  [    4/  175]\n",
      "loss: 0.127468  [   84/  175]\n",
      "loss: 0.030232  [  164/  175]\n",
      "Training accuracy: 90.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006781 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.025417  [    4/  175]\n",
      "loss: 0.024725  [   84/  175]\n",
      "loss: 0.076377  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.003819 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.023550  [    4/  175]\n",
      "loss: 0.015424  [   84/  175]\n",
      "loss: 0.008775  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.110984 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.016414  [    4/  175]\n",
      "loss: 0.025015  [   84/  175]\n",
      "loss: 0.003796  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.009417 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.890321  [    4/  175]\n",
      "loss: 0.538939  [   84/  175]\n",
      "loss: 0.030838  [  164/  175]\n",
      "Training accuracy: 83.7%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 2.460012 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.125528  [    4/  175]\n",
      "loss: 0.030010  [   84/  175]\n",
      "loss: 0.003053  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.039886 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.015261  [    4/  175]\n",
      "loss: 0.002058  [   84/  175]\n",
      "loss: 0.001355  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 3.562685 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.009848  [    4/  175]\n",
      "loss: 0.059741  [   84/  175]\n",
      "loss: 0.000458  [  164/  175]\n",
      "Training accuracy: 96.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.021083 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.000932  [    4/  175]\n",
      "loss: 0.795880  [   84/  175]\n",
      "loss: 0.017557  [  164/  175]\n",
      "Training accuracy: 91.1%\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.273311 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.012691  [    4/  175]\n",
      "loss: 0.001536  [   84/  175]\n",
      "loss: 0.042645  [  164/  175]\n",
      "Training accuracy: 94.9%\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.644655 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.003025  [    4/  175]\n",
      "loss: 0.866010  [   84/  175]\n",
      "loss: 0.064533  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 4.429913 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.084504  [    4/  175]\n",
      "loss: 0.210528  [   84/  175]\n",
      "loss: 1.117183  [  164/  175]\n",
      "Training accuracy: 96.0%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 2.140009 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.000911  [    4/  175]\n",
      "loss: 0.011626  [   84/  175]\n",
      "loss: 0.727345  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.055396 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.003189  [    4/  175]\n",
      "loss: 0.185100  [   84/  175]\n",
      "loss: 0.042620  [  164/  175]\n",
      "Training accuracy: 96.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007862 \n",
      "\n",
      "Done!\n",
      "Training model with momentum 0.1...\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "loss: 0.811496  [    4/  175]\n",
      "loss: 1.031057  [   84/  175]\n",
      "loss: 0.919758  [  164/  175]\n",
      "Training accuracy: 51.5%\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.688068 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.677922  [    4/  175]\n",
      "loss: 0.994477  [   84/  175]\n",
      "loss: 0.552146  [  164/  175]\n",
      "Training accuracy: 61.7%\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 0.777241 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.453365  [    4/  175]\n",
      "loss: 0.657082  [   84/  175]\n",
      "loss: 0.777556  [  164/  175]\n",
      "Training accuracy: 63.6%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.676959 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.816336  [    4/  175]\n",
      "loss: 0.417414  [   84/  175]\n",
      "loss: 0.739617  [  164/  175]\n",
      "Training accuracy: 62.7%\n",
      "Test Error: \n",
      " Accuracy: 65.2%, Avg loss: 0.596139 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.610069  [    4/  175]\n",
      "loss: 0.702439  [   84/  175]\n",
      "loss: 0.425120  [  164/  175]\n",
      "Training accuracy: 68.8%\n",
      "Test Error: \n",
      " Accuracy: 59.8%, Avg loss: 0.864492 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.520412  [    4/  175]\n",
      "loss: 0.431170  [   84/  175]\n",
      "loss: 0.594178  [  164/  175]\n",
      "Training accuracy: 70.5%\n",
      "Test Error: \n",
      " Accuracy: 72.7%, Avg loss: 0.553323 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.381288  [    4/  175]\n",
      "loss: 0.596921  [   84/  175]\n",
      "loss: 0.372335  [  164/  175]\n",
      "Training accuracy: 77.1%\n",
      "Test Error: \n",
      " Accuracy: 67.4%, Avg loss: 0.516488 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.450425  [    4/  175]\n",
      "loss: 0.363891  [   84/  175]\n",
      "loss: 0.396038  [  164/  175]\n",
      "Training accuracy: 78.2%\n",
      "Test Error: \n",
      " Accuracy: 68.9%, Avg loss: 0.499636 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.748119  [    4/  175]\n",
      "loss: 0.261427  [   84/  175]\n",
      "loss: 0.356574  [  164/  175]\n",
      "Training accuracy: 78.2%\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 1.335258 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.702372  [    4/  175]\n",
      "loss: 0.394479  [   84/  175]\n",
      "loss: 0.616059  [  164/  175]\n",
      "Training accuracy: 71.4%\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.443657 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.354853  [    4/  175]\n",
      "loss: 0.252492  [   84/  175]\n",
      "loss: 0.734387  [  164/  175]\n",
      "Training accuracy: 77.8%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 3.599492 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.439926  [    4/  175]\n",
      "loss: 0.374111  [   84/  175]\n",
      "loss: 0.522159  [  164/  175]\n",
      "Training accuracy: 72.9%\n",
      "Test Error: \n",
      " Accuracy: 52.3%, Avg loss: 1.989451 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.380315  [    4/  175]\n",
      "loss: 0.336114  [   84/  175]\n",
      "loss: 0.420053  [  164/  175]\n",
      "Training accuracy: 77.3%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 3.771572 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.401948  [    4/  175]\n",
      "loss: 0.327999  [   84/  175]\n",
      "loss: 0.584670  [  164/  175]\n",
      "Training accuracy: 79.5%\n",
      "Test Error: \n",
      " Accuracy: 70.5%, Avg loss: 0.589963 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.923568  [    4/  175]\n",
      "loss: 0.986040  [   84/  175]\n",
      "loss: 0.362141  [  164/  175]\n",
      "Training accuracy: 82.4%\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.294326 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.745136  [    4/  175]\n",
      "loss: 0.711872  [   84/  175]\n",
      "loss: 0.142134  [  164/  175]\n",
      "Training accuracy: 89.2%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 11.761488 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 1.147211  [    4/  175]\n",
      "loss: 0.352473  [   84/  175]\n",
      "loss: 0.775222  [  164/  175]\n",
      "Training accuracy: 79.0%\n",
      "Test Error: \n",
      " Accuracy: 62.9%, Avg loss: 0.546242 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.747299  [    4/  175]\n",
      "loss: 0.290931  [   84/  175]\n",
      "loss: 1.196837  [  164/  175]\n",
      "Training accuracy: 83.5%\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 4.755353 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.902924  [    4/  175]\n",
      "loss: 0.583702  [   84/  175]\n",
      "loss: 0.215676  [  164/  175]\n",
      "Training accuracy: 86.2%\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 0.616257 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.255745  [    4/  175]\n",
      "loss: 0.257874  [   84/  175]\n",
      "loss: 0.167725  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 72.7%, Avg loss: 0.431870 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.458268  [    4/  175]\n",
      "loss: 0.140151  [   84/  175]\n",
      "loss: 0.340761  [  164/  175]\n",
      "Training accuracy: 86.6%\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 0.803642 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.216527  [    4/  175]\n",
      "loss: 0.387163  [   84/  175]\n",
      "loss: 0.460358  [  164/  175]\n",
      "Training accuracy: 85.8%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.264510 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.106729  [    4/  175]\n",
      "loss: 0.248187  [   84/  175]\n",
      "loss: 0.488261  [  164/  175]\n",
      "Training accuracy: 85.6%\n",
      "Test Error: \n",
      " Accuracy: 52.3%, Avg loss: 1.124624 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.102653  [    4/  175]\n",
      "loss: 0.977531  [   84/  175]\n",
      "loss: 0.190434  [  164/  175]\n",
      "Training accuracy: 82.8%\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.321699 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.768864  [    4/  175]\n",
      "loss: 0.110795  [   84/  175]\n",
      "loss: 0.164506  [  164/  175]\n",
      "Training accuracy: 87.5%\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.206711 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.961678  [    4/  175]\n",
      "loss: 0.146161  [   84/  175]\n",
      "loss: 0.220082  [  164/  175]\n",
      "Training accuracy: 85.8%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.168461 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.742828  [    4/  175]\n",
      "loss: 0.147835  [   84/  175]\n",
      "loss: 0.188963  [  164/  175]\n",
      "Training accuracy: 87.5%\n",
      "Test Error: \n",
      " Accuracy: 67.4%, Avg loss: 0.425757 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.219588  [    4/  175]\n",
      "loss: 0.275103  [   84/  175]\n",
      "loss: 0.188243  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 5.561622 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.100493  [    4/  175]\n",
      "loss: 0.290119  [   84/  175]\n",
      "loss: 0.294286  [  164/  175]\n",
      "Training accuracy: 88.6%\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 0.512310 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.081634  [    4/  175]\n",
      "loss: 0.265553  [   84/  175]\n",
      "loss: 0.144505  [  164/  175]\n",
      "Training accuracy: 88.1%\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.922965 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.063631  [    4/  175]\n",
      "loss: 0.240631  [   84/  175]\n",
      "loss: 0.244440  [  164/  175]\n",
      "Training accuracy: 87.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.123893 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.060502  [    4/  175]\n",
      "loss: 0.888576  [   84/  175]\n",
      "loss: 0.207698  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.159398 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.144360  [    4/  175]\n",
      "loss: 0.203877  [   84/  175]\n",
      "loss: 1.093144  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.117184 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.160764  [    4/  175]\n",
      "loss: 0.048867  [   84/  175]\n",
      "loss: 0.313320  [  164/  175]\n",
      "Training accuracy: 91.9%\n",
      "Test Error: \n",
      " Accuracy: 92.4%, Avg loss: 0.192754 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.858200  [    4/  175]\n",
      "loss: 0.152798  [   84/  175]\n",
      "loss: 0.142500  [  164/  175]\n",
      "Training accuracy: 89.4%\n",
      "Test Error: \n",
      " Accuracy: 48.5%, Avg loss: 1.960544 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.199302  [    4/  175]\n",
      "loss: 0.200752  [   84/  175]\n",
      "loss: 0.137485  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.086122 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.079600  [    4/  175]\n",
      "loss: 0.166573  [   84/  175]\n",
      "loss: 0.859647  [  164/  175]\n",
      "Training accuracy: 89.4%\n",
      "Test Error: \n",
      " Accuracy: 69.7%, Avg loss: 0.450374 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.126582  [    4/  175]\n",
      "loss: 0.181709  [   84/  175]\n",
      "loss: 0.110232  [  164/  175]\n",
      "Training accuracy: 96.6%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.126769 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.111040  [    4/  175]\n",
      "loss: 0.461964  [   84/  175]\n",
      "loss: 0.481082  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.065166 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.043596  [    4/  175]\n",
      "loss: 1.124980  [   84/  175]\n",
      "loss: 0.114970  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.061638 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.224974  [    4/  175]\n",
      "loss: 0.039337  [   84/  175]\n",
      "loss: 0.218412  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.317552 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.095973  [    4/  175]\n",
      "loss: 0.133611  [   84/  175]\n",
      "loss: 0.419673  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 52.3%, Avg loss: 0.831578 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.025238  [    4/  175]\n",
      "loss: 0.023614  [   84/  175]\n",
      "loss: 0.225357  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.063142 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.079186  [    4/  175]\n",
      "loss: 0.164382  [   84/  175]\n",
      "loss: 0.260080  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.083846 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.018899  [    4/  175]\n",
      "loss: 0.041176  [   84/  175]\n",
      "loss: 0.033327  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.293014 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.159107  [    4/  175]\n",
      "loss: 0.855217  [   84/  175]\n",
      "loss: 0.105988  [  164/  175]\n",
      "Training accuracy: 88.1%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.170216 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.020919  [    4/  175]\n",
      "loss: 0.102663  [   84/  175]\n",
      "loss: 0.187183  [  164/  175]\n",
      "Training accuracy: 94.9%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.088692 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.086075  [    4/  175]\n",
      "loss: 0.161410  [   84/  175]\n",
      "loss: 0.139692  [  164/  175]\n",
      "Training accuracy: 93.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.045847 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.776775  [    4/  175]\n",
      "loss: 0.833486  [   84/  175]\n",
      "loss: 0.476416  [  164/  175]\n",
      "Training accuracy: 89.2%\n",
      "Test Error: \n",
      " Accuracy: 59.8%, Avg loss: 0.587419 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.141002  [    4/  175]\n",
      "loss: 0.034007  [   84/  175]\n",
      "loss: 0.153616  [  164/  175]\n",
      "Training accuracy: 95.5%\n",
      "Test Error: \n",
      " Accuracy: 67.4%, Avg loss: 0.491123 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.080476  [    4/  175]\n",
      "loss: 0.122791  [   84/  175]\n",
      "loss: 0.817714  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.035956 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.030444  [    4/  175]\n",
      "loss: 0.034558  [   84/  175]\n",
      "loss: 0.027655  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.095940 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.095863  [    4/  175]\n",
      "loss: 0.088762  [   84/  175]\n",
      "loss: 0.056153  [  164/  175]\n",
      "Training accuracy: 96.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.067439 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.087615  [    4/  175]\n",
      "loss: 0.114711  [   84/  175]\n",
      "loss: 0.055031  [  164/  175]\n",
      "Training accuracy: 89.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.057368 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.815580  [    4/  175]\n",
      "loss: 0.068173  [   84/  175]\n",
      "loss: 0.112033  [  164/  175]\n",
      "Training accuracy: 95.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.067286 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.807885  [    4/  175]\n",
      "loss: 0.277674  [   84/  175]\n",
      "loss: 0.200977  [  164/  175]\n",
      "Training accuracy: 82.4%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.084243 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.141555  [    4/  175]\n",
      "loss: 1.329590  [   84/  175]\n",
      "loss: 0.161130  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.038520 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.014952  [    4/  175]\n",
      "loss: 0.092260  [   84/  175]\n",
      "loss: 0.012605  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.035946 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.049841  [    4/  175]\n",
      "loss: 0.165176  [   84/  175]\n",
      "loss: 0.012699  [  164/  175]\n",
      "Training accuracy: 94.1%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.067725 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.084392  [    4/  175]\n",
      "loss: 0.012775  [   84/  175]\n",
      "loss: 0.165997  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.219910 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.040454  [    4/  175]\n",
      "loss: 0.019301  [   84/  175]\n",
      "loss: 0.985765  [  164/  175]\n",
      "Training accuracy: 94.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.025632 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.083066  [    4/  175]\n",
      "loss: 0.024421  [   84/  175]\n",
      "loss: 0.014490  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.102137 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.029842  [    4/  175]\n",
      "loss: 0.023135  [   84/  175]\n",
      "loss: 1.098432  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.066067 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.053384  [    4/  175]\n",
      "loss: 0.061519  [   84/  175]\n",
      "loss: 0.152608  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.031012 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.373792  [    4/  175]\n",
      "loss: 0.061781  [   84/  175]\n",
      "loss: 0.128342  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.022197 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.069597  [    4/  175]\n",
      "loss: 0.072270  [   84/  175]\n",
      "loss: 0.013186  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.068439 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.062173  [    4/  175]\n",
      "loss: 0.070358  [   84/  175]\n",
      "loss: 0.713529  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.031695 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.024533  [    4/  175]\n",
      "loss: 0.981727  [   84/  175]\n",
      "loss: 0.071347  [  164/  175]\n",
      "Training accuracy: 94.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.046420 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.028495  [    4/  175]\n",
      "loss: 0.132734  [   84/  175]\n",
      "loss: 0.078898  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.021109 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.014921  [    4/  175]\n",
      "loss: 0.010689  [   84/  175]\n",
      "loss: 0.019006  [  164/  175]\n",
      "Training accuracy: 97.7%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.054448 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.107646  [    4/  175]\n",
      "loss: 0.135496  [   84/  175]\n",
      "loss: 0.011128  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.021963 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.806681  [    4/  175]\n",
      "loss: 0.061535  [   84/  175]\n",
      "loss: 0.067651  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.028172 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.075151  [    4/  175]\n",
      "loss: 0.137221  [   84/  175]\n",
      "loss: 0.059722  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.023877 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.076623  [    4/  175]\n",
      "loss: 0.792758  [   84/  175]\n",
      "loss: 0.190242  [  164/  175]\n",
      "Training accuracy: 91.1%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.020727 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.011427  [    4/  175]\n",
      "loss: 0.144953  [   84/  175]\n",
      "loss: 0.257741  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.253278 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.113080  [    4/  175]\n",
      "loss: 0.075970  [   84/  175]\n",
      "loss: 0.847975  [  164/  175]\n",
      "Training accuracy: 87.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.035698 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.093850  [    4/  175]\n",
      "loss: 0.142109  [   84/  175]\n",
      "loss: 0.056658  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.016784 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.056434  [    4/  175]\n",
      "loss: 0.008403  [   84/  175]\n",
      "loss: 0.008596  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.014329 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.079441  [    4/  175]\n",
      "loss: 0.104289  [   84/  175]\n",
      "loss: 0.019129  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.075094 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.107186  [    4/  175]\n",
      "loss: 0.064110  [   84/  175]\n",
      "loss: 0.013304  [  164/  175]\n",
      "Training accuracy: 90.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.037055 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.008267  [    4/  175]\n",
      "loss: 0.051430  [   84/  175]\n",
      "loss: 0.696940  [  164/  175]\n",
      "Training accuracy: 95.5%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.110149 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.079075  [    4/  175]\n",
      "loss: 0.066454  [   84/  175]\n",
      "loss: 0.017537  [  164/  175]\n",
      "Training accuracy: 91.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.050130 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 1.788008  [    4/  175]\n",
      "loss: 0.244942  [   84/  175]\n",
      "loss: 0.077499  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.036441 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.059589  [    4/  175]\n",
      "loss: 0.009556  [   84/  175]\n",
      "loss: 0.108826  [  164/  175]\n",
      "Training accuracy: 95.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.017259 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.047022  [    4/  175]\n",
      "loss: 0.008776  [   84/  175]\n",
      "loss: 0.051138  [  164/  175]\n",
      "Training accuracy: 91.1%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.053008 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.256236  [    4/  175]\n",
      "loss: 0.809886  [   84/  175]\n",
      "loss: 0.005951  [  164/  175]\n",
      "Training accuracy: 93.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.019936 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.013099  [    4/  175]\n",
      "loss: 0.246837  [   84/  175]\n",
      "loss: 0.009376  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.053593 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.012110  [    4/  175]\n",
      "loss: 0.008859  [   84/  175]\n",
      "loss: 0.007536  [  164/  175]\n",
      "Training accuracy: 91.1%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.072895 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.126126  [    4/  175]\n",
      "loss: 0.113224  [   84/  175]\n",
      "loss: 0.937255  [  164/  175]\n",
      "Training accuracy: 87.1%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.097629 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.097066  [    4/  175]\n",
      "loss: 0.016737  [   84/  175]\n",
      "loss: 0.119996  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.092266 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.086247  [    4/  175]\n",
      "loss: 0.041285  [   84/  175]\n",
      "loss: 0.049199  [  164/  175]\n",
      "Training accuracy: 90.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.014657 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.049008  [    4/  175]\n",
      "loss: 0.005178  [   84/  175]\n",
      "loss: 0.112014  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.014880 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.008690  [    4/  175]\n",
      "loss: 0.008999  [   84/  175]\n",
      "loss: 0.200040  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.011967 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.703994  [    4/  175]\n",
      "loss: 0.009048  [   84/  175]\n",
      "loss: 0.011377  [  164/  175]\n",
      "Training accuracy: 91.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.022406 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.060751  [    4/  175]\n",
      "loss: 0.007611  [   84/  175]\n",
      "loss: 0.258225  [  164/  175]\n",
      "Training accuracy: 84.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.024530 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.058803  [    4/  175]\n",
      "loss: 0.135793  [   84/  175]\n",
      "loss: 0.004652  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.046830 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.020888  [    4/  175]\n",
      "loss: 0.361351  [   84/  175]\n",
      "loss: 0.070109  [  164/  175]\n",
      "Training accuracy: 95.5%\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.275385 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.253117  [    4/  175]\n",
      "loss: 0.057961  [   84/  175]\n",
      "loss: 0.007641  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.026876 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.074424  [    4/  175]\n",
      "loss: 0.006804  [   84/  175]\n",
      "loss: 0.833114  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.019932 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.011742  [    4/  175]\n",
      "loss: 0.050494  [   84/  175]\n",
      "loss: 0.010072  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.021325 \n",
      "\n",
      "Done!\n",
      "Training model with momentum 0.01...\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "loss: 0.820009  [    4/  175]\n",
      "loss: 0.827168  [   84/  175]\n",
      "loss: 0.883061  [  164/  175]\n",
      "Training accuracy: 57.0%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 0.695763 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.379587  [    4/  175]\n",
      "loss: 0.689658  [   84/  175]\n",
      "loss: 0.612806  [  164/  175]\n",
      "Training accuracy: 62.5%\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 0.664130 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.849715  [    4/  175]\n",
      "loss: 0.401570  [   84/  175]\n",
      "loss: 0.633008  [  164/  175]\n",
      "Training accuracy: 65.7%\n",
      "Test Error: \n",
      " Accuracy: 59.8%, Avg loss: 0.716691 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.897983  [    4/  175]\n",
      "loss: 0.704236  [   84/  175]\n",
      "loss: 0.704193  [  164/  175]\n",
      "Training accuracy: 60.8%\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 0.695550 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.485408  [    4/  175]\n",
      "loss: 0.480526  [   84/  175]\n",
      "loss: 0.671318  [  164/  175]\n",
      "Training accuracy: 61.0%\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 1.193033 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.567412  [    4/  175]\n",
      "loss: 0.583912  [   84/  175]\n",
      "loss: 0.893662  [  164/  175]\n",
      "Training accuracy: 63.3%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 0.854171 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.572961  [    4/  175]\n",
      "loss: 0.544948  [   84/  175]\n",
      "loss: 0.772572  [  164/  175]\n",
      "Training accuracy: 63.1%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 0.998973 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.536668  [    4/  175]\n",
      "loss: 0.550630  [   84/  175]\n",
      "loss: 0.436231  [  164/  175]\n",
      "Training accuracy: 67.4%\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 0.758847 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.509750  [    4/  175]\n",
      "loss: 0.474409  [   84/  175]\n",
      "loss: 0.538152  [  164/  175]\n",
      "Training accuracy: 66.5%\n",
      "Test Error: \n",
      " Accuracy: 62.9%, Avg loss: 0.665912 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.456638  [    4/  175]\n",
      "loss: 0.677442  [   84/  175]\n",
      "loss: 0.464571  [  164/  175]\n",
      "Training accuracy: 72.0%\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 0.673691 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.463139  [    4/  175]\n",
      "loss: 0.573247  [   84/  175]\n",
      "loss: 0.408207  [  164/  175]\n",
      "Training accuracy: 68.6%\n",
      "Test Error: \n",
      " Accuracy: 65.2%, Avg loss: 0.640401 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.964157  [    4/  175]\n",
      "loss: 0.524913  [   84/  175]\n",
      "loss: 0.781244  [  164/  175]\n",
      "Training accuracy: 65.3%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 2.363983 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.728296  [    4/  175]\n",
      "loss: 0.612850  [   84/  175]\n",
      "loss: 0.513097  [  164/  175]\n",
      "Training accuracy: 70.8%\n",
      "Test Error: \n",
      " Accuracy: 65.9%, Avg loss: 0.615129 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.495318  [    4/  175]\n",
      "loss: 0.414029  [   84/  175]\n",
      "loss: 0.891644  [  164/  175]\n",
      "Training accuracy: 69.9%\n",
      "Test Error: \n",
      " Accuracy: 62.9%, Avg loss: 0.617665 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.459355  [    4/  175]\n",
      "loss: 0.769455  [   84/  175]\n",
      "loss: 0.533320  [  164/  175]\n",
      "Training accuracy: 64.8%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.802422 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.501952  [    4/  175]\n",
      "loss: 0.845052  [   84/  175]\n",
      "loss: 0.539840  [  164/  175]\n",
      "Training accuracy: 72.7%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 1.204514 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.495435  [    4/  175]\n",
      "loss: 0.638379  [   84/  175]\n",
      "loss: 0.747588  [  164/  175]\n",
      "Training accuracy: 73.9%\n",
      "Test Error: \n",
      " Accuracy: 65.9%, Avg loss: 0.592695 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.531855  [    4/  175]\n",
      "loss: 0.441445  [   84/  175]\n",
      "loss: 0.622577  [  164/  175]\n",
      "Training accuracy: 76.3%\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 0.987015 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.420325  [    4/  175]\n",
      "loss: 0.719094  [   84/  175]\n",
      "loss: 0.393802  [  164/  175]\n",
      "Training accuracy: 70.3%\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 0.888449 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.332811  [    4/  175]\n",
      "loss: 0.751334  [   84/  175]\n",
      "loss: 0.427145  [  164/  175]\n",
      "Training accuracy: 75.4%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 0.664822 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.505474  [    4/  175]\n",
      "loss: 0.736885  [   84/  175]\n",
      "loss: 0.814306  [  164/  175]\n",
      "Training accuracy: 73.9%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.123966 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.428671  [    4/  175]\n",
      "loss: 0.348741  [   84/  175]\n",
      "loss: 0.537929  [  164/  175]\n",
      "Training accuracy: 76.3%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.902758 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.454112  [    4/  175]\n",
      "loss: 1.002723  [   84/  175]\n",
      "loss: 0.473964  [  164/  175]\n",
      "Training accuracy: 77.8%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.175028 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.479388  [    4/  175]\n",
      "loss: 0.763951  [   84/  175]\n",
      "loss: 0.453312  [  164/  175]\n",
      "Training accuracy: 75.4%\n",
      "Test Error: \n",
      " Accuracy: 72.7%, Avg loss: 0.571728 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.311595  [    4/  175]\n",
      "loss: 0.658686  [   84/  175]\n",
      "loss: 0.409539  [  164/  175]\n",
      "Training accuracy: 73.7%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 1.071891 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.788358  [    4/  175]\n",
      "loss: 0.460448  [   84/  175]\n",
      "loss: 0.407288  [  164/  175]\n",
      "Training accuracy: 82.8%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 2.031012 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.171329  [    4/  175]\n",
      "loss: 0.225402  [   84/  175]\n",
      "loss: 0.754714  [  164/  175]\n",
      "Training accuracy: 72.9%\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 1.700822 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.621905  [    4/  175]\n",
      "loss: 0.435830  [   84/  175]\n",
      "loss: 0.233886  [  164/  175]\n",
      "Training accuracy: 77.8%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 2.088741 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.387721  [    4/  175]\n",
      "loss: 0.460602  [   84/  175]\n",
      "loss: 0.767100  [  164/  175]\n",
      "Training accuracy: 77.8%\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 0.420204 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.807695  [    4/  175]\n",
      "loss: 0.462839  [   84/  175]\n",
      "loss: 0.338364  [  164/  175]\n",
      "Training accuracy: 82.6%\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.335791 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.292149  [    4/  175]\n",
      "loss: 0.308377  [   84/  175]\n",
      "loss: 0.190323  [  164/  175]\n",
      "Training accuracy: 87.3%\n",
      "Test Error: \n",
      " Accuracy: 72.0%, Avg loss: 0.482983 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.167902  [    4/  175]\n",
      "loss: 0.257417  [   84/  175]\n",
      "loss: 0.231844  [  164/  175]\n",
      "Training accuracy: 85.8%\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 0.456922 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.160913  [    4/  175]\n",
      "loss: 0.285317  [   84/  175]\n",
      "loss: 0.325210  [  164/  175]\n",
      "Training accuracy: 87.5%\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.225528 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.288105  [    4/  175]\n",
      "loss: 0.247204  [   84/  175]\n",
      "loss: 0.271731  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.333983 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.238672  [    4/  175]\n",
      "loss: 0.300696  [   84/  175]\n",
      "loss: 0.188308  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.157852 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.111140  [    4/  175]\n",
      "loss: 0.227393  [   84/  175]\n",
      "loss: 0.068675  [  164/  175]\n",
      "Training accuracy: 94.1%\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.226376 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.342024  [    4/  175]\n",
      "loss: 0.260690  [   84/  175]\n",
      "loss: 0.188776  [  164/  175]\n",
      "Training accuracy: 85.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.104162 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.201946  [    4/  175]\n",
      "loss: 0.080429  [   84/  175]\n",
      "loss: 0.957383  [  164/  175]\n",
      "Training accuracy: 86.6%\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 0.646220 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.172043  [    4/  175]\n",
      "loss: 0.074003  [   84/  175]\n",
      "loss: 0.313292  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.097684 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.135799  [    4/  175]\n",
      "loss: 0.843398  [   84/  175]\n",
      "loss: 0.050904  [  164/  175]\n",
      "Training accuracy: 86.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.081797 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.149423  [    4/  175]\n",
      "loss: 0.050674  [   84/  175]\n",
      "loss: 0.151017  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.080311 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.184987  [    4/  175]\n",
      "loss: 0.209525  [   84/  175]\n",
      "loss: 0.038409  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.090556 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.929028  [    4/  175]\n",
      "loss: 0.887537  [   84/  175]\n",
      "loss: 0.995455  [  164/  175]\n",
      "Training accuracy: 86.4%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.128300 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.445862  [    4/  175]\n",
      "loss: 0.892782  [   84/  175]\n",
      "loss: 0.116333  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.061319 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.137344  [    4/  175]\n",
      "loss: 0.744810  [   84/  175]\n",
      "loss: 0.153595  [  164/  175]\n",
      "Training accuracy: 90.2%\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.204387 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.073190  [    4/  175]\n",
      "loss: 0.141233  [   84/  175]\n",
      "loss: 0.032423  [  164/  175]\n",
      "Training accuracy: 95.3%\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.253648 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.155320  [    4/  175]\n",
      "loss: 0.104196  [   84/  175]\n",
      "loss: 0.129376  [  164/  175]\n",
      "Training accuracy: 91.3%\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.203350 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.176660  [    4/  175]\n",
      "loss: 0.122774  [   84/  175]\n",
      "loss: 0.294693  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.052255 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 1.164239  [    4/  175]\n",
      "loss: 0.092934  [   84/  175]\n",
      "loss: 0.131115  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.060210 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.163768  [    4/  175]\n",
      "loss: 0.032256  [   84/  175]\n",
      "loss: 0.043642  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.089088 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.085274  [    4/  175]\n",
      "loss: 0.020872  [   84/  175]\n",
      "loss: 0.164010  [  164/  175]\n",
      "Training accuracy: 91.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.067407 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.018675  [    4/  175]\n",
      "loss: 0.090923  [   84/  175]\n",
      "loss: 0.360114  [  164/  175]\n",
      "Training accuracy: 89.4%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.037100 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.137161  [    4/  175]\n",
      "loss: 0.139984  [   84/  175]\n",
      "loss: 0.033003  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.031223 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.081008  [    4/  175]\n",
      "loss: 0.141063  [   84/  175]\n",
      "loss: 0.033991  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.034537 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.030315  [    4/  175]\n",
      "loss: 0.030128  [   84/  175]\n",
      "loss: 1.056704  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.054628 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.165216  [    4/  175]\n",
      "loss: 0.080291  [   84/  175]\n",
      "loss: 0.021946  [  164/  175]\n",
      "Training accuracy: 91.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.105321 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.731982  [    4/  175]\n",
      "loss: 0.126778  [   84/  175]\n",
      "loss: 0.113908  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.053325 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.079496  [    4/  175]\n",
      "loss: 0.131599  [   84/  175]\n",
      "loss: 0.120379  [  164/  175]\n",
      "Training accuracy: 95.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.038393 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.116329  [    4/  175]\n",
      "loss: 0.064361  [   84/  175]\n",
      "loss: 0.098025  [  164/  175]\n",
      "Training accuracy: 94.7%\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 0.335476 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.183732  [    4/  175]\n",
      "loss: 0.094637  [   84/  175]\n",
      "loss: 0.028883  [  164/  175]\n",
      "Training accuracy: 94.7%\n",
      "Test Error: \n",
      " Accuracy: 69.7%, Avg loss: 0.449860 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.316457  [    4/  175]\n",
      "loss: 0.018648  [   84/  175]\n",
      "loss: 0.016518  [  164/  175]\n",
      "Training accuracy: 95.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.099261 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.022652  [    4/  175]\n",
      "loss: 0.021568  [   84/  175]\n",
      "loss: 0.242733  [  164/  175]\n",
      "Training accuracy: 93.4%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.029832 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.067401  [    4/  175]\n",
      "loss: 0.099115  [   84/  175]\n",
      "loss: 0.763061  [  164/  175]\n",
      "Training accuracy: 94.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.022136 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.062202  [    4/  175]\n",
      "loss: 0.010498  [   84/  175]\n",
      "loss: 0.014242  [  164/  175]\n",
      "Training accuracy: 88.8%\n",
      "Test Error: \n",
      " Accuracy: 59.8%, Avg loss: 0.828949 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.164472  [    4/  175]\n",
      "loss: 0.018471  [   84/  175]\n",
      "loss: 0.014591  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.071569 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.018630  [    4/  175]\n",
      "loss: 0.083576  [   84/  175]\n",
      "loss: 0.231269  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.031669 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.223925  [    4/  175]\n",
      "loss: 0.087261  [   84/  175]\n",
      "loss: 0.889184  [  164/  175]\n",
      "Training accuracy: 85.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.017826 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.011606  [    4/  175]\n",
      "loss: 0.184939  [   84/  175]\n",
      "loss: 0.073093  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.054625 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.092221  [    4/  175]\n",
      "loss: 0.061180  [   84/  175]\n",
      "loss: 0.011896  [  164/  175]\n",
      "Training accuracy: 97.7%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.019207 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.084052  [    4/  175]\n",
      "loss: 0.009474  [   84/  175]\n",
      "loss: 0.109167  [  164/  175]\n",
      "Training accuracy: 82.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.074615 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.955304  [    4/  175]\n",
      "loss: 0.196134  [   84/  175]\n",
      "loss: 0.084510  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.022842 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.017846  [    4/  175]\n",
      "loss: 0.062308  [   84/  175]\n",
      "loss: 0.013081  [  164/  175]\n",
      "Training accuracy: 89.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.057401 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.129447  [    4/  175]\n",
      "loss: 0.011614  [   84/  175]\n",
      "loss: 0.081086  [  164/  175]\n",
      "Training accuracy: 91.9%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.140854 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.381823  [    4/  175]\n",
      "loss: 0.009230  [   84/  175]\n",
      "loss: 0.044819  [  164/  175]\n",
      "Training accuracy: 93.6%\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 6.206230 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.040952  [    4/  175]\n",
      "loss: 0.149359  [   84/  175]\n",
      "loss: 0.187740  [  164/  175]\n",
      "Training accuracy: 89.0%\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 0.803782 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.012622  [    4/  175]\n",
      "loss: 0.011343  [   84/  175]\n",
      "loss: 0.074595  [  164/  175]\n",
      "Training accuracy: 92.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.016586 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.096806  [    4/  175]\n",
      "loss: 0.063970  [   84/  175]\n",
      "loss: 0.052053  [  164/  175]\n",
      "Training accuracy: 96.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.052525 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.086573  [    4/  175]\n",
      "loss: 0.200149  [   84/  175]\n",
      "loss: 0.077598  [  164/  175]\n",
      "Training accuracy: 93.6%\n",
      "Test Error: \n",
      " Accuracy: 69.7%, Avg loss: 0.984337 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.039464  [    4/  175]\n",
      "loss: 0.148883  [   84/  175]\n",
      "loss: 0.133945  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.079291 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.763600  [    4/  175]\n",
      "loss: 0.020502  [   84/  175]\n",
      "loss: 1.067117  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.085912 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 1.217834  [    4/  175]\n",
      "loss: 0.110483  [   84/  175]\n",
      "loss: 0.224820  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.062571 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.007703  [    4/  175]\n",
      "loss: 0.014905  [   84/  175]\n",
      "loss: 0.011037  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.027476 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.018937  [    4/  175]\n",
      "loss: 0.014581  [   84/  175]\n",
      "loss: 0.065031  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.032212 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.014543  [    4/  175]\n",
      "loss: 0.065497  [   84/  175]\n",
      "loss: 0.096280  [  164/  175]\n",
      "Training accuracy: 94.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.017203 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.013151  [    4/  175]\n",
      "loss: 0.007261  [   84/  175]\n",
      "loss: 0.080814  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.021919 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.066191  [    4/  175]\n",
      "loss: 0.065732  [   84/  175]\n",
      "loss: 1.319674  [  164/  175]\n",
      "Training accuracy: 85.8%\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.782881 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.021677  [    4/  175]\n",
      "loss: 0.009500  [   84/  175]\n",
      "loss: 0.054115  [  164/  175]\n",
      "Training accuracy: 89.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.016679 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.041559  [    4/  175]\n",
      "loss: 0.083231  [   84/  175]\n",
      "loss: 0.015505  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.031459 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.018587  [    4/  175]\n",
      "loss: 0.215592  [   84/  175]\n",
      "loss: 0.059670  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 56.8%, Avg loss: 0.779614 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 1.272740  [    4/  175]\n",
      "loss: 0.035900  [   84/  175]\n",
      "loss: 0.007456  [  164/  175]\n",
      "Training accuracy: 89.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.040874 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.084887  [    4/  175]\n",
      "loss: 0.249655  [   84/  175]\n",
      "loss: 0.007847  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.033922 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.009327  [    4/  175]\n",
      "loss: 0.010179  [   84/  175]\n",
      "loss: 0.088658  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.016565 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.007347  [    4/  175]\n",
      "loss: 0.114363  [   84/  175]\n",
      "loss: 0.051007  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.009884 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.011742  [    4/  175]\n",
      "loss: 0.073357  [   84/  175]\n",
      "loss: 0.687965  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.017704 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.127598  [    4/  175]\n",
      "loss: 0.826832  [   84/  175]\n",
      "loss: 0.007700  [  164/  175]\n",
      "Training accuracy: 93.9%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.129881 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.131238  [    4/  175]\n",
      "loss: 0.008073  [   84/  175]\n",
      "loss: 0.068392  [  164/  175]\n",
      "Training accuracy: 89.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.071269 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.035220  [    4/  175]\n",
      "loss: 0.955452  [   84/  175]\n",
      "loss: 0.085724  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.029010 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.008348  [    4/  175]\n",
      "loss: 0.129423  [   84/  175]\n",
      "loss: 0.061835  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.017526 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.080760  [    4/  175]\n",
      "loss: 0.787992  [   84/  175]\n",
      "loss: 0.052759  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.040311 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.057273  [    4/  175]\n",
      "loss: 0.017086  [   84/  175]\n",
      "loss: 0.093511  [  164/  175]\n",
      "Training accuracy: 91.3%\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 1.158305 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-2\n",
    "momenta = [0.0, 9e-1, 1e-1, 1e-2]\n",
    "batch_size = 4\n",
    "epochs = 100\n",
    "\n",
    "log_dir = os.path.join(\"runs\", \"experiment_005\")\n",
    "shutil.rmtree(log_dir, ignore_errors=True)\n",
    "\n",
    "for momentum in momenta:\n",
    "    model = ModelWithSimpleRnn().to(device)\n",
    "\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "    print(f\"Training model with momentum {momentum}...\")\n",
    "    log_subdir = os.path.join(log_dir, \"momentum_\" + str(momentum).replace(\".\", \"_\") + \"_\" + datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"))\n",
    "    tb = SummaryWriter(log_subdir)\n",
    "\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t}\\n-------------------------------\")\n",
    "        train_metrics = train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "        test_metrics = test_loop(test_dataloader, model, loss_fn)\n",
    "        tb.add_scalar(\"Loss/train\", train_metrics[\"loss\"], t)\n",
    "        tb.add_scalar(\"Accuracy/train\", train_metrics[\"acc\"], t)\n",
    "        tb.add_scalar(\"Loss/test\", test_metrics[\"loss\"], t)\n",
    "        tb.add_scalar(\"Accuracy/test\", test_metrics[\"acc\"], t)\n",
    "        for name, weight in model.named_parameters():\n",
    "            tb.add_histogram(f\"Weights/{name}\", weight, t)\n",
    "            tb.add_histogram(f\"Gradients/{name}\", weight.grad, t)\n",
    "\n",
    "    tb.close()\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding momentum doesn't seem to make any difference."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different optimizer\n",
    "\n",
    "What if we try a different optimizer, like Adam?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with learning rate 0.001...\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "loss: 0.791628  [    4/  175]\n",
      "loss: 0.679644  [   84/  175]\n",
      "loss: 0.579722  [  164/  175]\n",
      "Training accuracy: 57.2%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 0.697320 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.671694  [    4/  175]\n",
      "loss: 0.517959  [   84/  175]\n",
      "loss: 0.714158  [  164/  175]\n",
      "Training accuracy: 73.7%\n",
      "Test Error: \n",
      " Accuracy: 62.1%, Avg loss: 0.641724 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.464552  [    4/  175]\n",
      "loss: 0.483080  [   84/  175]\n",
      "loss: 0.563936  [  164/  175]\n",
      "Training accuracy: 73.3%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 1.621852 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.641107  [    4/  175]\n",
      "loss: 0.448335  [   84/  175]\n",
      "loss: 0.427998  [  164/  175]\n",
      "Training accuracy: 75.6%\n",
      "Test Error: \n",
      " Accuracy: 52.3%, Avg loss: 1.226841 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.444489  [    4/  175]\n",
      "loss: 0.496113  [   84/  175]\n",
      "loss: 0.841778  [  164/  175]\n",
      "Training accuracy: 76.1%\n",
      "Test Error: \n",
      " Accuracy: 59.1%, Avg loss: 0.527284 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.420837  [    4/  175]\n",
      "loss: 0.823009  [   84/  175]\n",
      "loss: 0.425444  [  164/  175]\n",
      "Training accuracy: 79.9%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 1.220858 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.391318  [    4/  175]\n",
      "loss: 0.434341  [   84/  175]\n",
      "loss: 0.315310  [  164/  175]\n",
      "Training accuracy: 83.0%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 0.768916 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.418830  [    4/  175]\n",
      "loss: 0.875740  [   84/  175]\n",
      "loss: 0.829309  [  164/  175]\n",
      "Training accuracy: 77.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.308643 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.313065  [    4/  175]\n",
      "loss: 0.289274  [   84/  175]\n",
      "loss: 0.794735  [  164/  175]\n",
      "Training accuracy: 84.8%\n",
      "Test Error: \n",
      " Accuracy: 94.7%, Avg loss: 0.291228 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.289695  [    4/  175]\n",
      "loss: 0.267444  [   84/  175]\n",
      "loss: 0.451047  [  164/  175]\n",
      "Training accuracy: 88.1%\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 1.141379 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.210830  [    4/  175]\n",
      "loss: 0.425125  [   84/  175]\n",
      "loss: 0.350673  [  164/  175]\n",
      "Training accuracy: 86.4%\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.312526 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.137611  [    4/  175]\n",
      "loss: 0.769282  [   84/  175]\n",
      "loss: 0.237461  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.257173 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.706034  [    4/  175]\n",
      "loss: 0.209967  [   84/  175]\n",
      "loss: 0.273969  [  164/  175]\n",
      "Training accuracy: 85.8%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.201969 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.129237  [    4/  175]\n",
      "loss: 0.331313  [   84/  175]\n",
      "loss: 0.702843  [  164/  175]\n",
      "Training accuracy: 82.8%\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 1.502292 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.290591  [    4/  175]\n",
      "loss: 0.307623  [   84/  175]\n",
      "loss: 0.291489  [  164/  175]\n",
      "Training accuracy: 88.6%\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.252490 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.216007  [    4/  175]\n",
      "loss: 0.278263  [   84/  175]\n",
      "loss: 0.681223  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.180968 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.764967  [    4/  175]\n",
      "loss: 0.517297  [   84/  175]\n",
      "loss: 0.093534  [  164/  175]\n",
      "Training accuracy: 84.7%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.123471 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.388152  [    4/  175]\n",
      "loss: 0.901987  [   84/  175]\n",
      "loss: 0.116269  [  164/  175]\n",
      "Training accuracy: 90.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.119273 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.101863  [    4/  175]\n",
      "loss: 0.172888  [   84/  175]\n",
      "loss: 0.066077  [  164/  175]\n",
      "Training accuracy: 89.2%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.171089 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.137298  [    4/  175]\n",
      "loss: 0.338249  [   84/  175]\n",
      "loss: 0.165176  [  164/  175]\n",
      "Training accuracy: 89.2%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.128831 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.149636  [    4/  175]\n",
      "loss: 0.178311  [   84/  175]\n",
      "loss: 0.381253  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.094309 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.307993  [    4/  175]\n",
      "loss: 0.049592  [   84/  175]\n",
      "loss: 0.061996  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.235827 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.231284  [    4/  175]\n",
      "loss: 0.037616  [   84/  175]\n",
      "loss: 0.061004  [  164/  175]\n",
      "Training accuracy: 93.6%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.192150 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.131280  [    4/  175]\n",
      "loss: 0.187089  [   84/  175]\n",
      "loss: 0.066877  [  164/  175]\n",
      "Training accuracy: 90.2%\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.164535 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.156739  [    4/  175]\n",
      "loss: 0.232961  [   84/  175]\n",
      "loss: 0.083319  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.079749 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.214942  [    4/  175]\n",
      "loss: 0.540164  [   84/  175]\n",
      "loss: 0.221992  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.079563 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.096211  [    4/  175]\n",
      "loss: 0.140950  [   84/  175]\n",
      "loss: 0.359384  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.077436 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.029046  [    4/  175]\n",
      "loss: 0.134608  [   84/  175]\n",
      "loss: 0.169126  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 50.8%, Avg loss: 1.323500 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.188260  [    4/  175]\n",
      "loss: 0.226723  [   84/  175]\n",
      "loss: 0.146937  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.110694 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.231735  [    4/  175]\n",
      "loss: 0.132751  [   84/  175]\n",
      "loss: 0.029435  [  164/  175]\n",
      "Training accuracy: 96.6%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.071256 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.018852  [    4/  175]\n",
      "loss: 0.952474  [   84/  175]\n",
      "loss: 0.032954  [  164/  175]\n",
      "Training accuracy: 92.8%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.100516 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.132885  [    4/  175]\n",
      "loss: 0.051226  [   84/  175]\n",
      "loss: 0.026579  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.049269 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.077602  [    4/  175]\n",
      "loss: 0.049996  [   84/  175]\n",
      "loss: 0.288089  [  164/  175]\n",
      "Training accuracy: 95.3%\n",
      "Test Error: \n",
      " Accuracy: 70.5%, Avg loss: 0.554669 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.128267  [    4/  175]\n",
      "loss: 0.123083  [   84/  175]\n",
      "loss: 0.306552  [  164/  175]\n",
      "Training accuracy: 91.7%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.117270 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.089004  [    4/  175]\n",
      "loss: 0.123162  [   84/  175]\n",
      "loss: 0.168636  [  164/  175]\n",
      "Training accuracy: 95.5%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.124447 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.271816  [    4/  175]\n",
      "loss: 0.397568  [   84/  175]\n",
      "loss: 0.022488  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.047118 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.037353  [    4/  175]\n",
      "loss: 0.070493  [   84/  175]\n",
      "loss: 0.104606  [  164/  175]\n",
      "Training accuracy: 95.5%\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.308304 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.878140  [    4/  175]\n",
      "loss: 0.872119  [   84/  175]\n",
      "loss: 0.129436  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.146004 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.011402  [    4/  175]\n",
      "loss: 0.108491  [   84/  175]\n",
      "loss: 0.101503  [  164/  175]\n",
      "Training accuracy: 86.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.037715 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.194121  [    4/  175]\n",
      "loss: 0.082796  [   84/  175]\n",
      "loss: 0.157530  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.075790 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.157004  [    4/  175]\n",
      "loss: 0.010120  [   84/  175]\n",
      "loss: 0.040224  [  164/  175]\n",
      "Training accuracy: 87.9%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 4.701875 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.034112  [    4/  175]\n",
      "loss: 0.018280  [   84/  175]\n",
      "loss: 0.188689  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.131665 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.209496  [    4/  175]\n",
      "loss: 0.814321  [   84/  175]\n",
      "loss: 0.028809  [  164/  175]\n",
      "Training accuracy: 86.9%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 2.128880 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.209615  [    4/  175]\n",
      "loss: 0.120807  [   84/  175]\n",
      "loss: 0.139057  [  164/  175]\n",
      "Training accuracy: 94.9%\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 0.642943 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.915385  [    4/  175]\n",
      "loss: 0.104996  [   84/  175]\n",
      "loss: 0.106149  [  164/  175]\n",
      "Training accuracy: 88.6%\n",
      "Test Error: \n",
      " Accuracy: 67.4%, Avg loss: 0.461667 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.390155  [    4/  175]\n",
      "loss: 0.071822  [   84/  175]\n",
      "loss: 0.015240  [  164/  175]\n",
      "Training accuracy: 88.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.114398 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.038972  [    4/  175]\n",
      "loss: 0.256570  [   84/  175]\n",
      "loss: 0.082064  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.032600 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 1.068343  [    4/  175]\n",
      "loss: 0.058697  [   84/  175]\n",
      "loss: 0.023810  [  164/  175]\n",
      "Training accuracy: 89.8%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.088553 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.141449  [    4/  175]\n",
      "loss: 0.037187  [   84/  175]\n",
      "loss: 0.014216  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.067495 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.115502  [    4/  175]\n",
      "loss: 0.107840  [   84/  175]\n",
      "loss: 0.016129  [  164/  175]\n",
      "Training accuracy: 91.7%\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.287137 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.785421  [    4/  175]\n",
      "loss: 0.034175  [   84/  175]\n",
      "loss: 0.224556  [  164/  175]\n",
      "Training accuracy: 91.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.045583 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.018663  [    4/  175]\n",
      "loss: 0.010336  [   84/  175]\n",
      "loss: 0.021709  [  164/  175]\n",
      "Training accuracy: 96.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.089668 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.958500  [    4/  175]\n",
      "loss: 0.827856  [   84/  175]\n",
      "loss: 0.121286  [  164/  175]\n",
      "Training accuracy: 88.6%\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 1.473926 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.076508  [    4/  175]\n",
      "loss: 0.085224  [   84/  175]\n",
      "loss: 0.025500  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.113345 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.419609  [    4/  175]\n",
      "loss: 1.022137  [   84/  175]\n",
      "loss: 0.037142  [  164/  175]\n",
      "Training accuracy: 88.1%\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.283692 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.793645  [    4/  175]\n",
      "loss: 0.140731  [   84/  175]\n",
      "loss: 0.947645  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 56.8%, Avg loss: 0.753755 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.078981  [    4/  175]\n",
      "loss: 0.106103  [   84/  175]\n",
      "loss: 0.108975  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.051271 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.026871  [    4/  175]\n",
      "loss: 0.013571  [   84/  175]\n",
      "loss: 0.883585  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.049117 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.088426  [    4/  175]\n",
      "loss: 0.157691  [   84/  175]\n",
      "loss: 0.214055  [  164/  175]\n",
      "Training accuracy: 94.9%\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 0.481939 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.019528  [    4/  175]\n",
      "loss: 1.028820  [   84/  175]\n",
      "loss: 0.082165  [  164/  175]\n",
      "Training accuracy: 89.2%\n",
      "Test Error: \n",
      " Accuracy: 72.0%, Avg loss: 0.440289 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 1.122293  [    4/  175]\n",
      "loss: 0.195609  [   84/  175]\n",
      "loss: 0.730005  [  164/  175]\n",
      "Training accuracy: 90.7%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.113066 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.283564  [    4/  175]\n",
      "loss: 0.116756  [   84/  175]\n",
      "loss: 0.213193  [  164/  175]\n",
      "Training accuracy: 86.4%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.067828 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.225841  [    4/  175]\n",
      "loss: 0.015482  [   84/  175]\n",
      "loss: 0.104710  [  164/  175]\n",
      "Training accuracy: 87.7%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.083796 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.048593  [    4/  175]\n",
      "loss: 0.012159  [   84/  175]\n",
      "loss: 0.072729  [  164/  175]\n",
      "Training accuracy: 94.5%\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 0.585960 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.010808  [    4/  175]\n",
      "loss: 0.070475  [   84/  175]\n",
      "loss: 0.089023  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.088350 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.855287  [    4/  175]\n",
      "loss: 0.010746  [   84/  175]\n",
      "loss: 0.113789  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.128636 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.111314  [    4/  175]\n",
      "loss: 0.096633  [   84/  175]\n",
      "loss: 0.095166  [  164/  175]\n",
      "Training accuracy: 94.1%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.064488 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.060042  [    4/  175]\n",
      "loss: 0.085532  [   84/  175]\n",
      "loss: 0.074956  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.020412 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.109857  [    4/  175]\n",
      "loss: 0.065288  [   84/  175]\n",
      "loss: 0.048686  [  164/  175]\n",
      "Training accuracy: 97.2%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.097935 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.230505  [    4/  175]\n",
      "loss: 0.787672  [   84/  175]\n",
      "loss: 0.061804  [  164/  175]\n",
      "Training accuracy: 94.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.030222 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.054567  [    4/  175]\n",
      "loss: 0.100186  [   84/  175]\n",
      "loss: 0.069166  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.219574 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.127274  [    4/  175]\n",
      "loss: 0.265016  [   84/  175]\n",
      "loss: 0.813836  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.018365 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.130739  [    4/  175]\n",
      "loss: 0.004169  [   84/  175]\n",
      "loss: 0.240522  [  164/  175]\n",
      "Training accuracy: 85.2%\n",
      "Test Error: \n",
      " Accuracy: 89.4%, Avg loss: 0.231071 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.011996  [    4/  175]\n",
      "loss: 0.663129  [   84/  175]\n",
      "loss: 0.127077  [  164/  175]\n",
      "Training accuracy: 92.4%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.090937 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.014564  [    4/  175]\n",
      "loss: 0.054796  [   84/  175]\n",
      "loss: 0.160281  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.100576 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.089845  [    4/  175]\n",
      "loss: 0.131704  [   84/  175]\n",
      "loss: 0.056199  [  164/  175]\n",
      "Training accuracy: 90.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.052615 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.369826  [    4/  175]\n",
      "loss: 0.169572  [   84/  175]\n",
      "loss: 0.015860  [  164/  175]\n",
      "Training accuracy: 87.3%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.706215 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.072668  [    4/  175]\n",
      "loss: 0.069344  [   84/  175]\n",
      "loss: 0.147986  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.034206 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.299034  [    4/  175]\n",
      "loss: 0.057399  [   84/  175]\n",
      "loss: 0.104010  [  164/  175]\n",
      "Training accuracy: 90.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.025123 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.014343  [    4/  175]\n",
      "loss: 0.092357  [   84/  175]\n",
      "loss: 0.046964  [  164/  175]\n",
      "Training accuracy: 89.8%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.080644 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.217817  [    4/  175]\n",
      "loss: 0.041660  [   84/  175]\n",
      "loss: 0.009933  [  164/  175]\n",
      "Training accuracy: 95.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.025002 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.080195  [    4/  175]\n",
      "loss: 0.013530  [   84/  175]\n",
      "loss: 0.738109  [  164/  175]\n",
      "Training accuracy: 90.0%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.220347 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.070674  [    4/  175]\n",
      "loss: 0.125292  [   84/  175]\n",
      "loss: 0.051904  [  164/  175]\n",
      "Training accuracy: 90.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.036259 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.136864  [    4/  175]\n",
      "loss: 0.062118  [   84/  175]\n",
      "loss: 0.014562  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.071837 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.979679  [    4/  175]\n",
      "loss: 0.138337  [   84/  175]\n",
      "loss: 0.806953  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.042855 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.032914  [    4/  175]\n",
      "loss: 0.039187  [   84/  175]\n",
      "loss: 0.040543  [  164/  175]\n",
      "Training accuracy: 92.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.048623 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.013403  [    4/  175]\n",
      "loss: 0.083521  [   84/  175]\n",
      "loss: 0.012419  [  164/  175]\n",
      "Training accuracy: 92.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.049691 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.096575  [    4/  175]\n",
      "loss: 0.138325  [   84/  175]\n",
      "loss: 0.005559  [  164/  175]\n",
      "Training accuracy: 91.7%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.038705 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.004132  [    4/  175]\n",
      "loss: 0.997976  [   84/  175]\n",
      "loss: 0.982299  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.079872 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.139135  [    4/  175]\n",
      "loss: 0.015074  [   84/  175]\n",
      "loss: 0.115037  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.038089 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.005759  [    4/  175]\n",
      "loss: 0.006887  [   84/  175]\n",
      "loss: 0.013199  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.017522 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.019718  [    4/  175]\n",
      "loss: 0.055341  [   84/  175]\n",
      "loss: 0.076213  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.013897 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.048869  [    4/  175]\n",
      "loss: 0.079369  [   84/  175]\n",
      "loss: 0.996857  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.016141 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.005266  [    4/  175]\n",
      "loss: 0.011619  [   84/  175]\n",
      "loss: 0.069382  [  164/  175]\n",
      "Training accuracy: 91.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.017980 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.089579  [    4/  175]\n",
      "loss: 0.065457  [   84/  175]\n",
      "loss: 0.091837  [  164/  175]\n",
      "Training accuracy: 97.2%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.074225 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.010434  [    4/  175]\n",
      "loss: 0.005804  [   84/  175]\n",
      "loss: 0.094471  [  164/  175]\n",
      "Training accuracy: 91.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.027439 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.026699  [    4/  175]\n",
      "loss: 0.057531  [   84/  175]\n",
      "loss: 0.065077  [  164/  175]\n",
      "Training accuracy: 86.4%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.018493 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.071777  [    4/  175]\n",
      "loss: 0.047805  [   84/  175]\n",
      "loss: 0.071502  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 92.4%, Avg loss: 0.168102 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.036453  [    4/  175]\n",
      "loss: 0.031455  [   84/  175]\n",
      "loss: 0.005278  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.086636 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.005590  [    4/  175]\n",
      "loss: 0.039349  [   84/  175]\n",
      "loss: 0.004739  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 66.7%, Avg loss: 0.955320 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 4\n",
    "epochs = 100\n",
    "\n",
    "log_dir = os.path.join(\"runs\", \"experiment_005\")\n",
    "shutil.rmtree(log_dir, ignore_errors=True)\n",
    "\n",
    "model = ModelWithSimpleRnn().to(device)\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "print(f\"Training model with Adam...\")\n",
    "log_subdir = os.path.join(log_dir, \"adam\" + \"_\" + datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"))\n",
    "tb = SummaryWriter(log_subdir)\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t}\\n-------------------------------\")\n",
    "    train_metrics = train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_metrics = test_loop(test_dataloader, model, loss_fn)\n",
    "    tb.add_scalar(\"Loss/train\", train_metrics[\"loss\"], t)\n",
    "    tb.add_scalar(\"Accuracy/train\", train_metrics[\"acc\"], t)\n",
    "    tb.add_scalar(\"Loss/test\", test_metrics[\"loss\"], t)\n",
    "    tb.add_scalar(\"Accuracy/test\", test_metrics[\"acc\"], t)\n",
    "    for name, weight in model.named_parameters():\n",
    "        tb.add_histogram(f\"Weights/{name}\", weight, t)\n",
    "        tb.add_histogram(f\"Gradients/{name}\", weight.grad, t)\n",
    "\n",
    "tb.close()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nope, that doesn't seem to help."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization\n",
    "\n",
    "L2 regularization might at least make the training more stable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with L2 regularization 0...\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "loss: 0.761756  [    4/  175]\n",
      "loss: 0.524852  [   84/  175]\n",
      "loss: 0.626425  [  164/  175]\n",
      "Training accuracy: 56.1%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 0.707432 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.561244  [    4/  175]\n",
      "loss: 0.563479  [   84/  175]\n",
      "loss: 0.710015  [  164/  175]\n",
      "Training accuracy: 63.4%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 0.727187 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.685253  [    4/  175]\n",
      "loss: 0.462435  [   84/  175]\n",
      "loss: 0.745215  [  164/  175]\n",
      "Training accuracy: 61.0%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.592807 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.647031  [    4/  175]\n",
      "loss: 0.568999  [   84/  175]\n",
      "loss: 0.522665  [  164/  175]\n",
      "Training accuracy: 63.4%\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 0.604766 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.592939  [    4/  175]\n",
      "loss: 0.839033  [   84/  175]\n",
      "loss: 0.620034  [  164/  175]\n",
      "Training accuracy: 72.0%\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 0.601896 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.531017  [    4/  175]\n",
      "loss: 0.577939  [   84/  175]\n",
      "loss: 0.851577  [  164/  175]\n",
      "Training accuracy: 72.2%\n",
      "Test Error: \n",
      " Accuracy: 68.9%, Avg loss: 0.576720 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.847124  [    4/  175]\n",
      "loss: 0.436805  [   84/  175]\n",
      "loss: 0.575758  [  164/  175]\n",
      "Training accuracy: 73.7%\n",
      "Test Error: \n",
      " Accuracy: 62.1%, Avg loss: 0.645187 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.601392  [    4/  175]\n",
      "loss: 0.679105  [   84/  175]\n",
      "loss: 0.674307  [  164/  175]\n",
      "Training accuracy: 66.7%\n",
      "Test Error: \n",
      " Accuracy: 72.7%, Avg loss: 0.572512 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.523702  [    4/  175]\n",
      "loss: 0.377612  [   84/  175]\n",
      "loss: 0.446115  [  164/  175]\n",
      "Training accuracy: 75.9%\n",
      "Test Error: \n",
      " Accuracy: 72.0%, Avg loss: 0.563821 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.536864  [    4/  175]\n",
      "loss: 0.370377  [   84/  175]\n",
      "loss: 0.393297  [  164/  175]\n",
      "Training accuracy: 77.7%\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 0.721421 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.364156  [    4/  175]\n",
      "loss: 0.350856  [   84/  175]\n",
      "loss: 0.304804  [  164/  175]\n",
      "Training accuracy: 74.2%\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.502816 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.608152  [    4/  175]\n",
      "loss: 0.445068  [   84/  175]\n",
      "loss: 0.986431  [  164/  175]\n",
      "Training accuracy: 75.6%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 2.558401 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.624191  [    4/  175]\n",
      "loss: 0.435162  [   84/  175]\n",
      "loss: 0.401318  [  164/  175]\n",
      "Training accuracy: 78.8%\n",
      "Test Error: \n",
      " Accuracy: 71.2%, Avg loss: 0.576105 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.589563  [    4/  175]\n",
      "loss: 0.416415  [   84/  175]\n",
      "loss: 0.636519  [  164/  175]\n",
      "Training accuracy: 80.1%\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 0.530036 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.222195  [    4/  175]\n",
      "loss: 0.369705  [   84/  175]\n",
      "loss: 0.352056  [  164/  175]\n",
      "Training accuracy: 83.1%\n",
      "Test Error: \n",
      " Accuracy: 69.7%, Avg loss: 0.618265 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.432693  [    4/  175]\n",
      "loss: 0.786015  [   84/  175]\n",
      "loss: 0.296075  [  164/  175]\n",
      "Training accuracy: 77.8%\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.453951 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.520752  [    4/  175]\n",
      "loss: 1.082702  [   84/  175]\n",
      "loss: 0.799768  [  164/  175]\n",
      "Training accuracy: 74.4%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.163303 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.215545  [    4/  175]\n",
      "loss: 0.449365  [   84/  175]\n",
      "loss: 0.408464  [  164/  175]\n",
      "Training accuracy: 77.1%\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.341244 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.764030  [    4/  175]\n",
      "loss: 0.390478  [   84/  175]\n",
      "loss: 0.325116  [  164/  175]\n",
      "Training accuracy: 77.5%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 0.640258 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.513723  [    4/  175]\n",
      "loss: 0.390678  [   84/  175]\n",
      "loss: 0.381804  [  164/  175]\n",
      "Training accuracy: 82.4%\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.363102 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.215358  [    4/  175]\n",
      "loss: 0.677994  [   84/  175]\n",
      "loss: 0.314736  [  164/  175]\n",
      "Training accuracy: 77.7%\n",
      "Test Error: \n",
      " Accuracy: 72.0%, Avg loss: 0.529895 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.258906  [    4/  175]\n",
      "loss: 0.155088  [   84/  175]\n",
      "loss: 0.777988  [  164/  175]\n",
      "Training accuracy: 82.2%\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 0.841918 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.480653  [    4/  175]\n",
      "loss: 0.424278  [   84/  175]\n",
      "loss: 0.109191  [  164/  175]\n",
      "Training accuracy: 81.6%\n",
      "Test Error: \n",
      " Accuracy: 55.3%, Avg loss: 0.600476 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.260601  [    4/  175]\n",
      "loss: 0.339437  [   84/  175]\n",
      "loss: 0.507798  [  164/  175]\n",
      "Training accuracy: 78.2%\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.295188 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.812222  [    4/  175]\n",
      "loss: 0.237236  [   84/  175]\n",
      "loss: 0.228944  [  164/  175]\n",
      "Training accuracy: 83.7%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 2.106449 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.304881  [    4/  175]\n",
      "loss: 0.438704  [   84/  175]\n",
      "loss: 0.599422  [  164/  175]\n",
      "Training accuracy: 81.2%\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.336925 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.431367  [    4/  175]\n",
      "loss: 0.459045  [   84/  175]\n",
      "loss: 0.239527  [  164/  175]\n",
      "Training accuracy: 85.2%\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.230550 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.663210  [    4/  175]\n",
      "loss: 0.354325  [   84/  175]\n",
      "loss: 0.313028  [  164/  175]\n",
      "Training accuracy: 84.7%\n",
      "Test Error: \n",
      " Accuracy: 92.4%, Avg loss: 0.232511 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.816616  [    4/  175]\n",
      "loss: 0.256376  [   84/  175]\n",
      "loss: 0.155540  [  164/  175]\n",
      "Training accuracy: 84.5%\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.434358 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.588475  [    4/  175]\n",
      "loss: 0.279134  [   84/  175]\n",
      "loss: 0.938300  [  164/  175]\n",
      "Training accuracy: 80.3%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 2.031174 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.542768  [    4/  175]\n",
      "loss: 0.263401  [   84/  175]\n",
      "loss: 0.991132  [  164/  175]\n",
      "Training accuracy: 83.9%\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.266373 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.179683  [    4/  175]\n",
      "loss: 0.290025  [   84/  175]\n",
      "loss: 0.129435  [  164/  175]\n",
      "Training accuracy: 83.5%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.186971 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.243714  [    4/  175]\n",
      "loss: 0.251977  [   84/  175]\n",
      "loss: 0.109016  [  164/  175]\n",
      "Training accuracy: 88.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.188284 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.640503  [    4/  175]\n",
      "loss: 0.144484  [   84/  175]\n",
      "loss: 0.720851  [  164/  175]\n",
      "Training accuracy: 81.1%\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.252053 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.185759  [    4/  175]\n",
      "loss: 0.121313  [   84/  175]\n",
      "loss: 0.911125  [  164/  175]\n",
      "Training accuracy: 88.1%\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.430096 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.094642  [    4/  175]\n",
      "loss: 0.153903  [   84/  175]\n",
      "loss: 0.585364  [  164/  175]\n",
      "Training accuracy: 89.2%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.187445 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 1.124121  [    4/  175]\n",
      "loss: 0.232630  [   84/  175]\n",
      "loss: 0.223514  [  164/  175]\n",
      "Training accuracy: 85.6%\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.462242 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.150736  [    4/  175]\n",
      "loss: 0.126155  [   84/  175]\n",
      "loss: 0.346091  [  164/  175]\n",
      "Training accuracy: 83.7%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 16.607621 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.059394  [    4/  175]\n",
      "loss: 0.850509  [   84/  175]\n",
      "loss: 0.206993  [  164/  175]\n",
      "Training accuracy: 86.9%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.164289 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.206367  [    4/  175]\n",
      "loss: 0.838489  [   84/  175]\n",
      "loss: 0.399359  [  164/  175]\n",
      "Training accuracy: 81.2%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.169085 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.077438  [    4/  175]\n",
      "loss: 0.082652  [   84/  175]\n",
      "loss: 0.682738  [  164/  175]\n",
      "Training accuracy: 85.2%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.130401 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.256207  [    4/  175]\n",
      "loss: 0.127723  [   84/  175]\n",
      "loss: 0.834742  [  164/  175]\n",
      "Training accuracy: 83.5%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.142128 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.774969  [    4/  175]\n",
      "loss: 0.198443  [   84/  175]\n",
      "loss: 0.638554  [  164/  175]\n",
      "Training accuracy: 85.0%\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 6.502747 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.348580  [    4/  175]\n",
      "loss: 0.078755  [   84/  175]\n",
      "loss: 0.127159  [  164/  175]\n",
      "Training accuracy: 88.1%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.170406 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.076050  [    4/  175]\n",
      "loss: 0.085967  [   84/  175]\n",
      "loss: 0.216277  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.101772 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.143024  [    4/  175]\n",
      "loss: 0.384419  [   84/  175]\n",
      "loss: 0.142909  [  164/  175]\n",
      "Training accuracy: 91.7%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.136502 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.396345  [    4/  175]\n",
      "loss: 0.164064  [   84/  175]\n",
      "loss: 0.380412  [  164/  175]\n",
      "Training accuracy: 86.4%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.121294 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.068260  [    4/  175]\n",
      "loss: 0.249174  [   84/  175]\n",
      "loss: 0.089210  [  164/  175]\n",
      "Training accuracy: 88.1%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.101317 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.251226  [    4/  175]\n",
      "loss: 1.073646  [   84/  175]\n",
      "loss: 0.053256  [  164/  175]\n",
      "Training accuracy: 84.1%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.086444 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.068661  [    4/  175]\n",
      "loss: 0.054410  [   84/  175]\n",
      "loss: 0.171667  [  164/  175]\n",
      "Training accuracy: 89.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.081799 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.201904  [    4/  175]\n",
      "loss: 0.061839  [   84/  175]\n",
      "loss: 0.839696  [  164/  175]\n",
      "Training accuracy: 88.4%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.085446 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.049341  [    4/  175]\n",
      "loss: 0.152210  [   84/  175]\n",
      "loss: 0.177883  [  164/  175]\n",
      "Training accuracy: 91.9%\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 0.457596 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.115280  [    4/  175]\n",
      "loss: 0.044837  [   84/  175]\n",
      "loss: 0.214400  [  164/  175]\n",
      "Training accuracy: 96.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.064474 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.048942  [    4/  175]\n",
      "loss: 0.124785  [   84/  175]\n",
      "loss: 0.129496  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.088447 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.105213  [    4/  175]\n",
      "loss: 0.125508  [   84/  175]\n",
      "loss: 0.175039  [  164/  175]\n",
      "Training accuracy: 90.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.076929 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.437219  [    4/  175]\n",
      "loss: 0.054366  [   84/  175]\n",
      "loss: 0.041303  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.061056 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.131333  [    4/  175]\n",
      "loss: 1.124949  [   84/  175]\n",
      "loss: 0.029159  [  164/  175]\n",
      "Training accuracy: 87.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.065992 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.916261  [    4/  175]\n",
      "loss: 0.135027  [   84/  175]\n",
      "loss: 0.473798  [  164/  175]\n",
      "Training accuracy: 87.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.055623 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.029969  [    4/  175]\n",
      "loss: 0.098433  [   84/  175]\n",
      "loss: 0.153240  [  164/  175]\n",
      "Training accuracy: 96.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.069904 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 1.105228  [    4/  175]\n",
      "loss: 0.049848  [   84/  175]\n",
      "loss: 0.163289  [  164/  175]\n",
      "Training accuracy: 86.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.062127 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.042236  [    4/  175]\n",
      "loss: 0.120710  [   84/  175]\n",
      "loss: 0.054392  [  164/  175]\n",
      "Training accuracy: 86.4%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.056739 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.098896  [    4/  175]\n",
      "loss: 0.180874  [   84/  175]\n",
      "loss: 0.733681  [  164/  175]\n",
      "Training accuracy: 95.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.056691 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.092032  [    4/  175]\n",
      "loss: 0.796280  [   84/  175]\n",
      "loss: 0.032835  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.051874 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.260343  [    4/  175]\n",
      "loss: 0.135939  [   84/  175]\n",
      "loss: 0.204986  [  164/  175]\n",
      "Training accuracy: 96.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.048672 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.109171  [    4/  175]\n",
      "loss: 1.103383  [   84/  175]\n",
      "loss: 0.078318  [  164/  175]\n",
      "Training accuracy: 91.1%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.037921 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.052251  [    4/  175]\n",
      "loss: 0.124618  [   84/  175]\n",
      "loss: 0.129079  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.050668 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.039063  [    4/  175]\n",
      "loss: 0.136429  [   84/  175]\n",
      "loss: 0.129182  [  164/  175]\n",
      "Training accuracy: 94.7%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.040728 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.036326  [    4/  175]\n",
      "loss: 0.021180  [   84/  175]\n",
      "loss: 0.348544  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.069346 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.112315  [    4/  175]\n",
      "loss: 1.089231  [   84/  175]\n",
      "loss: 0.100637  [  164/  175]\n",
      "Training accuracy: 91.1%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.115439 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.057019  [    4/  175]\n",
      "loss: 0.033847  [   84/  175]\n",
      "loss: 0.075256  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.056541 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.208883  [    4/  175]\n",
      "loss: 0.091738  [   84/  175]\n",
      "loss: 0.307619  [  164/  175]\n",
      "Training accuracy: 94.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.036946 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.750805  [    4/  175]\n",
      "loss: 0.069047  [   84/  175]\n",
      "loss: 0.220579  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.032640 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.017583  [    4/  175]\n",
      "loss: 0.020759  [   84/  175]\n",
      "loss: 0.091692  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.033029 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.092077  [    4/  175]\n",
      "loss: 0.026820  [   84/  175]\n",
      "loss: 0.016189  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.046880 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.958680  [    4/  175]\n",
      "loss: 0.796627  [   84/  175]\n",
      "loss: 1.213569  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.043940 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.015530  [    4/  175]\n",
      "loss: 0.112193  [   84/  175]\n",
      "loss: 0.086293  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.022133 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.117595  [    4/  175]\n",
      "loss: 0.041589  [   84/  175]\n",
      "loss: 0.108482  [  164/  175]\n",
      "Training accuracy: 86.4%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.035470 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.097896  [    4/  175]\n",
      "loss: 0.253516  [   84/  175]\n",
      "loss: 0.157805  [  164/  175]\n",
      "Training accuracy: 96.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.030427 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.018928  [    4/  175]\n",
      "loss: 0.286929  [   84/  175]\n",
      "loss: 0.021670  [  164/  175]\n",
      "Training accuracy: 87.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.035949 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.498034  [    4/  175]\n",
      "loss: 0.083364  [   84/  175]\n",
      "loss: 0.170673  [  164/  175]\n",
      "Training accuracy: 91.1%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.033809 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.115568  [    4/  175]\n",
      "loss: 0.017939  [   84/  175]\n",
      "loss: 0.049911  [  164/  175]\n",
      "Training accuracy: 95.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.058164 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.030518  [    4/  175]\n",
      "loss: 0.013399  [   84/  175]\n",
      "loss: 0.021720  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.035092 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.020304  [    4/  175]\n",
      "loss: 0.124531  [   84/  175]\n",
      "loss: 0.016493  [  164/  175]\n",
      "Training accuracy: 88.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.032885 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.015939  [    4/  175]\n",
      "loss: 0.713006  [   84/  175]\n",
      "loss: 0.027000  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.033504 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.142707  [    4/  175]\n",
      "loss: 0.014545  [   84/  175]\n",
      "loss: 0.099082  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.038846 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.228103  [    4/  175]\n",
      "loss: 0.186179  [   84/  175]\n",
      "loss: 0.083301  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.031951 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.662258  [    4/  175]\n",
      "loss: 0.024658  [   84/  175]\n",
      "loss: 0.137825  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.023139 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.100386  [    4/  175]\n",
      "loss: 0.020374  [   84/  175]\n",
      "loss: 0.021164  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.031677 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.361127  [    4/  175]\n",
      "loss: 0.103009  [   84/  175]\n",
      "loss: 0.169445  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.029557 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.074532  [    4/  175]\n",
      "loss: 1.192381  [   84/  175]\n",
      "loss: 0.988512  [  164/  175]\n",
      "Training accuracy: 89.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.022775 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.079105  [    4/  175]\n",
      "loss: 0.087430  [   84/  175]\n",
      "loss: 0.707988  [  164/  175]\n",
      "Training accuracy: 95.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.020832 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.078322  [    4/  175]\n",
      "loss: 0.130441  [   84/  175]\n",
      "loss: 0.015788  [  164/  175]\n",
      "Training accuracy: 91.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.027347 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.146862  [    4/  175]\n",
      "loss: 0.012028  [   84/  175]\n",
      "loss: 0.052077  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.020671 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.112324  [    4/  175]\n",
      "loss: 0.018282  [   84/  175]\n",
      "loss: 0.009513  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.042744 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.097276  [    4/  175]\n",
      "loss: 0.027782  [   84/  175]\n",
      "loss: 0.012556  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.017517 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.741902  [    4/  175]\n",
      "loss: 0.122022  [   84/  175]\n",
      "loss: 0.014927  [  164/  175]\n",
      "Training accuracy: 92.4%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.060665 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.163829  [    4/  175]\n",
      "loss: 0.174799  [   84/  175]\n",
      "loss: 0.009386  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.023523 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.718870  [    4/  175]\n",
      "loss: 0.021707  [   84/  175]\n",
      "loss: 0.293482  [  164/  175]\n",
      "Training accuracy: 85.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.030390 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.270600  [    4/  175]\n",
      "loss: 1.381536  [   84/  175]\n",
      "loss: 0.788815  [  164/  175]\n",
      "Training accuracy: 87.7%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.033535 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.094788  [    4/  175]\n",
      "loss: 0.124811  [   84/  175]\n",
      "loss: 0.141044  [  164/  175]\n",
      "Training accuracy: 96.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.021819 \n",
      "\n",
      "Done!\n",
      "Training model with L2 regularization 0.001...\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "loss: 0.678690  [    4/  175]\n",
      "loss: 0.729486  [   84/  175]\n",
      "loss: 0.629551  [  164/  175]\n",
      "Training accuracy: 63.3%\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.683647 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.611873  [    4/  175]\n",
      "loss: 0.395658  [   84/  175]\n",
      "loss: 0.688349  [  164/  175]\n",
      "Training accuracy: 68.2%\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.907071 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.494795  [    4/  175]\n",
      "loss: 0.752303  [   84/  175]\n",
      "loss: 0.927434  [  164/  175]\n",
      "Training accuracy: 70.8%\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 0.678244 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.680916  [    4/  175]\n",
      "loss: 0.529833  [   84/  175]\n",
      "loss: 0.584797  [  164/  175]\n",
      "Training accuracy: 64.4%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.456924 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.625444  [    4/  175]\n",
      "loss: 0.623682  [   84/  175]\n",
      "loss: 0.476862  [  164/  175]\n",
      "Training accuracy: 72.0%\n",
      "Test Error: \n",
      " Accuracy: 66.7%, Avg loss: 0.814524 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.422233  [    4/  175]\n",
      "loss: 0.780850  [   84/  175]\n",
      "loss: 0.552158  [  164/  175]\n",
      "Training accuracy: 68.6%\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 2.254991 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.763071  [    4/  175]\n",
      "loss: 0.585115  [   84/  175]\n",
      "loss: 0.673820  [  164/  175]\n",
      "Training accuracy: 72.7%\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 2.379863 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.435478  [    4/  175]\n",
      "loss: 0.741996  [   84/  175]\n",
      "loss: 0.478747  [  164/  175]\n",
      "Training accuracy: 74.2%\n",
      "Test Error: \n",
      " Accuracy: 52.3%, Avg loss: 1.061307 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.427471  [    4/  175]\n",
      "loss: 0.655186  [   84/  175]\n",
      "loss: 0.516563  [  164/  175]\n",
      "Training accuracy: 69.7%\n",
      "Test Error: \n",
      " Accuracy: 62.9%, Avg loss: 0.803032 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.781382  [    4/  175]\n",
      "loss: 0.477801  [   84/  175]\n",
      "loss: 0.736800  [  164/  175]\n",
      "Training accuracy: 75.0%\n",
      "Test Error: \n",
      " Accuracy: 65.2%, Avg loss: 0.773612 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.432355  [    4/  175]\n",
      "loss: 0.429794  [   84/  175]\n",
      "loss: 0.516275  [  164/  175]\n",
      "Training accuracy: 74.8%\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 0.538685 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.482749  [    4/  175]\n",
      "loss: 0.774956  [   84/  175]\n",
      "loss: 0.258238  [  164/  175]\n",
      "Training accuracy: 81.8%\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.726745 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.379993  [    4/  175]\n",
      "loss: 0.490954  [   84/  175]\n",
      "loss: 0.496391  [  164/  175]\n",
      "Training accuracy: 80.9%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 5.783500 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.507909  [    4/  175]\n",
      "loss: 0.418147  [   84/  175]\n",
      "loss: 0.291619  [  164/  175]\n",
      "Training accuracy: 81.2%\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 1.482297 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.380662  [    4/  175]\n",
      "loss: 0.731048  [   84/  175]\n",
      "loss: 0.267369  [  164/  175]\n",
      "Training accuracy: 81.1%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 2.948022 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.403580  [    4/  175]\n",
      "loss: 0.337236  [   84/  175]\n",
      "loss: 0.431837  [  164/  175]\n",
      "Training accuracy: 89.2%\n",
      "Test Error: \n",
      " Accuracy: 69.7%, Avg loss: 0.613362 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.703471  [    4/  175]\n",
      "loss: 0.307752  [   84/  175]\n",
      "loss: 0.365745  [  164/  175]\n",
      "Training accuracy: 83.7%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 2.184531 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.550281  [    4/  175]\n",
      "loss: 0.402941  [   84/  175]\n",
      "loss: 0.264258  [  164/  175]\n",
      "Training accuracy: 89.2%\n",
      "Test Error: \n",
      " Accuracy: 64.4%, Avg loss: 0.628655 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.142452  [    4/  175]\n",
      "loss: 0.289812  [   84/  175]\n",
      "loss: 0.385191  [  164/  175]\n",
      "Training accuracy: 89.8%\n",
      "Test Error: \n",
      " Accuracy: 92.4%, Avg loss: 0.288545 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.336726  [    4/  175]\n",
      "loss: 0.315667  [   84/  175]\n",
      "loss: 0.194478  [  164/  175]\n",
      "Training accuracy: 87.7%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.232309 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.276074  [    4/  175]\n",
      "loss: 0.754096  [   84/  175]\n",
      "loss: 0.250729  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 57.6%, Avg loss: 0.741901 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.197551  [    4/  175]\n",
      "loss: 0.233738  [   84/  175]\n",
      "loss: 0.212105  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.242610 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.197790  [    4/  175]\n",
      "loss: 0.219203  [   84/  175]\n",
      "loss: 0.305656  [  164/  175]\n",
      "Training accuracy: 86.4%\n",
      "Test Error: \n",
      " Accuracy: 59.1%, Avg loss: 0.959653 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.112704  [    4/  175]\n",
      "loss: 0.202043  [   84/  175]\n",
      "loss: 0.193750  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.162898 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.194503  [    4/  175]\n",
      "loss: 0.187253  [   84/  175]\n",
      "loss: 0.175889  [  164/  175]\n",
      "Training accuracy: 89.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.145226 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.059290  [    4/  175]\n",
      "loss: 0.186901  [   84/  175]\n",
      "loss: 0.292839  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.106101 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.282387  [    4/  175]\n",
      "loss: 0.059400  [   84/  175]\n",
      "loss: 1.064511  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 59.1%, Avg loss: 0.985789 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.156629  [    4/  175]\n",
      "loss: 0.130102  [   84/  175]\n",
      "loss: 0.045500  [  164/  175]\n",
      "Training accuracy: 94.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.139754 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.074131  [    4/  175]\n",
      "loss: 0.069250  [   84/  175]\n",
      "loss: 0.241985  [  164/  175]\n",
      "Training accuracy: 86.9%\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.262390 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.142766  [    4/  175]\n",
      "loss: 0.210054  [   84/  175]\n",
      "loss: 0.060575  [  164/  175]\n",
      "Training accuracy: 88.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.118450 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.308777  [    4/  175]\n",
      "loss: 0.053218  [   84/  175]\n",
      "loss: 0.142204  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.093819 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.056746  [    4/  175]\n",
      "loss: 0.065566  [   84/  175]\n",
      "loss: 0.199683  [  164/  175]\n",
      "Training accuracy: 90.5%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.150938 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.169522  [    4/  175]\n",
      "loss: 0.091207  [   84/  175]\n",
      "loss: 0.116671  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.100600 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.170844  [    4/  175]\n",
      "loss: 0.056660  [   84/  175]\n",
      "loss: 0.156120  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.120803 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.938987  [    4/  175]\n",
      "loss: 0.717234  [   84/  175]\n",
      "loss: 0.037765  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.077751 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.762787  [    4/  175]\n",
      "loss: 0.026653  [   84/  175]\n",
      "loss: 0.294277  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.107251 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.050624  [    4/  175]\n",
      "loss: 0.074277  [   84/  175]\n",
      "loss: 0.408122  [  164/  175]\n",
      "Training accuracy: 91.1%\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.331272 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.155852  [    4/  175]\n",
      "loss: 0.076019  [   84/  175]\n",
      "loss: 0.031625  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.090078 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.037148  [    4/  175]\n",
      "loss: 0.095008  [   84/  175]\n",
      "loss: 0.994426  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.061658 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.296799  [    4/  175]\n",
      "loss: 0.133976  [   84/  175]\n",
      "loss: 0.206433  [  164/  175]\n",
      "Training accuracy: 86.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.106374 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.021336  [    4/  175]\n",
      "loss: 1.130143  [   84/  175]\n",
      "loss: 0.150723  [  164/  175]\n",
      "Training accuracy: 92.4%\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.225866 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.031773  [    4/  175]\n",
      "loss: 0.017967  [   84/  175]\n",
      "loss: 1.299729  [  164/  175]\n",
      "Training accuracy: 87.5%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.154267 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.113405  [    4/  175]\n",
      "loss: 0.602295  [   84/  175]\n",
      "loss: 0.090849  [  164/  175]\n",
      "Training accuracy: 91.3%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 3.585845 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.534560  [    4/  175]\n",
      "loss: 0.179802  [   84/  175]\n",
      "loss: 0.018550  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.062598 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.081975  [    4/  175]\n",
      "loss: 0.025229  [   84/  175]\n",
      "loss: 0.865236  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.231480 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.149198  [    4/  175]\n",
      "loss: 0.049741  [   84/  175]\n",
      "loss: 0.178404  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.053707 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.033282  [    4/  175]\n",
      "loss: 0.073933  [   84/  175]\n",
      "loss: 0.719109  [  164/  175]\n",
      "Training accuracy: 93.9%\n",
      "Test Error: \n",
      " Accuracy: 67.4%, Avg loss: 0.919963 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.086663  [    4/  175]\n",
      "loss: 0.228557  [   84/  175]\n",
      "loss: 0.013598  [  164/  175]\n",
      "Training accuracy: 89.4%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.054546 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.026154  [    4/  175]\n",
      "loss: 0.102168  [   84/  175]\n",
      "loss: 0.187193  [  164/  175]\n",
      "Training accuracy: 88.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.053336 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.015386  [    4/  175]\n",
      "loss: 0.043338  [   84/  175]\n",
      "loss: 0.089981  [  164/  175]\n",
      "Training accuracy: 95.3%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.164354 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.206467  [    4/  175]\n",
      "loss: 0.226077  [   84/  175]\n",
      "loss: 0.192658  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.035120 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.819529  [    4/  175]\n",
      "loss: 0.084027  [   84/  175]\n",
      "loss: 0.992311  [  164/  175]\n",
      "Training accuracy: 85.2%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.098360 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.171246  [    4/  175]\n",
      "loss: 0.185039  [   84/  175]\n",
      "loss: 0.035643  [  164/  175]\n",
      "Training accuracy: 97.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.032818 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.151696  [    4/  175]\n",
      "loss: 0.722231  [   84/  175]\n",
      "loss: 0.050048  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.048154 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.016445  [    4/  175]\n",
      "loss: 0.272025  [   84/  175]\n",
      "loss: 0.080602  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.396148 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.031722  [    4/  175]\n",
      "loss: 0.782079  [   84/  175]\n",
      "loss: 0.841590  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.085807 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.235016  [    4/  175]\n",
      "loss: 0.015715  [   84/  175]\n",
      "loss: 0.076836  [  164/  175]\n",
      "Training accuracy: 95.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.036898 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.085612  [    4/  175]\n",
      "loss: 0.027881  [   84/  175]\n",
      "loss: 0.326971  [  164/  175]\n",
      "Training accuracy: 94.9%\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.164223 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.013985  [    4/  175]\n",
      "loss: 0.059726  [   84/  175]\n",
      "loss: 0.020416  [  164/  175]\n",
      "Training accuracy: 92.4%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.076042 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.009563  [    4/  175]\n",
      "loss: 0.016864  [   84/  175]\n",
      "loss: 0.354613  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.033194 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.058450  [    4/  175]\n",
      "loss: 0.083222  [   84/  175]\n",
      "loss: 0.064825  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.137042 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.093019  [    4/  175]\n",
      "loss: 0.669945  [   84/  175]\n",
      "loss: 0.413201  [  164/  175]\n",
      "Training accuracy: 89.8%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.098680 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.191988  [    4/  175]\n",
      "loss: 0.037929  [   84/  175]\n",
      "loss: 0.923361  [  164/  175]\n",
      "Training accuracy: 85.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.113281 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.069200  [    4/  175]\n",
      "loss: 0.086354  [   84/  175]\n",
      "loss: 0.017050  [  164/  175]\n",
      "Training accuracy: 95.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.034974 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.012175  [    4/  175]\n",
      "loss: 0.061401  [   84/  175]\n",
      "loss: 0.075085  [  164/  175]\n",
      "Training accuracy: 95.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.083769 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.009031  [    4/  175]\n",
      "loss: 0.164349  [   84/  175]\n",
      "loss: 0.330097  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 1.138507 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.011141  [    4/  175]\n",
      "loss: 0.125627  [   84/  175]\n",
      "loss: 0.043681  [  164/  175]\n",
      "Training accuracy: 95.5%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.072417 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.063989  [    4/  175]\n",
      "loss: 0.048750  [   84/  175]\n",
      "loss: 0.007564  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.202160 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.010759  [    4/  175]\n",
      "loss: 0.103857  [   84/  175]\n",
      "loss: 0.007373  [  164/  175]\n",
      "Training accuracy: 87.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.164406 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 1.317417  [    4/  175]\n",
      "loss: 0.925363  [   84/  175]\n",
      "loss: 0.057579  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.090930 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.191836  [    4/  175]\n",
      "loss: 0.061691  [   84/  175]\n",
      "loss: 0.114012  [  164/  175]\n",
      "Training accuracy: 90.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.035456 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.091585  [    4/  175]\n",
      "loss: 0.065630  [   84/  175]\n",
      "loss: 0.855618  [  164/  175]\n",
      "Training accuracy: 92.2%\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.267009 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.059220  [    4/  175]\n",
      "loss: 0.083473  [   84/  175]\n",
      "loss: 0.100100  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.118614 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.048941  [    4/  175]\n",
      "loss: 0.049594  [   84/  175]\n",
      "loss: 0.062205  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.031894 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.799198  [    4/  175]\n",
      "loss: 0.014554  [   84/  175]\n",
      "loss: 0.100331  [  164/  175]\n",
      "Training accuracy: 92.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.027453 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 1.235002  [    4/  175]\n",
      "loss: 0.012365  [   84/  175]\n",
      "loss: 0.036688  [  164/  175]\n",
      "Training accuracy: 95.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.066096 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.070500  [    4/  175]\n",
      "loss: 0.018587  [   84/  175]\n",
      "loss: 0.006924  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.034998 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.086606  [    4/  175]\n",
      "loss: 0.091557  [   84/  175]\n",
      "loss: 0.043559  [  164/  175]\n",
      "Training accuracy: 95.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.030094 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.055843  [    4/  175]\n",
      "loss: 0.852580  [   84/  175]\n",
      "loss: 0.011149  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.029998 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.056103  [    4/  175]\n",
      "loss: 0.696995  [   84/  175]\n",
      "loss: 0.817249  [  164/  175]\n",
      "Training accuracy: 89.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.024582 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.806109  [    4/  175]\n",
      "loss: 0.059736  [   84/  175]\n",
      "loss: 0.022715  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.027028 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.021605  [    4/  175]\n",
      "loss: 0.055611  [   84/  175]\n",
      "loss: 0.065304  [  164/  175]\n",
      "Training accuracy: 91.3%\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 2.747878 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.177001  [    4/  175]\n",
      "loss: 0.590876  [   84/  175]\n",
      "loss: 0.018702  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.052928 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.065790  [    4/  175]\n",
      "loss: 0.090466  [   84/  175]\n",
      "loss: 0.009549  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.068518 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.006180  [    4/  175]\n",
      "loss: 0.063014  [   84/  175]\n",
      "loss: 0.007062  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.022563 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.044432  [    4/  175]\n",
      "loss: 0.051248  [   84/  175]\n",
      "loss: 0.116101  [  164/  175]\n",
      "Training accuracy: 92.4%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.041418 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.060390  [    4/  175]\n",
      "loss: 0.032092  [   84/  175]\n",
      "loss: 0.085007  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.030765 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.057358  [    4/  175]\n",
      "loss: 0.010155  [   84/  175]\n",
      "loss: 0.101590  [  164/  175]\n",
      "Training accuracy: 93.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.025304 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.014319  [    4/  175]\n",
      "loss: 0.013842  [   84/  175]\n",
      "loss: 0.084878  [  164/  175]\n",
      "Training accuracy: 94.9%\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.079486 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.046454  [    4/  175]\n",
      "loss: 0.108787  [   84/  175]\n",
      "loss: 0.762527  [  164/  175]\n",
      "Training accuracy: 86.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.034169 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.082544  [    4/  175]\n",
      "loss: 0.021521  [   84/  175]\n",
      "loss: 0.005578  [  164/  175]\n",
      "Training accuracy: 88.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.061999 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.701928  [    4/  175]\n",
      "loss: 0.197989  [   84/  175]\n",
      "loss: 0.011482  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.026180 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.105129  [    4/  175]\n",
      "loss: 0.827609  [   84/  175]\n",
      "loss: 0.021596  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.020554 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.006435  [    4/  175]\n",
      "loss: 0.040177  [   84/  175]\n",
      "loss: 0.012299  [  164/  175]\n",
      "Training accuracy: 93.4%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 4.033680 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.472271  [    4/  175]\n",
      "loss: 0.012545  [   84/  175]\n",
      "loss: 0.043918  [  164/  175]\n",
      "Training accuracy: 88.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.027025 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.055526  [    4/  175]\n",
      "loss: 0.009504  [   84/  175]\n",
      "loss: 0.006209  [  164/  175]\n",
      "Training accuracy: 94.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.019777 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.277549  [    4/  175]\n",
      "loss: 0.291696  [   84/  175]\n",
      "loss: 0.050263  [  164/  175]\n",
      "Training accuracy: 88.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.011270 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.047514  [    4/  175]\n",
      "loss: 1.075829  [   84/  175]\n",
      "loss: 0.007071  [  164/  175]\n",
      "Training accuracy: 91.7%\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 1.896482 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.009827  [    4/  175]\n",
      "loss: 0.067451  [   84/  175]\n",
      "loss: 0.015706  [  164/  175]\n",
      "Training accuracy: 96.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.031268 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.072829  [    4/  175]\n",
      "loss: 0.067900  [   84/  175]\n",
      "loss: 0.008963  [  164/  175]\n",
      "Training accuracy: 96.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.024006 \n",
      "\n",
      "Done!\n",
      "Training model with L2 regularization 0.01...\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "loss: 0.674421  [    4/  175]\n",
      "loss: 0.699021  [   84/  175]\n",
      "loss: 0.617268  [  164/  175]\n",
      "Training accuracy: 62.1%\n",
      "Test Error: \n",
      " Accuracy: 59.8%, Avg loss: 0.691417 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.694020  [    4/  175]\n",
      "loss: 0.919907  [   84/  175]\n",
      "loss: 0.588128  [  164/  175]\n",
      "Training accuracy: 59.7%\n",
      "Test Error: \n",
      " Accuracy: 59.8%, Avg loss: 0.681711 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.542415  [    4/  175]\n",
      "loss: 0.715906  [   84/  175]\n",
      "loss: 0.725593  [  164/  175]\n",
      "Training accuracy: 62.5%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 0.716202 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.579050  [    4/  175]\n",
      "loss: 1.045344  [   84/  175]\n",
      "loss: 0.589275  [  164/  175]\n",
      "Training accuracy: 65.9%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.196700 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.776041  [    4/  175]\n",
      "loss: 0.627889  [   84/  175]\n",
      "loss: 0.975607  [  164/  175]\n",
      "Training accuracy: 65.2%\n",
      "Test Error: \n",
      " Accuracy: 57.6%, Avg loss: 0.660297 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.738953  [    4/  175]\n",
      "loss: 0.592824  [   84/  175]\n",
      "loss: 0.507332  [  164/  175]\n",
      "Training accuracy: 66.1%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 0.936097 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.524555  [    4/  175]\n",
      "loss: 0.737467  [   84/  175]\n",
      "loss: 0.726637  [  164/  175]\n",
      "Training accuracy: 66.1%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.936033 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.682472  [    4/  175]\n",
      "loss: 0.900231  [   84/  175]\n",
      "loss: 0.516807  [  164/  175]\n",
      "Training accuracy: 69.7%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 1.220155 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.744926  [    4/  175]\n",
      "loss: 1.054925  [   84/  175]\n",
      "loss: 0.790030  [  164/  175]\n",
      "Training accuracy: 65.3%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 2.152655 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.623943  [    4/  175]\n",
      "loss: 0.518834  [   84/  175]\n",
      "loss: 1.104318  [  164/  175]\n",
      "Training accuracy: 72.2%\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 2.632579 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.393638  [    4/  175]\n",
      "loss: 0.454119  [   84/  175]\n",
      "loss: 0.483175  [  164/  175]\n",
      "Training accuracy: 75.9%\n",
      "Test Error: \n",
      " Accuracy: 59.1%, Avg loss: 0.581293 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.488616  [    4/  175]\n",
      "loss: 0.828141  [   84/  175]\n",
      "loss: 0.962936  [  164/  175]\n",
      "Training accuracy: 71.8%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 0.687056 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.486600  [    4/  175]\n",
      "loss: 0.427286  [   84/  175]\n",
      "loss: 0.473663  [  164/  175]\n",
      "Training accuracy: 75.9%\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 1.352417 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.777097  [    4/  175]\n",
      "loss: 0.454251  [   84/  175]\n",
      "loss: 0.755947  [  164/  175]\n",
      "Training accuracy: 67.4%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 2.432428 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.734696  [    4/  175]\n",
      "loss: 0.765181  [   84/  175]\n",
      "loss: 0.409606  [  164/  175]\n",
      "Training accuracy: 80.7%\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.424578 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.760684  [    4/  175]\n",
      "loss: 0.313555  [   84/  175]\n",
      "loss: 0.804587  [  164/  175]\n",
      "Training accuracy: 81.2%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 0.791826 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.396501  [    4/  175]\n",
      "loss: 0.633313  [   84/  175]\n",
      "loss: 0.432316  [  164/  175]\n",
      "Training accuracy: 78.8%\n",
      "Test Error: \n",
      " Accuracy: 55.3%, Avg loss: 0.602751 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.325549  [    4/  175]\n",
      "loss: 0.193515  [   84/  175]\n",
      "loss: 0.403926  [  164/  175]\n",
      "Training accuracy: 84.5%\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 1.023212 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.266875  [    4/  175]\n",
      "loss: 0.740512  [   84/  175]\n",
      "loss: 0.386660  [  164/  175]\n",
      "Training accuracy: 80.1%\n",
      "Test Error: \n",
      " Accuracy: 92.4%, Avg loss: 0.308368 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.201152  [    4/  175]\n",
      "loss: 0.394362  [   84/  175]\n",
      "loss: 0.174974  [  164/  175]\n",
      "Training accuracy: 79.7%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.268571 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.303837  [    4/  175]\n",
      "loss: 0.331660  [   84/  175]\n",
      "loss: 0.342168  [  164/  175]\n",
      "Training accuracy: 85.2%\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.257453 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.217742  [    4/  175]\n",
      "loss: 0.371872  [   84/  175]\n",
      "loss: 0.199005  [  164/  175]\n",
      "Training accuracy: 85.2%\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.314216 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.364875  [    4/  175]\n",
      "loss: 0.144798  [   84/  175]\n",
      "loss: 0.905783  [  164/  175]\n",
      "Training accuracy: 86.9%\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.255264 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.433271  [    4/  175]\n",
      "loss: 0.218509  [   84/  175]\n",
      "loss: 0.326124  [  164/  175]\n",
      "Training accuracy: 84.1%\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.288326 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.419168  [    4/  175]\n",
      "loss: 0.458254  [   84/  175]\n",
      "loss: 0.826252  [  164/  175]\n",
      "Training accuracy: 83.9%\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.356118 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.379706  [    4/  175]\n",
      "loss: 0.487630  [   84/  175]\n",
      "loss: 0.285635  [  164/  175]\n",
      "Training accuracy: 79.2%\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.241099 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.344893  [    4/  175]\n",
      "loss: 0.371098  [   84/  175]\n",
      "loss: 0.269010  [  164/  175]\n",
      "Training accuracy: 85.8%\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.450783 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.471847  [    4/  175]\n",
      "loss: 0.354955  [   84/  175]\n",
      "loss: 0.842957  [  164/  175]\n",
      "Training accuracy: 83.7%\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.307162 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 1.021737  [    4/  175]\n",
      "loss: 0.233462  [   84/  175]\n",
      "loss: 0.243922  [  164/  175]\n",
      "Training accuracy: 85.0%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.193029 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.161670  [    4/  175]\n",
      "loss: 0.136597  [   84/  175]\n",
      "loss: 0.467460  [  164/  175]\n",
      "Training accuracy: 84.7%\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.261527 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.213777  [    4/  175]\n",
      "loss: 0.278788  [   84/  175]\n",
      "loss: 0.288187  [  164/  175]\n",
      "Training accuracy: 90.5%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.216537 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.308378  [    4/  175]\n",
      "loss: 0.779466  [   84/  175]\n",
      "loss: 0.322249  [  164/  175]\n",
      "Training accuracy: 88.6%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.171842 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.230398  [    4/  175]\n",
      "loss: 0.175057  [   84/  175]\n",
      "loss: 0.091519  [  164/  175]\n",
      "Training accuracy: 85.6%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.162596 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.201677  [    4/  175]\n",
      "loss: 0.597957  [   84/  175]\n",
      "loss: 0.622692  [  164/  175]\n",
      "Training accuracy: 86.4%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.150441 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.172865  [    4/  175]\n",
      "loss: 0.222573  [   84/  175]\n",
      "loss: 0.402602  [  164/  175]\n",
      "Training accuracy: 86.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.123303 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.069649  [    4/  175]\n",
      "loss: 0.112807  [   84/  175]\n",
      "loss: 0.887298  [  164/  175]\n",
      "Training accuracy: 89.0%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.161507 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.205942  [    4/  175]\n",
      "loss: 0.734708  [   84/  175]\n",
      "loss: 0.127209  [  164/  175]\n",
      "Training accuracy: 89.2%\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.130895 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.119935  [    4/  175]\n",
      "loss: 0.076725  [   84/  175]\n",
      "loss: 0.145518  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.118952 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.233130  [    4/  175]\n",
      "loss: 0.205830  [   84/  175]\n",
      "loss: 0.078260  [  164/  175]\n",
      "Training accuracy: 89.2%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.155295 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.136248  [    4/  175]\n",
      "loss: 0.113064  [   84/  175]\n",
      "loss: 0.978937  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.211650 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.640208  [    4/  175]\n",
      "loss: 0.273696  [   84/  175]\n",
      "loss: 1.166649  [  164/  175]\n",
      "Training accuracy: 88.6%\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.281163 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.162998  [    4/  175]\n",
      "loss: 0.042244  [   84/  175]\n",
      "loss: 0.286618  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.092126 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.296987  [    4/  175]\n",
      "loss: 0.167406  [   84/  175]\n",
      "loss: 0.044309  [  164/  175]\n",
      "Training accuracy: 89.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.149714 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.216722  [    4/  175]\n",
      "loss: 0.074631  [   84/  175]\n",
      "loss: 0.129075  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.117116 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.988871  [    4/  175]\n",
      "loss: 0.057707  [   84/  175]\n",
      "loss: 0.186437  [  164/  175]\n",
      "Training accuracy: 90.7%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.080747 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.201544  [    4/  175]\n",
      "loss: 0.041721  [   84/  175]\n",
      "loss: 0.404045  [  164/  175]\n",
      "Training accuracy: 89.8%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.091698 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.054341  [    4/  175]\n",
      "loss: 0.206567  [   84/  175]\n",
      "loss: 0.177460  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.109556 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.734843  [    4/  175]\n",
      "loss: 0.082389  [   84/  175]\n",
      "loss: 0.119875  [  164/  175]\n",
      "Training accuracy: 89.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.090560 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.361624  [    4/  175]\n",
      "loss: 0.079960  [   84/  175]\n",
      "loss: 1.098647  [  164/  175]\n",
      "Training accuracy: 86.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.100500 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.057843  [    4/  175]\n",
      "loss: 0.139922  [   84/  175]\n",
      "loss: 0.199832  [  164/  175]\n",
      "Training accuracy: 89.6%\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.205348 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.230647  [    4/  175]\n",
      "loss: 0.176699  [   84/  175]\n",
      "loss: 0.061254  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.085368 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.155961  [    4/  175]\n",
      "loss: 0.084627  [   84/  175]\n",
      "loss: 0.901244  [  164/  175]\n",
      "Training accuracy: 88.1%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.123237 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.052818  [    4/  175]\n",
      "loss: 0.151487  [   84/  175]\n",
      "loss: 0.667655  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.060822 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.156980  [    4/  175]\n",
      "loss: 1.450842  [   84/  175]\n",
      "loss: 0.526401  [  164/  175]\n",
      "Training accuracy: 61.2%\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 1.104931 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 1.362496  [    4/  175]\n",
      "loss: 0.289330  [   84/  175]\n",
      "loss: 0.200259  [  164/  175]\n",
      "Training accuracy: 62.5%\n",
      "Test Error: \n",
      " Accuracy: 56.8%, Avg loss: 0.874085 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 1.064944  [    4/  175]\n",
      "loss: 0.259195  [   84/  175]\n",
      "loss: 0.289096  [  164/  175]\n",
      "Training accuracy: 60.4%\n",
      "Test Error: \n",
      " Accuracy: 57.6%, Avg loss: 0.793182 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.185406  [    4/  175]\n",
      "loss: 0.395228  [   84/  175]\n",
      "loss: 0.515241  [  164/  175]\n",
      "Training accuracy: 61.6%\n",
      "Test Error: \n",
      " Accuracy: 59.1%, Avg loss: 0.703587 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.562572  [    4/  175]\n",
      "loss: 1.305810  [   84/  175]\n",
      "loss: 0.532929  [  164/  175]\n",
      "Training accuracy: 64.6%\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 0.687096 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.629417  [    4/  175]\n",
      "loss: 0.446668  [   84/  175]\n",
      "loss: 0.941432  [  164/  175]\n",
      "Training accuracy: 63.8%\n",
      "Test Error: \n",
      " Accuracy: 57.6%, Avg loss: 0.661341 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.576995  [    4/  175]\n",
      "loss: 0.437732  [   84/  175]\n",
      "loss: 0.466096  [  164/  175]\n",
      "Training accuracy: 66.3%\n",
      "Test Error: \n",
      " Accuracy: 59.1%, Avg loss: 0.655824 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.497555  [    4/  175]\n",
      "loss: 0.458787  [   84/  175]\n",
      "loss: 1.071441  [  164/  175]\n",
      "Training accuracy: 62.3%\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 0.705283 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.550887  [    4/  175]\n",
      "loss: 0.841286  [   84/  175]\n",
      "loss: 0.509261  [  164/  175]\n",
      "Training accuracy: 65.5%\n",
      "Test Error: \n",
      " Accuracy: 62.9%, Avg loss: 0.652886 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.436349  [    4/  175]\n",
      "loss: 0.580868  [   84/  175]\n",
      "loss: 0.738449  [  164/  175]\n",
      "Training accuracy: 68.6%\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 0.652858 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.529853  [    4/  175]\n",
      "loss: 0.729765  [   84/  175]\n",
      "loss: 0.441651  [  164/  175]\n",
      "Training accuracy: 67.0%\n",
      "Test Error: \n",
      " Accuracy: 65.9%, Avg loss: 0.626723 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.673004  [    4/  175]\n",
      "loss: 0.584374  [   84/  175]\n",
      "loss: 0.968361  [  164/  175]\n",
      "Training accuracy: 65.5%\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 2.605833 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.607741  [    4/  175]\n",
      "loss: 0.949606  [   84/  175]\n",
      "loss: 0.685130  [  164/  175]\n",
      "Training accuracy: 67.2%\n",
      "Test Error: \n",
      " Accuracy: 62.1%, Avg loss: 0.657563 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.587447  [    4/  175]\n",
      "loss: 0.491588  [   84/  175]\n",
      "loss: 0.788183  [  164/  175]\n",
      "Training accuracy: 67.0%\n",
      "Test Error: \n",
      " Accuracy: 62.1%, Avg loss: 0.636096 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.537413  [    4/  175]\n",
      "loss: 0.612327  [   84/  175]\n",
      "loss: 0.875933  [  164/  175]\n",
      "Training accuracy: 65.7%\n",
      "Test Error: \n",
      " Accuracy: 65.2%, Avg loss: 0.644883 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.752178  [    4/  175]\n",
      "loss: 0.469239  [   84/  175]\n",
      "loss: 0.668859  [  164/  175]\n",
      "Training accuracy: 65.9%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.073230 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.758602  [    4/  175]\n",
      "loss: 0.480199  [   84/  175]\n",
      "loss: 0.452144  [  164/  175]\n",
      "Training accuracy: 66.3%\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 0.751729 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.701486  [    4/  175]\n",
      "loss: 0.567448  [   84/  175]\n",
      "loss: 0.578242  [  164/  175]\n",
      "Training accuracy: 70.5%\n",
      "Test Error: \n",
      " Accuracy: 65.2%, Avg loss: 0.633988 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.746732  [    4/  175]\n",
      "loss: 0.642180  [   84/  175]\n",
      "loss: 0.401454  [  164/  175]\n",
      "Training accuracy: 68.2%\n",
      "Test Error: \n",
      " Accuracy: 64.4%, Avg loss: 0.620015 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.513426  [    4/  175]\n",
      "loss: 0.422533  [   84/  175]\n",
      "loss: 0.374401  [  164/  175]\n",
      "Training accuracy: 69.9%\n",
      "Test Error: \n",
      " Accuracy: 65.2%, Avg loss: 0.671919 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.445431  [    4/  175]\n",
      "loss: 0.713652  [   84/  175]\n",
      "loss: 0.319247  [  164/  175]\n",
      "Training accuracy: 81.4%\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.406543 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.258443  [    4/  175]\n",
      "loss: 0.283643  [   84/  175]\n",
      "loss: 0.378178  [  164/  175]\n",
      "Training accuracy: 86.7%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.247670 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.405980  [    4/  175]\n",
      "loss: 0.238536  [   84/  175]\n",
      "loss: 0.250621  [  164/  175]\n",
      "Training accuracy: 87.5%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.222089 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.265462  [    4/  175]\n",
      "loss: 0.265691  [   84/  175]\n",
      "loss: 0.150652  [  164/  175]\n",
      "Training accuracy: 88.1%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.191685 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.436333  [    4/  175]\n",
      "loss: 0.748664  [   84/  175]\n",
      "loss: 0.336638  [  164/  175]\n",
      "Training accuracy: 88.3%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.216181 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.251056  [    4/  175]\n",
      "loss: 0.309802  [   84/  175]\n",
      "loss: 0.249495  [  164/  175]\n",
      "Training accuracy: 93.0%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 7.523710 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.420414  [    4/  175]\n",
      "loss: 0.608481  [   84/  175]\n",
      "loss: 0.253761  [  164/  175]\n",
      "Training accuracy: 75.6%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 2.033808 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.584446  [    4/  175]\n",
      "loss: 0.207951  [   84/  175]\n",
      "loss: 0.672520  [  164/  175]\n",
      "Training accuracy: 89.2%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.233783 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.462898  [    4/  175]\n",
      "loss: 0.197672  [   84/  175]\n",
      "loss: 0.234126  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 57.6%, Avg loss: 0.551644 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.250794  [    4/  175]\n",
      "loss: 0.189800  [   84/  175]\n",
      "loss: 0.917440  [  164/  175]\n",
      "Training accuracy: 86.4%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.133212 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.272081  [    4/  175]\n",
      "loss: 0.231418  [   84/  175]\n",
      "loss: 0.091662  [  164/  175]\n",
      "Training accuracy: 87.5%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.110171 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.473470  [    4/  175]\n",
      "loss: 0.193899  [   84/  175]\n",
      "loss: 0.325121  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 62.1%, Avg loss: 0.510953 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.342005  [    4/  175]\n",
      "loss: 0.907551  [   84/  175]\n",
      "loss: 0.151645  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.135813 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.203457  [    4/  175]\n",
      "loss: 0.199957  [   84/  175]\n",
      "loss: 0.098539  [  164/  175]\n",
      "Training accuracy: 94.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.096202 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.085784  [    4/  175]\n",
      "loss: 0.173129  [   84/  175]\n",
      "loss: 0.133665  [  164/  175]\n",
      "Training accuracy: 88.1%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.108542 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.214554  [    4/  175]\n",
      "loss: 0.237783  [   84/  175]\n",
      "loss: 0.726902  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.215213 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.138511  [    4/  175]\n",
      "loss: 0.119748  [   84/  175]\n",
      "loss: 0.228620  [  164/  175]\n",
      "Training accuracy: 89.2%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.125466 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.109168  [    4/  175]\n",
      "loss: 0.071607  [   84/  175]\n",
      "loss: 0.095373  [  164/  175]\n",
      "Training accuracy: 90.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.127411 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.759821  [    4/  175]\n",
      "loss: 0.337629  [   84/  175]\n",
      "loss: 0.140178  [  164/  175]\n",
      "Training accuracy: 92.4%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.107673 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.055382  [    4/  175]\n",
      "loss: 0.066311  [   84/  175]\n",
      "loss: 0.165637  [  164/  175]\n",
      "Training accuracy: 91.9%\n",
      "Test Error: \n",
      " Accuracy: 91.7%, Avg loss: 0.280762 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.070385  [    4/  175]\n",
      "loss: 0.157470  [   84/  175]\n",
      "loss: 0.177598  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.077350 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 1.099379  [    4/  175]\n",
      "loss: 0.764128  [   84/  175]\n",
      "loss: 0.165398  [  164/  175]\n",
      "Training accuracy: 87.1%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.057583 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.323386  [    4/  175]\n",
      "loss: 0.882017  [   84/  175]\n",
      "loss: 0.167329  [  164/  175]\n",
      "Training accuracy: 73.5%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 2.498282 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 2.183571  [    4/  175]\n",
      "loss: 0.251150  [   84/  175]\n",
      "loss: 0.106382  [  164/  175]\n",
      "Training accuracy: 84.7%\n",
      "Test Error: \n",
      " Accuracy: 65.2%, Avg loss: 0.459118 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.199668  [    4/  175]\n",
      "loss: 1.200953  [   84/  175]\n",
      "loss: 0.058461  [  164/  175]\n",
      "Training accuracy: 93.6%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.096397 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.240655  [    4/  175]\n",
      "loss: 0.128443  [   84/  175]\n",
      "loss: 0.973729  [  164/  175]\n",
      "Training accuracy: 88.1%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.141112 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.284147  [    4/  175]\n",
      "loss: 0.900535  [   84/  175]\n",
      "loss: 0.479067  [  164/  175]\n",
      "Training accuracy: 87.9%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 10.758618 \n",
      "\n",
      "Done!\n",
      "Training model with L2 regularization 0.1...\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "loss: 0.639488  [    4/  175]\n",
      "loss: 1.010236  [   84/  175]\n",
      "loss: 0.726055  [  164/  175]\n",
      "Training accuracy: 65.3%\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 0.705233 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.525148  [    4/  175]\n",
      "loss: 0.660468  [   84/  175]\n",
      "loss: 0.669069  [  164/  175]\n",
      "Training accuracy: 72.0%\n",
      "Test Error: \n",
      " Accuracy: 67.4%, Avg loss: 0.652889 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.551396  [    4/  175]\n",
      "loss: 0.681815  [   84/  175]\n",
      "loss: 0.505676  [  164/  175]\n",
      "Training accuracy: 72.9%\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 1.047689 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.450012  [    4/  175]\n",
      "loss: 0.446314  [   84/  175]\n",
      "loss: 0.690962  [  164/  175]\n",
      "Training accuracy: 73.3%\n",
      "Test Error: \n",
      " Accuracy: 52.3%, Avg loss: 0.678696 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.512025  [    4/  175]\n",
      "loss: 0.509032  [   84/  175]\n",
      "loss: 0.463897  [  164/  175]\n",
      "Training accuracy: 74.4%\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 1.201074 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.528458  [    4/  175]\n",
      "loss: 0.628032  [   84/  175]\n",
      "loss: 0.669188  [  164/  175]\n",
      "Training accuracy: 77.1%\n",
      "Test Error: \n",
      " Accuracy: 69.7%, Avg loss: 0.585178 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.506123  [    4/  175]\n",
      "loss: 0.595698  [   84/  175]\n",
      "loss: 0.285174  [  164/  175]\n",
      "Training accuracy: 79.5%\n",
      "Test Error: \n",
      " Accuracy: 52.3%, Avg loss: 1.023763 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.881900  [    4/  175]\n",
      "loss: 0.778319  [   84/  175]\n",
      "loss: 0.500639  [  164/  175]\n",
      "Training accuracy: 74.2%\n",
      "Test Error: \n",
      " Accuracy: 51.5%, Avg loss: 0.615833 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.469795  [    4/  175]\n",
      "loss: 0.885210  [   84/  175]\n",
      "loss: 0.585251  [  164/  175]\n",
      "Training accuracy: 77.5%\n",
      "Test Error: \n",
      " Accuracy: 48.5%, Avg loss: 0.606442 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.457489  [    4/  175]\n",
      "loss: 0.452437  [   84/  175]\n",
      "loss: 0.378572  [  164/  175]\n",
      "Training accuracy: 83.0%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 2.227130 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.185988  [    4/  175]\n",
      "loss: 0.424727  [   84/  175]\n",
      "loss: 0.465593  [  164/  175]\n",
      "Training accuracy: 78.8%\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.503671 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.424827  [    4/  175]\n",
      "loss: 0.453250  [   84/  175]\n",
      "loss: 0.455539  [  164/  175]\n",
      "Training accuracy: 81.8%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.332185 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.463391  [    4/  175]\n",
      "loss: 0.862171  [   84/  175]\n",
      "loss: 0.710500  [  164/  175]\n",
      "Training accuracy: 83.0%\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.433541 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.461255  [    4/  175]\n",
      "loss: 0.660539  [   84/  175]\n",
      "loss: 0.449001  [  164/  175]\n",
      "Training accuracy: 81.8%\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.463892 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.471193  [    4/  175]\n",
      "loss: 0.312465  [   84/  175]\n",
      "loss: 0.421115  [  164/  175]\n",
      "Training accuracy: 78.8%\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 1.598739 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.470213  [    4/  175]\n",
      "loss: 0.418436  [   84/  175]\n",
      "loss: 0.542714  [  164/  175]\n",
      "Training accuracy: 83.0%\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 0.505090 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.473423  [    4/  175]\n",
      "loss: 0.611499  [   84/  175]\n",
      "loss: 0.545278  [  164/  175]\n",
      "Training accuracy: 84.7%\n",
      "Test Error: \n",
      " Accuracy: 50.8%, Avg loss: 0.674809 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.529414  [    4/  175]\n",
      "loss: 0.380888  [   84/  175]\n",
      "loss: 0.755992  [  164/  175]\n",
      "Training accuracy: 85.4%\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.444145 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.331790  [    4/  175]\n",
      "loss: 0.393087  [   84/  175]\n",
      "loss: 0.371735  [  164/  175]\n",
      "Training accuracy: 81.6%\n",
      "Test Error: \n",
      " Accuracy: 66.7%, Avg loss: 0.547976 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.589699  [    4/  175]\n",
      "loss: 0.444203  [   84/  175]\n",
      "loss: 0.371279  [  164/  175]\n",
      "Training accuracy: 76.9%\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.406303 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.371763  [    4/  175]\n",
      "loss: 0.448985  [   84/  175]\n",
      "loss: 0.459373  [  164/  175]\n",
      "Training accuracy: 79.9%\n",
      "Test Error: \n",
      " Accuracy: 50.8%, Avg loss: 0.664747 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.467291  [    4/  175]\n",
      "loss: 0.398875  [   84/  175]\n",
      "loss: 0.343757  [  164/  175]\n",
      "Training accuracy: 82.4%\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 2.098979 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.423614  [    4/  175]\n",
      "loss: 0.501279  [   84/  175]\n",
      "loss: 0.761401  [  164/  175]\n",
      "Training accuracy: 80.3%\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.423985 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.411145  [    4/  175]\n",
      "loss: 0.497156  [   84/  175]\n",
      "loss: 0.455050  [  164/  175]\n",
      "Training accuracy: 85.2%\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.403613 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.384736  [    4/  175]\n",
      "loss: 0.397986  [   84/  175]\n",
      "loss: 0.518275  [  164/  175]\n",
      "Training accuracy: 81.8%\n",
      "Test Error: \n",
      " Accuracy: 72.0%, Avg loss: 0.455044 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.596459  [    4/  175]\n",
      "loss: 0.399537  [   84/  175]\n",
      "loss: 0.474147  [  164/  175]\n",
      "Training accuracy: 84.5%\n",
      "Test Error: \n",
      " Accuracy: 51.5%, Avg loss: 0.606621 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.527145  [    4/  175]\n",
      "loss: 0.336795  [   84/  175]\n",
      "loss: 0.408978  [  164/  175]\n",
      "Training accuracy: 83.1%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.086413 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.422869  [    4/  175]\n",
      "loss: 0.338527  [   84/  175]\n",
      "loss: 0.616671  [  164/  175]\n",
      "Training accuracy: 80.7%\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.409785 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.447442  [    4/  175]\n",
      "loss: 0.454530  [   84/  175]\n",
      "loss: 0.435918  [  164/  175]\n",
      "Training accuracy: 82.6%\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.433663 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.427672  [    4/  175]\n",
      "loss: 0.587994  [   84/  175]\n",
      "loss: 0.402049  [  164/  175]\n",
      "Training accuracy: 83.0%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.416748 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.408285  [    4/  175]\n",
      "loss: 0.582532  [   84/  175]\n",
      "loss: 0.309591  [  164/  175]\n",
      "Training accuracy: 81.2%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 2.268554 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.734589  [    4/  175]\n",
      "loss: 0.482045  [   84/  175]\n",
      "loss: 0.377774  [  164/  175]\n",
      "Training accuracy: 85.6%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.434767 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.460470  [    4/  175]\n",
      "loss: 0.426638  [   84/  175]\n",
      "loss: 0.522877  [  164/  175]\n",
      "Training accuracy: 79.9%\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 1.772950 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.431395  [    4/  175]\n",
      "loss: 0.705141  [   84/  175]\n",
      "loss: 0.421083  [  164/  175]\n",
      "Training accuracy: 83.0%\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.460860 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.370209  [    4/  175]\n",
      "loss: 0.402975  [   84/  175]\n",
      "loss: 0.330455  [  164/  175]\n",
      "Training accuracy: 77.1%\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.406192 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.412641  [    4/  175]\n",
      "loss: 0.603385  [   84/  175]\n",
      "loss: 0.334374  [  164/  175]\n",
      "Training accuracy: 83.0%\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 0.697784 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.550534  [    4/  175]\n",
      "loss: 0.325020  [   84/  175]\n",
      "loss: 0.473350  [  164/  175]\n",
      "Training accuracy: 86.6%\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.411506 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.391057  [    4/  175]\n",
      "loss: 0.800406  [   84/  175]\n",
      "loss: 0.398044  [  164/  175]\n",
      "Training accuracy: 83.0%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.400712 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.731282  [    4/  175]\n",
      "loss: 0.509480  [   84/  175]\n",
      "loss: 0.428106  [  164/  175]\n",
      "Training accuracy: 81.2%\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.425072 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.298594  [    4/  175]\n",
      "loss: 0.421484  [   84/  175]\n",
      "loss: 0.483932  [  164/  175]\n",
      "Training accuracy: 86.9%\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.396089 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.491023  [    4/  175]\n",
      "loss: 0.500334  [   84/  175]\n",
      "loss: 0.841012  [  164/  175]\n",
      "Training accuracy: 78.4%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 0.942094 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.432732  [    4/  175]\n",
      "loss: 0.396783  [   84/  175]\n",
      "loss: 0.314356  [  164/  175]\n",
      "Training accuracy: 79.7%\n",
      "Test Error: \n",
      " Accuracy: 59.8%, Avg loss: 0.556809 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.483490  [    4/  175]\n",
      "loss: 0.780272  [   84/  175]\n",
      "loss: 0.449190  [  164/  175]\n",
      "Training accuracy: 84.1%\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.408499 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.517993  [    4/  175]\n",
      "loss: 0.355546  [   84/  175]\n",
      "loss: 0.396256  [  164/  175]\n",
      "Training accuracy: 87.5%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 2.774525 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.370733  [    4/  175]\n",
      "loss: 0.446462  [   84/  175]\n",
      "loss: 0.432891  [  164/  175]\n",
      "Training accuracy: 82.4%\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.393823 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.407706  [    4/  175]\n",
      "loss: 0.386956  [   84/  175]\n",
      "loss: 0.441035  [  164/  175]\n",
      "Training accuracy: 84.1%\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.417731 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.417906  [    4/  175]\n",
      "loss: 0.432571  [   84/  175]\n",
      "loss: 0.825971  [  164/  175]\n",
      "Training accuracy: 83.0%\n",
      "Test Error: \n",
      " Accuracy: 87.1%, Avg loss: 0.406598 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.427706  [    4/  175]\n",
      "loss: 0.380216  [   84/  175]\n",
      "loss: 0.555867  [  164/  175]\n",
      "Training accuracy: 89.8%\n",
      "Test Error: \n",
      " Accuracy: 65.2%, Avg loss: 0.477785 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.419617  [    4/  175]\n",
      "loss: 0.307186  [   84/  175]\n",
      "loss: 0.492028  [  164/  175]\n",
      "Training accuracy: 79.9%\n",
      "Test Error: \n",
      " Accuracy: 94.7%, Avg loss: 0.412909 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.476209  [    4/  175]\n",
      "loss: 0.422864  [   84/  175]\n",
      "loss: 0.721824  [  164/  175]\n",
      "Training accuracy: 83.5%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.355135 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.626175  [    4/  175]\n",
      "loss: 0.452000  [   84/  175]\n",
      "loss: 0.425792  [  164/  175]\n",
      "Training accuracy: 84.1%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.367246 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.716441  [    4/  175]\n",
      "loss: 0.723127  [   84/  175]\n",
      "loss: 0.460986  [  164/  175]\n",
      "Training accuracy: 79.5%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.401438 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.486784  [    4/  175]\n",
      "loss: 0.367956  [   84/  175]\n",
      "loss: 0.343955  [  164/  175]\n",
      "Training accuracy: 83.1%\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.534635 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.421834  [    4/  175]\n",
      "loss: 0.348282  [   84/  175]\n",
      "loss: 0.318024  [  164/  175]\n",
      "Training accuracy: 86.9%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.376010 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.520806  [    4/  175]\n",
      "loss: 0.347726  [   84/  175]\n",
      "loss: 0.489735  [  164/  175]\n",
      "Training accuracy: 85.0%\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.451686 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.359472  [    4/  175]\n",
      "loss: 0.516450  [   84/  175]\n",
      "loss: 0.441541  [  164/  175]\n",
      "Training accuracy: 88.4%\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.427124 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.728593  [    4/  175]\n",
      "loss: 0.788310  [   84/  175]\n",
      "loss: 0.734396  [  164/  175]\n",
      "Training accuracy: 83.0%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.369072 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.479808  [    4/  175]\n",
      "loss: 0.317487  [   84/  175]\n",
      "loss: 0.449618  [  164/  175]\n",
      "Training accuracy: 83.9%\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.371101 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.399299  [    4/  175]\n",
      "loss: 0.343513  [   84/  175]\n",
      "loss: 0.459744  [  164/  175]\n",
      "Training accuracy: 84.7%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.385463 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.378220  [    4/  175]\n",
      "loss: 0.469039  [   84/  175]\n",
      "loss: 0.518174  [  164/  175]\n",
      "Training accuracy: 85.6%\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.371959 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.394807  [    4/  175]\n",
      "loss: 0.743453  [   84/  175]\n",
      "loss: 0.449429  [  164/  175]\n",
      "Training accuracy: 86.2%\n",
      "Test Error: \n",
      " Accuracy: 83.3%, Avg loss: 0.444653 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.496741  [    4/  175]\n",
      "loss: 0.413751  [   84/  175]\n",
      "loss: 0.399027  [  164/  175]\n",
      "Training accuracy: 83.3%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.373104 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.427951  [    4/  175]\n",
      "loss: 0.398055  [   84/  175]\n",
      "loss: 0.358873  [  164/  175]\n",
      "Training accuracy: 79.5%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.408711 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.297100  [    4/  175]\n",
      "loss: 0.715345  [   84/  175]\n",
      "loss: 0.334957  [  164/  175]\n",
      "Training accuracy: 88.1%\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 0.492577 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.547022  [    4/  175]\n",
      "loss: 0.380342  [   84/  175]\n",
      "loss: 0.475080  [  164/  175]\n",
      "Training accuracy: 83.0%\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.388344 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.419889  [    4/  175]\n",
      "loss: 0.475500  [   84/  175]\n",
      "loss: 0.281940  [  164/  175]\n",
      "Training accuracy: 84.5%\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.382643 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.376599  [    4/  175]\n",
      "loss: 0.814582  [   84/  175]\n",
      "loss: 0.833786  [  164/  175]\n",
      "Training accuracy: 85.4%\n",
      "Test Error: \n",
      " Accuracy: 52.3%, Avg loss: 5.098844 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.410583  [    4/  175]\n",
      "loss: 0.420688  [   84/  175]\n",
      "loss: 0.446879  [  164/  175]\n",
      "Training accuracy: 84.1%\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.238981 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.413126  [    4/  175]\n",
      "loss: 0.586739  [   84/  175]\n",
      "loss: 0.736684  [  164/  175]\n",
      "Training accuracy: 84.7%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.330271 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.396655  [    4/  175]\n",
      "loss: 0.851177  [   84/  175]\n",
      "loss: 0.539715  [  164/  175]\n",
      "Training accuracy: 77.8%\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.409000 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.403016  [    4/  175]\n",
      "loss: 0.344522  [   84/  175]\n",
      "loss: 0.300273  [  164/  175]\n",
      "Training accuracy: 85.2%\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.402756 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.782866  [    4/  175]\n",
      "loss: 0.724752  [   84/  175]\n",
      "loss: 0.281313  [  164/  175]\n",
      "Training accuracy: 83.0%\n",
      "Test Error: \n",
      " Accuracy: 65.2%, Avg loss: 0.605544 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.530536  [    4/  175]\n",
      "loss: 0.285282  [   84/  175]\n",
      "loss: 0.652476  [  164/  175]\n",
      "Training accuracy: 85.6%\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 0.769484 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.450267  [    4/  175]\n",
      "loss: 0.418472  [   84/  175]\n",
      "loss: 0.727830  [  164/  175]\n",
      "Training accuracy: 86.2%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 0.825278 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.503856  [    4/  175]\n",
      "loss: 0.692768  [   84/  175]\n",
      "loss: 0.746044  [  164/  175]\n",
      "Training accuracy: 84.7%\n",
      "Test Error: \n",
      " Accuracy: 50.8%, Avg loss: 0.604333 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.496928  [    4/  175]\n",
      "loss: 0.291289  [   84/  175]\n",
      "loss: 0.342106  [  164/  175]\n",
      "Training accuracy: 89.2%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.345114 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.386128  [    4/  175]\n",
      "loss: 0.455530  [   84/  175]\n",
      "loss: 0.356286  [  164/  175]\n",
      "Training accuracy: 87.9%\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.402764 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.515369  [    4/  175]\n",
      "loss: 0.303440  [   84/  175]\n",
      "loss: 0.748695  [  164/  175]\n",
      "Training accuracy: 88.4%\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.372595 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.854122  [    4/  175]\n",
      "loss: 0.931253  [   84/  175]\n",
      "loss: 0.722445  [  164/  175]\n",
      "Training accuracy: 74.8%\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 1.161168 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.417231  [    4/  175]\n",
      "loss: 0.314417  [   84/  175]\n",
      "loss: 0.403986  [  164/  175]\n",
      "Training accuracy: 82.4%\n",
      "Test Error: \n",
      " Accuracy: 80.3%, Avg loss: 0.475619 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.536964  [    4/  175]\n",
      "loss: 0.349282  [   84/  175]\n",
      "loss: 0.848071  [  164/  175]\n",
      "Training accuracy: 81.4%\n",
      "Test Error: \n",
      " Accuracy: 72.7%, Avg loss: 0.462192 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.343172  [    4/  175]\n",
      "loss: 0.741653  [   84/  175]\n",
      "loss: 0.420591  [  164/  175]\n",
      "Training accuracy: 79.4%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.095360 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.432366  [    4/  175]\n",
      "loss: 0.386836  [   84/  175]\n",
      "loss: 0.391138  [  164/  175]\n",
      "Training accuracy: 82.8%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.838395 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.583906  [    4/  175]\n",
      "loss: 0.392442  [   84/  175]\n",
      "loss: 0.431551  [  164/  175]\n",
      "Training accuracy: 82.6%\n",
      "Test Error: \n",
      " Accuracy: 94.7%, Avg loss: 0.381515 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.418716  [    4/  175]\n",
      "loss: 0.375991  [   84/  175]\n",
      "loss: 0.340060  [  164/  175]\n",
      "Training accuracy: 86.9%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.344937 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.350926  [    4/  175]\n",
      "loss: 0.521135  [   84/  175]\n",
      "loss: 0.735261  [  164/  175]\n",
      "Training accuracy: 81.8%\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.370072 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.312601  [    4/  175]\n",
      "loss: 0.759893  [   84/  175]\n",
      "loss: 0.368962  [  164/  175]\n",
      "Training accuracy: 86.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.343787 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.302618  [    4/  175]\n",
      "loss: 0.300119  [   84/  175]\n",
      "loss: 0.498982  [  164/  175]\n",
      "Training accuracy: 83.9%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.354903 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.410511  [    4/  175]\n",
      "loss: 0.492462  [   84/  175]\n",
      "loss: 0.375715  [  164/  175]\n",
      "Training accuracy: 81.6%\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.393587 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.774864  [    4/  175]\n",
      "loss: 0.395646  [   84/  175]\n",
      "loss: 0.446959  [  164/  175]\n",
      "Training accuracy: 88.1%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.369850 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.409385  [    4/  175]\n",
      "loss: 0.419616  [   84/  175]\n",
      "loss: 0.376453  [  164/  175]\n",
      "Training accuracy: 84.1%\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.351642 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.293230  [    4/  175]\n",
      "loss: 0.477894  [   84/  175]\n",
      "loss: 0.306973  [  164/  175]\n",
      "Training accuracy: 86.9%\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 18.001829 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.559830  [    4/  175]\n",
      "loss: 0.529507  [   84/  175]\n",
      "loss: 0.365568  [  164/  175]\n",
      "Training accuracy: 76.5%\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.705127 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.736224  [    4/  175]\n",
      "loss: 0.396221  [   84/  175]\n",
      "loss: 0.285771  [  164/  175]\n",
      "Training accuracy: 88.1%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.371112 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.466673  [    4/  175]\n",
      "loss: 0.454736  [   84/  175]\n",
      "loss: 0.446795  [  164/  175]\n",
      "Training accuracy: 86.9%\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.443963 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.361322  [    4/  175]\n",
      "loss: 0.431675  [   84/  175]\n",
      "loss: 0.294996  [  164/  175]\n",
      "Training accuracy: 86.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.378140 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.416835  [    4/  175]\n",
      "loss: 0.372396  [   84/  175]\n",
      "loss: 0.377092  [  164/  175]\n",
      "Training accuracy: 87.9%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 4.412784 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.601470  [    4/  175]\n",
      "loss: 0.300043  [   84/  175]\n",
      "loss: 0.387546  [  164/  175]\n",
      "Training accuracy: 86.2%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.805334 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.291080  [    4/  175]\n",
      "loss: 0.306444  [   84/  175]\n",
      "loss: 0.747328  [  164/  175]\n",
      "Training accuracy: 83.3%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.386164 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.483470  [    4/  175]\n",
      "loss: 0.336980  [   84/  175]\n",
      "loss: 0.343956  [  164/  175]\n",
      "Training accuracy: 83.0%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.342510 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-2\n",
    "l2_regs = [0, 1e-3, 1e-2, 1e-1]\n",
    "batch_size = 4\n",
    "epochs = 100\n",
    "\n",
    "log_dir = os.path.join(\"runs\", \"experiment_005\")\n",
    "shutil.rmtree(log_dir, ignore_errors=True)\n",
    "\n",
    "for l2_reg in l2_regs:\n",
    "    model = ModelWithSimpleRnn().to(device)\n",
    "\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=l2_reg)\n",
    "\n",
    "    print(f\"Training model with L2 regularization {l2_reg}...\")\n",
    "    log_subdir = os.path.join(log_dir, \"l2_reg_\" + str(l2_reg) + \"_\" + datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"))\n",
    "    tb = SummaryWriter(log_subdir)\n",
    "\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t}\\n-------------------------------\")\n",
    "        train_metrics = train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "        test_metrics = test_loop(test_dataloader, model, loss_fn)\n",
    "        tb.add_scalar(\"Loss/train\", train_metrics[\"loss\"], t)\n",
    "        tb.add_scalar(\"Accuracy/train\", train_metrics[\"acc\"], t)\n",
    "        tb.add_scalar(\"Loss/test\", test_metrics[\"loss\"], t)\n",
    "        tb.add_scalar(\"Accuracy/test\", test_metrics[\"acc\"], t)\n",
    "        # for name, weight in model.named_parameters():\n",
    "        #     tb.add_histogram(f\"Weights/{name}\", weight, t)\n",
    "        #     tb.add_histogram(f\"Gradients/{name}\", weight.grad, t)\n",
    "\n",
    "    tb.close()\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regularization doesn't do anything for the training stability. A small amount of regularization does seem to speed up training slightly, but not enough for it to be worth the increased complexity."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model architecture 2\n",
    "\n",
    "Now that we've seen the benefit of the simple RNN structure, let's change other aspects of the model architecture and see if it improves the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRnnWithWiderRnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(2, 5, 3)\n",
    "        self.rnn = nn.RNN(5, 10)\n",
    "        self.norm = nn.BatchNorm1d(10)\n",
    "        self.lin = nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.one_hot(x.long(), 2) # One-hot encode the two cell classes\n",
    "        x = x.type(torch.float) # Convert to floating-point\n",
    "        x = x.permute((1, 0, 4, 2, 3)) # Move sequence to dimension 0 and channels/classes to dimension 2\n",
    "        x1, x2 = x # Split up the two timesteps so we can apply convolution to them both separately\n",
    "\n",
    "        x1 = F.relu(self.conv(F.pad(x1, (1, 1, 1, 1)))) # Pad height and width (the last 2 dimensions) with zeroes to represent the board boundaries\n",
    "        x1 = F.avg_pool2d(x1, kernel_size=x.shape[-2:]).squeeze(-1).squeeze(-1)\n",
    "\n",
    "        x2 = F.relu(self.conv(F.pad(x2, (1, 1, 1, 1))))\n",
    "        x2 = F.avg_pool2d(x2, kernel_size=x.shape[-2:]).squeeze(-1).squeeze(-1)\n",
    "\n",
    "        x = torch.concat((x1.unsqueeze(0), x2.unsqueeze(0)))\n",
    "        x, rnn_state = self.rnn(x)\n",
    "        x = x[-1] # Just take last predicted state\n",
    "        x = self.norm(x)\n",
    "        logits = self.lin(x).squeeze(-1)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRnnWithLinearBeforeRnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(2, 5, 3)\n",
    "        self.lin0 = nn.Linear(5, 5)\n",
    "        self.rnn = nn.RNN(5, 5)\n",
    "        self.norm = nn.BatchNorm1d(5)\n",
    "        self.lin1 = nn.Linear(5, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.one_hot(x.long(), 2) # One-hot encode the two cell classes\n",
    "        x = x.type(torch.float) # Convert to floating-point\n",
    "        x = x.permute((1, 0, 4, 2, 3)) # Move sequence to dimension 0 and channels/classes to dimension 2\n",
    "        x1, x2 = x # Split up the two timesteps so we can apply convolution to them both separately\n",
    "\n",
    "        x1 = F.relu(self.conv(F.pad(x1, (1, 1, 1, 1)))) # Pad height and width (the last 2 dimensions) with zeroes to represent the board boundaries\n",
    "        x1 = F.avg_pool2d(x1, kernel_size=x.shape[-2:]).squeeze(-1).squeeze(-1)\n",
    "        x1 = F.relu(self.lin0(x1))\n",
    "\n",
    "        x2 = F.relu(self.conv(F.pad(x2, (1, 1, 1, 1))))\n",
    "        x2 = F.avg_pool2d(x2, kernel_size=x.shape[-2:]).squeeze(-1).squeeze(-1)\n",
    "        x2 = F.relu(self.lin0(x2))\n",
    "\n",
    "        x = torch.concat((x1.unsqueeze(0), x2.unsqueeze(0)))\n",
    "        x, rnn_state = self.rnn(x)\n",
    "        x = x[-1] # Just take last predicted state\n",
    "        x = self.norm(x)\n",
    "        logits = self.lin1(x).squeeze(-1)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRnnWithExtraConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv0 = nn.Conv2d(2, 5, 3)\n",
    "        self.conv1 = nn.Conv2d(5, 5, 3)\n",
    "        self.rnn = nn.RNN(5, 5)\n",
    "        self.norm = nn.BatchNorm1d(5)\n",
    "        self.lin = nn.Linear(5, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.one_hot(x.long(), 2) # One-hot encode the two cell classes\n",
    "        x = x.type(torch.float) # Convert to floating-point\n",
    "        x = x.permute((1, 0, 4, 2, 3)) # Move sequence to dimension 0 and channels/classes to dimension 2\n",
    "        x1, x2 = x # Split up the two timesteps so we can apply convolution to them both separately\n",
    "\n",
    "        x1 = F.relu(self.conv0(F.pad(x1, (1, 1, 1, 1)))) # Pad height and width (the last 2 dimensions) with zeroes to represent the board boundaries\n",
    "        x1 = F.relu(self.conv1(F.pad(x1, (1, 1, 1, 1))))\n",
    "        x1 = F.avg_pool2d(x1, kernel_size=x.shape[-2:]).squeeze(-1).squeeze(-1)\n",
    "\n",
    "        x2 = F.relu(self.conv0(F.pad(x2, (1, 1, 1, 1))))\n",
    "        x2 = F.relu(self.conv1(F.pad(x2, (1, 1, 1, 1))))\n",
    "        x2 = F.avg_pool2d(x2, kernel_size=x.shape[-2:]).squeeze(-1).squeeze(-1)\n",
    "\n",
    "        x = torch.concat((x1.unsqueeze(0), x2.unsqueeze(0)))\n",
    "        x, rnn_state = self.rnn(x)\n",
    "        x = x[-1] # Just take last predicted state\n",
    "        x = self.norm(x)\n",
    "        logits = self.lin(x).squeeze(-1)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRnnWithExtraWideConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv0 = nn.Conv2d(2, 5, 3)\n",
    "        self.conv1 = nn.Conv2d(5, 10, 3)\n",
    "        self.rnn = nn.RNN(10, 5)\n",
    "        self.norm = nn.BatchNorm1d(5)\n",
    "        self.lin = nn.Linear(5, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.one_hot(x.long(), 2) # One-hot encode the two cell classes\n",
    "        x = x.type(torch.float) # Convert to floating-point\n",
    "        x = x.permute((1, 0, 4, 2, 3)) # Move sequence to dimension 0 and channels/classes to dimension 2\n",
    "        x1, x2 = x # Split up the two timesteps so we can apply convolution to them both separately\n",
    "\n",
    "        x1 = F.relu(self.conv0(F.pad(x1, (1, 1, 1, 1)))) # Pad height and width (the last 2 dimensions) with zeroes to represent the board boundaries\n",
    "        x1 = F.relu(self.conv1(F.pad(x1, (1, 1, 1, 1))))\n",
    "        x1 = F.avg_pool2d(x1, kernel_size=x.shape[-2:]).squeeze(-1).squeeze(-1)\n",
    "\n",
    "        x2 = F.relu(self.conv0(F.pad(x2, (1, 1, 1, 1))))\n",
    "        x2 = F.relu(self.conv1(F.pad(x2, (1, 1, 1, 1))))\n",
    "        x2 = F.avg_pool2d(x2, kernel_size=x.shape[-2:]).squeeze(-1).squeeze(-1)\n",
    "\n",
    "        x = torch.concat((x1.unsqueeze(0), x2.unsqueeze(0)))\n",
    "        x, rnn_state = self.rnn(x)\n",
    "        x = x[-1] # Just take last predicted state\n",
    "        x = self.norm(x)\n",
    "        logits = self.lin(x).squeeze(-1)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 'simple_rnn' has 171 parameters.\n",
      "Model 'wider' has 296 parameters.\n",
      "Model 'linear_before_rnn' has 201 parameters.\n",
      "Model 'extra_conv' has 401 parameters.\n",
      "Model 'extra_wide_conv' has 656 parameters.\n",
      "Training model 'simple_rnn'...\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "loss: 0.809214  [    4/  175]\n",
      "loss: 0.939461  [   84/  175]\n",
      "loss: 0.602728  [  164/  175]\n",
      "Training accuracy: 65.2%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 0.720875 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.826274  [    4/  175]\n",
      "loss: 0.920830  [   84/  175]\n",
      "loss: 0.589147  [  164/  175]\n",
      "Training accuracy: 67.2%\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 2.209103 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.827679  [    4/  175]\n",
      "loss: 0.652182  [   84/  175]\n",
      "loss: 0.551580  [  164/  175]\n",
      "Training accuracy: 67.4%\n",
      "Test Error: \n",
      " Accuracy: 62.9%, Avg loss: 0.654149 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.775076  [    4/  175]\n",
      "loss: 0.553623  [   84/  175]\n",
      "loss: 0.847242  [  164/  175]\n",
      "Training accuracy: 64.8%\n",
      "Test Error: \n",
      " Accuracy: 59.8%, Avg loss: 0.747028 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.386231  [    4/  175]\n",
      "loss: 0.841549  [   84/  175]\n",
      "loss: 0.559223  [  164/  175]\n",
      "Training accuracy: 68.4%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.382611 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.643730  [    4/  175]\n",
      "loss: 0.548325  [   84/  175]\n",
      "loss: 1.000261  [  164/  175]\n",
      "Training accuracy: 73.3%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 1.531984 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.465071  [    4/  175]\n",
      "loss: 0.440487  [   84/  175]\n",
      "loss: 0.493727  [  164/  175]\n",
      "Training accuracy: 69.3%\n",
      "Test Error: \n",
      " Accuracy: 62.9%, Avg loss: 0.725348 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.465489  [    4/  175]\n",
      "loss: 0.430897  [   84/  175]\n",
      "loss: 0.478824  [  164/  175]\n",
      "Training accuracy: 72.5%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.545486 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.420471  [    4/  175]\n",
      "loss: 0.456696  [   84/  175]\n",
      "loss: 0.547904  [  164/  175]\n",
      "Training accuracy: 75.6%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 3.118803 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.552931  [    4/  175]\n",
      "loss: 0.634070  [   84/  175]\n",
      "loss: 0.406645  [  164/  175]\n",
      "Training accuracy: 76.9%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 2.430693 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.820537  [    4/  175]\n",
      "loss: 0.360597  [   84/  175]\n",
      "loss: 0.717176  [  164/  175]\n",
      "Training accuracy: 78.8%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 2.278381 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.387910  [    4/  175]\n",
      "loss: 0.651407  [   84/  175]\n",
      "loss: 0.270828  [  164/  175]\n",
      "Training accuracy: 80.7%\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 3.568441 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.339692  [    4/  175]\n",
      "loss: 0.793905  [   84/  175]\n",
      "loss: 0.292097  [  164/  175]\n",
      "Training accuracy: 88.6%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 5.604050 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.302484  [    4/  175]\n",
      "loss: 0.343126  [   84/  175]\n",
      "loss: 0.142423  [  164/  175]\n",
      "Training accuracy: 89.2%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 2.101221 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.440846  [    4/  175]\n",
      "loss: 0.349192  [   84/  175]\n",
      "loss: 0.141685  [  164/  175]\n",
      "Training accuracy: 84.7%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.185843 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.283148  [    4/  175]\n",
      "loss: 0.417866  [   84/  175]\n",
      "loss: 0.433097  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 65.2%, Avg loss: 0.636050 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.229558  [    4/  175]\n",
      "loss: 0.662503  [   84/  175]\n",
      "loss: 0.222098  [  164/  175]\n",
      "Training accuracy: 89.0%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.174090 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.278004  [    4/  175]\n",
      "loss: 0.720291  [   84/  175]\n",
      "loss: 0.220580  [  164/  175]\n",
      "Training accuracy: 85.8%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.774931 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.754078  [    4/  175]\n",
      "loss: 0.249257  [   84/  175]\n",
      "loss: 1.045952  [  164/  175]\n",
      "Training accuracy: 86.9%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.175643 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.201373  [    4/  175]\n",
      "loss: 0.213968  [   84/  175]\n",
      "loss: 0.312829  [  164/  175]\n",
      "Training accuracy: 90.2%\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 3.317807 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.333764  [    4/  175]\n",
      "loss: 0.254374  [   84/  175]\n",
      "loss: 0.109215  [  164/  175]\n",
      "Training accuracy: 89.6%\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.239750 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.429795  [    4/  175]\n",
      "loss: 0.171620  [   84/  175]\n",
      "loss: 0.103182  [  164/  175]\n",
      "Training accuracy: 89.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.104830 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.080231  [    4/  175]\n",
      "loss: 0.183550  [   84/  175]\n",
      "loss: 0.214920  [  164/  175]\n",
      "Training accuracy: 90.7%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.103565 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.827972  [    4/  175]\n",
      "loss: 0.100817  [   84/  175]\n",
      "loss: 0.214942  [  164/  175]\n",
      "Training accuracy: 89.2%\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.302574 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.121954  [    4/  175]\n",
      "loss: 0.283855  [   84/  175]\n",
      "loss: 0.222904  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.154032 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.143910  [    4/  175]\n",
      "loss: 0.187293  [   84/  175]\n",
      "loss: 0.081399  [  164/  175]\n",
      "Training accuracy: 90.7%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.139452 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.259008  [    4/  175]\n",
      "loss: 0.223017  [   84/  175]\n",
      "loss: 1.248276  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.278467 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.127435  [    4/  175]\n",
      "loss: 0.167523  [   84/  175]\n",
      "loss: 0.251996  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.110953 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.153794  [    4/  175]\n",
      "loss: 0.085886  [   84/  175]\n",
      "loss: 0.067849  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 75.0%, Avg loss: 0.369268 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.040369  [    4/  175]\n",
      "loss: 0.149062  [   84/  175]\n",
      "loss: 0.055591  [  164/  175]\n",
      "Training accuracy: 91.7%\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.258038 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.089953  [    4/  175]\n",
      "loss: 0.273964  [   84/  175]\n",
      "loss: 0.294122  [  164/  175]\n",
      "Training accuracy: 87.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.065251 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.055223  [    4/  175]\n",
      "loss: 0.063461  [   84/  175]\n",
      "loss: 0.135186  [  164/  175]\n",
      "Training accuracy: 94.9%\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.381433 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.216528  [    4/  175]\n",
      "loss: 1.242041  [   84/  175]\n",
      "loss: 0.157727  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.071957 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.160812  [    4/  175]\n",
      "loss: 0.026373  [   84/  175]\n",
      "loss: 0.251297  [  164/  175]\n",
      "Training accuracy: 88.4%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.943474 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.332317  [    4/  175]\n",
      "loss: 0.141976  [   84/  175]\n",
      "loss: 0.786243  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.159911 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.066846  [    4/  175]\n",
      "loss: 0.130901  [   84/  175]\n",
      "loss: 0.171600  [  164/  175]\n",
      "Training accuracy: 87.1%\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 0.720387 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.334406  [    4/  175]\n",
      "loss: 0.187712  [   84/  175]\n",
      "loss: 0.024978  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.219421 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.110542  [    4/  175]\n",
      "loss: 0.046560  [   84/  175]\n",
      "loss: 0.157508  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.058039 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.034607  [    4/  175]\n",
      "loss: 0.720122  [   84/  175]\n",
      "loss: 0.028069  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 0.490139 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.092872  [    4/  175]\n",
      "loss: 0.052117  [   84/  175]\n",
      "loss: 0.089559  [  164/  175]\n",
      "Training accuracy: 86.7%\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.316003 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.020578  [    4/  175]\n",
      "loss: 0.159714  [   84/  175]\n",
      "loss: 0.024909  [  164/  175]\n",
      "Training accuracy: 97.7%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.051758 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.725917  [    4/  175]\n",
      "loss: 0.060156  [   84/  175]\n",
      "loss: 0.811791  [  164/  175]\n",
      "Training accuracy: 86.9%\n",
      "Test Error: \n",
      " Accuracy: 72.7%, Avg loss: 0.409816 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.121269  [    4/  175]\n",
      "loss: 0.141842  [   84/  175]\n",
      "loss: 0.032297  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.047190 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.020590  [    4/  175]\n",
      "loss: 0.894931  [   84/  175]\n",
      "loss: 0.018855  [  164/  175]\n",
      "Training accuracy: 89.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.040454 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.040722  [    4/  175]\n",
      "loss: 0.086099  [   84/  175]\n",
      "loss: 0.141732  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.037596 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.018897  [    4/  175]\n",
      "loss: 0.112266  [   84/  175]\n",
      "loss: 0.103352  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.044439 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.164013  [    4/  175]\n",
      "loss: 0.026320  [   84/  175]\n",
      "loss: 0.121232  [  164/  175]\n",
      "Training accuracy: 91.9%\n",
      "Test Error: \n",
      " Accuracy: 69.7%, Avg loss: 0.484365 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.076750  [    4/  175]\n",
      "loss: 0.095750  [   84/  175]\n",
      "loss: 0.016436  [  164/  175]\n",
      "Training accuracy: 91.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.063929 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.081125  [    4/  175]\n",
      "loss: 0.018209  [   84/  175]\n",
      "loss: 0.222388  [  164/  175]\n",
      "Training accuracy: 93.4%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.043157 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.031062  [    4/  175]\n",
      "loss: 0.019544  [   84/  175]\n",
      "loss: 1.066839  [  164/  175]\n",
      "Training accuracy: 88.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.046106 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.020137  [    4/  175]\n",
      "loss: 0.339296  [   84/  175]\n",
      "loss: 0.015443  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.047574 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.018763  [    4/  175]\n",
      "loss: 0.032040  [   84/  175]\n",
      "loss: 0.078483  [  164/  175]\n",
      "Training accuracy: 91.7%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.053463 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.063063  [    4/  175]\n",
      "loss: 0.094842  [   84/  175]\n",
      "loss: 0.019430  [  164/  175]\n",
      "Training accuracy: 88.6%\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.248072 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.147583  [    4/  175]\n",
      "loss: 0.078070  [   84/  175]\n",
      "loss: 0.098578  [  164/  175]\n",
      "Training accuracy: 93.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.030206 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 1.133939  [    4/  175]\n",
      "loss: 0.087172  [   84/  175]\n",
      "loss: 0.091506  [  164/  175]\n",
      "Training accuracy: 89.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.032658 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.021868  [    4/  175]\n",
      "loss: 0.037135  [   84/  175]\n",
      "loss: 0.011899  [  164/  175]\n",
      "Training accuracy: 95.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.024253 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.845793  [    4/  175]\n",
      "loss: 0.802952  [   84/  175]\n",
      "loss: 0.083679  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.280108 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.118718  [    4/  175]\n",
      "loss: 0.831216  [   84/  175]\n",
      "loss: 0.131389  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.036583 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.011318  [    4/  175]\n",
      "loss: 0.057383  [   84/  175]\n",
      "loss: 2.290167  [  164/  175]\n",
      "Training accuracy: 84.5%\n",
      "Test Error: \n",
      " Accuracy: 55.3%, Avg loss: 4.186789 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 2.498143  [    4/  175]\n",
      "loss: 1.904846  [   84/  175]\n",
      "loss: 0.108174  [  164/  175]\n",
      "Training accuracy: 76.1%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 4.002722 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.113826  [    4/  175]\n",
      "loss: 0.111651  [   84/  175]\n",
      "loss: 0.102271  [  164/  175]\n",
      "Training accuracy: 94.1%\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.381726 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.039347  [    4/  175]\n",
      "loss: 0.028608  [   84/  175]\n",
      "loss: 0.092932  [  164/  175]\n",
      "Training accuracy: 96.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.044726 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.764760  [    4/  175]\n",
      "loss: 0.786209  [   84/  175]\n",
      "loss: 0.697117  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.133420 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.025411  [    4/  175]\n",
      "loss: 0.592557  [   84/  175]\n",
      "loss: 0.094615  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.065645 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.359052  [    4/  175]\n",
      "loss: 0.091903  [   84/  175]\n",
      "loss: 0.106619  [  164/  175]\n",
      "Training accuracy: 89.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.030362 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.853679  [    4/  175]\n",
      "loss: 0.131801  [   84/  175]\n",
      "loss: 0.090365  [  164/  175]\n",
      "Training accuracy: 90.0%\n",
      "Test Error: \n",
      " Accuracy: 73.5%, Avg loss: 0.486755 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.021457  [    4/  175]\n",
      "loss: 0.051183  [   84/  175]\n",
      "loss: 0.929737  [  164/  175]\n",
      "Training accuracy: 89.8%\n",
      "Test Error: \n",
      " Accuracy: 65.2%, Avg loss: 0.578506 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.080386  [    4/  175]\n",
      "loss: 0.263028  [   84/  175]\n",
      "loss: 0.071258  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 69.7%, Avg loss: 0.483940 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.013218  [    4/  175]\n",
      "loss: 0.099394  [   84/  175]\n",
      "loss: 0.522629  [  164/  175]\n",
      "Training accuracy: 91.9%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 2.617782 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.161214  [    4/  175]\n",
      "loss: 0.116299  [   84/  175]\n",
      "loss: 0.108168  [  164/  175]\n",
      "Training accuracy: 91.7%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.024232 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.075230  [    4/  175]\n",
      "loss: 0.076836  [   84/  175]\n",
      "loss: 0.064836  [  164/  175]\n",
      "Training accuracy: 96.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.029616 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.071215  [    4/  175]\n",
      "loss: 0.092031  [   84/  175]\n",
      "loss: 0.084906  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.031686 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.157186  [    4/  175]\n",
      "loss: 0.021602  [   84/  175]\n",
      "loss: 0.016309  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.024224 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.093086  [    4/  175]\n",
      "loss: 0.117919  [   84/  175]\n",
      "loss: 0.072776  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.026381 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.022926  [    4/  175]\n",
      "loss: 0.025789  [   84/  175]\n",
      "loss: 0.062612  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.027233 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.085630  [    4/  175]\n",
      "loss: 0.063780  [   84/  175]\n",
      "loss: 1.134557  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.032006 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.080923  [    4/  175]\n",
      "loss: 0.647305  [   84/  175]\n",
      "loss: 0.131740  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 87.9%, Avg loss: 0.255870 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.015973  [    4/  175]\n",
      "loss: 0.066976  [   84/  175]\n",
      "loss: 0.761642  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.044545 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.198530  [    4/  175]\n",
      "loss: 0.073421  [   84/  175]\n",
      "loss: 0.085048  [  164/  175]\n",
      "Training accuracy: 94.9%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.070744 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.012142  [    4/  175]\n",
      "loss: 0.075959  [   84/  175]\n",
      "loss: 0.067036  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.077426 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.061036  [    4/  175]\n",
      "loss: 0.063661  [   84/  175]\n",
      "loss: 0.066084  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.043309 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.012971  [    4/  175]\n",
      "loss: 0.061277  [   84/  175]\n",
      "loss: 0.013658  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.054341 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.023166  [    4/  175]\n",
      "loss: 0.863250  [   84/  175]\n",
      "loss: 0.012420  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.030530 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.114223  [    4/  175]\n",
      "loss: 0.014740  [   84/  175]\n",
      "loss: 0.080450  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.069009 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.055101  [    4/  175]\n",
      "loss: 0.114033  [   84/  175]\n",
      "loss: 0.152753  [  164/  175]\n",
      "Training accuracy: 86.7%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 2.796214 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.095068  [    4/  175]\n",
      "loss: 0.178067  [   84/  175]\n",
      "loss: 0.093432  [  164/  175]\n",
      "Training accuracy: 91.7%\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.285262 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.106158  [    4/  175]\n",
      "loss: 0.019440  [   84/  175]\n",
      "loss: 0.848489  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.025348 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.008904  [    4/  175]\n",
      "loss: 0.056618  [   84/  175]\n",
      "loss: 0.019712  [  164/  175]\n",
      "Training accuracy: 96.6%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 1.303841 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.029224  [    4/  175]\n",
      "loss: 0.938222  [   84/  175]\n",
      "loss: 0.108991  [  164/  175]\n",
      "Training accuracy: 91.7%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.061872 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.131826  [    4/  175]\n",
      "loss: 0.014036  [   84/  175]\n",
      "loss: 0.064432  [  164/  175]\n",
      "Training accuracy: 93.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.043706 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.030039  [    4/  175]\n",
      "loss: 0.085245  [   84/  175]\n",
      "loss: 0.675004  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.014355 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.064483  [    4/  175]\n",
      "loss: 0.078264  [   84/  175]\n",
      "loss: 0.012330  [  164/  175]\n",
      "Training accuracy: 96.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.022802 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 1.165123  [    4/  175]\n",
      "loss: 0.011510  [   84/  175]\n",
      "loss: 0.077307  [  164/  175]\n",
      "Training accuracy: 92.4%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.136123 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 1.091325  [    4/  175]\n",
      "loss: 0.056709  [   84/  175]\n",
      "loss: 0.124486  [  164/  175]\n",
      "Training accuracy: 94.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.033892 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.094238  [    4/  175]\n",
      "loss: 0.139131  [   84/  175]\n",
      "loss: 0.062365  [  164/  175]\n",
      "Training accuracy: 94.7%\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.232795 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.103105  [    4/  175]\n",
      "loss: 0.743110  [   84/  175]\n",
      "loss: 0.710801  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 65.9%, Avg loss: 0.511100 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.010394  [    4/  175]\n",
      "loss: 0.012634  [   84/  175]\n",
      "loss: 0.099390  [  164/  175]\n",
      "Training accuracy: 88.4%\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 2.816059 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.040778  [    4/  175]\n",
      "loss: 0.893093  [   84/  175]\n",
      "loss: 0.009210  [  164/  175]\n",
      "Training accuracy: 90.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.029750 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.068379  [    4/  175]\n",
      "loss: 0.066694  [   84/  175]\n",
      "loss: 0.067613  [  164/  175]\n",
      "Training accuracy: 91.9%\n",
      "Test Error: \n",
      " Accuracy: 57.6%, Avg loss: 0.818942 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.084597  [    4/  175]\n",
      "loss: 0.062300  [   84/  175]\n",
      "loss: 0.073243  [  164/  175]\n",
      "Training accuracy: 90.7%\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.222707 \n",
      "\n",
      "Done!\n",
      "Training model 'wider'...\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "loss: 0.697480  [    4/  175]\n",
      "loss: 0.600877  [   84/  175]\n",
      "loss: 0.632640  [  164/  175]\n",
      "Training accuracy: 61.0%\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.683438 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.815756  [    4/  175]\n",
      "loss: 0.827822  [   84/  175]\n",
      "loss: 0.648654  [  164/  175]\n",
      "Training accuracy: 60.6%\n",
      "Test Error: \n",
      " Accuracy: 55.3%, Avg loss: 0.667873 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.453001  [    4/  175]\n",
      "loss: 0.437789  [   84/  175]\n",
      "loss: 0.557886  [  164/  175]\n",
      "Training accuracy: 67.6%\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.671509 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.698063  [    4/  175]\n",
      "loss: 0.544051  [   84/  175]\n",
      "loss: 0.540265  [  164/  175]\n",
      "Training accuracy: 63.8%\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 0.696597 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.403801  [    4/  175]\n",
      "loss: 0.608976  [   84/  175]\n",
      "loss: 0.537571  [  164/  175]\n",
      "Training accuracy: 63.8%\n",
      "Test Error: \n",
      " Accuracy: 61.4%, Avg loss: 0.667405 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.532787  [    4/  175]\n",
      "loss: 0.795121  [   84/  175]\n",
      "loss: 0.475938  [  164/  175]\n",
      "Training accuracy: 68.4%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.089628 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.688899  [    4/  175]\n",
      "loss: 0.651530  [   84/  175]\n",
      "loss: 0.631988  [  164/  175]\n",
      "Training accuracy: 71.4%\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 0.720721 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.402333  [    4/  175]\n",
      "loss: 0.989045  [   84/  175]\n",
      "loss: 0.521215  [  164/  175]\n",
      "Training accuracy: 66.5%\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.889785 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.402497  [    4/  175]\n",
      "loss: 0.471828  [   84/  175]\n",
      "loss: 0.841587  [  164/  175]\n",
      "Training accuracy: 71.4%\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 1.360579 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.383972  [    4/  175]\n",
      "loss: 0.354038  [   84/  175]\n",
      "loss: 0.594369  [  164/  175]\n",
      "Training accuracy: 74.2%\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 1.837844 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.482433  [    4/  175]\n",
      "loss: 0.789888  [   84/  175]\n",
      "loss: 0.381204  [  164/  175]\n",
      "Training accuracy: 75.8%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 2.546095 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.469873  [    4/  175]\n",
      "loss: 0.463292  [   84/  175]\n",
      "loss: 0.435792  [  164/  175]\n",
      "Training accuracy: 80.7%\n",
      "Test Error: \n",
      " Accuracy: 82.6%, Avg loss: 0.461686 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.455660  [    4/  175]\n",
      "loss: 0.828231  [   84/  175]\n",
      "loss: 0.315475  [  164/  175]\n",
      "Training accuracy: 82.4%\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 1.437992 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.273324  [    4/  175]\n",
      "loss: 0.261891  [   84/  175]\n",
      "loss: 0.238350  [  164/  175]\n",
      "Training accuracy: 85.6%\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 0.449081 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.285026  [    4/  175]\n",
      "loss: 0.264053  [   84/  175]\n",
      "loss: 0.751239  [  164/  175]\n",
      "Training accuracy: 80.7%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.788957 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.338027  [    4/  175]\n",
      "loss: 0.732172  [   84/  175]\n",
      "loss: 0.216503  [  164/  175]\n",
      "Training accuracy: 82.8%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 4.579788 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.558198  [    4/  175]\n",
      "loss: 0.263959  [   84/  175]\n",
      "loss: 0.290739  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.963011 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.282385  [    4/  175]\n",
      "loss: 0.274221  [   84/  175]\n",
      "loss: 0.128800  [  164/  175]\n",
      "Training accuracy: 85.8%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 0.923423 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.235484  [    4/  175]\n",
      "loss: 0.269564  [   84/  175]\n",
      "loss: 0.162051  [  164/  175]\n",
      "Training accuracy: 87.3%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.141167 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.276867  [    4/  175]\n",
      "loss: 0.231851  [   84/  175]\n",
      "loss: 0.129674  [  164/  175]\n",
      "Training accuracy: 95.5%\n",
      "Test Error: \n",
      " Accuracy: 56.1%, Avg loss: 0.923926 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.079708  [    4/  175]\n",
      "loss: 0.352109  [   84/  175]\n",
      "loss: 0.318135  [  164/  175]\n",
      "Training accuracy: 89.2%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 0.652517 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.073355  [    4/  175]\n",
      "loss: 0.088173  [   84/  175]\n",
      "loss: 0.227566  [  164/  175]\n",
      "Training accuracy: 84.1%\n",
      "Test Error: \n",
      " Accuracy: 65.9%, Avg loss: 0.493500 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.316530  [    4/  175]\n",
      "loss: 0.125073  [   84/  175]\n",
      "loss: 0.343054  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.288498 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.208085  [    4/  175]\n",
      "loss: 0.175474  [   84/  175]\n",
      "loss: 0.813312  [  164/  175]\n",
      "Training accuracy: 86.4%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 0.970178 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.059861  [    4/  175]\n",
      "loss: 0.289546  [   84/  175]\n",
      "loss: 1.090318  [  164/  175]\n",
      "Training accuracy: 87.3%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.365558 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.382273  [    4/  175]\n",
      "loss: 0.670971  [   84/  175]\n",
      "loss: 0.190332  [  164/  175]\n",
      "Training accuracy: 90.2%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 2.788139 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.261102  [    4/  175]\n",
      "loss: 0.212960  [   84/  175]\n",
      "loss: 0.235017  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.641064 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.212425  [    4/  175]\n",
      "loss: 0.047803  [   84/  175]\n",
      "loss: 0.049306  [  164/  175]\n",
      "Training accuracy: 95.5%\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.370641 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.144590  [    4/  175]\n",
      "loss: 0.117533  [   84/  175]\n",
      "loss: 0.135569  [  164/  175]\n",
      "Training accuracy: 85.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.199398 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.223650  [    4/  175]\n",
      "loss: 0.071620  [   84/  175]\n",
      "loss: 0.291945  [  164/  175]\n",
      "Training accuracy: 95.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.115423 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.178197  [    4/  175]\n",
      "loss: 0.176598  [   84/  175]\n",
      "loss: 0.022677  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 72.7%, Avg loss: 0.511619 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.140420  [    4/  175]\n",
      "loss: 0.026788  [   84/  175]\n",
      "loss: 0.100538  [  164/  175]\n",
      "Training accuracy: 96.6%\n",
      "Test Error: \n",
      " Accuracy: 69.7%, Avg loss: 0.414366 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.770910  [    4/  175]\n",
      "loss: 1.043311  [   84/  175]\n",
      "loss: 0.203113  [  164/  175]\n",
      "Training accuracy: 88.6%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.095382 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.019506  [    4/  175]\n",
      "loss: 0.949855  [   84/  175]\n",
      "loss: 0.062841  [  164/  175]\n",
      "Training accuracy: 86.4%\n",
      "Test Error: \n",
      " Accuracy: 66.7%, Avg loss: 0.625593 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.102453  [    4/  175]\n",
      "loss: 0.348256  [   84/  175]\n",
      "loss: 0.038040  [  164/  175]\n",
      "Training accuracy: 91.1%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.066504 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.047515  [    4/  175]\n",
      "loss: 0.098200  [   84/  175]\n",
      "loss: 0.060685  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.099759 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.207782  [    4/  175]\n",
      "loss: 0.039261  [   84/  175]\n",
      "loss: 0.722946  [  164/  175]\n",
      "Training accuracy: 90.2%\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.239932 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.281842  [    4/  175]\n",
      "loss: 0.181928  [   84/  175]\n",
      "loss: 0.044763  [  164/  175]\n",
      "Training accuracy: 91.3%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.094100 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.210532  [    4/  175]\n",
      "loss: 0.026375  [   84/  175]\n",
      "loss: 1.006397  [  164/  175]\n",
      "Training accuracy: 89.8%\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.380114 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.259227  [    4/  175]\n",
      "loss: 0.755820  [   84/  175]\n",
      "loss: 0.179855  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.050131 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.225409  [    4/  175]\n",
      "loss: 0.017100  [   84/  175]\n",
      "loss: 0.755372  [  164/  175]\n",
      "Training accuracy: 88.1%\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 0.634952 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.099466  [    4/  175]\n",
      "loss: 0.230744  [   84/  175]\n",
      "loss: 0.115338  [  164/  175]\n",
      "Training accuracy: 94.7%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.066204 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.721590  [    4/  175]\n",
      "loss: 0.287112  [   84/  175]\n",
      "loss: 0.170897  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.050161 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.018531  [    4/  175]\n",
      "loss: 0.070711  [   84/  175]\n",
      "loss: 0.230287  [  164/  175]\n",
      "Training accuracy: 94.9%\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.351529 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.185019  [    4/  175]\n",
      "loss: 1.021902  [   84/  175]\n",
      "loss: 0.179032  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.354095 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.126987  [    4/  175]\n",
      "loss: 1.271024  [   84/  175]\n",
      "loss: 0.108545  [  164/  175]\n",
      "Training accuracy: 90.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.050097 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.078936  [    4/  175]\n",
      "loss: 0.196234  [   84/  175]\n",
      "loss: 0.016611  [  164/  175]\n",
      "Training accuracy: 86.9%\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 0.472107 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.072313  [    4/  175]\n",
      "loss: 0.337880  [   84/  175]\n",
      "loss: 0.867006  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.301103 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.120843  [    4/  175]\n",
      "loss: 0.463928  [   84/  175]\n",
      "loss: 0.250657  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.052873 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.159003  [    4/  175]\n",
      "loss: 0.132650  [   84/  175]\n",
      "loss: 0.859008  [  164/  175]\n",
      "Training accuracy: 87.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.076399 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.301295  [    4/  175]\n",
      "loss: 0.019385  [   84/  175]\n",
      "loss: 0.015843  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.172679 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.194367  [    4/  175]\n",
      "loss: 0.103687  [   84/  175]\n",
      "loss: 0.162543  [  164/  175]\n",
      "Training accuracy: 92.2%\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 0.469289 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.775427  [    4/  175]\n",
      "loss: 0.164787  [   84/  175]\n",
      "loss: 0.765877  [  164/  175]\n",
      "Training accuracy: 89.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.043073 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.026688  [    4/  175]\n",
      "loss: 0.086378  [   84/  175]\n",
      "loss: 0.037578  [  164/  175]\n",
      "Training accuracy: 89.8%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.041047 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.020918  [    4/  175]\n",
      "loss: 0.765466  [   84/  175]\n",
      "loss: 0.099358  [  164/  175]\n",
      "Training accuracy: 86.6%\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.252170 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.120308  [    4/  175]\n",
      "loss: 0.026238  [   84/  175]\n",
      "loss: 0.297085  [  164/  175]\n",
      "Training accuracy: 90.7%\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 0.573871 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.163809  [    4/  175]\n",
      "loss: 0.012416  [   84/  175]\n",
      "loss: 0.048660  [  164/  175]\n",
      "Training accuracy: 93.0%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.834043 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.093831  [    4/  175]\n",
      "loss: 0.211071  [   84/  175]\n",
      "loss: 0.177506  [  164/  175]\n",
      "Training accuracy: 94.5%\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 1.808562 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.095817  [    4/  175]\n",
      "loss: 0.057591  [   84/  175]\n",
      "loss: 0.020225  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.046057 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.022084  [    4/  175]\n",
      "loss: 0.025547  [   84/  175]\n",
      "loss: 0.804313  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 51.5%, Avg loss: 0.551759 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.799736  [    4/  175]\n",
      "loss: 0.060741  [   84/  175]\n",
      "loss: 0.807247  [  164/  175]\n",
      "Training accuracy: 89.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.077318 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.108947  [    4/  175]\n",
      "loss: 0.142085  [   84/  175]\n",
      "loss: 0.119863  [  164/  175]\n",
      "Training accuracy: 89.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.036487 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.183992  [    4/  175]\n",
      "loss: 0.006563  [   84/  175]\n",
      "loss: 0.006845  [  164/  175]\n",
      "Training accuracy: 96.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.102400 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.055618  [    4/  175]\n",
      "loss: 0.130151  [   84/  175]\n",
      "loss: 0.078145  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.023486 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.008203  [    4/  175]\n",
      "loss: 0.067699  [   84/  175]\n",
      "loss: 0.089152  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.221772 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.075622  [    4/  175]\n",
      "loss: 0.055337  [   84/  175]\n",
      "loss: 0.119762  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.075676 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.085076  [    4/  175]\n",
      "loss: 0.011144  [   84/  175]\n",
      "loss: 0.161165  [  164/  175]\n",
      "Training accuracy: 97.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.030996 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.020987  [    4/  175]\n",
      "loss: 0.155359  [   84/  175]\n",
      "loss: 0.005378  [  164/  175]\n",
      "Training accuracy: 89.6%\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 0.411949 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.047102  [    4/  175]\n",
      "loss: 0.014056  [   84/  175]\n",
      "loss: 0.049374  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.028579 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.078238  [    4/  175]\n",
      "loss: 0.076339  [   84/  175]\n",
      "loss: 0.081081  [  164/  175]\n",
      "Training accuracy: 93.9%\n",
      "Test Error: \n",
      " Accuracy: 74.2%, Avg loss: 0.503242 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.216465  [    4/  175]\n",
      "loss: 0.882147  [   84/  175]\n",
      "loss: 0.046711  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.060716 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.084481  [    4/  175]\n",
      "loss: 0.050301  [   84/  175]\n",
      "loss: 0.065738  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 94.7%, Avg loss: 0.116259 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.048929  [    4/  175]\n",
      "loss: 0.224788  [   84/  175]\n",
      "loss: 0.209530  [  164/  175]\n",
      "Training accuracy: 89.0%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 3.425191 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.344429  [    4/  175]\n",
      "loss: 0.004630  [   84/  175]\n",
      "loss: 0.080288  [  164/  175]\n",
      "Training accuracy: 89.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.109166 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.115143  [    4/  175]\n",
      "loss: 0.161800  [   84/  175]\n",
      "loss: 0.013176  [  164/  175]\n",
      "Training accuracy: 97.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.027837 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.081325  [    4/  175]\n",
      "loss: 0.251816  [   84/  175]\n",
      "loss: 0.954137  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.040411 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.007844  [    4/  175]\n",
      "loss: 0.019427  [   84/  175]\n",
      "loss: 0.057498  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.023538 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.013916  [    4/  175]\n",
      "loss: 0.977706  [   84/  175]\n",
      "loss: 0.745563  [  164/  175]\n",
      "Training accuracy: 95.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.078811 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.004594  [    4/  175]\n",
      "loss: 0.006897  [   84/  175]\n",
      "loss: 0.069418  [  164/  175]\n",
      "Training accuracy: 86.6%\n",
      "Test Error: \n",
      " Accuracy: 56.8%, Avg loss: 1.283437 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.086311  [    4/  175]\n",
      "loss: 0.050848  [   84/  175]\n",
      "loss: 0.170731  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.033083 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.515807  [    4/  175]\n",
      "loss: 0.043775  [   84/  175]\n",
      "loss: 0.044731  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.147561 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.005560  [    4/  175]\n",
      "loss: 0.010037  [   84/  175]\n",
      "loss: 0.279287  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.021646 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.010666  [    4/  175]\n",
      "loss: 0.007110  [   84/  175]\n",
      "loss: 0.015385  [  164/  175]\n",
      "Training accuracy: 95.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.017891 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.125658  [    4/  175]\n",
      "loss: 0.803316  [   84/  175]\n",
      "loss: 0.006762  [  164/  175]\n",
      "Training accuracy: 89.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.195976 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.011887  [    4/  175]\n",
      "loss: 0.146398  [   84/  175]\n",
      "loss: 0.042747  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.075640 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.105616  [    4/  175]\n",
      "loss: 0.005018  [   84/  175]\n",
      "loss: 0.009811  [  164/  175]\n",
      "Training accuracy: 95.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.107343 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.800132  [    4/  175]\n",
      "loss: 0.215229  [   84/  175]\n",
      "loss: 0.113904  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.031497 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.699285  [    4/  175]\n",
      "loss: 1.336380  [   84/  175]\n",
      "loss: 0.180178  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.034172 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.093160  [    4/  175]\n",
      "loss: 0.005935  [   84/  175]\n",
      "loss: 0.037484  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.014515 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.011493  [    4/  175]\n",
      "loss: 0.103722  [   84/  175]\n",
      "loss: 0.010200  [  164/  175]\n",
      "Training accuracy: 91.7%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.066133 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.873482  [    4/  175]\n",
      "loss: 0.066439  [   84/  175]\n",
      "loss: 0.006838  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 70.5%, Avg loss: 0.812196 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 1.314874  [    4/  175]\n",
      "loss: 0.125999  [   84/  175]\n",
      "loss: 0.046388  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.157273 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.005041  [    4/  175]\n",
      "loss: 0.198804  [   84/  175]\n",
      "loss: 0.007141  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.399434 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.101904  [    4/  175]\n",
      "loss: 0.008639  [   84/  175]\n",
      "loss: 0.024079  [  164/  175]\n",
      "Training accuracy: 92.4%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.227590 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.369642  [    4/  175]\n",
      "loss: 0.058063  [   84/  175]\n",
      "loss: 0.061200  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.015616 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.012712  [    4/  175]\n",
      "loss: 0.007847  [   84/  175]\n",
      "loss: 0.097685  [  164/  175]\n",
      "Training accuracy: 93.4%\n",
      "Test Error: \n",
      " Accuracy: 75.8%, Avg loss: 0.375167 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.050893  [    4/  175]\n",
      "loss: 0.006653  [   84/  175]\n",
      "loss: 0.008275  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.014270 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.826623  [    4/  175]\n",
      "loss: 0.006966  [   84/  175]\n",
      "loss: 0.093156  [  164/  175]\n",
      "Training accuracy: 88.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.017108 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.009728  [    4/  175]\n",
      "loss: 0.053942  [   84/  175]\n",
      "loss: 0.054241  [  164/  175]\n",
      "Training accuracy: 88.4%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.554419 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.050027  [    4/  175]\n",
      "loss: 0.053501  [   84/  175]\n",
      "loss: 0.217049  [  164/  175]\n",
      "Training accuracy: 96.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.022002 \n",
      "\n",
      "Done!\n",
      "Training model 'linear_before_rnn'...\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "loss: 0.631580  [    4/  175]\n",
      "loss: 0.756986  [   84/  175]\n",
      "loss: 0.922201  [  164/  175]\n",
      "Training accuracy: 52.1%\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.696982 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.959819  [    4/  175]\n",
      "loss: 0.498977  [   84/  175]\n",
      "loss: 0.540670  [  164/  175]\n",
      "Training accuracy: 60.2%\n",
      "Test Error: \n",
      " Accuracy: 54.5%, Avg loss: 0.676003 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.578830  [    4/  175]\n",
      "loss: 0.784101  [   84/  175]\n",
      "loss: 0.708311  [  164/  175]\n",
      "Training accuracy: 64.6%\n",
      "Test Error: \n",
      " Accuracy: 62.1%, Avg loss: 0.661084 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.486400  [    4/  175]\n",
      "loss: 0.517650  [   84/  175]\n",
      "loss: 0.587215  [  164/  175]\n",
      "Training accuracy: 66.9%\n",
      "Test Error: \n",
      " Accuracy: 62.9%, Avg loss: 0.656734 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.906244  [    4/  175]\n",
      "loss: 0.604397  [   84/  175]\n",
      "loss: 0.684856  [  164/  175]\n",
      "Training accuracy: 65.0%\n",
      "Test Error: \n",
      " Accuracy: 62.9%, Avg loss: 0.628679 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.602233  [    4/  175]\n",
      "loss: 0.681871  [   84/  175]\n",
      "loss: 0.448662  [  164/  175]\n",
      "Training accuracy: 65.0%\n",
      "Test Error: \n",
      " Accuracy: 67.4%, Avg loss: 0.596934 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.618547  [    4/  175]\n",
      "loss: 0.481625  [   84/  175]\n",
      "loss: 0.621702  [  164/  175]\n",
      "Training accuracy: 72.7%\n",
      "Test Error: \n",
      " Accuracy: 63.6%, Avg loss: 0.594466 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.373788  [    4/  175]\n",
      "loss: 0.671569  [   84/  175]\n",
      "loss: 0.359101  [  164/  175]\n",
      "Training accuracy: 68.9%\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 0.747513 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.499965  [    4/  175]\n",
      "loss: 0.787661  [   84/  175]\n",
      "loss: 0.483007  [  164/  175]\n",
      "Training accuracy: 68.4%\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 0.545144 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.484404  [    4/  175]\n",
      "loss: 0.429313  [   84/  175]\n",
      "loss: 0.780562  [  164/  175]\n",
      "Training accuracy: 72.7%\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.506936 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.292924  [    4/  175]\n",
      "loss: 0.496235  [   84/  175]\n",
      "loss: 0.786525  [  164/  175]\n",
      "Training accuracy: 78.4%\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.523890 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.429736  [    4/  175]\n",
      "loss: 0.640307  [   84/  175]\n",
      "loss: 1.010623  [  164/  175]\n",
      "Training accuracy: 75.6%\n",
      "Test Error: \n",
      " Accuracy: 65.2%, Avg loss: 0.852975 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.772009  [    4/  175]\n",
      "loss: 0.337128  [   84/  175]\n",
      "loss: 0.486982  [  164/  175]\n",
      "Training accuracy: 74.6%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.361714 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.723772  [    4/  175]\n",
      "loss: 0.721865  [   84/  175]\n",
      "loss: 0.374149  [  164/  175]\n",
      "Training accuracy: 70.6%\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 1.832604 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.578816  [    4/  175]\n",
      "loss: 0.812046  [   84/  175]\n",
      "loss: 0.573966  [  164/  175]\n",
      "Training accuracy: 83.5%\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.372049 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.537240  [    4/  175]\n",
      "loss: 0.771680  [   84/  175]\n",
      "loss: 0.230055  [  164/  175]\n",
      "Training accuracy: 84.8%\n",
      "Test Error: \n",
      " Accuracy: 67.4%, Avg loss: 0.562800 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.298129  [    4/  175]\n",
      "loss: 0.163840  [   84/  175]\n",
      "loss: 0.493308  [  164/  175]\n",
      "Training accuracy: 83.9%\n",
      "Test Error: \n",
      " Accuracy: 90.2%, Avg loss: 0.343968 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.256618  [    4/  175]\n",
      "loss: 0.396434  [   84/  175]\n",
      "loss: 0.266317  [  164/  175]\n",
      "Training accuracy: 88.1%\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.357244 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.370710  [    4/  175]\n",
      "loss: 0.244813  [   84/  175]\n",
      "loss: 0.241840  [  164/  175]\n",
      "Training accuracy: 86.4%\n",
      "Test Error: \n",
      " Accuracy: 81.8%, Avg loss: 0.301652 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.279964  [    4/  175]\n",
      "loss: 0.217172  [   84/  175]\n",
      "loss: 0.708347  [  164/  175]\n",
      "Training accuracy: 88.6%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 0.863982 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.121609  [    4/  175]\n",
      "loss: 0.228476  [   84/  175]\n",
      "loss: 0.370716  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.197776 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.203331  [    4/  175]\n",
      "loss: 0.189228  [   84/  175]\n",
      "loss: 0.203828  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.244628 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.183624  [    4/  175]\n",
      "loss: 0.108087  [   84/  175]\n",
      "loss: 0.187022  [  164/  175]\n",
      "Training accuracy: 90.5%\n",
      "Test Error: \n",
      " Accuracy: 92.4%, Avg loss: 0.284997 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.259866  [    4/  175]\n",
      "loss: 0.494958  [   84/  175]\n",
      "loss: 0.260934  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 0.742017 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.106572  [    4/  175]\n",
      "loss: 0.278573  [   84/  175]\n",
      "loss: 0.662868  [  164/  175]\n",
      "Training accuracy: 87.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.106148 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.059769  [    4/  175]\n",
      "loss: 0.089854  [   84/  175]\n",
      "loss: 0.100979  [  164/  175]\n",
      "Training accuracy: 86.4%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.166812 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.180261  [    4/  175]\n",
      "loss: 0.174448  [   84/  175]\n",
      "loss: 0.078231  [  164/  175]\n",
      "Training accuracy: 91.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.135088 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.198196  [    4/  175]\n",
      "loss: 0.733335  [   84/  175]\n",
      "loss: 0.051646  [  164/  175]\n",
      "Training accuracy: 89.6%\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.269763 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.738953  [    4/  175]\n",
      "loss: 0.138750  [   84/  175]\n",
      "loss: 0.189379  [  164/  175]\n",
      "Training accuracy: 89.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.145723 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.255262  [    4/  175]\n",
      "loss: 0.169005  [   84/  175]\n",
      "loss: 0.047290  [  164/  175]\n",
      "Training accuracy: 97.2%\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.206716 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.150117  [    4/  175]\n",
      "loss: 0.054216  [   84/  175]\n",
      "loss: 0.141489  [  164/  175]\n",
      "Training accuracy: 89.4%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.066710 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.980281  [    4/  175]\n",
      "loss: 0.058251  [   84/  175]\n",
      "loss: 0.360537  [  164/  175]\n",
      "Training accuracy: 87.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.101684 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.104018  [    4/  175]\n",
      "loss: 0.089177  [   84/  175]\n",
      "loss: 1.002889  [  164/  175]\n",
      "Training accuracy: 86.2%\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.389902 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.068178  [    4/  175]\n",
      "loss: 1.173366  [   84/  175]\n",
      "loss: 0.117875  [  164/  175]\n",
      "Training accuracy: 94.1%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.085845 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 1.050230  [    4/  175]\n",
      "loss: 0.037845  [   84/  175]\n",
      "loss: 0.028761  [  164/  175]\n",
      "Training accuracy: 89.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.095019 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.076252  [    4/  175]\n",
      "loss: 0.030069  [   84/  175]\n",
      "loss: 0.428852  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.073442 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.035071  [    4/  175]\n",
      "loss: 0.110025  [   84/  175]\n",
      "loss: 0.173832  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.181739 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.047106  [    4/  175]\n",
      "loss: 0.257176  [   84/  175]\n",
      "loss: 0.148836  [  164/  175]\n",
      "Training accuracy: 90.7%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.091350 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.035726  [    4/  175]\n",
      "loss: 0.229018  [   84/  175]\n",
      "loss: 0.743285  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.244039 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.132530  [    4/  175]\n",
      "loss: 0.090149  [   84/  175]\n",
      "loss: 0.027827  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.070235 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.917299  [    4/  175]\n",
      "loss: 0.117133  [   84/  175]\n",
      "loss: 0.714572  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 47.7%, Avg loss: 0.812150 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.227126  [    4/  175]\n",
      "loss: 0.034341  [   84/  175]\n",
      "loss: 0.019764  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.050994 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.917085  [    4/  175]\n",
      "loss: 0.125875  [   84/  175]\n",
      "loss: 0.140856  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.065959 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.050375  [    4/  175]\n",
      "loss: 0.091089  [   84/  175]\n",
      "loss: 0.101908  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.063880 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.059226  [    4/  175]\n",
      "loss: 0.215612  [   84/  175]\n",
      "loss: 0.016449  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 52.3%, Avg loss: 0.440161 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.021406  [    4/  175]\n",
      "loss: 0.118797  [   84/  175]\n",
      "loss: 0.185887  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.044959 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.798151  [    4/  175]\n",
      "loss: 0.029255  [   84/  175]\n",
      "loss: 0.016782  [  164/  175]\n",
      "Training accuracy: 88.1%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.065646 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.082421  [    4/  175]\n",
      "loss: 0.054883  [   84/  175]\n",
      "loss: 0.153699  [  164/  175]\n",
      "Training accuracy: 85.6%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.706272 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.061633  [    4/  175]\n",
      "loss: 0.144307  [   84/  175]\n",
      "loss: 0.163238  [  164/  175]\n",
      "Training accuracy: 93.0%\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 1.700838 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.209070  [    4/  175]\n",
      "loss: 0.095728  [   84/  175]\n",
      "loss: 0.048930  [  164/  175]\n",
      "Training accuracy: 88.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.249256 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.154177  [    4/  175]\n",
      "loss: 0.090191  [   84/  175]\n",
      "loss: 0.097068  [  164/  175]\n",
      "Training accuracy: 86.4%\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.496008 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.163295  [    4/  175]\n",
      "loss: 0.189407  [   84/  175]\n",
      "loss: 0.015973  [  164/  175]\n",
      "Training accuracy: 92.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.122310 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.077541  [    4/  175]\n",
      "loss: 0.082770  [   84/  175]\n",
      "loss: 0.088289  [  164/  175]\n",
      "Training accuracy: 93.0%\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.297500 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.614157  [    4/  175]\n",
      "loss: 0.088937  [   84/  175]\n",
      "loss: 0.073675  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.070004 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.093775  [    4/  175]\n",
      "loss: 0.017433  [   84/  175]\n",
      "loss: 0.108243  [  164/  175]\n",
      "Training accuracy: 88.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.083192 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.327781  [    4/  175]\n",
      "loss: 0.166012  [   84/  175]\n",
      "loss: 0.242171  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.042208 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.015949  [    4/  175]\n",
      "loss: 0.232461  [   84/  175]\n",
      "loss: 0.015464  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.041526 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.190712  [    4/  175]\n",
      "loss: 0.225862  [   84/  175]\n",
      "loss: 0.014720  [  164/  175]\n",
      "Training accuracy: 88.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.049428 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.168081  [    4/  175]\n",
      "loss: 0.083818  [   84/  175]\n",
      "loss: 0.021243  [  164/  175]\n",
      "Training accuracy: 96.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.032654 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.011440  [    4/  175]\n",
      "loss: 0.021720  [   84/  175]\n",
      "loss: 0.050754  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.053810 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.013659  [    4/  175]\n",
      "loss: 1.129618  [   84/  175]\n",
      "loss: 0.098381  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.031536 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.018276  [    4/  175]\n",
      "loss: 0.698074  [   84/  175]\n",
      "loss: 0.016078  [  164/  175]\n",
      "Training accuracy: 85.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.047002 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.208301  [    4/  175]\n",
      "loss: 0.029794  [   84/  175]\n",
      "loss: 0.091248  [  164/  175]\n",
      "Training accuracy: 94.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.091503 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.082095  [    4/  175]\n",
      "loss: 0.059403  [   84/  175]\n",
      "loss: 0.012646  [  164/  175]\n",
      "Training accuracy: 93.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.032320 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.015411  [    4/  175]\n",
      "loss: 0.020426  [   84/  175]\n",
      "loss: 0.149540  [  164/  175]\n",
      "Training accuracy: 88.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.086717 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.068381  [    4/  175]\n",
      "loss: 0.013685  [   84/  175]\n",
      "loss: 0.174821  [  164/  175]\n",
      "Training accuracy: 87.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.026481 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.135977  [    4/  175]\n",
      "loss: 0.097793  [   84/  175]\n",
      "loss: 0.824714  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.028249 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.056421  [    4/  175]\n",
      "loss: 0.019613  [   84/  175]\n",
      "loss: 0.109931  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.040459 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.058487  [    4/  175]\n",
      "loss: 0.080430  [   84/  175]\n",
      "loss: 0.103353  [  164/  175]\n",
      "Training accuracy: 97.7%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.022900 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.085865  [    4/  175]\n",
      "loss: 0.070053  [   84/  175]\n",
      "loss: 0.071743  [  164/  175]\n",
      "Training accuracy: 92.4%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.021838 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.073233  [    4/  175]\n",
      "loss: 1.365200  [   84/  175]\n",
      "loss: 0.106439  [  164/  175]\n",
      "Training accuracy: 96.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.030609 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.024346  [    4/  175]\n",
      "loss: 0.063029  [   84/  175]\n",
      "loss: 0.067732  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.018047 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.861274  [    4/  175]\n",
      "loss: 0.033968  [   84/  175]\n",
      "loss: 0.099000  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.022406 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.012146  [    4/  175]\n",
      "loss: 0.121132  [   84/  175]\n",
      "loss: 0.007273  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.020927 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.020665  [    4/  175]\n",
      "loss: 0.012791  [   84/  175]\n",
      "loss: 0.009786  [  164/  175]\n",
      "Training accuracy: 95.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.019279 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 1.033606  [    4/  175]\n",
      "loss: 0.824799  [   84/  175]\n",
      "loss: 0.022157  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.023038 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.019871  [    4/  175]\n",
      "loss: 0.013923  [   84/  175]\n",
      "loss: 0.060652  [  164/  175]\n",
      "Training accuracy: 97.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.017460 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.076402  [    4/  175]\n",
      "loss: 0.009280  [   84/  175]\n",
      "loss: 0.053801  [  164/  175]\n",
      "Training accuracy: 95.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.021217 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.179011  [    4/  175]\n",
      "loss: 0.072644  [   84/  175]\n",
      "loss: 0.007857  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.033952 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.073379  [    4/  175]\n",
      "loss: 0.016457  [   84/  175]\n",
      "loss: 0.078724  [  164/  175]\n",
      "Training accuracy: 94.5%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.070120 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.051306  [    4/  175]\n",
      "loss: 0.095972  [   84/  175]\n",
      "loss: 0.024582  [  164/  175]\n",
      "Training accuracy: 94.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.013587 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.930165  [    4/  175]\n",
      "loss: 1.218090  [   84/  175]\n",
      "loss: 0.050833  [  164/  175]\n",
      "Training accuracy: 88.1%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.018702 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.089622  [    4/  175]\n",
      "loss: 0.006460  [   84/  175]\n",
      "loss: 0.084683  [  164/  175]\n",
      "Training accuracy: 96.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.016310 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.085454  [    4/  175]\n",
      "loss: 0.053118  [   84/  175]\n",
      "loss: 0.012811  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.020483 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.816702  [    4/  175]\n",
      "loss: 0.838031  [   84/  175]\n",
      "loss: 0.660339  [  164/  175]\n",
      "Training accuracy: 88.1%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.106995 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.059689  [    4/  175]\n",
      "loss: 0.077709  [   84/  175]\n",
      "loss: 0.089178  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.014484 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.011603  [    4/  175]\n",
      "loss: 0.055173  [   84/  175]\n",
      "loss: 0.008693  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.016017 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.015806  [    4/  175]\n",
      "loss: 0.096479  [   84/  175]\n",
      "loss: 0.067295  [  164/  175]\n",
      "Training accuracy: 96.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.019269 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.779056  [    4/  175]\n",
      "loss: 0.039626  [   84/  175]\n",
      "loss: 0.057699  [  164/  175]\n",
      "Training accuracy: 94.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.023870 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.047725  [    4/  175]\n",
      "loss: 0.915628  [   84/  175]\n",
      "loss: 0.078253  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.025008 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.061437  [    4/  175]\n",
      "loss: 0.040998  [   84/  175]\n",
      "loss: 0.051222  [  164/  175]\n",
      "Training accuracy: 93.9%\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.207723 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.029129  [    4/  175]\n",
      "loss: 0.008627  [   84/  175]\n",
      "loss: 0.005878  [  164/  175]\n",
      "Training accuracy: 95.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.019911 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.005889  [    4/  175]\n",
      "loss: 0.063592  [   84/  175]\n",
      "loss: 0.112667  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.035460 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.107852  [    4/  175]\n",
      "loss: 0.092342  [   84/  175]\n",
      "loss: 0.006933  [  164/  175]\n",
      "Training accuracy: 88.8%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.053900 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.015881  [    4/  175]\n",
      "loss: 0.017082  [   84/  175]\n",
      "loss: 0.048141  [  164/  175]\n",
      "Training accuracy: 90.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.012451 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.005223  [    4/  175]\n",
      "loss: 0.011419  [   84/  175]\n",
      "loss: 0.011022  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.016224 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.005634  [    4/  175]\n",
      "loss: 0.042392  [   84/  175]\n",
      "loss: 0.845034  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.038266 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.005610  [    4/  175]\n",
      "loss: 0.023453  [   84/  175]\n",
      "loss: 0.213660  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.052450 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.827503  [    4/  175]\n",
      "loss: 0.006520  [   84/  175]\n",
      "loss: 0.012911  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.019068 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.064974  [    4/  175]\n",
      "loss: 0.743205  [   84/  175]\n",
      "loss: 0.057729  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.024823 \n",
      "\n",
      "Done!\n",
      "Training model 'extra_conv'...\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "loss: 0.928337  [    4/  175]\n",
      "loss: 0.593992  [   84/  175]\n",
      "loss: 0.458008  [  164/  175]\n",
      "Training accuracy: 63.3%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 0.690197 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.506406  [    4/  175]\n",
      "loss: 0.757181  [   84/  175]\n",
      "loss: 0.975567  [  164/  175]\n",
      "Training accuracy: 62.7%\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 0.656266 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.473540  [    4/  175]\n",
      "loss: 0.726324  [   84/  175]\n",
      "loss: 0.636260  [  164/  175]\n",
      "Training accuracy: 63.1%\n",
      "Test Error: \n",
      " Accuracy: 67.4%, Avg loss: 0.637461 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.797861  [    4/  175]\n",
      "loss: 0.648468  [   84/  175]\n",
      "loss: 0.567144  [  164/  175]\n",
      "Training accuracy: 67.6%\n",
      "Test Error: \n",
      " Accuracy: 65.2%, Avg loss: 0.664057 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.430669  [    4/  175]\n",
      "loss: 0.647485  [   84/  175]\n",
      "loss: 0.698702  [  164/  175]\n",
      "Training accuracy: 62.3%\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 0.638066 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.990931  [    4/  175]\n",
      "loss: 0.570225  [   84/  175]\n",
      "loss: 0.527135  [  164/  175]\n",
      "Training accuracy: 72.7%\n",
      "Test Error: \n",
      " Accuracy: 62.9%, Avg loss: 0.687219 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.487748  [    4/  175]\n",
      "loss: 0.423866  [   84/  175]\n",
      "loss: 0.588432  [  164/  175]\n",
      "Training accuracy: 75.9%\n",
      "Test Error: \n",
      " Accuracy: 69.7%, Avg loss: 0.590946 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.696299  [    4/  175]\n",
      "loss: 0.767281  [   84/  175]\n",
      "loss: 0.949600  [  164/  175]\n",
      "Training accuracy: 70.3%\n",
      "Test Error: \n",
      " Accuracy: 75.8%, Avg loss: 0.559004 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.462257  [    4/  175]\n",
      "loss: 0.388558  [   84/  175]\n",
      "loss: 0.472634  [  164/  175]\n",
      "Training accuracy: 78.2%\n",
      "Test Error: \n",
      " Accuracy: 57.6%, Avg loss: 0.606350 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.346596  [    4/  175]\n",
      "loss: 0.795273  [   84/  175]\n",
      "loss: 0.548332  [  164/  175]\n",
      "Training accuracy: 78.4%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.560644 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.844749  [    4/  175]\n",
      "loss: 0.321903  [   84/  175]\n",
      "loss: 0.375927  [  164/  175]\n",
      "Training accuracy: 77.1%\n",
      "Test Error: \n",
      " Accuracy: 67.4%, Avg loss: 0.603669 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.529832  [    4/  175]\n",
      "loss: 0.315211  [   84/  175]\n",
      "loss: 0.312967  [  164/  175]\n",
      "Training accuracy: 82.8%\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.412435 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.181000  [    4/  175]\n",
      "loss: 0.549584  [   84/  175]\n",
      "loss: 0.256297  [  164/  175]\n",
      "Training accuracy: 85.0%\n",
      "Test Error: \n",
      " Accuracy: 68.9%, Avg loss: 0.481835 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.309065  [    4/  175]\n",
      "loss: 0.500114  [   84/  175]\n",
      "loss: 0.814991  [  164/  175]\n",
      "Training accuracy: 81.4%\n",
      "Test Error: \n",
      " Accuracy: 65.2%, Avg loss: 0.637719 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.592747  [    4/  175]\n",
      "loss: 0.174297  [   84/  175]\n",
      "loss: 0.249353  [  164/  175]\n",
      "Training accuracy: 80.3%\n",
      "Test Error: \n",
      " Accuracy: 72.7%, Avg loss: 0.436539 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.272937  [    4/  175]\n",
      "loss: 0.250971  [   84/  175]\n",
      "loss: 0.342655  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.218059 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.259201  [    4/  175]\n",
      "loss: 0.655954  [   84/  175]\n",
      "loss: 0.219154  [  164/  175]\n",
      "Training accuracy: 82.4%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.195225 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.276149  [    4/  175]\n",
      "loss: 0.169064  [   84/  175]\n",
      "loss: 0.206368  [  164/  175]\n",
      "Training accuracy: 87.1%\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.344237 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.272024  [    4/  175]\n",
      "loss: 0.224525  [   84/  175]\n",
      "loss: 0.099771  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.164028 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.292789  [    4/  175]\n",
      "loss: 0.084680  [   84/  175]\n",
      "loss: 0.685397  [  164/  175]\n",
      "Training accuracy: 88.4%\n",
      "Test Error: \n",
      " Accuracy: 78.0%, Avg loss: 0.368823 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.355731  [    4/  175]\n",
      "loss: 0.156499  [   84/  175]\n",
      "loss: 0.142867  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.129001 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.056322  [    4/  175]\n",
      "loss: 0.057744  [   84/  175]\n",
      "loss: 0.070887  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.102811 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.169700  [    4/  175]\n",
      "loss: 0.178653  [   84/  175]\n",
      "loss: 0.832637  [  164/  175]\n",
      "Training accuracy: 86.4%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.110665 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.171389  [    4/  175]\n",
      "loss: 0.196934  [   84/  175]\n",
      "loss: 0.291553  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.141089 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.100893  [    4/  175]\n",
      "loss: 0.303488  [   84/  175]\n",
      "loss: 0.065193  [  164/  175]\n",
      "Training accuracy: 91.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.172272 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.210394  [    4/  175]\n",
      "loss: 0.253054  [   84/  175]\n",
      "loss: 0.107841  [  164/  175]\n",
      "Training accuracy: 95.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.074251 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.223398  [    4/  175]\n",
      "loss: 0.781715  [   84/  175]\n",
      "loss: 0.044549  [  164/  175]\n",
      "Training accuracy: 88.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.070349 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.033620  [    4/  175]\n",
      "loss: 0.166795  [   84/  175]\n",
      "loss: 0.161293  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.080524 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.224834  [    4/  175]\n",
      "loss: 0.887529  [   84/  175]\n",
      "loss: 0.031640  [  164/  175]\n",
      "Training accuracy: 91.7%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.050640 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.897598  [    4/  175]\n",
      "loss: 0.061621  [   84/  175]\n",
      "loss: 0.125456  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.060091 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.030635  [    4/  175]\n",
      "loss: 0.177422  [   84/  175]\n",
      "loss: 0.035429  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.043340 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.863360  [    4/  175]\n",
      "loss: 0.041471  [   84/  175]\n",
      "loss: 0.137460  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.040428 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.022470  [    4/  175]\n",
      "loss: 0.026737  [   84/  175]\n",
      "loss: 0.027600  [  164/  175]\n",
      "Training accuracy: 96.4%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.039967 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.021033  [    4/  175]\n",
      "loss: 0.056650  [   84/  175]\n",
      "loss: 0.024619  [  164/  175]\n",
      "Training accuracy: 95.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.053486 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.123115  [    4/  175]\n",
      "loss: 0.195955  [   84/  175]\n",
      "loss: 0.307316  [  164/  175]\n",
      "Training accuracy: 88.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.053888 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.044117  [    4/  175]\n",
      "loss: 0.057923  [   84/  175]\n",
      "loss: 0.040251  [  164/  175]\n",
      "Training accuracy: 95.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.055523 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.757004  [    4/  175]\n",
      "loss: 0.111276  [   84/  175]\n",
      "loss: 0.076040  [  164/  175]\n",
      "Training accuracy: 93.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.087599 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.090353  [    4/  175]\n",
      "loss: 0.767153  [   84/  175]\n",
      "loss: 0.100544  [  164/  175]\n",
      "Training accuracy: 87.1%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.035471 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.149509  [    4/  175]\n",
      "loss: 0.072729  [   84/  175]\n",
      "loss: 0.127067  [  164/  175]\n",
      "Training accuracy: 88.8%\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.262856 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.760182  [    4/  175]\n",
      "loss: 0.944894  [   84/  175]\n",
      "loss: 0.084314  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.041146 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.018059  [    4/  175]\n",
      "loss: 0.017691  [   84/  175]\n",
      "loss: 0.079296  [  164/  175]\n",
      "Training accuracy: 95.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.041965 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.124346  [    4/  175]\n",
      "loss: 0.017075  [   84/  175]\n",
      "loss: 0.071542  [  164/  175]\n",
      "Training accuracy: 94.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.060992 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.070811  [    4/  175]\n",
      "loss: 0.033962  [   84/  175]\n",
      "loss: 0.021684  [  164/  175]\n",
      "Training accuracy: 97.7%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.030250 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.085728  [    4/  175]\n",
      "loss: 0.076746  [   84/  175]\n",
      "loss: 0.080757  [  164/  175]\n",
      "Training accuracy: 92.4%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.024585 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.026287  [    4/  175]\n",
      "loss: 0.099875  [   84/  175]\n",
      "loss: 0.096705  [  164/  175]\n",
      "Training accuracy: 97.7%\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.442938 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.048529  [    4/  175]\n",
      "loss: 0.014262  [   84/  175]\n",
      "loss: 0.016347  [  164/  175]\n",
      "Training accuracy: 97.7%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.027504 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.010368  [    4/  175]\n",
      "loss: 0.820284  [   84/  175]\n",
      "loss: 0.862411  [  164/  175]\n",
      "Training accuracy: 90.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.026014 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 1.095377  [    4/  175]\n",
      "loss: 0.012252  [   84/  175]\n",
      "loss: 0.887545  [  164/  175]\n",
      "Training accuracy: 83.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.189417 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.741680  [    4/  175]\n",
      "loss: 0.931268  [   84/  175]\n",
      "loss: 0.039406  [  164/  175]\n",
      "Training accuracy: 89.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.042084 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.078431  [    4/  175]\n",
      "loss: 0.013366  [   84/  175]\n",
      "loss: 0.063632  [  164/  175]\n",
      "Training accuracy: 89.6%\n",
      "Test Error: \n",
      " Accuracy: 56.8%, Avg loss: 1.008770 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.111407  [    4/  175]\n",
      "loss: 0.015117  [   84/  175]\n",
      "loss: 0.162393  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.041208 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.045172  [    4/  175]\n",
      "loss: 0.086869  [   84/  175]\n",
      "loss: 0.110806  [  164/  175]\n",
      "Training accuracy: 95.5%\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.218154 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.028781  [    4/  175]\n",
      "loss: 0.011367  [   84/  175]\n",
      "loss: 0.088488  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.039826 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.021608  [    4/  175]\n",
      "loss: 0.011996  [   84/  175]\n",
      "loss: 0.772128  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.020246 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.048736  [    4/  175]\n",
      "loss: 0.008355  [   84/  175]\n",
      "loss: 0.935615  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.039168 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.101642  [    4/  175]\n",
      "loss: 0.010565  [   84/  175]\n",
      "loss: 0.069122  [  164/  175]\n",
      "Training accuracy: 92.4%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.030025 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.010402  [    4/  175]\n",
      "loss: 0.084385  [   84/  175]\n",
      "loss: 0.076905  [  164/  175]\n",
      "Training accuracy: 98.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.020693 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.074569  [    4/  175]\n",
      "loss: 0.725359  [   84/  175]\n",
      "loss: 0.067438  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.020626 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.007915  [    4/  175]\n",
      "loss: 0.008095  [   84/  175]\n",
      "loss: 0.112036  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.026592 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 1.656005  [    4/  175]\n",
      "loss: 0.050650  [   84/  175]\n",
      "loss: 0.006955  [  164/  175]\n",
      "Training accuracy: 95.8%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.074100 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.006500  [    4/  175]\n",
      "loss: 0.012794  [   84/  175]\n",
      "loss: 0.224472  [  164/  175]\n",
      "Training accuracy: 95.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.023991 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.011594  [    4/  175]\n",
      "loss: 1.104569  [   84/  175]\n",
      "loss: 0.183014  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.019201 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.008266  [    4/  175]\n",
      "loss: 0.007852  [   84/  175]\n",
      "loss: 0.178796  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.036165 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.063165  [    4/  175]\n",
      "loss: 0.013705  [   84/  175]\n",
      "loss: 0.315409  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.044108 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.086668  [    4/  175]\n",
      "loss: 0.014598  [   84/  175]\n",
      "loss: 0.076027  [  164/  175]\n",
      "Training accuracy: 96.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.017383 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.010894  [    4/  175]\n",
      "loss: 0.045217  [   84/  175]\n",
      "loss: 0.049295  [  164/  175]\n",
      "Training accuracy: 96.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.016736 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.007304  [    4/  175]\n",
      "loss: 0.052253  [   84/  175]\n",
      "loss: 0.135190  [  164/  175]\n",
      "Training accuracy: 89.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.059825 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.009013  [    4/  175]\n",
      "loss: 0.030245  [   84/  175]\n",
      "loss: 0.011290  [  164/  175]\n",
      "Training accuracy: 98.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.016644 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.095747  [    4/  175]\n",
      "loss: 0.007871  [   84/  175]\n",
      "loss: 0.034397  [  164/  175]\n",
      "Training accuracy: 92.4%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.133804 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.169782  [    4/  175]\n",
      "loss: 0.014630  [   84/  175]\n",
      "loss: 0.010660  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.014619 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.049860  [    4/  175]\n",
      "loss: 0.063059  [   84/  175]\n",
      "loss: 0.075698  [  164/  175]\n",
      "Training accuracy: 96.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.016523 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.012940  [    4/  175]\n",
      "loss: 0.007066  [   84/  175]\n",
      "loss: 0.072063  [  164/  175]\n",
      "Training accuracy: 93.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.032130 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.052434  [    4/  175]\n",
      "loss: 0.167994  [   84/  175]\n",
      "loss: 0.073712  [  164/  175]\n",
      "Training accuracy: 94.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.030308 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.039702  [    4/  175]\n",
      "loss: 0.011047  [   84/  175]\n",
      "loss: 0.053078  [  164/  175]\n",
      "Training accuracy: 89.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.099160 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.053118  [    4/  175]\n",
      "loss: 0.549332  [   84/  175]\n",
      "loss: 0.097909  [  164/  175]\n",
      "Training accuracy: 96.0%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.065014 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.005956  [    4/  175]\n",
      "loss: 0.058399  [   84/  175]\n",
      "loss: 0.011272  [  164/  175]\n",
      "Training accuracy: 96.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.024471 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.006454  [    4/  175]\n",
      "loss: 0.092579  [   84/  175]\n",
      "loss: 0.182950  [  164/  175]\n",
      "Training accuracy: 94.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.017723 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.005495  [    4/  175]\n",
      "loss: 0.743545  [   84/  175]\n",
      "loss: 0.010272  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 61.4%, Avg loss: 0.566213 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.098210  [    4/  175]\n",
      "loss: 0.005856  [   84/  175]\n",
      "loss: 0.044228  [  164/  175]\n",
      "Training accuracy: 95.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008648 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.062898  [    4/  175]\n",
      "loss: 0.045332  [   84/  175]\n",
      "loss: 0.007861  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.011969 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.062413  [    4/  175]\n",
      "loss: 0.070497  [   84/  175]\n",
      "loss: 0.044099  [  164/  175]\n",
      "Training accuracy: 96.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.010231 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.034162  [    4/  175]\n",
      "loss: 0.046285  [   84/  175]\n",
      "loss: 0.051359  [  164/  175]\n",
      "Training accuracy: 90.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.021455 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.062928  [    4/  175]\n",
      "loss: 0.006751  [   84/  175]\n",
      "loss: 0.039600  [  164/  175]\n",
      "Training accuracy: 98.7%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.025044 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.005578  [    4/  175]\n",
      "loss: 0.702640  [   84/  175]\n",
      "loss: 0.078349  [  164/  175]\n",
      "Training accuracy: 92.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.023026 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.027129  [    4/  175]\n",
      "loss: 0.083889  [   84/  175]\n",
      "loss: 1.106569  [  164/  175]\n",
      "Training accuracy: 94.1%\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.246167 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.036916  [    4/  175]\n",
      "loss: 0.040697  [   84/  175]\n",
      "loss: 0.378535  [  164/  175]\n",
      "Training accuracy: 88.6%\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 2.889629 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.015998  [    4/  175]\n",
      "loss: 0.091759  [   84/  175]\n",
      "loss: 0.131493  [  164/  175]\n",
      "Training accuracy: 94.7%\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 0.721062 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 1.067081  [    4/  175]\n",
      "loss: 0.036202  [   84/  175]\n",
      "loss: 0.004616  [  164/  175]\n",
      "Training accuracy: 90.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.138878 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.880584  [    4/  175]\n",
      "loss: 0.063962  [   84/  175]\n",
      "loss: 0.017059  [  164/  175]\n",
      "Training accuracy: 88.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.031494 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.060070  [    4/  175]\n",
      "loss: 0.047073  [   84/  175]\n",
      "loss: 0.147025  [  164/  175]\n",
      "Training accuracy: 97.7%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.020281 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.004411  [    4/  175]\n",
      "loss: 1.089230  [   84/  175]\n",
      "loss: 0.716131  [  164/  175]\n",
      "Training accuracy: 89.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.098289 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.778663  [    4/  175]\n",
      "loss: 0.014278  [   84/  175]\n",
      "loss: 0.026855  [  164/  175]\n",
      "Training accuracy: 95.5%\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.182513 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.006777  [    4/  175]\n",
      "loss: 0.052063  [   84/  175]\n",
      "loss: 0.007232  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.022822 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.006974  [    4/  175]\n",
      "loss: 0.033450  [   84/  175]\n",
      "loss: 0.063376  [  164/  175]\n",
      "Training accuracy: 96.4%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006770 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.006130  [    4/  175]\n",
      "loss: 0.006129  [   84/  175]\n",
      "loss: 0.878182  [  164/  175]\n",
      "Training accuracy: 96.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.006897 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.047467  [    4/  175]\n",
      "loss: 0.002331  [   84/  175]\n",
      "loss: 0.006609  [  164/  175]\n",
      "Training accuracy: 95.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.018849 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.021937  [    4/  175]\n",
      "loss: 0.004925  [   84/  175]\n",
      "loss: 0.016485  [  164/  175]\n",
      "Training accuracy: 89.2%\n",
      "Test Error: \n",
      " Accuracy: 95.5%, Avg loss: 0.138457 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.097236  [    4/  175]\n",
      "loss: 0.006500  [   84/  175]\n",
      "loss: 0.054457  [  164/  175]\n",
      "Training accuracy: 98.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.010772 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.006573  [    4/  175]\n",
      "loss: 0.031823  [   84/  175]\n",
      "loss: 0.913467  [  164/  175]\n",
      "Training accuracy: 88.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.023728 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.009974  [    4/  175]\n",
      "loss: 0.029551  [   84/  175]\n",
      "loss: 0.054856  [  164/  175]\n",
      "Training accuracy: 89.4%\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.413202 \n",
      "\n",
      "Done!\n",
      "Training model 'extra_wide_conv'...\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "loss: 0.659968  [    4/  175]\n",
      "loss: 0.634834  [   84/  175]\n",
      "loss: 0.726647  [  164/  175]\n",
      "Training accuracy: 63.4%\n",
      "Test Error: \n",
      " Accuracy: 57.6%, Avg loss: 0.687402 \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.584679  [    4/  175]\n",
      "loss: 0.980936  [   84/  175]\n",
      "loss: 0.787291  [  164/  175]\n",
      "Training accuracy: 70.6%\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 0.734082 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.578008  [    4/  175]\n",
      "loss: 0.500234  [   84/  175]\n",
      "loss: 0.349694  [  164/  175]\n",
      "Training accuracy: 73.5%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.555070 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.690322  [    4/  175]\n",
      "loss: 0.801137  [   84/  175]\n",
      "loss: 0.497880  [  164/  175]\n",
      "Training accuracy: 75.6%\n",
      "Test Error: \n",
      " Accuracy: 76.5%, Avg loss: 0.520428 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.466451  [    4/  175]\n",
      "loss: 0.381156  [   84/  175]\n",
      "loss: 0.757979  [  164/  175]\n",
      "Training accuracy: 75.0%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.751245 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.579205  [    4/  175]\n",
      "loss: 0.681773  [   84/  175]\n",
      "loss: 0.381309  [  164/  175]\n",
      "Training accuracy: 74.8%\n",
      "Test Error: \n",
      " Accuracy: 62.1%, Avg loss: 0.701882 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.348341  [    4/  175]\n",
      "loss: 0.323000  [   84/  175]\n",
      "loss: 0.376819  [  164/  175]\n",
      "Training accuracy: 87.9%\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 2.823125 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.342460  [    4/  175]\n",
      "loss: 0.884310  [   84/  175]\n",
      "loss: 0.407006  [  164/  175]\n",
      "Training accuracy: 83.5%\n",
      "Test Error: \n",
      " Accuracy: 49.2%, Avg loss: 0.825643 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.395369  [    4/  175]\n",
      "loss: 0.826770  [   84/  175]\n",
      "loss: 0.490957  [  164/  175]\n",
      "Training accuracy: 88.4%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.271691 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.269783  [    4/  175]\n",
      "loss: 0.531968  [   84/  175]\n",
      "loss: 0.161826  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 78.8%, Avg loss: 0.382158 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.200267  [    4/  175]\n",
      "loss: 0.335245  [   84/  175]\n",
      "loss: 0.148039  [  164/  175]\n",
      "Training accuracy: 87.1%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 0.861620 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.218184  [    4/  175]\n",
      "loss: 0.152537  [   84/  175]\n",
      "loss: 0.280097  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.292436 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.237244  [    4/  175]\n",
      "loss: 0.090454  [   84/  175]\n",
      "loss: 0.215812  [  164/  175]\n",
      "Training accuracy: 83.0%\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 2.423360 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.752150  [    4/  175]\n",
      "loss: 0.226667  [   84/  175]\n",
      "loss: 0.115288  [  164/  175]\n",
      "Training accuracy: 86.6%\n",
      "Test Error: \n",
      " Accuracy: 59.1%, Avg loss: 0.457494 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.167547  [    4/  175]\n",
      "loss: 0.282997  [   84/  175]\n",
      "loss: 0.270444  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.143657 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.229142  [    4/  175]\n",
      "loss: 0.106534  [   84/  175]\n",
      "loss: 0.305028  [  164/  175]\n",
      "Training accuracy: 87.9%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 4.065805 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.163894  [    4/  175]\n",
      "loss: 0.097960  [   84/  175]\n",
      "loss: 0.212182  [  164/  175]\n",
      "Training accuracy: 82.6%\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.247993 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.088939  [    4/  175]\n",
      "loss: 0.392331  [   84/  175]\n",
      "loss: 0.075444  [  164/  175]\n",
      "Training accuracy: 94.9%\n",
      "Test Error: \n",
      " Accuracy: 55.3%, Avg loss: 0.820599 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.193295  [    4/  175]\n",
      "loss: 0.092027  [   84/  175]\n",
      "loss: 0.070762  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.137373 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.157714  [    4/  175]\n",
      "loss: 0.078240  [   84/  175]\n",
      "loss: 0.101504  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.285524 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.140905  [    4/  175]\n",
      "loss: 0.435919  [   84/  175]\n",
      "loss: 0.250097  [  164/  175]\n",
      "Training accuracy: 89.2%\n",
      "Test Error: \n",
      " Accuracy: 57.6%, Avg loss: 0.521171 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.126712  [    4/  175]\n",
      "loss: 0.945022  [   84/  175]\n",
      "loss: 0.704018  [  164/  175]\n",
      "Training accuracy: 86.9%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 0.777388 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.165309  [    4/  175]\n",
      "loss: 0.179748  [   84/  175]\n",
      "loss: 0.193033  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.116783 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.045386  [    4/  175]\n",
      "loss: 0.316082  [   84/  175]\n",
      "loss: 0.119101  [  164/  175]\n",
      "Training accuracy: 90.7%\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.208633 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.055689  [    4/  175]\n",
      "loss: 0.768371  [   84/  175]\n",
      "loss: 0.053094  [  164/  175]\n",
      "Training accuracy: 85.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.093001 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.079866  [    4/  175]\n",
      "loss: 0.169991  [   84/  175]\n",
      "loss: 0.119306  [  164/  175]\n",
      "Training accuracy: 85.8%\n",
      "Test Error: \n",
      " Accuracy: 53.0%, Avg loss: 1.956304 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.110360  [    4/  175]\n",
      "loss: 0.189807  [   84/  175]\n",
      "loss: 0.064294  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 45.5%, Avg loss: 1.516590 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.953997  [    4/  175]\n",
      "loss: 0.174982  [   84/  175]\n",
      "loss: 0.177942  [  164/  175]\n",
      "Training accuracy: 88.3%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.142653 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.110731  [    4/  175]\n",
      "loss: 0.040684  [   84/  175]\n",
      "loss: 0.206494  [  164/  175]\n",
      "Training accuracy: 89.6%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.182707 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.126565  [    4/  175]\n",
      "loss: 0.102832  [   84/  175]\n",
      "loss: 0.252957  [  164/  175]\n",
      "Training accuracy: 91.9%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 1.246485 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.036499  [    4/  175]\n",
      "loss: 0.289960  [   84/  175]\n",
      "loss: 0.095094  [  164/  175]\n",
      "Training accuracy: 88.8%\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.260314 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.034641  [    4/  175]\n",
      "loss: 0.123687  [   84/  175]\n",
      "loss: 0.232347  [  164/  175]\n",
      "Training accuracy: 89.6%\n",
      "Test Error: \n",
      " Accuracy: 90.9%, Avg loss: 0.260533 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.058196  [    4/  175]\n",
      "loss: 0.109460  [   84/  175]\n",
      "loss: 0.068677  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.097447 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.121527  [    4/  175]\n",
      "loss: 0.109177  [   84/  175]\n",
      "loss: 0.221014  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 84.1%, Avg loss: 0.247531 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.130698  [    4/  175]\n",
      "loss: 0.257086  [   84/  175]\n",
      "loss: 0.931776  [  164/  175]\n",
      "Training accuracy: 93.2%\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.191744 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 1.030229  [    4/  175]\n",
      "loss: 0.037209  [   84/  175]\n",
      "loss: 0.055654  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.057225 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.097713  [    4/  175]\n",
      "loss: 1.530389  [   84/  175]\n",
      "loss: 0.293358  [  164/  175]\n",
      "Training accuracy: 92.4%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.107524 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.965781  [    4/  175]\n",
      "loss: 0.046253  [   84/  175]\n",
      "loss: 0.096702  [  164/  175]\n",
      "Training accuracy: 85.2%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.076458 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.097461  [    4/  175]\n",
      "loss: 0.670602  [   84/  175]\n",
      "loss: 0.900770  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.101185 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.031555  [    4/  175]\n",
      "loss: 0.025847  [   84/  175]\n",
      "loss: 0.124725  [  164/  175]\n",
      "Training accuracy: 97.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.060005 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.018547  [    4/  175]\n",
      "loss: 0.139705  [   84/  175]\n",
      "loss: 0.019865  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.042171 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.045794  [    4/  175]\n",
      "loss: 0.019593  [   84/  175]\n",
      "loss: 0.020162  [  164/  175]\n",
      "Training accuracy: 95.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.099099 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.787742  [    4/  175]\n",
      "loss: 0.021906  [   84/  175]\n",
      "loss: 0.062560  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.073090 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.015965  [    4/  175]\n",
      "loss: 0.815613  [   84/  175]\n",
      "loss: 0.130967  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.061360 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.777981  [    4/  175]\n",
      "loss: 0.186901  [   84/  175]\n",
      "loss: 0.014748  [  164/  175]\n",
      "Training accuracy: 94.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.099175 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 1.352178  [    4/  175]\n",
      "loss: 0.171567  [   84/  175]\n",
      "loss: 0.146494  [  164/  175]\n",
      "Training accuracy: 88.1%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.049466 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.019760  [    4/  175]\n",
      "loss: 0.864662  [   84/  175]\n",
      "loss: 0.076577  [  164/  175]\n",
      "Training accuracy: 94.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.036621 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.031109  [    4/  175]\n",
      "loss: 0.224577  [   84/  175]\n",
      "loss: 0.965688  [  164/  175]\n",
      "Training accuracy: 88.1%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.157192 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.139951  [    4/  175]\n",
      "loss: 0.068340  [   84/  175]\n",
      "loss: 0.097870  [  164/  175]\n",
      "Training accuracy: 94.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.109026 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.020253  [    4/  175]\n",
      "loss: 0.984876  [   84/  175]\n",
      "loss: 0.021051  [  164/  175]\n",
      "Training accuracy: 93.4%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.081107 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.050357  [    4/  175]\n",
      "loss: 0.055943  [   84/  175]\n",
      "loss: 0.049327  [  164/  175]\n",
      "Training accuracy: 91.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.021542 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.133171  [    4/  175]\n",
      "loss: 0.025527  [   84/  175]\n",
      "loss: 0.049367  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.061277 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.114465  [    4/  175]\n",
      "loss: 0.011371  [   84/  175]\n",
      "loss: 0.862048  [  164/  175]\n",
      "Training accuracy: 86.7%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.027581 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.072163  [    4/  175]\n",
      "loss: 0.023487  [   84/  175]\n",
      "loss: 0.940054  [  164/  175]\n",
      "Training accuracy: 87.7%\n",
      "Test Error: \n",
      " Accuracy: 94.7%, Avg loss: 0.148574 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.114194  [    4/  175]\n",
      "loss: 0.020276  [   84/  175]\n",
      "loss: 0.104736  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.051692 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.015081  [    4/  175]\n",
      "loss: 0.022330  [   84/  175]\n",
      "loss: 0.744089  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.256915 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.012173  [    4/  175]\n",
      "loss: 0.029090  [   84/  175]\n",
      "loss: 0.025404  [  164/  175]\n",
      "Training accuracy: 90.9%\n",
      "Test Error: \n",
      " Accuracy: 77.3%, Avg loss: 0.350343 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.125736  [    4/  175]\n",
      "loss: 1.039238  [   84/  175]\n",
      "loss: 0.091874  [  164/  175]\n",
      "Training accuracy: 93.0%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.033365 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.037802  [    4/  175]\n",
      "loss: 0.111718  [   84/  175]\n",
      "loss: 0.081145  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.033804 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.065498  [    4/  175]\n",
      "loss: 0.064036  [   84/  175]\n",
      "loss: 0.028138  [  164/  175]\n",
      "Training accuracy: 91.7%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.108836 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.063211  [    4/  175]\n",
      "loss: 0.087701  [   84/  175]\n",
      "loss: 0.068820  [  164/  175]\n",
      "Training accuracy: 94.9%\n",
      "Test Error: \n",
      " Accuracy: 97.0%, Avg loss: 0.063593 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.012149  [    4/  175]\n",
      "loss: 1.646088  [   84/  175]\n",
      "loss: 0.115054  [  164/  175]\n",
      "Training accuracy: 86.4%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.123957 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.121840  [    4/  175]\n",
      "loss: 0.065204  [   84/  175]\n",
      "loss: 0.062085  [  164/  175]\n",
      "Training accuracy: 93.4%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.025683 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.011797  [    4/  175]\n",
      "loss: 0.060470  [   84/  175]\n",
      "loss: 0.013505  [  164/  175]\n",
      "Training accuracy: 93.4%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.014562 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.042146  [    4/  175]\n",
      "loss: 0.064211  [   84/  175]\n",
      "loss: 0.048591  [  164/  175]\n",
      "Training accuracy: 97.2%\n",
      "Test Error: \n",
      " Accuracy: 46.2%, Avg loss: 0.942061 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.020288  [    4/  175]\n",
      "loss: 0.033110  [   84/  175]\n",
      "loss: 0.090800  [  164/  175]\n",
      "Training accuracy: 90.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.046801 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.102123  [    4/  175]\n",
      "loss: 0.054578  [   84/  175]\n",
      "loss: 0.049344  [  164/  175]\n",
      "Training accuracy: 90.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.015114 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.007858  [    4/  175]\n",
      "loss: 0.094602  [   84/  175]\n",
      "loss: 0.010038  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.018599 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.006582  [    4/  175]\n",
      "loss: 0.044100  [   84/  175]\n",
      "loss: 0.095495  [  164/  175]\n",
      "Training accuracy: 89.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.014684 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.015407  [    4/  175]\n",
      "loss: 0.314858  [   84/  175]\n",
      "loss: 0.272414  [  164/  175]\n",
      "Training accuracy: 92.0%\n",
      "Test Error: \n",
      " Accuracy: 53.8%, Avg loss: 2.841170 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.024516  [    4/  175]\n",
      "loss: 0.055013  [   84/  175]\n",
      "loss: 0.010961  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.032438 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.018148  [    4/  175]\n",
      "loss: 0.009780  [   84/  175]\n",
      "loss: 0.109356  [  164/  175]\n",
      "Training accuracy: 97.0%\n",
      "Test Error: \n",
      " Accuracy: 88.6%, Avg loss: 0.275564 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.066186  [    4/  175]\n",
      "loss: 0.490213  [   84/  175]\n",
      "loss: 0.128089  [  164/  175]\n",
      "Training accuracy: 91.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.079151 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.085365  [    4/  175]\n",
      "loss: 0.078543  [   84/  175]\n",
      "loss: 0.012323  [  164/  175]\n",
      "Training accuracy: 94.5%\n",
      "Test Error: \n",
      " Accuracy: 64.4%, Avg loss: 0.506546 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.105817  [    4/  175]\n",
      "loss: 0.081138  [   84/  175]\n",
      "loss: 0.012717  [  164/  175]\n",
      "Training accuracy: 91.1%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.131089 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.077065  [    4/  175]\n",
      "loss: 0.005078  [   84/  175]\n",
      "loss: 0.134417  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.215847 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 1.214677  [    4/  175]\n",
      "loss: 0.090541  [   84/  175]\n",
      "loss: 0.064149  [  164/  175]\n",
      "Training accuracy: 94.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.028014 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.049083  [    4/  175]\n",
      "loss: 0.006510  [   84/  175]\n",
      "loss: 0.081055  [  164/  175]\n",
      "Training accuracy: 97.2%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.012957 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.101703  [    4/  175]\n",
      "loss: 0.064924  [   84/  175]\n",
      "loss: 0.014286  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 68.2%, Avg loss: 0.607981 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 1.291122  [    4/  175]\n",
      "loss: 0.798887  [   84/  175]\n",
      "loss: 0.058284  [  164/  175]\n",
      "Training accuracy: 87.7%\n",
      "Test Error: \n",
      " Accuracy: 93.2%, Avg loss: 0.258224 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.109913  [    4/  175]\n",
      "loss: 0.076621  [   84/  175]\n",
      "loss: 0.062921  [  164/  175]\n",
      "Training accuracy: 87.9%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.952942 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.074286  [    4/  175]\n",
      "loss: 0.085120  [   84/  175]\n",
      "loss: 0.005150  [  164/  175]\n",
      "Training accuracy: 95.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.043905 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.004840  [    4/  175]\n",
      "loss: 0.037328  [   84/  175]\n",
      "loss: 0.043453  [  164/  175]\n",
      "Training accuracy: 94.9%\n",
      "Test Error: \n",
      " Accuracy: 97.7%, Avg loss: 0.129253 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.005540  [    4/  175]\n",
      "loss: 0.053644  [   84/  175]\n",
      "loss: 0.006499  [  164/  175]\n",
      "Training accuracy: 95.5%\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.328459 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.097108  [    4/  175]\n",
      "loss: 0.010673  [   84/  175]\n",
      "loss: 0.005961  [  164/  175]\n",
      "Training accuracy: 92.2%\n",
      "Test Error: \n",
      " Accuracy: 81.1%, Avg loss: 0.252085 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.041424  [    4/  175]\n",
      "loss: 0.006818  [   84/  175]\n",
      "loss: 0.006136  [  164/  175]\n",
      "Training accuracy: 94.9%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.036626 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.061207  [    4/  175]\n",
      "loss: 0.005886  [   84/  175]\n",
      "loss: 0.094605  [  164/  175]\n",
      "Training accuracy: 93.9%\n",
      "Test Error: \n",
      " Accuracy: 47.0%, Avg loss: 1.189707 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.006397  [    4/  175]\n",
      "loss: 0.056130  [   84/  175]\n",
      "loss: 0.064883  [  164/  175]\n",
      "Training accuracy: 87.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.028085 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.020340  [    4/  175]\n",
      "loss: 0.855973  [   84/  175]\n",
      "loss: 0.208317  [  164/  175]\n",
      "Training accuracy: 94.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.009105 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.011153  [    4/  175]\n",
      "loss: 0.012066  [   84/  175]\n",
      "loss: 0.704818  [  164/  175]\n",
      "Training accuracy: 92.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.032085 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.047634  [    4/  175]\n",
      "loss: 0.077876  [   84/  175]\n",
      "loss: 0.046776  [  164/  175]\n",
      "Training accuracy: 98.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.007669 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.043467  [    4/  175]\n",
      "loss: 0.737860  [   84/  175]\n",
      "loss: 0.797390  [  164/  175]\n",
      "Training accuracy: 90.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.027819 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.014947  [    4/  175]\n",
      "loss: 0.010250  [   84/  175]\n",
      "loss: 0.031692  [  164/  175]\n",
      "Training accuracy: 93.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.016252 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.835919  [    4/  175]\n",
      "loss: 0.008339  [   84/  175]\n",
      "loss: 0.005857  [  164/  175]\n",
      "Training accuracy: 94.1%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.009394 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.035388  [    4/  175]\n",
      "loss: 0.060427  [   84/  175]\n",
      "loss: 0.003802  [  164/  175]\n",
      "Training accuracy: 95.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008508 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.041358  [    4/  175]\n",
      "loss: 0.050337  [   84/  175]\n",
      "loss: 0.036782  [  164/  175]\n",
      "Training accuracy: 89.8%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008767 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.804608  [    4/  175]\n",
      "loss: 0.044564  [   84/  175]\n",
      "loss: 0.040071  [  164/  175]\n",
      "Training accuracy: 95.3%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.012550 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.818885  [    4/  175]\n",
      "loss: 0.051625  [   84/  175]\n",
      "loss: 0.064597  [  164/  175]\n",
      "Training accuracy: 94.5%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.012485 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.050716  [    4/  175]\n",
      "loss: 0.004164  [   84/  175]\n",
      "loss: 0.038995  [  164/  175]\n",
      "Training accuracy: 94.9%\n",
      "Test Error: \n",
      " Accuracy: 79.5%, Avg loss: 0.371807 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.003243  [    4/  175]\n",
      "loss: 0.004817  [   84/  175]\n",
      "loss: 0.002993  [  164/  175]\n",
      "Training accuracy: 96.6%\n",
      "Test Error: \n",
      " Accuracy: 100.0%, Avg loss: 0.008917 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-2\n",
    "batch_size = 4\n",
    "epochs = 100\n",
    "\n",
    "models = {\n",
    "    \"simple_rnn\": ModelWithSimpleRnn().to(device),\n",
    "    \"wider\": SimpleRnnWithWiderRnn().to(device),\n",
    "    \"linear_before_rnn\": SimpleRnnWithLinearBeforeRnn().to(device),\n",
    "    \"extra_conv\": SimpleRnnWithExtraConv().to(device),\n",
    "    \"extra_wide_conv\": SimpleRnnWithExtraWideConv().to(device),\n",
    "}\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Model '{name}' has {count_parameters(model)} parameters.\")\n",
    "\n",
    "log_dir = os.path.join(\"runs\", \"experiment_005\")\n",
    "shutil.rmtree(log_dir, ignore_errors=True)\n",
    "\n",
    "for name, model in models.items():\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    print(f\"Training model '{name}'...\")\n",
    "    log_subdir = os.path.join(log_dir, name + \"_\" + datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"))\n",
    "    tb = SummaryWriter(log_subdir)\n",
    "\n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t}\\n-------------------------------\")\n",
    "        train_metrics = train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "        test_metrics = test_loop(test_dataloader, model, loss_fn)\n",
    "        tb.add_scalar(\"Loss/train\", train_metrics[\"loss\"], t)\n",
    "        tb.add_scalar(\"Accuracy/train\", train_metrics[\"acc\"], t)\n",
    "        tb.add_scalar(\"Loss/test\", test_metrics[\"loss\"], t)\n",
    "        tb.add_scalar(\"Accuracy/test\", test_metrics[\"acc\"], t)\n",
    "        for name, weight in model.named_parameters():\n",
    "            tb.add_histogram(f\"Weights/{name}\", weight, t)\n",
    "            tb.add_histogram(f\"Gradients/{name}\", weight.grad, t)\n",
    "\n",
    "    tb.close()\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no clear winner here; the models all perform about the same."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "We have tried a range of approaches to get past the plateau and get to 100% accuracy. Most approaches did not seem to help, but we did find that a simple RNN trains faster than a GRU for this task and performs just as well, so we will adapt the main block landing model architecture accordingly.\n",
    "\n",
    "It's interesting to note that all the misclassified examples examined in this experiment were false positives (i.e. block was predicted to land but it didn't). False negatives are more impactful in our case, so the block landing model might already be in a state where we can integrate it into the Tetris emulator as a pre-trained component. It would also be interesting to see the precision-recall curve for the block landing model to see how well it can separate the two classes.\n",
    "\n",
    "Another thing we can try to improve the predictions of the block landing model is to give it sequences of length 3 instead of length 2 as input. Having more timesteps might give the model more useful information with which to predict the block landing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
