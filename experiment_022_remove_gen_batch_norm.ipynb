{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 022\n",
    "\n",
    "In this experiment, we will try removing some or all batch normalization from the generator and see if this improves the performance. The reason for doing this is it worked for the discriminator before. We'll continue using a learning rate of 1e-4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecordingDataset(Dataset):\n",
    "    def __init__(self, path: str):\n",
    "        self.path = path\n",
    "        if not os.path.exists(path):\n",
    "            raise FileNotFoundError()\n",
    "        with os.scandir(self.path) as it:\n",
    "            entry: os.DirEntry = next(iter(it))\n",
    "            _, self.ext = os.path.splitext(entry.name)\n",
    "            self.highest_index = max((int(Path(file.path).stem) for file in it), default=-1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.highest_index + 1\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file = os.path.join(self.path, f\"{idx}{self.ext}\")\n",
    "        if not os.path.exists(file):\n",
    "            raise IndexError()\n",
    "        boards = np.load(file)\n",
    "\n",
    "        def transform(board):\n",
    "            board = torch.tensor(board, dtype=torch.long)\n",
    "            board = F.one_hot(board, 2) # One-hot encode the cell types\n",
    "            board = board.type(torch.float) # Convert to floating-point\n",
    "            board = board.permute((2, 0, 1)) # Move channels/classes to dimension 0\n",
    "            return board\n",
    "\n",
    "        x = transform(boards[-2]) # Ignore all boards except the last two\n",
    "        y = transform(boards[-1])\n",
    "        return x, y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 2, 22, 10]) torch.float32\n",
      "torch.Size([4, 2, 22, 10]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "train_dataset = RecordingDataset(os.path.join(\"data\", \"tetris_emulator\", \"train\"))\n",
    "test_dataset = RecordingDataset(os.path.join(\"data\", \"tetris_emulator\", \"test\"))\n",
    "batch_size = 4\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "x, y = next(iter(train_dataloader))\n",
    "print(x.shape, x.dtype)\n",
    "print(y.shape, y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TetrisModel(nn.Module):\n",
    "    \"\"\"Predicts the next state of the cells.\n",
    "\n",
    "    Inputs:\n",
    "        x: Tensor of float32 of shape (batch_size, channels, height, width). channels = 2 is the one-hot encoding of cell types, with\n",
    "           0 for empty cells and 1 for filled cells. height = 22 and width = 10 are the dimensions of the game board. The entries\n",
    "           should be 0 for empty cells and 1 for filled cells.\n",
    "        z: Tensor of float32 of shape (batch_size, 4). The entries should be random numbers sampled from a uniform distribution.\n",
    "    \n",
    "    Returns: Tensor of float32 of shape (batch_size, height, width), logits for the new cells. Probabilities close to 0 (negative logits)\n",
    "             correspond to empty cells, and probabilities close to 1 (positive logits) correspond to filled cells.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.loc = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.glob = nn.Sequential(\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(160, 10)\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Conv2d(26, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 2, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, z):\n",
    "        batch_size, channels, height, width = x.shape\n",
    "        \n",
    "        z = z[:, :, None, None] # Expand dims to match x\n",
    "        z = z.repeat(1, 1, height, width) # Upscale to image size\n",
    "        x = torch.cat((x, z), dim=1)\n",
    "\n",
    "        x = self.loc(x)\n",
    "\n",
    "        x_glob = self.glob(x)\n",
    "        x_glob = x_glob[:, :, None, None] # Expand dims\n",
    "        x_glob = x_glob.repeat(1, 1, height, width) # Upscale to image size\n",
    "        x = torch.cat((x, x_glob), dim=1)\n",
    "\n",
    "        y = self.head(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TetrisDiscriminator(nn.Module):\n",
    "    \"\"\"A discriminator for the cell state predictions. Assesses the output of the generator.\n",
    "\n",
    "    Inputs:\n",
    "        x: Tensor of float32 of shape (batch_size, channels, height, width). channels = 2 is the one-hot encoding of cell types, with\n",
    "           0 for empty cells and 1 for filled cells. height = 22 and width = 10 are the dimensions of the game board. The entries\n",
    "           should be 0 for empty cells and 1 for filled cells.\n",
    "        y: Tensor of float32 of shape (batch_size, channels, height, width), as with x. This should be either the output of the\n",
    "           generator (with exp applied) or the one-hot encoding of the ground truth of the next cell states.\n",
    "    \n",
    "    Returns: Tensor of float32 of shape (batch_size, 1), decisions on whether the data are real or fake. Probabilities close to 0 (negative logits)\n",
    "             correspond to fake data, and probabilities close to 1 (positive logits) correspond to real data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.body = nn.Sequential(\n",
    "                nn.Conv2d(4, 16, 3, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2),\n",
    "                nn.Conv2d(16, 16, 3),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(16, 16, 3),\n",
    "                nn.ReLU(),\n",
    "                nn.Flatten(),\n",
    "                nn.Linear(112, 16),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(16, 1),\n",
    "                nn.Flatten(start_dim=0)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        x = torch.cat((x, y), dim=1)\n",
    "        logits = self.body(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def check_gen(gen):\n",
    "    with torch.no_grad():\n",
    "        X, y = next(iter(train_dataloader))\n",
    "        z = torch.rand(batch_size, 4)\n",
    "        y_fake = gen(X, z)\n",
    "        print(f\"Number of generator parameters: {count_parameters(gen)}\")\n",
    "        print(f\"Fake data: {y_fake[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of generator parameters: 17996\n",
      "Number of discriminator parameters: 7057\n",
      "Predicted label for real data: 0.5265039801597595\n",
      "Predicted label for fake data: 0.5276320576667786\n"
     ]
    }
   ],
   "source": [
    "gen = TetrisModel().to(device)\n",
    "disc = TetrisDiscriminator().to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    X, y = next(iter(train_dataloader))\n",
    "    z = torch.rand(batch_size, 4)\n",
    "    y_gen = gen(X, z)\n",
    "    pred_on_real = F.sigmoid(disc(X, y)[0])\n",
    "    pred_on_fake = F.sigmoid(disc(X, y_gen)[0])\n",
    "    print(f\"Number of generator parameters: {count_parameters(gen)}\")\n",
    "    print(f\"Number of discriminator parameters: {count_parameters(disc)}\")\n",
    "    print(f\"Predicted label for real data: {pred_on_real}\")\n",
    "    print(f\"Predicted label for fake data: {pred_on_fake}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def find_interesting_examples(dataset, num=3):\n",
    "    num_spawns = num\n",
    "    \n",
    "    def inner():\n",
    "        num_spawns_left = num_spawns\n",
    "\n",
    "        for x, y in dataset:\n",
    "            # Check for block spawn\n",
    "            if (x.argmax(0)[0] == 0).all() & (y.argmax(0)[0] == 1).any():\n",
    "                if num_spawns_left > 0:\n",
    "                    num_spawns_left -= 1\n",
    "                    yield x, y\n",
    "                else:\n",
    "                    continue\n",
    "            \n",
    "    return list(itertools.islice(inner(), num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_prediction(x, pred, y):\n",
    "    \"\"\"Renders an example and prediction into a single-image array.\n",
    "    \n",
    "    Inputs:\n",
    "        x: Tensor of shape (height, width), the model input.\n",
    "        pred: Tensor of shape (height, width), the model prediction.\n",
    "        y: Tensor of shape (height, width), the target.\n",
    "    \"\"\"\n",
    "    assert len(x.shape) == 2, f\"Expected tensors of shape (width, height) but got {x.shape}\"\n",
    "    assert x.shape == pred.shape, f\"Shapes do not match: {x.shape} != {pred.shape}\"\n",
    "    assert x.shape == y.shape, f\"Shapes do not match: {x.shape} != {y.shape}\"\n",
    "    height, width = x.shape\n",
    "    with torch.no_grad():\n",
    "        separator = torch.ones(height, 1, dtype=x.dtype)\n",
    "        return torch.cat((x, separator, pred, separator, y), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = [\n",
    "    torch.tensor(\n",
    "        [[0, 0, 0, 1, 1, 1, 1, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
    "        dtype=torch.int), # I\n",
    "\n",
    "    torch.tensor(\n",
    "        [[0, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
    "        dtype=torch.int), # O\n",
    "\n",
    "    torch.tensor(\n",
    "        [[0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 1, 1, 1, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
    "        dtype=torch.int), # J\n",
    "\n",
    "    torch.tensor(\n",
    "        [[0, 0, 0, 1, 1, 1, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
    "        dtype=torch.int), # T\n",
    "\n",
    "    torch.tensor(\n",
    "        [[0, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 1, 1, 0, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
    "        dtype=torch.int), # S\n",
    "\n",
    "    torch.tensor(\n",
    "        [[0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 1, 1, 1, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
    "        dtype=torch.int), # L\n",
    "\n",
    "    torch.tensor(\n",
    "        [[0, 0, 0, 1, 1, 0, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
    "        dtype=torch.int) # Z\n",
    "]\n",
    "\n",
    "def get_valid_block_spawns(classes_X, classes_y_fake):\n",
    "    \"\"\"Determines whether predicted block spawns have a valid shape.\n",
    "    \n",
    "    Inputs:\n",
    "        classes_X: Tensor of int32 of shape (batch_size, height, width), the first time step (with argmax applied on cell types).\n",
    "        classes_y_fake: Tensor of int32 of shape (batch_size, height, width), the model's prediction (with argmax applied on cell types).\n",
    "\n",
    "    Returns: Tensor of bool of shape (batch_size,), whether the items are predicted block spawns AND valid.\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        batch_size = classes_X.size(0)\n",
    "        ret = torch.full((batch_size,), False)\n",
    "\n",
    "        # Take difference to see which cells are full but weren't before.\n",
    "        diff = classes_y_fake - classes_X\n",
    "\n",
    "        # It's only a valid block spawn if the change in the first 3 rows matches\n",
    "        # one of the valid configurations.\n",
    "        for block in blocks:\n",
    "            ret |= (diff[:, :3, :] == block).all(-1).all(-1)\n",
    "        \n",
    "        return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_label = 1.0\n",
    "fake_label = 0.0\n",
    "\n",
    "def train_loop(dataloader, gen, disc, loss_fn, optimizer_gen, optimizer_disc):\n",
    "    gen.train()\n",
    "    disc.train()\n",
    "\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        ##################################################################\n",
    "        # (1) Update discriminator: minimize -log(D(x)) - log(1 - D(G(z)))\n",
    "        ##################################################################\n",
    "        disc.zero_grad()\n",
    "\n",
    "        ## Train with all-real batch\n",
    "        # Format batch\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        batch_size = X.size(0)\n",
    "        real_labels = torch.full((batch_size,), real_label, dtype=torch.float, device=device)\n",
    "        # Forward pass real batch through discriminator\n",
    "        output = torch.flatten(disc(X, y))\n",
    "        # Calculate loss on all-real batch\n",
    "        err_disc_real = loss_fn(output, real_labels)\n",
    "        # Calculate gradients for discriminator in backward pass\n",
    "        err_disc_real.backward()\n",
    "\n",
    "        ## Train with all-fake batch\n",
    "        # Generate batch of latent vectors\n",
    "        z = torch.rand(batch_size, 4, device=device)\n",
    "        # Generate fake image batch with generator\n",
    "        y_fake = gen(X, z)\n",
    "        fake_labels = torch.full((batch_size,), fake_label, dtype=torch.float, device=device)\n",
    "        # Classify all fake batch with discriminator\n",
    "        output = torch.flatten(disc(X, y_fake.detach()))\n",
    "        # Calculate discriminator's loss on the all-fake batch\n",
    "        err_disc_fake = loss_fn(output, fake_labels)\n",
    "        # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
    "        err_disc_fake.backward()\n",
    "\n",
    "        ## Update discriminator weights\n",
    "        # Compute error of discriminator as sum over the fake and the real batches\n",
    "        err_disc = err_disc_real + err_disc_fake\n",
    "        # Update discriminator\n",
    "        optimizer_disc.step()\n",
    "\n",
    "        ##############################################\n",
    "        # (2) Update generator: minimize -log(D(G(z)))\n",
    "        ##############################################\n",
    "        gen.zero_grad()\n",
    "        # Since we just updated the discriminator, perform another forward pass of the all-fake batch through it\n",
    "        output = torch.flatten(disc(X, y_fake))\n",
    "        # Calculate the generator's loss based on this output\n",
    "        # We use real labels because the generator wants to fool the discriminator\n",
    "        err_gen = loss_fn(output, real_labels)\n",
    "        # Calculate gradients for generator\n",
    "        err_gen.backward()\n",
    "        # Update generator\n",
    "        optimizer_gen.step()\n",
    "\n",
    "        # Output training stats\n",
    "        if batch % 20 == 0:\n",
    "            current = batch * dataloader.batch_size + batch_size\n",
    "            print(f\"[{current}/{size}] D loss: {err_disc.item():.4f}, G loss: {err_gen.item():.4f}\")\n",
    "\n",
    "\n",
    "def test_loop(split_name, dataloader, gen, disc, loss_fn, tb_writer, epoch, examples):\n",
    "    gen.eval()\n",
    "    disc.eval()\n",
    "\n",
    "    loss_disc = 0.0\n",
    "    loss_gen = 0.0\n",
    "    disc_accuracy = 0.0\n",
    "    cell_accuracy = 0.0\n",
    "    board_accuracy = 0.0\n",
    "    spawn_recall = 0.0\n",
    "    num_spawns = 0.0\n",
    "    spawn_validity = 0.0\n",
    "    num_predicted_spawns = 0.0\n",
    "    spawn_precision = 0.0\n",
    "    scores_real = np.zeros(len(dataloader.dataset))\n",
    "    scores_fake = np.zeros(len(dataloader.dataset))\n",
    "\n",
    "    num_batches = len(dataloader)\n",
    "    with torch.no_grad():        \n",
    "        for batch, (X, y) in enumerate(dataloader):\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            batch_size = X.size(0)\n",
    "            real_labels = torch.full((batch_size,), real_label, dtype=torch.float, device=device)\n",
    "            fake_labels = torch.full((batch_size,), fake_label, dtype=torch.float, device=device)\n",
    "\n",
    "            output_real = disc(X, y)\n",
    "            loss_disc += loss_fn(output_real, real_labels).item()\n",
    "\n",
    "            z = torch.rand(batch_size, 4, device=device)\n",
    "            y_fake = gen(X, z)\n",
    "            output_fake = disc(X, y_fake)\n",
    "            \n",
    "            loss_disc += loss_fn(output_fake, fake_labels).item()\n",
    "            loss_gen += loss_fn(output_fake, real_labels).item()\n",
    "\n",
    "            pred_real = (output_real > 0.0)\n",
    "            pred_fake = (output_fake > 0.0)\n",
    "            disc_accuracy += pred_real.type(torch.float).mean().item()\n",
    "            disc_accuracy += (~pred_fake).type(torch.float).mean().item()\n",
    "\n",
    "            classes_X = torch.argmax(X, dim=1)\n",
    "            classes_y = torch.argmax(y, dim=1)\n",
    "            classes_y_fake = torch.argmax(y_fake, dim=1)\n",
    "            cell_accuracy += (classes_y_fake == classes_y).type(torch.float).mean().item()\n",
    "            board_accuracy += (classes_y_fake == classes_y).all(-1).all(-1).type(torch.float).mean().item()\n",
    "\n",
    "            actual_spawns = (classes_X[:, 0, :] == 0).all(-1) & (classes_y[:, 0, :] == 1).any(-1)\n",
    "            predicted_spawns = (classes_X[:, 0, :] == 0).all(-1) & (classes_y_fake[:, 0, :] == 1).any(-1)\n",
    "            num_true_positives = (actual_spawns & predicted_spawns).type(torch.float).sum().item()\n",
    "            spawn_recall += num_true_positives\n",
    "            spawn_precision += num_true_positives\n",
    "            num_spawns += actual_spawns.type(torch.float).sum().item()\n",
    "            valid_spawns = get_valid_block_spawns(classes_X, classes_y_fake)\n",
    "            spawn_validity += valid_spawns.type(torch.float).sum().item()\n",
    "            num_predicted_spawns += predicted_spawns.type(torch.float).sum().item()\n",
    "\n",
    "            start_index = dataloader.batch_size * batch\n",
    "            end_index = start_index + batch_size\n",
    "            scores_real[start_index:end_index] = torch.sigmoid(output_real).numpy()\n",
    "            scores_fake[start_index:end_index] = torch.sigmoid(output_fake).numpy()\n",
    "\n",
    "    loss_disc /= num_batches\n",
    "    loss_gen /= num_batches\n",
    "    cell_accuracy /= num_batches\n",
    "    board_accuracy /= num_batches\n",
    "    spawn_recall /= num_spawns\n",
    "    spawn_precision = np.nan if (num_predicted_spawns == 0.0) else spawn_precision / num_predicted_spawns\n",
    "    disc_accuracy /= (2.0 * num_batches)\n",
    "    spawn_validity = np.nan if (num_predicted_spawns == 0.0) else spawn_validity / num_predicted_spawns\n",
    "\n",
    "    print(f\"{split_name} error: \\n D loss: {loss_disc:>8f}, G loss: {loss_gen:>8f}, D accuracy: {(100*disc_accuracy):>0.1f}%, cell accuracy: {(100*cell_accuracy):>0.1f}%, board accuracy: {(100*board_accuracy):>0.1f}% \\n\")\n",
    "\n",
    "    tb_writer.add_scalar(f\"Discriminator loss/{split_name}\", loss_disc, epoch)\n",
    "    tb_writer.add_scalar(f\"Loss/{split_name}\", loss_gen, epoch)\n",
    "    tb_writer.add_scalar(f\"Discriminator accuracy/{split_name}\", disc_accuracy, epoch)\n",
    "    tb_writer.add_scalar(f\"Cell accuracy/{split_name}\", cell_accuracy, epoch)\n",
    "    tb_writer.add_scalar(f\"Board accuracy/{split_name}\", board_accuracy, epoch)\n",
    "    tb_writer.add_scalar(f\"Spawn recall/{split_name}\", spawn_recall, epoch)\n",
    "    tb_writer.add_scalar(f\"Spawn precision/{split_name}\", spawn_precision, epoch)\n",
    "    tb_writer.add_scalar(f\"Spawn validity/{split_name}\", spawn_validity, epoch)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (X, y) in enumerate(examples):\n",
    "            X, y = X.unsqueeze(0), y.unsqueeze(0)\n",
    "            z = torch.rand(1, 4, device=device)\n",
    "            y_fake = gen(X, z)\n",
    "            X, y, y_fake = X.squeeze(0), y.squeeze(0), y_fake.squeeze(0)\n",
    "            X, y, y_fake = X.argmax(0), y.argmax(0), y_fake.argmax(0)\n",
    "            img = render_prediction(X, y_fake, y)\n",
    "            tb_writer.add_image(f\"Predictions/{split_name}/{i}\", img, epoch, dataformats=\"HW\")\n",
    "    \n",
    "    tb_writer.add_histogram(f\"Discriminator scores/{split_name}/real\", scores_real, epoch)\n",
    "    tb_writer.add_histogram(f\"Discriminator scores/{split_name}/fake\", scores_fake, epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(run_name=\"\", gen_cls=TetrisModel, learning_rate=1e-4, epochs=100):\n",
    "    gen = gen_cls().to(device)\n",
    "    disc = TetrisDiscriminator().to(device)\n",
    "\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    optimizer_gen = torch.optim.Adam(gen.parameters(), lr=learning_rate)\n",
    "    optimizer_disc = torch.optim.Adam(disc.parameters(), lr=learning_rate)\n",
    "\n",
    "    log_dir = os.path.join(\"runs\", \"experiment_021\")\n",
    "    log_subdir = os.path.join(log_dir, run_name + \"_\" + datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\"))\n",
    "    tb_writer = SummaryWriter(log_subdir)\n",
    "\n",
    "    train_examples = find_interesting_examples(train_dataset)\n",
    "    test_examples = find_interesting_examples(test_dataset)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch}\\n-------------------------------\")\n",
    "        train_loop(train_dataloader, gen, disc, loss_fn, optimizer_gen, optimizer_disc)\n",
    "        test_loop(\"train\", train_dataloader, gen, disc, loss_fn, tb_writer, epoch, train_examples)\n",
    "        test_loop(\"test\", test_dataloader, gen, disc, loss_fn, tb_writer, epoch, test_examples)\n",
    "        gen_zero_grads = 0\n",
    "        for name, weight in gen.named_parameters():\n",
    "            tb_writer.add_histogram(f\"Weights/{name}\", weight, epoch)\n",
    "            tb_writer.add_histogram(f\"Gradients/{name}\", weight.grad, epoch)\n",
    "            gen_zero_grads += weight.grad.numel() - weight.grad.count_nonzero().item()\n",
    "        tb_writer.add_scalar(f\"Zero gradients\", gen_zero_grads, epoch)\n",
    "        disc_zero_grads = 0\n",
    "        for name, weight in disc.named_parameters():\n",
    "            tb_writer.add_histogram(f\"Discriminator weights/{name}\", weight, epoch)\n",
    "            tb_writer.add_histogram(f\"Discriminator gradients/{name}\", weight.grad, epoch)\n",
    "            disc_zero_grads += weight.grad.numel() - weight.grad.count_nonzero().item()\n",
    "        tb_writer.add_scalar(f\"Discriminator zero gradients\", disc_zero_grads, epoch)\n",
    "\n",
    "    tb_writer.close()\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of generator parameters: 17964\n",
      "Fake data: tensor([[[0.5508, 0.5530, 0.4990, 0.5312, 0.5358, 0.5246, 0.5180, 0.4471,\n",
      "          0.5257, 0.5231],\n",
      "         [0.5574, 0.5251, 0.5174, 0.5436, 0.5468, 0.5483, 0.5457, 0.3969,\n",
      "          0.4996, 0.5236],\n",
      "         [0.4968, 0.5570, 0.5463, 0.5517, 0.5819, 0.5783, 0.5512, 0.5082,\n",
      "          0.5453, 0.5528],\n",
      "         [0.5184, 0.5934, 0.5474, 0.5536, 0.5833, 0.5853, 0.5785, 0.5201,\n",
      "          0.5887, 0.5566],\n",
      "         [0.5254, 0.5960, 0.5568, 0.5705, 0.5836, 0.5863, 0.5628, 0.5329,\n",
      "          0.5854, 0.5637],\n",
      "         [0.5146, 0.5951, 0.5543, 0.5647, 0.5719, 0.5859, 0.5661, 0.5344,\n",
      "          0.5814, 0.5654],\n",
      "         [0.5146, 0.5951, 0.5543, 0.5647, 0.5719, 0.5859, 0.5661, 0.5344,\n",
      "          0.5814, 0.5654],\n",
      "         [0.5146, 0.5951, 0.5543, 0.5647, 0.5719, 0.5859, 0.5661, 0.5344,\n",
      "          0.5814, 0.5654],\n",
      "         [0.5146, 0.5951, 0.5543, 0.5647, 0.5719, 0.5859, 0.5661, 0.5344,\n",
      "          0.5814, 0.5654],\n",
      "         [0.5146, 0.5951, 0.5543, 0.5647, 0.5719, 0.5859, 0.5661, 0.5344,\n",
      "          0.5814, 0.5654],\n",
      "         [0.5146, 0.5951, 0.5543, 0.5647, 0.5719, 0.5859, 0.5661, 0.5344,\n",
      "          0.5814, 0.5654],\n",
      "         [0.5146, 0.5951, 0.5543, 0.5647, 0.5719, 0.5859, 0.5661, 0.5344,\n",
      "          0.5814, 0.5654],\n",
      "         [0.5146, 0.5951, 0.5543, 0.5647, 0.5719, 0.5859, 0.5661, 0.5344,\n",
      "          0.5814, 0.5654],\n",
      "         [0.5146, 0.5951, 0.5543, 0.5647, 0.5719, 0.5859, 0.5661, 0.5344,\n",
      "          0.5814, 0.5654],\n",
      "         [0.5146, 0.5951, 0.5543, 0.5647, 0.5719, 0.5859, 0.5661, 0.5344,\n",
      "          0.5814, 0.5654],\n",
      "         [0.5168, 0.5956, 0.5584, 0.5651, 0.5685, 0.5817, 0.5685, 0.5328,\n",
      "          0.5822, 0.5654],\n",
      "         [0.5094, 0.5949, 0.5540, 0.5657, 0.5678, 0.5840, 0.5655, 0.5438,\n",
      "          0.5825, 0.5668],\n",
      "         [0.5329, 0.5932, 0.5460, 0.5605, 0.5655, 0.5765, 0.5530, 0.5148,\n",
      "          0.5864, 0.5607],\n",
      "         [0.4378, 0.4735, 0.5050, 0.5139, 0.5638, 0.5604, 0.5144, 0.5121,\n",
      "          0.5551, 0.5526],\n",
      "         [0.4808, 0.5137, 0.4767, 0.5125, 0.5474, 0.5480, 0.5446, 0.5236,\n",
      "          0.5572, 0.5484],\n",
      "         [0.5288, 0.5687, 0.5297, 0.5110, 0.5588, 0.5910, 0.5927, 0.5700,\n",
      "          0.5497, 0.5395],\n",
      "         [0.4769, 0.5381, 0.4478, 0.5117, 0.5354, 0.5649, 0.5397, 0.5343,\n",
      "          0.5484, 0.5786]],\n",
      "\n",
      "        [[0.4492, 0.4470, 0.5010, 0.4688, 0.4642, 0.4754, 0.4820, 0.5529,\n",
      "          0.4743, 0.4769],\n",
      "         [0.4426, 0.4749, 0.4826, 0.4564, 0.4532, 0.4517, 0.4543, 0.6031,\n",
      "          0.5004, 0.4764],\n",
      "         [0.5032, 0.4430, 0.4537, 0.4483, 0.4181, 0.4217, 0.4488, 0.4918,\n",
      "          0.4547, 0.4472],\n",
      "         [0.4816, 0.4066, 0.4526, 0.4464, 0.4167, 0.4147, 0.4215, 0.4799,\n",
      "          0.4113, 0.4434],\n",
      "         [0.4746, 0.4040, 0.4432, 0.4295, 0.4164, 0.4137, 0.4372, 0.4671,\n",
      "          0.4146, 0.4363],\n",
      "         [0.4854, 0.4049, 0.4457, 0.4353, 0.4281, 0.4141, 0.4339, 0.4656,\n",
      "          0.4186, 0.4346],\n",
      "         [0.4854, 0.4049, 0.4457, 0.4353, 0.4281, 0.4141, 0.4339, 0.4656,\n",
      "          0.4186, 0.4346],\n",
      "         [0.4854, 0.4049, 0.4457, 0.4353, 0.4281, 0.4141, 0.4339, 0.4656,\n",
      "          0.4186, 0.4346],\n",
      "         [0.4854, 0.4049, 0.4457, 0.4353, 0.4281, 0.4141, 0.4339, 0.4656,\n",
      "          0.4186, 0.4346],\n",
      "         [0.4854, 0.4049, 0.4457, 0.4353, 0.4281, 0.4141, 0.4339, 0.4656,\n",
      "          0.4186, 0.4346],\n",
      "         [0.4854, 0.4049, 0.4457, 0.4353, 0.4281, 0.4141, 0.4339, 0.4656,\n",
      "          0.4186, 0.4346],\n",
      "         [0.4854, 0.4049, 0.4457, 0.4353, 0.4281, 0.4141, 0.4339, 0.4656,\n",
      "          0.4186, 0.4346],\n",
      "         [0.4854, 0.4049, 0.4457, 0.4353, 0.4281, 0.4141, 0.4339, 0.4656,\n",
      "          0.4186, 0.4346],\n",
      "         [0.4854, 0.4049, 0.4457, 0.4353, 0.4281, 0.4141, 0.4339, 0.4656,\n",
      "          0.4186, 0.4346],\n",
      "         [0.4854, 0.4049, 0.4457, 0.4353, 0.4281, 0.4141, 0.4339, 0.4656,\n",
      "          0.4186, 0.4346],\n",
      "         [0.4832, 0.4044, 0.4416, 0.4349, 0.4315, 0.4183, 0.4315, 0.4672,\n",
      "          0.4178, 0.4346],\n",
      "         [0.4906, 0.4051, 0.4460, 0.4343, 0.4322, 0.4160, 0.4345, 0.4562,\n",
      "          0.4175, 0.4332],\n",
      "         [0.4671, 0.4068, 0.4540, 0.4395, 0.4345, 0.4235, 0.4470, 0.4852,\n",
      "          0.4136, 0.4393],\n",
      "         [0.5622, 0.5265, 0.4950, 0.4861, 0.4362, 0.4396, 0.4856, 0.4879,\n",
      "          0.4449, 0.4474],\n",
      "         [0.5192, 0.4863, 0.5233, 0.4875, 0.4526, 0.4520, 0.4554, 0.4764,\n",
      "          0.4428, 0.4516],\n",
      "         [0.4712, 0.4313, 0.4703, 0.4890, 0.4412, 0.4090, 0.4073, 0.4300,\n",
      "          0.4503, 0.4605],\n",
      "         [0.5231, 0.4619, 0.5522, 0.4883, 0.4646, 0.4351, 0.4603, 0.4657,\n",
      "          0.4516, 0.4214]]])\n"
     ]
    }
   ],
   "source": [
    "class GenWithLessBatchNorm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.loc = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.glob = nn.Sequential(\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(160, 10)\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Conv2d(26, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 2, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, z):\n",
    "        batch_size, channels, height, width = x.shape\n",
    "        \n",
    "        z = z[:, :, None, None] # Expand dims to match x\n",
    "        z = z.repeat(1, 1, height, width) # Upscale to image size\n",
    "        x = torch.cat((x, z), dim=1)\n",
    "\n",
    "        x = self.loc(x)\n",
    "\n",
    "        x_glob = self.glob(x)\n",
    "        x_glob = x_glob[:, :, None, None] # Expand dims\n",
    "        x_glob = x_glob.repeat(1, 1, height, width) # Upscale to image size\n",
    "        x = torch.cat((x, x_glob), dim=1)\n",
    "\n",
    "        y = self.head(x)\n",
    "        return y\n",
    "\n",
    "\n",
    "check_gen(GenWithLessBatchNorm().to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of generator parameters: 17884\n",
      "Fake data: tensor([[[0.4335, 0.4334, 0.4333, 0.4333, 0.4332, 0.4332, 0.4333, 0.4330,\n",
      "          0.4328, 0.4327],\n",
      "         [0.4348, 0.4345, 0.4347, 0.4346, 0.4346, 0.4346, 0.4345, 0.4344,\n",
      "          0.4345, 0.4335],\n",
      "         [0.4346, 0.4342, 0.4346, 0.4347, 0.4346, 0.4346, 0.4345, 0.4343,\n",
      "          0.4345, 0.4337],\n",
      "         [0.4345, 0.4342, 0.4346, 0.4346, 0.4345, 0.4345, 0.4344, 0.4343,\n",
      "          0.4345, 0.4337],\n",
      "         [0.4346, 0.4342, 0.4346, 0.4346, 0.4346, 0.4345, 0.4344, 0.4343,\n",
      "          0.4345, 0.4338],\n",
      "         [0.4346, 0.4341, 0.4346, 0.4346, 0.4345, 0.4345, 0.4344, 0.4343,\n",
      "          0.4345, 0.4337],\n",
      "         [0.4346, 0.4341, 0.4345, 0.4346, 0.4345, 0.4345, 0.4344, 0.4343,\n",
      "          0.4345, 0.4337],\n",
      "         [0.4345, 0.4341, 0.4345, 0.4344, 0.4346, 0.4345, 0.4344, 0.4344,\n",
      "          0.4345, 0.4337],\n",
      "         [0.4346, 0.4340, 0.4343, 0.4344, 0.4345, 0.4346, 0.4344, 0.4343,\n",
      "          0.4346, 0.4337],\n",
      "         [0.4345, 0.4342, 0.4344, 0.4344, 0.4344, 0.4346, 0.4344, 0.4342,\n",
      "          0.4346, 0.4338],\n",
      "         [0.4345, 0.4339, 0.4345, 0.4346, 0.4346, 0.4344, 0.4344, 0.4342,\n",
      "          0.4345, 0.4338],\n",
      "         [0.4345, 0.4341, 0.4343, 0.4343, 0.4345, 0.4346, 0.4343, 0.4342,\n",
      "          0.4345, 0.4338],\n",
      "         [0.4346, 0.4342, 0.4345, 0.4345, 0.4344, 0.4345, 0.4344, 0.4342,\n",
      "          0.4345, 0.4338],\n",
      "         [0.4345, 0.4342, 0.4344, 0.4345, 0.4346, 0.4346, 0.4345, 0.4342,\n",
      "          0.4346, 0.4338],\n",
      "         [0.4345, 0.4340, 0.4343, 0.4343, 0.4344, 0.4345, 0.4346, 0.4342,\n",
      "          0.4345, 0.4338],\n",
      "         [0.4344, 0.4342, 0.4343, 0.4344, 0.4345, 0.4344, 0.4343, 0.4342,\n",
      "          0.4345, 0.4338],\n",
      "         [0.4345, 0.4339, 0.4343, 0.4343, 0.4345, 0.4347, 0.4343, 0.4342,\n",
      "          0.4346, 0.4337],\n",
      "         [0.4345, 0.4341, 0.4343, 0.4342, 0.4344, 0.4348, 0.4343, 0.4341,\n",
      "          0.4345, 0.4337],\n",
      "         [0.4344, 0.4341, 0.4343, 0.4344, 0.4345, 0.4346, 0.4343, 0.4342,\n",
      "          0.4345, 0.4337],\n",
      "         [0.4343, 0.4339, 0.4341, 0.4341, 0.4344, 0.4344, 0.4343, 0.4342,\n",
      "          0.4344, 0.4337],\n",
      "         [0.4343, 0.4342, 0.4344, 0.4344, 0.4346, 0.4346, 0.4344, 0.4345,\n",
      "          0.4347, 0.4338],\n",
      "         [0.4330, 0.4334, 0.4336, 0.4336, 0.4336, 0.4337, 0.4337, 0.4337,\n",
      "          0.4340, 0.4329]],\n",
      "\n",
      "        [[0.5665, 0.5666, 0.5667, 0.5667, 0.5668, 0.5668, 0.5667, 0.5670,\n",
      "          0.5672, 0.5673],\n",
      "         [0.5652, 0.5655, 0.5653, 0.5654, 0.5654, 0.5654, 0.5655, 0.5656,\n",
      "          0.5655, 0.5665],\n",
      "         [0.5654, 0.5658, 0.5654, 0.5653, 0.5654, 0.5654, 0.5655, 0.5657,\n",
      "          0.5655, 0.5663],\n",
      "         [0.5655, 0.5658, 0.5654, 0.5654, 0.5655, 0.5655, 0.5656, 0.5657,\n",
      "          0.5655, 0.5663],\n",
      "         [0.5654, 0.5658, 0.5654, 0.5654, 0.5654, 0.5655, 0.5656, 0.5657,\n",
      "          0.5655, 0.5662],\n",
      "         [0.5654, 0.5659, 0.5654, 0.5654, 0.5655, 0.5655, 0.5656, 0.5657,\n",
      "          0.5655, 0.5663],\n",
      "         [0.5654, 0.5659, 0.5655, 0.5654, 0.5655, 0.5655, 0.5656, 0.5657,\n",
      "          0.5655, 0.5663],\n",
      "         [0.5655, 0.5659, 0.5655, 0.5656, 0.5654, 0.5655, 0.5656, 0.5656,\n",
      "          0.5655, 0.5663],\n",
      "         [0.5654, 0.5660, 0.5657, 0.5656, 0.5655, 0.5654, 0.5656, 0.5657,\n",
      "          0.5654, 0.5663],\n",
      "         [0.5655, 0.5658, 0.5656, 0.5656, 0.5656, 0.5654, 0.5656, 0.5658,\n",
      "          0.5654, 0.5662],\n",
      "         [0.5655, 0.5661, 0.5655, 0.5654, 0.5654, 0.5656, 0.5656, 0.5658,\n",
      "          0.5655, 0.5662],\n",
      "         [0.5655, 0.5659, 0.5657, 0.5657, 0.5655, 0.5654, 0.5657, 0.5658,\n",
      "          0.5655, 0.5662],\n",
      "         [0.5654, 0.5658, 0.5655, 0.5655, 0.5656, 0.5655, 0.5656, 0.5658,\n",
      "          0.5655, 0.5662],\n",
      "         [0.5655, 0.5658, 0.5656, 0.5655, 0.5654, 0.5654, 0.5655, 0.5658,\n",
      "          0.5654, 0.5662],\n",
      "         [0.5655, 0.5660, 0.5657, 0.5657, 0.5656, 0.5655, 0.5654, 0.5658,\n",
      "          0.5655, 0.5662],\n",
      "         [0.5656, 0.5658, 0.5657, 0.5656, 0.5655, 0.5656, 0.5657, 0.5658,\n",
      "          0.5655, 0.5662],\n",
      "         [0.5655, 0.5661, 0.5657, 0.5657, 0.5655, 0.5653, 0.5657, 0.5658,\n",
      "          0.5654, 0.5663],\n",
      "         [0.5655, 0.5659, 0.5657, 0.5658, 0.5656, 0.5652, 0.5657, 0.5659,\n",
      "          0.5655, 0.5663],\n",
      "         [0.5656, 0.5659, 0.5657, 0.5656, 0.5655, 0.5654, 0.5657, 0.5658,\n",
      "          0.5655, 0.5663],\n",
      "         [0.5657, 0.5661, 0.5659, 0.5659, 0.5656, 0.5656, 0.5657, 0.5658,\n",
      "          0.5656, 0.5663],\n",
      "         [0.5657, 0.5658, 0.5656, 0.5656, 0.5654, 0.5654, 0.5656, 0.5655,\n",
      "          0.5653, 0.5662],\n",
      "         [0.5670, 0.5666, 0.5664, 0.5664, 0.5664, 0.5663, 0.5663, 0.5663,\n",
      "          0.5660, 0.5671]]])\n"
     ]
    }
   ],
   "source": [
    "class GenWithNoBatchNorm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.loc = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.glob = nn.Sequential(\n",
    "            nn.Conv2d(16, 16, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(16, 16, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(160, 10)\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Conv2d(26, 16, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 2, 1),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, z):\n",
    "        batch_size, channels, height, width = x.shape\n",
    "        \n",
    "        z = z[:, :, None, None] # Expand dims to match x\n",
    "        z = z.repeat(1, 1, height, width) # Upscale to image size\n",
    "        x = torch.cat((x, z), dim=1)\n",
    "\n",
    "        x = self.loc(x)\n",
    "\n",
    "        x_glob = self.glob(x)\n",
    "        x_glob = x_glob[:, :, None, None] # Expand dims\n",
    "        x_glob = x_glob.repeat(1, 1, height, width) # Upscale to image size\n",
    "        x = torch.cat((x, x_glob), dim=1)\n",
    "\n",
    "        y = self.head(x)\n",
    "        return y\n",
    "\n",
    "\n",
    "check_gen(GenWithNoBatchNorm().to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3952, G loss: 0.6108\n",
      "[84/1762] D loss: 1.3918, G loss: 0.6124\n",
      "[164/1762] D loss: 1.3890, G loss: 0.6122\n",
      "[244/1762] D loss: 1.3846, G loss: 0.6142\n",
      "[324/1762] D loss: 1.3762, G loss: 0.6138\n",
      "[404/1762] D loss: 1.3697, G loss: 0.6092\n",
      "[484/1762] D loss: 1.3542, G loss: 0.6088\n",
      "[564/1762] D loss: 1.3546, G loss: 0.5990\n",
      "[644/1762] D loss: 1.3479, G loss: 0.5927\n",
      "[724/1762] D loss: 1.3322, G loss: 0.6271\n",
      "[804/1762] D loss: 1.3237, G loss: 0.6290\n",
      "[884/1762] D loss: 1.3195, G loss: 0.6720\n",
      "[964/1762] D loss: 1.3062, G loss: 0.6950\n",
      "[1044/1762] D loss: 1.1925, G loss: 0.7284\n",
      "[1124/1762] D loss: 1.1477, G loss: 0.7707\n",
      "[1204/1762] D loss: 1.2408, G loss: 0.7895\n",
      "[1284/1762] D loss: 1.1822, G loss: 0.8150\n",
      "[1364/1762] D loss: 1.2085, G loss: 0.8063\n",
      "[1444/1762] D loss: 1.2636, G loss: 0.8523\n",
      "[1524/1762] D loss: 1.2433, G loss: 0.7369\n",
      "[1604/1762] D loss: 1.1020, G loss: 0.8566\n",
      "[1684/1762] D loss: 1.1281, G loss: 0.8525\n",
      "[1762/1762] D loss: 1.3395, G loss: 0.6790\n",
      "train error: \n",
      " D loss: 1.206003, G loss: 0.850598, D accuracy: 70.9%, cell accuracy: 96.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.202998, G loss: 0.852006, D accuracy: 72.0%, cell accuracy: 96.5%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2113, G loss: 0.8377\n",
      "[84/1762] D loss: 1.1150, G loss: 0.8223\n",
      "[164/1762] D loss: 1.2455, G loss: 0.6758\n",
      "[244/1762] D loss: 1.2019, G loss: 0.8653\n",
      "[324/1762] D loss: 1.1963, G loss: 0.6538\n",
      "[404/1762] D loss: 1.1751, G loss: 0.9982\n",
      "[484/1762] D loss: 1.1958, G loss: 0.7136\n",
      "[564/1762] D loss: 1.1399, G loss: 0.9967\n",
      "[644/1762] D loss: 1.0890, G loss: 0.8601\n",
      "[724/1762] D loss: 1.0160, G loss: 0.9534\n",
      "[804/1762] D loss: 1.0440, G loss: 1.0721\n",
      "[884/1762] D loss: 1.0778, G loss: 0.8245\n",
      "[964/1762] D loss: 0.9947, G loss: 0.8369\n",
      "[1044/1762] D loss: 0.8801, G loss: 0.8737\n",
      "[1124/1762] D loss: 1.1017, G loss: 0.8784\n",
      "[1204/1762] D loss: 1.2016, G loss: 1.1927\n",
      "[1284/1762] D loss: 0.9658, G loss: 0.8829\n",
      "[1364/1762] D loss: 1.6830, G loss: 0.7853\n",
      "[1444/1762] D loss: 1.7214, G loss: 0.7927\n",
      "[1524/1762] D loss: 1.6099, G loss: 0.6134\n",
      "[1604/1762] D loss: 1.3750, G loss: 0.5928\n",
      "[1684/1762] D loss: 1.3596, G loss: 0.6952\n",
      "[1762/1762] D loss: 1.2213, G loss: 0.9994\n",
      "train error: \n",
      " D loss: 1.471590, G loss: 0.688711, D accuracy: 44.3%, cell accuracy: 95.3%, board accuracy: 0.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.474285, G loss: 0.697370, D accuracy: 45.1%, cell accuracy: 95.2%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4270, G loss: 0.7265\n",
      "[84/1762] D loss: 1.4282, G loss: 0.7055\n",
      "[164/1762] D loss: 1.2184, G loss: 0.9870\n",
      "[244/1762] D loss: 1.4059, G loss: 0.5856\n",
      "[324/1762] D loss: 1.3487, G loss: 0.7584\n",
      "[404/1762] D loss: 1.2972, G loss: 0.8778\n",
      "[484/1762] D loss: 1.2718, G loss: 0.9418\n",
      "[564/1762] D loss: 1.2380, G loss: 0.7776\n",
      "[644/1762] D loss: 1.2602, G loss: 0.9558\n",
      "[724/1762] D loss: 1.2730, G loss: 0.7818\n",
      "[804/1762] D loss: 1.3474, G loss: 0.6457\n",
      "[884/1762] D loss: 1.2354, G loss: 0.6811\n",
      "[964/1762] D loss: 1.3381, G loss: 0.7772\n",
      "[1044/1762] D loss: 1.1038, G loss: 0.9382\n",
      "[1124/1762] D loss: 1.2546, G loss: 0.7708\n",
      "[1204/1762] D loss: 1.2689, G loss: 0.8076\n",
      "[1284/1762] D loss: 1.1659, G loss: 0.8202\n",
      "[1364/1762] D loss: 1.2649, G loss: 0.8551\n",
      "[1444/1762] D loss: 1.2706, G loss: 0.8445\n",
      "[1524/1762] D loss: 1.2810, G loss: 0.7487\n",
      "[1604/1762] D loss: 1.3223, G loss: 0.7090\n",
      "[1684/1762] D loss: 1.3493, G loss: 0.6449\n",
      "[1762/1762] D loss: 1.1542, G loss: 0.9277\n",
      "train error: \n",
      " D loss: 1.283303, G loss: 0.828751, D accuracy: 63.9%, cell accuracy: 97.8%, board accuracy: 2.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.269314, G loss: 0.845892, D accuracy: 65.6%, cell accuracy: 97.6%, board accuracy: 2.3% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2451, G loss: 0.8193\n",
      "[84/1762] D loss: 1.2578, G loss: 0.8365\n",
      "[164/1762] D loss: 1.2560, G loss: 0.7979\n",
      "[244/1762] D loss: 1.2165, G loss: 0.8931\n",
      "[324/1762] D loss: 1.3846, G loss: 0.7931\n",
      "[404/1762] D loss: 1.4480, G loss: 0.7006\n",
      "[484/1762] D loss: 1.2489, G loss: 0.9915\n",
      "[564/1762] D loss: 1.2179, G loss: 0.8043\n",
      "[644/1762] D loss: 1.2778, G loss: 0.6348\n",
      "[724/1762] D loss: 1.3210, G loss: 0.8054\n",
      "[804/1762] D loss: 1.3824, G loss: 0.6577\n",
      "[884/1762] D loss: 1.2933, G loss: 0.7336\n",
      "[964/1762] D loss: 1.2654, G loss: 0.7857\n",
      "[1044/1762] D loss: 1.3138, G loss: 0.7646\n",
      "[1124/1762] D loss: 1.4194, G loss: 0.6105\n",
      "[1204/1762] D loss: 1.2773, G loss: 0.9070\n",
      "[1284/1762] D loss: 1.3708, G loss: 0.6801\n",
      "[1364/1762] D loss: 1.3895, G loss: 0.7299\n",
      "[1444/1762] D loss: 1.3562, G loss: 0.7522\n",
      "[1524/1762] D loss: 1.3182, G loss: 0.8246\n",
      "[1604/1762] D loss: 1.2465, G loss: 0.8610\n",
      "[1684/1762] D loss: 1.3248, G loss: 0.7621\n",
      "[1762/1762] D loss: 1.1529, G loss: 1.0830\n",
      "train error: \n",
      " D loss: 1.310138, G loss: 0.729492, D accuracy: 62.3%, cell accuracy: 98.8%, board accuracy: 16.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.307557, G loss: 0.736516, D accuracy: 61.3%, cell accuracy: 98.8%, board accuracy: 16.8% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3740, G loss: 0.7640\n",
      "[84/1762] D loss: 1.2070, G loss: 0.9037\n",
      "[164/1762] D loss: 1.4491, G loss: 0.6646\n",
      "[244/1762] D loss: 1.2347, G loss: 0.6982\n",
      "[324/1762] D loss: 1.2912, G loss: 0.7906\n",
      "[404/1762] D loss: 1.3304, G loss: 0.6636\n",
      "[484/1762] D loss: 1.4197, G loss: 0.6116\n",
      "[564/1762] D loss: 1.3255, G loss: 0.6177\n",
      "[644/1762] D loss: 1.3659, G loss: 0.6049\n",
      "[724/1762] D loss: 1.2456, G loss: 0.9023\n",
      "[804/1762] D loss: 1.3192, G loss: 0.7120\n",
      "[884/1762] D loss: 1.2798, G loss: 0.7205\n",
      "[964/1762] D loss: 1.3243, G loss: 0.6445\n",
      "[1044/1762] D loss: 1.4029, G loss: 0.6346\n",
      "[1124/1762] D loss: 1.3077, G loss: 0.8236\n",
      "[1204/1762] D loss: 1.3943, G loss: 0.6260\n",
      "[1284/1762] D loss: 1.2429, G loss: 0.7562\n",
      "[1364/1762] D loss: 1.4413, G loss: 0.7284\n",
      "[1444/1762] D loss: 1.3935, G loss: 0.6935\n",
      "[1524/1762] D loss: 1.1354, G loss: 0.8358\n",
      "[1604/1762] D loss: 1.3451, G loss: 0.5816\n",
      "[1684/1762] D loss: 1.3153, G loss: 0.7988\n",
      "[1762/1762] D loss: 1.3441, G loss: 0.6382\n",
      "train error: \n",
      " D loss: 1.307973, G loss: 0.762094, D accuracy: 59.5%, cell accuracy: 99.0%, board accuracy: 18.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.307719, G loss: 0.771119, D accuracy: 59.9%, cell accuracy: 99.0%, board accuracy: 17.7% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3168, G loss: 0.7347\n",
      "[84/1762] D loss: 1.2254, G loss: 0.6862\n",
      "[164/1762] D loss: 1.2185, G loss: 0.9260\n",
      "[244/1762] D loss: 1.2704, G loss: 0.7764\n",
      "[324/1762] D loss: 1.3060, G loss: 0.8784\n",
      "[404/1762] D loss: 1.2962, G loss: 0.8058\n",
      "[484/1762] D loss: 1.2410, G loss: 0.6448\n",
      "[564/1762] D loss: 1.4396, G loss: 0.5930\n",
      "[644/1762] D loss: 1.4194, G loss: 0.8224\n",
      "[724/1762] D loss: 1.3065, G loss: 0.6326\n",
      "[804/1762] D loss: 1.3563, G loss: 0.7142\n",
      "[884/1762] D loss: 1.3141, G loss: 0.7359\n",
      "[964/1762] D loss: 1.3742, G loss: 0.5632\n",
      "[1044/1762] D loss: 1.4678, G loss: 0.5543\n",
      "[1124/1762] D loss: 1.4134, G loss: 0.6328\n",
      "[1204/1762] D loss: 1.4573, G loss: 0.7793\n",
      "[1284/1762] D loss: 1.3816, G loss: 0.7427\n",
      "[1364/1762] D loss: 1.4320, G loss: 0.9182\n",
      "[1444/1762] D loss: 1.3230, G loss: 0.7465\n",
      "[1524/1762] D loss: 1.2950, G loss: 0.7378\n",
      "[1604/1762] D loss: 1.3886, G loss: 0.6800\n",
      "[1684/1762] D loss: 1.4348, G loss: 0.5171\n",
      "[1762/1762] D loss: 1.3650, G loss: 0.7602\n",
      "train error: \n",
      " D loss: 1.405456, G loss: 0.806314, D accuracy: 51.1%, cell accuracy: 99.5%, board accuracy: 50.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.411116, G loss: 0.805734, D accuracy: 51.6%, cell accuracy: 99.4%, board accuracy: 47.5% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4137, G loss: 0.8641\n",
      "[84/1762] D loss: 1.4020, G loss: 0.6655\n",
      "[164/1762] D loss: 1.3887, G loss: 0.6482\n",
      "[244/1762] D loss: 1.3878, G loss: 0.6672\n",
      "[324/1762] D loss: 1.4004, G loss: 0.7232\n",
      "[404/1762] D loss: 1.4191, G loss: 0.6809\n",
      "[484/1762] D loss: 1.3932, G loss: 0.7009\n",
      "[564/1762] D loss: 1.3899, G loss: 0.7100\n",
      "[644/1762] D loss: 1.3786, G loss: 0.7443\n",
      "[724/1762] D loss: 1.4034, G loss: 0.7208\n",
      "[804/1762] D loss: 1.4017, G loss: 0.7163\n",
      "[884/1762] D loss: 1.3468, G loss: 0.7671\n",
      "[964/1762] D loss: 1.4038, G loss: 0.6804\n",
      "[1044/1762] D loss: 1.4018, G loss: 0.6265\n",
      "[1124/1762] D loss: 1.4016, G loss: 0.6992\n",
      "[1204/1762] D loss: 1.3934, G loss: 0.6709\n",
      "[1284/1762] D loss: 1.4096, G loss: 0.7731\n",
      "[1364/1762] D loss: 1.4398, G loss: 0.6920\n",
      "[1444/1762] D loss: 1.4080, G loss: 0.6297\n",
      "[1524/1762] D loss: 1.3976, G loss: 0.7118\n",
      "[1604/1762] D loss: 1.3600, G loss: 0.8093\n",
      "[1684/1762] D loss: 1.4063, G loss: 0.6053\n",
      "[1762/1762] D loss: 1.4007, G loss: 0.8420\n",
      "train error: \n",
      " D loss: 1.388289, G loss: 0.690346, D accuracy: 51.5%, cell accuracy: 99.6%, board accuracy: 60.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.391468, G loss: 0.690345, D accuracy: 50.8%, cell accuracy: 99.6%, board accuracy: 60.9% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3872, G loss: 0.6836\n",
      "[84/1762] D loss: 1.3699, G loss: 0.6684\n",
      "[164/1762] D loss: 1.3884, G loss: 0.6798\n",
      "[244/1762] D loss: 1.3766, G loss: 0.6732\n",
      "[324/1762] D loss: 1.3752, G loss: 0.6523\n",
      "[404/1762] D loss: 1.3947, G loss: 0.6236\n",
      "[484/1762] D loss: 1.3916, G loss: 0.6384\n",
      "[564/1762] D loss: 1.3696, G loss: 0.6967\n",
      "[644/1762] D loss: 1.4417, G loss: 0.9045\n",
      "[724/1762] D loss: 1.3895, G loss: 0.6443\n",
      "[804/1762] D loss: 1.3841, G loss: 0.7844\n",
      "[884/1762] D loss: 1.3868, G loss: 0.7261\n",
      "[964/1762] D loss: 1.3649, G loss: 0.6687\n",
      "[1044/1762] D loss: 1.3943, G loss: 0.6638\n",
      "[1124/1762] D loss: 1.3900, G loss: 0.8301\n",
      "[1204/1762] D loss: 1.4094, G loss: 0.6954\n",
      "[1284/1762] D loss: 1.3846, G loss: 0.6939\n",
      "[1364/1762] D loss: 1.4022, G loss: 0.6977\n",
      "[1444/1762] D loss: 1.3940, G loss: 0.7522\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.8270\n",
      "[1604/1762] D loss: 1.4118, G loss: 0.7426\n",
      "[1684/1762] D loss: 1.4057, G loss: 0.7271\n",
      "[1762/1762] D loss: 1.3658, G loss: 0.8421\n",
      "train error: \n",
      " D loss: 1.389455, G loss: 0.787354, D accuracy: 51.2%, cell accuracy: 99.7%, board accuracy: 73.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.391488, G loss: 0.787836, D accuracy: 50.9%, cell accuracy: 99.6%, board accuracy: 70.5% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3998, G loss: 0.7098\n",
      "[84/1762] D loss: 1.3953, G loss: 0.6349\n",
      "[164/1762] D loss: 1.4041, G loss: 0.6143\n",
      "[244/1762] D loss: 1.3816, G loss: 0.6849\n",
      "[324/1762] D loss: 1.3708, G loss: 0.6598\n",
      "[404/1762] D loss: 1.4042, G loss: 0.7442\n",
      "[484/1762] D loss: 1.3522, G loss: 0.7515\n",
      "[564/1762] D loss: 1.3781, G loss: 0.6873\n",
      "[644/1762] D loss: 1.3901, G loss: 0.7955\n",
      "[724/1762] D loss: 1.4104, G loss: 0.6593\n",
      "[804/1762] D loss: 1.3724, G loss: 0.8077\n",
      "[884/1762] D loss: 1.4083, G loss: 0.6969\n",
      "[964/1762] D loss: 1.3919, G loss: 0.7100\n",
      "[1044/1762] D loss: 1.3892, G loss: 0.6616\n",
      "[1124/1762] D loss: 1.3902, G loss: 0.7447\n",
      "[1204/1762] D loss: 1.3836, G loss: 0.7789\n",
      "[1284/1762] D loss: 1.3733, G loss: 0.7445\n",
      "[1364/1762] D loss: 1.3662, G loss: 0.7273\n",
      "[1444/1762] D loss: 1.3636, G loss: 0.6789\n",
      "[1524/1762] D loss: 1.3584, G loss: 0.7464\n",
      "[1604/1762] D loss: 1.3641, G loss: 0.6932\n",
      "[1684/1762] D loss: 1.3852, G loss: 0.6803\n",
      "[1762/1762] D loss: 1.3960, G loss: 0.7761\n",
      "train error: \n",
      " D loss: 1.379860, G loss: 0.711132, D accuracy: 52.8%, cell accuracy: 99.7%, board accuracy: 75.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.380483, G loss: 0.711932, D accuracy: 53.6%, cell accuracy: 99.6%, board accuracy: 74.3% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3853, G loss: 0.6961\n",
      "[84/1762] D loss: 1.3914, G loss: 0.6746\n",
      "[164/1762] D loss: 1.3794, G loss: 0.6756\n",
      "[244/1762] D loss: 1.3870, G loss: 0.7667\n",
      "[324/1762] D loss: 1.3605, G loss: 0.7438\n",
      "[404/1762] D loss: 1.3672, G loss: 0.6903\n",
      "[484/1762] D loss: 1.3988, G loss: 0.7470\n",
      "[564/1762] D loss: 1.3860, G loss: 0.6431\n",
      "[644/1762] D loss: 1.4079, G loss: 0.6755\n",
      "[724/1762] D loss: 1.3879, G loss: 0.6674\n",
      "[804/1762] D loss: 1.3873, G loss: 0.7521\n",
      "[884/1762] D loss: 1.4088, G loss: 0.6543\n",
      "[964/1762] D loss: 1.3901, G loss: 0.7324\n",
      "[1044/1762] D loss: 1.3434, G loss: 0.6653\n",
      "[1124/1762] D loss: 1.3564, G loss: 0.6536\n",
      "[1204/1762] D loss: 1.3505, G loss: 0.7254\n",
      "[1284/1762] D loss: 1.3540, G loss: 0.6935\n",
      "[1364/1762] D loss: 1.3209, G loss: 0.7454\n",
      "[1444/1762] D loss: 1.3936, G loss: 0.7663\n",
      "[1524/1762] D loss: 1.3875, G loss: 0.6935\n",
      "[1604/1762] D loss: 1.3814, G loss: 0.7037\n",
      "[1684/1762] D loss: 1.3672, G loss: 0.6962\n",
      "[1762/1762] D loss: 1.3917, G loss: 0.6300\n",
      "train error: \n",
      " D loss: 1.377894, G loss: 0.677505, D accuracy: 53.2%, cell accuracy: 99.7%, board accuracy: 77.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.378666, G loss: 0.677412, D accuracy: 53.9%, cell accuracy: 99.7%, board accuracy: 75.9% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3885, G loss: 0.6567\n",
      "[84/1762] D loss: 1.3741, G loss: 0.7486\n",
      "[164/1762] D loss: 1.4003, G loss: 0.6678\n",
      "[244/1762] D loss: 1.3896, G loss: 0.7248\n",
      "[324/1762] D loss: 1.3369, G loss: 0.7534\n",
      "[404/1762] D loss: 1.3980, G loss: 0.6002\n",
      "[484/1762] D loss: 1.3921, G loss: 0.7393\n",
      "[564/1762] D loss: 1.3977, G loss: 0.6676\n",
      "[644/1762] D loss: 1.3813, G loss: 0.6879\n",
      "[724/1762] D loss: 1.3653, G loss: 0.7644\n",
      "[804/1762] D loss: 1.3733, G loss: 0.6234\n",
      "[884/1762] D loss: 1.3243, G loss: 0.8476\n",
      "[964/1762] D loss: 1.3982, G loss: 0.6848\n",
      "[1044/1762] D loss: 1.3618, G loss: 0.7255\n",
      "[1124/1762] D loss: 1.3900, G loss: 0.6988\n",
      "[1204/1762] D loss: 1.3512, G loss: 0.6912\n",
      "[1284/1762] D loss: 1.3778, G loss: 0.6817\n",
      "[1364/1762] D loss: 1.3920, G loss: 0.7123\n",
      "[1444/1762] D loss: 1.3705, G loss: 0.7268\n",
      "[1524/1762] D loss: 1.3757, G loss: 0.7385\n",
      "[1604/1762] D loss: 1.3976, G loss: 0.7074\n",
      "[1684/1762] D loss: 1.3814, G loss: 0.6754\n",
      "[1762/1762] D loss: 1.3884, G loss: 0.6560\n",
      "train error: \n",
      " D loss: 1.378991, G loss: 0.757235, D accuracy: 52.1%, cell accuracy: 99.7%, board accuracy: 77.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.378553, G loss: 0.758106, D accuracy: 52.2%, cell accuracy: 99.7%, board accuracy: 73.6% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3894, G loss: 0.7375\n",
      "[84/1762] D loss: 1.3496, G loss: 0.7227\n",
      "[164/1762] D loss: 1.3726, G loss: 0.6598\n",
      "[244/1762] D loss: 1.3810, G loss: 0.7629\n",
      "[324/1762] D loss: 1.3901, G loss: 0.7151\n",
      "[404/1762] D loss: 1.4228, G loss: 0.6797\n",
      "[484/1762] D loss: 1.3865, G loss: 0.7465\n",
      "[564/1762] D loss: 1.4232, G loss: 0.6757\n",
      "[644/1762] D loss: 1.4057, G loss: 0.7340\n",
      "[724/1762] D loss: 1.3885, G loss: 0.6594\n",
      "[804/1762] D loss: 1.3696, G loss: 0.6762\n",
      "[884/1762] D loss: 1.3513, G loss: 0.6579\n",
      "[964/1762] D loss: 1.3668, G loss: 0.6552\n",
      "[1044/1762] D loss: 1.3992, G loss: 0.6920\n",
      "[1124/1762] D loss: 1.3803, G loss: 0.7235\n",
      "[1204/1762] D loss: 1.3801, G loss: 0.7399\n",
      "[1284/1762] D loss: 1.3923, G loss: 0.7137\n",
      "[1364/1762] D loss: 1.4022, G loss: 0.7212\n",
      "[1444/1762] D loss: 1.3938, G loss: 0.7473\n",
      "[1524/1762] D loss: 1.3961, G loss: 0.7072\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6986\n",
      "[1684/1762] D loss: 1.3899, G loss: 0.6976\n",
      "[1762/1762] D loss: 1.3907, G loss: 0.6282\n",
      "train error: \n",
      " D loss: 1.388590, G loss: 0.622222, D accuracy: 51.3%, cell accuracy: 99.8%, board accuracy: 81.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.390517, G loss: 0.621427, D accuracy: 50.9%, cell accuracy: 99.7%, board accuracy: 79.3% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3980, G loss: 0.6521\n",
      "[84/1762] D loss: 1.4032, G loss: 0.7691\n",
      "[164/1762] D loss: 1.3750, G loss: 0.7058\n",
      "[244/1762] D loss: 1.3864, G loss: 0.6646\n",
      "[324/1762] D loss: 1.3621, G loss: 0.7202\n",
      "[404/1762] D loss: 1.3940, G loss: 0.6647\n",
      "[484/1762] D loss: 1.3648, G loss: 0.6791\n",
      "[564/1762] D loss: 1.3871, G loss: 0.6794\n",
      "[644/1762] D loss: 1.3919, G loss: 0.6429\n",
      "[724/1762] D loss: 1.3753, G loss: 0.7702\n",
      "[804/1762] D loss: 1.3728, G loss: 0.7261\n",
      "[884/1762] D loss: 1.3883, G loss: 0.6859\n",
      "[964/1762] D loss: 1.3890, G loss: 0.6503\n",
      "[1044/1762] D loss: 1.3878, G loss: 0.7341\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.7500\n",
      "[1204/1762] D loss: 1.3870, G loss: 0.7076\n",
      "[1284/1762] D loss: 1.3728, G loss: 0.6442\n",
      "[1364/1762] D loss: 1.3643, G loss: 0.7167\n",
      "[1444/1762] D loss: 1.3827, G loss: 0.7272\n",
      "[1524/1762] D loss: 1.3985, G loss: 0.6573\n",
      "[1604/1762] D loss: 1.3950, G loss: 0.6853\n",
      "[1684/1762] D loss: 1.3388, G loss: 0.7771\n",
      "[1762/1762] D loss: 1.4095, G loss: 0.6209\n",
      "train error: \n",
      " D loss: 1.379236, G loss: 0.716194, D accuracy: 52.7%, cell accuracy: 99.8%, board accuracy: 80.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.379092, G loss: 0.717734, D accuracy: 52.7%, cell accuracy: 99.7%, board accuracy: 78.4% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3800, G loss: 0.7401\n",
      "[84/1762] D loss: 1.3828, G loss: 0.7055\n",
      "[164/1762] D loss: 1.3692, G loss: 0.7763\n",
      "[244/1762] D loss: 1.3918, G loss: 0.6889\n",
      "[324/1762] D loss: 1.3929, G loss: 0.7020\n",
      "[404/1762] D loss: 1.3738, G loss: 0.7538\n",
      "[484/1762] D loss: 1.3670, G loss: 0.7263\n",
      "[564/1762] D loss: 1.3877, G loss: 0.7131\n",
      "[644/1762] D loss: 1.3807, G loss: 0.7005\n",
      "[724/1762] D loss: 1.3894, G loss: 0.6875\n",
      "[804/1762] D loss: 1.3860, G loss: 0.6836\n",
      "[884/1762] D loss: 1.3893, G loss: 0.7450\n",
      "[964/1762] D loss: 1.3604, G loss: 0.7231\n",
      "[1044/1762] D loss: 1.3591, G loss: 0.7288\n",
      "[1124/1762] D loss: 1.3551, G loss: 0.8105\n",
      "[1204/1762] D loss: 1.3874, G loss: 0.7059\n",
      "[1284/1762] D loss: 1.3885, G loss: 0.6564\n",
      "[1364/1762] D loss: 1.3819, G loss: 0.7539\n",
      "[1444/1762] D loss: 1.3680, G loss: 0.6757\n",
      "[1524/1762] D loss: 1.3550, G loss: 0.6719\n",
      "[1604/1762] D loss: 1.3984, G loss: 0.8183\n",
      "[1684/1762] D loss: 1.3392, G loss: 0.7216\n",
      "[1762/1762] D loss: 1.3332, G loss: 0.6939\n",
      "train error: \n",
      " D loss: 1.376604, G loss: 0.724858, D accuracy: 52.9%, cell accuracy: 99.8%, board accuracy: 83.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.376499, G loss: 0.725260, D accuracy: 53.1%, cell accuracy: 99.7%, board accuracy: 80.2% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3625, G loss: 0.7363\n",
      "[84/1762] D loss: 1.3570, G loss: 0.7245\n",
      "[164/1762] D loss: 1.3869, G loss: 0.6848\n",
      "[244/1762] D loss: 1.3879, G loss: 0.6600\n",
      "[324/1762] D loss: 1.3652, G loss: 0.7431\n",
      "[404/1762] D loss: 1.3812, G loss: 0.7377\n",
      "[484/1762] D loss: 1.3809, G loss: 0.6712\n",
      "[564/1762] D loss: 1.3891, G loss: 0.6769\n",
      "[644/1762] D loss: 1.3983, G loss: 0.6001\n",
      "[724/1762] D loss: 1.3698, G loss: 0.7648\n",
      "[804/1762] D loss: 1.3880, G loss: 0.6808\n",
      "[884/1762] D loss: 1.3899, G loss: 0.7475\n",
      "[964/1762] D loss: 1.3764, G loss: 0.7348\n",
      "[1044/1762] D loss: 1.3629, G loss: 0.6629\n",
      "[1124/1762] D loss: 1.3555, G loss: 0.7092\n",
      "[1204/1762] D loss: 1.3605, G loss: 0.6655\n",
      "[1284/1762] D loss: 1.3943, G loss: 0.6379\n",
      "[1364/1762] D loss: 1.3898, G loss: 0.6373\n",
      "[1444/1762] D loss: 1.3465, G loss: 0.6883\n",
      "[1524/1762] D loss: 1.3916, G loss: 0.7297\n",
      "[1604/1762] D loss: 1.3596, G loss: 0.6933\n",
      "[1684/1762] D loss: 1.3877, G loss: 0.6727\n",
      "[1762/1762] D loss: 1.3960, G loss: 0.7694\n",
      "train error: \n",
      " D loss: 1.376041, G loss: 0.674829, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 84.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.373341, G loss: 0.676998, D accuracy: 54.3%, cell accuracy: 99.7%, board accuracy: 82.0% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3865, G loss: 0.6497\n",
      "[84/1762] D loss: 1.3797, G loss: 0.7480\n",
      "[164/1762] D loss: 1.3854, G loss: 0.7083\n",
      "[244/1762] D loss: 1.3433, G loss: 0.6695\n",
      "[324/1762] D loss: 1.4185, G loss: 0.7500\n",
      "[404/1762] D loss: 1.3881, G loss: 0.7110\n",
      "[484/1762] D loss: 1.3893, G loss: 0.6376\n",
      "[564/1762] D loss: 1.3704, G loss: 0.7929\n",
      "[644/1762] D loss: 1.3554, G loss: 0.6708\n",
      "[724/1762] D loss: 1.4135, G loss: 0.6529\n",
      "[804/1762] D loss: 1.3886, G loss: 0.6908\n",
      "[884/1762] D loss: 1.3936, G loss: 0.7338\n",
      "[964/1762] D loss: 1.3895, G loss: 0.6519\n",
      "[1044/1762] D loss: 1.3913, G loss: 0.6931\n",
      "[1124/1762] D loss: 1.3668, G loss: 0.6482\n",
      "[1204/1762] D loss: 1.3700, G loss: 0.5909\n",
      "[1284/1762] D loss: 1.5103, G loss: 0.6424\n",
      "[1364/1762] D loss: 1.4209, G loss: 0.6255\n",
      "[1444/1762] D loss: 1.3351, G loss: 0.7302\n",
      "[1524/1762] D loss: 1.3278, G loss: 0.7624\n",
      "[1604/1762] D loss: 1.3178, G loss: 0.6816\n",
      "[1684/1762] D loss: 1.3680, G loss: 0.8631\n",
      "[1762/1762] D loss: 1.3908, G loss: 0.6662\n",
      "train error: \n",
      " D loss: 1.391120, G loss: 0.722519, D accuracy: 50.8%, cell accuracy: 99.8%, board accuracy: 81.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.391578, G loss: 0.722046, D accuracy: 49.8%, cell accuracy: 99.7%, board accuracy: 77.5% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4049, G loss: 0.7075\n",
      "[84/1762] D loss: 1.3963, G loss: 0.6659\n",
      "[164/1762] D loss: 1.4101, G loss: 0.6615\n",
      "[244/1762] D loss: 1.3892, G loss: 0.7059\n",
      "[324/1762] D loss: 1.3936, G loss: 0.6825\n",
      "[404/1762] D loss: 1.3826, G loss: 0.6533\n",
      "[484/1762] D loss: 1.3904, G loss: 0.6992\n",
      "[564/1762] D loss: 1.3750, G loss: 0.7172\n",
      "[644/1762] D loss: 1.3940, G loss: 0.6160\n",
      "[724/1762] D loss: 1.3759, G loss: 0.6664\n",
      "[804/1762] D loss: 1.3924, G loss: 0.6474\n",
      "[884/1762] D loss: 1.3866, G loss: 0.6937\n",
      "[964/1762] D loss: 1.3794, G loss: 0.6866\n",
      "[1044/1762] D loss: 1.3893, G loss: 0.6863\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.7229\n",
      "[1204/1762] D loss: 1.3552, G loss: 0.7033\n",
      "[1284/1762] D loss: 1.3872, G loss: 0.6971\n",
      "[1364/1762] D loss: 1.3667, G loss: 0.6944\n",
      "[1444/1762] D loss: 1.3985, G loss: 0.6576\n",
      "[1524/1762] D loss: 1.3899, G loss: 0.6518\n",
      "[1604/1762] D loss: 1.3918, G loss: 0.7423\n",
      "[1684/1762] D loss: 1.3961, G loss: 0.7032\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.6917\n",
      "train error: \n",
      " D loss: 1.381533, G loss: 0.719084, D accuracy: 52.5%, cell accuracy: 99.8%, board accuracy: 87.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.379960, G loss: 0.720134, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 84.5% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4108, G loss: 0.7218\n",
      "[84/1762] D loss: 1.3562, G loss: 0.6807\n",
      "[164/1762] D loss: 1.3860, G loss: 0.6760\n",
      "[244/1762] D loss: 1.3866, G loss: 0.6982\n",
      "[324/1762] D loss: 1.3538, G loss: 0.7663\n",
      "[404/1762] D loss: 1.3880, G loss: 0.7024\n",
      "[484/1762] D loss: 1.3432, G loss: 0.7223\n",
      "[564/1762] D loss: 1.3335, G loss: 0.7073\n",
      "[644/1762] D loss: 1.3871, G loss: 0.7122\n",
      "[724/1762] D loss: 1.4031, G loss: 0.7082\n",
      "[804/1762] D loss: 1.3895, G loss: 0.6714\n",
      "[884/1762] D loss: 1.3964, G loss: 0.6774\n",
      "[964/1762] D loss: 1.3930, G loss: 0.6205\n",
      "[1044/1762] D loss: 1.3874, G loss: 0.6888\n",
      "[1124/1762] D loss: 1.3870, G loss: 0.7285\n",
      "[1204/1762] D loss: 1.3858, G loss: 0.6609\n",
      "[1284/1762] D loss: 1.2969, G loss: 0.7854\n",
      "[1364/1762] D loss: 1.3883, G loss: 0.6581\n",
      "[1444/1762] D loss: 1.3915, G loss: 0.8308\n",
      "[1524/1762] D loss: 1.3855, G loss: 0.6885\n",
      "[1604/1762] D loss: 1.4022, G loss: 0.5993\n",
      "[1684/1762] D loss: 1.3311, G loss: 0.6326\n",
      "[1762/1762] D loss: 1.3929, G loss: 0.7405\n",
      "train error: \n",
      " D loss: 1.373083, G loss: 0.673229, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 86.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.367975, G loss: 0.678086, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 82.5% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3340, G loss: 0.7135\n",
      "[84/1762] D loss: 1.3906, G loss: 0.7754\n",
      "[164/1762] D loss: 1.3878, G loss: 0.7163\n",
      "[244/1762] D loss: 1.3913, G loss: 0.7345\n",
      "[324/1762] D loss: 1.3991, G loss: 0.8084\n",
      "[404/1762] D loss: 1.3176, G loss: 0.7462\n",
      "[484/1762] D loss: 1.3202, G loss: 0.7290\n",
      "[564/1762] D loss: 1.3426, G loss: 0.6942\n",
      "[644/1762] D loss: 1.3884, G loss: 0.6816\n",
      "[724/1762] D loss: 1.3906, G loss: 0.6374\n",
      "[804/1762] D loss: 1.4077, G loss: 0.7828\n",
      "[884/1762] D loss: 1.3932, G loss: 0.7142\n",
      "[964/1762] D loss: 1.3933, G loss: 0.7579\n",
      "[1044/1762] D loss: 1.3951, G loss: 0.6258\n",
      "[1124/1762] D loss: 1.3935, G loss: 0.6160\n",
      "[1204/1762] D loss: 1.3914, G loss: 0.7644\n",
      "[1284/1762] D loss: 1.3046, G loss: 0.7675\n",
      "[1364/1762] D loss: 1.3055, G loss: 0.7717\n",
      "[1444/1762] D loss: 1.3896, G loss: 0.7186\n",
      "[1524/1762] D loss: 1.3911, G loss: 0.6842\n",
      "[1604/1762] D loss: 1.4072, G loss: 0.7448\n",
      "[1684/1762] D loss: 1.3975, G loss: 0.6596\n",
      "[1762/1762] D loss: 1.3901, G loss: 0.6883\n",
      "train error: \n",
      " D loss: 1.371830, G loss: 0.633063, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.366722, G loss: 0.636627, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 82.7% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3959, G loss: 0.6102\n",
      "[84/1762] D loss: 1.2957, G loss: 0.7625\n",
      "[164/1762] D loss: 1.3873, G loss: 0.7350\n",
      "[244/1762] D loss: 1.4210, G loss: 0.6918\n",
      "[324/1762] D loss: 1.4159, G loss: 0.7550\n",
      "[404/1762] D loss: 1.3911, G loss: 0.7478\n",
      "[484/1762] D loss: 1.4056, G loss: 0.6327\n",
      "[564/1762] D loss: 1.2381, G loss: 0.7617\n",
      "[644/1762] D loss: 1.5224, G loss: 0.6736\n",
      "[724/1762] D loss: 1.4157, G loss: 0.8410\n",
      "[804/1762] D loss: 1.2988, G loss: 0.7806\n",
      "[884/1762] D loss: 1.3804, G loss: 0.8295\n",
      "[964/1762] D loss: 1.4115, G loss: 0.6328\n",
      "[1044/1762] D loss: 1.3698, G loss: 0.6894\n",
      "[1124/1762] D loss: 1.3900, G loss: 0.6972\n",
      "[1204/1762] D loss: 1.3706, G loss: 0.6447\n",
      "[1284/1762] D loss: 1.3939, G loss: 0.6104\n",
      "[1364/1762] D loss: 1.3394, G loss: 0.7701\n",
      "[1444/1762] D loss: 1.3552, G loss: 0.7588\n",
      "[1524/1762] D loss: 1.3847, G loss: 0.6924\n",
      "[1604/1762] D loss: 1.3746, G loss: 0.7478\n",
      "[1684/1762] D loss: 1.3877, G loss: 0.6474\n",
      "[1762/1762] D loss: 1.3985, G loss: 0.6387\n",
      "train error: \n",
      " D loss: 1.380003, G loss: 0.727057, D accuracy: 52.6%, cell accuracy: 99.8%, board accuracy: 87.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.377284, G loss: 0.731278, D accuracy: 52.7%, cell accuracy: 99.8%, board accuracy: 84.1% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3871, G loss: 0.7576\n",
      "[84/1762] D loss: 1.3446, G loss: 0.7098\n",
      "[164/1762] D loss: 1.3905, G loss: 0.6490\n",
      "[244/1762] D loss: 1.3966, G loss: 0.7569\n",
      "[324/1762] D loss: 1.3532, G loss: 0.6729\n",
      "[404/1762] D loss: 1.3913, G loss: 0.6613\n",
      "[484/1762] D loss: 1.3914, G loss: 0.6468\n",
      "[564/1762] D loss: 1.3884, G loss: 0.7263\n",
      "[644/1762] D loss: 1.3922, G loss: 0.7000\n",
      "[724/1762] D loss: 1.3450, G loss: 0.7310\n",
      "[804/1762] D loss: 1.3899, G loss: 0.7453\n",
      "[884/1762] D loss: 1.3737, G loss: 0.6733\n",
      "[964/1762] D loss: 1.3986, G loss: 0.6780\n",
      "[1044/1762] D loss: 1.3241, G loss: 0.7502\n",
      "[1124/1762] D loss: 1.3867, G loss: 0.6903\n",
      "[1204/1762] D loss: 1.3887, G loss: 0.6891\n",
      "[1284/1762] D loss: 1.4383, G loss: 0.6510\n",
      "[1364/1762] D loss: 1.5754, G loss: 0.6801\n",
      "[1444/1762] D loss: 1.4646, G loss: 0.8243\n",
      "[1524/1762] D loss: 1.3900, G loss: 0.6480\n",
      "[1604/1762] D loss: 1.3272, G loss: 0.7103\n",
      "[1684/1762] D loss: 1.4090, G loss: 0.8355\n",
      "[1762/1762] D loss: 1.4168, G loss: 0.6433\n",
      "train error: \n",
      " D loss: 1.418195, G loss: 0.610981, D accuracy: 47.7%, cell accuracy: 99.8%, board accuracy: 76.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.420296, G loss: 0.611329, D accuracy: 47.2%, cell accuracy: 99.7%, board accuracy: 76.8% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4690, G loss: 0.5874\n",
      "[84/1762] D loss: 1.4657, G loss: 0.6902\n",
      "[164/1762] D loss: 1.4302, G loss: 0.6915\n",
      "[244/1762] D loss: 1.4216, G loss: 0.6699\n",
      "[324/1762] D loss: 1.3974, G loss: 0.7188\n",
      "[404/1762] D loss: 1.3968, G loss: 0.7909\n",
      "[484/1762] D loss: 1.4076, G loss: 0.7448\n",
      "[564/1762] D loss: 1.3882, G loss: 0.6817\n",
      "[644/1762] D loss: 1.3885, G loss: 0.6414\n",
      "[724/1762] D loss: 1.3879, G loss: 0.7284\n",
      "[804/1762] D loss: 1.4038, G loss: 0.6678\n",
      "[884/1762] D loss: 1.3885, G loss: 0.7190\n",
      "[964/1762] D loss: 1.4067, G loss: 0.6353\n",
      "[1044/1762] D loss: 1.3874, G loss: 0.7198\n",
      "[1124/1762] D loss: 1.3852, G loss: 0.6734\n",
      "[1204/1762] D loss: 1.3846, G loss: 0.7261\n",
      "[1284/1762] D loss: 1.3698, G loss: 0.7218\n",
      "[1364/1762] D loss: 1.3867, G loss: 0.6836\n",
      "[1444/1762] D loss: 1.3852, G loss: 0.6888\n",
      "[1524/1762] D loss: 1.3734, G loss: 0.6947\n",
      "[1604/1762] D loss: 1.3772, G loss: 0.6824\n",
      "[1684/1762] D loss: 1.3516, G loss: 0.6869\n",
      "[1762/1762] D loss: 1.3875, G loss: 0.6700\n",
      "train error: \n",
      " D loss: 1.378308, G loss: 0.693460, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 74.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.377535, G loss: 0.694079, D accuracy: 54.9%, cell accuracy: 99.7%, board accuracy: 73.2% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3870, G loss: 0.7021\n",
      "[84/1762] D loss: 1.3868, G loss: 0.6599\n",
      "[164/1762] D loss: 1.3659, G loss: 0.7059\n",
      "[244/1762] D loss: 1.3752, G loss: 0.6436\n",
      "[324/1762] D loss: 1.3295, G loss: 0.7682\n",
      "[404/1762] D loss: 1.3877, G loss: 0.6881\n",
      "[484/1762] D loss: 1.3681, G loss: 0.7093\n",
      "[564/1762] D loss: 1.3877, G loss: 0.7261\n",
      "[644/1762] D loss: 1.3600, G loss: 0.6651\n",
      "[724/1762] D loss: 1.3942, G loss: 0.7699\n",
      "[804/1762] D loss: 1.3880, G loss: 0.7263\n",
      "[884/1762] D loss: 1.3901, G loss: 0.7093\n",
      "[964/1762] D loss: 1.3657, G loss: 0.6685\n",
      "[1044/1762] D loss: 1.3767, G loss: 0.6820\n",
      "[1124/1762] D loss: 1.3454, G loss: 0.7615\n",
      "[1204/1762] D loss: 1.3557, G loss: 0.6662\n",
      "[1284/1762] D loss: 1.3580, G loss: 0.7567\n",
      "[1364/1762] D loss: 1.3972, G loss: 0.6342\n",
      "[1444/1762] D loss: 1.3588, G loss: 0.7169\n",
      "[1524/1762] D loss: 1.3861, G loss: 0.7169\n",
      "[1604/1762] D loss: 1.3907, G loss: 0.7307\n",
      "[1684/1762] D loss: 1.3986, G loss: 0.6873\n",
      "[1762/1762] D loss: 1.2985, G loss: 0.7988\n",
      "train error: \n",
      " D loss: 1.376643, G loss: 0.713560, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.372941, G loss: 0.717295, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 85.2% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3910, G loss: 0.7167\n",
      "[84/1762] D loss: 1.3872, G loss: 0.6924\n",
      "[164/1762] D loss: 1.3904, G loss: 0.7075\n",
      "[244/1762] D loss: 1.3882, G loss: 0.6965\n",
      "[324/1762] D loss: 1.3893, G loss: 0.7386\n",
      "[404/1762] D loss: 1.3883, G loss: 0.6489\n",
      "[484/1762] D loss: 1.3882, G loss: 0.7135\n",
      "[564/1762] D loss: 1.3883, G loss: 0.7166\n",
      "[644/1762] D loss: 1.4567, G loss: 0.6171\n",
      "[724/1762] D loss: 1.4544, G loss: 0.5265\n",
      "[804/1762] D loss: 1.3895, G loss: 0.7213\n",
      "[884/1762] D loss: 1.2948, G loss: 0.6694\n",
      "[964/1762] D loss: 1.3377, G loss: 0.7244\n",
      "[1044/1762] D loss: 1.3922, G loss: 0.7540\n",
      "[1124/1762] D loss: 1.4231, G loss: 0.6908\n",
      "[1204/1762] D loss: 1.4191, G loss: 0.6932\n",
      "[1284/1762] D loss: 1.3900, G loss: 0.6506\n",
      "[1364/1762] D loss: 1.3952, G loss: 0.7621\n",
      "[1444/1762] D loss: 1.3881, G loss: 0.7287\n",
      "[1524/1762] D loss: 1.3874, G loss: 0.6865\n",
      "[1604/1762] D loss: 1.3880, G loss: 0.6656\n",
      "[1684/1762] D loss: 1.3985, G loss: 0.6764\n",
      "[1762/1762] D loss: 1.3875, G loss: 0.7148\n",
      "train error: \n",
      " D loss: 1.391091, G loss: 0.697964, D accuracy: 48.3%, cell accuracy: 99.8%, board accuracy: 88.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.391877, G loss: 0.699326, D accuracy: 47.6%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4026, G loss: 0.6818\n",
      "[84/1762] D loss: 1.4054, G loss: 0.6573\n",
      "[164/1762] D loss: 1.3873, G loss: 0.6918\n",
      "[244/1762] D loss: 1.3877, G loss: 0.6717\n",
      "[324/1762] D loss: 1.3874, G loss: 0.7027\n",
      "[404/1762] D loss: 1.3885, G loss: 0.6719\n",
      "[484/1762] D loss: 1.3711, G loss: 0.7628\n",
      "[564/1762] D loss: 1.3785, G loss: 0.6732\n",
      "[644/1762] D loss: 1.3868, G loss: 0.6906\n",
      "[724/1762] D loss: 1.3883, G loss: 0.7270\n",
      "[804/1762] D loss: 1.3824, G loss: 0.6552\n",
      "[884/1762] D loss: 1.3900, G loss: 0.7179\n",
      "[964/1762] D loss: 1.3485, G loss: 0.7394\n",
      "[1044/1762] D loss: 1.3873, G loss: 0.6919\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.7130\n",
      "[1204/1762] D loss: 1.3880, G loss: 0.6782\n",
      "[1284/1762] D loss: 1.3867, G loss: 0.6964\n",
      "[1364/1762] D loss: 1.3876, G loss: 0.6900\n",
      "[1444/1762] D loss: 1.3869, G loss: 0.7012\n",
      "[1524/1762] D loss: 1.3890, G loss: 0.6739\n",
      "[1604/1762] D loss: 1.3732, G loss: 0.6996\n",
      "[1684/1762] D loss: 1.3892, G loss: 0.6866\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6864\n",
      "train error: \n",
      " D loss: 1.379003, G loss: 0.688579, D accuracy: 52.3%, cell accuracy: 99.8%, board accuracy: 86.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.376831, G loss: 0.691296, D accuracy: 52.3%, cell accuracy: 99.8%, board accuracy: 84.8% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3876, G loss: 0.6834\n",
      "[84/1762] D loss: 1.3546, G loss: 0.7049\n",
      "[164/1762] D loss: 1.3751, G loss: 0.6934\n",
      "[244/1762] D loss: 1.3501, G loss: 0.6944\n",
      "[324/1762] D loss: 1.3861, G loss: 0.7156\n",
      "[404/1762] D loss: 1.3934, G loss: 0.7434\n",
      "[484/1762] D loss: 1.3874, G loss: 0.6762\n",
      "[564/1762] D loss: 1.3912, G loss: 0.7167\n",
      "[644/1762] D loss: 1.3868, G loss: 0.6971\n",
      "[724/1762] D loss: 1.3857, G loss: 0.7668\n",
      "[804/1762] D loss: 1.3877, G loss: 0.7131\n",
      "[884/1762] D loss: 1.3925, G loss: 0.6693\n",
      "[964/1762] D loss: 1.3885, G loss: 0.6971\n",
      "[1044/1762] D loss: 1.3930, G loss: 0.6930\n",
      "[1124/1762] D loss: 1.3758, G loss: 0.7905\n",
      "[1204/1762] D loss: 1.3885, G loss: 0.6889\n",
      "[1284/1762] D loss: 1.3284, G loss: 0.7046\n",
      "[1364/1762] D loss: 1.3319, G loss: 0.7059\n",
      "[1444/1762] D loss: 1.3896, G loss: 0.6919\n",
      "[1524/1762] D loss: 1.3904, G loss: 0.6058\n",
      "[1604/1762] D loss: 1.3934, G loss: 0.6671\n",
      "[1684/1762] D loss: 1.3880, G loss: 0.6868\n",
      "[1762/1762] D loss: 1.3336, G loss: 0.7135\n",
      "train error: \n",
      " D loss: 1.374679, G loss: 0.754497, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 85.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.370115, G loss: 0.758273, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 83.6% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3928, G loss: 0.7870\n",
      "[84/1762] D loss: 1.3936, G loss: 0.6735\n",
      "[164/1762] D loss: 1.4142, G loss: 0.6425\n",
      "[244/1762] D loss: 1.3149, G loss: 0.7573\n",
      "[324/1762] D loss: 1.2502, G loss: 0.7908\n",
      "[404/1762] D loss: 1.3911, G loss: 0.6594\n",
      "[484/1762] D loss: 1.3356, G loss: 0.7061\n",
      "[564/1762] D loss: 1.3542, G loss: 0.7178\n",
      "[644/1762] D loss: 1.3976, G loss: 0.6318\n",
      "[724/1762] D loss: 1.2497, G loss: 0.7946\n",
      "[804/1762] D loss: 1.3496, G loss: 0.7323\n",
      "[884/1762] D loss: 1.3935, G loss: 0.6473\n",
      "[964/1762] D loss: 1.3866, G loss: 0.6427\n",
      "[1044/1762] D loss: 1.3887, G loss: 0.7213\n",
      "[1124/1762] D loss: 1.3898, G loss: 0.7691\n",
      "[1204/1762] D loss: 1.3904, G loss: 0.6440\n",
      "[1284/1762] D loss: 1.3171, G loss: 0.7249\n",
      "[1364/1762] D loss: 1.3902, G loss: 0.7210\n",
      "[1444/1762] D loss: 1.3891, G loss: 0.6721\n",
      "[1524/1762] D loss: 1.4040, G loss: 0.7667\n",
      "[1604/1762] D loss: 1.3614, G loss: 0.7882\n",
      "[1684/1762] D loss: 1.3865, G loss: 0.6911\n",
      "[1762/1762] D loss: 1.3922, G loss: 0.6563\n",
      "train error: \n",
      " D loss: 1.364406, G loss: 0.704918, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 85.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.358706, G loss: 0.709715, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 83.9% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3012, G loss: 0.7095\n",
      "[84/1762] D loss: 1.3923, G loss: 0.7032\n",
      "[164/1762] D loss: 1.3892, G loss: 0.6816\n",
      "[244/1762] D loss: 1.3869, G loss: 0.6969\n",
      "[324/1762] D loss: 1.2952, G loss: 0.7188\n",
      "[404/1762] D loss: 1.5359, G loss: 0.7197\n",
      "[484/1762] D loss: 1.5121, G loss: 1.0176\n",
      "[564/1762] D loss: 1.4210, G loss: 0.7206\n",
      "[644/1762] D loss: 1.3832, G loss: 0.6721\n",
      "[724/1762] D loss: 1.3891, G loss: 0.6714\n",
      "[804/1762] D loss: 1.3941, G loss: 0.7316\n",
      "[884/1762] D loss: 1.3892, G loss: 0.7092\n",
      "[964/1762] D loss: 1.3931, G loss: 0.7536\n",
      "[1044/1762] D loss: 1.3965, G loss: 0.7457\n",
      "[1124/1762] D loss: 1.3856, G loss: 0.7259\n",
      "[1204/1762] D loss: 1.3837, G loss: 0.7194\n",
      "[1284/1762] D loss: 1.3938, G loss: 0.6915\n",
      "[1364/1762] D loss: 1.3886, G loss: 0.6994\n",
      "[1444/1762] D loss: 1.3798, G loss: 0.7148\n",
      "[1524/1762] D loss: 1.3869, G loss: 0.7133\n",
      "[1604/1762] D loss: 1.3876, G loss: 0.6801\n",
      "[1684/1762] D loss: 1.3879, G loss: 0.6677\n",
      "[1762/1762] D loss: 1.3890, G loss: 0.6795\n",
      "train error: \n",
      " D loss: 1.383991, G loss: 0.679942, D accuracy: 52.4%, cell accuracy: 99.8%, board accuracy: 88.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.383597, G loss: 0.681466, D accuracy: 52.7%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3873, G loss: 0.6758\n",
      "[84/1762] D loss: 1.3877, G loss: 0.6822\n",
      "[164/1762] D loss: 1.3864, G loss: 0.6774\n",
      "[244/1762] D loss: 1.3809, G loss: 0.7117\n",
      "[324/1762] D loss: 1.3867, G loss: 0.6927\n",
      "[404/1762] D loss: 1.3868, G loss: 0.6766\n",
      "[484/1762] D loss: 1.3847, G loss: 0.6784\n",
      "[564/1762] D loss: 1.3869, G loss: 0.6841\n",
      "[644/1762] D loss: 1.3827, G loss: 0.6962\n",
      "[724/1762] D loss: 1.3875, G loss: 0.6822\n",
      "[804/1762] D loss: 1.3870, G loss: 0.7118\n",
      "[884/1762] D loss: 1.3887, G loss: 0.6799\n",
      "[964/1762] D loss: 1.3352, G loss: 0.7102\n",
      "[1044/1762] D loss: 1.3871, G loss: 0.6959\n",
      "[1124/1762] D loss: 1.3873, G loss: 0.6801\n",
      "[1204/1762] D loss: 1.3887, G loss: 0.7287\n",
      "[1284/1762] D loss: 1.3313, G loss: 0.6996\n",
      "[1364/1762] D loss: 1.3437, G loss: 0.6979\n",
      "[1444/1762] D loss: 1.3895, G loss: 0.6876\n",
      "[1524/1762] D loss: 1.3879, G loss: 0.7108\n",
      "[1604/1762] D loss: 1.3795, G loss: 0.6969\n",
      "[1684/1762] D loss: 1.3594, G loss: 0.7049\n",
      "[1762/1762] D loss: 1.2211, G loss: 0.7739\n",
      "train error: \n",
      " D loss: 1.368938, G loss: 0.702828, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.364057, G loss: 0.706163, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 85.2% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3871, G loss: 0.6984\n",
      "[84/1762] D loss: 1.3888, G loss: 0.7285\n",
      "[164/1762] D loss: 1.3858, G loss: 0.6935\n",
      "[244/1762] D loss: 1.3896, G loss: 0.6723\n",
      "[324/1762] D loss: 1.3935, G loss: 0.7540\n",
      "[404/1762] D loss: 1.3869, G loss: 0.6807\n",
      "[484/1762] D loss: 1.3890, G loss: 0.7074\n",
      "[564/1762] D loss: 1.3993, G loss: 0.8044\n",
      "[644/1762] D loss: 1.3916, G loss: 0.6387\n",
      "[724/1762] D loss: 1.3889, G loss: 0.7400\n",
      "[804/1762] D loss: 1.3909, G loss: 0.7518\n",
      "[884/1762] D loss: 1.3884, G loss: 0.7244\n",
      "[964/1762] D loss: 1.1766, G loss: 0.8103\n",
      "[1044/1762] D loss: 1.3847, G loss: 0.6302\n",
      "[1124/1762] D loss: 1.3971, G loss: 0.7553\n",
      "[1204/1762] D loss: 1.4058, G loss: 0.7014\n",
      "[1284/1762] D loss: 1.5452, G loss: 0.9005\n",
      "[1364/1762] D loss: 1.3502, G loss: 0.7978\n",
      "[1444/1762] D loss: 1.3301, G loss: 0.7310\n",
      "[1524/1762] D loss: 1.4023, G loss: 0.7309\n",
      "[1604/1762] D loss: 1.3887, G loss: 0.6676\n",
      "[1684/1762] D loss: 1.4012, G loss: 0.7150\n",
      "[1762/1762] D loss: 1.3886, G loss: 0.7378\n",
      "train error: \n",
      " D loss: 1.389043, G loss: 0.702497, D accuracy: 49.0%, cell accuracy: 99.8%, board accuracy: 79.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.389470, G loss: 0.703068, D accuracy: 48.5%, cell accuracy: 99.7%, board accuracy: 77.0% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4051, G loss: 0.6992\n",
      "[84/1762] D loss: 1.3939, G loss: 0.6918\n",
      "[164/1762] D loss: 1.3865, G loss: 0.6899\n",
      "[244/1762] D loss: 1.3891, G loss: 0.6836\n",
      "[324/1762] D loss: 1.3866, G loss: 0.7004\n",
      "[404/1762] D loss: 1.3858, G loss: 0.6971\n",
      "[484/1762] D loss: 1.3866, G loss: 0.6937\n",
      "[564/1762] D loss: 1.3865, G loss: 0.6922\n",
      "[644/1762] D loss: 1.3865, G loss: 0.6945\n",
      "[724/1762] D loss: 1.3866, G loss: 0.6995\n",
      "[804/1762] D loss: 1.3863, G loss: 0.6979\n",
      "[884/1762] D loss: 1.3893, G loss: 0.6934\n",
      "[964/1762] D loss: 1.3865, G loss: 0.6903\n",
      "[1044/1762] D loss: 1.3851, G loss: 0.6984\n",
      "[1124/1762] D loss: 1.3855, G loss: 0.6949\n",
      "[1204/1762] D loss: 1.3865, G loss: 0.6897\n",
      "[1284/1762] D loss: 1.3857, G loss: 0.6986\n",
      "[1364/1762] D loss: 1.3873, G loss: 0.6964\n",
      "[1444/1762] D loss: 1.3880, G loss: 0.6863\n",
      "[1524/1762] D loss: 1.3865, G loss: 0.6920\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6897\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6894\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6989\n",
      "train error: \n",
      " D loss: 1.386763, G loss: 0.692745, D accuracy: 49.1%, cell accuracy: 99.8%, board accuracy: 86.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.386814, G loss: 0.692978, D accuracy: 49.2%, cell accuracy: 99.8%, board accuracy: 83.9% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3870, G loss: 0.6844\n",
      "[84/1762] D loss: 1.3866, G loss: 0.6904\n",
      "[164/1762] D loss: 1.3864, G loss: 0.6867\n",
      "[244/1762] D loss: 1.3883, G loss: 0.6918\n",
      "[324/1762] D loss: 1.3857, G loss: 0.6942\n",
      "[404/1762] D loss: 1.3883, G loss: 0.6892\n",
      "[484/1762] D loss: 1.3878, G loss: 0.6870\n",
      "[564/1762] D loss: 1.3863, G loss: 0.6945\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6876\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6874\n",
      "[804/1762] D loss: 1.3863, G loss: 0.6952\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6928\n",
      "[964/1762] D loss: 1.3863, G loss: 0.6880\n",
      "[1044/1762] D loss: 1.3871, G loss: 0.6907\n",
      "[1124/1762] D loss: 1.3873, G loss: 0.6955\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6909\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6952\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6923\n",
      "[1444/1762] D loss: 1.3869, G loss: 0.6926\n",
      "[1524/1762] D loss: 1.3862, G loss: 0.6941\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6958\n",
      "[1684/1762] D loss: 1.3868, G loss: 0.6906\n",
      "[1762/1762] D loss: 1.3884, G loss: 0.6900\n",
      "train error: \n",
      " D loss: 1.386457, G loss: 0.692156, D accuracy: 49.2%, cell accuracy: 99.8%, board accuracy: 86.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.386471, G loss: 0.692538, D accuracy: 49.4%, cell accuracy: 99.8%, board accuracy: 82.7% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6915\n",
      "[84/1762] D loss: 1.3862, G loss: 0.6949\n",
      "[164/1762] D loss: 1.3870, G loss: 0.6949\n",
      "[244/1762] D loss: 1.3862, G loss: 0.6905\n",
      "[324/1762] D loss: 1.3865, G loss: 0.6930\n",
      "[404/1762] D loss: 1.3863, G loss: 0.6926\n",
      "[484/1762] D loss: 1.3863, G loss: 0.6907\n",
      "[564/1762] D loss: 1.3858, G loss: 0.6991\n",
      "[644/1762] D loss: 1.3867, G loss: 0.6967\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6901\n",
      "[804/1762] D loss: 1.3863, G loss: 0.6914\n",
      "[884/1762] D loss: 1.3857, G loss: 0.6882\n",
      "[964/1762] D loss: 1.3863, G loss: 0.6901\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.6926\n",
      "[1124/1762] D loss: 1.3867, G loss: 0.6921\n",
      "[1204/1762] D loss: 1.3856, G loss: 0.6918\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6934\n",
      "[1364/1762] D loss: 1.3858, G loss: 0.6967\n",
      "[1444/1762] D loss: 1.3870, G loss: 0.6963\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.6877\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6929\n",
      "[1684/1762] D loss: 1.3862, G loss: 0.6910\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6903\n",
      "train error: \n",
      " D loss: 1.386205, G loss: 0.691004, D accuracy: 50.9%, cell accuracy: 99.8%, board accuracy: 86.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.386166, G loss: 0.691435, D accuracy: 50.6%, cell accuracy: 99.8%, board accuracy: 84.8% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3860, G loss: 0.6843\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6963\n",
      "[164/1762] D loss: 1.3861, G loss: 0.6907\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6900\n",
      "[324/1762] D loss: 1.3844, G loss: 0.6977\n",
      "[404/1762] D loss: 1.3863, G loss: 0.6932\n",
      "[484/1762] D loss: 1.3863, G loss: 0.6916\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6920\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6909\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6941\n",
      "[804/1762] D loss: 1.3855, G loss: 0.6923\n",
      "[884/1762] D loss: 1.3862, G loss: 0.6949\n",
      "[964/1762] D loss: 1.3862, G loss: 0.6919\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6939\n",
      "[1124/1762] D loss: 1.3863, G loss: 0.6895\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6918\n",
      "[1284/1762] D loss: 1.3853, G loss: 0.6928\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6908\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6901\n",
      "[1524/1762] D loss: 1.3862, G loss: 0.6941\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6909\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6916\n",
      "[1762/1762] D loss: 1.3781, G loss: 0.6951\n",
      "train error: \n",
      " D loss: 1.385795, G loss: 0.693169, D accuracy: 52.0%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.385656, G loss: 0.693637, D accuracy: 52.3%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.6894\n",
      "[84/1762] D loss: 1.3839, G loss: 0.6947\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6969\n",
      "[244/1762] D loss: 1.3864, G loss: 0.6905\n",
      "[324/1762] D loss: 1.3824, G loss: 0.6955\n",
      "[404/1762] D loss: 1.3862, G loss: 0.6952\n",
      "[484/1762] D loss: 1.3819, G loss: 0.6974\n",
      "[564/1762] D loss: 1.3846, G loss: 0.6929\n",
      "[644/1762] D loss: 1.3864, G loss: 0.6997\n",
      "[724/1762] D loss: 1.3822, G loss: 0.6938\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6988\n",
      "[884/1762] D loss: 1.3863, G loss: 0.6981\n",
      "[964/1762] D loss: 1.3866, G loss: 0.6914\n",
      "[1044/1762] D loss: 1.3829, G loss: 0.6985\n",
      "[1124/1762] D loss: 1.3810, G loss: 0.6987\n",
      "[1204/1762] D loss: 1.3865, G loss: 0.7020\n",
      "[1284/1762] D loss: 1.3841, G loss: 0.6987\n",
      "[1364/1762] D loss: 1.3862, G loss: 0.6975\n",
      "[1444/1762] D loss: 1.3821, G loss: 0.6991\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.6894\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6971\n",
      "[1684/1762] D loss: 1.3863, G loss: 0.6919\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6975\n",
      "train error: \n",
      " D loss: 1.384858, G loss: 0.695141, D accuracy: 52.8%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.384528, G loss: 0.695486, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6957\n",
      "[84/1762] D loss: 1.3819, G loss: 0.6951\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6947\n",
      "[244/1762] D loss: 1.3864, G loss: 0.6881\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6898\n",
      "[404/1762] D loss: 1.3863, G loss: 0.6918\n",
      "[484/1762] D loss: 1.3865, G loss: 0.6895\n",
      "[564/1762] D loss: 1.3786, G loss: 0.7033\n",
      "[644/1762] D loss: 1.3785, G loss: 0.6898\n",
      "[724/1762] D loss: 1.3864, G loss: 0.6981\n",
      "[804/1762] D loss: 1.3865, G loss: 0.7002\n",
      "[884/1762] D loss: 1.3864, G loss: 0.6987\n",
      "[964/1762] D loss: 1.3878, G loss: 0.7025\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.6944\n",
      "[1124/1762] D loss: 1.3864, G loss: 0.6998\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6986\n",
      "[1284/1762] D loss: 1.3753, G loss: 0.7005\n",
      "[1364/1762] D loss: 1.3866, G loss: 0.6864\n",
      "[1444/1762] D loss: 1.3608, G loss: 0.7003\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.6905\n",
      "[1604/1762] D loss: 1.3817, G loss: 0.7090\n",
      "[1684/1762] D loss: 1.3752, G loss: 0.6923\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.6805\n",
      "train error: \n",
      " D loss: 1.382487, G loss: 0.699845, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 90.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.381581, G loss: 0.700171, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3867, G loss: 0.7006\n",
      "[84/1762] D loss: 1.3867, G loss: 0.7036\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6976\n",
      "[244/1762] D loss: 1.3868, G loss: 0.6853\n",
      "[324/1762] D loss: 1.3867, G loss: 0.7011\n",
      "[404/1762] D loss: 1.3682, G loss: 0.7072\n",
      "[484/1762] D loss: 1.3864, G loss: 0.7024\n",
      "[564/1762] D loss: 1.3634, G loss: 0.6942\n",
      "[644/1762] D loss: 1.3870, G loss: 0.6929\n",
      "[724/1762] D loss: 1.3866, G loss: 0.6918\n",
      "[804/1762] D loss: 1.3872, G loss: 0.7015\n",
      "[884/1762] D loss: 1.3485, G loss: 0.6615\n",
      "[964/1762] D loss: 1.3955, G loss: 0.6603\n",
      "[1044/1762] D loss: 1.3987, G loss: 0.6290\n",
      "[1124/1762] D loss: 1.3882, G loss: 0.7126\n",
      "[1204/1762] D loss: 1.2144, G loss: 0.8014\n",
      "[1284/1762] D loss: 1.2726, G loss: 0.7613\n",
      "[1364/1762] D loss: 1.3943, G loss: 0.7498\n",
      "[1444/1762] D loss: 1.4082, G loss: 0.7998\n",
      "[1524/1762] D loss: 1.3944, G loss: 0.7004\n",
      "[1604/1762] D loss: 1.3880, G loss: 0.7251\n",
      "[1684/1762] D loss: 1.1251, G loss: 0.7730\n",
      "[1762/1762] D loss: 1.3918, G loss: 0.7590\n",
      "train error: \n",
      " D loss: 1.356434, G loss: 0.755878, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.348644, G loss: 0.759051, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2730, G loss: 0.7713\n",
      "[84/1762] D loss: 1.3900, G loss: 0.7718\n",
      "[164/1762] D loss: 1.3851, G loss: 0.6772\n",
      "[244/1762] D loss: 1.3902, G loss: 0.7357\n",
      "[324/1762] D loss: 1.2632, G loss: 0.7668\n",
      "[404/1762] D loss: 1.5270, G loss: 0.9794\n",
      "[484/1762] D loss: 1.4140, G loss: 0.6620\n",
      "[564/1762] D loss: 1.3863, G loss: 0.6639\n",
      "[644/1762] D loss: 1.3889, G loss: 0.6821\n",
      "[724/1762] D loss: 1.3734, G loss: 0.7064\n",
      "[804/1762] D loss: 1.3656, G loss: 0.7264\n",
      "[884/1762] D loss: 1.3875, G loss: 0.6901\n",
      "[964/1762] D loss: 1.3878, G loss: 0.6754\n",
      "[1044/1762] D loss: 1.3868, G loss: 0.6837\n",
      "[1124/1762] D loss: 1.3912, G loss: 0.6993\n",
      "[1204/1762] D loss: 1.3868, G loss: 0.6853\n",
      "[1284/1762] D loss: 1.3834, G loss: 0.6976\n",
      "[1364/1762] D loss: 1.3825, G loss: 0.6777\n",
      "[1444/1762] D loss: 1.3925, G loss: 0.6796\n",
      "[1524/1762] D loss: 1.3846, G loss: 0.6967\n",
      "[1604/1762] D loss: 1.3857, G loss: 0.6758\n",
      "[1684/1762] D loss: 1.3848, G loss: 0.6982\n",
      "[1762/1762] D loss: 1.3891, G loss: 0.6986\n",
      "train error: \n",
      " D loss: 1.387413, G loss: 0.689018, D accuracy: 50.1%, cell accuracy: 99.4%, board accuracy: 46.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.387724, G loss: 0.688625, D accuracy: 49.7%, cell accuracy: 99.4%, board accuracy: 48.0% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3884, G loss: 0.6869\n",
      "[84/1762] D loss: 1.3867, G loss: 0.6868\n",
      "[164/1762] D loss: 1.3846, G loss: 0.6970\n",
      "[244/1762] D loss: 1.3826, G loss: 0.6830\n",
      "[324/1762] D loss: 1.3861, G loss: 0.7006\n",
      "[404/1762] D loss: 1.3879, G loss: 0.6973\n",
      "[484/1762] D loss: 1.3804, G loss: 0.6913\n",
      "[564/1762] D loss: 1.3877, G loss: 0.6907\n",
      "[644/1762] D loss: 1.3914, G loss: 0.6920\n",
      "[724/1762] D loss: 1.3868, G loss: 0.6871\n",
      "[804/1762] D loss: 1.3834, G loss: 0.7028\n",
      "[884/1762] D loss: 1.3785, G loss: 0.7080\n",
      "[964/1762] D loss: 1.3765, G loss: 0.6956\n",
      "[1044/1762] D loss: 1.3870, G loss: 0.6905\n",
      "[1124/1762] D loss: 1.3866, G loss: 0.6926\n",
      "[1204/1762] D loss: 1.3859, G loss: 0.6866\n",
      "[1284/1762] D loss: 1.3859, G loss: 0.6995\n",
      "[1364/1762] D loss: 1.3670, G loss: 0.6979\n",
      "[1444/1762] D loss: 1.3847, G loss: 0.6894\n",
      "[1524/1762] D loss: 1.3683, G loss: 0.7034\n",
      "[1604/1762] D loss: 1.3646, G loss: 0.6980\n",
      "[1684/1762] D loss: 1.3553, G loss: 0.6964\n",
      "[1762/1762] D loss: 1.3370, G loss: 0.6757\n",
      "train error: \n",
      " D loss: 1.369749, G loss: 0.642907, D accuracy: 53.3%, cell accuracy: 99.5%, board accuracy: 47.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.367916, G loss: 0.644220, D accuracy: 53.4%, cell accuracy: 99.4%, board accuracy: 47.5% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3487, G loss: 0.6271\n",
      "[84/1762] D loss: 1.3769, G loss: 0.7382\n",
      "[164/1762] D loss: 1.3927, G loss: 0.7644\n",
      "[244/1762] D loss: 1.3503, G loss: 0.7375\n",
      "[324/1762] D loss: 1.3064, G loss: 0.7276\n",
      "[404/1762] D loss: 1.3954, G loss: 0.7089\n",
      "[484/1762] D loss: 1.3928, G loss: 0.6325\n",
      "[564/1762] D loss: 1.2900, G loss: 0.7325\n",
      "[644/1762] D loss: 1.2532, G loss: 0.7343\n",
      "[724/1762] D loss: 1.5108, G loss: 0.5941\n",
      "[804/1762] D loss: 1.4590, G loss: 0.8484\n",
      "[884/1762] D loss: 1.4141, G loss: 0.6384\n",
      "[964/1762] D loss: 1.3944, G loss: 0.6916\n",
      "[1044/1762] D loss: 1.3723, G loss: 0.7383\n",
      "[1124/1762] D loss: 1.3648, G loss: 0.7441\n",
      "[1204/1762] D loss: 1.3499, G loss: 0.8219\n",
      "[1284/1762] D loss: 1.3697, G loss: 0.7802\n",
      "[1364/1762] D loss: 1.3543, G loss: 0.7378\n",
      "[1444/1762] D loss: 1.3742, G loss: 0.7568\n",
      "[1524/1762] D loss: 1.3899, G loss: 0.7488\n",
      "[1604/1762] D loss: 1.3903, G loss: 0.6979\n",
      "[1684/1762] D loss: 1.4046, G loss: 0.6887\n",
      "[1762/1762] D loss: 1.3931, G loss: 0.7182\n",
      "train error: \n",
      " D loss: 1.390043, G loss: 0.720912, D accuracy: 50.1%, cell accuracy: 98.6%, board accuracy: 46.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.390969, G loss: 0.721091, D accuracy: 49.9%, cell accuracy: 98.6%, board accuracy: 40.5% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3865, G loss: 0.7143\n",
      "[84/1762] D loss: 1.3876, G loss: 0.7291\n",
      "[164/1762] D loss: 1.3781, G loss: 0.7177\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6890\n",
      "[324/1762] D loss: 1.3879, G loss: 0.6846\n",
      "[404/1762] D loss: 1.3886, G loss: 0.6860\n",
      "[484/1762] D loss: 1.3870, G loss: 0.6780\n",
      "[564/1762] D loss: 1.3888, G loss: 0.6846\n",
      "[644/1762] D loss: 1.3860, G loss: 0.6793\n",
      "[724/1762] D loss: 1.3857, G loss: 0.6745\n",
      "[804/1762] D loss: 1.3901, G loss: 0.6749\n",
      "[884/1762] D loss: 1.3862, G loss: 0.6921\n",
      "[964/1762] D loss: 1.3856, G loss: 0.6832\n",
      "[1044/1762] D loss: 1.3923, G loss: 0.6927\n",
      "[1124/1762] D loss: 1.3859, G loss: 0.7074\n",
      "[1204/1762] D loss: 1.3888, G loss: 0.7124\n",
      "[1284/1762] D loss: 1.3800, G loss: 0.7004\n",
      "[1364/1762] D loss: 1.3863, G loss: 0.6823\n",
      "[1444/1762] D loss: 1.3857, G loss: 0.6832\n",
      "[1524/1762] D loss: 1.3868, G loss: 0.6870\n",
      "[1604/1762] D loss: 1.3797, G loss: 0.6824\n",
      "[1684/1762] D loss: 1.3854, G loss: 0.6907\n",
      "[1762/1762] D loss: 1.3885, G loss: 0.6810\n",
      "train error: \n",
      " D loss: 1.385518, G loss: 0.692870, D accuracy: 51.8%, cell accuracy: 99.0%, board accuracy: 35.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.385588, G loss: 0.692955, D accuracy: 51.2%, cell accuracy: 98.9%, board accuracy: 31.8% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3844, G loss: 0.6925\n",
      "[84/1762] D loss: 1.3803, G loss: 0.6959\n",
      "[164/1762] D loss: 1.3846, G loss: 0.7039\n",
      "[244/1762] D loss: 1.3865, G loss: 0.6943\n",
      "[324/1762] D loss: 1.3807, G loss: 0.7050\n",
      "[404/1762] D loss: 1.3856, G loss: 0.6881\n",
      "[484/1762] D loss: 1.3833, G loss: 0.6995\n",
      "[564/1762] D loss: 1.3863, G loss: 0.6952\n",
      "[644/1762] D loss: 1.3841, G loss: 0.6963\n",
      "[724/1762] D loss: 1.3855, G loss: 0.6995\n",
      "[804/1762] D loss: 1.3875, G loss: 0.6882\n",
      "[884/1762] D loss: 1.3865, G loss: 0.7025\n",
      "[964/1762] D loss: 1.3785, G loss: 0.6836\n",
      "[1044/1762] D loss: 1.3829, G loss: 0.6910\n",
      "[1124/1762] D loss: 1.3725, G loss: 0.6902\n",
      "[1204/1762] D loss: 1.3773, G loss: 0.6947\n",
      "[1284/1762] D loss: 1.3790, G loss: 0.6886\n",
      "[1364/1762] D loss: 1.3846, G loss: 0.6946\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.7007\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.6919\n",
      "[1604/1762] D loss: 1.3871, G loss: 0.6934\n",
      "[1684/1762] D loss: 1.3862, G loss: 0.6906\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.7079\n",
      "train error: \n",
      " D loss: 1.382428, G loss: 0.695504, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 82.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.381639, G loss: 0.695941, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 79.1% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6913\n",
      "[84/1762] D loss: 1.3855, G loss: 0.6860\n",
      "[164/1762] D loss: 1.3873, G loss: 0.6873\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6931\n",
      "[324/1762] D loss: 1.3866, G loss: 0.6951\n",
      "[404/1762] D loss: 1.3864, G loss: 0.7032\n",
      "[484/1762] D loss: 1.3865, G loss: 0.7062\n",
      "[564/1762] D loss: 1.3867, G loss: 0.7131\n",
      "[644/1762] D loss: 1.3863, G loss: 0.7151\n",
      "[724/1762] D loss: 1.3840, G loss: 0.6969\n",
      "[804/1762] D loss: 1.3874, G loss: 0.6955\n",
      "[884/1762] D loss: 1.3969, G loss: 0.6737\n",
      "[964/1762] D loss: 1.4281, G loss: 0.6790\n",
      "[1044/1762] D loss: 1.4089, G loss: 0.7084\n",
      "[1124/1762] D loss: 1.3670, G loss: 0.7433\n",
      "[1204/1762] D loss: 1.3345, G loss: 0.7504\n",
      "[1284/1762] D loss: 1.3571, G loss: 0.7030\n",
      "[1364/1762] D loss: 1.3867, G loss: 0.6757\n",
      "[1444/1762] D loss: 1.3873, G loss: 0.6939\n",
      "[1524/1762] D loss: 1.3882, G loss: 0.6877\n",
      "[1604/1762] D loss: 1.3866, G loss: 0.6928\n",
      "[1684/1762] D loss: 1.3984, G loss: 0.6962\n",
      "[1762/1762] D loss: 1.3890, G loss: 0.6831\n",
      "train error: \n",
      " D loss: 1.390999, G loss: 0.682519, D accuracy: 46.5%, cell accuracy: 99.0%, board accuracy: 34.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.392441, G loss: 0.682131, D accuracy: 45.6%, cell accuracy: 98.9%, board accuracy: 28.9% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3865, G loss: 0.6813\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6862\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6912\n",
      "[244/1762] D loss: 1.3865, G loss: 0.6819\n",
      "[324/1762] D loss: 1.3861, G loss: 0.6870\n",
      "[404/1762] D loss: 1.4002, G loss: 0.6905\n",
      "[484/1762] D loss: 1.3867, G loss: 0.6947\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6922\n",
      "[644/1762] D loss: 1.3980, G loss: 0.6988\n",
      "[724/1762] D loss: 1.3947, G loss: 0.6923\n",
      "[804/1762] D loss: 1.3882, G loss: 0.6918\n",
      "[884/1762] D loss: 1.3867, G loss: 0.6970\n",
      "[964/1762] D loss: 1.3908, G loss: 0.6940\n",
      "[1044/1762] D loss: 1.3861, G loss: 0.6910\n",
      "[1124/1762] D loss: 1.3986, G loss: 0.6940\n",
      "[1204/1762] D loss: 1.3980, G loss: 0.6910\n",
      "[1284/1762] D loss: 1.3892, G loss: 0.6920\n",
      "[1364/1762] D loss: 1.3861, G loss: 0.6966\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.6878\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.6930\n",
      "[1604/1762] D loss: 1.3866, G loss: 0.6939\n",
      "[1684/1762] D loss: 1.3862, G loss: 0.6969\n",
      "[1762/1762] D loss: 1.3857, G loss: 0.6756\n",
      "train error: \n",
      " D loss: 1.384801, G loss: 0.695539, D accuracy: 51.8%, cell accuracy: 99.7%, board accuracy: 73.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.384641, G loss: 0.695957, D accuracy: 53.3%, cell accuracy: 99.7%, board accuracy: 73.6% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.7038\n",
      "[84/1762] D loss: 1.3823, G loss: 0.6964\n",
      "[164/1762] D loss: 1.3862, G loss: 0.7007\n",
      "[244/1762] D loss: 1.3790, G loss: 0.7030\n",
      "[324/1762] D loss: 1.3854, G loss: 0.6949\n",
      "[404/1762] D loss: 1.3866, G loss: 0.6984\n",
      "[484/1762] D loss: 1.3866, G loss: 0.6933\n",
      "[564/1762] D loss: 1.3696, G loss: 0.7122\n",
      "[644/1762] D loss: 1.3863, G loss: 0.6970\n",
      "[724/1762] D loss: 1.3861, G loss: 0.6946\n",
      "[804/1762] D loss: 1.3867, G loss: 0.6997\n",
      "[884/1762] D loss: 1.3866, G loss: 0.6908\n",
      "[964/1762] D loss: 1.3731, G loss: 0.6934\n",
      "[1044/1762] D loss: 1.3699, G loss: 0.6922\n",
      "[1124/1762] D loss: 1.3763, G loss: 0.6811\n",
      "[1204/1762] D loss: 1.3857, G loss: 0.6918\n",
      "[1284/1762] D loss: 1.3823, G loss: 0.6868\n",
      "[1364/1762] D loss: 1.3869, G loss: 0.7045\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.7011\n",
      "[1524/1762] D loss: 1.3870, G loss: 0.6734\n",
      "[1604/1762] D loss: 1.3866, G loss: 0.6940\n",
      "[1684/1762] D loss: 1.3867, G loss: 0.7009\n",
      "[1762/1762] D loss: 1.3858, G loss: 0.7142\n",
      "train error: \n",
      " D loss: 1.382057, G loss: 0.697235, D accuracy: 52.3%, cell accuracy: 99.6%, board accuracy: 66.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.381324, G loss: 0.697463, D accuracy: 53.3%, cell accuracy: 99.5%, board accuracy: 61.4% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3437, G loss: 0.7021\n",
      "[84/1762] D loss: 1.4005, G loss: 0.6867\n",
      "[164/1762] D loss: 1.4019, G loss: 0.7098\n",
      "[244/1762] D loss: 1.3679, G loss: 0.7129\n",
      "[324/1762] D loss: 1.3444, G loss: 0.7288\n",
      "[404/1762] D loss: 1.3364, G loss: 0.7225\n",
      "[484/1762] D loss: 1.4272, G loss: 0.6676\n",
      "[564/1762] D loss: 1.3869, G loss: 0.6749\n",
      "[644/1762] D loss: 1.3873, G loss: 0.6898\n",
      "[724/1762] D loss: 1.4023, G loss: 0.6785\n",
      "[804/1762] D loss: 1.4007, G loss: 0.6943\n",
      "[884/1762] D loss: 1.3858, G loss: 0.6994\n",
      "[964/1762] D loss: 1.3866, G loss: 0.6789\n",
      "[1044/1762] D loss: 1.3863, G loss: 0.6915\n",
      "[1124/1762] D loss: 1.4039, G loss: 0.6838\n",
      "[1204/1762] D loss: 1.3964, G loss: 0.6879\n",
      "[1284/1762] D loss: 1.3860, G loss: 0.6910\n",
      "[1364/1762] D loss: 1.3911, G loss: 0.7012\n",
      "[1444/1762] D loss: 1.3862, G loss: 0.6861\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.6974\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6972\n",
      "[1684/1762] D loss: 1.3865, G loss: 0.7035\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.6799\n",
      "train error: \n",
      " D loss: 1.387176, G loss: 0.689045, D accuracy: 50.1%, cell accuracy: 99.8%, board accuracy: 85.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.387742, G loss: 0.688766, D accuracy: 49.9%, cell accuracy: 99.8%, board accuracy: 82.7% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6994\n",
      "[84/1762] D loss: 1.3863, G loss: 0.6811\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6938\n",
      "[244/1762] D loss: 1.3878, G loss: 0.6933\n",
      "[324/1762] D loss: 1.3864, G loss: 0.7005\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6963\n",
      "[484/1762] D loss: 1.3864, G loss: 0.7007\n",
      "[564/1762] D loss: 1.3866, G loss: 0.7020\n",
      "[644/1762] D loss: 1.3799, G loss: 0.6983\n",
      "[724/1762] D loss: 1.3868, G loss: 0.6874\n",
      "[804/1762] D loss: 1.3773, G loss: 0.6915\n",
      "[884/1762] D loss: 1.3866, G loss: 0.6917\n",
      "[964/1762] D loss: 1.3858, G loss: 0.7013\n",
      "[1044/1762] D loss: 1.3870, G loss: 0.6930\n",
      "[1124/1762] D loss: 1.3762, G loss: 0.6978\n",
      "[1204/1762] D loss: 1.3869, G loss: 0.6832\n",
      "[1284/1762] D loss: 1.3866, G loss: 0.7095\n",
      "[1364/1762] D loss: 1.3608, G loss: 0.7053\n",
      "[1444/1762] D loss: 1.3876, G loss: 0.6826\n",
      "[1524/1762] D loss: 1.3865, G loss: 0.7081\n",
      "[1604/1762] D loss: 1.3803, G loss: 0.6998\n",
      "[1684/1762] D loss: 1.3864, G loss: 0.6913\n",
      "[1762/1762] D loss: 1.3870, G loss: 0.7223\n",
      "train error: \n",
      " D loss: 1.376756, G loss: 0.710338, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 85.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.374609, G loss: 0.711182, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 83.0% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3779, G loss: 0.6946\n",
      "[84/1762] D loss: 1.3394, G loss: 0.7280\n",
      "[164/1762] D loss: 1.3624, G loss: 0.6270\n",
      "[244/1762] D loss: 1.3869, G loss: 0.7104\n",
      "[324/1762] D loss: 1.3883, G loss: 0.7199\n",
      "[404/1762] D loss: 1.3430, G loss: 0.7342\n",
      "[484/1762] D loss: 1.3866, G loss: 0.7021\n",
      "[564/1762] D loss: 1.3901, G loss: 0.7550\n",
      "[644/1762] D loss: 1.3867, G loss: 0.6999\n",
      "[724/1762] D loss: 1.3893, G loss: 0.7129\n",
      "[804/1762] D loss: 1.3328, G loss: 0.7080\n",
      "[884/1762] D loss: 1.3872, G loss: 0.7191\n",
      "[964/1762] D loss: 1.3902, G loss: 0.6902\n",
      "[1044/1762] D loss: 1.5132, G loss: 0.6920\n",
      "[1124/1762] D loss: 1.4097, G loss: 0.6625\n",
      "[1204/1762] D loss: 1.3451, G loss: 0.7310\n",
      "[1284/1762] D loss: 1.3245, G loss: 0.7266\n",
      "[1364/1762] D loss: 1.3547, G loss: 0.6742\n",
      "[1444/1762] D loss: 1.3844, G loss: 0.6863\n",
      "[1524/1762] D loss: 1.3893, G loss: 0.6767\n",
      "[1604/1762] D loss: 1.3830, G loss: 0.6871\n",
      "[1684/1762] D loss: 1.3851, G loss: 0.6839\n",
      "[1762/1762] D loss: 1.3765, G loss: 0.6951\n",
      "train error: \n",
      " D loss: 1.382959, G loss: 0.704277, D accuracy: 53.5%, cell accuracy: 98.8%, board accuracy: 6.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.383891, G loss: 0.704254, D accuracy: 54.1%, cell accuracy: 98.7%, board accuracy: 7.7% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3831, G loss: 0.6995\n",
      "[84/1762] D loss: 1.3831, G loss: 0.6947\n",
      "[164/1762] D loss: 1.3949, G loss: 0.6981\n",
      "[244/1762] D loss: 1.3866, G loss: 0.7054\n",
      "[324/1762] D loss: 1.3868, G loss: 0.7003\n",
      "[404/1762] D loss: 1.3785, G loss: 0.6842\n",
      "[484/1762] D loss: 1.3865, G loss: 0.7028\n",
      "[564/1762] D loss: 1.3866, G loss: 0.6956\n",
      "[644/1762] D loss: 1.3864, G loss: 0.7057\n",
      "[724/1762] D loss: 1.3868, G loss: 0.6923\n",
      "[804/1762] D loss: 1.3865, G loss: 0.6842\n",
      "[884/1762] D loss: 1.3833, G loss: 0.7052\n",
      "[964/1762] D loss: 1.3746, G loss: 0.6984\n",
      "[1044/1762] D loss: 1.3714, G loss: 0.7014\n",
      "[1124/1762] D loss: 1.3858, G loss: 0.7021\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6932\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6897\n",
      "[1364/1762] D loss: 1.3866, G loss: 0.7043\n",
      "[1444/1762] D loss: 1.3470, G loss: 0.7055\n",
      "[1524/1762] D loss: 1.3859, G loss: 0.6947\n",
      "[1604/1762] D loss: 1.3555, G loss: 0.7126\n",
      "[1684/1762] D loss: 1.3856, G loss: 0.7008\n",
      "[1762/1762] D loss: 1.3856, G loss: 0.6878\n",
      "train error: \n",
      " D loss: 1.377925, G loss: 0.689950, D accuracy: 52.2%, cell accuracy: 99.2%, board accuracy: 44.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.376307, G loss: 0.690573, D accuracy: 52.0%, cell accuracy: 99.2%, board accuracy: 43.4% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3574, G loss: 0.6961\n",
      "[84/1762] D loss: 1.3787, G loss: 0.7058\n",
      "[164/1762] D loss: 1.3658, G loss: 0.6989\n",
      "[244/1762] D loss: 1.3867, G loss: 0.6881\n",
      "[324/1762] D loss: 1.3857, G loss: 0.6962\n",
      "[404/1762] D loss: 1.3889, G loss: 0.6945\n",
      "[484/1762] D loss: 1.3870, G loss: 0.6898\n",
      "[564/1762] D loss: 1.3848, G loss: 0.7058\n",
      "[644/1762] D loss: 1.3873, G loss: 0.7057\n",
      "[724/1762] D loss: 1.3877, G loss: 0.7207\n",
      "[804/1762] D loss: 1.3105, G loss: 0.7425\n",
      "[884/1762] D loss: 1.3867, G loss: 0.7114\n",
      "[964/1762] D loss: 1.3861, G loss: 0.7039\n",
      "[1044/1762] D loss: 1.3179, G loss: 0.7681\n",
      "[1124/1762] D loss: 1.5413, G loss: 0.5918\n",
      "[1204/1762] D loss: 1.4559, G loss: 0.6583\n",
      "[1284/1762] D loss: 1.3123, G loss: 0.7827\n",
      "[1364/1762] D loss: 1.3265, G loss: 0.7733\n",
      "[1444/1762] D loss: 1.4092, G loss: 0.6874\n",
      "[1524/1762] D loss: 1.3735, G loss: 0.6755\n",
      "[1604/1762] D loss: 1.3568, G loss: 0.6675\n",
      "[1684/1762] D loss: 1.3751, G loss: 0.6368\n",
      "[1762/1762] D loss: 1.4441, G loss: 0.6877\n",
      "train error: \n",
      " D loss: 1.393771, G loss: 0.708798, D accuracy: 48.4%, cell accuracy: 99.4%, board accuracy: 44.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.396029, G loss: 0.706059, D accuracy: 47.6%, cell accuracy: 99.3%, board accuracy: 43.6% \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3908, G loss: 0.7348\n",
      "[84/1762] D loss: 1.3919, G loss: 0.6740\n",
      "[164/1762] D loss: 1.3883, G loss: 0.6977\n",
      "[244/1762] D loss: 1.3864, G loss: 0.7113\n",
      "[324/1762] D loss: 1.3975, G loss: 0.7021\n",
      "[404/1762] D loss: 1.3757, G loss: 0.7512\n",
      "[484/1762] D loss: 1.3866, G loss: 0.7112\n",
      "[564/1762] D loss: 1.3805, G loss: 0.6874\n",
      "[644/1762] D loss: 1.3727, G loss: 0.6920\n",
      "[724/1762] D loss: 1.3877, G loss: 0.7017\n",
      "[804/1762] D loss: 1.4046, G loss: 0.6938\n",
      "[884/1762] D loss: 1.3788, G loss: 0.7035\n",
      "[964/1762] D loss: 1.3879, G loss: 0.7025\n",
      "[1044/1762] D loss: 1.3721, G loss: 0.6841\n",
      "[1124/1762] D loss: 1.3834, G loss: 0.6880\n",
      "[1204/1762] D loss: 1.3846, G loss: 0.6943\n",
      "[1284/1762] D loss: 1.3870, G loss: 0.6627\n",
      "[1364/1762] D loss: 1.3856, G loss: 0.6943\n",
      "[1444/1762] D loss: 1.3870, G loss: 0.6881\n",
      "[1524/1762] D loss: 1.3870, G loss: 0.6692\n",
      "[1604/1762] D loss: 1.3868, G loss: 0.7079\n",
      "[1684/1762] D loss: 1.3869, G loss: 0.7028\n",
      "[1762/1762] D loss: 1.3829, G loss: 0.6669\n",
      "train error: \n",
      " D loss: 1.378996, G loss: 0.682862, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 81.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.377420, G loss: 0.682865, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 78.2% \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3584, G loss: 0.6823\n",
      "[84/1762] D loss: 1.3868, G loss: 0.7136\n",
      "[164/1762] D loss: 1.3874, G loss: 0.7095\n",
      "[244/1762] D loss: 1.3626, G loss: 0.7118\n",
      "[324/1762] D loss: 1.3869, G loss: 0.6969\n",
      "[404/1762] D loss: 1.3749, G loss: 0.7051\n",
      "[484/1762] D loss: 1.3440, G loss: 0.7251\n",
      "[564/1762] D loss: 1.3425, G loss: 0.7097\n",
      "[644/1762] D loss: 1.3874, G loss: 0.7252\n",
      "[724/1762] D loss: 1.2652, G loss: 0.7337\n",
      "[804/1762] D loss: 1.3247, G loss: 0.6904\n",
      "[884/1762] D loss: 1.3918, G loss: 0.6837\n",
      "[964/1762] D loss: 1.5189, G loss: 0.6514\n",
      "[1044/1762] D loss: 1.3464, G loss: 0.7212\n",
      "[1124/1762] D loss: 1.2877, G loss: 0.7566\n",
      "[1204/1762] D loss: 1.3620, G loss: 0.7135\n",
      "[1284/1762] D loss: 1.4338, G loss: 0.7478\n",
      "[1364/1762] D loss: 1.3856, G loss: 0.7260\n",
      "[1444/1762] D loss: 1.4102, G loss: 0.6791\n",
      "[1524/1762] D loss: 1.3872, G loss: 0.6877\n",
      "[1604/1762] D loss: 1.3863, G loss: 0.6916\n",
      "[1684/1762] D loss: 1.3866, G loss: 0.6828\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.6920\n",
      "train error: \n",
      " D loss: 1.392121, G loss: 0.689487, D accuracy: 48.1%, cell accuracy: 99.8%, board accuracy: 78.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.394293, G loss: 0.688150, D accuracy: 47.4%, cell accuracy: 99.7%, board accuracy: 75.7% \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3846, G loss: 0.7007\n",
      "[84/1762] D loss: 1.3876, G loss: 0.6915\n",
      "[164/1762] D loss: 1.3872, G loss: 0.7057\n",
      "[244/1762] D loss: 1.3867, G loss: 0.6799\n",
      "[324/1762] D loss: 1.3851, G loss: 0.6907\n",
      "[404/1762] D loss: 1.3865, G loss: 0.7016\n",
      "[484/1762] D loss: 1.3773, G loss: 0.6976\n",
      "[564/1762] D loss: 1.3864, G loss: 0.6892\n",
      "[644/1762] D loss: 1.3862, G loss: 0.6968\n",
      "[724/1762] D loss: 1.3864, G loss: 0.7010\n",
      "[804/1762] D loss: 1.3864, G loss: 0.7022\n",
      "[884/1762] D loss: 1.3864, G loss: 0.7022\n",
      "[964/1762] D loss: 1.3866, G loss: 0.6904\n",
      "[1044/1762] D loss: 1.3816, G loss: 0.6943\n",
      "[1124/1762] D loss: 1.3867, G loss: 0.6772\n",
      "[1204/1762] D loss: 1.3854, G loss: 0.6981\n",
      "[1284/1762] D loss: 1.3867, G loss: 0.7065\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6993\n",
      "[1444/1762] D loss: 1.3869, G loss: 0.6752\n",
      "[1524/1762] D loss: 1.3855, G loss: 0.6985\n",
      "[1604/1762] D loss: 1.3884, G loss: 0.7084\n",
      "[1684/1762] D loss: 1.3417, G loss: 0.6946\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.7142\n",
      "train error: \n",
      " D loss: 1.380258, G loss: 0.697886, D accuracy: 52.8%, cell accuracy: 99.8%, board accuracy: 81.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.379322, G loss: 0.698534, D accuracy: 54.0%, cell accuracy: 99.7%, board accuracy: 78.6% \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.7070\n",
      "[84/1762] D loss: 1.3864, G loss: 0.6924\n",
      "[164/1762] D loss: 1.3869, G loss: 0.6809\n",
      "[244/1762] D loss: 1.3521, G loss: 0.7017\n",
      "[324/1762] D loss: 1.3863, G loss: 0.6980\n",
      "[404/1762] D loss: 1.3869, G loss: 0.6917\n",
      "[484/1762] D loss: 1.3866, G loss: 0.7078\n",
      "[564/1762] D loss: 1.3865, G loss: 0.7081\n",
      "[644/1762] D loss: 1.3502, G loss: 0.7130\n",
      "[724/1762] D loss: 1.3731, G loss: 0.6915\n",
      "[804/1762] D loss: 1.3857, G loss: 0.6950\n",
      "[884/1762] D loss: 1.3877, G loss: 0.6926\n",
      "[964/1762] D loss: 1.3858, G loss: 0.6993\n",
      "[1044/1762] D loss: 1.3381, G loss: 0.7258\n",
      "[1124/1762] D loss: 1.3672, G loss: 0.7057\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6847\n",
      "[1284/1762] D loss: 1.3870, G loss: 0.7197\n",
      "[1364/1762] D loss: 1.3867, G loss: 0.6955\n",
      "[1444/1762] D loss: 1.3862, G loss: 0.6960\n",
      "[1524/1762] D loss: 1.3880, G loss: 0.7127\n",
      "[1604/1762] D loss: 1.3394, G loss: 0.7073\n",
      "[1684/1762] D loss: 1.3875, G loss: 0.7133\n",
      "[1762/1762] D loss: 1.2858, G loss: 0.7494\n",
      "train error: \n",
      " D loss: 1.370617, G loss: 0.706840, D accuracy: 53.2%, cell accuracy: 99.6%, board accuracy: 65.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.367007, G loss: 0.707732, D accuracy: 54.4%, cell accuracy: 99.6%, board accuracy: 66.4% \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3904, G loss: 0.6823\n",
      "[84/1762] D loss: 1.3323, G loss: 0.6843\n",
      "[164/1762] D loss: 1.3871, G loss: 0.6844\n",
      "[244/1762] D loss: 1.3877, G loss: 0.7252\n",
      "[324/1762] D loss: 1.3910, G loss: 0.7457\n",
      "[404/1762] D loss: 1.3876, G loss: 0.6793\n",
      "[484/1762] D loss: 1.3877, G loss: 0.7028\n",
      "[564/1762] D loss: 1.3894, G loss: 0.6974\n",
      "[644/1762] D loss: 1.3059, G loss: 0.7200\n",
      "[724/1762] D loss: 1.3855, G loss: 0.6979\n",
      "[804/1762] D loss: 1.3249, G loss: 0.6734\n",
      "[884/1762] D loss: 1.5603, G loss: 0.5471\n",
      "[964/1762] D loss: 1.3918, G loss: 0.7157\n",
      "[1044/1762] D loss: 1.2307, G loss: 0.7439\n",
      "[1124/1762] D loss: 1.3579, G loss: 0.6974\n",
      "[1204/1762] D loss: 1.3808, G loss: 0.6354\n",
      "[1284/1762] D loss: 1.3860, G loss: 0.6971\n",
      "[1364/1762] D loss: 1.3857, G loss: 0.6935\n",
      "[1444/1762] D loss: 1.3559, G loss: 0.7272\n",
      "[1524/1762] D loss: 1.3887, G loss: 0.7312\n",
      "[1604/1762] D loss: 1.3861, G loss: 0.6861\n",
      "[1684/1762] D loss: 1.3314, G loss: 0.7030\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.6756\n",
      "train error: \n",
      " D loss: 1.371647, G loss: 0.685268, D accuracy: 51.1%, cell accuracy: 99.8%, board accuracy: 78.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.368851, G loss: 0.686835, D accuracy: 51.4%, cell accuracy: 99.7%, board accuracy: 74.3% \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3871, G loss: 0.6674\n",
      "[84/1762] D loss: 1.3875, G loss: 0.7153\n",
      "[164/1762] D loss: 1.3737, G loss: 0.6651\n",
      "[244/1762] D loss: 1.3575, G loss: 0.7352\n",
      "[324/1762] D loss: 1.2508, G loss: 0.7407\n",
      "[404/1762] D loss: 1.3854, G loss: 0.6819\n",
      "[484/1762] D loss: 1.4743, G loss: 0.7190\n",
      "[564/1762] D loss: 1.3965, G loss: 0.7182\n",
      "[644/1762] D loss: 1.3876, G loss: 0.6618\n",
      "[724/1762] D loss: 1.3865, G loss: 0.6862\n",
      "[804/1762] D loss: 1.3869, G loss: 0.7015\n",
      "[884/1762] D loss: 1.3869, G loss: 0.6972\n",
      "[964/1762] D loss: 1.3849, G loss: 0.7175\n",
      "[1044/1762] D loss: 1.3854, G loss: 0.7114\n",
      "[1124/1762] D loss: 1.3881, G loss: 0.7118\n",
      "[1204/1762] D loss: 1.2298, G loss: 0.6976\n",
      "[1284/1762] D loss: 1.3869, G loss: 0.6816\n",
      "[1364/1762] D loss: 1.3867, G loss: 0.6820\n",
      "[1444/1762] D loss: 1.3870, G loss: 0.7072\n",
      "[1524/1762] D loss: 1.3875, G loss: 0.7111\n",
      "[1604/1762] D loss: 1.3889, G loss: 0.6916\n",
      "[1684/1762] D loss: 1.3856, G loss: 0.7069\n",
      "[1762/1762] D loss: 1.1796, G loss: 0.7686\n",
      "train error: \n",
      " D loss: 1.363971, G loss: 0.724133, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 86.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.359111, G loss: 0.725344, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 83.0% \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3872, G loss: 0.7132\n",
      "[84/1762] D loss: 1.3871, G loss: 0.6940\n",
      "[164/1762] D loss: 1.3887, G loss: 0.7415\n",
      "[244/1762] D loss: 1.3388, G loss: 0.6942\n",
      "[324/1762] D loss: 1.3875, G loss: 0.7074\n",
      "[404/1762] D loss: 1.3873, G loss: 0.6841\n",
      "[484/1762] D loss: 1.3868, G loss: 0.6859\n",
      "[564/1762] D loss: 1.3941, G loss: 0.6471\n",
      "[644/1762] D loss: 1.3890, G loss: 0.6766\n",
      "[724/1762] D loss: 1.3931, G loss: 0.7691\n",
      "[804/1762] D loss: 1.3873, G loss: 0.7062\n",
      "[884/1762] D loss: 1.3878, G loss: 0.7287\n",
      "[964/1762] D loss: 1.4406, G loss: 0.6747\n",
      "[1044/1762] D loss: 1.3418, G loss: 0.7719\n",
      "[1124/1762] D loss: 1.3441, G loss: 0.6531\n",
      "[1204/1762] D loss: 1.3376, G loss: 0.7160\n",
      "[1284/1762] D loss: 1.3822, G loss: 0.6806\n",
      "[1364/1762] D loss: 1.3861, G loss: 0.6879\n",
      "[1444/1762] D loss: 1.4467, G loss: 0.6513\n",
      "[1524/1762] D loss: 1.3798, G loss: 0.7360\n",
      "[1604/1762] D loss: 1.3861, G loss: 0.6920\n",
      "[1684/1762] D loss: 1.3887, G loss: 0.6629\n",
      "[1762/1762] D loss: 1.3905, G loss: 0.6459\n",
      "train error: \n",
      " D loss: 1.391674, G loss: 0.683477, D accuracy: 51.3%, cell accuracy: 99.4%, board accuracy: 45.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.394717, G loss: 0.683731, D accuracy: 51.6%, cell accuracy: 99.3%, board accuracy: 43.0% \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3853, G loss: 0.6943\n",
      "[84/1762] D loss: 1.4234, G loss: 0.7192\n",
      "[164/1762] D loss: 1.3847, G loss: 0.6994\n",
      "[244/1762] D loss: 1.3861, G loss: 0.6880\n",
      "[324/1762] D loss: 1.3844, G loss: 0.6786\n",
      "[404/1762] D loss: 1.3802, G loss: 0.6986\n",
      "[484/1762] D loss: 1.3866, G loss: 0.7007\n",
      "[564/1762] D loss: 1.3550, G loss: 0.6880\n",
      "[644/1762] D loss: 1.3875, G loss: 0.6547\n",
      "[724/1762] D loss: 1.3581, G loss: 0.7035\n",
      "[804/1762] D loss: 1.3866, G loss: 0.6773\n",
      "[884/1762] D loss: 1.3867, G loss: 0.7007\n",
      "[964/1762] D loss: 1.3867, G loss: 0.7188\n",
      "[1044/1762] D loss: 1.3867, G loss: 0.7065\n",
      "[1124/1762] D loss: 1.3876, G loss: 0.6979\n",
      "[1204/1762] D loss: 1.3872, G loss: 0.7103\n",
      "[1284/1762] D loss: 1.3870, G loss: 0.7020\n",
      "[1364/1762] D loss: 1.3865, G loss: 0.6970\n",
      "[1444/1762] D loss: 1.3870, G loss: 0.7171\n",
      "[1524/1762] D loss: 1.3869, G loss: 0.6909\n",
      "[1604/1762] D loss: 1.3859, G loss: 0.7110\n",
      "[1684/1762] D loss: 1.3893, G loss: 0.7521\n",
      "[1762/1762] D loss: 1.3877, G loss: 0.7305\n",
      "train error: \n",
      " D loss: 1.367558, G loss: 0.708299, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 84.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.364295, G loss: 0.708497, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 81.6% \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3891, G loss: 0.6987\n",
      "[84/1762] D loss: 1.3871, G loss: 0.7243\n",
      "[164/1762] D loss: 1.3878, G loss: 0.7124\n",
      "[244/1762] D loss: 1.3911, G loss: 0.7322\n",
      "[324/1762] D loss: 1.3103, G loss: 0.7418\n",
      "[404/1762] D loss: 1.2781, G loss: 0.7217\n",
      "[484/1762] D loss: 1.2914, G loss: 0.7771\n",
      "[564/1762] D loss: 1.3930, G loss: 0.6803\n",
      "[644/1762] D loss: 1.7788, G loss: 0.4605\n",
      "[724/1762] D loss: 1.4212, G loss: 0.6837\n",
      "[804/1762] D loss: 1.2682, G loss: 0.7076\n",
      "[884/1762] D loss: 1.1536, G loss: 0.8326\n",
      "[964/1762] D loss: 1.4029, G loss: 0.7163\n",
      "[1044/1762] D loss: 1.0001, G loss: 0.8838\n",
      "[1124/1762] D loss: 1.6384, G loss: 0.8675\n",
      "[1204/1762] D loss: 1.5678, G loss: 0.7030\n",
      "[1284/1762] D loss: 1.4167, G loss: 0.7794\n",
      "[1364/1762] D loss: 1.4991, G loss: 0.6897\n",
      "[1444/1762] D loss: 1.3909, G loss: 0.6409\n",
      "[1524/1762] D loss: 1.4862, G loss: 0.6919\n",
      "[1604/1762] D loss: 1.3869, G loss: 0.6765\n",
      "[1684/1762] D loss: 1.3797, G loss: 0.7006\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.7096\n",
      "train error: \n",
      " D loss: 1.405958, G loss: 0.703449, D accuracy: 49.9%, cell accuracy: 99.7%, board accuracy: 80.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.412105, G loss: 0.704981, D accuracy: 49.9%, cell accuracy: 99.6%, board accuracy: 78.4% \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3864, G loss: 0.6996\n",
      "[84/1762] D loss: 1.4799, G loss: 0.6453\n",
      "[164/1762] D loss: 1.4550, G loss: 0.6972\n",
      "[244/1762] D loss: 1.3893, G loss: 0.6818\n",
      "[324/1762] D loss: 1.3867, G loss: 0.6736\n",
      "[404/1762] D loss: 1.4029, G loss: 0.7147\n",
      "[484/1762] D loss: 1.4075, G loss: 0.6569\n",
      "[564/1762] D loss: 1.3872, G loss: 0.6702\n",
      "[644/1762] D loss: 1.3864, G loss: 0.6824\n",
      "[724/1762] D loss: 1.4235, G loss: 0.6954\n",
      "[804/1762] D loss: 1.3865, G loss: 0.7109\n",
      "[884/1762] D loss: 1.3881, G loss: 0.6643\n",
      "[964/1762] D loss: 1.3872, G loss: 0.6740\n",
      "[1044/1762] D loss: 1.3880, G loss: 0.6835\n",
      "[1124/1762] D loss: 1.3877, G loss: 0.6938\n",
      "[1204/1762] D loss: 1.3863, G loss: 0.6926\n",
      "[1284/1762] D loss: 1.4135, G loss: 0.6599\n",
      "[1364/1762] D loss: 1.3891, G loss: 0.6902\n",
      "[1444/1762] D loss: 1.3881, G loss: 0.6754\n",
      "[1524/1762] D loss: 1.3876, G loss: 0.7019\n",
      "[1604/1762] D loss: 1.3867, G loss: 0.6865\n",
      "[1684/1762] D loss: 1.3872, G loss: 0.6934\n",
      "[1762/1762] D loss: 1.3873, G loss: 0.6752\n",
      "train error: \n",
      " D loss: 1.382558, G loss: 0.695945, D accuracy: 52.8%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.382558, G loss: 0.697308, D accuracy: 53.0%, cell accuracy: 99.8%, board accuracy: 84.8% \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3795, G loss: 0.7110\n",
      "[84/1762] D loss: 1.3873, G loss: 0.6658\n",
      "[164/1762] D loss: 1.3872, G loss: 0.6846\n",
      "[244/1762] D loss: 1.3866, G loss: 0.7168\n",
      "[324/1762] D loss: 1.3869, G loss: 0.7088\n",
      "[404/1762] D loss: 1.3864, G loss: 0.7021\n",
      "[484/1762] D loss: 1.2945, G loss: 0.7418\n",
      "[564/1762] D loss: 1.3882, G loss: 0.6720\n",
      "[644/1762] D loss: 1.3867, G loss: 0.7078\n",
      "[724/1762] D loss: 1.3883, G loss: 0.7340\n",
      "[804/1762] D loss: 1.3856, G loss: 0.7187\n",
      "[884/1762] D loss: 1.3402, G loss: 0.7145\n",
      "[964/1762] D loss: 1.3875, G loss: 0.6969\n",
      "[1044/1762] D loss: 1.3861, G loss: 0.7110\n",
      "[1124/1762] D loss: 1.3873, G loss: 0.7270\n",
      "[1204/1762] D loss: 1.3865, G loss: 0.6854\n",
      "[1284/1762] D loss: 1.3866, G loss: 0.6818\n",
      "[1364/1762] D loss: 1.3867, G loss: 0.7118\n",
      "[1444/1762] D loss: 1.3875, G loss: 0.6720\n",
      "[1524/1762] D loss: 1.3105, G loss: 0.7514\n",
      "[1604/1762] D loss: 1.3932, G loss: 0.6656\n",
      "[1684/1762] D loss: 1.2787, G loss: 0.6934\n",
      "[1762/1762] D loss: 1.3927, G loss: 0.6270\n",
      "train error: \n",
      " D loss: 1.363532, G loss: 0.685749, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 88.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.357698, G loss: 0.686512, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3865, G loss: 0.6936\n",
      "[84/1762] D loss: 1.3935, G loss: 0.7117\n",
      "[164/1762] D loss: 1.3863, G loss: 0.7011\n",
      "[244/1762] D loss: 1.3894, G loss: 0.7424\n",
      "[324/1762] D loss: 1.3855, G loss: 0.6911\n",
      "[404/1762] D loss: 1.3864, G loss: 0.6928\n",
      "[484/1762] D loss: 1.2704, G loss: 0.6716\n",
      "[564/1762] D loss: 1.2785, G loss: 0.6898\n",
      "[644/1762] D loss: 1.2443, G loss: 0.8187\n",
      "[724/1762] D loss: 1.3886, G loss: 0.7439\n",
      "[804/1762] D loss: 1.2695, G loss: 0.7426\n",
      "[884/1762] D loss: 1.3881, G loss: 0.6788\n",
      "[964/1762] D loss: 1.2566, G loss: 0.7478\n",
      "[1044/1762] D loss: 1.3867, G loss: 0.7124\n",
      "[1124/1762] D loss: 1.3944, G loss: 0.6767\n",
      "[1204/1762] D loss: 1.2568, G loss: 0.7037\n",
      "[1284/1762] D loss: 1.3980, G loss: 0.7211\n",
      "[1364/1762] D loss: 1.3874, G loss: 0.7292\n",
      "[1444/1762] D loss: 1.4008, G loss: 0.6246\n",
      "[1524/1762] D loss: 1.3901, G loss: 0.7480\n",
      "[1604/1762] D loss: 1.3876, G loss: 0.6756\n",
      "[1684/1762] D loss: 1.3873, G loss: 0.7052\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.6911\n",
      "train error: \n",
      " D loss: 1.347961, G loss: 0.685615, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 89.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.336662, G loss: 0.687187, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3879, G loss: 0.7040\n",
      "[84/1762] D loss: 1.2421, G loss: 0.7160\n",
      "[164/1762] D loss: 1.3941, G loss: 0.7728\n",
      "[244/1762] D loss: 1.3868, G loss: 0.6974\n",
      "[324/1762] D loss: 1.3904, G loss: 0.7585\n",
      "[404/1762] D loss: 1.3831, G loss: 0.7795\n",
      "[484/1762] D loss: 1.3879, G loss: 0.7201\n",
      "[564/1762] D loss: 1.3870, G loss: 0.6925\n",
      "[644/1762] D loss: 1.2228, G loss: 0.7685\n",
      "[724/1762] D loss: 1.2159, G loss: 0.7718\n",
      "[804/1762] D loss: 1.3870, G loss: 0.7016\n",
      "[884/1762] D loss: 1.3894, G loss: 0.7133\n",
      "[964/1762] D loss: 1.3891, G loss: 0.7338\n",
      "[1044/1762] D loss: 1.3951, G loss: 0.6025\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.6588\n",
      "[1204/1762] D loss: 1.3862, G loss: 0.6676\n",
      "[1284/1762] D loss: 1.2069, G loss: 0.7145\n",
      "[1364/1762] D loss: 1.8192, G loss: 0.4819\n",
      "[1444/1762] D loss: 1.4949, G loss: 0.6057\n",
      "[1524/1762] D loss: 1.3905, G loss: 0.6748\n",
      "[1604/1762] D loss: 1.2837, G loss: 0.7712\n",
      "[1684/1762] D loss: 1.1573, G loss: 0.8500\n",
      "[1762/1762] D loss: 1.4890, G loss: 0.7526\n",
      "train error: \n",
      " D loss: 1.360391, G loss: 0.714752, D accuracy: 61.7%, cell accuracy: 99.4%, board accuracy: 34.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.367682, G loss: 0.714749, D accuracy: 61.5%, cell accuracy: 99.3%, board accuracy: 31.1% \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3238, G loss: 0.7348\n",
      "[84/1762] D loss: 1.4881, G loss: 0.9411\n",
      "[164/1762] D loss: 1.3896, G loss: 0.6479\n",
      "[244/1762] D loss: 1.4013, G loss: 0.5974\n",
      "[324/1762] D loss: 1.4338, G loss: 0.6659\n",
      "[404/1762] D loss: 1.4523, G loss: 0.7316\n",
      "[484/1762] D loss: 1.4074, G loss: 0.7488\n",
      "[564/1762] D loss: 1.4314, G loss: 0.6914\n",
      "[644/1762] D loss: 1.3866, G loss: 0.6834\n",
      "[724/1762] D loss: 1.3891, G loss: 0.6491\n",
      "[804/1762] D loss: 1.4263, G loss: 0.6825\n",
      "[884/1762] D loss: 1.3869, G loss: 0.6943\n",
      "[964/1762] D loss: 1.3902, G loss: 0.6980\n",
      "[1044/1762] D loss: 1.3897, G loss: 0.7157\n",
      "[1124/1762] D loss: 1.3898, G loss: 0.7013\n",
      "[1204/1762] D loss: 1.3962, G loss: 0.6693\n",
      "[1284/1762] D loss: 1.3885, G loss: 0.7071\n",
      "[1364/1762] D loss: 1.3865, G loss: 0.6798\n",
      "[1444/1762] D loss: 1.3863, G loss: 0.6872\n",
      "[1524/1762] D loss: 1.3862, G loss: 0.6982\n",
      "[1604/1762] D loss: 1.3864, G loss: 0.6960\n",
      "[1684/1762] D loss: 1.4021, G loss: 0.7172\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.7043\n",
      "train error: \n",
      " D loss: 1.387618, G loss: 0.702304, D accuracy: 50.7%, cell accuracy: 99.8%, board accuracy: 87.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.388588, G loss: 0.703169, D accuracy: 50.5%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3877, G loss: 0.7132\n",
      "[84/1762] D loss: 1.3872, G loss: 0.6824\n",
      "[164/1762] D loss: 1.3852, G loss: 0.6997\n",
      "[244/1762] D loss: 1.3808, G loss: 0.6892\n",
      "[324/1762] D loss: 1.3775, G loss: 0.6820\n",
      "[404/1762] D loss: 1.3865, G loss: 0.6881\n",
      "[484/1762] D loss: 1.3856, G loss: 0.7053\n",
      "[564/1762] D loss: 1.3860, G loss: 0.6926\n",
      "[644/1762] D loss: 1.3878, G loss: 0.6678\n",
      "[724/1762] D loss: 1.3872, G loss: 0.6804\n",
      "[804/1762] D loss: 1.3876, G loss: 0.6598\n",
      "[884/1762] D loss: 1.3426, G loss: 0.6727\n",
      "[964/1762] D loss: 1.3540, G loss: 0.7214\n",
      "[1044/1762] D loss: 1.3676, G loss: 0.6950\n",
      "[1124/1762] D loss: 1.3872, G loss: 0.6999\n",
      "[1204/1762] D loss: 1.3259, G loss: 0.7107\n",
      "[1284/1762] D loss: 1.3870, G loss: 0.7105\n",
      "[1364/1762] D loss: 1.3891, G loss: 0.6812\n",
      "[1444/1762] D loss: 1.3453, G loss: 0.6985\n",
      "[1524/1762] D loss: 1.3864, G loss: 0.7095\n",
      "[1604/1762] D loss: 1.3318, G loss: 0.7357\n",
      "[1684/1762] D loss: 1.3866, G loss: 0.6807\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.7024\n",
      "train error: \n",
      " D loss: 1.372035, G loss: 0.699999, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 87.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.368781, G loss: 0.701159, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 83.6% \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3871, G loss: 0.6931\n",
      "[84/1762] D loss: 1.3866, G loss: 0.7063\n",
      "[164/1762] D loss: 1.3263, G loss: 0.7068\n",
      "[244/1762] D loss: 1.3866, G loss: 0.6962\n",
      "[324/1762] D loss: 1.3872, G loss: 0.7087\n",
      "[404/1762] D loss: 1.3529, G loss: 0.7082\n",
      "[484/1762] D loss: 1.3227, G loss: 0.6785\n",
      "[564/1762] D loss: 1.3865, G loss: 0.7039\n",
      "[644/1762] D loss: 1.3881, G loss: 0.7264\n",
      "[724/1762] D loss: 1.3862, G loss: 0.6973\n",
      "[804/1762] D loss: 1.3882, G loss: 0.6770\n",
      "[884/1762] D loss: 1.3886, G loss: 0.7080\n",
      "[964/1762] D loss: 1.2444, G loss: 0.7383\n",
      "[1044/1762] D loss: 1.3871, G loss: 0.6913\n",
      "[1124/1762] D loss: 1.2776, G loss: 0.7322\n",
      "[1204/1762] D loss: 1.2770, G loss: 0.7252\n",
      "[1284/1762] D loss: 1.3894, G loss: 0.6889\n",
      "[1364/1762] D loss: 1.2871, G loss: 0.7312\n",
      "[1444/1762] D loss: 1.3880, G loss: 0.7115\n",
      "[1524/1762] D loss: 1.3881, G loss: 0.7262\n",
      "[1604/1762] D loss: 1.3929, G loss: 0.6719\n",
      "[1684/1762] D loss: 1.3869, G loss: 0.6731\n",
      "[1762/1762] D loss: 1.3867, G loss: 0.7127\n",
      "train error: \n",
      " D loss: 1.357819, G loss: 0.694262, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 89.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.350131, G loss: 0.695542, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3881, G loss: 0.6725\n",
      "[84/1762] D loss: 1.3874, G loss: 0.6811\n",
      "[164/1762] D loss: 1.3129, G loss: 0.7107\n",
      "[244/1762] D loss: 1.3866, G loss: 0.6983\n",
      "[324/1762] D loss: 1.3851, G loss: 0.7287\n",
      "[404/1762] D loss: 1.2136, G loss: 0.7646\n",
      "[484/1762] D loss: 1.2390, G loss: 0.7606\n",
      "[564/1762] D loss: 1.3882, G loss: 0.6993\n",
      "[644/1762] D loss: 1.3873, G loss: 0.7340\n",
      "[724/1762] D loss: 1.3879, G loss: 0.7273\n",
      "[804/1762] D loss: 1.2494, G loss: 0.7857\n",
      "[884/1762] D loss: 1.3869, G loss: 0.6941\n",
      "[964/1762] D loss: 1.3888, G loss: 0.6782\n",
      "[1044/1762] D loss: 1.3889, G loss: 0.6633\n",
      "[1124/1762] D loss: 1.3359, G loss: 0.6431\n",
      "[1204/1762] D loss: 1.9481, G loss: 0.5506\n",
      "[1284/1762] D loss: 1.6670, G loss: 0.5145\n",
      "[1364/1762] D loss: 1.4424, G loss: 0.6410\n",
      "[1444/1762] D loss: 1.2393, G loss: 0.8261\n",
      "[1524/1762] D loss: 1.2200, G loss: 0.7323\n",
      "[1604/1762] D loss: 1.4573, G loss: 0.5872\n",
      "[1684/1762] D loss: 1.3861, G loss: 0.6756\n",
      "[1762/1762] D loss: 1.3953, G loss: 0.6230\n",
      "train error: \n",
      " D loss: 1.415836, G loss: 0.697747, D accuracy: 47.3%, cell accuracy: 99.4%, board accuracy: 47.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.420748, G loss: 0.700159, D accuracy: 47.3%, cell accuracy: 99.3%, board accuracy: 45.0% \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3923, G loss: 0.7332\n",
      "[84/1762] D loss: 1.4362, G loss: 0.6756\n",
      "[164/1762] D loss: 1.3924, G loss: 0.7358\n",
      "[244/1762] D loss: 1.3903, G loss: 0.6503\n",
      "[324/1762] D loss: 1.3918, G loss: 0.6781\n",
      "[404/1762] D loss: 1.3908, G loss: 0.7170\n",
      "[484/1762] D loss: 1.3893, G loss: 0.7101\n",
      "[564/1762] D loss: 1.3807, G loss: 0.7394\n",
      "[644/1762] D loss: 1.3865, G loss: 0.6840\n",
      "[724/1762] D loss: 1.3890, G loss: 0.7083\n",
      "[804/1762] D loss: 1.3862, G loss: 0.6921\n",
      "[884/1762] D loss: 1.4172, G loss: 0.7096\n",
      "[964/1762] D loss: 1.3868, G loss: 0.6724\n",
      "[1044/1762] D loss: 1.3878, G loss: 0.6853\n",
      "[1124/1762] D loss: 1.3879, G loss: 0.6860\n",
      "[1204/1762] D loss: 1.3873, G loss: 0.6897\n",
      "[1284/1762] D loss: 1.4069, G loss: 0.6838\n",
      "[1364/1762] D loss: 1.3869, G loss: 0.6936\n",
      "[1444/1762] D loss: 1.3850, G loss: 0.7137\n",
      "[1524/1762] D loss: 1.3868, G loss: 0.7005\n",
      "[1604/1762] D loss: 1.3879, G loss: 0.6818\n",
      "[1684/1762] D loss: 1.3866, G loss: 0.7048\n",
      "[1762/1762] D loss: 1.3889, G loss: 0.6650\n",
      "train error: \n",
      " D loss: 1.381785, G loss: 0.695335, D accuracy: 52.4%, cell accuracy: 99.8%, board accuracy: 82.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.380246, G loss: 0.696000, D accuracy: 53.1%, cell accuracy: 99.8%, board accuracy: 80.5% \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3630, G loss: 0.7114\n",
      "[84/1762] D loss: 1.3867, G loss: 0.7140\n",
      "[164/1762] D loss: 1.3865, G loss: 0.7039\n",
      "[244/1762] D loss: 1.3870, G loss: 0.6987\n",
      "[324/1762] D loss: 1.3887, G loss: 0.7088\n",
      "[404/1762] D loss: 1.3869, G loss: 0.7084\n",
      "[484/1762] D loss: 1.3529, G loss: 0.6963\n",
      "[564/1762] D loss: 1.3906, G loss: 0.6987\n",
      "[644/1762] D loss: 1.3854, G loss: 0.7078\n",
      "[724/1762] D loss: 1.3619, G loss: 0.6972\n",
      "[804/1762] D loss: 1.3645, G loss: 0.7554\n",
      "[884/1762] D loss: 1.3898, G loss: 0.7217\n",
      "[964/1762] D loss: 1.3869, G loss: 0.7069\n",
      "[1044/1762] D loss: 1.3309, G loss: 0.7339\n",
      "[1124/1762] D loss: 1.3866, G loss: 0.7019\n",
      "[1204/1762] D loss: 1.3909, G loss: 0.7104\n",
      "[1284/1762] D loss: 1.3277, G loss: 0.7261\n",
      "[1364/1762] D loss: 1.3872, G loss: 0.7274\n",
      "[1444/1762] D loss: 1.3903, G loss: 0.6657\n",
      "[1524/1762] D loss: 1.3896, G loss: 0.7072\n",
      "[1604/1762] D loss: 1.3862, G loss: 0.7272\n",
      "[1684/1762] D loss: 1.3874, G loss: 0.7356\n",
      "[1762/1762] D loss: 1.3772, G loss: 0.7141\n",
      "train error: \n",
      " D loss: 1.357906, G loss: 0.713703, D accuracy: 56.2%, cell accuracy: 97.6%, board accuracy: 28.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.353235, G loss: 0.713735, D accuracy: 56.9%, cell accuracy: 97.5%, board accuracy: 28.0% \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3729, G loss: 0.7047\n",
      "[84/1762] D loss: 1.3806, G loss: 0.7077\n",
      "[164/1762] D loss: 1.3912, G loss: 0.6861\n",
      "[244/1762] D loss: 1.3955, G loss: 0.6942\n",
      "[324/1762] D loss: 1.3208, G loss: 0.7058\n",
      "[404/1762] D loss: 1.3938, G loss: 0.7142\n",
      "[484/1762] D loss: 1.3774, G loss: 0.7227\n",
      "[564/1762] D loss: 1.3920, G loss: 0.7053\n",
      "[644/1762] D loss: 1.3949, G loss: 0.7450\n",
      "[724/1762] D loss: 1.3937, G loss: 0.7225\n",
      "[804/1762] D loss: 1.3884, G loss: 0.6862\n",
      "[884/1762] D loss: 1.3880, G loss: 0.6984\n",
      "[964/1762] D loss: 1.2747, G loss: 0.7313\n",
      "[1044/1762] D loss: 1.4060, G loss: 0.7343\n",
      "[1124/1762] D loss: 1.2595, G loss: 0.7524\n",
      "[1204/1762] D loss: 1.3847, G loss: 0.6851\n",
      "[1284/1762] D loss: 1.3892, G loss: 0.7333\n",
      "[1364/1762] D loss: 1.3901, G loss: 0.7194\n",
      "[1444/1762] D loss: 1.3906, G loss: 0.7133\n",
      "[1524/1762] D loss: 1.3942, G loss: 0.6648\n",
      "[1604/1762] D loss: 1.3902, G loss: 0.7207\n",
      "[1684/1762] D loss: 1.3758, G loss: 0.7839\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.7443\n",
      "train error: \n",
      " D loss: 1.346169, G loss: 0.694237, D accuracy: 53.5%, cell accuracy: 99.6%, board accuracy: 52.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.335510, G loss: 0.695508, D accuracy: 54.9%, cell accuracy: 99.5%, board accuracy: 53.6% \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3872, G loss: 0.6871\n",
      "[84/1762] D loss: 1.3896, G loss: 0.7447\n",
      "[164/1762] D loss: 1.2546, G loss: 0.7386\n",
      "[244/1762] D loss: 1.3922, G loss: 0.7565\n",
      "[324/1762] D loss: 1.6719, G loss: 0.5738\n",
      "[404/1762] D loss: 1.5533, G loss: 0.5799\n",
      "[484/1762] D loss: 1.3006, G loss: 0.7437\n",
      "[564/1762] D loss: 1.3044, G loss: 0.7566\n",
      "[644/1762] D loss: 1.2695, G loss: 0.7659\n",
      "[724/1762] D loss: 1.2335, G loss: 0.8670\n",
      "[804/1762] D loss: 1.4272, G loss: 0.8185\n",
      "[884/1762] D loss: 1.3943, G loss: 0.7820\n",
      "[964/1762] D loss: 1.4164, G loss: 0.8080\n",
      "[1044/1762] D loss: 1.3881, G loss: 0.6535\n",
      "[1124/1762] D loss: 1.4101, G loss: 0.7176\n",
      "[1204/1762] D loss: 1.3531, G loss: 0.7060\n",
      "[1284/1762] D loss: 1.3863, G loss: 0.6803\n",
      "[1364/1762] D loss: 1.3881, G loss: 0.6792\n",
      "[1444/1762] D loss: 1.3877, G loss: 0.6789\n",
      "[1524/1762] D loss: 1.3888, G loss: 0.6668\n",
      "[1604/1762] D loss: 1.3909, G loss: 0.6468\n",
      "[1684/1762] D loss: 1.3516, G loss: 0.6958\n",
      "[1762/1762] D loss: 1.3850, G loss: 0.6484\n",
      "train error: \n",
      " D loss: 1.386691, G loss: 0.704113, D accuracy: 51.0%, cell accuracy: 99.7%, board accuracy: 77.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.387727, G loss: 0.703957, D accuracy: 51.7%, cell accuracy: 99.6%, board accuracy: 75.0% \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3872, G loss: 0.6886\n",
      "[84/1762] D loss: 1.3897, G loss: 0.6684\n",
      "[164/1762] D loss: 1.3884, G loss: 0.6800\n",
      "[244/1762] D loss: 1.3881, G loss: 0.6594\n",
      "[324/1762] D loss: 1.3872, G loss: 0.6749\n",
      "[404/1762] D loss: 1.3897, G loss: 0.7114\n",
      "[484/1762] D loss: 1.3863, G loss: 0.6934\n",
      "[564/1762] D loss: 1.3865, G loss: 0.6979\n",
      "[644/1762] D loss: 1.3880, G loss: 0.6898\n",
      "[724/1762] D loss: 1.3863, G loss: 0.6827\n",
      "[804/1762] D loss: 1.3866, G loss: 0.7115\n",
      "[884/1762] D loss: 1.3888, G loss: 0.6608\n",
      "[964/1762] D loss: 1.3874, G loss: 0.6763\n",
      "[1044/1762] D loss: 1.3865, G loss: 0.7009\n",
      "[1124/1762] D loss: 1.3793, G loss: 0.7204\n",
      "[1204/1762] D loss: 1.3635, G loss: 0.7032\n",
      "[1284/1762] D loss: 1.3868, G loss: 0.6768\n",
      "[1364/1762] D loss: 1.3841, G loss: 0.6993\n",
      "[1444/1762] D loss: 1.3867, G loss: 0.7017\n",
      "[1524/1762] D loss: 1.3861, G loss: 0.7076\n",
      "[1604/1762] D loss: 1.3825, G loss: 0.7214\n",
      "[1684/1762] D loss: 1.3210, G loss: 0.7102\n",
      "[1762/1762] D loss: 1.3863, G loss: 0.6946\n",
      "train error: \n",
      " D loss: 1.368570, G loss: 0.699566, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 85.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.362779, G loss: 0.701340, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 83.9% \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3858, G loss: 0.7119\n",
      "[84/1762] D loss: 1.3071, G loss: 0.7339\n",
      "[164/1762] D loss: 1.3027, G loss: 0.7352\n",
      "[244/1762] D loss: 1.3880, G loss: 0.6972\n",
      "[324/1762] D loss: 1.3934, G loss: 0.6288\n",
      "[404/1762] D loss: 1.2417, G loss: 0.7333\n",
      "[484/1762] D loss: 1.3907, G loss: 0.6827\n",
      "[564/1762] D loss: 1.3873, G loss: 0.7116\n",
      "[644/1762] D loss: 1.3870, G loss: 0.6760\n",
      "[724/1762] D loss: 1.3865, G loss: 0.6882\n",
      "[804/1762] D loss: 1.3870, G loss: 0.6972\n",
      "[884/1762] D loss: 1.2884, G loss: 0.7011\n",
      "[964/1762] D loss: 1.2478, G loss: 0.7696\n",
      "[1044/1762] D loss: 1.3875, G loss: 0.6955\n",
      "[1124/1762] D loss: 1.3877, G loss: 0.6609\n",
      "[1204/1762] D loss: 1.3881, G loss: 0.7231\n",
      "[1284/1762] D loss: 1.3880, G loss: 0.7211\n",
      "[1364/1762] D loss: 1.3909, G loss: 0.7153\n",
      "[1444/1762] D loss: 1.3933, G loss: 0.6519\n",
      "[1524/1762] D loss: 1.5758, G loss: 0.5711\n",
      "[1604/1762] D loss: 1.8178, G loss: 0.5221\n",
      "[1684/1762] D loss: 1.5845, G loss: 0.5338\n",
      "[1762/1762] D loss: 1.3712, G loss: 0.6461\n",
      "train error: \n",
      " D loss: 1.345249, G loss: 0.712538, D accuracy: 55.5%, cell accuracy: 98.1%, board accuracy: 6.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.345972, G loss: 0.715283, D accuracy: 55.7%, cell accuracy: 98.1%, board accuracy: 5.9% \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3482, G loss: 0.7232\n",
      "[84/1762] D loss: 1.1976, G loss: 0.8222\n",
      "[164/1762] D loss: 1.1157, G loss: 1.0110\n",
      "[244/1762] D loss: 0.9221, G loss: 0.9834\n",
      "[324/1762] D loss: 1.3808, G loss: 0.8132\n",
      "[404/1762] D loss: 1.3971, G loss: 0.5828\n",
      "[484/1762] D loss: 1.4929, G loss: 0.7293\n",
      "[564/1762] D loss: 1.3900, G loss: 0.6714\n",
      "[644/1762] D loss: 1.3818, G loss: 0.6680\n",
      "[724/1762] D loss: 1.3894, G loss: 0.6473\n",
      "[804/1762] D loss: 1.3892, G loss: 0.6594\n",
      "[884/1762] D loss: 1.3592, G loss: 0.7595\n",
      "[964/1762] D loss: 1.5143, G loss: 0.7264\n",
      "[1044/1762] D loss: 1.3875, G loss: 0.6980\n",
      "[1124/1762] D loss: 1.3893, G loss: 0.6737\n",
      "[1204/1762] D loss: 1.5523, G loss: 0.7036\n",
      "[1284/1762] D loss: 1.3883, G loss: 0.7111\n",
      "[1364/1762] D loss: 1.3883, G loss: 0.6711\n",
      "[1444/1762] D loss: 1.3867, G loss: 0.6839\n",
      "[1524/1762] D loss: 1.3890, G loss: 0.7155\n",
      "[1604/1762] D loss: 1.3884, G loss: 0.6712\n",
      "[1684/1762] D loss: 1.3866, G loss: 0.6815\n",
      "[1762/1762] D loss: 1.3619, G loss: 0.6945\n",
      "train error: \n",
      " D loss: 1.386476, G loss: 0.711443, D accuracy: 51.9%, cell accuracy: 99.7%, board accuracy: 66.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.386707, G loss: 0.710439, D accuracy: 52.8%, cell accuracy: 99.6%, board accuracy: 63.0% \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3890, G loss: 0.6990\n",
      "[84/1762] D loss: 1.3879, G loss: 0.7234\n",
      "[164/1762] D loss: 1.3860, G loss: 0.6787\n",
      "[244/1762] D loss: 1.3887, G loss: 0.6946\n",
      "[324/1762] D loss: 1.3866, G loss: 0.7088\n",
      "[404/1762] D loss: 1.3879, G loss: 0.6847\n",
      "[484/1762] D loss: 1.3905, G loss: 0.6822\n",
      "[564/1762] D loss: 1.3867, G loss: 0.7143\n",
      "[644/1762] D loss: 1.3870, G loss: 0.7140\n",
      "[724/1762] D loss: 1.3314, G loss: 0.7304\n",
      "[804/1762] D loss: 1.3864, G loss: 0.6771\n",
      "[884/1762] D loss: 1.3890, G loss: 0.6854\n",
      "[964/1762] D loss: 1.3848, G loss: 0.6915\n",
      "[1044/1762] D loss: 1.2615, G loss: 0.7474\n",
      "[1124/1762] D loss: 1.3886, G loss: 0.7463\n",
      "[1204/1762] D loss: 1.3189, G loss: 0.7433\n",
      "[1284/1762] D loss: 1.3870, G loss: 0.6955\n",
      "[1364/1762] D loss: 1.3668, G loss: 0.7106\n",
      "[1444/1762] D loss: 1.3141, G loss: 0.7220\n",
      "[1524/1762] D loss: 1.4006, G loss: 0.6758\n",
      "[1604/1762] D loss: 1.3853, G loss: 0.6865\n",
      "[1684/1762] D loss: 1.3940, G loss: 0.7240\n",
      "[1762/1762] D loss: 1.2031, G loss: 0.7234\n",
      "train error: \n",
      " D loss: 1.365287, G loss: 0.720251, D accuracy: 53.8%, cell accuracy: 99.7%, board accuracy: 74.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.359700, G loss: 0.720895, D accuracy: 54.9%, cell accuracy: 99.7%, board accuracy: 71.1% \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3874, G loss: 0.7291\n",
      "[84/1762] D loss: 1.3859, G loss: 0.7108\n",
      "[164/1762] D loss: 1.3869, G loss: 0.7214\n",
      "[244/1762] D loss: 1.3871, G loss: 0.6768\n",
      "[324/1762] D loss: 1.3406, G loss: 0.7635\n",
      "[404/1762] D loss: 1.2778, G loss: 0.7404\n",
      "[484/1762] D loss: 1.3932, G loss: 0.6914\n",
      "[564/1762] D loss: 1.2888, G loss: 0.7045\n",
      "[644/1762] D loss: 1.3870, G loss: 0.7122\n",
      "[724/1762] D loss: 1.2643, G loss: 0.7396\n",
      "[804/1762] D loss: 1.2645, G loss: 0.7375\n",
      "[884/1762] D loss: 1.3887, G loss: 0.7001\n",
      "[964/1762] D loss: 1.3868, G loss: 0.7133\n",
      "[1044/1762] D loss: 1.3877, G loss: 0.7307\n",
      "[1124/1762] D loss: 1.2726, G loss: 0.7666\n",
      "[1204/1762] D loss: 1.2731, G loss: 0.6744\n",
      "[1284/1762] D loss: 1.3847, G loss: 0.6693\n",
      "[1364/1762] D loss: 1.3889, G loss: 0.7291\n",
      "[1444/1762] D loss: 1.3893, G loss: 0.7491\n",
      "[1524/1762] D loss: 1.3961, G loss: 0.7917\n",
      "[1604/1762] D loss: 1.3891, G loss: 0.7568\n",
      "[1684/1762] D loss: 1.3904, G loss: 0.7405\n",
      "[1762/1762] D loss: 1.3872, G loss: 0.6670\n",
      "train error: \n",
      " D loss: 1.363579, G loss: 0.688542, D accuracy: 51.7%, cell accuracy: 99.7%, board accuracy: 76.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.353353, G loss: 0.687228, D accuracy: 53.2%, cell accuracy: 99.6%, board accuracy: 72.3% \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2317, G loss: 0.7296\n",
      "[84/1762] D loss: 0.9781, G loss: 0.7320\n",
      "[164/1762] D loss: 1.5890, G loss: 0.6471\n",
      "[244/1762] D loss: 1.1357, G loss: 0.8230\n",
      "[324/1762] D loss: 0.8556, G loss: 1.2233\n",
      "[404/1762] D loss: 1.0908, G loss: 0.9119\n",
      "[484/1762] D loss: 0.9279, G loss: 1.2822\n",
      "[564/1762] D loss: 1.7156, G loss: 0.6946\n",
      "[644/1762] D loss: 1.7517, G loss: 0.6435\n",
      "[724/1762] D loss: 1.3974, G loss: 0.6102\n",
      "[804/1762] D loss: 1.3976, G loss: 0.7209\n",
      "[884/1762] D loss: 1.3950, G loss: 0.7188\n",
      "[964/1762] D loss: 1.5181, G loss: 0.6656\n",
      "[1044/1762] D loss: 1.3899, G loss: 0.6327\n",
      "[1124/1762] D loss: 1.3753, G loss: 0.7757\n",
      "[1204/1762] D loss: 1.3862, G loss: 0.7064\n",
      "[1284/1762] D loss: 1.3879, G loss: 0.6940\n",
      "[1364/1762] D loss: 1.3875, G loss: 0.6697\n",
      "[1444/1762] D loss: 1.3891, G loss: 0.6527\n",
      "[1524/1762] D loss: 1.3893, G loss: 0.6694\n",
      "[1604/1762] D loss: 1.5025, G loss: 0.7129\n",
      "[1684/1762] D loss: 1.3861, G loss: 0.7089\n",
      "[1762/1762] D loss: 1.3915, G loss: 0.6292\n",
      "train error: \n",
      " D loss: 1.398146, G loss: 0.694542, D accuracy: 49.7%, cell accuracy: 99.7%, board accuracy: 76.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.400072, G loss: 0.694661, D accuracy: 49.3%, cell accuracy: 99.7%, board accuracy: 73.4% \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3869, G loss: 0.6964\n",
      "[84/1762] D loss: 1.4098, G loss: 0.7243\n",
      "[164/1762] D loss: 1.3852, G loss: 0.6881\n",
      "[244/1762] D loss: 1.3868, G loss: 0.7024\n",
      "[324/1762] D loss: 1.3862, G loss: 0.6915\n",
      "[404/1762] D loss: 1.3866, G loss: 0.6954\n",
      "[484/1762] D loss: 1.3724, G loss: 0.7251\n",
      "[564/1762] D loss: 1.3870, G loss: 0.6537\n",
      "[644/1762] D loss: 1.3698, G loss: 0.7010\n",
      "[724/1762] D loss: 1.3860, G loss: 0.6820\n",
      "[804/1762] D loss: 1.3878, G loss: 0.6639\n",
      "[884/1762] D loss: 1.3762, G loss: 0.7273\n",
      "[964/1762] D loss: 1.3866, G loss: 0.6921\n",
      "[1044/1762] D loss: 1.3883, G loss: 0.6782\n",
      "[1124/1762] D loss: 1.3565, G loss: 0.7151\n",
      "[1204/1762] D loss: 1.3888, G loss: 0.6672\n",
      "[1284/1762] D loss: 1.3875, G loss: 0.7197\n",
      "[1364/1762] D loss: 1.3915, G loss: 0.6620\n",
      "[1444/1762] D loss: 1.3871, G loss: 0.7162\n",
      "[1524/1762] D loss: 1.3808, G loss: 0.7122\n",
      "[1604/1762] D loss: 1.3861, G loss: 0.6841\n",
      "[1684/1762] D loss: 1.3873, G loss: 0.6873\n",
      "[1762/1762] D loss: 1.2634, G loss: 0.7241\n",
      "train error: \n",
      " D loss: 1.366750, G loss: 0.705457, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 83.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.360466, G loss: 0.707169, D accuracy: 55.0%, cell accuracy: 99.7%, board accuracy: 81.8% \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3861, G loss: 0.7074\n",
      "[84/1762] D loss: 1.3923, G loss: 0.6594\n",
      "[164/1762] D loss: 1.3000, G loss: 0.6988\n",
      "[244/1762] D loss: 1.3863, G loss: 0.6880\n",
      "[324/1762] D loss: 1.3868, G loss: 0.7091\n",
      "[404/1762] D loss: 1.3891, G loss: 0.7145\n",
      "[484/1762] D loss: 1.3878, G loss: 0.7278\n",
      "[564/1762] D loss: 1.2948, G loss: 0.6993\n",
      "[644/1762] D loss: 1.3896, G loss: 0.6514\n",
      "[724/1762] D loss: 1.3875, G loss: 0.6853\n",
      "[804/1762] D loss: 1.3879, G loss: 0.6981\n",
      "[884/1762] D loss: 1.3845, G loss: 0.7129\n",
      "[964/1762] D loss: 1.3861, G loss: 0.7499\n",
      "[1044/1762] D loss: 1.2416, G loss: 0.7517\n",
      "[1124/1762] D loss: 1.6217, G loss: 0.6204\n",
      "[1204/1762] D loss: 1.5417, G loss: 0.5925\n",
      "[1284/1762] D loss: 1.4083, G loss: 0.7570\n",
      "[1364/1762] D loss: 1.2911, G loss: 0.7834\n",
      "[1444/1762] D loss: 1.1376, G loss: 0.8573\n",
      "[1524/1762] D loss: 0.9807, G loss: 0.8765\n",
      "[1604/1762] D loss: 1.0929, G loss: 0.8738\n",
      "[1684/1762] D loss: 1.0381, G loss: 1.2029\n",
      "[1762/1762] D loss: 1.4332, G loss: 0.6926\n",
      "train error: \n",
      " D loss: 1.582346, G loss: 0.830156, D accuracy: 47.3%, cell accuracy: 99.6%, board accuracy: 62.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.607661, G loss: 0.835022, D accuracy: 46.4%, cell accuracy: 99.6%, board accuracy: 58.2% \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5073, G loss: 1.0840\n",
      "[84/1762] D loss: 1.9368, G loss: 0.5899\n",
      "[164/1762] D loss: 1.3957, G loss: 0.6680\n",
      "[244/1762] D loss: 1.3866, G loss: 0.6286\n",
      "[324/1762] D loss: 1.5789, G loss: 0.6324\n",
      "[404/1762] D loss: 1.3860, G loss: 0.6594\n",
      "[484/1762] D loss: 1.3869, G loss: 0.6673\n",
      "[564/1762] D loss: 1.3885, G loss: 0.6639\n",
      "[644/1762] D loss: 1.3873, G loss: 0.6688\n",
      "[724/1762] D loss: 1.3563, G loss: 0.7059\n",
      "[804/1762] D loss: 1.3850, G loss: 0.6972\n",
      "[884/1762] D loss: 1.3655, G loss: 0.7157\n",
      "[964/1762] D loss: 1.3862, G loss: 0.6830\n",
      "[1044/1762] D loss: 1.3890, G loss: 0.6494\n",
      "[1124/1762] D loss: 1.5144, G loss: 0.6935\n",
      "[1204/1762] D loss: 1.4470, G loss: 0.6534\n",
      "[1284/1762] D loss: 1.3915, G loss: 0.7039\n",
      "[1364/1762] D loss: 1.3875, G loss: 0.7001\n",
      "[1444/1762] D loss: 1.3894, G loss: 0.7045\n",
      "[1524/1762] D loss: 1.3839, G loss: 0.6904\n",
      "[1604/1762] D loss: 1.3884, G loss: 0.7089\n",
      "[1684/1762] D loss: 1.3885, G loss: 0.6724\n",
      "[1762/1762] D loss: 1.3896, G loss: 0.6801\n",
      "train error: \n",
      " D loss: 1.389828, G loss: 0.708475, D accuracy: 51.1%, cell accuracy: 99.7%, board accuracy: 73.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.390796, G loss: 0.707816, D accuracy: 51.9%, cell accuracy: 99.7%, board accuracy: 69.3% \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3890, G loss: 0.6911\n",
      "[84/1762] D loss: 1.3899, G loss: 0.6970\n",
      "[164/1762] D loss: 1.3871, G loss: 0.7066\n",
      "[244/1762] D loss: 1.3885, G loss: 0.6578\n",
      "[324/1762] D loss: 1.3869, G loss: 0.6843\n",
      "[404/1762] D loss: 1.3865, G loss: 0.7047\n",
      "[484/1762] D loss: 1.3878, G loss: 0.7111\n",
      "[564/1762] D loss: 1.3205, G loss: 0.7278\n",
      "[644/1762] D loss: 1.3885, G loss: 0.7189\n",
      "[724/1762] D loss: 1.3127, G loss: 0.7245\n",
      "[804/1762] D loss: 1.3880, G loss: 0.6938\n",
      "[884/1762] D loss: 1.3063, G loss: 0.7030\n",
      "[964/1762] D loss: 1.3848, G loss: 0.6848\n",
      "[1044/1762] D loss: 1.3881, G loss: 0.7128\n",
      "[1124/1762] D loss: 1.3025, G loss: 0.7047\n",
      "[1204/1762] D loss: 1.3879, G loss: 0.7180\n",
      "[1284/1762] D loss: 1.3875, G loss: 0.7192\n",
      "[1364/1762] D loss: 1.3864, G loss: 0.6926\n",
      "[1444/1762] D loss: 1.2908, G loss: 0.7378\n",
      "[1524/1762] D loss: 1.3865, G loss: 0.6942\n",
      "[1604/1762] D loss: 1.2970, G loss: 0.7037\n",
      "[1684/1762] D loss: 1.3139, G loss: 0.7141\n",
      "[1762/1762] D loss: 1.3873, G loss: 0.6787\n",
      "train error: \n",
      " D loss: 1.362054, G loss: 0.723659, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 80.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.355403, G loss: 0.725464, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 76.8% \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3872, G loss: 0.7397\n",
      "[84/1762] D loss: 1.2696, G loss: 0.7286\n",
      "[164/1762] D loss: 1.3866, G loss: 0.6864\n",
      "[244/1762] D loss: 1.3852, G loss: 0.6992\n",
      "[324/1762] D loss: 1.3859, G loss: 0.6955\n",
      "[404/1762] D loss: 1.3871, G loss: 0.6946\n",
      "[484/1762] D loss: 1.3903, G loss: 0.7714\n",
      "[564/1762] D loss: 1.3917, G loss: 0.6827\n",
      "[644/1762] D loss: 1.2319, G loss: 0.7488\n",
      "[724/1762] D loss: 1.2315, G loss: 0.7282\n",
      "[804/1762] D loss: 1.3866, G loss: 0.7006\n",
      "[884/1762] D loss: 1.2342, G loss: 0.7133\n",
      "[964/1762] D loss: 1.3872, G loss: 0.7173\n",
      "[1044/1762] D loss: 1.3816, G loss: 0.7176\n",
      "[1124/1762] D loss: 1.3948, G loss: 0.8076\n",
      "[1204/1762] D loss: 1.3835, G loss: 0.7112\n",
      "[1284/1762] D loss: 1.2125, G loss: 0.7384\n",
      "[1364/1762] D loss: 1.3873, G loss: 0.7190\n",
      "[1444/1762] D loss: 1.3876, G loss: 0.7335\n",
      "[1524/1762] D loss: 1.3863, G loss: 0.6872\n",
      "[1604/1762] D loss: 1.3926, G loss: 0.7324\n",
      "[1684/1762] D loss: 1.3776, G loss: 0.7219\n",
      "[1762/1762] D loss: 1.3888, G loss: 0.7211\n",
      "train error: \n",
      " D loss: 1.339297, G loss: 0.713688, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 78.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.325482, G loss: 0.715637, D accuracy: 54.3%, cell accuracy: 99.7%, board accuracy: 74.8% \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2091, G loss: 0.7323\n",
      "[84/1762] D loss: 1.3919, G loss: 0.7342\n",
      "[164/1762] D loss: 1.1901, G loss: 0.7560\n",
      "[244/1762] D loss: 1.3874, G loss: 0.7150\n",
      "[324/1762] D loss: 1.3877, G loss: 0.7338\n",
      "[404/1762] D loss: 1.2403, G loss: 0.7421\n",
      "[484/1762] D loss: 1.2015, G loss: 0.7559\n",
      "[564/1762] D loss: 1.3879, G loss: 0.6843\n",
      "[644/1762] D loss: 1.1876, G loss: 0.8347\n",
      "[724/1762] D loss: 1.3915, G loss: 0.7273\n",
      "[804/1762] D loss: 1.3868, G loss: 0.7344\n",
      "[884/1762] D loss: 1.3886, G loss: 0.6948\n",
      "[964/1762] D loss: 1.2418, G loss: 0.7113\n",
      "[1044/1762] D loss: 1.1940, G loss: 0.7665\n",
      "[1124/1762] D loss: 1.3897, G loss: 0.7428\n",
      "[1204/1762] D loss: 1.3882, G loss: 0.7366\n",
      "[1284/1762] D loss: 1.3880, G loss: 0.7271\n",
      "[1364/1762] D loss: 1.3902, G loss: 0.7438\n",
      "[1444/1762] D loss: 1.3919, G loss: 0.7570\n",
      "[1524/1762] D loss: 1.3936, G loss: 0.7294\n",
      "[1604/1762] D loss: 1.3877, G loss: 0.7223\n",
      "[1684/1762] D loss: 1.3869, G loss: 0.6923\n",
      "[1762/1762] D loss: 1.6519, G loss: 0.5018\n",
      "train error: \n",
      " D loss: 1.334930, G loss: 0.721334, D accuracy: 53.5%, cell accuracy: 99.7%, board accuracy: 76.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.320540, G loss: 0.724029, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 75.2% \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3892, G loss: 0.7116\n",
      "[84/1762] D loss: 1.3908, G loss: 0.7014\n",
      "[164/1762] D loss: 1.3872, G loss: 0.6905\n",
      "[244/1762] D loss: 1.1875, G loss: 0.8023\n",
      "[324/1762] D loss: 1.3860, G loss: 0.7042\n",
      "[404/1762] D loss: 1.3918, G loss: 0.7284\n",
      "[484/1762] D loss: 1.3893, G loss: 0.7489\n",
      "[564/1762] D loss: 1.3900, G loss: 0.7383\n",
      "[644/1762] D loss: 1.2044, G loss: 0.7645\n",
      "[724/1762] D loss: 1.3876, G loss: 0.7369\n",
      "[804/1762] D loss: 1.3877, G loss: 0.7185\n",
      "[884/1762] D loss: 1.3881, G loss: 0.7211\n",
      "[964/1762] D loss: 1.3865, G loss: 0.7147\n",
      "[1044/1762] D loss: 1.3874, G loss: 0.6678\n",
      "[1124/1762] D loss: 1.2046, G loss: 0.8089\n",
      "[1204/1762] D loss: 1.1857, G loss: 0.7030\n",
      "[1284/1762] D loss: 1.1979, G loss: 0.6968\n",
      "[1364/1762] D loss: 1.3928, G loss: 0.7522\n",
      "[1444/1762] D loss: 1.3897, G loss: 0.7417\n",
      "[1524/1762] D loss: 1.1956, G loss: 0.7717\n",
      "[1604/1762] D loss: 1.3928, G loss: 0.7660\n",
      "[1684/1762] D loss: 1.1966, G loss: 0.7943\n",
      "[1762/1762] D loss: 1.4079, G loss: 0.7711\n",
      "train error: \n",
      " D loss: 1.335149, G loss: 0.775007, D accuracy: 53.4%, cell accuracy: 99.4%, board accuracy: 47.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.317952, G loss: 0.779278, D accuracy: 55.0%, cell accuracy: 99.4%, board accuracy: 47.0% \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3935, G loss: 0.7884\n",
      "[84/1762] D loss: 1.1800, G loss: 0.7444\n",
      "[164/1762] D loss: 1.3934, G loss: 0.7131\n",
      "[244/1762] D loss: 1.3879, G loss: 0.6816\n",
      "[324/1762] D loss: 1.2045, G loss: 0.7340\n",
      "[404/1762] D loss: 1.3867, G loss: 0.7318\n",
      "[484/1762] D loss: 1.4027, G loss: 0.6283\n",
      "[564/1762] D loss: 1.3966, G loss: 0.7462\n",
      "[644/1762] D loss: 1.1941, G loss: 0.7473\n",
      "[724/1762] D loss: 1.1933, G loss: 0.7090\n",
      "[804/1762] D loss: 1.3952, G loss: 0.7324\n",
      "[884/1762] D loss: 1.3873, G loss: 0.6758\n",
      "[964/1762] D loss: 1.3948, G loss: 0.6923\n",
      "[1044/1762] D loss: 1.4006, G loss: 0.7891\n",
      "[1124/1762] D loss: 1.3922, G loss: 0.7027\n",
      "[1204/1762] D loss: 1.1848, G loss: 0.7756\n",
      "[1284/1762] D loss: 1.1858, G loss: 0.7732\n",
      "[1364/1762] D loss: 1.3803, G loss: 0.7177\n",
      "[1444/1762] D loss: 1.3903, G loss: 0.7387\n",
      "[1524/1762] D loss: 1.3854, G loss: 0.6429\n",
      "[1604/1762] D loss: 1.3895, G loss: 0.6984\n",
      "[1684/1762] D loss: 1.3885, G loss: 0.7222\n",
      "[1762/1762] D loss: 1.3853, G loss: 0.6969\n",
      "train error: \n",
      " D loss: 1.335743, G loss: 0.719276, D accuracy: 53.4%, cell accuracy: 99.5%, board accuracy: 51.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.320488, G loss: 0.721691, D accuracy: 54.2%, cell accuracy: 99.4%, board accuracy: 54.8% \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3882, G loss: 0.7146\n",
      "[84/1762] D loss: 1.3886, G loss: 0.7360\n",
      "[164/1762] D loss: 1.3921, G loss: 0.6773\n",
      "[244/1762] D loss: 1.3908, G loss: 0.6962\n",
      "[324/1762] D loss: 1.3876, G loss: 0.7156\n",
      "[404/1762] D loss: 1.3885, G loss: 0.7050\n",
      "[484/1762] D loss: 1.3834, G loss: 0.7188\n",
      "[564/1762] D loss: 1.3887, G loss: 0.6987\n",
      "[644/1762] D loss: 1.3884, G loss: 0.7219\n",
      "[724/1762] D loss: 1.3789, G loss: 0.6634\n",
      "[804/1762] D loss: 1.3890, G loss: 0.6799\n",
      "[884/1762] D loss: 1.3816, G loss: 0.7413\n",
      "[964/1762] D loss: 1.3917, G loss: 0.6548\n",
      "[1044/1762] D loss: 1.4373, G loss: 0.6933\n",
      "[1124/1762] D loss: 1.1907, G loss: 0.8319\n",
      "[1204/1762] D loss: 1.3927, G loss: 0.7656\n",
      "[1284/1762] D loss: 1.3980, G loss: 0.6433\n",
      "[1364/1762] D loss: 1.3801, G loss: 0.7226\n",
      "[1444/1762] D loss: 1.3794, G loss: 0.7690\n",
      "[1524/1762] D loss: 1.2089, G loss: 0.7225\n",
      "[1604/1762] D loss: 1.2047, G loss: 0.7385\n",
      "[1684/1762] D loss: 1.1911, G loss: 0.7641\n",
      "[1762/1762] D loss: 1.3909, G loss: 0.7755\n",
      "train error: \n",
      " D loss: 1.340726, G loss: 0.817146, D accuracy: 52.9%, cell accuracy: 99.6%, board accuracy: 60.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.324194, G loss: 0.818210, D accuracy: 53.5%, cell accuracy: 99.6%, board accuracy: 60.7% \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3950, G loss: 0.8117\n",
      "[84/1762] D loss: 1.3958, G loss: 0.7198\n",
      "[164/1762] D loss: 1.2199, G loss: 0.6607\n",
      "[244/1762] D loss: 1.3903, G loss: 0.6968\n",
      "[324/1762] D loss: 1.1983, G loss: 0.7493\n",
      "[404/1762] D loss: 1.4030, G loss: 0.7866\n",
      "[484/1762] D loss: 1.3913, G loss: 0.7761\n",
      "[564/1762] D loss: 1.1680, G loss: 0.8006\n",
      "[644/1762] D loss: 1.3930, G loss: 0.7429\n",
      "[724/1762] D loss: 1.3842, G loss: 0.7372\n",
      "[804/1762] D loss: 1.3869, G loss: 0.6794\n",
      "[884/1762] D loss: 1.3859, G loss: 0.6903\n",
      "[964/1762] D loss: 1.3914, G loss: 0.7422\n",
      "[1044/1762] D loss: 1.3829, G loss: 0.6577\n",
      "[1124/1762] D loss: 1.3879, G loss: 0.7017\n",
      "[1204/1762] D loss: 0.9901, G loss: 0.8101\n",
      "[1284/1762] D loss: 1.4012, G loss: 0.7261\n",
      "[1364/1762] D loss: 1.4037, G loss: 0.7759\n",
      "[1444/1762] D loss: 1.3897, G loss: 0.6951\n",
      "[1524/1762] D loss: 1.3900, G loss: 0.7398\n",
      "[1604/1762] D loss: 1.3910, G loss: 0.6394\n",
      "[1684/1762] D loss: 1.3870, G loss: 0.7224\n",
      "[1762/1762] D loss: 1.4008, G loss: 0.8144\n",
      "train error: \n",
      " D loss: 1.331730, G loss: 0.759503, D accuracy: 53.8%, cell accuracy: 99.6%, board accuracy: 70.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.314927, G loss: 0.762267, D accuracy: 55.1%, cell accuracy: 99.6%, board accuracy: 66.1% \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3863, G loss: 0.7374\n",
      "[84/1762] D loss: 1.3923, G loss: 0.7663\n",
      "[164/1762] D loss: 1.1921, G loss: 0.7477\n",
      "[244/1762] D loss: 1.3880, G loss: 0.6521\n",
      "[324/1762] D loss: 1.3938, G loss: 0.7704\n",
      "[404/1762] D loss: 1.3980, G loss: 0.8058\n",
      "[484/1762] D loss: 1.3939, G loss: 0.7621\n",
      "[564/1762] D loss: 1.3900, G loss: 0.7318\n",
      "[644/1762] D loss: 1.1926, G loss: 0.7394\n",
      "[724/1762] D loss: 1.3882, G loss: 0.6672\n",
      "[804/1762] D loss: 1.3876, G loss: 0.6825\n",
      "[884/1762] D loss: 1.3861, G loss: 0.6810\n",
      "[964/1762] D loss: 1.4186, G loss: 0.6701\n",
      "[1044/1762] D loss: 1.1866, G loss: 0.7743\n",
      "[1124/1762] D loss: 1.3886, G loss: 0.7144\n",
      "[1204/1762] D loss: 1.3811, G loss: 0.7670\n",
      "[1284/1762] D loss: 1.3949, G loss: 0.7987\n",
      "[1364/1762] D loss: 0.9754, G loss: 0.8296\n",
      "[1444/1762] D loss: 0.9728, G loss: 0.8493\n",
      "[1524/1762] D loss: 1.1611, G loss: 0.7565\n",
      "[1604/1762] D loss: 1.3796, G loss: 0.7261\n",
      "[1684/1762] D loss: 1.3996, G loss: 0.7908\n",
      "[1762/1762] D loss: 1.3917, G loss: 0.7632\n",
      "train error: \n",
      " D loss: 1.331264, G loss: 0.780989, D accuracy: 53.4%, cell accuracy: 99.7%, board accuracy: 77.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.312083, G loss: 0.786496, D accuracy: 54.4%, cell accuracy: 99.6%, board accuracy: 75.7% \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1717, G loss: 0.8085\n",
      "[84/1762] D loss: 1.3857, G loss: 0.7256\n",
      "[164/1762] D loss: 1.3798, G loss: 0.7566\n",
      "[244/1762] D loss: 1.1843, G loss: 0.7439\n",
      "[324/1762] D loss: 1.3850, G loss: 0.7251\n",
      "[404/1762] D loss: 1.3883, G loss: 0.7005\n",
      "[484/1762] D loss: 1.3928, G loss: 0.7124\n",
      "[564/1762] D loss: 1.1768, G loss: 0.7870\n",
      "[644/1762] D loss: 1.3873, G loss: 0.7094\n",
      "[724/1762] D loss: 1.3888, G loss: 0.7051\n",
      "[804/1762] D loss: 1.4005, G loss: 0.7775\n",
      "[884/1762] D loss: 1.3907, G loss: 0.6847\n",
      "[964/1762] D loss: 1.1720, G loss: 0.7573\n",
      "[1044/1762] D loss: 1.4152, G loss: 0.8843\n",
      "[1124/1762] D loss: 1.3842, G loss: 0.6820\n",
      "[1204/1762] D loss: 1.4003, G loss: 0.7737\n",
      "[1284/1762] D loss: 1.3857, G loss: 0.7035\n",
      "[1364/1762] D loss: 1.3927, G loss: 0.7494\n",
      "[1444/1762] D loss: 1.4099, G loss: 0.7515\n",
      "[1524/1762] D loss: 1.0871, G loss: 0.7908\n",
      "[1604/1762] D loss: 1.1832, G loss: 0.8692\n",
      "[1684/1762] D loss: 1.0290, G loss: 0.7685\n",
      "[1762/1762] D loss: 2.0080, G loss: 0.6330\n",
      "train error: \n",
      " D loss: 2.046505, G loss: 0.564749, D accuracy: 26.0%, cell accuracy: 96.3%, board accuracy: 6.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.993367, G loss: 0.586953, D accuracy: 28.4%, cell accuracy: 96.2%, board accuracy: 7.0% \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.5659, G loss: 0.7182\n",
      "[84/1762] D loss: 1.4357, G loss: 0.6230\n",
      "[164/1762] D loss: 1.0132, G loss: 0.8568\n",
      "[244/1762] D loss: 1.2399, G loss: 0.7046\n",
      "[324/1762] D loss: 1.3309, G loss: 1.0392\n",
      "[404/1762] D loss: 1.5002, G loss: 0.6685\n",
      "[484/1762] D loss: 1.4204, G loss: 0.6511\n",
      "[564/1762] D loss: 1.5057, G loss: 0.5833\n",
      "[644/1762] D loss: 1.4971, G loss: 0.7094\n",
      "[724/1762] D loss: 1.3915, G loss: 0.7192\n",
      "[804/1762] D loss: 1.3908, G loss: 0.6964\n",
      "[884/1762] D loss: 1.4048, G loss: 0.7522\n",
      "[964/1762] D loss: 1.4903, G loss: 0.6665\n",
      "[1044/1762] D loss: 1.3910, G loss: 0.6674\n",
      "[1124/1762] D loss: 1.3858, G loss: 0.6523\n",
      "[1204/1762] D loss: 1.3892, G loss: 0.6624\n",
      "[1284/1762] D loss: 1.3900, G loss: 0.6685\n",
      "[1364/1762] D loss: 1.3885, G loss: 0.6679\n",
      "[1444/1762] D loss: 1.4969, G loss: 0.6564\n",
      "[1524/1762] D loss: 1.3876, G loss: 0.6930\n",
      "[1604/1762] D loss: 1.2714, G loss: 0.7246\n",
      "[1684/1762] D loss: 1.3892, G loss: 0.6909\n",
      "[1762/1762] D loss: 1.3901, G loss: 0.7494\n",
      "train error: \n",
      " D loss: 1.378467, G loss: 0.740948, D accuracy: 52.2%, cell accuracy: 99.8%, board accuracy: 81.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.376406, G loss: 0.741593, D accuracy: 53.4%, cell accuracy: 99.7%, board accuracy: 76.1% \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3929, G loss: 0.7687\n",
      "[84/1762] D loss: 1.3120, G loss: 0.7525\n",
      "[164/1762] D loss: 1.3907, G loss: 0.6623\n",
      "[244/1762] D loss: 1.3885, G loss: 0.6910\n",
      "[324/1762] D loss: 1.3742, G loss: 0.7427\n",
      "[404/1762] D loss: 1.3530, G loss: 0.7175\n",
      "[484/1762] D loss: 1.3471, G loss: 0.6799\n",
      "[564/1762] D loss: 1.3876, G loss: 0.6976\n",
      "[644/1762] D loss: 1.3304, G loss: 0.7181\n",
      "[724/1762] D loss: 1.3878, G loss: 0.7201\n",
      "[804/1762] D loss: 1.3860, G loss: 0.6725\n",
      "[884/1762] D loss: 1.3868, G loss: 0.6944\n",
      "[964/1762] D loss: 1.2714, G loss: 0.7432\n",
      "[1044/1762] D loss: 1.2735, G loss: 0.7678\n",
      "[1124/1762] D loss: 1.3886, G loss: 0.7559\n",
      "[1204/1762] D loss: 1.2523, G loss: 0.6905\n",
      "[1284/1762] D loss: 1.2527, G loss: 0.7033\n",
      "[1364/1762] D loss: 1.3955, G loss: 0.6614\n",
      "[1444/1762] D loss: 1.3959, G loss: 0.6770\n",
      "[1524/1762] D loss: 1.3841, G loss: 0.7121\n",
      "[1604/1762] D loss: 1.1461, G loss: 0.7173\n",
      "[1684/1762] D loss: 1.3889, G loss: 0.7342\n",
      "[1762/1762] D loss: 1.4012, G loss: 0.8007\n",
      "train error: \n",
      " D loss: 1.350384, G loss: 0.776441, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.339197, G loss: 0.778052, D accuracy: 54.7%, cell accuracy: 99.7%, board accuracy: 83.9% \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3899, G loss: 0.7055\n",
      "[84/1762] D loss: 1.2640, G loss: 0.7619\n",
      "[164/1762] D loss: 1.3878, G loss: 0.7000\n",
      "[244/1762] D loss: 1.3930, G loss: 0.7632\n",
      "[324/1762] D loss: 1.3884, G loss: 0.7219\n",
      "[404/1762] D loss: 1.3910, G loss: 0.7556\n",
      "[484/1762] D loss: 1.3989, G loss: 0.8014\n",
      "[564/1762] D loss: 1.3872, G loss: 0.6878\n",
      "[644/1762] D loss: 1.3848, G loss: 0.7209\n",
      "[724/1762] D loss: 1.3863, G loss: 0.7035\n",
      "[804/1762] D loss: 1.3910, G loss: 0.7033\n",
      "[884/1762] D loss: 1.2099, G loss: 0.7763\n",
      "[964/1762] D loss: 1.3905, G loss: 0.7555\n",
      "[1044/1762] D loss: 1.3904, G loss: 0.6882\n",
      "[1124/1762] D loss: 1.2718, G loss: 0.7690\n",
      "[1204/1762] D loss: 1.1972, G loss: 0.7806\n",
      "[1284/1762] D loss: 1.3908, G loss: 0.7145\n",
      "[1364/1762] D loss: 1.2213, G loss: 0.8336\n",
      "[1444/1762] D loss: 1.4086, G loss: 0.8051\n",
      "[1524/1762] D loss: 1.3890, G loss: 0.7443\n",
      "[1604/1762] D loss: 1.3880, G loss: 0.7329\n",
      "[1684/1762] D loss: 1.2128, G loss: 0.6932\n",
      "[1762/1762] D loss: 1.3888, G loss: 0.7107\n",
      "train error: \n",
      " D loss: 1.337926, G loss: 0.720937, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 83.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.323657, G loss: 0.726453, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 81.8% \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2115, G loss: 0.7397\n",
      "[84/1762] D loss: 1.3896, G loss: 0.7636\n",
      "[164/1762] D loss: 1.4037, G loss: 0.6129\n",
      "[244/1762] D loss: 1.3920, G loss: 0.7049\n",
      "[324/1762] D loss: 1.3870, G loss: 0.6688\n",
      "[404/1762] D loss: 1.3781, G loss: 0.7472\n",
      "[484/1762] D loss: 1.3818, G loss: 0.7189\n",
      "[564/1762] D loss: 1.3910, G loss: 0.7537\n",
      "[644/1762] D loss: 1.2006, G loss: 0.7578\n",
      "[724/1762] D loss: 1.3891, G loss: 0.6838\n",
      "[804/1762] D loss: 1.3912, G loss: 0.6672\n",
      "[884/1762] D loss: 1.2400, G loss: 0.7957\n",
      "[964/1762] D loss: 1.3925, G loss: 0.7331\n",
      "[1044/1762] D loss: 1.3903, G loss: 0.7159\n",
      "[1124/1762] D loss: 1.3880, G loss: 0.7391\n",
      "[1204/1762] D loss: 1.0300, G loss: 0.7276\n",
      "[1284/1762] D loss: 1.3943, G loss: 0.6636\n",
      "[1364/1762] D loss: 1.3926, G loss: 0.6429\n",
      "[1444/1762] D loss: 1.3887, G loss: 0.6524\n",
      "[1524/1762] D loss: 1.3852, G loss: 0.7035\n",
      "[1604/1762] D loss: 1.3961, G loss: 0.7829\n",
      "[1684/1762] D loss: 1.4002, G loss: 0.7822\n",
      "[1762/1762] D loss: 0.9006, G loss: 0.9673\n",
      "train error: \n",
      " D loss: 1.333782, G loss: 0.775296, D accuracy: 53.5%, cell accuracy: 99.7%, board accuracy: 80.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.318809, G loss: 0.780931, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 77.5% \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1891, G loss: 0.8264\n",
      "[84/1762] D loss: 1.1943, G loss: 0.7960\n",
      "[164/1762] D loss: 1.3993, G loss: 0.8138\n",
      "[244/1762] D loss: 1.3914, G loss: 0.7561\n",
      "[324/1762] D loss: 1.3973, G loss: 0.7943\n",
      "[404/1762] D loss: 1.3941, G loss: 0.7612\n",
      "[484/1762] D loss: 1.3876, G loss: 0.6926\n",
      "[564/1762] D loss: 1.1935, G loss: 0.7682\n",
      "[644/1762] D loss: 1.4110, G loss: 0.8142\n",
      "[724/1762] D loss: 1.1790, G loss: 0.8296\n",
      "[804/1762] D loss: 1.3890, G loss: 0.7189\n",
      "[884/1762] D loss: 1.3892, G loss: 0.7142\n",
      "[964/1762] D loss: 1.3879, G loss: 0.6576\n",
      "[1044/1762] D loss: 1.3925, G loss: 0.7077\n",
      "[1124/1762] D loss: 1.3878, G loss: 0.7211\n",
      "[1204/1762] D loss: 1.3888, G loss: 0.7679\n",
      "[1284/1762] D loss: 1.3869, G loss: 0.6979\n",
      "[1364/1762] D loss: 1.3915, G loss: 0.6668\n",
      "[1444/1762] D loss: 1.3894, G loss: 0.7330\n",
      "[1524/1762] D loss: 1.1652, G loss: 0.8147\n",
      "[1604/1762] D loss: 1.4418, G loss: 0.6598\n",
      "[1684/1762] D loss: 1.3659, G loss: 0.7380\n",
      "[1762/1762] D loss: 1.4131, G loss: 0.7374\n",
      "train error: \n",
      " D loss: 1.336056, G loss: 0.643988, D accuracy: 54.9%, cell accuracy: 99.7%, board accuracy: 67.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.319661, G loss: 0.652808, D accuracy: 56.1%, cell accuracy: 99.7%, board accuracy: 68.9% \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3982, G loss: 0.5810\n",
      "[84/1762] D loss: 1.1918, G loss: 0.6909\n",
      "[164/1762] D loss: 1.1556, G loss: 0.8096\n",
      "[244/1762] D loss: 1.3881, G loss: 0.6923\n",
      "[324/1762] D loss: 1.1838, G loss: 0.7320\n",
      "[404/1762] D loss: 1.1854, G loss: 0.7406\n",
      "[484/1762] D loss: 1.1587, G loss: 0.7929\n",
      "[564/1762] D loss: 1.3928, G loss: 0.8159\n",
      "[644/1762] D loss: 1.1784, G loss: 0.7770\n",
      "[724/1762] D loss: 1.1935, G loss: 0.7441\n",
      "[804/1762] D loss: 1.3953, G loss: 0.6871\n",
      "[884/1762] D loss: 1.3797, G loss: 0.6830\n",
      "[964/1762] D loss: 1.4114, G loss: 0.6620\n",
      "[1044/1762] D loss: 1.3965, G loss: 0.7631\n",
      "[1124/1762] D loss: 1.3737, G loss: 0.8067\n",
      "[1204/1762] D loss: 1.3877, G loss: 0.7724\n",
      "[1284/1762] D loss: 1.2060, G loss: 0.8657\n",
      "[1364/1762] D loss: 1.3990, G loss: 0.7410\n",
      "[1444/1762] D loss: 1.1821, G loss: 0.7258\n",
      "[1524/1762] D loss: 1.1856, G loss: 0.7589\n",
      "[1604/1762] D loss: 1.3834, G loss: 0.6841\n",
      "[1684/1762] D loss: 1.7831, G loss: 0.5627\n",
      "[1762/1762] D loss: 2.3797, G loss: 0.4087\n",
      "train error: \n",
      " D loss: 2.074439, G loss: 0.585397, D accuracy: 20.0%, cell accuracy: 96.9%, board accuracy: 2.7% \n",
      "\n",
      "test error: \n",
      " D loss: 2.065958, G loss: 0.579098, D accuracy: 20.2%, cell accuracy: 96.8%, board accuracy: 2.0% \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "[4/1762] D loss: 2.5016, G loss: 0.3170\n",
      "[84/1762] D loss: 1.4283, G loss: 0.8258\n",
      "[164/1762] D loss: 1.1820, G loss: 0.8152\n",
      "[244/1762] D loss: 1.0911, G loss: 0.8212\n",
      "[324/1762] D loss: 1.0514, G loss: 0.8742\n",
      "[404/1762] D loss: 1.4322, G loss: 0.7273\n",
      "[484/1762] D loss: 1.3830, G loss: 0.6520\n",
      "[564/1762] D loss: 1.3741, G loss: 0.6869\n",
      "[644/1762] D loss: 1.4145, G loss: 0.8001\n",
      "[724/1762] D loss: 1.3912, G loss: 0.6670\n",
      "[804/1762] D loss: 1.3904, G loss: 0.6857\n",
      "[884/1762] D loss: 1.4071, G loss: 0.7204\n",
      "[964/1762] D loss: 1.3922, G loss: 0.6919\n",
      "[1044/1762] D loss: 1.3927, G loss: 0.6219\n",
      "[1124/1762] D loss: 1.3876, G loss: 0.6786\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6996\n",
      "[1284/1762] D loss: 1.3962, G loss: 0.7564\n",
      "[1364/1762] D loss: 1.3898, G loss: 0.6914\n",
      "[1444/1762] D loss: 1.3915, G loss: 0.6341\n",
      "[1524/1762] D loss: 1.3876, G loss: 0.6960\n",
      "[1604/1762] D loss: 1.3849, G loss: 0.7166\n",
      "[1684/1762] D loss: 1.3890, G loss: 0.6996\n",
      "[1762/1762] D loss: 1.2595, G loss: 0.7305\n",
      "train error: \n",
      " D loss: 1.377506, G loss: 0.696693, D accuracy: 52.2%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.375198, G loss: 0.698248, D accuracy: 52.6%, cell accuracy: 99.7%, board accuracy: 82.5% \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3867, G loss: 0.6961\n",
      "[84/1762] D loss: 1.3851, G loss: 0.6852\n",
      "[164/1762] D loss: 1.3080, G loss: 0.6959\n",
      "[244/1762] D loss: 1.3868, G loss: 0.6886\n",
      "[324/1762] D loss: 1.3890, G loss: 0.6923\n",
      "[404/1762] D loss: 1.1943, G loss: 0.7377\n",
      "[484/1762] D loss: 1.3771, G loss: 0.7007\n",
      "[564/1762] D loss: 1.3872, G loss: 0.7205\n",
      "[644/1762] D loss: 1.2177, G loss: 0.7466\n",
      "[724/1762] D loss: 1.3963, G loss: 0.7163\n",
      "[804/1762] D loss: 1.3880, G loss: 0.7286\n",
      "[884/1762] D loss: 1.2719, G loss: 0.7245\n",
      "[964/1762] D loss: 1.1515, G loss: 0.7517\n",
      "[1044/1762] D loss: 1.2723, G loss: 0.7032\n",
      "[1124/1762] D loss: 1.3824, G loss: 0.6729\n",
      "[1204/1762] D loss: 1.3855, G loss: 0.7058\n",
      "[1284/1762] D loss: 1.3881, G loss: 0.6885\n",
      "[1364/1762] D loss: 1.3870, G loss: 0.6981\n",
      "[1444/1762] D loss: 1.3003, G loss: 0.7214\n",
      "[1524/1762] D loss: 1.3870, G loss: 0.6668\n",
      "[1604/1762] D loss: 1.3879, G loss: 0.7081\n",
      "[1684/1762] D loss: 1.2779, G loss: 0.7959\n",
      "[1762/1762] D loss: 1.3939, G loss: 0.7828\n",
      "train error: \n",
      " D loss: 1.353006, G loss: 0.755322, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 86.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.343001, G loss: 0.758693, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 83.4% \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3840, G loss: 0.7496\n",
      "[84/1762] D loss: 1.3829, G loss: 0.7257\n",
      "[164/1762] D loss: 1.3869, G loss: 0.7110\n",
      "[244/1762] D loss: 1.3868, G loss: 0.7021\n",
      "[324/1762] D loss: 1.3869, G loss: 0.6943\n",
      "[404/1762] D loss: 1.3865, G loss: 0.6797\n",
      "[484/1762] D loss: 1.3906, G loss: 0.7496\n",
      "[564/1762] D loss: 1.3915, G loss: 0.7494\n",
      "[644/1762] D loss: 1.3870, G loss: 0.7202\n",
      "[724/1762] D loss: 1.3875, G loss: 0.6750\n",
      "[804/1762] D loss: 1.2297, G loss: 0.7570\n",
      "[884/1762] D loss: 1.3865, G loss: 0.7686\n",
      "[964/1762] D loss: 1.2318, G loss: 0.7564\n",
      "[1044/1762] D loss: 1.3864, G loss: 0.7021\n",
      "[1124/1762] D loss: 1.2389, G loss: 0.7275\n",
      "[1204/1762] D loss: 1.3900, G loss: 0.6560\n",
      "[1284/1762] D loss: 1.3958, G loss: 0.7949\n",
      "[1364/1762] D loss: 1.0516, G loss: 0.8225\n",
      "[1444/1762] D loss: 1.2278, G loss: 0.7265\n",
      "[1524/1762] D loss: 1.3854, G loss: 0.7109\n",
      "[1604/1762] D loss: 1.3978, G loss: 0.7021\n",
      "[1684/1762] D loss: 1.3906, G loss: 0.6521\n",
      "[1762/1762] D loss: 1.3916, G loss: 0.6912\n",
      "train error: \n",
      " D loss: 1.344033, G loss: 0.796950, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.329775, G loss: 0.800994, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 83.4% \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3911, G loss: 0.7866\n",
      "[84/1762] D loss: 1.3866, G loss: 0.7171\n",
      "[164/1762] D loss: 1.2083, G loss: 0.7889\n",
      "[244/1762] D loss: 1.2144, G loss: 0.7064\n",
      "[324/1762] D loss: 1.3865, G loss: 0.6711\n",
      "[404/1762] D loss: 1.3978, G loss: 0.6752\n",
      "[484/1762] D loss: 1.3818, G loss: 0.6643\n",
      "[564/1762] D loss: 1.3929, G loss: 0.7581\n",
      "[644/1762] D loss: 1.2086, G loss: 0.7605\n",
      "[724/1762] D loss: 1.3896, G loss: 0.7230\n",
      "[804/1762] D loss: 1.3952, G loss: 0.7594\n",
      "[884/1762] D loss: 1.1877, G loss: 0.8325\n",
      "[964/1762] D loss: 1.3892, G loss: 0.7273\n",
      "[1044/1762] D loss: 1.3954, G loss: 0.7661\n",
      "[1124/1762] D loss: 1.3827, G loss: 0.7004\n",
      "[1204/1762] D loss: 1.3874, G loss: 0.7200\n",
      "[1284/1762] D loss: 1.3874, G loss: 0.7759\n",
      "[1364/1762] D loss: 1.3975, G loss: 0.7305\n",
      "[1444/1762] D loss: 1.3871, G loss: 0.6470\n",
      "[1524/1762] D loss: 1.2276, G loss: 0.8000\n",
      "[1604/1762] D loss: 1.3977, G loss: 0.7006\n",
      "[1684/1762] D loss: 1.3849, G loss: 0.6769\n",
      "[1762/1762] D loss: 0.9903, G loss: 0.9688\n",
      "train error: \n",
      " D loss: 1.335994, G loss: 0.792894, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 88.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.320032, G loss: 0.798424, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 85.2% \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3893, G loss: 0.7577\n",
      "[84/1762] D loss: 1.3884, G loss: 0.6867\n",
      "[164/1762] D loss: 1.3940, G loss: 0.7398\n",
      "[244/1762] D loss: 1.3911, G loss: 0.7731\n",
      "[324/1762] D loss: 1.3810, G loss: 0.7319\n",
      "[404/1762] D loss: 1.3876, G loss: 0.8038\n",
      "[484/1762] D loss: 1.1932, G loss: 0.7483\n",
      "[564/1762] D loss: 1.4124, G loss: 0.7044\n",
      "[644/1762] D loss: 0.9804, G loss: 0.8540\n",
      "[724/1762] D loss: 1.2194, G loss: 0.7904\n",
      "[804/1762] D loss: 1.4177, G loss: 0.7276\n",
      "[884/1762] D loss: 1.3948, G loss: 0.7224\n",
      "[964/1762] D loss: 1.3906, G loss: 0.7733\n",
      "[1044/1762] D loss: 1.3960, G loss: 0.7176\n",
      "[1124/1762] D loss: 1.3865, G loss: 0.7343\n",
      "[1204/1762] D loss: 1.3953, G loss: 0.7546\n",
      "[1284/1762] D loss: 1.3788, G loss: 0.7508\n",
      "[1364/1762] D loss: 1.3994, G loss: 0.8081\n",
      "[1444/1762] D loss: 1.3819, G loss: 0.8092\n",
      "[1524/1762] D loss: 1.2158, G loss: 0.8014\n",
      "[1604/1762] D loss: 1.2203, G loss: 0.7663\n",
      "[1684/1762] D loss: 1.3936, G loss: 0.7211\n",
      "[1762/1762] D loss: 1.3857, G loss: 0.7762\n",
      "train error: \n",
      " D loss: 1.333400, G loss: 0.781887, D accuracy: 53.3%, cell accuracy: 99.1%, board accuracy: 38.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.319348, G loss: 0.782397, D accuracy: 54.2%, cell accuracy: 99.0%, board accuracy: 35.5% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3894, G loss: 0.6519\n",
      "[84/1762] D loss: 1.3846, G loss: 0.6549\n",
      "[164/1762] D loss: 1.3734, G loss: 0.6608\n",
      "[244/1762] D loss: 1.3557, G loss: 0.6655\n",
      "[324/1762] D loss: 1.3347, G loss: 0.6722\n",
      "[404/1762] D loss: 1.4052, G loss: 0.6333\n",
      "[484/1762] D loss: 1.3866, G loss: 0.6771\n",
      "[564/1762] D loss: 1.3844, G loss: 0.6893\n",
      "[644/1762] D loss: 1.3830, G loss: 0.6877\n",
      "[724/1762] D loss: 1.3709, G loss: 0.6717\n",
      "[804/1762] D loss: 1.3418, G loss: 0.6898\n",
      "[884/1762] D loss: 1.3252, G loss: 0.7058\n",
      "[964/1762] D loss: 1.2894, G loss: 0.7368\n",
      "[1044/1762] D loss: 1.3267, G loss: 0.7658\n",
      "[1124/1762] D loss: 1.0127, G loss: 0.8805\n",
      "[1204/1762] D loss: 0.7004, G loss: 1.0575\n",
      "[1284/1762] D loss: 1.1097, G loss: 1.1188\n",
      "[1364/1762] D loss: 0.7022, G loss: 1.2816\n",
      "[1444/1762] D loss: 0.4788, G loss: 1.5440\n",
      "[1524/1762] D loss: 0.5051, G loss: 1.3183\n",
      "[1604/1762] D loss: 4.1937, G loss: 0.0259\n",
      "[1684/1762] D loss: 2.3482, G loss: 0.1787\n",
      "[1762/1762] D loss: 1.6810, G loss: 0.3143\n",
      "train error: \n",
      " D loss: 1.625574, G loss: 0.313005, D accuracy: 50.0%, cell accuracy: 13.6%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.622568, G loss: 0.313477, D accuracy: 50.0%, cell accuracy: 13.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.7694, G loss: 0.3082\n",
      "[84/1762] D loss: 1.3149, G loss: 0.4341\n",
      "[164/1762] D loss: 1.1550, G loss: 0.5138\n",
      "[244/1762] D loss: 0.9944, G loss: 0.5928\n",
      "[324/1762] D loss: 1.2159, G loss: 0.4910\n",
      "[404/1762] D loss: 1.0721, G loss: 0.6309\n",
      "[484/1762] D loss: 0.9463, G loss: 0.6862\n",
      "[564/1762] D loss: 0.9144, G loss: 0.7215\n",
      "[644/1762] D loss: 0.9148, G loss: 0.8066\n",
      "[724/1762] D loss: 1.0413, G loss: 0.7924\n",
      "[804/1762] D loss: 0.9951, G loss: 0.9317\n",
      "[884/1762] D loss: 0.9493, G loss: 0.8950\n",
      "[964/1762] D loss: 1.0016, G loss: 0.9503\n",
      "[1044/1762] D loss: 1.2134, G loss: 0.6890\n",
      "[1124/1762] D loss: 1.1880, G loss: 0.7772\n",
      "[1204/1762] D loss: 1.1305, G loss: 0.8012\n",
      "[1284/1762] D loss: 1.1530, G loss: 0.7729\n",
      "[1364/1762] D loss: 1.1010, G loss: 0.7890\n",
      "[1444/1762] D loss: 1.0985, G loss: 0.8160\n",
      "[1524/1762] D loss: 1.1133, G loss: 0.8792\n",
      "[1604/1762] D loss: 0.8208, G loss: 1.0581\n",
      "[1684/1762] D loss: 1.1454, G loss: 0.8008\n",
      "[1762/1762] D loss: 1.0018, G loss: 0.9751\n",
      "train error: \n",
      " D loss: 1.094033, G loss: 0.849094, D accuracy: 78.3%, cell accuracy: 91.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.086584, G loss: 0.853578, D accuracy: 77.7%, cell accuracy: 91.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1286, G loss: 0.8936\n",
      "[84/1762] D loss: 1.0184, G loss: 0.8114\n",
      "[164/1762] D loss: 1.0035, G loss: 0.9201\n",
      "[244/1762] D loss: 1.1262, G loss: 0.9439\n",
      "[324/1762] D loss: 0.6484, G loss: 1.2641\n",
      "[404/1762] D loss: 0.9309, G loss: 1.1793\n",
      "[484/1762] D loss: 0.6812, G loss: 1.1141\n",
      "[564/1762] D loss: 1.0301, G loss: 1.0359\n",
      "[644/1762] D loss: 0.9078, G loss: 1.0364\n",
      "[724/1762] D loss: 1.2013, G loss: 0.8140\n",
      "[804/1762] D loss: 0.7486, G loss: 1.0850\n",
      "[884/1762] D loss: 1.3030, G loss: 0.8089\n",
      "[964/1762] D loss: 0.4385, G loss: 2.2383\n",
      "[1044/1762] D loss: 0.7062, G loss: 1.3385\n",
      "[1124/1762] D loss: 1.0490, G loss: 1.1567\n",
      "[1204/1762] D loss: 0.9767, G loss: 1.1339\n",
      "[1284/1762] D loss: 0.8348, G loss: 1.3196\n",
      "[1364/1762] D loss: 0.7561, G loss: 1.2226\n",
      "[1444/1762] D loss: 0.7304, G loss: 1.8614\n",
      "[1524/1762] D loss: 0.7615, G loss: 1.3241\n",
      "[1604/1762] D loss: 0.7950, G loss: 1.4406\n",
      "[1684/1762] D loss: 0.8618, G loss: 0.8757\n",
      "[1762/1762] D loss: 0.0899, G loss: 3.3602\n",
      "train error: \n",
      " D loss: 0.793603, G loss: 1.924799, D accuracy: 81.8%, cell accuracy: 92.4%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.777742, G loss: 1.974896, D accuracy: 82.8%, cell accuracy: 92.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8112, G loss: 1.4871\n",
      "[84/1762] D loss: 0.6385, G loss: 1.6913\n",
      "[164/1762] D loss: 0.6058, G loss: 1.6409\n",
      "[244/1762] D loss: 1.0014, G loss: 1.1196\n",
      "[324/1762] D loss: 0.7346, G loss: 1.4695\n",
      "[404/1762] D loss: 0.4305, G loss: 1.8192\n",
      "[484/1762] D loss: 0.7358, G loss: 2.3352\n",
      "[564/1762] D loss: 0.6220, G loss: 2.1540\n",
      "[644/1762] D loss: 0.3606, G loss: 2.2734\n",
      "[724/1762] D loss: 0.7838, G loss: 1.5915\n",
      "[804/1762] D loss: 0.4989, G loss: 1.8557\n",
      "[884/1762] D loss: 0.8529, G loss: 2.0793\n",
      "[964/1762] D loss: 0.4904, G loss: 1.8665\n",
      "[1044/1762] D loss: 0.9806, G loss: 1.1851\n",
      "[1124/1762] D loss: 0.5100, G loss: 2.6231\n",
      "[1204/1762] D loss: 0.7035, G loss: 1.7249\n",
      "[1284/1762] D loss: 0.9536, G loss: 1.9042\n",
      "[1364/1762] D loss: 0.5944, G loss: 1.5192\n",
      "[1444/1762] D loss: 0.8794, G loss: 1.2280\n",
      "[1524/1762] D loss: 0.6326, G loss: 1.4844\n",
      "[1604/1762] D loss: 0.2783, G loss: 3.3281\n",
      "[1684/1762] D loss: 0.3716, G loss: 1.8994\n",
      "[1762/1762] D loss: 1.1399, G loss: 1.3056\n",
      "train error: \n",
      " D loss: 0.528816, G loss: 2.214110, D accuracy: 91.9%, cell accuracy: 91.6%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.530202, G loss: 2.218224, D accuracy: 91.7%, cell accuracy: 91.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.4519, G loss: 1.9550\n",
      "[84/1762] D loss: 0.3881, G loss: 2.9624\n",
      "[164/1762] D loss: 0.6063, G loss: 2.5939\n",
      "[244/1762] D loss: 0.5312, G loss: 2.4039\n",
      "[324/1762] D loss: 0.7362, G loss: 1.2627\n",
      "[404/1762] D loss: 0.6247, G loss: 2.0469\n",
      "[484/1762] D loss: 0.6599, G loss: 2.3527\n",
      "[564/1762] D loss: 1.2339, G loss: 2.2410\n",
      "[644/1762] D loss: 0.5402, G loss: 1.8571\n",
      "[724/1762] D loss: 1.3982, G loss: 1.8599\n",
      "[804/1762] D loss: 1.2337, G loss: 2.4730\n",
      "[884/1762] D loss: 0.3952, G loss: 1.8462\n",
      "[964/1762] D loss: 0.4620, G loss: 1.7352\n",
      "[1044/1762] D loss: 0.4061, G loss: 1.9312\n",
      "[1124/1762] D loss: 0.9288, G loss: 1.2147\n",
      "[1204/1762] D loss: 1.0922, G loss: 1.6640\n",
      "[1284/1762] D loss: 0.2422, G loss: 2.6818\n",
      "[1364/1762] D loss: 0.6566, G loss: 1.7203\n",
      "[1444/1762] D loss: 0.7728, G loss: 2.9334\n",
      "[1524/1762] D loss: 0.6444, G loss: 1.5107\n",
      "[1604/1762] D loss: 0.7571, G loss: 1.4658\n",
      "[1684/1762] D loss: 0.9265, G loss: 1.1742\n",
      "[1762/1762] D loss: 0.3237, G loss: 2.8984\n",
      "train error: \n",
      " D loss: 0.625002, G loss: 2.052448, D accuracy: 88.9%, cell accuracy: 94.8%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.625863, G loss: 2.030298, D accuracy: 89.1%, cell accuracy: 94.8%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5502, G loss: 1.6899\n",
      "[84/1762] D loss: 1.1507, G loss: 1.4035\n",
      "[164/1762] D loss: 0.4671, G loss: 1.3090\n",
      "[244/1762] D loss: 0.5123, G loss: 2.1556\n",
      "[324/1762] D loss: 0.6684, G loss: 1.5482\n",
      "[404/1762] D loss: 0.6836, G loss: 2.0474\n",
      "[484/1762] D loss: 0.5432, G loss: 1.9549\n",
      "[564/1762] D loss: 0.3763, G loss: 2.1370\n",
      "[644/1762] D loss: 0.3688, G loss: 2.6108\n",
      "[724/1762] D loss: 0.6541, G loss: 1.5918\n",
      "[804/1762] D loss: 0.4870, G loss: 2.0002\n",
      "[884/1762] D loss: 0.6586, G loss: 1.8623\n",
      "[964/1762] D loss: 0.7150, G loss: 2.6066\n",
      "[1044/1762] D loss: 0.5611, G loss: 2.1558\n",
      "[1124/1762] D loss: 0.6189, G loss: 1.6623\n",
      "[1204/1762] D loss: 0.4192, G loss: 2.7405\n",
      "[1284/1762] D loss: 0.7633, G loss: 1.4227\n",
      "[1364/1762] D loss: 0.8055, G loss: 1.0901\n",
      "[1444/1762] D loss: 0.5389, G loss: 2.1244\n",
      "[1524/1762] D loss: 0.2385, G loss: 3.0367\n",
      "[1604/1762] D loss: 0.3326, G loss: 2.4416\n",
      "[1684/1762] D loss: 0.2152, G loss: 3.2928\n",
      "[1762/1762] D loss: 0.7197, G loss: 1.8450\n",
      "train error: \n",
      " D loss: 0.464807, G loss: 2.631227, D accuracy: 93.7%, cell accuracy: 95.3%, board accuracy: 0.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.463868, G loss: 2.652570, D accuracy: 94.0%, cell accuracy: 95.2%, board accuracy: 0.5% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1123, G loss: 2.7530\n",
      "[84/1762] D loss: 0.1714, G loss: 3.3658\n",
      "[164/1762] D loss: 0.6634, G loss: 2.0618\n",
      "[244/1762] D loss: 0.2454, G loss: 2.9961\n",
      "[324/1762] D loss: 0.1051, G loss: 2.5449\n",
      "[404/1762] D loss: 0.4983, G loss: 1.8845\n",
      "[484/1762] D loss: 0.2869, G loss: 2.7737\n",
      "[564/1762] D loss: 0.3934, G loss: 2.6337\n",
      "[644/1762] D loss: 0.4044, G loss: 2.7317\n",
      "[724/1762] D loss: 0.1139, G loss: 3.0560\n",
      "[804/1762] D loss: 0.5471, G loss: 2.7979\n",
      "[884/1762] D loss: 0.2236, G loss: 4.2748\n",
      "[964/1762] D loss: 0.7291, G loss: 1.7396\n",
      "[1044/1762] D loss: 0.5664, G loss: 4.6762\n",
      "[1124/1762] D loss: 0.6243, G loss: 1.2538\n",
      "[1204/1762] D loss: 0.8844, G loss: 1.0960\n",
      "[1284/1762] D loss: 0.7334, G loss: 3.0423\n",
      "[1364/1762] D loss: 0.5241, G loss: 2.2923\n",
      "[1444/1762] D loss: 0.6186, G loss: 3.0215\n",
      "[1524/1762] D loss: 0.5460, G loss: 4.4761\n",
      "[1604/1762] D loss: 0.2780, G loss: 2.4615\n",
      "[1684/1762] D loss: 0.6930, G loss: 1.4259\n",
      "[1762/1762] D loss: 0.2048, G loss: 2.7081\n",
      "train error: \n",
      " D loss: 0.395817, G loss: 2.605097, D accuracy: 95.2%, cell accuracy: 95.8%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.391158, G loss: 2.592789, D accuracy: 95.9%, cell accuracy: 95.7%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3094, G loss: 2.9749\n",
      "[84/1762] D loss: 0.4500, G loss: 3.2275\n",
      "[164/1762] D loss: 0.1344, G loss: 5.1152\n",
      "[244/1762] D loss: 0.9487, G loss: 2.4211\n",
      "[324/1762] D loss: 0.1888, G loss: 2.5211\n",
      "[404/1762] D loss: 0.4166, G loss: 3.2147\n",
      "[484/1762] D loss: 0.3040, G loss: 2.7356\n",
      "[564/1762] D loss: 0.2191, G loss: 1.9642\n",
      "[644/1762] D loss: 0.2636, G loss: 2.5362\n",
      "[724/1762] D loss: 0.4874, G loss: 2.8578\n",
      "[804/1762] D loss: 0.3473, G loss: 2.5322\n",
      "[884/1762] D loss: 0.2992, G loss: 2.3955\n",
      "[964/1762] D loss: 0.6759, G loss: 1.7247\n",
      "[1044/1762] D loss: 0.3736, G loss: 3.0016\n",
      "[1124/1762] D loss: 0.4528, G loss: 3.5798\n",
      "[1204/1762] D loss: 0.2487, G loss: 2.0785\n",
      "[1284/1762] D loss: 0.2870, G loss: 4.0940\n",
      "[1364/1762] D loss: 0.4555, G loss: 4.5595\n",
      "[1444/1762] D loss: 0.0825, G loss: 6.1544\n",
      "[1524/1762] D loss: 0.8569, G loss: 1.1850\n",
      "[1604/1762] D loss: 0.2750, G loss: 2.4549\n",
      "[1684/1762] D loss: 0.6907, G loss: 1.8418\n",
      "[1762/1762] D loss: 0.0456, G loss: 4.0216\n",
      "train error: \n",
      " D loss: 0.380527, G loss: 3.380732, D accuracy: 93.9%, cell accuracy: 96.1%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.394581, G loss: 3.386377, D accuracy: 93.0%, cell accuracy: 96.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.3524, G loss: 2.9084\n",
      "[84/1762] D loss: 0.7427, G loss: 2.4304\n",
      "[164/1762] D loss: 0.4235, G loss: 2.6818\n",
      "[244/1762] D loss: 0.2598, G loss: 3.3353\n",
      "[324/1762] D loss: 0.6258, G loss: 2.5789\n",
      "[404/1762] D loss: 0.2131, G loss: 3.6699\n",
      "[484/1762] D loss: 0.2818, G loss: 4.4202\n",
      "[564/1762] D loss: 0.2813, G loss: 2.7145\n",
      "[644/1762] D loss: 0.4377, G loss: 2.0710\n",
      "[724/1762] D loss: 0.4886, G loss: 2.3792\n",
      "[804/1762] D loss: 0.0317, G loss: 6.1115\n",
      "[884/1762] D loss: 0.3978, G loss: 2.0194\n",
      "[964/1762] D loss: 0.2318, G loss: 1.8029\n",
      "[1044/1762] D loss: 0.1915, G loss: 2.7651\n",
      "[1124/1762] D loss: 0.4698, G loss: 1.9090\n",
      "[1204/1762] D loss: 0.7553, G loss: 1.6739\n",
      "[1284/1762] D loss: 0.4294, G loss: 1.7248\n",
      "[1364/1762] D loss: 1.2295, G loss: 2.0744\n",
      "[1444/1762] D loss: 0.2483, G loss: 2.6732\n",
      "[1524/1762] D loss: 0.1058, G loss: 3.8914\n",
      "[1604/1762] D loss: 0.5112, G loss: 2.1962\n",
      "[1684/1762] D loss: 0.0722, G loss: 4.2660\n",
      "[1762/1762] D loss: 0.1236, G loss: 2.8178\n",
      "train error: \n",
      " D loss: 0.348324, G loss: 3.577833, D accuracy: 94.8%, cell accuracy: 96.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.373482, G loss: 3.460798, D accuracy: 93.8%, cell accuracy: 96.8%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9025, G loss: 2.9611\n",
      "[84/1762] D loss: 0.1838, G loss: 3.1801\n",
      "[164/1762] D loss: 0.2325, G loss: 2.9802\n",
      "[244/1762] D loss: 0.3087, G loss: 2.9189\n",
      "[324/1762] D loss: 0.1108, G loss: 3.5097\n",
      "[404/1762] D loss: 0.1431, G loss: 2.5767\n",
      "[484/1762] D loss: 0.0978, G loss: 3.5731\n",
      "[564/1762] D loss: 0.2737, G loss: 3.2139\n",
      "[644/1762] D loss: 0.2235, G loss: 2.8766\n",
      "[724/1762] D loss: 0.4276, G loss: 2.4752\n",
      "[804/1762] D loss: 0.4814, G loss: 1.8822\n",
      "[884/1762] D loss: 0.4306, G loss: 4.2948\n",
      "[964/1762] D loss: 0.5911, G loss: 2.4883\n",
      "[1044/1762] D loss: 0.7951, G loss: 0.9280\n",
      "[1124/1762] D loss: 0.6163, G loss: 2.2388\n",
      "[1204/1762] D loss: 0.5770, G loss: 4.2251\n",
      "[1284/1762] D loss: 0.2126, G loss: 3.0704\n",
      "[1364/1762] D loss: 0.4703, G loss: 3.0412\n",
      "[1444/1762] D loss: 0.5891, G loss: 2.2425\n",
      "[1524/1762] D loss: 0.4085, G loss: 2.5830\n",
      "[1604/1762] D loss: 0.3241, G loss: 3.7919\n",
      "[1684/1762] D loss: 0.2841, G loss: 3.9435\n",
      "[1762/1762] D loss: 0.0154, G loss: 6.3176\n",
      "train error: \n",
      " D loss: 0.420137, G loss: 3.477453, D accuracy: 93.3%, cell accuracy: 97.2%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.439048, G loss: 3.375765, D accuracy: 92.0%, cell accuracy: 97.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1931, G loss: 4.7462\n",
      "[84/1762] D loss: 0.3934, G loss: 2.3353\n",
      "[164/1762] D loss: 0.2673, G loss: 4.4429\n",
      "[244/1762] D loss: 0.4050, G loss: 2.0913\n",
      "[324/1762] D loss: 0.2888, G loss: 2.9623\n",
      "[404/1762] D loss: 0.9741, G loss: 1.0038\n",
      "[484/1762] D loss: 0.3617, G loss: 2.6362\n",
      "[564/1762] D loss: 0.3382, G loss: 2.4108\n",
      "[644/1762] D loss: 0.8918, G loss: 1.9300\n",
      "[724/1762] D loss: 0.9577, G loss: 5.8553\n",
      "[804/1762] D loss: 0.4229, G loss: 3.1404\n",
      "[884/1762] D loss: 0.4299, G loss: 1.8260\n",
      "[964/1762] D loss: 0.4623, G loss: 4.7776\n",
      "[1044/1762] D loss: 0.8349, G loss: 1.7738\n",
      "[1124/1762] D loss: 0.7405, G loss: 1.9794\n",
      "[1204/1762] D loss: 0.8009, G loss: 3.1113\n",
      "[1284/1762] D loss: 0.7290, G loss: 2.0574\n",
      "[1364/1762] D loss: 0.5793, G loss: 2.8945\n",
      "[1444/1762] D loss: 0.7368, G loss: 4.1377\n",
      "[1524/1762] D loss: 0.2973, G loss: 1.9429\n",
      "[1604/1762] D loss: 0.5750, G loss: 1.4201\n",
      "[1684/1762] D loss: 1.0395, G loss: 3.2282\n",
      "[1762/1762] D loss: 0.3450, G loss: 1.6482\n",
      "train error: \n",
      " D loss: 1.006618, G loss: 1.072943, D accuracy: 75.0%, cell accuracy: 97.9%, board accuracy: 0.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.014195, G loss: 1.125250, D accuracy: 77.0%, cell accuracy: 97.9%, board accuracy: 0.5% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1958, G loss: 0.9396\n",
      "[84/1762] D loss: 1.2368, G loss: 4.1876\n",
      "[164/1762] D loss: 0.5363, G loss: 2.5763\n",
      "[244/1762] D loss: 0.5009, G loss: 1.8417\n",
      "[324/1762] D loss: 1.4215, G loss: 0.5011\n",
      "[404/1762] D loss: 0.4500, G loss: 2.3079\n",
      "[484/1762] D loss: 0.6482, G loss: 1.2828\n",
      "[564/1762] D loss: 0.8110, G loss: 3.0136\n",
      "[644/1762] D loss: 0.7830, G loss: 1.6727\n",
      "[724/1762] D loss: 0.4822, G loss: 3.0825\n",
      "[804/1762] D loss: 0.7012, G loss: 2.4062\n",
      "[884/1762] D loss: 1.0635, G loss: 1.5255\n",
      "[964/1762] D loss: 0.9116, G loss: 1.8540\n",
      "[1044/1762] D loss: 2.2466, G loss: 2.8573\n",
      "[1124/1762] D loss: 0.8106, G loss: 1.2288\n",
      "[1204/1762] D loss: 0.7681, G loss: 1.6265\n",
      "[1284/1762] D loss: 1.0986, G loss: 1.3479\n",
      "[1364/1762] D loss: 0.8308, G loss: 2.7507\n",
      "[1444/1762] D loss: 0.7514, G loss: 1.2028\n",
      "[1524/1762] D loss: 1.1227, G loss: 1.6375\n",
      "[1604/1762] D loss: 1.1704, G loss: 0.9618\n",
      "[1684/1762] D loss: 1.2606, G loss: 2.0192\n",
      "[1762/1762] D loss: 0.7074, G loss: 1.3715\n",
      "train error: \n",
      " D loss: 1.081894, G loss: 1.373691, D accuracy: 73.2%, cell accuracy: 98.6%, board accuracy: 14.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.045581, G loss: 1.533586, D accuracy: 75.7%, cell accuracy: 98.4%, board accuracy: 12.7% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.5151, G loss: 2.1535\n",
      "[84/1762] D loss: 0.8477, G loss: 2.0074\n",
      "[164/1762] D loss: 1.5035, G loss: 1.3455\n",
      "[244/1762] D loss: 1.0052, G loss: 1.4245\n",
      "[324/1762] D loss: 1.1554, G loss: 1.2221\n",
      "[404/1762] D loss: 1.3264, G loss: 1.1608\n",
      "[484/1762] D loss: 0.7939, G loss: 1.1714\n",
      "[564/1762] D loss: 1.2531, G loss: 1.9280\n",
      "[644/1762] D loss: 1.4982, G loss: 0.7331\n",
      "[724/1762] D loss: 0.6405, G loss: 2.3213\n",
      "[804/1762] D loss: 0.6329, G loss: 2.9115\n",
      "[884/1762] D loss: 1.0222, G loss: 0.8118\n",
      "[964/1762] D loss: 0.9789, G loss: 1.0890\n",
      "[1044/1762] D loss: 1.2497, G loss: 1.2399\n",
      "[1124/1762] D loss: 1.3030, G loss: 0.7247\n",
      "[1204/1762] D loss: 1.2652, G loss: 1.2750\n",
      "[1284/1762] D loss: 1.1033, G loss: 0.9658\n",
      "[1364/1762] D loss: 0.8789, G loss: 3.3328\n",
      "[1444/1762] D loss: 1.3059, G loss: 1.5935\n",
      "[1524/1762] D loss: 0.8379, G loss: 1.2348\n",
      "[1604/1762] D loss: 1.0489, G loss: 1.3731\n",
      "[1684/1762] D loss: 1.0978, G loss: 1.2311\n",
      "[1762/1762] D loss: 1.3102, G loss: 0.4599\n",
      "train error: \n",
      " D loss: 1.177682, G loss: 1.077346, D accuracy: 68.9%, cell accuracy: 98.7%, board accuracy: 17.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.144077, G loss: 1.166848, D accuracy: 70.9%, cell accuracy: 98.6%, board accuracy: 15.2% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9075, G loss: 0.8364\n",
      "[84/1762] D loss: 0.8767, G loss: 1.0301\n",
      "[164/1762] D loss: 1.2348, G loss: 2.2371\n",
      "[244/1762] D loss: 1.2185, G loss: 1.1084\n",
      "[324/1762] D loss: 0.9295, G loss: 0.9591\n",
      "[404/1762] D loss: 0.8786, G loss: 1.0864\n",
      "[484/1762] D loss: 1.3598, G loss: 1.4002\n",
      "[564/1762] D loss: 1.2238, G loss: 0.5947\n",
      "[644/1762] D loss: 1.6843, G loss: 1.7637\n",
      "[724/1762] D loss: 1.2468, G loss: 1.4931\n",
      "[804/1762] D loss: 1.0096, G loss: 1.3984\n",
      "[884/1762] D loss: 1.1087, G loss: 1.2252\n",
      "[964/1762] D loss: 1.1347, G loss: 0.9821\n",
      "[1044/1762] D loss: 0.9551, G loss: 1.1686\n",
      "[1124/1762] D loss: 1.3110, G loss: 0.8286\n",
      "[1204/1762] D loss: 1.3150, G loss: 0.5672\n",
      "[1284/1762] D loss: 0.8246, G loss: 1.1610\n",
      "[1364/1762] D loss: 1.4745, G loss: 0.8837\n",
      "[1444/1762] D loss: 1.2860, G loss: 0.8426\n",
      "[1524/1762] D loss: 1.2888, G loss: 1.4929\n",
      "[1604/1762] D loss: 1.5001, G loss: 0.7587\n",
      "[1684/1762] D loss: 1.0628, G loss: 1.2791\n",
      "[1762/1762] D loss: 0.8576, G loss: 1.8843\n",
      "train error: \n",
      " D loss: 1.182766, G loss: 1.231370, D accuracy: 67.3%, cell accuracy: 99.0%, board accuracy: 27.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.184768, G loss: 1.292253, D accuracy: 68.0%, cell accuracy: 98.9%, board accuracy: 24.1% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4629, G loss: 1.0143\n",
      "[84/1762] D loss: 1.1496, G loss: 0.7846\n",
      "[164/1762] D loss: 1.4003, G loss: 1.1320\n",
      "[244/1762] D loss: 1.6329, G loss: 2.7500\n",
      "[324/1762] D loss: 1.2929, G loss: 0.8464\n",
      "[404/1762] D loss: 1.4440, G loss: 0.7808\n",
      "[484/1762] D loss: 1.2454, G loss: 1.0370\n",
      "[564/1762] D loss: 1.1341, G loss: 1.1520\n",
      "[644/1762] D loss: 1.4654, G loss: 1.2725\n",
      "[724/1762] D loss: 0.9944, G loss: 1.3375\n",
      "[804/1762] D loss: 0.8095, G loss: 1.5863\n",
      "[884/1762] D loss: 1.2672, G loss: 0.7716\n",
      "[964/1762] D loss: 0.9887, G loss: 1.7685\n",
      "[1044/1762] D loss: 0.9405, G loss: 1.6043\n",
      "[1124/1762] D loss: 1.4500, G loss: 0.6629\n",
      "[1204/1762] D loss: 1.0284, G loss: 1.3960\n",
      "[1284/1762] D loss: 1.2287, G loss: 0.4327\n",
      "[1364/1762] D loss: 0.8133, G loss: 1.4198\n",
      "[1444/1762] D loss: 1.3608, G loss: 0.8771\n",
      "[1524/1762] D loss: 1.0821, G loss: 1.4273\n",
      "[1604/1762] D loss: 1.2478, G loss: 0.8385\n",
      "[1684/1762] D loss: 1.2989, G loss: 1.8980\n",
      "[1762/1762] D loss: 1.5764, G loss: 1.1357\n",
      "train error: \n",
      " D loss: 1.244333, G loss: 1.189078, D accuracy: 64.1%, cell accuracy: 99.1%, board accuracy: 33.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.251673, G loss: 1.250180, D accuracy: 65.2%, cell accuracy: 99.0%, board accuracy: 31.1% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0458, G loss: 1.1416\n",
      "[84/1762] D loss: 0.9842, G loss: 0.7549\n",
      "[164/1762] D loss: 1.0904, G loss: 1.1313\n",
      "[244/1762] D loss: 0.8746, G loss: 1.2624\n",
      "[324/1762] D loss: 0.9774, G loss: 1.4483\n",
      "[404/1762] D loss: 1.8204, G loss: 1.1806\n",
      "[484/1762] D loss: 1.0274, G loss: 0.7924\n",
      "[564/1762] D loss: 1.4191, G loss: 1.8511\n",
      "[644/1762] D loss: 1.2948, G loss: 1.4557\n",
      "[724/1762] D loss: 1.1649, G loss: 1.6777\n",
      "[804/1762] D loss: 1.5627, G loss: 0.4739\n",
      "[884/1762] D loss: 1.4523, G loss: 0.8013\n",
      "[964/1762] D loss: 1.2547, G loss: 0.5798\n",
      "[1044/1762] D loss: 1.0583, G loss: 1.5509\n",
      "[1124/1762] D loss: 1.0739, G loss: 1.2849\n",
      "[1204/1762] D loss: 1.1336, G loss: 0.7722\n",
      "[1284/1762] D loss: 1.3700, G loss: 0.8088\n",
      "[1364/1762] D loss: 1.1961, G loss: 0.9736\n",
      "[1444/1762] D loss: 1.0975, G loss: 1.0421\n",
      "[1524/1762] D loss: 1.3965, G loss: 0.4625\n",
      "[1604/1762] D loss: 1.0328, G loss: 1.2648\n",
      "[1684/1762] D loss: 1.5139, G loss: 0.4663\n",
      "[1762/1762] D loss: 1.7696, G loss: 1.0665\n",
      "train error: \n",
      " D loss: 1.303779, G loss: 1.043991, D accuracy: 61.9%, cell accuracy: 99.3%, board accuracy: 44.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.314654, G loss: 1.081070, D accuracy: 62.4%, cell accuracy: 99.2%, board accuracy: 42.0% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1028, G loss: 0.9954\n",
      "[84/1762] D loss: 1.0227, G loss: 1.2893\n",
      "[164/1762] D loss: 1.3788, G loss: 0.6938\n",
      "[244/1762] D loss: 0.8825, G loss: 1.2926\n",
      "[324/1762] D loss: 1.1602, G loss: 1.0140\n",
      "[404/1762] D loss: 1.3890, G loss: 0.7235\n",
      "[484/1762] D loss: 1.4695, G loss: 0.4339\n",
      "[564/1762] D loss: 1.2383, G loss: 0.8022\n",
      "[644/1762] D loss: 1.2796, G loss: 1.3139\n",
      "[724/1762] D loss: 1.1811, G loss: 1.3523\n",
      "[804/1762] D loss: 1.3387, G loss: 0.5747\n",
      "[884/1762] D loss: 1.1601, G loss: 1.4326\n",
      "[964/1762] D loss: 1.6062, G loss: 0.4933\n",
      "[1044/1762] D loss: 1.1957, G loss: 1.0671\n",
      "[1124/1762] D loss: 1.2364, G loss: 0.9703\n",
      "[1204/1762] D loss: 1.4124, G loss: 1.3708\n",
      "[1284/1762] D loss: 1.2373, G loss: 0.8331\n",
      "[1364/1762] D loss: 1.1591, G loss: 1.0310\n",
      "[1444/1762] D loss: 1.2948, G loss: 1.5530\n",
      "[1524/1762] D loss: 1.3531, G loss: 0.6565\n",
      "[1604/1762] D loss: 1.8173, G loss: 2.0789\n",
      "[1684/1762] D loss: 1.4470, G loss: 0.7518\n",
      "[1762/1762] D loss: 1.2326, G loss: 1.1292\n",
      "train error: \n",
      " D loss: 1.357817, G loss: 1.227386, D accuracy: 59.0%, cell accuracy: 99.3%, board accuracy: 49.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.377834, G loss: 1.247535, D accuracy: 57.4%, cell accuracy: 99.3%, board accuracy: 47.3% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2490, G loss: 1.0636\n",
      "[84/1762] D loss: 1.4294, G loss: 0.4928\n",
      "[164/1762] D loss: 1.4101, G loss: 1.4524\n",
      "[244/1762] D loss: 1.0131, G loss: 0.8985\n",
      "[324/1762] D loss: 1.2262, G loss: 1.6596\n",
      "[404/1762] D loss: 1.3225, G loss: 0.7003\n",
      "[484/1762] D loss: 1.3925, G loss: 0.7121\n",
      "[564/1762] D loss: 1.4600, G loss: 0.5378\n",
      "[644/1762] D loss: 0.9751, G loss: 1.0926\n",
      "[724/1762] D loss: 1.2945, G loss: 1.1265\n",
      "[804/1762] D loss: 1.3735, G loss: 0.8033\n",
      "[884/1762] D loss: 1.4817, G loss: 0.7714\n",
      "[964/1762] D loss: 1.2816, G loss: 0.7614\n",
      "[1044/1762] D loss: 1.5581, G loss: 0.8647\n",
      "[1124/1762] D loss: 1.3113, G loss: 1.2319\n",
      "[1204/1762] D loss: 1.4232, G loss: 0.7583\n",
      "[1284/1762] D loss: 1.1913, G loss: 0.9117\n",
      "[1364/1762] D loss: 1.3130, G loss: 0.6924\n",
      "[1444/1762] D loss: 1.1989, G loss: 0.5981\n",
      "[1524/1762] D loss: 1.6561, G loss: 0.5269\n",
      "[1604/1762] D loss: 1.4563, G loss: 0.7638\n",
      "[1684/1762] D loss: 1.2265, G loss: 1.9351\n",
      "[1762/1762] D loss: 1.5838, G loss: 0.4160\n",
      "train error: \n",
      " D loss: 1.309504, G loss: 0.820800, D accuracy: 60.6%, cell accuracy: 99.3%, board accuracy: 50.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.319193, G loss: 0.836590, D accuracy: 61.6%, cell accuracy: 99.3%, board accuracy: 46.6% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3823, G loss: 1.6491\n",
      "[84/1762] D loss: 1.3404, G loss: 0.6977\n",
      "[164/1762] D loss: 1.3386, G loss: 0.8708\n",
      "[244/1762] D loss: 1.3230, G loss: 1.5157\n",
      "[324/1762] D loss: 1.1038, G loss: 0.8161\n",
      "[404/1762] D loss: 1.2634, G loss: 0.9860\n",
      "[484/1762] D loss: 1.0887, G loss: 0.9001\n",
      "[564/1762] D loss: 1.2120, G loss: 0.8509\n",
      "[644/1762] D loss: 1.4664, G loss: 0.5585\n",
      "[724/1762] D loss: 1.0573, G loss: 1.2169\n",
      "[804/1762] D loss: 1.1019, G loss: 1.1349\n",
      "[884/1762] D loss: 0.9712, G loss: 1.1495\n",
      "[964/1762] D loss: 1.0851, G loss: 1.2188\n",
      "[1044/1762] D loss: 1.3770, G loss: 0.5736\n",
      "[1124/1762] D loss: 1.6064, G loss: 0.7751\n",
      "[1204/1762] D loss: 1.5243, G loss: 1.4788\n",
      "[1284/1762] D loss: 1.2728, G loss: 1.0595\n",
      "[1364/1762] D loss: 0.8960, G loss: 0.9926\n",
      "[1444/1762] D loss: 1.6054, G loss: 0.3461\n",
      "[1524/1762] D loss: 1.3885, G loss: 0.6569\n",
      "[1604/1762] D loss: 1.2390, G loss: 0.6730\n",
      "[1684/1762] D loss: 1.4356, G loss: 1.1355\n",
      "[1762/1762] D loss: 1.3725, G loss: 0.6608\n",
      "train error: \n",
      " D loss: 1.271367, G loss: 0.882499, D accuracy: 63.0%, cell accuracy: 99.4%, board accuracy: 53.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.285664, G loss: 0.894411, D accuracy: 64.0%, cell accuracy: 99.4%, board accuracy: 48.6% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1555, G loss: 1.0532\n",
      "[84/1762] D loss: 1.2289, G loss: 0.9495\n",
      "[164/1762] D loss: 1.2189, G loss: 0.7459\n",
      "[244/1762] D loss: 0.9346, G loss: 1.4243\n",
      "[324/1762] D loss: 1.1717, G loss: 0.9343\n",
      "[404/1762] D loss: 1.4080, G loss: 1.0232\n",
      "[484/1762] D loss: 1.2692, G loss: 0.9180\n",
      "[564/1762] D loss: 1.0993, G loss: 1.3297\n",
      "[644/1762] D loss: 1.2408, G loss: 0.7115\n",
      "[724/1762] D loss: 1.3586, G loss: 0.7001\n",
      "[804/1762] D loss: 1.5396, G loss: 1.0739\n",
      "[884/1762] D loss: 1.0874, G loss: 1.5583\n",
      "[964/1762] D loss: 1.3390, G loss: 1.2030\n",
      "[1044/1762] D loss: 1.5541, G loss: 0.5862\n",
      "[1124/1762] D loss: 1.4785, G loss: 1.2149\n",
      "[1204/1762] D loss: 1.2009, G loss: 0.7917\n",
      "[1284/1762] D loss: 1.1199, G loss: 0.7529\n",
      "[1364/1762] D loss: 1.2202, G loss: 0.8555\n",
      "[1444/1762] D loss: 1.2724, G loss: 0.9302\n",
      "[1524/1762] D loss: 1.2180, G loss: 1.1605\n",
      "[1604/1762] D loss: 1.3593, G loss: 0.5926\n",
      "[1684/1762] D loss: 1.4114, G loss: 0.6068\n",
      "[1762/1762] D loss: 1.1190, G loss: 1.3400\n",
      "train error: \n",
      " D loss: 1.281961, G loss: 0.863194, D accuracy: 61.2%, cell accuracy: 99.4%, board accuracy: 53.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.291894, G loss: 0.871388, D accuracy: 62.2%, cell accuracy: 99.4%, board accuracy: 49.8% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3937, G loss: 0.8984\n",
      "[84/1762] D loss: 1.3910, G loss: 0.6707\n",
      "[164/1762] D loss: 1.1963, G loss: 1.0129\n",
      "[244/1762] D loss: 1.0680, G loss: 0.9697\n",
      "[324/1762] D loss: 1.1790, G loss: 0.8976\n",
      "[404/1762] D loss: 1.1524, G loss: 0.8547\n",
      "[484/1762] D loss: 1.6419, G loss: 0.5109\n",
      "[564/1762] D loss: 1.4929, G loss: 0.5695\n",
      "[644/1762] D loss: 1.4527, G loss: 0.7750\n",
      "[724/1762] D loss: 1.4391, G loss: 0.7986\n",
      "[804/1762] D loss: 1.4997, G loss: 1.4558\n",
      "[884/1762] D loss: 1.4485, G loss: 0.9452\n",
      "[964/1762] D loss: 0.9384, G loss: 1.4405\n",
      "[1044/1762] D loss: 1.2047, G loss: 0.8382\n",
      "[1124/1762] D loss: 1.2706, G loss: 0.8669\n",
      "[1204/1762] D loss: 1.3329, G loss: 0.8336\n",
      "[1284/1762] D loss: 1.3352, G loss: 0.9235\n",
      "[1364/1762] D loss: 1.4025, G loss: 1.0742\n",
      "[1444/1762] D loss: 1.2702, G loss: 0.8442\n",
      "[1524/1762] D loss: 1.2227, G loss: 0.8631\n",
      "[1604/1762] D loss: 1.0970, G loss: 0.9651\n",
      "[1684/1762] D loss: 1.0546, G loss: 1.2476\n",
      "[1762/1762] D loss: 1.2462, G loss: 0.7552\n",
      "train error: \n",
      " D loss: 1.271510, G loss: 1.031376, D accuracy: 61.7%, cell accuracy: 99.4%, board accuracy: 53.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.281033, G loss: 1.042508, D accuracy: 60.9%, cell accuracy: 99.4%, board accuracy: 50.0% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2002, G loss: 0.9625\n",
      "[84/1762] D loss: 1.4365, G loss: 1.1262\n",
      "[164/1762] D loss: 0.9980, G loss: 0.8277\n",
      "[244/1762] D loss: 1.2158, G loss: 0.8671\n",
      "[324/1762] D loss: 1.1385, G loss: 0.8850\n",
      "[404/1762] D loss: 1.2479, G loss: 0.7981\n",
      "[484/1762] D loss: 1.3505, G loss: 1.1757\n",
      "[564/1762] D loss: 1.3148, G loss: 0.7571\n",
      "[644/1762] D loss: 0.9603, G loss: 1.4796\n",
      "[724/1762] D loss: 1.3311, G loss: 1.4774\n",
      "[804/1762] D loss: 1.2245, G loss: 0.8707\n",
      "[884/1762] D loss: 1.2105, G loss: 0.8238\n",
      "[964/1762] D loss: 1.1662, G loss: 1.1081\n",
      "[1044/1762] D loss: 1.1607, G loss: 1.2276\n",
      "[1124/1762] D loss: 1.4945, G loss: 1.0283\n",
      "[1204/1762] D loss: 1.1786, G loss: 0.7596\n",
      "[1284/1762] D loss: 1.3016, G loss: 1.5794\n",
      "[1364/1762] D loss: 1.2178, G loss: 1.0626\n",
      "[1444/1762] D loss: 1.2936, G loss: 0.9197\n",
      "[1524/1762] D loss: 1.0042, G loss: 1.0087\n",
      "[1604/1762] D loss: 1.0108, G loss: 1.2190\n",
      "[1684/1762] D loss: 1.3186, G loss: 1.1171\n",
      "[1762/1762] D loss: 1.5544, G loss: 1.0453\n",
      "train error: \n",
      " D loss: 1.260481, G loss: 0.753112, D accuracy: 62.8%, cell accuracy: 99.4%, board accuracy: 53.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.267141, G loss: 0.760370, D accuracy: 64.7%, cell accuracy: 99.4%, board accuracy: 49.8% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.8890, G loss: 0.9966\n",
      "[84/1762] D loss: 1.3722, G loss: 0.6631\n",
      "[164/1762] D loss: 1.0861, G loss: 1.3297\n",
      "[244/1762] D loss: 1.5935, G loss: 0.8386\n",
      "[324/1762] D loss: 1.1789, G loss: 0.9185\n",
      "[404/1762] D loss: 1.5337, G loss: 1.2649\n",
      "[484/1762] D loss: 1.2480, G loss: 0.8207\n",
      "[564/1762] D loss: 1.0689, G loss: 1.4463\n",
      "[644/1762] D loss: 1.5680, G loss: 0.7636\n",
      "[724/1762] D loss: 0.8505, G loss: 1.3932\n",
      "[804/1762] D loss: 1.4456, G loss: 0.8633\n",
      "[884/1762] D loss: 1.2919, G loss: 0.5688\n",
      "[964/1762] D loss: 1.1549, G loss: 1.2624\n",
      "[1044/1762] D loss: 1.2967, G loss: 0.6883\n",
      "[1124/1762] D loss: 1.1916, G loss: 2.1359\n",
      "[1204/1762] D loss: 1.6214, G loss: 0.5124\n",
      "[1284/1762] D loss: 1.3605, G loss: 0.9410\n",
      "[1364/1762] D loss: 1.3329, G loss: 0.5605\n",
      "[1444/1762] D loss: 1.4606, G loss: 0.9624\n",
      "[1524/1762] D loss: 1.5222, G loss: 0.8825\n",
      "[1604/1762] D loss: 0.9745, G loss: 1.1088\n",
      "[1684/1762] D loss: 1.2151, G loss: 1.0321\n",
      "[1762/1762] D loss: 1.4433, G loss: 0.8251\n",
      "train error: \n",
      " D loss: 1.341037, G loss: 1.396741, D accuracy: 59.3%, cell accuracy: 99.4%, board accuracy: 55.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.347418, G loss: 1.400035, D accuracy: 56.9%, cell accuracy: 99.4%, board accuracy: 51.4% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2648, G loss: 1.8539\n",
      "[84/1762] D loss: 1.3757, G loss: 1.1162\n",
      "[164/1762] D loss: 1.2256, G loss: 0.9533\n",
      "[244/1762] D loss: 1.3801, G loss: 0.6072\n",
      "[324/1762] D loss: 1.1576, G loss: 0.9717\n",
      "[404/1762] D loss: 0.8978, G loss: 1.1086\n",
      "[484/1762] D loss: 0.8867, G loss: 1.2338\n",
      "[564/1762] D loss: 0.8603, G loss: 1.4222\n",
      "[644/1762] D loss: 1.4343, G loss: 0.7698\n",
      "[724/1762] D loss: 1.4723, G loss: 0.9488\n",
      "[804/1762] D loss: 1.1099, G loss: 0.9763\n",
      "[884/1762] D loss: 0.9425, G loss: 1.5933\n",
      "[964/1762] D loss: 1.4679, G loss: 0.5132\n",
      "[1044/1762] D loss: 1.3624, G loss: 1.2955\n",
      "[1124/1762] D loss: 1.2175, G loss: 0.9157\n",
      "[1204/1762] D loss: 1.3958, G loss: 0.6506\n",
      "[1284/1762] D loss: 1.0104, G loss: 1.1978\n",
      "[1364/1762] D loss: 1.2878, G loss: 0.7706\n",
      "[1444/1762] D loss: 1.2835, G loss: 0.7063\n",
      "[1524/1762] D loss: 1.3171, G loss: 0.8488\n",
      "[1604/1762] D loss: 1.3351, G loss: 0.8522\n",
      "[1684/1762] D loss: 0.9825, G loss: 1.1211\n",
      "[1762/1762] D loss: 1.3860, G loss: 0.7255\n",
      "train error: \n",
      " D loss: 1.214951, G loss: 0.832819, D accuracy: 64.2%, cell accuracy: 99.4%, board accuracy: 55.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.221852, G loss: 0.837512, D accuracy: 66.0%, cell accuracy: 99.4%, board accuracy: 51.6% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1945, G loss: 0.6511\n",
      "[84/1762] D loss: 1.4235, G loss: 0.7307\n",
      "[164/1762] D loss: 0.9647, G loss: 1.0708\n",
      "[244/1762] D loss: 1.5282, G loss: 0.8505\n",
      "[324/1762] D loss: 0.6751, G loss: 1.3613\n",
      "[404/1762] D loss: 1.2852, G loss: 1.2704\n",
      "[484/1762] D loss: 1.1184, G loss: 0.9525\n",
      "[564/1762] D loss: 1.3495, G loss: 0.5173\n",
      "[644/1762] D loss: 1.0596, G loss: 0.8600\n",
      "[724/1762] D loss: 1.4487, G loss: 0.5587\n",
      "[804/1762] D loss: 1.0615, G loss: 1.1969\n",
      "[884/1762] D loss: 0.9160, G loss: 1.2268\n",
      "[964/1762] D loss: 1.0066, G loss: 1.2145\n",
      "[1044/1762] D loss: 1.5238, G loss: 1.4322\n",
      "[1124/1762] D loss: 1.2863, G loss: 1.0733\n",
      "[1204/1762] D loss: 1.3114, G loss: 0.8117\n",
      "[1284/1762] D loss: 1.4581, G loss: 0.7047\n",
      "[1364/1762] D loss: 1.2005, G loss: 0.8615\n",
      "[1444/1762] D loss: 1.3203, G loss: 0.5499\n",
      "[1524/1762] D loss: 1.4016, G loss: 0.5401\n",
      "[1604/1762] D loss: 1.4038, G loss: 1.0151\n",
      "[1684/1762] D loss: 0.8324, G loss: 1.4236\n",
      "[1762/1762] D loss: 1.5256, G loss: 0.4598\n",
      "train error: \n",
      " D loss: 1.321761, G loss: 1.122700, D accuracy: 58.2%, cell accuracy: 99.5%, board accuracy: 65.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.305786, G loss: 1.151630, D accuracy: 58.2%, cell accuracy: 99.5%, board accuracy: 59.1% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3907, G loss: 0.9586\n",
      "[84/1762] D loss: 0.9941, G loss: 1.4313\n",
      "[164/1762] D loss: 1.1944, G loss: 0.9471\n",
      "[244/1762] D loss: 1.1441, G loss: 0.8893\n",
      "[324/1762] D loss: 1.5069, G loss: 0.5836\n",
      "[404/1762] D loss: 1.4241, G loss: 0.5475\n",
      "[484/1762] D loss: 1.3493, G loss: 1.0556\n",
      "[564/1762] D loss: 1.5404, G loss: 1.0169\n",
      "[644/1762] D loss: 1.1358, G loss: 0.8237\n",
      "[724/1762] D loss: 1.2973, G loss: 0.6760\n",
      "[804/1762] D loss: 1.6252, G loss: 0.4239\n",
      "[884/1762] D loss: 1.4140, G loss: 0.8320\n",
      "[964/1762] D loss: 1.3626, G loss: 0.8489\n",
      "[1044/1762] D loss: 1.6057, G loss: 0.6757\n",
      "[1124/1762] D loss: 1.3676, G loss: 0.7284\n",
      "[1204/1762] D loss: 1.2334, G loss: 0.7771\n",
      "[1284/1762] D loss: 1.1703, G loss: 0.7061\n",
      "[1364/1762] D loss: 0.9728, G loss: 1.3849\n",
      "[1444/1762] D loss: 1.0313, G loss: 1.2377\n",
      "[1524/1762] D loss: 1.4468, G loss: 0.5488\n",
      "[1604/1762] D loss: 1.2811, G loss: 1.2134\n",
      "[1684/1762] D loss: 1.4314, G loss: 0.6630\n",
      "[1762/1762] D loss: 1.0588, G loss: 0.9474\n",
      "train error: \n",
      " D loss: 1.370763, G loss: 0.655796, D accuracy: 57.1%, cell accuracy: 99.6%, board accuracy: 72.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.369756, G loss: 0.651590, D accuracy: 56.9%, cell accuracy: 99.6%, board accuracy: 69.3% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3429, G loss: 0.7417\n",
      "[84/1762] D loss: 1.3959, G loss: 1.2696\n",
      "[164/1762] D loss: 1.4212, G loss: 0.7236\n",
      "[244/1762] D loss: 1.2211, G loss: 0.7470\n",
      "[324/1762] D loss: 1.4782, G loss: 0.9943\n",
      "[404/1762] D loss: 1.4288, G loss: 0.9436\n",
      "[484/1762] D loss: 1.2187, G loss: 0.9839\n",
      "[564/1762] D loss: 1.3580, G loss: 0.5866\n",
      "[644/1762] D loss: 1.4330, G loss: 0.6197\n",
      "[724/1762] D loss: 1.4104, G loss: 0.6186\n",
      "[804/1762] D loss: 1.3799, G loss: 0.7156\n",
      "[884/1762] D loss: 1.3439, G loss: 0.7878\n",
      "[964/1762] D loss: 1.4908, G loss: 0.8138\n",
      "[1044/1762] D loss: 1.4899, G loss: 1.0921\n",
      "[1124/1762] D loss: 1.3770, G loss: 0.6184\n",
      "[1204/1762] D loss: 1.3520, G loss: 0.7368\n",
      "[1284/1762] D loss: 1.4049, G loss: 0.6894\n",
      "[1364/1762] D loss: 1.5078, G loss: 0.5888\n",
      "[1444/1762] D loss: 1.3010, G loss: 0.9753\n",
      "[1524/1762] D loss: 1.2675, G loss: 0.7485\n",
      "[1604/1762] D loss: 1.0320, G loss: 1.2393\n",
      "[1684/1762] D loss: 1.4171, G loss: 0.8608\n",
      "[1762/1762] D loss: 1.4510, G loss: 0.9322\n",
      "train error: \n",
      " D loss: 1.355231, G loss: 0.799802, D accuracy: 55.3%, cell accuracy: 99.7%, board accuracy: 78.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.360579, G loss: 0.787848, D accuracy: 55.7%, cell accuracy: 99.6%, board accuracy: 76.4% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4318, G loss: 0.7217\n",
      "[84/1762] D loss: 1.3514, G loss: 0.5409\n",
      "[164/1762] D loss: 1.3631, G loss: 0.6924\n",
      "[244/1762] D loss: 1.4134, G loss: 0.8448\n",
      "[324/1762] D loss: 1.4589, G loss: 0.6568\n",
      "[404/1762] D loss: 1.4655, G loss: 0.7900\n",
      "[484/1762] D loss: 1.1996, G loss: 1.2024\n",
      "[564/1762] D loss: 1.3070, G loss: 1.1986\n",
      "[644/1762] D loss: 1.3916, G loss: 0.9463\n",
      "[724/1762] D loss: 1.3392, G loss: 0.6702\n",
      "[804/1762] D loss: 0.9832, G loss: 1.3628\n",
      "[884/1762] D loss: 1.3423, G loss: 0.7627\n",
      "[964/1762] D loss: 1.5062, G loss: 0.7465\n",
      "[1044/1762] D loss: 1.4793, G loss: 0.7541\n",
      "[1124/1762] D loss: 1.3005, G loss: 0.6445\n",
      "[1204/1762] D loss: 1.4277, G loss: 0.7869\n",
      "[1284/1762] D loss: 1.3629, G loss: 0.8729\n",
      "[1364/1762] D loss: 1.4635, G loss: 0.9645\n",
      "[1444/1762] D loss: 1.3725, G loss: 0.7629\n",
      "[1524/1762] D loss: 1.3920, G loss: 0.6971\n",
      "[1604/1762] D loss: 1.2775, G loss: 0.7039\n",
      "[1684/1762] D loss: 1.0292, G loss: 1.0167\n",
      "[1762/1762] D loss: 1.3945, G loss: 0.8237\n",
      "train error: \n",
      " D loss: 1.358221, G loss: 0.902837, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 78.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.363387, G loss: 0.896560, D accuracy: 55.3%, cell accuracy: 99.6%, board accuracy: 75.7% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4053, G loss: 0.6516\n",
      "[84/1762] D loss: 1.3177, G loss: 1.1547\n",
      "[164/1762] D loss: 1.3880, G loss: 0.7263\n",
      "[244/1762] D loss: 1.4720, G loss: 0.8176\n",
      "[324/1762] D loss: 1.3663, G loss: 0.5650\n",
      "[404/1762] D loss: 0.9867, G loss: 1.5454\n",
      "[484/1762] D loss: 1.4421, G loss: 0.5969\n",
      "[564/1762] D loss: 1.5180, G loss: 0.6307\n",
      "[644/1762] D loss: 1.1427, G loss: 0.9922\n",
      "[724/1762] D loss: 1.3122, G loss: 0.7780\n",
      "[804/1762] D loss: 1.4171, G loss: 0.6122\n",
      "[884/1762] D loss: 1.3252, G loss: 1.0038\n",
      "[964/1762] D loss: 1.3681, G loss: 0.8635\n",
      "[1044/1762] D loss: 1.5629, G loss: 1.0604\n",
      "[1124/1762] D loss: 1.2689, G loss: 1.0470\n",
      "[1204/1762] D loss: 1.3389, G loss: 0.6773\n",
      "[1284/1762] D loss: 1.1146, G loss: 0.9672\n",
      "[1364/1762] D loss: 1.3072, G loss: 0.7368\n",
      "[1444/1762] D loss: 1.3993, G loss: 0.6341\n",
      "[1524/1762] D loss: 1.0580, G loss: 1.0404\n",
      "[1604/1762] D loss: 1.3993, G loss: 0.8020\n",
      "[1684/1762] D loss: 1.4276, G loss: 0.5860\n",
      "[1762/1762] D loss: 1.0024, G loss: 1.7486\n",
      "train error: \n",
      " D loss: 1.347509, G loss: 0.840027, D accuracy: 55.2%, cell accuracy: 99.7%, board accuracy: 78.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.353995, G loss: 0.839217, D accuracy: 54.9%, cell accuracy: 99.6%, board accuracy: 76.1% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4248, G loss: 0.7700\n",
      "[84/1762] D loss: 1.4251, G loss: 0.6152\n",
      "[164/1762] D loss: 1.2013, G loss: 0.9892\n",
      "[244/1762] D loss: 1.4096, G loss: 0.8032\n",
      "[324/1762] D loss: 1.2325, G loss: 1.1176\n",
      "[404/1762] D loss: 1.3864, G loss: 0.5785\n",
      "[484/1762] D loss: 1.4033, G loss: 0.5905\n",
      "[564/1762] D loss: 1.2263, G loss: 1.0475\n",
      "[644/1762] D loss: 1.2606, G loss: 0.6983\n",
      "[724/1762] D loss: 1.3060, G loss: 0.6827\n",
      "[804/1762] D loss: 1.3521, G loss: 0.5941\n",
      "[884/1762] D loss: 1.2641, G loss: 1.1814\n",
      "[964/1762] D loss: 1.3453, G loss: 0.7370\n",
      "[1044/1762] D loss: 1.4507, G loss: 0.8514\n",
      "[1124/1762] D loss: 1.3993, G loss: 0.6688\n",
      "[1204/1762] D loss: 1.3490, G loss: 0.8004\n",
      "[1284/1762] D loss: 1.1583, G loss: 1.0082\n",
      "[1364/1762] D loss: 1.3475, G loss: 0.8374\n",
      "[1444/1762] D loss: 1.1495, G loss: 0.7250\n",
      "[1524/1762] D loss: 1.4012, G loss: 0.6237\n",
      "[1604/1762] D loss: 1.3991, G loss: 0.6652\n",
      "[1684/1762] D loss: 1.1862, G loss: 1.0114\n",
      "[1762/1762] D loss: 1.3996, G loss: 0.6260\n",
      "train error: \n",
      " D loss: 1.344309, G loss: 0.747058, D accuracy: 55.6%, cell accuracy: 99.6%, board accuracy: 78.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.351957, G loss: 0.742838, D accuracy: 55.2%, cell accuracy: 99.6%, board accuracy: 76.1% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3908, G loss: 0.7092\n",
      "[84/1762] D loss: 1.3987, G loss: 0.8842\n",
      "[164/1762] D loss: 1.3868, G loss: 0.6497\n",
      "[244/1762] D loss: 1.1878, G loss: 0.9485\n",
      "[324/1762] D loss: 1.4101, G loss: 0.8707\n",
      "[404/1762] D loss: 1.4010, G loss: 0.7005\n",
      "[484/1762] D loss: 1.5057, G loss: 1.1043\n",
      "[564/1762] D loss: 1.2449, G loss: 0.8176\n",
      "[644/1762] D loss: 1.3792, G loss: 0.7453\n",
      "[724/1762] D loss: 1.2192, G loss: 0.9417\n",
      "[804/1762] D loss: 1.4051, G loss: 0.7902\n",
      "[884/1762] D loss: 1.4468, G loss: 0.7480\n",
      "[964/1762] D loss: 1.6094, G loss: 0.5961\n",
      "[1044/1762] D loss: 1.1417, G loss: 1.0725\n",
      "[1124/1762] D loss: 1.4094, G loss: 0.6422\n",
      "[1204/1762] D loss: 1.4410, G loss: 0.8040\n",
      "[1284/1762] D loss: 1.4052, G loss: 0.6153\n",
      "[1364/1762] D loss: 1.4558, G loss: 0.5370\n",
      "[1444/1762] D loss: 1.5213, G loss: 0.9642\n",
      "[1524/1762] D loss: 1.3369, G loss: 0.6981\n",
      "[1604/1762] D loss: 1.2791, G loss: 0.9411\n",
      "[1684/1762] D loss: 1.1999, G loss: 0.7896\n",
      "[1762/1762] D loss: 1.2881, G loss: 0.7209\n",
      "train error: \n",
      " D loss: 1.340172, G loss: 0.798505, D accuracy: 55.2%, cell accuracy: 99.7%, board accuracy: 78.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.347398, G loss: 0.791329, D accuracy: 55.2%, cell accuracy: 99.6%, board accuracy: 76.6% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3215, G loss: 0.7861\n",
      "[84/1762] D loss: 1.3854, G loss: 0.6597\n",
      "[164/1762] D loss: 1.4201, G loss: 0.9388\n",
      "[244/1762] D loss: 1.3240, G loss: 0.7437\n",
      "[324/1762] D loss: 1.4078, G loss: 0.7704\n",
      "[404/1762] D loss: 1.2378, G loss: 1.2863\n",
      "[484/1762] D loss: 1.4160, G loss: 0.7154\n",
      "[564/1762] D loss: 1.4080, G loss: 0.8003\n",
      "[644/1762] D loss: 1.4554, G loss: 0.6070\n",
      "[724/1762] D loss: 1.2467, G loss: 1.0959\n",
      "[804/1762] D loss: 1.3420, G loss: 0.7194\n",
      "[884/1762] D loss: 1.3334, G loss: 0.7890\n",
      "[964/1762] D loss: 1.0412, G loss: 1.0667\n",
      "[1044/1762] D loss: 1.1662, G loss: 1.3266\n",
      "[1124/1762] D loss: 1.1602, G loss: 1.2916\n",
      "[1204/1762] D loss: 1.3516, G loss: 0.8295\n",
      "[1284/1762] D loss: 1.3827, G loss: 0.8647\n",
      "[1364/1762] D loss: 1.3083, G loss: 0.8378\n",
      "[1444/1762] D loss: 1.2636, G loss: 1.3505\n",
      "[1524/1762] D loss: 1.4567, G loss: 0.6090\n",
      "[1604/1762] D loss: 1.1678, G loss: 1.1680\n",
      "[1684/1762] D loss: 1.1593, G loss: 1.2608\n",
      "[1762/1762] D loss: 1.0615, G loss: 1.4371\n",
      "train error: \n",
      " D loss: 1.331073, G loss: 0.772462, D accuracy: 56.2%, cell accuracy: 99.7%, board accuracy: 78.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.335912, G loss: 0.767843, D accuracy: 55.8%, cell accuracy: 99.6%, board accuracy: 76.4% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1534, G loss: 1.0948\n",
      "[84/1762] D loss: 1.1615, G loss: 0.9334\n",
      "[164/1762] D loss: 1.4128, G loss: 0.5996\n",
      "[244/1762] D loss: 1.4257, G loss: 0.7625\n",
      "[324/1762] D loss: 1.4477, G loss: 0.5548\n",
      "[404/1762] D loss: 1.1779, G loss: 1.2056\n",
      "[484/1762] D loss: 1.3947, G loss: 0.5684\n",
      "[564/1762] D loss: 1.4562, G loss: 0.5142\n",
      "[644/1762] D loss: 1.4163, G loss: 0.8126\n",
      "[724/1762] D loss: 1.4155, G loss: 0.5706\n",
      "[804/1762] D loss: 1.4033, G loss: 0.8200\n",
      "[884/1762] D loss: 1.2128, G loss: 0.6972\n",
      "[964/1762] D loss: 1.1243, G loss: 1.1018\n",
      "[1044/1762] D loss: 1.1860, G loss: 1.2163\n",
      "[1124/1762] D loss: 1.3812, G loss: 0.7325\n",
      "[1204/1762] D loss: 1.3839, G loss: 0.6567\n",
      "[1284/1762] D loss: 1.4441, G loss: 0.5198\n",
      "[1364/1762] D loss: 1.4162, G loss: 0.7949\n",
      "[1444/1762] D loss: 1.4367, G loss: 0.5105\n",
      "[1524/1762] D loss: 1.3464, G loss: 0.8066\n",
      "[1604/1762] D loss: 1.4518, G loss: 0.5454\n",
      "[1684/1762] D loss: 1.4606, G loss: 0.6788\n",
      "[1762/1762] D loss: 1.4065, G loss: 0.6735\n",
      "train error: \n",
      " D loss: 1.330775, G loss: 0.813800, D accuracy: 56.1%, cell accuracy: 99.7%, board accuracy: 78.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.335272, G loss: 0.809450, D accuracy: 56.1%, cell accuracy: 99.6%, board accuracy: 76.1% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3796, G loss: 0.7279\n",
      "[84/1762] D loss: 1.4296, G loss: 0.5579\n",
      "[164/1762] D loss: 1.4125, G loss: 0.6779\n",
      "[244/1762] D loss: 1.4041, G loss: 0.6983\n",
      "[324/1762] D loss: 1.4495, G loss: 0.9781\n",
      "[404/1762] D loss: 1.3591, G loss: 0.5701\n",
      "[484/1762] D loss: 1.3718, G loss: 0.7352\n",
      "[564/1762] D loss: 1.1861, G loss: 0.7843\n",
      "[644/1762] D loss: 1.3018, G loss: 0.8889\n",
      "[724/1762] D loss: 1.4086, G loss: 0.5188\n",
      "[804/1762] D loss: 1.3714, G loss: 0.8817\n",
      "[884/1762] D loss: 1.4195, G loss: 0.8090\n",
      "[964/1762] D loss: 1.1758, G loss: 0.7522\n",
      "[1044/1762] D loss: 1.2302, G loss: 0.8907\n",
      "[1124/1762] D loss: 1.2497, G loss: 0.8367\n",
      "[1204/1762] D loss: 1.4302, G loss: 0.5299\n",
      "[1284/1762] D loss: 1.2244, G loss: 0.8886\n",
      "[1364/1762] D loss: 1.3804, G loss: 0.6125\n",
      "[1444/1762] D loss: 1.4130, G loss: 0.8012\n",
      "[1524/1762] D loss: 1.4019, G loss: 0.6317\n",
      "[1604/1762] D loss: 1.3078, G loss: 0.9995\n",
      "[1684/1762] D loss: 1.4178, G loss: 0.5384\n",
      "[1762/1762] D loss: 1.3415, G loss: 0.9025\n",
      "train error: \n",
      " D loss: 1.310637, G loss: 0.747354, D accuracy: 58.1%, cell accuracy: 99.7%, board accuracy: 73.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.317319, G loss: 0.744273, D accuracy: 57.4%, cell accuracy: 99.6%, board accuracy: 71.6% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1045, G loss: 1.0186\n",
      "[84/1762] D loss: 1.4142, G loss: 0.8504\n",
      "[164/1762] D loss: 1.1718, G loss: 1.1268\n",
      "[244/1762] D loss: 1.4017, G loss: 0.6395\n",
      "[324/1762] D loss: 1.2654, G loss: 0.8432\n",
      "[404/1762] D loss: 1.2167, G loss: 0.9147\n",
      "[484/1762] D loss: 1.0437, G loss: 1.2224\n",
      "[564/1762] D loss: 1.4572, G loss: 0.5771\n",
      "[644/1762] D loss: 1.3965, G loss: 0.7713\n",
      "[724/1762] D loss: 1.2883, G loss: 0.6514\n",
      "[804/1762] D loss: 1.3959, G loss: 0.5969\n",
      "[884/1762] D loss: 1.0778, G loss: 1.1177\n",
      "[964/1762] D loss: 1.4061, G loss: 0.8125\n",
      "[1044/1762] D loss: 1.4101, G loss: 0.8427\n",
      "[1124/1762] D loss: 1.2112, G loss: 0.8908\n",
      "[1204/1762] D loss: 1.2520, G loss: 0.6902\n",
      "[1284/1762] D loss: 1.3630, G loss: 0.7709\n",
      "[1364/1762] D loss: 1.3882, G loss: 0.6893\n",
      "[1444/1762] D loss: 1.3667, G loss: 0.7571\n",
      "[1524/1762] D loss: 1.4147, G loss: 0.6033\n",
      "[1604/1762] D loss: 1.3754, G loss: 0.7222\n",
      "[1684/1762] D loss: 1.3745, G loss: 0.7752\n",
      "[1762/1762] D loss: 1.4260, G loss: 0.8890\n",
      "train error: \n",
      " D loss: 1.324483, G loss: 0.872781, D accuracy: 55.8%, cell accuracy: 99.7%, board accuracy: 77.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.330100, G loss: 0.869522, D accuracy: 55.3%, cell accuracy: 99.6%, board accuracy: 74.3% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4118, G loss: 0.8290\n",
      "[84/1762] D loss: 1.3719, G loss: 0.7815\n",
      "[164/1762] D loss: 1.1423, G loss: 0.8805\n",
      "[244/1762] D loss: 1.4006, G loss: 0.6416\n",
      "[324/1762] D loss: 1.3883, G loss: 0.6521\n",
      "[404/1762] D loss: 1.3631, G loss: 0.5617\n",
      "[484/1762] D loss: 1.4311, G loss: 0.8016\n",
      "[564/1762] D loss: 1.4607, G loss: 0.5064\n",
      "[644/1762] D loss: 1.3985, G loss: 0.6365\n",
      "[724/1762] D loss: 1.3660, G loss: 0.7565\n",
      "[804/1762] D loss: 1.4099, G loss: 0.6053\n",
      "[884/1762] D loss: 1.4112, G loss: 0.8252\n",
      "[964/1762] D loss: 1.1482, G loss: 1.0900\n",
      "[1044/1762] D loss: 1.1883, G loss: 0.8414\n",
      "[1124/1762] D loss: 1.4164, G loss: 0.5272\n",
      "[1204/1762] D loss: 0.8806, G loss: 1.2442\n",
      "[1284/1762] D loss: 1.2644, G loss: 0.7725\n",
      "[1364/1762] D loss: 1.3610, G loss: 0.7467\n",
      "[1444/1762] D loss: 1.3607, G loss: 0.8377\n",
      "[1524/1762] D loss: 1.4437, G loss: 0.5266\n",
      "[1604/1762] D loss: 1.3410, G loss: 0.8113\n",
      "[1684/1762] D loss: 1.3448, G loss: 0.6264\n",
      "[1762/1762] D loss: 1.4568, G loss: 0.9770\n",
      "train error: \n",
      " D loss: 1.329902, G loss: 0.865511, D accuracy: 55.4%, cell accuracy: 99.7%, board accuracy: 79.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.337009, G loss: 0.865191, D accuracy: 54.7%, cell accuracy: 99.6%, board accuracy: 77.5% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4002, G loss: 0.7534\n",
      "[84/1762] D loss: 1.3382, G loss: 0.7916\n",
      "[164/1762] D loss: 1.4205, G loss: 0.7690\n",
      "[244/1762] D loss: 1.3950, G loss: 0.6787\n",
      "[324/1762] D loss: 1.3667, G loss: 0.6951\n",
      "[404/1762] D loss: 1.3199, G loss: 0.7510\n",
      "[484/1762] D loss: 1.2395, G loss: 1.0179\n",
      "[564/1762] D loss: 1.2164, G loss: 0.9903\n",
      "[644/1762] D loss: 1.2625, G loss: 0.7679\n",
      "[724/1762] D loss: 1.4009, G loss: 0.6474\n",
      "[804/1762] D loss: 1.0888, G loss: 1.1471\n",
      "[884/1762] D loss: 1.2012, G loss: 1.0757\n",
      "[964/1762] D loss: 1.3112, G loss: 0.6141\n",
      "[1044/1762] D loss: 1.3398, G loss: 0.7504\n",
      "[1124/1762] D loss: 1.3332, G loss: 0.7770\n",
      "[1204/1762] D loss: 1.4068, G loss: 0.6914\n",
      "[1284/1762] D loss: 1.3541, G loss: 0.6653\n",
      "[1364/1762] D loss: 1.4047, G loss: 0.5781\n",
      "[1444/1762] D loss: 1.1710, G loss: 0.8729\n",
      "[1524/1762] D loss: 1.4454, G loss: 0.5998\n",
      "[1604/1762] D loss: 1.1514, G loss: 1.1130\n",
      "[1684/1762] D loss: 1.3353, G loss: 0.6454\n",
      "[1762/1762] D loss: 1.2454, G loss: 0.8224\n",
      "train error: \n",
      " D loss: 1.317596, G loss: 0.815890, D accuracy: 56.8%, cell accuracy: 99.7%, board accuracy: 76.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.322270, G loss: 0.819103, D accuracy: 56.9%, cell accuracy: 99.7%, board accuracy: 76.4% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3887, G loss: 0.7400\n",
      "[84/1762] D loss: 1.4119, G loss: 0.6517\n",
      "[164/1762] D loss: 1.3953, G loss: 0.6844\n",
      "[244/1762] D loss: 1.2592, G loss: 0.9935\n",
      "[324/1762] D loss: 1.4183, G loss: 0.6696\n",
      "[404/1762] D loss: 1.2486, G loss: 0.9406\n",
      "[484/1762] D loss: 1.2825, G loss: 0.6475\n",
      "[564/1762] D loss: 1.2829, G loss: 0.9251\n",
      "[644/1762] D loss: 1.1639, G loss: 0.8856\n",
      "[724/1762] D loss: 1.2013, G loss: 0.9320\n",
      "[804/1762] D loss: 1.4011, G loss: 0.7917\n",
      "[884/1762] D loss: 1.4100, G loss: 0.5313\n",
      "[964/1762] D loss: 1.3961, G loss: 0.6499\n",
      "[1044/1762] D loss: 1.1700, G loss: 0.8059\n",
      "[1124/1762] D loss: 1.2363, G loss: 0.8394\n",
      "[1204/1762] D loss: 1.2527, G loss: 0.8001\n",
      "[1284/1762] D loss: 1.3910, G loss: 0.7499\n",
      "[1364/1762] D loss: 1.4515, G loss: 0.7636\n",
      "[1444/1762] D loss: 1.3865, G loss: 0.7397\n",
      "[1524/1762] D loss: 1.2260, G loss: 0.7072\n",
      "[1604/1762] D loss: 1.4153, G loss: 0.6775\n",
      "[1684/1762] D loss: 1.2339, G loss: 0.7293\n",
      "[1762/1762] D loss: 1.3326, G loss: 0.5911\n",
      "train error: \n",
      " D loss: 1.338176, G loss: 0.676537, D accuracy: 56.5%, cell accuracy: 99.7%, board accuracy: 76.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.339967, G loss: 0.680782, D accuracy: 56.2%, cell accuracy: 99.7%, board accuracy: 75.9% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4038, G loss: 0.5743\n",
      "[84/1762] D loss: 1.3956, G loss: 0.6339\n",
      "[164/1762] D loss: 1.3165, G loss: 0.7787\n",
      "[244/1762] D loss: 1.3952, G loss: 0.6130\n",
      "[324/1762] D loss: 1.3945, G loss: 0.6364\n",
      "[404/1762] D loss: 1.3121, G loss: 0.7448\n",
      "[484/1762] D loss: 1.3225, G loss: 0.6203\n",
      "[564/1762] D loss: 1.3888, G loss: 0.7288\n",
      "[644/1762] D loss: 1.4050, G loss: 0.8586\n",
      "[724/1762] D loss: 1.3364, G loss: 0.8480\n",
      "[804/1762] D loss: 0.9723, G loss: 1.0965\n",
      "[884/1762] D loss: 1.3041, G loss: 1.1008\n",
      "[964/1762] D loss: 1.1010, G loss: 1.3877\n",
      "[1044/1762] D loss: 1.3410, G loss: 0.6245\n",
      "[1124/1762] D loss: 1.3300, G loss: 0.8757\n",
      "[1204/1762] D loss: 1.3915, G loss: 0.7117\n",
      "[1284/1762] D loss: 1.3339, G loss: 0.8142\n",
      "[1364/1762] D loss: 1.4532, G loss: 0.5576\n",
      "[1444/1762] D loss: 1.2557, G loss: 1.0199\n",
      "[1524/1762] D loss: 1.0902, G loss: 0.8673\n",
      "[1604/1762] D loss: 1.1300, G loss: 0.9953\n",
      "[1684/1762] D loss: 1.1643, G loss: 0.9464\n",
      "[1762/1762] D loss: 1.4061, G loss: 0.6226\n",
      "train error: \n",
      " D loss: 1.337705, G loss: 0.742722, D accuracy: 55.7%, cell accuracy: 99.7%, board accuracy: 76.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.335924, G loss: 0.751027, D accuracy: 56.0%, cell accuracy: 99.7%, board accuracy: 76.1% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3932, G loss: 0.6970\n",
      "[84/1762] D loss: 1.3511, G loss: 0.7948\n",
      "[164/1762] D loss: 1.3250, G loss: 0.6736\n",
      "[244/1762] D loss: 1.3958, G loss: 0.5569\n",
      "[324/1762] D loss: 1.4171, G loss: 0.6958\n",
      "[404/1762] D loss: 1.3729, G loss: 0.8474\n",
      "[484/1762] D loss: 1.4246, G loss: 0.5453\n",
      "[564/1762] D loss: 1.4665, G loss: 0.7046\n",
      "[644/1762] D loss: 0.9384, G loss: 1.2108\n",
      "[724/1762] D loss: 1.2357, G loss: 0.8497\n",
      "[804/1762] D loss: 1.3181, G loss: 0.7280\n",
      "[884/1762] D loss: 1.3471, G loss: 0.7337\n",
      "[964/1762] D loss: 1.3903, G loss: 0.8079\n",
      "[1044/1762] D loss: 1.1031, G loss: 1.2532\n",
      "[1124/1762] D loss: 1.1728, G loss: 0.8009\n",
      "[1204/1762] D loss: 1.3889, G loss: 0.6503\n",
      "[1284/1762] D loss: 1.2158, G loss: 0.9398\n",
      "[1364/1762] D loss: 1.3912, G loss: 0.5950\n",
      "[1444/1762] D loss: 1.3872, G loss: 0.8803\n",
      "[1524/1762] D loss: 1.4175, G loss: 0.7711\n",
      "[1604/1762] D loss: 1.2059, G loss: 0.8741\n",
      "[1684/1762] D loss: 1.3257, G loss: 0.8398\n",
      "[1762/1762] D loss: 1.3733, G loss: 0.7062\n",
      "train error: \n",
      " D loss: 1.325996, G loss: 0.821576, D accuracy: 56.0%, cell accuracy: 99.7%, board accuracy: 72.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.325238, G loss: 0.825688, D accuracy: 56.5%, cell accuracy: 99.6%, board accuracy: 72.0% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3184, G loss: 0.7628\n",
      "[84/1762] D loss: 1.3913, G loss: 0.6952\n",
      "[164/1762] D loss: 1.3743, G loss: 0.8778\n",
      "[244/1762] D loss: 1.3784, G loss: 0.8239\n",
      "[324/1762] D loss: 1.3391, G loss: 0.8520\n",
      "[404/1762] D loss: 1.3172, G loss: 0.8839\n",
      "[484/1762] D loss: 1.4042, G loss: 0.7111\n",
      "[564/1762] D loss: 1.4391, G loss: 0.9450\n",
      "[644/1762] D loss: 1.4376, G loss: 0.5883\n",
      "[724/1762] D loss: 1.3885, G loss: 0.6566\n",
      "[804/1762] D loss: 1.2097, G loss: 0.8477\n",
      "[884/1762] D loss: 1.3924, G loss: 0.7507\n",
      "[964/1762] D loss: 1.3040, G loss: 0.6783\n",
      "[1044/1762] D loss: 1.3877, G loss: 0.6726\n",
      "[1124/1762] D loss: 1.2295, G loss: 0.8404\n",
      "[1204/1762] D loss: 1.2307, G loss: 1.1920\n",
      "[1284/1762] D loss: 1.4320, G loss: 0.6532\n",
      "[1364/1762] D loss: 1.3621, G loss: 0.7999\n",
      "[1444/1762] D loss: 1.4472, G loss: 0.6846\n",
      "[1524/1762] D loss: 1.3922, G loss: 0.6315\n",
      "[1604/1762] D loss: 1.4029, G loss: 0.8050\n",
      "[1684/1762] D loss: 1.1793, G loss: 0.8630\n",
      "[1762/1762] D loss: 1.4199, G loss: 0.8008\n",
      "train error: \n",
      " D loss: 1.331762, G loss: 0.691082, D accuracy: 56.9%, cell accuracy: 99.7%, board accuracy: 74.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.329746, G loss: 0.700905, D accuracy: 57.2%, cell accuracy: 99.6%, board accuracy: 73.4% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4266, G loss: 0.5340\n",
      "[84/1762] D loss: 1.1465, G loss: 0.9107\n",
      "[164/1762] D loss: 1.2941, G loss: 0.6796\n",
      "[244/1762] D loss: 1.4064, G loss: 0.7209\n",
      "[324/1762] D loss: 1.2669, G loss: 0.9044\n",
      "[404/1762] D loss: 1.2732, G loss: 0.8341\n",
      "[484/1762] D loss: 1.3887, G loss: 0.7334\n",
      "[564/1762] D loss: 0.9652, G loss: 1.5758\n",
      "[644/1762] D loss: 1.3723, G loss: 0.6612\n",
      "[724/1762] D loss: 1.3671, G loss: 0.8149\n",
      "[804/1762] D loss: 1.3967, G loss: 0.6266\n",
      "[884/1762] D loss: 1.3892, G loss: 0.7480\n",
      "[964/1762] D loss: 1.3636, G loss: 0.8126\n",
      "[1044/1762] D loss: 1.3950, G loss: 0.7084\n",
      "[1124/1762] D loss: 1.2777, G loss: 0.8165\n",
      "[1204/1762] D loss: 1.3298, G loss: 0.7168\n",
      "[1284/1762] D loss: 1.4280, G loss: 0.7526\n",
      "[1364/1762] D loss: 1.3618, G loss: 0.6734\n",
      "[1444/1762] D loss: 1.1933, G loss: 0.9648\n",
      "[1524/1762] D loss: 1.4156, G loss: 0.5955\n",
      "[1604/1762] D loss: 1.3949, G loss: 0.6499\n",
      "[1684/1762] D loss: 1.3891, G loss: 0.7308\n",
      "[1762/1762] D loss: 1.4131, G loss: 0.6043\n",
      "train error: \n",
      " D loss: 1.327168, G loss: 0.762626, D accuracy: 56.2%, cell accuracy: 99.7%, board accuracy: 76.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.322585, G loss: 0.773708, D accuracy: 56.2%, cell accuracy: 99.7%, board accuracy: 74.5% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3677, G loss: 0.7576\n",
      "[84/1762] D loss: 1.4011, G loss: 0.5722\n",
      "[164/1762] D loss: 1.4142, G loss: 0.7212\n",
      "[244/1762] D loss: 1.1859, G loss: 1.2994\n",
      "[324/1762] D loss: 1.2951, G loss: 0.7280\n",
      "[404/1762] D loss: 1.3965, G loss: 0.6877\n",
      "[484/1762] D loss: 1.3334, G loss: 0.8699\n",
      "[564/1762] D loss: 1.3912, G loss: 0.7078\n",
      "[644/1762] D loss: 1.3077, G loss: 0.9046\n",
      "[724/1762] D loss: 1.2328, G loss: 0.8207\n",
      "[804/1762] D loss: 1.1234, G loss: 1.1632\n",
      "[884/1762] D loss: 1.1776, G loss: 0.8279\n",
      "[964/1762] D loss: 1.4118, G loss: 0.5892\n",
      "[1044/1762] D loss: 1.4041, G loss: 0.7167\n",
      "[1124/1762] D loss: 1.1337, G loss: 1.0482\n",
      "[1204/1762] D loss: 1.3907, G loss: 0.6998\n",
      "[1284/1762] D loss: 1.4074, G loss: 0.7170\n",
      "[1364/1762] D loss: 1.4129, G loss: 0.5703\n",
      "[1444/1762] D loss: 1.4031, G loss: 0.7573\n",
      "[1524/1762] D loss: 1.3811, G loss: 0.6751\n",
      "[1604/1762] D loss: 1.4034, G loss: 0.5768\n",
      "[1684/1762] D loss: 1.3668, G loss: 0.7222\n",
      "[1762/1762] D loss: 1.2336, G loss: 0.6871\n",
      "train error: \n",
      " D loss: 1.326057, G loss: 0.812929, D accuracy: 56.6%, cell accuracy: 99.7%, board accuracy: 75.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.325448, G loss: 0.813754, D accuracy: 56.8%, cell accuracy: 99.7%, board accuracy: 74.1% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2730, G loss: 0.7796\n",
      "[84/1762] D loss: 1.3997, G loss: 0.5916\n",
      "[164/1762] D loss: 1.3981, G loss: 0.6696\n",
      "[244/1762] D loss: 1.3875, G loss: 0.5413\n",
      "[324/1762] D loss: 1.1983, G loss: 1.0135\n",
      "[404/1762] D loss: 1.3939, G loss: 0.5387\n",
      "[484/1762] D loss: 1.4336, G loss: 0.9403\n",
      "[564/1762] D loss: 1.4031, G loss: 0.7086\n",
      "[644/1762] D loss: 1.3985, G loss: 0.7709\n",
      "[724/1762] D loss: 1.4455, G loss: 0.5313\n",
      "[804/1762] D loss: 1.3066, G loss: 0.7729\n",
      "[884/1762] D loss: 1.4040, G loss: 0.8369\n",
      "[964/1762] D loss: 1.2385, G loss: 0.7737\n",
      "[1044/1762] D loss: 1.1947, G loss: 0.7905\n",
      "[1124/1762] D loss: 1.3141, G loss: 0.6498\n",
      "[1204/1762] D loss: 1.2820, G loss: 0.7898\n",
      "[1284/1762] D loss: 1.1894, G loss: 0.8961\n",
      "[1364/1762] D loss: 1.4386, G loss: 0.5004\n",
      "[1444/1762] D loss: 1.3839, G loss: 0.8521\n",
      "[1524/1762] D loss: 1.1172, G loss: 0.8973\n",
      "[1604/1762] D loss: 1.2629, G loss: 1.0092\n",
      "[1684/1762] D loss: 1.4702, G loss: 1.0389\n",
      "[1762/1762] D loss: 1.2126, G loss: 0.7219\n",
      "train error: \n",
      " D loss: 1.321897, G loss: 0.754184, D accuracy: 56.9%, cell accuracy: 99.7%, board accuracy: 75.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.321563, G loss: 0.759317, D accuracy: 56.6%, cell accuracy: 99.7%, board accuracy: 74.5% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3174, G loss: 0.6747\n",
      "[84/1762] D loss: 1.3954, G loss: 0.7006\n",
      "[164/1762] D loss: 1.3432, G loss: 0.7227\n",
      "[244/1762] D loss: 1.3961, G loss: 0.6037\n",
      "[324/1762] D loss: 1.4324, G loss: 0.8310\n",
      "[404/1762] D loss: 1.0680, G loss: 1.0581\n",
      "[484/1762] D loss: 1.2470, G loss: 0.8699\n",
      "[564/1762] D loss: 1.3712, G loss: 0.7708\n",
      "[644/1762] D loss: 1.3896, G loss: 0.6759\n",
      "[724/1762] D loss: 1.4014, G loss: 0.8375\n",
      "[804/1762] D loss: 1.2791, G loss: 0.8556\n",
      "[884/1762] D loss: 1.3906, G loss: 0.6653\n",
      "[964/1762] D loss: 1.3235, G loss: 0.6242\n",
      "[1044/1762] D loss: 1.2303, G loss: 0.8906\n",
      "[1124/1762] D loss: 1.4173, G loss: 0.7133\n",
      "[1204/1762] D loss: 1.3990, G loss: 0.7699\n",
      "[1284/1762] D loss: 1.3443, G loss: 0.6386\n",
      "[1364/1762] D loss: 1.4841, G loss: 0.7593\n",
      "[1444/1762] D loss: 1.4001, G loss: 0.7291\n",
      "[1524/1762] D loss: 1.1533, G loss: 0.6666\n",
      "[1604/1762] D loss: 1.4298, G loss: 0.8817\n",
      "[1684/1762] D loss: 1.2229, G loss: 1.1518\n",
      "[1762/1762] D loss: 1.4271, G loss: 0.9076\n",
      "train error: \n",
      " D loss: 1.356535, G loss: 1.003396, D accuracy: 54.0%, cell accuracy: 99.7%, board accuracy: 76.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.353993, G loss: 1.013482, D accuracy: 54.9%, cell accuracy: 99.7%, board accuracy: 75.7% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4101, G loss: 0.7845\n",
      "[84/1762] D loss: 1.3069, G loss: 0.6298\n",
      "[164/1762] D loss: 1.3680, G loss: 0.6476\n",
      "[244/1762] D loss: 1.2483, G loss: 0.9119\n",
      "[324/1762] D loss: 1.2676, G loss: 0.7622\n",
      "[404/1762] D loss: 1.4108, G loss: 0.7372\n",
      "[484/1762] D loss: 1.0513, G loss: 0.9507\n",
      "[564/1762] D loss: 1.3906, G loss: 0.7075\n",
      "[644/1762] D loss: 1.3305, G loss: 1.0812\n",
      "[724/1762] D loss: 1.2264, G loss: 0.8024\n",
      "[804/1762] D loss: 1.3937, G loss: 0.6103\n",
      "[884/1762] D loss: 1.1776, G loss: 0.9548\n",
      "[964/1762] D loss: 1.1591, G loss: 0.8664\n",
      "[1044/1762] D loss: 1.2654, G loss: 0.7697\n",
      "[1124/1762] D loss: 1.2898, G loss: 0.8621\n",
      "[1204/1762] D loss: 1.4066, G loss: 0.7809\n",
      "[1284/1762] D loss: 1.3764, G loss: 0.6633\n",
      "[1364/1762] D loss: 1.1927, G loss: 0.8503\n",
      "[1444/1762] D loss: 1.2502, G loss: 0.8021\n",
      "[1524/1762] D loss: 1.1612, G loss: 1.0750\n",
      "[1604/1762] D loss: 1.2974, G loss: 0.7749\n",
      "[1684/1762] D loss: 1.2906, G loss: 0.9222\n",
      "[1762/1762] D loss: 1.4159, G loss: 0.6356\n",
      "train error: \n",
      " D loss: 1.308913, G loss: 0.762373, D accuracy: 58.2%, cell accuracy: 99.7%, board accuracy: 74.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.310514, G loss: 0.769717, D accuracy: 57.5%, cell accuracy: 99.7%, board accuracy: 72.5% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3988, G loss: 0.5907\n",
      "[84/1762] D loss: 1.4081, G loss: 0.6245\n",
      "[164/1762] D loss: 1.1058, G loss: 0.9972\n",
      "[244/1762] D loss: 1.1765, G loss: 1.0869\n",
      "[324/1762] D loss: 1.5051, G loss: 0.4585\n",
      "[404/1762] D loss: 1.3166, G loss: 0.5866\n",
      "[484/1762] D loss: 1.2882, G loss: 1.0318\n",
      "[564/1762] D loss: 1.4084, G loss: 0.6138\n",
      "[644/1762] D loss: 1.0525, G loss: 1.3543\n",
      "[724/1762] D loss: 1.3963, G loss: 0.6236\n",
      "[804/1762] D loss: 1.3893, G loss: 0.7583\n",
      "[884/1762] D loss: 1.3179, G loss: 0.9902\n",
      "[964/1762] D loss: 1.4680, G loss: 0.5518\n",
      "[1044/1762] D loss: 1.4306, G loss: 0.7711\n",
      "[1124/1762] D loss: 1.4100, G loss: 0.5940\n",
      "[1204/1762] D loss: 1.3687, G loss: 0.6407\n",
      "[1284/1762] D loss: 1.3227, G loss: 0.5663\n",
      "[1364/1762] D loss: 1.4001, G loss: 0.8352\n",
      "[1444/1762] D loss: 1.3947, G loss: 0.6036\n",
      "[1524/1762] D loss: 1.2134, G loss: 0.9053\n",
      "[1604/1762] D loss: 1.3087, G loss: 0.8197\n",
      "[1684/1762] D loss: 1.2461, G loss: 0.8470\n",
      "[1762/1762] D loss: 1.4036, G loss: 0.7128\n",
      "train error: \n",
      " D loss: 1.310224, G loss: 0.795145, D accuracy: 57.4%, cell accuracy: 99.7%, board accuracy: 75.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.309173, G loss: 0.801485, D accuracy: 57.3%, cell accuracy: 99.7%, board accuracy: 73.0% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1447, G loss: 0.9429\n",
      "[84/1762] D loss: 1.4119, G loss: 0.6119\n",
      "[164/1762] D loss: 1.3902, G loss: 0.6058\n",
      "[244/1762] D loss: 1.2140, G loss: 0.8046\n",
      "[324/1762] D loss: 1.2651, G loss: 0.7317\n",
      "[404/1762] D loss: 1.0291, G loss: 1.0529\n",
      "[484/1762] D loss: 1.3611, G loss: 0.8421\n",
      "[564/1762] D loss: 1.2203, G loss: 1.0215\n",
      "[644/1762] D loss: 1.3063, G loss: 0.9136\n",
      "[724/1762] D loss: 1.4372, G loss: 0.6588\n",
      "[804/1762] D loss: 1.4035, G loss: 0.8106\n",
      "[884/1762] D loss: 1.4132, G loss: 0.5691\n",
      "[964/1762] D loss: 1.3969, G loss: 0.8032\n",
      "[1044/1762] D loss: 0.9777, G loss: 0.9466\n",
      "[1124/1762] D loss: 1.3892, G loss: 0.6799\n",
      "[1204/1762] D loss: 1.3907, G loss: 0.7000\n",
      "[1284/1762] D loss: 1.1896, G loss: 0.9404\n",
      "[1364/1762] D loss: 1.3255, G loss: 0.6899\n",
      "[1444/1762] D loss: 1.2570, G loss: 1.0071\n",
      "[1524/1762] D loss: 1.2661, G loss: 0.7377\n",
      "[1604/1762] D loss: 1.4102, G loss: 0.6237\n",
      "[1684/1762] D loss: 1.3991, G loss: 0.6905\n",
      "[1762/1762] D loss: 1.2824, G loss: 0.5689\n",
      "train error: \n",
      " D loss: 1.318671, G loss: 0.717275, D accuracy: 56.5%, cell accuracy: 99.8%, board accuracy: 77.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.317668, G loss: 0.725573, D accuracy: 57.5%, cell accuracy: 99.7%, board accuracy: 75.9% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2390, G loss: 0.8325\n",
      "[84/1762] D loss: 1.4090, G loss: 0.8708\n",
      "[164/1762] D loss: 1.4021, G loss: 0.6569\n",
      "[244/1762] D loss: 1.4292, G loss: 0.6578\n",
      "[324/1762] D loss: 1.3913, G loss: 0.7271\n",
      "[404/1762] D loss: 1.4741, G loss: 0.5658\n",
      "[484/1762] D loss: 1.2623, G loss: 0.7778\n",
      "[564/1762] D loss: 1.4181, G loss: 0.6475\n",
      "[644/1762] D loss: 1.1641, G loss: 0.9461\n",
      "[724/1762] D loss: 1.2083, G loss: 0.9721\n",
      "[804/1762] D loss: 1.4228, G loss: 0.5150\n",
      "[884/1762] D loss: 1.3139, G loss: 0.9413\n",
      "[964/1762] D loss: 1.4393, G loss: 0.8756\n",
      "[1044/1762] D loss: 1.3964, G loss: 0.8056\n",
      "[1124/1762] D loss: 1.2403, G loss: 0.9242\n",
      "[1204/1762] D loss: 1.4045, G loss: 0.6672\n",
      "[1284/1762] D loss: 1.1811, G loss: 0.8285\n",
      "[1364/1762] D loss: 1.2020, G loss: 0.9035\n",
      "[1444/1762] D loss: 1.2480, G loss: 0.8302\n",
      "[1524/1762] D loss: 1.2789, G loss: 0.7871\n",
      "[1604/1762] D loss: 1.1163, G loss: 1.0753\n",
      "[1684/1762] D loss: 1.4208, G loss: 0.6337\n",
      "[1762/1762] D loss: 1.4829, G loss: 1.2766\n",
      "train error: \n",
      " D loss: 1.315900, G loss: 0.827619, D accuracy: 56.9%, cell accuracy: 99.8%, board accuracy: 78.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.313190, G loss: 0.835500, D accuracy: 57.0%, cell accuracy: 99.7%, board accuracy: 76.8% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3867, G loss: 0.6133\n",
      "[84/1762] D loss: 1.2564, G loss: 0.8553\n",
      "[164/1762] D loss: 1.4223, G loss: 0.6769\n",
      "[244/1762] D loss: 1.3674, G loss: 1.0441\n",
      "[324/1762] D loss: 1.4526, G loss: 0.6095\n",
      "[404/1762] D loss: 1.4125, G loss: 0.5438\n",
      "[484/1762] D loss: 1.4109, G loss: 0.7634\n",
      "[564/1762] D loss: 1.2355, G loss: 0.8917\n",
      "[644/1762] D loss: 1.3811, G loss: 0.5706\n",
      "[724/1762] D loss: 1.3963, G loss: 0.7727\n",
      "[804/1762] D loss: 1.6324, G loss: 0.6061\n",
      "[884/1762] D loss: 1.2768, G loss: 0.6713\n",
      "[964/1762] D loss: 1.3302, G loss: 0.6827\n",
      "[1044/1762] D loss: 1.4070, G loss: 0.6406\n",
      "[1124/1762] D loss: 1.4323, G loss: 0.6315\n",
      "[1204/1762] D loss: 1.4136, G loss: 0.6253\n",
      "[1284/1762] D loss: 1.4042, G loss: 0.7887\n",
      "[1364/1762] D loss: 1.3355, G loss: 1.1395\n",
      "[1444/1762] D loss: 1.3878, G loss: 0.7179\n",
      "[1524/1762] D loss: 1.3534, G loss: 0.8644\n",
      "[1604/1762] D loss: 1.2781, G loss: 1.0471\n",
      "[1684/1762] D loss: 1.2889, G loss: 0.6429\n",
      "[1762/1762] D loss: 1.3413, G loss: 0.8368\n",
      "train error: \n",
      " D loss: 1.370696, G loss: 0.986329, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 80.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.361953, G loss: 1.002708, D accuracy: 54.8%, cell accuracy: 99.7%, board accuracy: 76.1% \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4410, G loss: 0.9181\n",
      "[84/1762] D loss: 1.2977, G loss: 0.9053\n",
      "[164/1762] D loss: 1.4019, G loss: 0.7841\n",
      "[244/1762] D loss: 1.2389, G loss: 0.9696\n",
      "[324/1762] D loss: 1.4096, G loss: 0.6089\n",
      "[404/1762] D loss: 1.4318, G loss: 0.5347\n",
      "[484/1762] D loss: 1.4006, G loss: 0.6251\n",
      "[564/1762] D loss: 1.1834, G loss: 1.1059\n",
      "[644/1762] D loss: 1.2018, G loss: 0.8228\n",
      "[724/1762] D loss: 1.3958, G loss: 0.6267\n",
      "[804/1762] D loss: 1.2407, G loss: 0.7735\n",
      "[884/1762] D loss: 1.3916, G loss: 0.6995\n",
      "[964/1762] D loss: 1.1991, G loss: 0.9181\n",
      "[1044/1762] D loss: 1.3406, G loss: 0.6275\n",
      "[1124/1762] D loss: 1.2058, G loss: 0.7679\n",
      "[1204/1762] D loss: 1.2061, G loss: 0.7529\n",
      "[1284/1762] D loss: 1.1197, G loss: 1.1842\n",
      "[1364/1762] D loss: 1.3438, G loss: 0.7031\n",
      "[1444/1762] D loss: 1.3724, G loss: 0.7718\n",
      "[1524/1762] D loss: 1.4465, G loss: 0.9657\n",
      "[1604/1762] D loss: 1.3361, G loss: 0.6373\n",
      "[1684/1762] D loss: 1.2879, G loss: 1.0623\n",
      "[1762/1762] D loss: 1.3911, G loss: 0.6789\n",
      "train error: \n",
      " D loss: 1.341662, G loss: 0.716169, D accuracy: 55.4%, cell accuracy: 99.8%, board accuracy: 82.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.332132, G loss: 0.731368, D accuracy: 56.0%, cell accuracy: 99.8%, board accuracy: 80.2% \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3973, G loss: 0.7248\n",
      "[84/1762] D loss: 1.2500, G loss: 0.9521\n",
      "[164/1762] D loss: 1.4326, G loss: 0.7603\n",
      "[244/1762] D loss: 1.4032, G loss: 0.6040\n",
      "[324/1762] D loss: 1.1283, G loss: 0.9939\n",
      "[404/1762] D loss: 1.4050, G loss: 0.6380\n",
      "[484/1762] D loss: 1.1957, G loss: 1.0270\n",
      "[564/1762] D loss: 1.3309, G loss: 0.6558\n",
      "[644/1762] D loss: 1.4346, G loss: 0.5748\n",
      "[724/1762] D loss: 1.4154, G loss: 0.8224\n",
      "[804/1762] D loss: 1.1970, G loss: 0.9961\n",
      "[884/1762] D loss: 1.1917, G loss: 0.8522\n",
      "[964/1762] D loss: 1.1646, G loss: 0.9751\n",
      "[1044/1762] D loss: 1.3434, G loss: 0.6755\n",
      "[1124/1762] D loss: 1.3109, G loss: 0.7554\n",
      "[1204/1762] D loss: 1.4739, G loss: 0.6383\n",
      "[1284/1762] D loss: 1.3997, G loss: 0.7649\n",
      "[1364/1762] D loss: 1.4013, G loss: 0.8314\n",
      "[1444/1762] D loss: 1.0768, G loss: 1.0450\n",
      "[1524/1762] D loss: 1.3947, G loss: 0.6131\n",
      "[1604/1762] D loss: 1.5402, G loss: 0.5352\n",
      "[1684/1762] D loss: 1.4160, G loss: 0.7734\n",
      "[1762/1762] D loss: 1.3940, G loss: 0.7834\n",
      "train error: \n",
      " D loss: 1.331986, G loss: 0.758967, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 82.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.322648, G loss: 0.774269, D accuracy: 55.9%, cell accuracy: 99.7%, board accuracy: 79.1% \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3736, G loss: 0.6892\n",
      "[84/1762] D loss: 1.4056, G loss: 0.6113\n",
      "[164/1762] D loss: 1.3961, G loss: 0.6613\n",
      "[244/1762] D loss: 1.3981, G loss: 0.7449\n",
      "[324/1762] D loss: 1.1905, G loss: 0.7748\n",
      "[404/1762] D loss: 1.3324, G loss: 0.9201\n",
      "[484/1762] D loss: 1.4629, G loss: 0.5673\n",
      "[564/1762] D loss: 1.4006, G loss: 0.7837\n",
      "[644/1762] D loss: 1.1969, G loss: 0.6997\n",
      "[724/1762] D loss: 1.4086, G loss: 0.8341\n",
      "[804/1762] D loss: 1.3902, G loss: 0.6617\n",
      "[884/1762] D loss: 1.4332, G loss: 0.9200\n",
      "[964/1762] D loss: 1.2300, G loss: 0.7411\n",
      "[1044/1762] D loss: 1.3149, G loss: 0.8051\n",
      "[1124/1762] D loss: 1.0466, G loss: 0.9836\n",
      "[1204/1762] D loss: 1.1957, G loss: 0.8159\n",
      "[1284/1762] D loss: 1.3437, G loss: 0.8303\n",
      "[1364/1762] D loss: 1.4381, G loss: 0.6120\n",
      "[1444/1762] D loss: 1.4062, G loss: 0.7706\n",
      "[1524/1762] D loss: 1.3371, G loss: 0.7228\n",
      "[1604/1762] D loss: 1.4175, G loss: 0.5879\n",
      "[1684/1762] D loss: 1.3686, G loss: 0.9084\n",
      "[1762/1762] D loss: 1.3900, G loss: 0.6734\n",
      "train error: \n",
      " D loss: 1.318383, G loss: 0.714017, D accuracy: 57.4%, cell accuracy: 99.8%, board accuracy: 77.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.314632, G loss: 0.721998, D accuracy: 57.3%, cell accuracy: 99.7%, board accuracy: 74.5% \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3962, G loss: 0.6977\n",
      "[84/1762] D loss: 1.3865, G loss: 0.6599\n",
      "[164/1762] D loss: 1.3972, G loss: 0.6611\n",
      "[244/1762] D loss: 1.3979, G loss: 0.6378\n",
      "[324/1762] D loss: 1.4559, G loss: 0.8950\n",
      "[404/1762] D loss: 1.4679, G loss: 0.4995\n",
      "[484/1762] D loss: 1.1743, G loss: 0.9526\n",
      "[564/1762] D loss: 1.1925, G loss: 0.9350\n",
      "[644/1762] D loss: 1.1866, G loss: 0.9864\n",
      "[724/1762] D loss: 1.3956, G loss: 0.6646\n",
      "[804/1762] D loss: 1.3873, G loss: 0.7415\n",
      "[884/1762] D loss: 1.4242, G loss: 0.7480\n",
      "[964/1762] D loss: 1.3337, G loss: 0.6476\n",
      "[1044/1762] D loss: 1.2951, G loss: 0.9076\n",
      "[1124/1762] D loss: 1.2218, G loss: 0.7232\n",
      "[1204/1762] D loss: 1.3906, G loss: 0.6202\n",
      "[1284/1762] D loss: 1.4172, G loss: 0.7243\n",
      "[1364/1762] D loss: 1.4048, G loss: 0.6867\n",
      "[1444/1762] D loss: 1.3919, G loss: 0.7106\n",
      "[1524/1762] D loss: 1.3389, G loss: 0.8255\n",
      "[1604/1762] D loss: 1.1560, G loss: 1.0768\n",
      "[1684/1762] D loss: 1.4151, G loss: 0.7257\n",
      "[1762/1762] D loss: 1.2631, G loss: 0.9161\n",
      "train error: \n",
      " D loss: 1.319710, G loss: 0.758172, D accuracy: 56.3%, cell accuracy: 99.8%, board accuracy: 82.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.309200, G loss: 0.773801, D accuracy: 56.0%, cell accuracy: 99.8%, board accuracy: 80.0% \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3840, G loss: 0.6801\n",
      "[84/1762] D loss: 1.3804, G loss: 0.9184\n",
      "[164/1762] D loss: 1.1663, G loss: 1.0666\n",
      "[244/1762] D loss: 1.3179, G loss: 0.7334\n",
      "[324/1762] D loss: 1.3864, G loss: 0.6482\n",
      "[404/1762] D loss: 1.1385, G loss: 0.7909\n",
      "[484/1762] D loss: 1.1583, G loss: 0.9162\n",
      "[564/1762] D loss: 1.4223, G loss: 0.6145\n",
      "[644/1762] D loss: 1.4593, G loss: 0.8907\n",
      "[724/1762] D loss: 1.4031, G loss: 0.8452\n",
      "[804/1762] D loss: 1.3748, G loss: 0.6676\n",
      "[884/1762] D loss: 1.4342, G loss: 0.6109\n",
      "[964/1762] D loss: 1.4346, G loss: 0.8629\n",
      "[1044/1762] D loss: 1.3981, G loss: 0.7770\n",
      "[1124/1762] D loss: 1.3311, G loss: 0.8565\n",
      "[1204/1762] D loss: 1.5099, G loss: 0.4937\n",
      "[1284/1762] D loss: 1.3971, G loss: 0.7799\n",
      "[1364/1762] D loss: 1.3880, G loss: 0.6352\n",
      "[1444/1762] D loss: 1.3942, G loss: 0.7294\n",
      "[1524/1762] D loss: 1.3156, G loss: 0.7421\n",
      "[1604/1762] D loss: 1.3138, G loss: 0.8780\n",
      "[1684/1762] D loss: 1.3366, G loss: 0.8109\n",
      "[1762/1762] D loss: 1.3922, G loss: 0.6422\n",
      "train error: \n",
      " D loss: 1.329094, G loss: 0.891181, D accuracy: 56.1%, cell accuracy: 99.8%, board accuracy: 82.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.319818, G loss: 0.904162, D accuracy: 56.9%, cell accuracy: 99.8%, board accuracy: 80.5% \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1282, G loss: 1.1999\n",
      "[84/1762] D loss: 1.2510, G loss: 0.7747\n",
      "[164/1762] D loss: 1.3854, G loss: 0.7411\n",
      "[244/1762] D loss: 1.3930, G loss: 0.6672\n",
      "[324/1762] D loss: 1.4013, G loss: 0.6596\n",
      "[404/1762] D loss: 1.1736, G loss: 1.2205\n",
      "[484/1762] D loss: 1.1427, G loss: 1.0395\n",
      "[564/1762] D loss: 1.3940, G loss: 0.6892\n",
      "[644/1762] D loss: 1.3872, G loss: 0.7311\n",
      "[724/1762] D loss: 1.1102, G loss: 0.8094\n",
      "[804/1762] D loss: 1.3931, G loss: 0.7004\n",
      "[884/1762] D loss: 1.4090, G loss: 0.7891\n",
      "[964/1762] D loss: 1.3967, G loss: 0.7031\n",
      "[1044/1762] D loss: 1.4025, G loss: 0.7366\n",
      "[1124/1762] D loss: 1.4373, G loss: 0.8136\n",
      "[1204/1762] D loss: 1.4052, G loss: 0.6244\n",
      "[1284/1762] D loss: 1.3739, G loss: 0.6797\n",
      "[1364/1762] D loss: 1.3897, G loss: 0.7472\n",
      "[1444/1762] D loss: 1.4893, G loss: 0.5582\n",
      "[1524/1762] D loss: 1.1886, G loss: 0.9494\n",
      "[1604/1762] D loss: 1.2512, G loss: 0.9858\n",
      "[1684/1762] D loss: 1.3751, G loss: 0.6598\n",
      "[1762/1762] D loss: 1.4683, G loss: 0.6218\n",
      "train error: \n",
      " D loss: 1.337411, G loss: 0.854837, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.326513, G loss: 0.872602, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4163, G loss: 0.8589\n",
      "[84/1762] D loss: 1.4089, G loss: 0.8172\n",
      "[164/1762] D loss: 1.1541, G loss: 1.0812\n",
      "[244/1762] D loss: 1.2564, G loss: 0.7581\n",
      "[324/1762] D loss: 1.4082, G loss: 0.7259\n",
      "[404/1762] D loss: 1.2099, G loss: 0.7670\n",
      "[484/1762] D loss: 1.4025, G loss: 0.7916\n",
      "[564/1762] D loss: 1.3914, G loss: 0.7697\n",
      "[644/1762] D loss: 1.1448, G loss: 0.8670\n",
      "[724/1762] D loss: 1.2779, G loss: 0.9417\n",
      "[804/1762] D loss: 1.1450, G loss: 1.1124\n",
      "[884/1762] D loss: 1.3891, G loss: 0.7019\n",
      "[964/1762] D loss: 1.3459, G loss: 0.9802\n",
      "[1044/1762] D loss: 1.3967, G loss: 0.8174\n",
      "[1124/1762] D loss: 1.1713, G loss: 0.8788\n",
      "[1204/1762] D loss: 1.3877, G loss: 0.7256\n",
      "[1284/1762] D loss: 1.3826, G loss: 0.6887\n",
      "[1364/1762] D loss: 1.4448, G loss: 0.6486\n",
      "[1444/1762] D loss: 1.3705, G loss: 0.7486\n",
      "[1524/1762] D loss: 1.3932, G loss: 0.7523\n",
      "[1604/1762] D loss: 0.9388, G loss: 1.3074\n",
      "[1684/1762] D loss: 1.4002, G loss: 0.8623\n",
      "[1762/1762] D loss: 1.3884, G loss: 0.6831\n",
      "train error: \n",
      " D loss: 1.337495, G loss: 0.691074, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 90.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.325091, G loss: 0.709892, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1242, G loss: 0.9771\n",
      "[84/1762] D loss: 1.4164, G loss: 0.7415\n",
      "[164/1762] D loss: 1.3955, G loss: 0.6076\n",
      "[244/1762] D loss: 1.4360, G loss: 0.5504\n",
      "[324/1762] D loss: 1.4273, G loss: 0.8122\n",
      "[404/1762] D loss: 1.1489, G loss: 0.8988\n",
      "[484/1762] D loss: 1.1439, G loss: 0.9194\n",
      "[564/1762] D loss: 1.4131, G loss: 0.7756\n",
      "[644/1762] D loss: 1.3938, G loss: 0.6187\n",
      "[724/1762] D loss: 1.4725, G loss: 1.0105\n",
      "[804/1762] D loss: 1.3919, G loss: 0.7399\n",
      "[884/1762] D loss: 1.1560, G loss: 0.8136\n",
      "[964/1762] D loss: 1.2179, G loss: 1.0182\n",
      "[1044/1762] D loss: 1.3937, G loss: 0.8112\n",
      "[1124/1762] D loss: 1.4167, G loss: 0.5373\n",
      "[1204/1762] D loss: 1.3968, G loss: 0.6292\n",
      "[1284/1762] D loss: 1.4120, G loss: 0.5890\n",
      "[1364/1762] D loss: 1.1384, G loss: 1.0235\n",
      "[1444/1762] D loss: 1.1451, G loss: 0.8737\n",
      "[1524/1762] D loss: 1.3951, G loss: 0.6741\n",
      "[1604/1762] D loss: 1.3166, G loss: 0.7788\n",
      "[1684/1762] D loss: 1.1221, G loss: 0.9198\n",
      "[1762/1762] D loss: 1.3903, G loss: 0.7384\n",
      "train error: \n",
      " D loss: 1.328326, G loss: 0.812832, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.314524, G loss: 0.834756, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1485, G loss: 1.0344\n",
      "[84/1762] D loss: 1.4075, G loss: 0.6217\n",
      "[164/1762] D loss: 0.9256, G loss: 1.2124\n",
      "[244/1762] D loss: 1.3946, G loss: 0.7220\n",
      "[324/1762] D loss: 1.4302, G loss: 0.8562\n",
      "[404/1762] D loss: 1.4189, G loss: 0.6706\n",
      "[484/1762] D loss: 1.3956, G loss: 0.7468\n",
      "[564/1762] D loss: 1.4167, G loss: 0.6417\n",
      "[644/1762] D loss: 1.4350, G loss: 0.9271\n",
      "[724/1762] D loss: 1.3999, G loss: 0.6094\n",
      "[804/1762] D loss: 1.3943, G loss: 0.7504\n",
      "[884/1762] D loss: 1.1340, G loss: 0.8493\n",
      "[964/1762] D loss: 1.3926, G loss: 0.7206\n",
      "[1044/1762] D loss: 1.3922, G loss: 0.7690\n",
      "[1124/1762] D loss: 1.4182, G loss: 0.5954\n",
      "[1204/1762] D loss: 1.4211, G loss: 0.5829\n",
      "[1284/1762] D loss: 1.1475, G loss: 0.9775\n",
      "[1364/1762] D loss: 1.3908, G loss: 0.6767\n",
      "[1444/1762] D loss: 1.3995, G loss: 0.7370\n",
      "[1524/1762] D loss: 1.4079, G loss: 0.5862\n",
      "[1604/1762] D loss: 1.3920, G loss: 0.7207\n",
      "[1684/1762] D loss: 1.4099, G loss: 0.7396\n",
      "[1762/1762] D loss: 1.3994, G loss: 0.8131\n",
      "train error: \n",
      " D loss: 1.331989, G loss: 0.874166, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 90.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.316321, G loss: 0.897902, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3526, G loss: 0.8073\n",
      "[84/1762] D loss: 1.4132, G loss: 0.5875\n",
      "[164/1762] D loss: 1.4095, G loss: 0.7882\n",
      "[244/1762] D loss: 1.4073, G loss: 0.7556\n",
      "[324/1762] D loss: 1.4143, G loss: 0.8836\n",
      "[404/1762] D loss: 1.4093, G loss: 0.6447\n",
      "[484/1762] D loss: 1.1257, G loss: 1.0248\n",
      "[564/1762] D loss: 1.4236, G loss: 0.8310\n",
      "[644/1762] D loss: 1.4142, G loss: 0.7928\n",
      "[724/1762] D loss: 1.1367, G loss: 0.9178\n",
      "[804/1762] D loss: 1.1273, G loss: 0.9992\n",
      "[884/1762] D loss: 1.4296, G loss: 0.5517\n",
      "[964/1762] D loss: 1.3898, G loss: 0.7539\n",
      "[1044/1762] D loss: 1.3910, G loss: 0.7315\n",
      "[1124/1762] D loss: 1.2093, G loss: 0.7444\n",
      "[1204/1762] D loss: 1.4214, G loss: 0.8852\n",
      "[1284/1762] D loss: 1.3881, G loss: 0.6697\n",
      "[1364/1762] D loss: 0.8709, G loss: 1.1015\n",
      "[1444/1762] D loss: 1.3909, G loss: 0.6142\n",
      "[1524/1762] D loss: 1.4041, G loss: 0.6575\n",
      "[1604/1762] D loss: 1.4002, G loss: 0.8333\n",
      "[1684/1762] D loss: 1.3989, G loss: 0.6941\n",
      "[1762/1762] D loss: 0.5087, G loss: 1.6255\n",
      "train error: \n",
      " D loss: 1.332555, G loss: 0.695825, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 90.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.320084, G loss: 0.717248, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3879, G loss: 0.6478\n",
      "[84/1762] D loss: 1.4025, G loss: 0.7672\n",
      "[164/1762] D loss: 1.4082, G loss: 0.7116\n",
      "[244/1762] D loss: 1.4342, G loss: 0.7962\n",
      "[324/1762] D loss: 1.4001, G loss: 0.7747\n",
      "[404/1762] D loss: 1.3909, G loss: 0.6707\n",
      "[484/1762] D loss: 1.1286, G loss: 0.9698\n",
      "[564/1762] D loss: 1.4005, G loss: 0.6898\n",
      "[644/1762] D loss: 1.3891, G loss: 0.6704\n",
      "[724/1762] D loss: 1.1400, G loss: 0.8955\n",
      "[804/1762] D loss: 1.1474, G loss: 0.9402\n",
      "[884/1762] D loss: 1.4022, G loss: 0.6887\n",
      "[964/1762] D loss: 1.4025, G loss: 0.8528\n",
      "[1044/1762] D loss: 1.4046, G loss: 0.7673\n",
      "[1124/1762] D loss: 1.1201, G loss: 1.0417\n",
      "[1204/1762] D loss: 1.3928, G loss: 0.7267\n",
      "[1284/1762] D loss: 1.3913, G loss: 0.7547\n",
      "[1364/1762] D loss: 1.4161, G loss: 0.7393\n",
      "[1444/1762] D loss: 1.3916, G loss: 0.7069\n",
      "[1524/1762] D loss: 1.3901, G loss: 0.6219\n",
      "[1604/1762] D loss: 1.4057, G loss: 0.7139\n",
      "[1684/1762] D loss: 1.3903, G loss: 0.7574\n",
      "[1762/1762] D loss: 0.8299, G loss: 1.1898\n",
      "train error: \n",
      " D loss: 1.350959, G loss: 0.608679, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 90.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.333322, G loss: 0.629405, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3973, G loss: 0.5626\n",
      "[84/1762] D loss: 1.3945, G loss: 0.7772\n",
      "[164/1762] D loss: 1.3952, G loss: 0.6499\n",
      "[244/1762] D loss: 1.3913, G loss: 0.7360\n",
      "[324/1762] D loss: 1.3989, G loss: 0.8116\n",
      "[404/1762] D loss: 1.4121, G loss: 0.6131\n",
      "[484/1762] D loss: 1.1164, G loss: 0.9376\n",
      "[564/1762] D loss: 1.3979, G loss: 0.7068\n",
      "[644/1762] D loss: 1.1202, G loss: 0.8565\n",
      "[724/1762] D loss: 1.4034, G loss: 0.5942\n",
      "[804/1762] D loss: 1.1259, G loss: 1.2482\n",
      "[884/1762] D loss: 1.4232, G loss: 0.6353\n",
      "[964/1762] D loss: 1.4044, G loss: 0.5942\n",
      "[1044/1762] D loss: 1.4228, G loss: 0.8847\n",
      "[1124/1762] D loss: 1.1228, G loss: 0.8742\n",
      "[1204/1762] D loss: 1.3928, G loss: 0.6246\n",
      "[1284/1762] D loss: 1.3927, G loss: 0.7045\n",
      "[1364/1762] D loss: 1.4046, G loss: 0.6755\n",
      "[1444/1762] D loss: 1.4679, G loss: 0.7820\n",
      "[1524/1762] D loss: 1.3949, G loss: 0.7186\n",
      "[1604/1762] D loss: 1.3143, G loss: 0.8778\n",
      "[1684/1762] D loss: 1.3944, G loss: 0.7928\n",
      "[1762/1762] D loss: 1.3925, G loss: 0.6964\n",
      "train error: \n",
      " D loss: 1.321835, G loss: 0.799505, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 90.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.308096, G loss: 0.823391, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4310, G loss: 0.6568\n",
      "[84/1762] D loss: 1.4261, G loss: 0.7971\n",
      "[164/1762] D loss: 1.2548, G loss: 0.7188\n",
      "[244/1762] D loss: 1.4081, G loss: 0.5825\n",
      "[324/1762] D loss: 1.3915, G loss: 0.7299\n",
      "[404/1762] D loss: 1.4264, G loss: 0.7997\n",
      "[484/1762] D loss: 1.3913, G loss: 0.6640\n",
      "[564/1762] D loss: 1.3688, G loss: 0.7277\n",
      "[644/1762] D loss: 1.1082, G loss: 1.1063\n",
      "[724/1762] D loss: 1.1221, G loss: 0.8574\n",
      "[804/1762] D loss: 1.3970, G loss: 0.6208\n",
      "[884/1762] D loss: 1.0592, G loss: 1.0657\n",
      "[964/1762] D loss: 1.1472, G loss: 1.0400\n",
      "[1044/1762] D loss: 1.4004, G loss: 0.6990\n",
      "[1124/1762] D loss: 1.4078, G loss: 0.7268\n",
      "[1204/1762] D loss: 0.8315, G loss: 1.2383\n",
      "[1284/1762] D loss: 1.3868, G loss: 0.6951\n",
      "[1364/1762] D loss: 1.1075, G loss: 1.0611\n",
      "[1444/1762] D loss: 1.4242, G loss: 0.5527\n",
      "[1524/1762] D loss: 1.3915, G loss: 0.6914\n",
      "[1604/1762] D loss: 1.4074, G loss: 0.8293\n",
      "[1684/1762] D loss: 1.4332, G loss: 0.8603\n",
      "[1762/1762] D loss: 1.4142, G loss: 0.8458\n",
      "train error: \n",
      " D loss: 1.321957, G loss: 0.859222, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 90.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.306990, G loss: 0.886066, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4619, G loss: 0.8352\n",
      "[84/1762] D loss: 1.4014, G loss: 0.7792\n",
      "[164/1762] D loss: 1.1070, G loss: 1.0329\n",
      "[244/1762] D loss: 1.3942, G loss: 0.7474\n",
      "[324/1762] D loss: 1.3872, G loss: 0.6777\n",
      "[404/1762] D loss: 1.3964, G loss: 0.6869\n",
      "[484/1762] D loss: 1.4566, G loss: 0.6360\n",
      "[564/1762] D loss: 1.3985, G loss: 0.7475\n",
      "[644/1762] D loss: 1.3911, G loss: 0.6727\n",
      "[724/1762] D loss: 1.4015, G loss: 0.5930\n",
      "[804/1762] D loss: 1.4013, G loss: 0.7386\n",
      "[884/1762] D loss: 1.3854, G loss: 0.6945\n",
      "[964/1762] D loss: 1.4257, G loss: 0.9043\n",
      "[1044/1762] D loss: 1.3752, G loss: 0.7085\n",
      "[1124/1762] D loss: 1.1016, G loss: 1.0843\n",
      "[1204/1762] D loss: 1.3962, G loss: 0.6908\n",
      "[1284/1762] D loss: 1.4071, G loss: 0.8470\n",
      "[1364/1762] D loss: 1.4281, G loss: 0.5401\n",
      "[1444/1762] D loss: 1.3892, G loss: 0.7193\n",
      "[1524/1762] D loss: 1.3968, G loss: 0.5998\n",
      "[1604/1762] D loss: 1.4013, G loss: 0.7786\n",
      "[1684/1762] D loss: 1.3946, G loss: 0.6376\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.6540\n",
      "train error: \n",
      " D loss: 1.322171, G loss: 0.721607, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 90.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.305194, G loss: 0.747050, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4157, G loss: 0.5878\n",
      "[84/1762] D loss: 1.3985, G loss: 0.7802\n",
      "[164/1762] D loss: 1.4033, G loss: 0.7030\n",
      "[244/1762] D loss: 1.3895, G loss: 0.6585\n",
      "[324/1762] D loss: 1.3892, G loss: 0.6183\n",
      "[404/1762] D loss: 1.3876, G loss: 0.7255\n",
      "[484/1762] D loss: 1.4005, G loss: 0.6942\n",
      "[564/1762] D loss: 1.4278, G loss: 0.9252\n",
      "[644/1762] D loss: 1.3911, G loss: 0.6789\n",
      "[724/1762] D loss: 1.4112, G loss: 0.7652\n",
      "[804/1762] D loss: 1.3833, G loss: 0.7026\n",
      "[884/1762] D loss: 1.4191, G loss: 0.8679\n",
      "[964/1762] D loss: 1.3923, G loss: 0.7600\n",
      "[1044/1762] D loss: 1.4000, G loss: 0.8005\n",
      "[1124/1762] D loss: 1.3997, G loss: 0.7227\n",
      "[1204/1762] D loss: 1.1941, G loss: 1.0636\n",
      "[1284/1762] D loss: 1.4044, G loss: 0.6845\n",
      "[1364/1762] D loss: 1.3922, G loss: 0.6599\n",
      "[1444/1762] D loss: 1.4042, G loss: 0.6786\n",
      "[1524/1762] D loss: 0.7774, G loss: 1.6601\n",
      "[1604/1762] D loss: 1.1109, G loss: 1.1452\n",
      "[1684/1762] D loss: 1.3943, G loss: 0.6272\n",
      "[1762/1762] D loss: 0.7968, G loss: 1.3421\n",
      "train error: \n",
      " D loss: 1.314753, G loss: 0.781220, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.296149, G loss: 0.809061, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1099, G loss: 0.9230\n",
      "[84/1762] D loss: 1.3609, G loss: 0.7458\n",
      "[164/1762] D loss: 1.3913, G loss: 0.7045\n",
      "[244/1762] D loss: 1.4115, G loss: 0.7955\n",
      "[324/1762] D loss: 1.1143, G loss: 0.9950\n",
      "[404/1762] D loss: 1.3891, G loss: 0.7007\n",
      "[484/1762] D loss: 1.1101, G loss: 0.9138\n",
      "[564/1762] D loss: 1.4044, G loss: 0.5951\n",
      "[644/1762] D loss: 1.4154, G loss: 0.8103\n",
      "[724/1762] D loss: 1.3941, G loss: 0.7225\n",
      "[804/1762] D loss: 1.3900, G loss: 0.6940\n",
      "[884/1762] D loss: 1.4366, G loss: 0.8195\n",
      "[964/1762] D loss: 1.4026, G loss: 0.6844\n",
      "[1044/1762] D loss: 1.1170, G loss: 0.9782\n",
      "[1124/1762] D loss: 1.4083, G loss: 0.7890\n",
      "[1204/1762] D loss: 0.8230, G loss: 1.2189\n",
      "[1284/1762] D loss: 1.4010, G loss: 0.7806\n",
      "[1364/1762] D loss: 1.4196, G loss: 0.6746\n",
      "[1444/1762] D loss: 1.3864, G loss: 0.7594\n",
      "[1524/1762] D loss: 1.0327, G loss: 1.3246\n",
      "[1604/1762] D loss: 1.3935, G loss: 0.6474\n",
      "[1684/1762] D loss: 1.3924, G loss: 0.6972\n",
      "[1762/1762] D loss: 1.3936, G loss: 0.6808\n",
      "train error: \n",
      " D loss: 1.322326, G loss: 0.705842, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 90.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.304536, G loss: 0.732632, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1117, G loss: 0.9488\n",
      "[84/1762] D loss: 1.3921, G loss: 0.7259\n",
      "[164/1762] D loss: 1.3926, G loss: 0.7289\n",
      "[244/1762] D loss: 1.3997, G loss: 0.6501\n",
      "[324/1762] D loss: 1.3907, G loss: 0.6459\n",
      "[404/1762] D loss: 1.3995, G loss: 0.6801\n",
      "[484/1762] D loss: 1.0470, G loss: 1.0773\n",
      "[564/1762] D loss: 1.3936, G loss: 0.7010\n",
      "[644/1762] D loss: 1.1008, G loss: 1.0672\n",
      "[724/1762] D loss: 1.3968, G loss: 0.6387\n",
      "[804/1762] D loss: 1.3954, G loss: 0.7661\n",
      "[884/1762] D loss: 0.8410, G loss: 1.1426\n",
      "[964/1762] D loss: 1.4031, G loss: 0.7162\n",
      "[1044/1762] D loss: 1.3802, G loss: 0.8618\n",
      "[1124/1762] D loss: 1.4016, G loss: 0.7258\n",
      "[1204/1762] D loss: 1.1049, G loss: 1.0387\n",
      "[1284/1762] D loss: 1.4018, G loss: 0.6717\n",
      "[1364/1762] D loss: 1.4164, G loss: 0.6016\n",
      "[1444/1762] D loss: 1.3911, G loss: 1.1875\n",
      "[1524/1762] D loss: 1.3901, G loss: 0.7410\n",
      "[1604/1762] D loss: 1.3915, G loss: 0.7586\n",
      "[1684/1762] D loss: 1.3727, G loss: 0.6971\n",
      "[1762/1762] D loss: 1.3905, G loss: 0.7135\n",
      "train error: \n",
      " D loss: 1.314949, G loss: 0.819497, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 90.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.297188, G loss: 0.850557, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4221, G loss: 0.7577\n",
      "[84/1762] D loss: 1.0928, G loss: 1.0092\n",
      "[164/1762] D loss: 1.0891, G loss: 1.0187\n",
      "[244/1762] D loss: 1.4247, G loss: 0.8624\n",
      "[324/1762] D loss: 1.4158, G loss: 0.5705\n",
      "[404/1762] D loss: 1.3995, G loss: 0.6353\n",
      "[484/1762] D loss: 1.3887, G loss: 0.7284\n",
      "[564/1762] D loss: 1.3985, G loss: 0.7515\n",
      "[644/1762] D loss: 1.0979, G loss: 0.9705\n",
      "[724/1762] D loss: 1.3997, G loss: 0.7950\n",
      "[804/1762] D loss: 1.4047, G loss: 0.7360\n",
      "[884/1762] D loss: 1.3933, G loss: 0.7577\n",
      "[964/1762] D loss: 1.3907, G loss: 0.6843\n",
      "[1044/1762] D loss: 1.1047, G loss: 1.0019\n",
      "[1124/1762] D loss: 1.1104, G loss: 1.0106\n",
      "[1204/1762] D loss: 1.1037, G loss: 0.9438\n",
      "[1284/1762] D loss: 1.3746, G loss: 0.8229\n",
      "[1364/1762] D loss: 1.3891, G loss: 0.6041\n",
      "[1444/1762] D loss: 1.4234, G loss: 0.8746\n",
      "[1524/1762] D loss: 1.4095, G loss: 0.6139\n",
      "[1604/1762] D loss: 1.5045, G loss: 1.0975\n",
      "[1684/1762] D loss: 1.4035, G loss: 0.6274\n",
      "[1762/1762] D loss: 1.4128, G loss: 0.7982\n",
      "train error: \n",
      " D loss: 1.313368, G loss: 0.846524, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.294993, G loss: 0.881093, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 85.9% \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3971, G loss: 0.7177\n",
      "[84/1762] D loss: 1.3921, G loss: 0.7704\n",
      "[164/1762] D loss: 1.3826, G loss: 0.6879\n",
      "[244/1762] D loss: 1.4011, G loss: 0.7697\n",
      "[324/1762] D loss: 1.3944, G loss: 0.6852\n",
      "[404/1762] D loss: 1.0996, G loss: 1.0139\n",
      "[484/1762] D loss: 1.3649, G loss: 1.0429\n",
      "[564/1762] D loss: 1.1093, G loss: 1.0495\n",
      "[644/1762] D loss: 1.3883, G loss: 0.6990\n",
      "[724/1762] D loss: 1.3908, G loss: 0.6780\n",
      "[804/1762] D loss: 1.3986, G loss: 0.7301\n",
      "[884/1762] D loss: 1.0584, G loss: 1.1120\n",
      "[964/1762] D loss: 1.3982, G loss: 0.6813\n",
      "[1044/1762] D loss: 1.3905, G loss: 0.7080\n",
      "[1124/1762] D loss: 1.3921, G loss: 0.6734\n",
      "[1204/1762] D loss: 1.3915, G loss: 0.7434\n",
      "[1284/1762] D loss: 1.3960, G loss: 0.7783\n",
      "[1364/1762] D loss: 1.3925, G loss: 0.7511\n",
      "[1444/1762] D loss: 1.3896, G loss: 0.6351\n",
      "[1524/1762] D loss: 1.4758, G loss: 0.9812\n",
      "[1604/1762] D loss: 1.3898, G loss: 0.7365\n",
      "[1684/1762] D loss: 1.3914, G loss: 0.7454\n",
      "[1762/1762] D loss: 1.1854, G loss: 1.3323\n",
      "train error: \n",
      " D loss: 1.243585, G loss: 0.796178, D accuracy: 63.6%, cell accuracy: 99.6%, board accuracy: 66.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.235698, G loss: 0.822141, D accuracy: 62.5%, cell accuracy: 99.6%, board accuracy: 67.5% \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3169, G loss: 0.6365\n",
      "[84/1762] D loss: 1.3972, G loss: 0.7421\n",
      "[164/1762] D loss: 1.3870, G loss: 0.6737\n",
      "[244/1762] D loss: 1.0984, G loss: 0.9732\n",
      "[324/1762] D loss: 1.3903, G loss: 0.6646\n",
      "[404/1762] D loss: 1.4037, G loss: 0.5983\n",
      "[484/1762] D loss: 1.3985, G loss: 0.7842\n",
      "[564/1762] D loss: 1.1032, G loss: 1.0121\n",
      "[644/1762] D loss: 1.3906, G loss: 0.6464\n",
      "[724/1762] D loss: 1.4198, G loss: 0.6678\n",
      "[804/1762] D loss: 1.1142, G loss: 0.9440\n",
      "[884/1762] D loss: 1.4299, G loss: 0.7232\n",
      "[964/1762] D loss: 1.3913, G loss: 0.6723\n",
      "[1044/1762] D loss: 1.4163, G loss: 0.8387\n",
      "[1124/1762] D loss: 1.0832, G loss: 1.0747\n",
      "[1204/1762] D loss: 1.4396, G loss: 0.6147\n",
      "[1284/1762] D loss: 1.4013, G loss: 0.7339\n",
      "[1364/1762] D loss: 1.3881, G loss: 0.6925\n",
      "[1444/1762] D loss: 1.4018, G loss: 0.6028\n",
      "[1524/1762] D loss: 1.3793, G loss: 0.6887\n",
      "[1604/1762] D loss: 1.3903, G loss: 0.7107\n",
      "[1684/1762] D loss: 1.3881, G loss: 0.6648\n",
      "[1762/1762] D loss: 1.3933, G loss: 0.6489\n",
      "train error: \n",
      " D loss: 1.315102, G loss: 0.735815, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 90.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.294904, G loss: 0.768404, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3962, G loss: 0.6836\n",
      "[84/1762] D loss: 1.3891, G loss: 0.7569\n",
      "[164/1762] D loss: 1.3905, G loss: 0.6884\n",
      "[244/1762] D loss: 1.4029, G loss: 0.7886\n",
      "[324/1762] D loss: 1.0784, G loss: 1.0509\n",
      "[404/1762] D loss: 1.1707, G loss: 1.2477\n",
      "[484/1762] D loss: 1.4010, G loss: 0.5539\n",
      "[564/1762] D loss: 1.3887, G loss: 0.7131\n",
      "[644/1762] D loss: 1.3971, G loss: 0.7426\n",
      "[724/1762] D loss: 1.1000, G loss: 0.9543\n",
      "[804/1762] D loss: 1.0996, G loss: 1.1041\n",
      "[884/1762] D loss: 1.0989, G loss: 1.1036\n",
      "[964/1762] D loss: 1.3932, G loss: 0.7105\n",
      "[1044/1762] D loss: 1.3944, G loss: 0.7177\n",
      "[1124/1762] D loss: 1.3895, G loss: 0.6629\n",
      "[1204/1762] D loss: 1.3859, G loss: 0.7520\n",
      "[1284/1762] D loss: 1.3980, G loss: 0.6492\n",
      "[1364/1762] D loss: 1.3886, G loss: 0.6835\n",
      "[1444/1762] D loss: 1.0224, G loss: 1.1288\n",
      "[1524/1762] D loss: 1.3827, G loss: 0.6907\n",
      "[1604/1762] D loss: 0.7852, G loss: 1.5102\n",
      "[1684/1762] D loss: 0.9952, G loss: 1.2356\n",
      "[1762/1762] D loss: 1.3934, G loss: 0.6385\n",
      "train error: \n",
      " D loss: 1.311957, G loss: 0.742680, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 90.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.291479, G loss: 0.776074, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4029, G loss: 0.6198\n",
      "[84/1762] D loss: 1.3949, G loss: 0.6474\n",
      "[164/1762] D loss: 1.3896, G loss: 0.6986\n",
      "[244/1762] D loss: 1.3898, G loss: 0.6626\n",
      "[324/1762] D loss: 1.3891, G loss: 0.7320\n",
      "[404/1762] D loss: 1.4061, G loss: 0.7189\n",
      "[484/1762] D loss: 1.3815, G loss: 0.6636\n",
      "[564/1762] D loss: 1.3839, G loss: 0.6870\n",
      "[644/1762] D loss: 1.3879, G loss: 0.7316\n",
      "[724/1762] D loss: 1.3862, G loss: 0.6588\n",
      "[804/1762] D loss: 1.3901, G loss: 0.7336\n",
      "[884/1762] D loss: 1.0961, G loss: 1.0445\n",
      "[964/1762] D loss: 1.0856, G loss: 1.0815\n",
      "[1044/1762] D loss: 1.4021, G loss: 0.7134\n",
      "[1124/1762] D loss: 1.3924, G loss: 0.6652\n",
      "[1204/1762] D loss: 1.3955, G loss: 0.8827\n",
      "[1284/1762] D loss: 1.0983, G loss: 0.8960\n",
      "[1364/1762] D loss: 1.4071, G loss: 0.7960\n",
      "[1444/1762] D loss: 1.0970, G loss: 0.9997\n",
      "[1524/1762] D loss: 1.0905, G loss: 1.1454\n",
      "[1604/1762] D loss: 1.4075, G loss: 0.6010\n",
      "[1684/1762] D loss: 1.3933, G loss: 0.7217\n",
      "[1762/1762] D loss: 1.3880, G loss: 0.7046\n",
      "train error: \n",
      " D loss: 1.308845, G loss: 0.786058, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 90.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.288273, G loss: 0.821113, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0924, G loss: 0.9727\n",
      "[84/1762] D loss: 1.3903, G loss: 0.7591\n",
      "[164/1762] D loss: 1.3910, G loss: 0.6862\n",
      "[244/1762] D loss: 1.3942, G loss: 0.7371\n",
      "[324/1762] D loss: 1.3767, G loss: 0.6348\n",
      "[404/1762] D loss: 1.3994, G loss: 0.7767\n",
      "[484/1762] D loss: 1.3918, G loss: 0.6971\n",
      "[564/1762] D loss: 1.3978, G loss: 0.6736\n",
      "[644/1762] D loss: 1.3949, G loss: 0.7682\n",
      "[724/1762] D loss: 1.3917, G loss: 0.7388\n",
      "[804/1762] D loss: 1.3905, G loss: 0.6368\n",
      "[884/1762] D loss: 1.4021, G loss: 0.7857\n",
      "[964/1762] D loss: 1.3884, G loss: 0.6951\n",
      "[1044/1762] D loss: 1.3907, G loss: 0.7183\n",
      "[1124/1762] D loss: 1.3923, G loss: 0.7837\n",
      "[1204/1762] D loss: 1.4051, G loss: 0.7365\n",
      "[1284/1762] D loss: 1.0853, G loss: 1.0702\n",
      "[1364/1762] D loss: 1.3957, G loss: 0.7712\n",
      "[1444/1762] D loss: 1.4027, G loss: 0.7291\n",
      "[1524/1762] D loss: 1.3975, G loss: 0.7658\n",
      "[1604/1762] D loss: 1.3945, G loss: 0.7226\n",
      "[1684/1762] D loss: 1.3918, G loss: 0.6439\n",
      "[1762/1762] D loss: 1.4234, G loss: 0.8608\n",
      "train error: \n",
      " D loss: 1.311686, G loss: 0.861919, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 90.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.292213, G loss: 0.897070, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 87.3% \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0999, G loss: 1.1076\n",
      "[84/1762] D loss: 1.3928, G loss: 0.6824\n",
      "[164/1762] D loss: 1.3956, G loss: 0.7757\n",
      "[244/1762] D loss: 1.0175, G loss: 1.5063\n",
      "[324/1762] D loss: 1.4381, G loss: 0.6338\n",
      "[404/1762] D loss: 1.0742, G loss: 1.0236\n",
      "[484/1762] D loss: 1.4216, G loss: 0.9014\n",
      "[564/1762] D loss: 1.4710, G loss: 0.5778\n",
      "[644/1762] D loss: 1.3061, G loss: 0.7372\n",
      "[724/1762] D loss: 1.1250, G loss: 0.9175\n",
      "[804/1762] D loss: 1.0763, G loss: 1.0606\n",
      "[884/1762] D loss: 1.3978, G loss: 0.7221\n",
      "[964/1762] D loss: 1.3870, G loss: 0.6833\n",
      "[1044/1762] D loss: 1.3036, G loss: 0.9713\n",
      "[1124/1762] D loss: 1.3947, G loss: 0.6552\n",
      "[1204/1762] D loss: 1.3923, G loss: 0.7063\n",
      "[1284/1762] D loss: 1.3921, G loss: 0.7495\n",
      "[1364/1762] D loss: 1.3898, G loss: 0.6790\n",
      "[1444/1762] D loss: 1.4314, G loss: 0.8430\n",
      "[1524/1762] D loss: 1.1030, G loss: 1.0407\n",
      "[1604/1762] D loss: 1.0940, G loss: 1.1631\n",
      "[1684/1762] D loss: 1.0545, G loss: 1.2109\n",
      "[1762/1762] D loss: 1.3975, G loss: 0.6452\n",
      "train error: \n",
      " D loss: 1.309639, G loss: 0.737587, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 85.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.287591, G loss: 0.773729, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 84.1% \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3914, G loss: 0.6738\n",
      "[84/1762] D loss: 1.3767, G loss: 0.7219\n",
      "[164/1762] D loss: 0.8901, G loss: 1.3573\n",
      "[244/1762] D loss: 1.3963, G loss: 0.7565\n",
      "[324/1762] D loss: 1.3641, G loss: 0.8430\n",
      "[404/1762] D loss: 1.4128, G loss: 0.8170\n",
      "[484/1762] D loss: 1.3856, G loss: 0.6643\n",
      "[564/1762] D loss: 1.3873, G loss: 0.7536\n",
      "[644/1762] D loss: 1.1049, G loss: 1.0731\n",
      "[724/1762] D loss: 1.3935, G loss: 0.6781\n",
      "[804/1762] D loss: 1.1528, G loss: 1.0468\n",
      "[884/1762] D loss: 1.3743, G loss: 0.7164\n",
      "[964/1762] D loss: 1.0837, G loss: 1.0805\n",
      "[1044/1762] D loss: 1.3937, G loss: 0.7403\n",
      "[1124/1762] D loss: 1.3985, G loss: 0.6350\n",
      "[1204/1762] D loss: 1.3909, G loss: 0.6639\n",
      "[1284/1762] D loss: 1.3871, G loss: 0.6763\n",
      "[1364/1762] D loss: 1.3911, G loss: 0.7661\n",
      "[1444/1762] D loss: 1.3952, G loss: 0.5972\n",
      "[1524/1762] D loss: 1.1219, G loss: 1.1736\n",
      "[1604/1762] D loss: 1.0976, G loss: 1.0212\n",
      "[1684/1762] D loss: 1.4015, G loss: 0.7659\n",
      "[1762/1762] D loss: 1.3870, G loss: 0.7138\n",
      "train error: \n",
      " D loss: 1.306000, G loss: 0.871107, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 88.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.282991, G loss: 0.909546, D accuracy: 55.7%, cell accuracy: 99.8%, board accuracy: 84.1% \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4003, G loss: 0.7438\n",
      "[84/1762] D loss: 1.3905, G loss: 0.7995\n",
      "[164/1762] D loss: 1.0817, G loss: 1.0134\n",
      "[244/1762] D loss: 1.0722, G loss: 1.2471\n",
      "[324/1762] D loss: 1.4370, G loss: 0.5417\n",
      "[404/1762] D loss: 1.4305, G loss: 0.5082\n",
      "[484/1762] D loss: 1.3887, G loss: 0.7316\n",
      "[564/1762] D loss: 1.3918, G loss: 0.7343\n",
      "[644/1762] D loss: 1.0711, G loss: 1.1367\n",
      "[724/1762] D loss: 1.0773, G loss: 1.1445\n",
      "[804/1762] D loss: 1.4061, G loss: 0.8126\n",
      "[884/1762] D loss: 1.3898, G loss: 0.7578\n",
      "[964/1762] D loss: 1.3872, G loss: 0.7289\n",
      "[1044/1762] D loss: 1.3914, G loss: 0.6607\n",
      "[1124/1762] D loss: 1.1520, G loss: 1.1987\n",
      "[1204/1762] D loss: 1.3947, G loss: 0.7536\n",
      "[1284/1762] D loss: 1.4083, G loss: 0.6750\n",
      "[1364/1762] D loss: 1.0757, G loss: 1.1080\n",
      "[1444/1762] D loss: 1.3904, G loss: 0.6775\n",
      "[1524/1762] D loss: 1.3928, G loss: 0.6860\n",
      "[1604/1762] D loss: 1.3938, G loss: 0.6596\n",
      "[1684/1762] D loss: 1.0813, G loss: 1.1087\n",
      "[1762/1762] D loss: 1.4259, G loss: 0.8202\n",
      "train error: \n",
      " D loss: 1.323614, G loss: 0.668999, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.303265, G loss: 0.698438, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4136, G loss: 0.6005\n",
      "[84/1762] D loss: 1.3886, G loss: 0.6568\n",
      "[164/1762] D loss: 1.3957, G loss: 0.6646\n",
      "[244/1762] D loss: 1.3899, G loss: 0.6874\n",
      "[324/1762] D loss: 1.0874, G loss: 1.0817\n",
      "[404/1762] D loss: 1.0772, G loss: 0.9757\n",
      "[484/1762] D loss: 1.0964, G loss: 0.9870\n",
      "[564/1762] D loss: 1.3955, G loss: 0.7349\n",
      "[644/1762] D loss: 1.3891, G loss: 0.7672\n",
      "[724/1762] D loss: 1.1834, G loss: 1.2647\n",
      "[804/1762] D loss: 1.4022, G loss: 0.7830\n",
      "[884/1762] D loss: 1.3889, G loss: 0.7728\n",
      "[964/1762] D loss: 1.3940, G loss: 0.5681\n",
      "[1044/1762] D loss: 1.4800, G loss: 1.0589\n",
      "[1124/1762] D loss: 1.0843, G loss: 1.0628\n",
      "[1204/1762] D loss: 1.3911, G loss: 0.6646\n",
      "[1284/1762] D loss: 1.3948, G loss: 0.7505\n",
      "[1364/1762] D loss: 1.3889, G loss: 0.6558\n",
      "[1444/1762] D loss: 1.1172, G loss: 0.9086\n",
      "[1524/1762] D loss: 1.3934, G loss: 0.6883\n",
      "[1604/1762] D loss: 1.4020, G loss: 0.7877\n",
      "[1684/1762] D loss: 1.3938, G loss: 0.6536\n",
      "[1762/1762] D loss: 1.3784, G loss: 0.6141\n",
      "train error: \n",
      " D loss: 1.304189, G loss: 0.787606, D accuracy: 54.0%, cell accuracy: 99.9%, board accuracy: 90.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.282692, G loss: 0.822735, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3944, G loss: 0.6279\n",
      "[84/1762] D loss: 1.3876, G loss: 0.6326\n",
      "[164/1762] D loss: 1.3977, G loss: 0.6706\n",
      "[244/1762] D loss: 1.3902, G loss: 0.7076\n",
      "[324/1762] D loss: 1.0822, G loss: 1.0075\n",
      "[404/1762] D loss: 1.3439, G loss: 1.0308\n",
      "[484/1762] D loss: 1.3922, G loss: 0.7572\n",
      "[564/1762] D loss: 1.3940, G loss: 0.7056\n",
      "[644/1762] D loss: 1.3994, G loss: 0.7830\n",
      "[724/1762] D loss: 1.3878, G loss: 0.7225\n",
      "[804/1762] D loss: 1.3886, G loss: 0.7535\n",
      "[884/1762] D loss: 1.3881, G loss: 0.7485\n",
      "[964/1762] D loss: 1.4932, G loss: 1.0830\n",
      "[1044/1762] D loss: 1.4002, G loss: 0.6615\n",
      "[1124/1762] D loss: 1.4199, G loss: 0.8632\n",
      "[1204/1762] D loss: 1.3957, G loss: 0.6623\n",
      "[1284/1762] D loss: 1.3882, G loss: 0.7119\n",
      "[1364/1762] D loss: 1.0829, G loss: 1.0295\n",
      "[1444/1762] D loss: 1.3878, G loss: 0.6816\n",
      "[1524/1762] D loss: 1.4055, G loss: 0.7215\n",
      "[1604/1762] D loss: 1.3953, G loss: 0.7541\n",
      "[1684/1762] D loss: 1.4014, G loss: 0.7773\n",
      "[1762/1762] D loss: 0.7364, G loss: 1.7858\n",
      "train error: \n",
      " D loss: 1.309042, G loss: 0.883544, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.287895, G loss: 0.925225, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3881, G loss: 0.7866\n",
      "[84/1762] D loss: 1.3884, G loss: 0.7014\n",
      "[164/1762] D loss: 1.4044, G loss: 0.7139\n",
      "[244/1762] D loss: 1.3942, G loss: 0.6068\n",
      "[324/1762] D loss: 1.3896, G loss: 0.7296\n",
      "[404/1762] D loss: 1.3912, G loss: 0.7270\n",
      "[484/1762] D loss: 1.3868, G loss: 0.6618\n",
      "[564/1762] D loss: 1.3758, G loss: 0.7014\n",
      "[644/1762] D loss: 1.3542, G loss: 0.6717\n",
      "[724/1762] D loss: 1.3040, G loss: 1.0700\n",
      "[804/1762] D loss: 1.3965, G loss: 0.7385\n",
      "[884/1762] D loss: 1.3984, G loss: 0.6455\n",
      "[964/1762] D loss: 1.3918, G loss: 0.7324\n",
      "[1044/1762] D loss: 1.4309, G loss: 0.8523\n",
      "[1124/1762] D loss: 1.3996, G loss: 0.7759\n",
      "[1204/1762] D loss: 1.3972, G loss: 0.7725\n",
      "[1284/1762] D loss: 1.3884, G loss: 0.7173\n",
      "[1364/1762] D loss: 1.3903, G loss: 0.6595\n",
      "[1444/1762] D loss: 1.0877, G loss: 1.2501\n",
      "[1524/1762] D loss: 0.7554, G loss: 1.6115\n",
      "[1604/1762] D loss: 1.3983, G loss: 0.5589\n",
      "[1684/1762] D loss: 1.3968, G loss: 0.6638\n",
      "[1762/1762] D loss: 1.4376, G loss: 0.8740\n",
      "train error: \n",
      " D loss: 1.304127, G loss: 0.800421, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.282501, G loss: 0.839221, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0755, G loss: 1.0427\n",
      "[84/1762] D loss: 1.4070, G loss: 0.7806\n",
      "[164/1762] D loss: 1.0753, G loss: 1.1106\n",
      "[244/1762] D loss: 1.3926, G loss: 0.6730\n",
      "[324/1762] D loss: 1.4110, G loss: 0.6313\n",
      "[404/1762] D loss: 1.0831, G loss: 0.9998\n",
      "[484/1762] D loss: 1.3957, G loss: 0.7132\n",
      "[564/1762] D loss: 1.4040, G loss: 0.6719\n",
      "[644/1762] D loss: 1.4546, G loss: 0.7387\n",
      "[724/1762] D loss: 1.2934, G loss: 0.9701\n",
      "[804/1762] D loss: 1.0771, G loss: 1.1456\n",
      "[884/1762] D loss: 1.0611, G loss: 1.2276\n",
      "[964/1762] D loss: 1.3882, G loss: 0.6186\n",
      "[1044/1762] D loss: 1.3971, G loss: 0.7827\n",
      "[1124/1762] D loss: 1.3939, G loss: 0.6126\n",
      "[1204/1762] D loss: 1.3803, G loss: 0.6278\n",
      "[1284/1762] D loss: 1.3920, G loss: 0.7902\n",
      "[1364/1762] D loss: 1.3744, G loss: 0.8026\n",
      "[1444/1762] D loss: 1.3866, G loss: 0.6882\n",
      "[1524/1762] D loss: 1.0822, G loss: 1.0157\n",
      "[1604/1762] D loss: 1.3880, G loss: 0.6880\n",
      "[1684/1762] D loss: 1.2397, G loss: 0.8277\n",
      "[1762/1762] D loss: 1.3996, G loss: 0.8386\n",
      "train error: \n",
      " D loss: 1.312847, G loss: 0.926741, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 91.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.291756, G loss: 0.969439, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4017, G loss: 0.8037\n",
      "[84/1762] D loss: 1.0765, G loss: 1.1008\n",
      "[164/1762] D loss: 1.0808, G loss: 1.1084\n",
      "[244/1762] D loss: 1.3882, G loss: 0.6680\n",
      "[324/1762] D loss: 1.0609, G loss: 1.1971\n",
      "[404/1762] D loss: 1.4137, G loss: 0.7056\n",
      "[484/1762] D loss: 1.3317, G loss: 0.7072\n",
      "[564/1762] D loss: 1.0870, G loss: 0.9830\n",
      "[644/1762] D loss: 1.3885, G loss: 0.6842\n",
      "[724/1762] D loss: 1.3922, G loss: 0.6570\n",
      "[804/1762] D loss: 1.3984, G loss: 0.6207\n",
      "[884/1762] D loss: 1.3938, G loss: 0.7343\n",
      "[964/1762] D loss: 1.3892, G loss: 0.7320\n",
      "[1044/1762] D loss: 1.3911, G loss: 0.6277\n",
      "[1124/1762] D loss: 1.3878, G loss: 0.7085\n",
      "[1204/1762] D loss: 1.2865, G loss: 0.9497\n",
      "[1284/1762] D loss: 1.0950, G loss: 1.1811\n",
      "[1364/1762] D loss: 1.0938, G loss: 1.1325\n",
      "[1444/1762] D loss: 1.1051, G loss: 1.0365\n",
      "[1524/1762] D loss: 1.3903, G loss: 0.6637\n",
      "[1604/1762] D loss: 1.4820, G loss: 0.6420\n",
      "[1684/1762] D loss: 1.3995, G loss: 0.6041\n",
      "[1762/1762] D loss: 1.3869, G loss: 0.6444\n",
      "train error: \n",
      " D loss: 1.305061, G loss: 0.832977, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.282008, G loss: 0.872416, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3912, G loss: 0.6586\n",
      "[84/1762] D loss: 1.3925, G loss: 0.6524\n",
      "[164/1762] D loss: 1.3892, G loss: 0.6676\n",
      "[244/1762] D loss: 1.0760, G loss: 1.1031\n",
      "[324/1762] D loss: 1.3958, G loss: 0.7499\n",
      "[404/1762] D loss: 1.3414, G loss: 0.8395\n",
      "[484/1762] D loss: 1.0752, G loss: 1.1386\n",
      "[564/1762] D loss: 1.3894, G loss: 0.6582\n",
      "[644/1762] D loss: 1.3898, G loss: 0.7065\n",
      "[724/1762] D loss: 1.0200, G loss: 1.2038\n",
      "[804/1762] D loss: 1.3874, G loss: 0.7098\n",
      "[884/1762] D loss: 1.4037, G loss: 0.7891\n",
      "[964/1762] D loss: 1.3959, G loss: 0.7622\n",
      "[1044/1762] D loss: 1.0870, G loss: 1.0454\n",
      "[1124/1762] D loss: 1.2911, G loss: 0.9385\n",
      "[1204/1762] D loss: 1.3989, G loss: 0.7833\n",
      "[1284/1762] D loss: 1.0817, G loss: 1.0144\n",
      "[1364/1762] D loss: 1.4356, G loss: 0.8448\n",
      "[1444/1762] D loss: 1.3899, G loss: 0.7279\n",
      "[1524/1762] D loss: 1.0852, G loss: 1.0515\n",
      "[1604/1762] D loss: 1.3909, G loss: 0.7490\n",
      "[1684/1762] D loss: 0.7569, G loss: 1.6763\n",
      "[1762/1762] D loss: 1.3866, G loss: 0.7431\n",
      "train error: \n",
      " D loss: 1.306407, G loss: 0.882034, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.284932, G loss: 0.923492, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7587, G loss: 1.5871\n",
      "[84/1762] D loss: 1.3895, G loss: 0.7152\n",
      "[164/1762] D loss: 1.3869, G loss: 0.7385\n",
      "[244/1762] D loss: 1.3974, G loss: 0.6443\n",
      "[324/1762] D loss: 1.3866, G loss: 0.7406\n",
      "[404/1762] D loss: 0.6840, G loss: 1.7600\n",
      "[484/1762] D loss: 1.3914, G loss: 0.6565\n",
      "[564/1762] D loss: 1.2972, G loss: 0.8138\n",
      "[644/1762] D loss: 1.0786, G loss: 1.0893\n",
      "[724/1762] D loss: 1.3905, G loss: 0.6637\n",
      "[804/1762] D loss: 1.0048, G loss: 1.2127\n",
      "[884/1762] D loss: 1.3942, G loss: 0.6359\n",
      "[964/1762] D loss: 1.3932, G loss: 0.6531\n",
      "[1044/1762] D loss: 1.3885, G loss: 0.7354\n",
      "[1124/1762] D loss: 1.3967, G loss: 0.7753\n",
      "[1204/1762] D loss: 1.0754, G loss: 1.0615\n",
      "[1284/1762] D loss: 1.3988, G loss: 0.5961\n",
      "[1364/1762] D loss: 1.3895, G loss: 0.6518\n",
      "[1444/1762] D loss: 1.3862, G loss: 0.6446\n",
      "[1524/1762] D loss: 1.4017, G loss: 0.8142\n",
      "[1604/1762] D loss: 1.3930, G loss: 0.7755\n",
      "[1684/1762] D loss: 1.0991, G loss: 1.0156\n",
      "[1762/1762] D loss: 1.3895, G loss: 0.7359\n",
      "train error: \n",
      " D loss: 1.302208, G loss: 0.835417, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.280179, G loss: 0.877294, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3880, G loss: 0.6765\n",
      "[84/1762] D loss: 1.4002, G loss: 0.7769\n",
      "[164/1762] D loss: 0.7540, G loss: 1.5369\n",
      "[244/1762] D loss: 1.3919, G loss: 0.7278\n",
      "[324/1762] D loss: 1.3955, G loss: 0.6955\n",
      "[404/1762] D loss: 1.0696, G loss: 1.1716\n",
      "[484/1762] D loss: 1.3883, G loss: 0.6975\n",
      "[564/1762] D loss: 1.3983, G loss: 0.8163\n",
      "[644/1762] D loss: 1.0916, G loss: 1.0400\n",
      "[724/1762] D loss: 1.0729, G loss: 1.0879\n",
      "[804/1762] D loss: 1.0588, G loss: 1.2819\n",
      "[884/1762] D loss: 1.2783, G loss: 0.8721\n",
      "[964/1762] D loss: 1.0719, G loss: 1.2608\n",
      "[1044/1762] D loss: 1.0821, G loss: 1.1789\n",
      "[1124/1762] D loss: 1.4035, G loss: 0.6410\n",
      "[1204/1762] D loss: 1.3864, G loss: 0.6387\n",
      "[1284/1762] D loss: 0.9682, G loss: 1.4581\n",
      "[1364/1762] D loss: 1.3896, G loss: 0.6717\n",
      "[1444/1762] D loss: 1.4139, G loss: 0.6583\n",
      "[1524/1762] D loss: 1.0890, G loss: 1.2319\n",
      "[1604/1762] D loss: 1.3903, G loss: 0.7094\n",
      "[1684/1762] D loss: 1.4051, G loss: 0.7663\n",
      "[1762/1762] D loss: 1.3943, G loss: 0.6340\n",
      "train error: \n",
      " D loss: 1.304156, G loss: 0.828423, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 92.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.281275, G loss: 0.870457, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0688, G loss: 1.1373\n",
      "[84/1762] D loss: 1.3924, G loss: 0.6978\n",
      "[164/1762] D loss: 1.0666, G loss: 1.1028\n",
      "[244/1762] D loss: 1.3890, G loss: 0.6703\n",
      "[324/1762] D loss: 1.3470, G loss: 0.7315\n",
      "[404/1762] D loss: 1.3931, G loss: 0.7774\n",
      "[484/1762] D loss: 1.3925, G loss: 0.7071\n",
      "[564/1762] D loss: 1.3876, G loss: 0.7238\n",
      "[644/1762] D loss: 1.5221, G loss: 0.6589\n",
      "[724/1762] D loss: 1.3949, G loss: 0.6526\n",
      "[804/1762] D loss: 1.3997, G loss: 0.7653\n",
      "[884/1762] D loss: 1.0325, G loss: 1.2954\n",
      "[964/1762] D loss: 1.3904, G loss: 0.6974\n",
      "[1044/1762] D loss: 1.3974, G loss: 0.7460\n",
      "[1124/1762] D loss: 1.0807, G loss: 1.0993\n",
      "[1204/1762] D loss: 1.3871, G loss: 0.6626\n",
      "[1284/1762] D loss: 1.3886, G loss: 0.7171\n",
      "[1364/1762] D loss: 1.0855, G loss: 1.0657\n",
      "[1444/1762] D loss: 1.3976, G loss: 0.7592\n",
      "[1524/1762] D loss: 1.4084, G loss: 0.6471\n",
      "[1604/1762] D loss: 1.4544, G loss: 0.9956\n",
      "[1684/1762] D loss: 1.5134, G loss: 0.7176\n",
      "[1762/1762] D loss: 1.3891, G loss: 0.6922\n",
      "train error: \n",
      " D loss: 1.303354, G loss: 0.809156, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.280274, G loss: 0.849688, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0948, G loss: 1.0513\n",
      "[84/1762] D loss: 1.3935, G loss: 0.7195\n",
      "[164/1762] D loss: 1.3878, G loss: 0.7096\n",
      "[244/1762] D loss: 1.0781, G loss: 1.0376\n",
      "[324/1762] D loss: 1.3909, G loss: 0.6764\n",
      "[404/1762] D loss: 1.0809, G loss: 1.0557\n",
      "[484/1762] D loss: 1.3871, G loss: 0.7288\n",
      "[564/1762] D loss: 1.3895, G loss: 0.6602\n",
      "[644/1762] D loss: 1.3900, G loss: 0.7453\n",
      "[724/1762] D loss: 0.7524, G loss: 1.5848\n",
      "[804/1762] D loss: 1.2813, G loss: 0.7614\n",
      "[884/1762] D loss: 1.3927, G loss: 0.6257\n",
      "[964/1762] D loss: 1.2553, G loss: 1.0774\n",
      "[1044/1762] D loss: 1.4003, G loss: 0.6316\n",
      "[1124/1762] D loss: 1.3929, G loss: 0.7603\n",
      "[1204/1762] D loss: 1.3903, G loss: 0.7206\n",
      "[1284/1762] D loss: 1.3903, G loss: 0.6629\n",
      "[1364/1762] D loss: 1.3888, G loss: 0.6540\n",
      "[1444/1762] D loss: 1.4555, G loss: 0.7412\n",
      "[1524/1762] D loss: 1.4281, G loss: 0.8000\n",
      "[1604/1762] D loss: 1.0739, G loss: 1.1258\n",
      "[1684/1762] D loss: 1.3922, G loss: 0.6207\n",
      "[1762/1762] D loss: 0.8051, G loss: 1.3903\n",
      "train error: \n",
      " D loss: 1.299459, G loss: 0.811179, D accuracy: 54.1%, cell accuracy: 99.9%, board accuracy: 90.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.277670, G loss: 0.851445, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3954, G loss: 0.6617\n",
      "[84/1762] D loss: 1.0786, G loss: 0.9837\n",
      "[164/1762] D loss: 1.4095, G loss: 0.8657\n",
      "[244/1762] D loss: 1.3874, G loss: 0.7132\n",
      "[324/1762] D loss: 1.4071, G loss: 0.5964\n",
      "[404/1762] D loss: 0.7602, G loss: 1.4995\n",
      "[484/1762] D loss: 1.3801, G loss: 0.7041\n",
      "[564/1762] D loss: 1.3988, G loss: 0.6396\n",
      "[644/1762] D loss: 1.0736, G loss: 1.0662\n",
      "[724/1762] D loss: 1.3898, G loss: 0.6680\n",
      "[804/1762] D loss: 1.4034, G loss: 0.7507\n",
      "[884/1762] D loss: 1.3977, G loss: 0.8485\n",
      "[964/1762] D loss: 1.3899, G loss: 0.6356\n",
      "[1044/1762] D loss: 1.3855, G loss: 0.6814\n",
      "[1124/1762] D loss: 1.4119, G loss: 0.5483\n",
      "[1204/1762] D loss: 1.3908, G loss: 0.6669\n",
      "[1284/1762] D loss: 0.7495, G loss: 1.6368\n",
      "[1364/1762] D loss: 1.3907, G loss: 0.6855\n",
      "[1444/1762] D loss: 1.4376, G loss: 0.8570\n",
      "[1524/1762] D loss: 1.3940, G loss: 0.6319\n",
      "[1604/1762] D loss: 1.1116, G loss: 0.9611\n",
      "[1684/1762] D loss: 1.0771, G loss: 1.0222\n",
      "[1762/1762] D loss: 1.3944, G loss: 0.6737\n",
      "train error: \n",
      " D loss: 1.299170, G loss: 0.823797, D accuracy: 53.7%, cell accuracy: 99.9%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.277147, G loss: 0.865065, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 89.1% \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3898, G loss: 0.6817\n",
      "[84/1762] D loss: 1.0680, G loss: 1.1423\n",
      "[164/1762] D loss: 1.0766, G loss: 1.0822\n",
      "[244/1762] D loss: 1.3905, G loss: 0.7387\n",
      "[324/1762] D loss: 1.3876, G loss: 0.6801\n",
      "[404/1762] D loss: 0.7535, G loss: 1.7954\n",
      "[484/1762] D loss: 1.3870, G loss: 0.6854\n",
      "[564/1762] D loss: 1.3885, G loss: 0.6681\n",
      "[644/1762] D loss: 1.0686, G loss: 1.2042\n",
      "[724/1762] D loss: 1.4053, G loss: 0.8089\n",
      "[804/1762] D loss: 1.0695, G loss: 1.1925\n",
      "[884/1762] D loss: 1.3873, G loss: 0.7649\n",
      "[964/1762] D loss: 1.4039, G loss: 0.7018\n",
      "[1044/1762] D loss: 1.4026, G loss: 0.7810\n",
      "[1124/1762] D loss: 1.0720, G loss: 1.2073\n",
      "[1204/1762] D loss: 1.3903, G loss: 0.6749\n",
      "[1284/1762] D loss: 1.4015, G loss: 0.7632\n",
      "[1364/1762] D loss: 1.3938, G loss: 0.6530\n",
      "[1444/1762] D loss: 1.3876, G loss: 0.6715\n",
      "[1524/1762] D loss: 1.3883, G loss: 0.6752\n",
      "[1604/1762] D loss: 1.0656, G loss: 1.1736\n",
      "[1684/1762] D loss: 1.3959, G loss: 0.6659\n",
      "[1762/1762] D loss: 0.7468, G loss: 1.6286\n",
      "train error: \n",
      " D loss: 1.302521, G loss: 0.856060, D accuracy: 53.4%, cell accuracy: 99.9%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.280719, G loss: 0.899790, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3927, G loss: 0.7155\n",
      "[84/1762] D loss: 1.3893, G loss: 0.6803\n",
      "[164/1762] D loss: 1.0797, G loss: 0.9941\n",
      "[244/1762] D loss: 1.4005, G loss: 0.7551\n",
      "[324/1762] D loss: 1.4165, G loss: 0.5938\n",
      "[404/1762] D loss: 1.0711, G loss: 1.0752\n",
      "[484/1762] D loss: 1.0712, G loss: 1.2153\n",
      "[564/1762] D loss: 1.3975, G loss: 0.6377\n",
      "[644/1762] D loss: 1.4208, G loss: 0.5534\n",
      "[724/1762] D loss: 1.3896, G loss: 0.6937\n",
      "[804/1762] D loss: 1.3999, G loss: 0.7907\n",
      "[884/1762] D loss: 1.3872, G loss: 0.7091\n",
      "[964/1762] D loss: 1.3883, G loss: 0.7258\n",
      "[1044/1762] D loss: 1.3942, G loss: 0.6040\n",
      "[1124/1762] D loss: 1.0992, G loss: 0.9994\n",
      "[1204/1762] D loss: 0.7533, G loss: 1.4652\n",
      "[1284/1762] D loss: 1.3967, G loss: 0.7158\n",
      "[1364/1762] D loss: 1.3957, G loss: 0.7555\n",
      "[1444/1762] D loss: 1.3882, G loss: 0.7416\n",
      "[1524/1762] D loss: 1.3913, G loss: 0.6697\n",
      "[1604/1762] D loss: 1.4123, G loss: 0.8378\n",
      "[1684/1762] D loss: 1.3890, G loss: 0.6924\n",
      "[1762/1762] D loss: 1.3960, G loss: 0.6045\n",
      "train error: \n",
      " D loss: 1.300414, G loss: 0.811421, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 92.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.278168, G loss: 0.854188, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 89.8% \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3955, G loss: 0.6551\n",
      "[84/1762] D loss: 1.4189, G loss: 0.6788\n",
      "[164/1762] D loss: 0.7597, G loss: 1.6576\n",
      "[244/1762] D loss: 1.0680, G loss: 1.3162\n",
      "[324/1762] D loss: 1.0654, G loss: 1.1910\n",
      "[404/1762] D loss: 1.3900, G loss: 0.6155\n",
      "[484/1762] D loss: 1.3939, G loss: 0.7427\n",
      "[564/1762] D loss: 1.3957, G loss: 0.6362\n",
      "[644/1762] D loss: 1.3876, G loss: 0.7209\n",
      "[724/1762] D loss: 1.0671, G loss: 1.1689\n",
      "[804/1762] D loss: 1.3956, G loss: 0.6559\n",
      "[884/1762] D loss: 1.4054, G loss: 0.5921\n",
      "[964/1762] D loss: 1.3936, G loss: 0.7321\n",
      "[1044/1762] D loss: 1.3954, G loss: 0.6486\n",
      "[1124/1762] D loss: 1.3913, G loss: 0.7786\n",
      "[1204/1762] D loss: 1.3906, G loss: 0.7204\n",
      "[1284/1762] D loss: 1.3281, G loss: 0.8203\n",
      "[1364/1762] D loss: 1.3938, G loss: 0.7319\n",
      "[1444/1762] D loss: 1.0611, G loss: 1.1874\n",
      "[1524/1762] D loss: 1.3017, G loss: 0.8242\n",
      "[1604/1762] D loss: 1.4032, G loss: 0.7106\n",
      "[1684/1762] D loss: 1.3393, G loss: 0.7885\n",
      "[1762/1762] D loss: 0.7840, G loss: 1.8329\n",
      "train error: \n",
      " D loss: 1.313122, G loss: 0.966971, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 91.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.291368, G loss: 1.010178, D accuracy: 54.9%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4005, G loss: 0.7919\n",
      "[84/1762] D loss: 1.0782, G loss: 1.0833\n",
      "[164/1762] D loss: 1.0646, G loss: 1.1855\n",
      "[244/1762] D loss: 1.0169, G loss: 1.6590\n",
      "[324/1762] D loss: 1.3919, G loss: 0.7412\n",
      "[404/1762] D loss: 1.3914, G loss: 0.7147\n",
      "[484/1762] D loss: 1.3898, G loss: 0.7264\n",
      "[564/1762] D loss: 0.9363, G loss: 1.3220\n",
      "[644/1762] D loss: 1.3911, G loss: 0.7813\n",
      "[724/1762] D loss: 1.3925, G loss: 0.7367\n",
      "[804/1762] D loss: 1.3873, G loss: 0.6745\n",
      "[884/1762] D loss: 1.3919, G loss: 0.6952\n",
      "[964/1762] D loss: 1.0838, G loss: 0.9211\n",
      "[1044/1762] D loss: 1.4224, G loss: 0.8119\n",
      "[1124/1762] D loss: 1.3803, G loss: 0.6847\n",
      "[1204/1762] D loss: 1.0590, G loss: 1.2461\n",
      "[1284/1762] D loss: 1.3942, G loss: 0.7444\n",
      "[1364/1762] D loss: 1.4220, G loss: 0.6417\n",
      "[1444/1762] D loss: 1.4004, G loss: 0.7374\n",
      "[1524/1762] D loss: 1.4820, G loss: 0.6697\n",
      "[1604/1762] D loss: 1.3904, G loss: 0.7308\n",
      "[1684/1762] D loss: 1.3884, G loss: 0.7159\n",
      "[1762/1762] D loss: 1.4080, G loss: 0.7315\n",
      "train error: \n",
      " D loss: 1.280120, G loss: 0.760411, D accuracy: 59.3%, cell accuracy: 99.7%, board accuracy: 68.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.254201, G loss: 0.803393, D accuracy: 59.4%, cell accuracy: 99.7%, board accuracy: 66.6% \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0222, G loss: 1.1804\n",
      "[84/1762] D loss: 1.3617, G loss: 0.7400\n",
      "[164/1762] D loss: 1.3924, G loss: 0.7429\n",
      "[244/1762] D loss: 1.4355, G loss: 0.5766\n",
      "[324/1762] D loss: 1.4041, G loss: 0.5486\n",
      "[404/1762] D loss: 1.3965, G loss: 0.7883\n",
      "[484/1762] D loss: 1.3874, G loss: 0.6785\n",
      "[564/1762] D loss: 1.3935, G loss: 0.7602\n",
      "[644/1762] D loss: 1.3975, G loss: 0.7562\n",
      "[724/1762] D loss: 1.0383, G loss: 1.2045\n",
      "[804/1762] D loss: 1.3918, G loss: 0.6560\n",
      "[884/1762] D loss: 1.3897, G loss: 0.7356\n",
      "[964/1762] D loss: 1.4018, G loss: 0.6131\n",
      "[1044/1762] D loss: 1.3933, G loss: 0.7085\n",
      "[1124/1762] D loss: 1.3895, G loss: 0.7431\n",
      "[1204/1762] D loss: 1.3876, G loss: 0.6940\n",
      "[1284/1762] D loss: 1.3864, G loss: 0.6660\n",
      "[1364/1762] D loss: 1.4401, G loss: 0.6690\n",
      "[1444/1762] D loss: 1.3930, G loss: 0.6739\n",
      "[1524/1762] D loss: 1.3898, G loss: 0.7014\n",
      "[1604/1762] D loss: 1.3849, G loss: 0.6770\n",
      "[1684/1762] D loss: 1.0715, G loss: 1.1273\n",
      "[1762/1762] D loss: 1.3801, G loss: 0.7073\n",
      "train error: \n",
      " D loss: 1.293189, G loss: 0.872270, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 89.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.270999, G loss: 0.916719, D accuracy: 55.8%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3838, G loss: 0.7825\n",
      "[84/1762] D loss: 1.4512, G loss: 0.5446\n",
      "[164/1762] D loss: 1.3422, G loss: 0.7054\n",
      "[244/1762] D loss: 1.3872, G loss: 0.7169\n",
      "[324/1762] D loss: 1.3165, G loss: 1.0643\n",
      "[404/1762] D loss: 1.3863, G loss: 0.8150\n",
      "[484/1762] D loss: 1.0616, G loss: 1.2215\n",
      "[564/1762] D loss: 1.0692, G loss: 1.1983\n",
      "[644/1762] D loss: 1.3973, G loss: 0.7566\n",
      "[724/1762] D loss: 1.3878, G loss: 0.6867\n",
      "[804/1762] D loss: 1.3941, G loss: 0.7248\n",
      "[884/1762] D loss: 1.3937, G loss: 0.7047\n",
      "[964/1762] D loss: 1.0703, G loss: 1.1142\n",
      "[1044/1762] D loss: 1.3893, G loss: 0.6628\n",
      "[1124/1762] D loss: 0.7762, G loss: 1.6251\n",
      "[1204/1762] D loss: 1.2920, G loss: 1.1057\n",
      "[1284/1762] D loss: 1.0626, G loss: 1.1957\n",
      "[1364/1762] D loss: 1.3904, G loss: 0.6648\n",
      "[1444/1762] D loss: 1.0693, G loss: 1.1648\n",
      "[1524/1762] D loss: 1.3927, G loss: 0.6746\n",
      "[1604/1762] D loss: 1.4045, G loss: 0.7878\n",
      "[1684/1762] D loss: 1.3862, G loss: 0.6963\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.7470\n",
      "train error: \n",
      " D loss: 1.302681, G loss: 0.879056, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 91.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.279752, G loss: 0.925643, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4011, G loss: 0.7700\n",
      "[84/1762] D loss: 1.3881, G loss: 0.6825\n",
      "[164/1762] D loss: 1.3824, G loss: 0.6335\n",
      "[244/1762] D loss: 1.3857, G loss: 0.7190\n",
      "[324/1762] D loss: 1.3909, G loss: 0.7245\n",
      "[404/1762] D loss: 1.0300, G loss: 1.1774\n",
      "[484/1762] D loss: 1.3872, G loss: 0.7382\n",
      "[564/1762] D loss: 1.0819, G loss: 1.0851\n",
      "[644/1762] D loss: 1.4689, G loss: 0.9263\n",
      "[724/1762] D loss: 1.3893, G loss: 0.7245\n",
      "[804/1762] D loss: 1.0685, G loss: 1.1376\n",
      "[884/1762] D loss: 1.3937, G loss: 0.7226\n",
      "[964/1762] D loss: 1.4076, G loss: 0.7159\n",
      "[1044/1762] D loss: 1.4216, G loss: 0.8137\n",
      "[1124/1762] D loss: 0.7635, G loss: 1.5320\n",
      "[1204/1762] D loss: 1.3874, G loss: 0.6653\n",
      "[1284/1762] D loss: 1.3905, G loss: 0.7326\n",
      "[1364/1762] D loss: 1.3985, G loss: 0.7024\n",
      "[1444/1762] D loss: 1.3973, G loss: 0.6549\n",
      "[1524/1762] D loss: 1.3998, G loss: 0.6285\n",
      "[1604/1762] D loss: 1.4042, G loss: 0.6036\n",
      "[1684/1762] D loss: 1.0715, G loss: 1.0609\n",
      "[1762/1762] D loss: 1.3874, G loss: 0.6902\n",
      "train error: \n",
      " D loss: 1.283516, G loss: 0.858065, D accuracy: 56.0%, cell accuracy: 99.7%, board accuracy: 73.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.260461, G loss: 0.910724, D accuracy: 56.9%, cell accuracy: 99.7%, board accuracy: 72.3% \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3853, G loss: 0.6886\n",
      "[84/1762] D loss: 1.4040, G loss: 0.8408\n",
      "[164/1762] D loss: 1.4058, G loss: 0.6520\n",
      "[244/1762] D loss: 1.0885, G loss: 0.9755\n",
      "[324/1762] D loss: 1.3886, G loss: 0.7051\n",
      "[404/1762] D loss: 1.3933, G loss: 0.7579\n",
      "[484/1762] D loss: 1.3931, G loss: 0.7694\n",
      "[564/1762] D loss: 1.4015, G loss: 0.7513\n",
      "[644/1762] D loss: 1.3839, G loss: 0.7586\n",
      "[724/1762] D loss: 1.3952, G loss: 0.6518\n",
      "[804/1762] D loss: 1.3617, G loss: 0.7579\n",
      "[884/1762] D loss: 1.3892, G loss: 0.7185\n",
      "[964/1762] D loss: 1.0683, G loss: 1.1302\n",
      "[1044/1762] D loss: 1.3944, G loss: 0.6214\n",
      "[1124/1762] D loss: 1.3916, G loss: 0.6770\n",
      "[1204/1762] D loss: 1.3905, G loss: 0.7464\n",
      "[1284/1762] D loss: 1.3919, G loss: 0.6447\n",
      "[1364/1762] D loss: 1.3965, G loss: 0.7438\n",
      "[1444/1762] D loss: 1.3873, G loss: 0.7269\n",
      "[1524/1762] D loss: 1.3884, G loss: 0.6352\n",
      "[1604/1762] D loss: 1.3892, G loss: 0.7595\n",
      "[1684/1762] D loss: 1.3900, G loss: 0.6694\n",
      "[1762/1762] D loss: 1.3895, G loss: 0.6581\n",
      "train error: \n",
      " D loss: 1.300868, G loss: 0.807821, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.277311, G loss: 0.853822, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 89.3% \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3880, G loss: 0.6886\n",
      "[84/1762] D loss: 1.3875, G loss: 0.7066\n",
      "[164/1762] D loss: 1.3901, G loss: 0.7123\n",
      "[244/1762] D loss: 1.3878, G loss: 0.6829\n",
      "[324/1762] D loss: 1.3919, G loss: 0.7092\n",
      "[404/1762] D loss: 1.3964, G loss: 0.6894\n",
      "[484/1762] D loss: 1.3884, G loss: 0.7450\n",
      "[564/1762] D loss: 1.3896, G loss: 0.7590\n",
      "[644/1762] D loss: 1.3897, G loss: 0.7222\n",
      "[724/1762] D loss: 1.3888, G loss: 0.7556\n",
      "[804/1762] D loss: 1.0790, G loss: 1.0392\n",
      "[884/1762] D loss: 1.3884, G loss: 0.6601\n",
      "[964/1762] D loss: 0.9380, G loss: 1.5739\n",
      "[1044/1762] D loss: 1.0647, G loss: 1.1539\n",
      "[1124/1762] D loss: 1.3881, G loss: 0.6989\n",
      "[1204/1762] D loss: 1.3884, G loss: 0.7182\n",
      "[1284/1762] D loss: 1.4008, G loss: 0.6459\n",
      "[1364/1762] D loss: 1.4157, G loss: 0.6269\n",
      "[1444/1762] D loss: 1.0796, G loss: 0.9975\n",
      "[1524/1762] D loss: 1.3943, G loss: 0.7912\n",
      "[1604/1762] D loss: 1.3995, G loss: 0.5852\n",
      "[1684/1762] D loss: 1.3918, G loss: 0.7153\n",
      "[1762/1762] D loss: 1.3967, G loss: 0.7994\n",
      "train error: \n",
      " D loss: 1.309898, G loss: 0.949146, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.288347, G loss: 0.997246, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0636, G loss: 1.3377\n",
      "[84/1762] D loss: 0.7416, G loss: 1.7504\n",
      "[164/1762] D loss: 1.3930, G loss: 0.6254\n",
      "[244/1762] D loss: 1.0589, G loss: 1.2686\n",
      "[324/1762] D loss: 1.3997, G loss: 0.6518\n",
      "[404/1762] D loss: 1.3937, G loss: 0.7635\n",
      "[484/1762] D loss: 0.6900, G loss: 1.6001\n",
      "[564/1762] D loss: 1.3944, G loss: 0.6436\n",
      "[644/1762] D loss: 1.0668, G loss: 1.1566\n",
      "[724/1762] D loss: 1.0615, G loss: 1.1751\n",
      "[804/1762] D loss: 1.3928, G loss: 0.7570\n",
      "[884/1762] D loss: 1.0860, G loss: 1.1562\n",
      "[964/1762] D loss: 1.3897, G loss: 0.6204\n",
      "[1044/1762] D loss: 1.3911, G loss: 0.7124\n",
      "[1124/1762] D loss: 1.2516, G loss: 1.1641\n",
      "[1204/1762] D loss: 1.3903, G loss: 0.6873\n",
      "[1284/1762] D loss: 1.0652, G loss: 1.1562\n",
      "[1364/1762] D loss: 1.4018, G loss: 0.6472\n",
      "[1444/1762] D loss: 1.3942, G loss: 0.6232\n",
      "[1524/1762] D loss: 1.3911, G loss: 0.7287\n",
      "[1604/1762] D loss: 1.0652, G loss: 1.3658\n",
      "[1684/1762] D loss: 1.3814, G loss: 0.6764\n",
      "[1762/1762] D loss: 1.3922, G loss: 0.7458\n",
      "train error: \n",
      " D loss: 1.302102, G loss: 0.877864, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 91.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.279833, G loss: 0.924989, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3936, G loss: 0.7166\n",
      "[84/1762] D loss: 1.3820, G loss: 0.7643\n",
      "[164/1762] D loss: 1.3977, G loss: 0.6691\n",
      "[244/1762] D loss: 1.3895, G loss: 0.6522\n",
      "[324/1762] D loss: 1.3954, G loss: 0.7061\n",
      "[404/1762] D loss: 1.3930, G loss: 0.7272\n",
      "[484/1762] D loss: 1.0547, G loss: 1.3215\n",
      "[564/1762] D loss: 1.0755, G loss: 1.0632\n",
      "[644/1762] D loss: 1.3940, G loss: 0.7700\n",
      "[724/1762] D loss: 1.3833, G loss: 0.6656\n",
      "[804/1762] D loss: 1.3946, G loss: 0.6011\n",
      "[884/1762] D loss: 1.3817, G loss: 0.7040\n",
      "[964/1762] D loss: 1.3896, G loss: 0.7237\n",
      "[1044/1762] D loss: 1.3992, G loss: 0.6925\n",
      "[1124/1762] D loss: 1.3875, G loss: 0.7642\n",
      "[1204/1762] D loss: 1.1083, G loss: 0.9653\n",
      "[1284/1762] D loss: 1.4457, G loss: 0.8179\n",
      "[1364/1762] D loss: 1.0716, G loss: 1.2066\n",
      "[1444/1762] D loss: 1.3932, G loss: 0.6302\n",
      "[1524/1762] D loss: 1.3894, G loss: 0.6596\n",
      "[1604/1762] D loss: 1.4380, G loss: 0.8470\n",
      "[1684/1762] D loss: 1.3868, G loss: 0.7609\n",
      "[1762/1762] D loss: 1.4092, G loss: 0.7920\n",
      "train error: \n",
      " D loss: 1.303978, G loss: 0.894385, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 91.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.281956, G loss: 0.943316, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4005, G loss: 0.6918\n",
      "[84/1762] D loss: 1.3722, G loss: 0.6799\n",
      "[164/1762] D loss: 1.3903, G loss: 0.6549\n",
      "[244/1762] D loss: 1.3903, G loss: 0.7442\n",
      "[324/1762] D loss: 1.0660, G loss: 1.1308\n",
      "[404/1762] D loss: 1.3959, G loss: 0.6904\n",
      "[484/1762] D loss: 1.4487, G loss: 0.6274\n",
      "[564/1762] D loss: 1.3888, G loss: 0.6967\n",
      "[644/1762] D loss: 1.3871, G loss: 0.6832\n",
      "[724/1762] D loss: 1.3956, G loss: 0.6840\n",
      "[804/1762] D loss: 1.3908, G loss: 0.6827\n",
      "[884/1762] D loss: 1.3937, G loss: 0.7390\n",
      "[964/1762] D loss: 1.0626, G loss: 1.3028\n",
      "[1044/1762] D loss: 1.4150, G loss: 0.8017\n",
      "[1124/1762] D loss: 1.3891, G loss: 0.7106\n",
      "[1204/1762] D loss: 1.3887, G loss: 0.6696\n",
      "[1284/1762] D loss: 1.3913, G loss: 0.7422\n",
      "[1364/1762] D loss: 1.3875, G loss: 0.6401\n",
      "[1444/1762] D loss: 1.3988, G loss: 0.6724\n",
      "[1524/1762] D loss: 1.3879, G loss: 0.6562\n",
      "[1604/1762] D loss: 1.0766, G loss: 1.1330\n",
      "[1684/1762] D loss: 1.3873, G loss: 0.6782\n",
      "[1762/1762] D loss: 1.3707, G loss: 0.6208\n",
      "train error: \n",
      " D loss: 1.291971, G loss: 0.795888, D accuracy: 56.2%, cell accuracy: 99.8%, board accuracy: 81.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.267010, G loss: 0.843417, D accuracy: 57.3%, cell accuracy: 99.8%, board accuracy: 79.3% \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3917, G loss: 0.6569\n",
      "[84/1762] D loss: 1.3884, G loss: 0.6599\n",
      "[164/1762] D loss: 1.3907, G loss: 0.7590\n",
      "[244/1762] D loss: 1.3931, G loss: 0.7078\n",
      "[324/1762] D loss: 1.0825, G loss: 1.0594\n",
      "[404/1762] D loss: 1.3883, G loss: 0.6817\n",
      "[484/1762] D loss: 1.3893, G loss: 0.7016\n",
      "[564/1762] D loss: 1.0656, G loss: 1.1888\n",
      "[644/1762] D loss: 1.0655, G loss: 1.3650\n",
      "[724/1762] D loss: 1.0593, G loss: 1.1849\n",
      "[804/1762] D loss: 1.0594, G loss: 1.2682\n",
      "[884/1762] D loss: 1.3883, G loss: 0.7229\n",
      "[964/1762] D loss: 1.3888, G loss: 0.7037\n",
      "[1044/1762] D loss: 1.3934, G loss: 0.7114\n",
      "[1124/1762] D loss: 1.0690, G loss: 1.1156\n",
      "[1204/1762] D loss: 1.4262, G loss: 0.7078\n",
      "[1284/1762] D loss: 1.0059, G loss: 1.7100\n",
      "[1364/1762] D loss: 1.3899, G loss: 0.7118\n",
      "[1444/1762] D loss: 1.3908, G loss: 0.6949\n",
      "[1524/1762] D loss: 1.0637, G loss: 1.1561\n",
      "[1604/1762] D loss: 1.3926, G loss: 0.7469\n",
      "[1684/1762] D loss: 1.3169, G loss: 1.2764\n",
      "[1762/1762] D loss: 1.3830, G loss: 0.6578\n",
      "train error: \n",
      " D loss: 1.282655, G loss: 0.862449, D accuracy: 56.9%, cell accuracy: 99.8%, board accuracy: 79.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.258648, G loss: 0.909856, D accuracy: 58.3%, cell accuracy: 99.7%, board accuracy: 78.2% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3930, G loss: 0.6185\n",
      "[84/1762] D loss: 1.3890, G loss: 0.6231\n",
      "[164/1762] D loss: 1.3825, G loss: 0.6278\n",
      "[244/1762] D loss: 1.3724, G loss: 0.6323\n",
      "[324/1762] D loss: 1.3598, G loss: 0.6380\n",
      "[404/1762] D loss: 1.3482, G loss: 0.6442\n",
      "[484/1762] D loss: 1.3293, G loss: 0.6596\n",
      "[564/1762] D loss: 1.3386, G loss: 0.6665\n",
      "[644/1762] D loss: 1.2952, G loss: 0.6905\n",
      "[724/1762] D loss: 1.2451, G loss: 0.7252\n",
      "[804/1762] D loss: 1.2423, G loss: 0.7832\n",
      "[884/1762] D loss: 1.0943, G loss: 0.8283\n",
      "[964/1762] D loss: 1.0920, G loss: 0.9061\n",
      "[1044/1762] D loss: 1.0091, G loss: 0.9412\n",
      "[1124/1762] D loss: 1.1016, G loss: 0.9021\n",
      "[1204/1762] D loss: 0.7174, G loss: 1.1811\n",
      "[1284/1762] D loss: 0.8333, G loss: 1.1092\n",
      "[1364/1762] D loss: 0.8403, G loss: 1.3567\n",
      "[1444/1762] D loss: 1.1659, G loss: 0.7354\n",
      "[1524/1762] D loss: 1.0397, G loss: 0.7800\n",
      "[1604/1762] D loss: 0.4310, G loss: 1.8300\n",
      "[1684/1762] D loss: 0.7990, G loss: 1.2913\n",
      "[1762/1762] D loss: 1.1960, G loss: 0.7322\n",
      "train error: \n",
      " D loss: 0.907852, G loss: 1.200486, D accuracy: 87.4%, cell accuracy: 93.7%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.892388, G loss: 1.218917, D accuracy: 88.3%, cell accuracy: 93.6%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2830, G loss: 0.8173\n",
      "[84/1762] D loss: 1.1296, G loss: 0.8557\n",
      "[164/1762] D loss: 1.2795, G loss: 0.9037\n",
      "[244/1762] D loss: 1.1074, G loss: 0.7878\n",
      "[324/1762] D loss: 0.7524, G loss: 1.6786\n",
      "[404/1762] D loss: 1.0897, G loss: 0.7404\n",
      "[484/1762] D loss: 0.9878, G loss: 0.7899\n",
      "[564/1762] D loss: 1.0785, G loss: 1.1883\n",
      "[644/1762] D loss: 0.8037, G loss: 0.8017\n",
      "[724/1762] D loss: 0.3313, G loss: 2.0656\n",
      "[804/1762] D loss: 0.8787, G loss: 1.4946\n",
      "[884/1762] D loss: 0.8465, G loss: 0.8813\n",
      "[964/1762] D loss: 1.1420, G loss: 0.9719\n",
      "[1044/1762] D loss: 1.2570, G loss: 0.5965\n",
      "[1124/1762] D loss: 1.3564, G loss: 0.8483\n",
      "[1204/1762] D loss: 1.2810, G loss: 0.8700\n",
      "[1284/1762] D loss: 1.3671, G loss: 0.7485\n",
      "[1364/1762] D loss: 1.3235, G loss: 1.3107\n",
      "[1444/1762] D loss: 1.2264, G loss: 1.2267\n",
      "[1524/1762] D loss: 1.2516, G loss: 0.8950\n",
      "[1604/1762] D loss: 1.1533, G loss: 0.6803\n",
      "[1684/1762] D loss: 1.0766, G loss: 0.8366\n",
      "[1762/1762] D loss: 1.4107, G loss: 0.7583\n",
      "train error: \n",
      " D loss: 1.198543, G loss: 0.894307, D accuracy: 75.7%, cell accuracy: 96.3%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.220415, G loss: 0.865850, D accuracy: 74.0%, cell accuracy: 96.3%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1540, G loss: 0.7500\n",
      "[84/1762] D loss: 1.0540, G loss: 1.1850\n",
      "[164/1762] D loss: 1.0573, G loss: 1.1996\n",
      "[244/1762] D loss: 1.2047, G loss: 0.8893\n",
      "[324/1762] D loss: 1.0452, G loss: 1.2230\n",
      "[404/1762] D loss: 0.9940, G loss: 0.9103\n",
      "[484/1762] D loss: 0.8578, G loss: 0.9097\n",
      "[564/1762] D loss: 0.9536, G loss: 0.9440\n",
      "[644/1762] D loss: 0.7250, G loss: 1.4357\n",
      "[724/1762] D loss: 0.9040, G loss: 1.0200\n",
      "[804/1762] D loss: 0.8249, G loss: 1.3775\n",
      "[884/1762] D loss: 0.7995, G loss: 0.9930\n",
      "[964/1762] D loss: 1.0308, G loss: 1.6028\n",
      "[1044/1762] D loss: 0.8138, G loss: 1.6258\n",
      "[1124/1762] D loss: 0.9636, G loss: 1.0455\n",
      "[1204/1762] D loss: 1.0794, G loss: 1.0477\n",
      "[1284/1762] D loss: 1.6248, G loss: 0.5537\n",
      "[1364/1762] D loss: 1.4893, G loss: 0.7216\n",
      "[1444/1762] D loss: 0.8540, G loss: 1.0932\n",
      "[1524/1762] D loss: 1.4565, G loss: 0.6395\n",
      "[1604/1762] D loss: 1.1267, G loss: 0.7346\n",
      "[1684/1762] D loss: 0.8589, G loss: 1.2462\n",
      "[1762/1762] D loss: 0.6780, G loss: 1.9026\n",
      "train error: \n",
      " D loss: 1.018163, G loss: 1.293606, D accuracy: 81.9%, cell accuracy: 95.0%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.052789, G loss: 1.239191, D accuracy: 79.3%, cell accuracy: 95.1%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.7693, G loss: 1.5270\n",
      "[84/1762] D loss: 0.7900, G loss: 1.4356\n",
      "[164/1762] D loss: 0.9996, G loss: 1.1454\n",
      "[244/1762] D loss: 0.9445, G loss: 0.8567\n",
      "[324/1762] D loss: 1.0072, G loss: 0.9144\n",
      "[404/1762] D loss: 0.9063, G loss: 0.8941\n",
      "[484/1762] D loss: 1.2836, G loss: 1.0506\n",
      "[564/1762] D loss: 1.0785, G loss: 1.0917\n",
      "[644/1762] D loss: 0.8433, G loss: 0.9851\n",
      "[724/1762] D loss: 0.7006, G loss: 1.2089\n",
      "[804/1762] D loss: 0.8448, G loss: 1.0134\n",
      "[884/1762] D loss: 1.1900, G loss: 0.7812\n",
      "[964/1762] D loss: 1.2672, G loss: 1.3597\n",
      "[1044/1762] D loss: 0.8565, G loss: 1.0336\n",
      "[1124/1762] D loss: 1.0958, G loss: 1.1892\n",
      "[1204/1762] D loss: 1.2567, G loss: 0.9306\n",
      "[1284/1762] D loss: 1.4515, G loss: 0.7798\n",
      "[1364/1762] D loss: 1.6153, G loss: 0.8788\n",
      "[1444/1762] D loss: 1.2255, G loss: 0.6897\n",
      "[1524/1762] D loss: 1.3509, G loss: 0.9073\n",
      "[1604/1762] D loss: 1.0603, G loss: 0.7686\n",
      "[1684/1762] D loss: 0.9820, G loss: 1.0132\n",
      "[1762/1762] D loss: 0.9858, G loss: 0.8893\n",
      "train error: \n",
      " D loss: 1.015082, G loss: 1.024624, D accuracy: 78.5%, cell accuracy: 95.5%, board accuracy: 1.9% \n",
      "\n",
      "test error: \n",
      " D loss: 0.996418, G loss: 1.026425, D accuracy: 78.1%, cell accuracy: 95.3%, board accuracy: 2.0% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9067, G loss: 1.2732\n",
      "[84/1762] D loss: 1.0682, G loss: 0.8470\n",
      "[164/1762] D loss: 0.6106, G loss: 2.0257\n",
      "[244/1762] D loss: 1.1537, G loss: 1.1574\n",
      "[324/1762] D loss: 1.0874, G loss: 0.8014\n",
      "[404/1762] D loss: 0.5101, G loss: 1.5456\n",
      "[484/1762] D loss: 1.1262, G loss: 0.7277\n",
      "[564/1762] D loss: 0.8530, G loss: 1.5010\n",
      "[644/1762] D loss: 1.2521, G loss: 1.2301\n",
      "[724/1762] D loss: 0.7836, G loss: 1.3522\n",
      "[804/1762] D loss: 1.1230, G loss: 1.0336\n",
      "[884/1762] D loss: 0.8404, G loss: 1.2137\n",
      "[964/1762] D loss: 0.7884, G loss: 1.2137\n",
      "[1044/1762] D loss: 0.7946, G loss: 1.6908\n",
      "[1124/1762] D loss: 1.5679, G loss: 0.5439\n",
      "[1204/1762] D loss: 0.9173, G loss: 1.3580\n",
      "[1284/1762] D loss: 0.9373, G loss: 1.7278\n",
      "[1364/1762] D loss: 0.9225, G loss: 1.1061\n",
      "[1444/1762] D loss: 0.7457, G loss: 2.1348\n",
      "[1524/1762] D loss: 0.7930, G loss: 1.6757\n",
      "[1604/1762] D loss: 1.0421, G loss: 1.1762\n",
      "[1684/1762] D loss: 0.3674, G loss: 2.3062\n",
      "[1762/1762] D loss: 1.1670, G loss: 1.1241\n",
      "train error: \n",
      " D loss: 0.905031, G loss: 1.426783, D accuracy: 80.1%, cell accuracy: 96.3%, board accuracy: 1.3% \n",
      "\n",
      "test error: \n",
      " D loss: 0.891678, G loss: 1.411509, D accuracy: 81.4%, cell accuracy: 96.1%, board accuracy: 0.5% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9251, G loss: 1.2522\n",
      "[84/1762] D loss: 0.8172, G loss: 1.7558\n",
      "[164/1762] D loss: 1.0820, G loss: 1.9960\n",
      "[244/1762] D loss: 0.9616, G loss: 1.0249\n",
      "[324/1762] D loss: 0.8458, G loss: 1.6146\n",
      "[404/1762] D loss: 0.7070, G loss: 1.3620\n",
      "[484/1762] D loss: 1.0869, G loss: 0.8266\n",
      "[564/1762] D loss: 0.3223, G loss: 2.3525\n",
      "[644/1762] D loss: 0.8036, G loss: 1.8585\n",
      "[724/1762] D loss: 0.9520, G loss: 0.8869\n",
      "[804/1762] D loss: 0.4928, G loss: 2.4525\n",
      "[884/1762] D loss: 0.7064, G loss: 1.6578\n",
      "[964/1762] D loss: 1.1632, G loss: 1.3592\n",
      "[1044/1762] D loss: 0.9713, G loss: 1.1663\n",
      "[1124/1762] D loss: 0.8896, G loss: 1.4392\n",
      "[1204/1762] D loss: 0.6547, G loss: 1.5238\n",
      "[1284/1762] D loss: 0.4618, G loss: 2.1809\n",
      "[1364/1762] D loss: 0.8346, G loss: 1.0874\n",
      "[1444/1762] D loss: 1.1327, G loss: 1.5060\n",
      "[1524/1762] D loss: 1.3153, G loss: 0.8250\n",
      "[1604/1762] D loss: 0.8889, G loss: 1.3117\n",
      "[1684/1762] D loss: 1.3398, G loss: 0.9790\n",
      "[1762/1762] D loss: 1.1544, G loss: 1.1132\n",
      "train error: \n",
      " D loss: 1.294832, G loss: 0.927609, D accuracy: 65.1%, cell accuracy: 98.5%, board accuracy: 17.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.313222, G loss: 0.917150, D accuracy: 65.7%, cell accuracy: 98.3%, board accuracy: 14.5% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9660, G loss: 1.0908\n",
      "[84/1762] D loss: 1.6249, G loss: 0.8053\n",
      "[164/1762] D loss: 1.4061, G loss: 0.6621\n",
      "[244/1762] D loss: 1.6362, G loss: 1.0362\n",
      "[324/1762] D loss: 1.4411, G loss: 0.5551\n",
      "[404/1762] D loss: 1.2102, G loss: 0.9863\n",
      "[484/1762] D loss: 1.3718, G loss: 0.8043\n",
      "[564/1762] D loss: 1.3510, G loss: 0.8320\n",
      "[644/1762] D loss: 1.5073, G loss: 0.6894\n",
      "[724/1762] D loss: 1.3908, G loss: 0.6085\n",
      "[804/1762] D loss: 1.1792, G loss: 0.9315\n",
      "[884/1762] D loss: 1.2789, G loss: 0.8403\n",
      "[964/1762] D loss: 1.4956, G loss: 0.4611\n",
      "[1044/1762] D loss: 1.3336, G loss: 0.9557\n",
      "[1124/1762] D loss: 1.3004, G loss: 0.7789\n",
      "[1204/1762] D loss: 1.4231, G loss: 0.6657\n",
      "[1284/1762] D loss: 1.3509, G loss: 0.9810\n",
      "[1364/1762] D loss: 1.4257, G loss: 0.7324\n",
      "[1444/1762] D loss: 1.3987, G loss: 0.7915\n",
      "[1524/1762] D loss: 1.5886, G loss: 0.5449\n",
      "[1604/1762] D loss: 1.3737, G loss: 0.8737\n",
      "[1684/1762] D loss: 1.3114, G loss: 0.8437\n",
      "[1762/1762] D loss: 1.4269, G loss: 1.0778\n",
      "train error: \n",
      " D loss: 1.397730, G loss: 0.783384, D accuracy: 55.3%, cell accuracy: 99.2%, board accuracy: 40.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.404994, G loss: 0.772120, D accuracy: 56.0%, cell accuracy: 99.1%, board accuracy: 34.5% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4699, G loss: 0.8254\n",
      "[84/1762] D loss: 1.2486, G loss: 1.0786\n",
      "[164/1762] D loss: 1.4425, G loss: 0.6296\n",
      "[244/1762] D loss: 1.5465, G loss: 0.5562\n",
      "[324/1762] D loss: 1.2892, G loss: 0.8209\n",
      "[404/1762] D loss: 1.3764, G loss: 0.5844\n",
      "[484/1762] D loss: 1.3816, G loss: 0.9333\n",
      "[564/1762] D loss: 1.2391, G loss: 0.9243\n",
      "[644/1762] D loss: 1.2204, G loss: 0.8241\n",
      "[724/1762] D loss: 1.4570, G loss: 0.5175\n",
      "[804/1762] D loss: 1.4883, G loss: 0.6857\n",
      "[884/1762] D loss: 1.6556, G loss: 0.7847\n",
      "[964/1762] D loss: 1.3966, G loss: 0.7095\n",
      "[1044/1762] D loss: 1.4420, G loss: 0.7152\n",
      "[1124/1762] D loss: 1.5686, G loss: 0.7634\n",
      "[1204/1762] D loss: 1.4810, G loss: 0.4454\n",
      "[1284/1762] D loss: 1.4372, G loss: 0.7806\n",
      "[1364/1762] D loss: 1.2756, G loss: 0.6092\n",
      "[1444/1762] D loss: 1.3119, G loss: 0.6839\n",
      "[1524/1762] D loss: 1.2556, G loss: 0.8955\n",
      "[1604/1762] D loss: 1.3089, G loss: 0.8162\n",
      "[1684/1762] D loss: 1.4168, G loss: 0.8031\n",
      "[1762/1762] D loss: 1.2934, G loss: 0.5441\n",
      "train error: \n",
      " D loss: 1.364500, G loss: 0.730394, D accuracy: 56.4%, cell accuracy: 99.3%, board accuracy: 44.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.364626, G loss: 0.725782, D accuracy: 57.8%, cell accuracy: 99.2%, board accuracy: 40.0% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2660, G loss: 0.6613\n",
      "[84/1762] D loss: 1.3758, G loss: 0.7238\n",
      "[164/1762] D loss: 1.4194, G loss: 0.5735\n",
      "[244/1762] D loss: 1.1935, G loss: 0.9544\n",
      "[324/1762] D loss: 1.2101, G loss: 0.9143\n",
      "[404/1762] D loss: 1.5501, G loss: 0.8771\n",
      "[484/1762] D loss: 1.4695, G loss: 0.6195\n",
      "[564/1762] D loss: 1.4073, G loss: 0.5442\n",
      "[644/1762] D loss: 1.3314, G loss: 1.0060\n",
      "[724/1762] D loss: 1.3920, G loss: 0.7983\n",
      "[804/1762] D loss: 1.3668, G loss: 0.8277\n",
      "[884/1762] D loss: 1.4942, G loss: 1.0289\n",
      "[964/1762] D loss: 1.1428, G loss: 0.8884\n",
      "[1044/1762] D loss: 1.4219, G loss: 0.7759\n",
      "[1124/1762] D loss: 1.3329, G loss: 0.8455\n",
      "[1204/1762] D loss: 1.4249, G loss: 0.5237\n",
      "[1284/1762] D loss: 1.4952, G loss: 0.6663\n",
      "[1364/1762] D loss: 1.1930, G loss: 0.7087\n",
      "[1444/1762] D loss: 1.0242, G loss: 1.2057\n",
      "[1524/1762] D loss: 1.3436, G loss: 0.6429\n",
      "[1604/1762] D loss: 1.1996, G loss: 0.8931\n",
      "[1684/1762] D loss: 1.2273, G loss: 0.7525\n",
      "[1762/1762] D loss: 1.4821, G loss: 1.0875\n",
      "train error: \n",
      " D loss: 1.357332, G loss: 0.945747, D accuracy: 58.4%, cell accuracy: 99.3%, board accuracy: 45.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.349444, G loss: 0.940650, D accuracy: 59.3%, cell accuracy: 99.2%, board accuracy: 40.2% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0639, G loss: 1.1318\n",
      "[84/1762] D loss: 1.3506, G loss: 0.6443\n",
      "[164/1762] D loss: 1.2454, G loss: 1.1296\n",
      "[244/1762] D loss: 1.3427, G loss: 1.1175\n",
      "[324/1762] D loss: 1.4117, G loss: 0.6081\n",
      "[404/1762] D loss: 1.4094, G loss: 0.6590\n",
      "[484/1762] D loss: 1.3163, G loss: 0.8529\n",
      "[564/1762] D loss: 1.5205, G loss: 0.7081\n",
      "[644/1762] D loss: 1.3370, G loss: 0.9244\n",
      "[724/1762] D loss: 1.3832, G loss: 0.6194\n",
      "[804/1762] D loss: 1.4336, G loss: 0.5703\n",
      "[884/1762] D loss: 1.2024, G loss: 0.6568\n",
      "[964/1762] D loss: 1.2287, G loss: 0.8394\n",
      "[1044/1762] D loss: 1.4334, G loss: 0.5721\n",
      "[1124/1762] D loss: 1.2425, G loss: 0.9037\n",
      "[1204/1762] D loss: 1.2698, G loss: 0.8155\n",
      "[1284/1762] D loss: 1.2167, G loss: 0.7934\n",
      "[1364/1762] D loss: 1.4088, G loss: 0.7664\n",
      "[1444/1762] D loss: 1.4718, G loss: 0.5900\n",
      "[1524/1762] D loss: 1.3105, G loss: 1.0169\n",
      "[1604/1762] D loss: 1.2269, G loss: 0.9089\n",
      "[1684/1762] D loss: 1.3275, G loss: 0.8631\n",
      "[1762/1762] D loss: 1.3780, G loss: 0.6162\n",
      "train error: \n",
      " D loss: 1.316873, G loss: 0.808246, D accuracy: 60.9%, cell accuracy: 99.1%, board accuracy: 17.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.309097, G loss: 0.810598, D accuracy: 61.8%, cell accuracy: 99.0%, board accuracy: 17.5% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4077, G loss: 0.7246\n",
      "[84/1762] D loss: 1.4195, G loss: 0.5832\n",
      "[164/1762] D loss: 1.5339, G loss: 0.8646\n",
      "[244/1762] D loss: 1.3978, G loss: 0.8377\n",
      "[324/1762] D loss: 1.3288, G loss: 0.5539\n",
      "[404/1762] D loss: 1.1075, G loss: 0.8459\n",
      "[484/1762] D loss: 1.2415, G loss: 0.8707\n",
      "[564/1762] D loss: 1.1552, G loss: 1.0127\n",
      "[644/1762] D loss: 1.2629, G loss: 0.7885\n",
      "[724/1762] D loss: 1.1734, G loss: 1.1080\n",
      "[804/1762] D loss: 1.5521, G loss: 0.9796\n",
      "[884/1762] D loss: 1.2194, G loss: 0.7665\n",
      "[964/1762] D loss: 1.2593, G loss: 0.8578\n",
      "[1044/1762] D loss: 1.2329, G loss: 0.7333\n",
      "[1124/1762] D loss: 1.4309, G loss: 0.6344\n",
      "[1204/1762] D loss: 1.4045, G loss: 0.7757\n",
      "[1284/1762] D loss: 1.4011, G loss: 0.7926\n",
      "[1364/1762] D loss: 1.5310, G loss: 0.8558\n",
      "[1444/1762] D loss: 1.3838, G loss: 0.6565\n",
      "[1524/1762] D loss: 1.2396, G loss: 0.7824\n",
      "[1604/1762] D loss: 1.3530, G loss: 0.7121\n",
      "[1684/1762] D loss: 1.4809, G loss: 0.9320\n",
      "[1762/1762] D loss: 1.3770, G loss: 0.7962\n",
      "train error: \n",
      " D loss: 1.409304, G loss: 0.767487, D accuracy: 52.8%, cell accuracy: 99.6%, board accuracy: 62.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.411586, G loss: 0.757120, D accuracy: 52.8%, cell accuracy: 99.5%, board accuracy: 61.1% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4071, G loss: 0.6258\n",
      "[84/1762] D loss: 1.3957, G loss: 0.6847\n",
      "[164/1762] D loss: 1.3537, G loss: 0.7476\n",
      "[244/1762] D loss: 1.3996, G loss: 0.7702\n",
      "[324/1762] D loss: 1.2332, G loss: 0.8507\n",
      "[404/1762] D loss: 1.4172, G loss: 0.7360\n",
      "[484/1762] D loss: 1.4394, G loss: 0.8709\n",
      "[564/1762] D loss: 1.4990, G loss: 0.7686\n",
      "[644/1762] D loss: 1.3608, G loss: 0.6187\n",
      "[724/1762] D loss: 1.3984, G loss: 0.7094\n",
      "[804/1762] D loss: 1.3016, G loss: 0.6129\n",
      "[884/1762] D loss: 1.4215, G loss: 0.6991\n",
      "[964/1762] D loss: 1.3691, G loss: 0.8087\n",
      "[1044/1762] D loss: 1.4354, G loss: 0.5376\n",
      "[1124/1762] D loss: 1.3655, G loss: 0.8130\n",
      "[1204/1762] D loss: 1.4308, G loss: 0.7018\n",
      "[1284/1762] D loss: 1.4767, G loss: 0.7043\n",
      "[1364/1762] D loss: 1.4224, G loss: 0.5470\n",
      "[1444/1762] D loss: 1.4399, G loss: 0.9822\n",
      "[1524/1762] D loss: 1.3981, G loss: 0.6091\n",
      "[1604/1762] D loss: 1.3125, G loss: 0.6314\n",
      "[1684/1762] D loss: 1.3743, G loss: 0.7367\n",
      "[1762/1762] D loss: 1.3840, G loss: 0.7907\n",
      "train error: \n",
      " D loss: 1.397243, G loss: 0.775905, D accuracy: 51.6%, cell accuracy: 99.7%, board accuracy: 78.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.397445, G loss: 0.764535, D accuracy: 51.9%, cell accuracy: 99.7%, board accuracy: 78.4% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4248, G loss: 0.7134\n",
      "[84/1762] D loss: 1.4316, G loss: 0.8806\n",
      "[164/1762] D loss: 1.3713, G loss: 0.6537\n",
      "[244/1762] D loss: 1.3767, G loss: 0.7253\n",
      "[324/1762] D loss: 1.2891, G loss: 0.8736\n",
      "[404/1762] D loss: 1.4476, G loss: 0.6764\n",
      "[484/1762] D loss: 1.3908, G loss: 0.6845\n",
      "[564/1762] D loss: 1.3238, G loss: 0.8273\n",
      "[644/1762] D loss: 1.2891, G loss: 0.9692\n",
      "[724/1762] D loss: 1.3839, G loss: 0.6317\n",
      "[804/1762] D loss: 1.3951, G loss: 0.7020\n",
      "[884/1762] D loss: 1.4070, G loss: 0.7831\n",
      "[964/1762] D loss: 1.4384, G loss: 0.7718\n",
      "[1044/1762] D loss: 1.3695, G loss: 0.7550\n",
      "[1124/1762] D loss: 1.3985, G loss: 0.6202\n",
      "[1204/1762] D loss: 1.3707, G loss: 0.6222\n",
      "[1284/1762] D loss: 1.1806, G loss: 0.8105\n",
      "[1364/1762] D loss: 1.4063, G loss: 0.6679\n",
      "[1444/1762] D loss: 1.3949, G loss: 0.6487\n",
      "[1524/1762] D loss: 1.1745, G loss: 0.9348\n",
      "[1604/1762] D loss: 1.4036, G loss: 0.7768\n",
      "[1684/1762] D loss: 1.4013, G loss: 0.7371\n",
      "[1762/1762] D loss: 1.2800, G loss: 0.7584\n",
      "train error: \n",
      " D loss: 1.384909, G loss: 0.710849, D accuracy: 52.2%, cell accuracy: 99.7%, board accuracy: 82.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.387006, G loss: 0.700020, D accuracy: 52.6%, cell accuracy: 99.7%, board accuracy: 81.4% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4258, G loss: 0.5686\n",
      "[84/1762] D loss: 1.3597, G loss: 0.6640\n",
      "[164/1762] D loss: 1.3816, G loss: 0.7523\n",
      "[244/1762] D loss: 1.3884, G loss: 0.6990\n",
      "[324/1762] D loss: 1.3843, G loss: 0.7184\n",
      "[404/1762] D loss: 1.3958, G loss: 0.6489\n",
      "[484/1762] D loss: 1.3380, G loss: 0.6657\n",
      "[564/1762] D loss: 1.3911, G loss: 0.6516\n",
      "[644/1762] D loss: 1.4102, G loss: 0.7124\n",
      "[724/1762] D loss: 1.3839, G loss: 0.7381\n",
      "[804/1762] D loss: 1.4056, G loss: 0.7476\n",
      "[884/1762] D loss: 1.3222, G loss: 0.8574\n",
      "[964/1762] D loss: 1.3862, G loss: 0.8007\n",
      "[1044/1762] D loss: 1.3735, G loss: 0.6019\n",
      "[1124/1762] D loss: 1.3892, G loss: 0.5996\n",
      "[1204/1762] D loss: 1.3160, G loss: 0.7612\n",
      "[1284/1762] D loss: 1.3027, G loss: 0.7773\n",
      "[1364/1762] D loss: 1.3022, G loss: 0.8018\n",
      "[1444/1762] D loss: 1.4242, G loss: 0.5758\n",
      "[1524/1762] D loss: 1.4238, G loss: 0.6030\n",
      "[1604/1762] D loss: 1.3532, G loss: 0.6641\n",
      "[1684/1762] D loss: 1.4120, G loss: 0.7949\n",
      "[1762/1762] D loss: 1.3703, G loss: 0.6548\n",
      "train error: \n",
      " D loss: 1.383767, G loss: 0.668914, D accuracy: 52.0%, cell accuracy: 99.7%, board accuracy: 82.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.387813, G loss: 0.658053, D accuracy: 53.3%, cell accuracy: 99.7%, board accuracy: 81.1% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3974, G loss: 0.6166\n",
      "[84/1762] D loss: 1.4012, G loss: 0.6685\n",
      "[164/1762] D loss: 1.2630, G loss: 0.7228\n",
      "[244/1762] D loss: 1.3909, G loss: 0.6367\n",
      "[324/1762] D loss: 1.4006, G loss: 0.6446\n",
      "[404/1762] D loss: 1.3653, G loss: 0.7735\n",
      "[484/1762] D loss: 1.4434, G loss: 0.8589\n",
      "[564/1762] D loss: 1.3032, G loss: 0.7989\n",
      "[644/1762] D loss: 1.3624, G loss: 0.6674\n",
      "[724/1762] D loss: 1.3866, G loss: 0.7800\n",
      "[804/1762] D loss: 1.3879, G loss: 0.7250\n",
      "[884/1762] D loss: 1.3639, G loss: 0.7685\n",
      "[964/1762] D loss: 1.3793, G loss: 0.6905\n",
      "[1044/1762] D loss: 1.3751, G loss: 0.6672\n",
      "[1124/1762] D loss: 1.3996, G loss: 0.6617\n",
      "[1204/1762] D loss: 1.3717, G loss: 0.7116\n",
      "[1284/1762] D loss: 1.4099, G loss: 0.8081\n",
      "[1364/1762] D loss: 1.3948, G loss: 0.7542\n",
      "[1444/1762] D loss: 1.3529, G loss: 0.6440\n",
      "[1524/1762] D loss: 1.3808, G loss: 0.6354\n",
      "[1604/1762] D loss: 1.3938, G loss: 0.6657\n",
      "[1684/1762] D loss: 1.3258, G loss: 0.7965\n",
      "[1762/1762] D loss: 1.2899, G loss: 0.6247\n",
      "train error: \n",
      " D loss: 1.376812, G loss: 0.710909, D accuracy: 52.6%, cell accuracy: 99.7%, board accuracy: 82.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.377351, G loss: 0.703930, D accuracy: 53.0%, cell accuracy: 99.7%, board accuracy: 81.6% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3924, G loss: 0.6400\n",
      "[84/1762] D loss: 1.3906, G loss: 0.6917\n",
      "[164/1762] D loss: 1.2589, G loss: 0.8008\n",
      "[244/1762] D loss: 1.4125, G loss: 0.6846\n",
      "[324/1762] D loss: 1.3895, G loss: 0.6932\n",
      "[404/1762] D loss: 1.3997, G loss: 0.6671\n",
      "[484/1762] D loss: 1.3155, G loss: 0.7840\n",
      "[564/1762] D loss: 1.4183, G loss: 0.6410\n",
      "[644/1762] D loss: 1.3954, G loss: 0.7367\n",
      "[724/1762] D loss: 1.4031, G loss: 0.8099\n",
      "[804/1762] D loss: 1.4049, G loss: 0.7961\n",
      "[884/1762] D loss: 1.2987, G loss: 0.7808\n",
      "[964/1762] D loss: 1.4145, G loss: 0.5862\n",
      "[1044/1762] D loss: 1.3851, G loss: 0.7130\n",
      "[1124/1762] D loss: 1.4064, G loss: 0.7739\n",
      "[1204/1762] D loss: 1.3910, G loss: 0.6778\n",
      "[1284/1762] D loss: 1.4035, G loss: 0.7095\n",
      "[1364/1762] D loss: 1.3824, G loss: 0.7109\n",
      "[1444/1762] D loss: 1.3882, G loss: 0.6715\n",
      "[1524/1762] D loss: 1.2256, G loss: 1.0128\n",
      "[1604/1762] D loss: 1.3904, G loss: 0.6480\n",
      "[1684/1762] D loss: 1.3920, G loss: 0.6748\n",
      "[1762/1762] D loss: 1.3970, G loss: 0.8304\n",
      "train error: \n",
      " D loss: 1.375742, G loss: 0.740585, D accuracy: 52.4%, cell accuracy: 99.8%, board accuracy: 84.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.374659, G loss: 0.732883, D accuracy: 53.0%, cell accuracy: 99.7%, board accuracy: 82.5% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3501, G loss: 0.7494\n",
      "[84/1762] D loss: 1.3716, G loss: 0.7478\n",
      "[164/1762] D loss: 1.4024, G loss: 0.7658\n",
      "[244/1762] D loss: 1.3942, G loss: 0.7285\n",
      "[324/1762] D loss: 1.4085, G loss: 0.7920\n",
      "[404/1762] D loss: 1.3791, G loss: 0.6551\n",
      "[484/1762] D loss: 1.3896, G loss: 0.6297\n",
      "[564/1762] D loss: 1.3923, G loss: 0.7048\n",
      "[644/1762] D loss: 1.2611, G loss: 0.8411\n",
      "[724/1762] D loss: 1.4086, G loss: 0.6668\n",
      "[804/1762] D loss: 1.3793, G loss: 0.7791\n",
      "[884/1762] D loss: 1.3464, G loss: 0.7694\n",
      "[964/1762] D loss: 1.3889, G loss: 0.6842\n",
      "[1044/1762] D loss: 1.4011, G loss: 0.7299\n",
      "[1124/1762] D loss: 1.3990, G loss: 0.6343\n",
      "[1204/1762] D loss: 1.3113, G loss: 0.8763\n",
      "[1284/1762] D loss: 1.3869, G loss: 0.6843\n",
      "[1364/1762] D loss: 1.3544, G loss: 0.6715\n",
      "[1444/1762] D loss: 1.4068, G loss: 0.5637\n",
      "[1524/1762] D loss: 1.3661, G loss: 0.6775\n",
      "[1604/1762] D loss: 1.3762, G loss: 0.8242\n",
      "[1684/1762] D loss: 1.3921, G loss: 0.7448\n",
      "[1762/1762] D loss: 1.4008, G loss: 0.7609\n",
      "train error: \n",
      " D loss: 1.374666, G loss: 0.664100, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 84.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.374156, G loss: 0.657136, D accuracy: 53.8%, cell accuracy: 99.7%, board accuracy: 81.1% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3226, G loss: 0.6536\n",
      "[84/1762] D loss: 1.3930, G loss: 0.6449\n",
      "[164/1762] D loss: 1.3931, G loss: 0.6926\n",
      "[244/1762] D loss: 1.4026, G loss: 0.6551\n",
      "[324/1762] D loss: 1.3198, G loss: 0.9529\n",
      "[404/1762] D loss: 1.3201, G loss: 0.6333\n",
      "[484/1762] D loss: 1.3603, G loss: 0.7395\n",
      "[564/1762] D loss: 1.3390, G loss: 0.7522\n",
      "[644/1762] D loss: 1.3746, G loss: 0.7442\n",
      "[724/1762] D loss: 1.3909, G loss: 0.6797\n",
      "[804/1762] D loss: 1.3946, G loss: 0.7657\n",
      "[884/1762] D loss: 1.3794, G loss: 0.7695\n",
      "[964/1762] D loss: 1.3971, G loss: 0.6503\n",
      "[1044/1762] D loss: 1.4461, G loss: 0.7742\n",
      "[1124/1762] D loss: 1.3422, G loss: 0.7537\n",
      "[1204/1762] D loss: 1.4026, G loss: 0.8577\n",
      "[1284/1762] D loss: 1.3547, G loss: 0.8150\n",
      "[1364/1762] D loss: 1.3871, G loss: 0.6641\n",
      "[1444/1762] D loss: 1.3812, G loss: 0.7060\n",
      "[1524/1762] D loss: 1.4892, G loss: 0.9050\n",
      "[1604/1762] D loss: 1.3914, G loss: 0.6130\n",
      "[1684/1762] D loss: 1.3870, G loss: 0.6158\n",
      "[1762/1762] D loss: 1.4195, G loss: 0.5749\n",
      "train error: \n",
      " D loss: 1.375167, G loss: 0.690484, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 84.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.372131, G loss: 0.685574, D accuracy: 53.8%, cell accuracy: 99.7%, board accuracy: 81.8% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4223, G loss: 0.6106\n",
      "[84/1762] D loss: 1.4036, G loss: 0.8129\n",
      "[164/1762] D loss: 1.3942, G loss: 0.6433\n",
      "[244/1762] D loss: 1.3905, G loss: 0.6322\n",
      "[324/1762] D loss: 1.4135, G loss: 0.6434\n",
      "[404/1762] D loss: 1.3189, G loss: 0.6672\n",
      "[484/1762] D loss: 1.3868, G loss: 0.6655\n",
      "[564/1762] D loss: 1.3551, G loss: 0.7322\n",
      "[644/1762] D loss: 1.3869, G loss: 0.7216\n",
      "[724/1762] D loss: 1.3742, G loss: 0.8114\n",
      "[804/1762] D loss: 1.3885, G loss: 0.6751\n",
      "[884/1762] D loss: 1.3090, G loss: 0.6764\n",
      "[964/1762] D loss: 1.3452, G loss: 0.7007\n",
      "[1044/1762] D loss: 1.2851, G loss: 0.8351\n",
      "[1124/1762] D loss: 1.3628, G loss: 0.6888\n",
      "[1204/1762] D loss: 1.3025, G loss: 0.9010\n",
      "[1284/1762] D loss: 1.3907, G loss: 0.7184\n",
      "[1364/1762] D loss: 1.3144, G loss: 0.8775\n",
      "[1444/1762] D loss: 1.3624, G loss: 0.7140\n",
      "[1524/1762] D loss: 1.3894, G loss: 0.7577\n",
      "[1604/1762] D loss: 1.3951, G loss: 0.6742\n",
      "[1684/1762] D loss: 1.3880, G loss: 0.6998\n",
      "[1762/1762] D loss: 1.4053, G loss: 0.8064\n",
      "train error: \n",
      " D loss: 1.372091, G loss: 0.689817, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 85.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.369789, G loss: 0.684107, D accuracy: 53.8%, cell accuracy: 99.7%, board accuracy: 82.5% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3924, G loss: 0.6375\n",
      "[84/1762] D loss: 1.3938, G loss: 0.6100\n",
      "[164/1762] D loss: 1.3348, G loss: 0.7458\n",
      "[244/1762] D loss: 1.3906, G loss: 0.6919\n",
      "[324/1762] D loss: 1.3662, G loss: 0.7190\n",
      "[404/1762] D loss: 1.2773, G loss: 0.7173\n",
      "[484/1762] D loss: 1.3876, G loss: 0.6456\n",
      "[564/1762] D loss: 1.3882, G loss: 0.6771\n",
      "[644/1762] D loss: 1.4016, G loss: 0.6919\n",
      "[724/1762] D loss: 1.3896, G loss: 0.6428\n",
      "[804/1762] D loss: 1.4031, G loss: 0.7315\n",
      "[884/1762] D loss: 1.4079, G loss: 0.6394\n",
      "[964/1762] D loss: 1.3267, G loss: 0.6651\n",
      "[1044/1762] D loss: 1.3962, G loss: 0.7007\n",
      "[1124/1762] D loss: 1.4272, G loss: 0.5696\n",
      "[1204/1762] D loss: 1.2906, G loss: 0.8099\n",
      "[1284/1762] D loss: 1.3999, G loss: 0.6534\n",
      "[1364/1762] D loss: 1.3904, G loss: 0.7076\n",
      "[1444/1762] D loss: 1.3897, G loss: 0.6582\n",
      "[1524/1762] D loss: 1.3479, G loss: 0.8609\n",
      "[1604/1762] D loss: 1.2799, G loss: 0.7252\n",
      "[1684/1762] D loss: 1.3915, G loss: 0.7754\n",
      "[1762/1762] D loss: 1.3876, G loss: 0.6670\n",
      "train error: \n",
      " D loss: 1.372022, G loss: 0.727638, D accuracy: 53.1%, cell accuracy: 99.8%, board accuracy: 87.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.368173, G loss: 0.721848, D accuracy: 53.1%, cell accuracy: 99.8%, board accuracy: 85.0% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3877, G loss: 0.6524\n",
      "[84/1762] D loss: 1.3847, G loss: 0.6326\n",
      "[164/1762] D loss: 1.3902, G loss: 0.7337\n",
      "[244/1762] D loss: 1.3874, G loss: 0.6747\n",
      "[324/1762] D loss: 1.3310, G loss: 0.7258\n",
      "[404/1762] D loss: 1.3981, G loss: 0.8033\n",
      "[484/1762] D loss: 1.3944, G loss: 0.6521\n",
      "[564/1762] D loss: 1.3959, G loss: 0.7325\n",
      "[644/1762] D loss: 1.2831, G loss: 0.7373\n",
      "[724/1762] D loss: 1.3268, G loss: 0.7506\n",
      "[804/1762] D loss: 1.3868, G loss: 0.7109\n",
      "[884/1762] D loss: 1.3906, G loss: 0.6981\n",
      "[964/1762] D loss: 1.4528, G loss: 0.7457\n",
      "[1044/1762] D loss: 1.2713, G loss: 0.9309\n",
      "[1124/1762] D loss: 1.3535, G loss: 0.7649\n",
      "[1204/1762] D loss: 1.4005, G loss: 0.7003\n",
      "[1284/1762] D loss: 1.3792, G loss: 0.7330\n",
      "[1364/1762] D loss: 1.3633, G loss: 0.7797\n",
      "[1444/1762] D loss: 1.3272, G loss: 0.7607\n",
      "[1524/1762] D loss: 1.3834, G loss: 0.8068\n",
      "[1604/1762] D loss: 1.3664, G loss: 0.6581\n",
      "[1684/1762] D loss: 1.2894, G loss: 0.7889\n",
      "[1762/1762] D loss: 1.4007, G loss: 0.7566\n",
      "train error: \n",
      " D loss: 1.370088, G loss: 0.731621, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 84.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.366379, G loss: 0.726145, D accuracy: 53.4%, cell accuracy: 99.7%, board accuracy: 79.5% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4018, G loss: 0.7519\n",
      "[84/1762] D loss: 1.3939, G loss: 0.7636\n",
      "[164/1762] D loss: 1.3945, G loss: 0.7012\n",
      "[244/1762] D loss: 1.3232, G loss: 0.8544\n",
      "[324/1762] D loss: 1.3637, G loss: 0.7678\n",
      "[404/1762] D loss: 1.4041, G loss: 0.6177\n",
      "[484/1762] D loss: 1.3890, G loss: 0.6932\n",
      "[564/1762] D loss: 1.3884, G loss: 0.6875\n",
      "[644/1762] D loss: 1.4590, G loss: 0.7527\n",
      "[724/1762] D loss: 1.3977, G loss: 0.6243\n",
      "[804/1762] D loss: 1.4041, G loss: 0.7880\n",
      "[884/1762] D loss: 1.4102, G loss: 0.6448\n",
      "[964/1762] D loss: 1.3130, G loss: 0.7530\n",
      "[1044/1762] D loss: 1.4084, G loss: 0.8100\n",
      "[1124/1762] D loss: 1.2965, G loss: 0.7160\n",
      "[1204/1762] D loss: 1.4142, G loss: 0.7056\n",
      "[1284/1762] D loss: 1.3958, G loss: 0.7224\n",
      "[1364/1762] D loss: 1.3227, G loss: 0.9389\n",
      "[1444/1762] D loss: 1.3981, G loss: 0.6422\n",
      "[1524/1762] D loss: 1.3161, G loss: 0.7850\n",
      "[1604/1762] D loss: 1.3901, G loss: 0.6813\n",
      "[1684/1762] D loss: 1.3952, G loss: 0.7659\n",
      "[1762/1762] D loss: 1.3909, G loss: 0.6801\n",
      "train error: \n",
      " D loss: 1.360101, G loss: 0.701856, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 82.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.354547, G loss: 0.699721, D accuracy: 55.7%, cell accuracy: 99.7%, board accuracy: 76.8% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2985, G loss: 0.7367\n",
      "[84/1762] D loss: 1.4282, G loss: 0.8255\n",
      "[164/1762] D loss: 1.3869, G loss: 0.7760\n",
      "[244/1762] D loss: 1.3108, G loss: 0.8268\n",
      "[324/1762] D loss: 1.3906, G loss: 0.7375\n",
      "[404/1762] D loss: 1.3872, G loss: 0.6709\n",
      "[484/1762] D loss: 1.2108, G loss: 0.8240\n",
      "[564/1762] D loss: 1.3012, G loss: 0.7780\n",
      "[644/1762] D loss: 1.3049, G loss: 0.6846\n",
      "[724/1762] D loss: 1.3572, G loss: 0.8119\n",
      "[804/1762] D loss: 1.3733, G loss: 0.7611\n",
      "[884/1762] D loss: 1.3948, G loss: 0.6657\n",
      "[964/1762] D loss: 1.3931, G loss: 0.7173\n",
      "[1044/1762] D loss: 1.3061, G loss: 0.8746\n",
      "[1124/1762] D loss: 1.3989, G loss: 0.6592\n",
      "[1204/1762] D loss: 1.3329, G loss: 0.8852\n",
      "[1284/1762] D loss: 1.3060, G loss: 0.6379\n",
      "[1364/1762] D loss: 1.3930, G loss: 0.7523\n",
      "[1444/1762] D loss: 1.3029, G loss: 0.7376\n",
      "[1524/1762] D loss: 1.3976, G loss: 0.6274\n",
      "[1604/1762] D loss: 1.3885, G loss: 0.7266\n",
      "[1684/1762] D loss: 1.3088, G loss: 0.8330\n",
      "[1762/1762] D loss: 1.3884, G loss: 0.6818\n",
      "train error: \n",
      " D loss: 1.360837, G loss: 0.726709, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 85.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.353938, G loss: 0.724948, D accuracy: 54.2%, cell accuracy: 99.7%, board accuracy: 80.0% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3733, G loss: 0.8199\n",
      "[84/1762] D loss: 1.3048, G loss: 0.8283\n",
      "[164/1762] D loss: 1.3251, G loss: 0.7636\n",
      "[244/1762] D loss: 1.4079, G loss: 0.6902\n",
      "[324/1762] D loss: 1.3936, G loss: 0.7104\n",
      "[404/1762] D loss: 1.3923, G loss: 0.6738\n",
      "[484/1762] D loss: 1.3776, G loss: 0.7235\n",
      "[564/1762] D loss: 1.7913, G loss: 0.5075\n",
      "[644/1762] D loss: 1.5442, G loss: 0.5996\n",
      "[724/1762] D loss: 1.4996, G loss: 0.7704\n",
      "[804/1762] D loss: 1.4020, G loss: 0.7093\n",
      "[884/1762] D loss: 1.3054, G loss: 0.7277\n",
      "[964/1762] D loss: 1.3347, G loss: 0.6523\n",
      "[1044/1762] D loss: 1.3962, G loss: 0.8183\n",
      "[1124/1762] D loss: 1.3903, G loss: 0.7599\n",
      "[1204/1762] D loss: 1.4162, G loss: 0.5625\n",
      "[1284/1762] D loss: 1.3782, G loss: 0.6702\n",
      "[1364/1762] D loss: 1.3665, G loss: 0.7253\n",
      "[1444/1762] D loss: 1.3885, G loss: 0.6615\n",
      "[1524/1762] D loss: 1.4135, G loss: 0.6014\n",
      "[1604/1762] D loss: 1.3777, G loss: 0.7976\n",
      "[1684/1762] D loss: 1.3841, G loss: 0.6614\n",
      "[1762/1762] D loss: 1.3899, G loss: 0.7580\n",
      "train error: \n",
      " D loss: 1.386290, G loss: 0.651665, D accuracy: 52.2%, cell accuracy: 99.8%, board accuracy: 85.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.384182, G loss: 0.651720, D accuracy: 52.8%, cell accuracy: 99.8%, board accuracy: 82.0% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3341, G loss: 0.7235\n",
      "[84/1762] D loss: 1.4069, G loss: 0.6729\n",
      "[164/1762] D loss: 1.3542, G loss: 0.7232\n",
      "[244/1762] D loss: 1.3948, G loss: 0.7120\n",
      "[324/1762] D loss: 1.3723, G loss: 0.6878\n",
      "[404/1762] D loss: 1.4308, G loss: 0.8288\n",
      "[484/1762] D loss: 1.3670, G loss: 0.6667\n",
      "[564/1762] D loss: 1.3982, G loss: 0.7828\n",
      "[644/1762] D loss: 1.3209, G loss: 0.6554\n",
      "[724/1762] D loss: 1.3517, G loss: 0.7046\n",
      "[804/1762] D loss: 1.3416, G loss: 0.7443\n",
      "[884/1762] D loss: 1.2948, G loss: 0.7779\n",
      "[964/1762] D loss: 1.3880, G loss: 0.6919\n",
      "[1044/1762] D loss: 1.3901, G loss: 0.6944\n",
      "[1124/1762] D loss: 1.3969, G loss: 0.8027\n",
      "[1204/1762] D loss: 1.3866, G loss: 0.6598\n",
      "[1284/1762] D loss: 1.3898, G loss: 0.7226\n",
      "[1364/1762] D loss: 1.3886, G loss: 0.7005\n",
      "[1444/1762] D loss: 1.3773, G loss: 0.7723\n",
      "[1524/1762] D loss: 1.3944, G loss: 0.7439\n",
      "[1604/1762] D loss: 1.3929, G loss: 0.7321\n",
      "[1684/1762] D loss: 1.3969, G loss: 0.6323\n",
      "[1762/1762] D loss: 1.4048, G loss: 0.6307\n",
      "train error: \n",
      " D loss: 1.366702, G loss: 0.722459, D accuracy: 55.8%, cell accuracy: 99.2%, board accuracy: 42.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.361919, G loss: 0.722877, D accuracy: 55.5%, cell accuracy: 99.2%, board accuracy: 38.6% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3679, G loss: 0.6888\n",
      "[84/1762] D loss: 1.3944, G loss: 0.7518\n",
      "[164/1762] D loss: 1.3974, G loss: 0.7652\n",
      "[244/1762] D loss: 1.3321, G loss: 0.7284\n",
      "[324/1762] D loss: 1.3887, G loss: 0.7391\n",
      "[404/1762] D loss: 1.3920, G loss: 0.6451\n",
      "[484/1762] D loss: 1.4065, G loss: 0.7328\n",
      "[564/1762] D loss: 1.4022, G loss: 0.7016\n",
      "[644/1762] D loss: 1.1864, G loss: 0.7237\n",
      "[724/1762] D loss: 1.3877, G loss: 0.6938\n",
      "[804/1762] D loss: 1.3209, G loss: 0.7823\n",
      "[884/1762] D loss: 1.4053, G loss: 0.6376\n",
      "[964/1762] D loss: 1.3899, G loss: 0.7021\n",
      "[1044/1762] D loss: 1.2843, G loss: 0.7822\n",
      "[1124/1762] D loss: 1.3917, G loss: 0.6930\n",
      "[1204/1762] D loss: 1.3949, G loss: 0.7543\n",
      "[1284/1762] D loss: 1.4181, G loss: 0.6554\n",
      "[1364/1762] D loss: 1.3984, G loss: 0.6983\n",
      "[1444/1762] D loss: 1.3813, G loss: 0.6186\n",
      "[1524/1762] D loss: 1.4027, G loss: 0.7428\n",
      "[1604/1762] D loss: 1.2458, G loss: 0.7267\n",
      "[1684/1762] D loss: 1.4493, G loss: 0.6974\n",
      "[1762/1762] D loss: 1.4170, G loss: 0.6017\n",
      "train error: \n",
      " D loss: 1.371247, G loss: 0.711233, D accuracy: 53.1%, cell accuracy: 99.6%, board accuracy: 65.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.366857, G loss: 0.711382, D accuracy: 53.1%, cell accuracy: 99.6%, board accuracy: 63.0% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4294, G loss: 0.6438\n",
      "[84/1762] D loss: 1.3896, G loss: 0.7315\n",
      "[164/1762] D loss: 1.3930, G loss: 0.6989\n",
      "[244/1762] D loss: 1.3162, G loss: 0.7040\n",
      "[324/1762] D loss: 1.3948, G loss: 0.6821\n",
      "[404/1762] D loss: 1.3332, G loss: 0.6991\n",
      "[484/1762] D loss: 1.3878, G loss: 0.7182\n",
      "[564/1762] D loss: 1.3411, G loss: 0.6595\n",
      "[644/1762] D loss: 1.4065, G loss: 0.6277\n",
      "[724/1762] D loss: 1.3886, G loss: 0.7227\n",
      "[804/1762] D loss: 1.4338, G loss: 0.6491\n",
      "[884/1762] D loss: 1.3933, G loss: 0.8142\n",
      "[964/1762] D loss: 1.3992, G loss: 0.6621\n",
      "[1044/1762] D loss: 1.3873, G loss: 0.7082\n",
      "[1124/1762] D loss: 1.3898, G loss: 0.6707\n",
      "[1204/1762] D loss: 1.4195, G loss: 0.8534\n",
      "[1284/1762] D loss: 1.4074, G loss: 0.7082\n",
      "[1364/1762] D loss: 1.3978, G loss: 0.8150\n",
      "[1444/1762] D loss: 1.3441, G loss: 0.7489\n",
      "[1524/1762] D loss: 1.2916, G loss: 0.7679\n",
      "[1604/1762] D loss: 1.3890, G loss: 0.6678\n",
      "[1684/1762] D loss: 1.4029, G loss: 0.7748\n",
      "[1762/1762] D loss: 1.3915, G loss: 0.6434\n",
      "train error: \n",
      " D loss: 1.364042, G loss: 0.684121, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 86.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.359338, G loss: 0.679447, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 82.7% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3916, G loss: 0.6508\n",
      "[84/1762] D loss: 1.2877, G loss: 0.7056\n",
      "[164/1762] D loss: 1.3872, G loss: 0.6435\n",
      "[244/1762] D loss: 1.3853, G loss: 0.7125\n",
      "[324/1762] D loss: 1.3898, G loss: 0.7564\n",
      "[404/1762] D loss: 1.3940, G loss: 0.7194\n",
      "[484/1762] D loss: 1.3913, G loss: 0.6218\n",
      "[564/1762] D loss: 1.3897, G loss: 0.6816\n",
      "[644/1762] D loss: 1.3943, G loss: 0.7001\n",
      "[724/1762] D loss: 1.3888, G loss: 0.6569\n",
      "[804/1762] D loss: 1.4418, G loss: 0.6312\n",
      "[884/1762] D loss: 1.3964, G loss: 0.8040\n",
      "[964/1762] D loss: 1.3876, G loss: 0.6870\n",
      "[1044/1762] D loss: 1.2690, G loss: 0.8092\n",
      "[1124/1762] D loss: 1.1512, G loss: 0.8416\n",
      "[1204/1762] D loss: 1.4082, G loss: 0.7301\n",
      "[1284/1762] D loss: 1.2551, G loss: 0.7678\n",
      "[1364/1762] D loss: 1.3915, G loss: 0.7549\n",
      "[1444/1762] D loss: 1.4022, G loss: 0.7077\n",
      "[1524/1762] D loss: 1.3898, G loss: 0.6645\n",
      "[1604/1762] D loss: 1.3875, G loss: 0.6680\n",
      "[1684/1762] D loss: 1.2955, G loss: 0.9024\n",
      "[1762/1762] D loss: 1.3955, G loss: 0.6775\n",
      "train error: \n",
      " D loss: 1.352966, G loss: 0.719328, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 84.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.345671, G loss: 0.717346, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 80.5% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3898, G loss: 0.7266\n",
      "[84/1762] D loss: 1.2446, G loss: 0.8733\n",
      "[164/1762] D loss: 1.3890, G loss: 0.6804\n",
      "[244/1762] D loss: 1.4201, G loss: 0.6136\n",
      "[324/1762] D loss: 1.3992, G loss: 0.6446\n",
      "[404/1762] D loss: 1.3935, G loss: 0.6212\n",
      "[484/1762] D loss: 1.4135, G loss: 0.7554\n",
      "[564/1762] D loss: 1.3926, G loss: 0.7595\n",
      "[644/1762] D loss: 1.2357, G loss: 0.7682\n",
      "[724/1762] D loss: 1.3779, G loss: 0.6860\n",
      "[804/1762] D loss: 1.3891, G loss: 0.7343\n",
      "[884/1762] D loss: 1.3925, G loss: 0.6351\n",
      "[964/1762] D loss: 1.2115, G loss: 0.8067\n",
      "[1044/1762] D loss: 1.3947, G loss: 0.7067\n",
      "[1124/1762] D loss: 1.3734, G loss: 0.6517\n",
      "[1204/1762] D loss: 1.5637, G loss: 0.7215\n",
      "[1284/1762] D loss: 1.4322, G loss: 0.7646\n",
      "[1364/1762] D loss: 1.3340, G loss: 0.6924\n",
      "[1444/1762] D loss: 1.3214, G loss: 0.8032\n",
      "[1524/1762] D loss: 1.3099, G loss: 0.8384\n",
      "[1604/1762] D loss: 1.2924, G loss: 0.7912\n",
      "[1684/1762] D loss: 1.3885, G loss: 0.7134\n",
      "[1762/1762] D loss: 1.3911, G loss: 0.6690\n",
      "train error: \n",
      " D loss: 1.364406, G loss: 0.712075, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 87.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.360893, G loss: 0.706465, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 84.8% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3919, G loss: 0.7131\n",
      "[84/1762] D loss: 1.3892, G loss: 0.7164\n",
      "[164/1762] D loss: 1.3888, G loss: 0.6827\n",
      "[244/1762] D loss: 1.2869, G loss: 0.7908\n",
      "[324/1762] D loss: 1.2928, G loss: 0.8858\n",
      "[404/1762] D loss: 1.3622, G loss: 0.7825\n",
      "[484/1762] D loss: 1.3835, G loss: 0.6982\n",
      "[564/1762] D loss: 1.4021, G loss: 0.7868\n",
      "[644/1762] D loss: 1.3977, G loss: 0.6570\n",
      "[724/1762] D loss: 1.3936, G loss: 0.7336\n",
      "[804/1762] D loss: 1.2555, G loss: 0.7717\n",
      "[884/1762] D loss: 1.3893, G loss: 0.6945\n",
      "[964/1762] D loss: 1.3909, G loss: 0.7307\n",
      "[1044/1762] D loss: 1.4032, G loss: 0.7055\n",
      "[1124/1762] D loss: 1.2486, G loss: 0.7344\n",
      "[1204/1762] D loss: 1.2620, G loss: 0.7394\n",
      "[1284/1762] D loss: 1.3899, G loss: 0.6884\n",
      "[1364/1762] D loss: 1.2720, G loss: 0.7131\n",
      "[1444/1762] D loss: 1.2527, G loss: 0.8550\n",
      "[1524/1762] D loss: 1.2435, G loss: 0.7279\n",
      "[1604/1762] D loss: 1.2465, G loss: 0.9273\n",
      "[1684/1762] D loss: 1.3999, G loss: 0.7737\n",
      "[1762/1762] D loss: 1.3913, G loss: 0.6282\n",
      "train error: \n",
      " D loss: 1.365420, G loss: 0.616128, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 88.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.360242, G loss: 0.614051, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4086, G loss: 0.6218\n",
      "[84/1762] D loss: 1.3912, G loss: 0.7550\n",
      "[164/1762] D loss: 1.3909, G loss: 0.6638\n",
      "[244/1762] D loss: 1.2370, G loss: 0.7512\n",
      "[324/1762] D loss: 1.2328, G loss: 0.8434\n",
      "[404/1762] D loss: 1.4028, G loss: 0.7752\n",
      "[484/1762] D loss: 1.3918, G loss: 0.6542\n",
      "[564/1762] D loss: 1.0903, G loss: 0.9389\n",
      "[644/1762] D loss: 1.4175, G loss: 0.7259\n",
      "[724/1762] D loss: 1.3931, G loss: 0.6421\n",
      "[804/1762] D loss: 1.3868, G loss: 0.7377\n",
      "[884/1762] D loss: 1.3896, G loss: 0.6690\n",
      "[964/1762] D loss: 1.4337, G loss: 0.6121\n",
      "[1044/1762] D loss: 1.4056, G loss: 0.7727\n",
      "[1124/1762] D loss: 1.2078, G loss: 0.8012\n",
      "[1204/1762] D loss: 1.2097, G loss: 0.7824\n",
      "[1284/1762] D loss: 1.3940, G loss: 0.6918\n",
      "[1364/1762] D loss: 1.4087, G loss: 0.6445\n",
      "[1444/1762] D loss: 1.3902, G loss: 0.7017\n",
      "[1524/1762] D loss: 1.3860, G loss: 0.6905\n",
      "[1604/1762] D loss: 1.2889, G loss: 0.6800\n",
      "[1684/1762] D loss: 1.3507, G loss: 0.6588\n",
      "[1762/1762] D loss: 1.3973, G loss: 0.7393\n",
      "train error: \n",
      " D loss: 1.339616, G loss: 0.743021, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 84.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.332267, G loss: 0.738321, D accuracy: 54.4%, cell accuracy: 99.7%, board accuracy: 80.0% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3897, G loss: 0.6548\n",
      "[84/1762] D loss: 1.4073, G loss: 0.7357\n",
      "[164/1762] D loss: 1.8023, G loss: 0.5619\n",
      "[244/1762] D loss: 1.4016, G loss: 0.8153\n",
      "[324/1762] D loss: 1.3529, G loss: 0.7590\n",
      "[404/1762] D loss: 1.3814, G loss: 0.7473\n",
      "[484/1762] D loss: 1.3933, G loss: 0.7339\n",
      "[564/1762] D loss: 1.3961, G loss: 0.6621\n",
      "[644/1762] D loss: 1.3970, G loss: 0.7183\n",
      "[724/1762] D loss: 1.3154, G loss: 0.6825\n",
      "[804/1762] D loss: 1.3059, G loss: 0.6195\n",
      "[884/1762] D loss: 1.3748, G loss: 0.7354\n",
      "[964/1762] D loss: 1.3100, G loss: 0.7301\n",
      "[1044/1762] D loss: 1.3927, G loss: 0.6673\n",
      "[1124/1762] D loss: 1.3580, G loss: 0.6423\n",
      "[1204/1762] D loss: 1.4491, G loss: 0.6940\n",
      "[1284/1762] D loss: 1.3849, G loss: 0.7068\n",
      "[1364/1762] D loss: 1.3004, G loss: 0.6921\n",
      "[1444/1762] D loss: 1.3704, G loss: 0.7846\n",
      "[1524/1762] D loss: 1.3667, G loss: 0.6356\n",
      "[1604/1762] D loss: 1.4074, G loss: 0.7142\n",
      "[1684/1762] D loss: 1.3370, G loss: 0.6550\n",
      "[1762/1762] D loss: 1.4152, G loss: 0.7707\n",
      "train error: \n",
      " D loss: 1.410941, G loss: 0.807329, D accuracy: 50.1%, cell accuracy: 99.4%, board accuracy: 3.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.407245, G loss: 0.799387, D accuracy: 50.3%, cell accuracy: 99.3%, board accuracy: 3.6% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4718, G loss: 0.8057\n",
      "[84/1762] D loss: 1.3483, G loss: 0.6813\n",
      "[164/1762] D loss: 1.4098, G loss: 0.6628\n",
      "[244/1762] D loss: 1.3849, G loss: 0.7129\n",
      "[324/1762] D loss: 1.4142, G loss: 0.7223\n",
      "[404/1762] D loss: 1.4055, G loss: 0.6025\n",
      "[484/1762] D loss: 1.3930, G loss: 0.6499\n",
      "[564/1762] D loss: 1.3698, G loss: 0.7177\n",
      "[644/1762] D loss: 1.3921, G loss: 0.6150\n",
      "[724/1762] D loss: 1.3977, G loss: 0.6882\n",
      "[804/1762] D loss: 1.3867, G loss: 0.6967\n",
      "[884/1762] D loss: 1.4194, G loss: 0.6888\n",
      "[964/1762] D loss: 1.3880, G loss: 0.6680\n",
      "[1044/1762] D loss: 1.3996, G loss: 0.6524\n",
      "[1124/1762] D loss: 1.4568, G loss: 0.7513\n",
      "[1204/1762] D loss: 1.3941, G loss: 0.7512\n",
      "[1284/1762] D loss: 1.3733, G loss: 0.7101\n",
      "[1364/1762] D loss: 1.3493, G loss: 0.6114\n",
      "[1444/1762] D loss: 1.3900, G loss: 0.7438\n",
      "[1524/1762] D loss: 1.3861, G loss: 0.6927\n",
      "[1604/1762] D loss: 1.3099, G loss: 0.7047\n",
      "[1684/1762] D loss: 1.3386, G loss: 0.7817\n",
      "[1762/1762] D loss: 1.0275, G loss: 0.8558\n",
      "train error: \n",
      " D loss: 1.376504, G loss: 0.745437, D accuracy: 51.5%, cell accuracy: 99.7%, board accuracy: 76.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.372845, G loss: 0.738874, D accuracy: 53.0%, cell accuracy: 99.7%, board accuracy: 73.0% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2140, G loss: 0.8325\n",
      "[84/1762] D loss: 1.3319, G loss: 0.8245\n",
      "[164/1762] D loss: 1.3808, G loss: 0.7787\n",
      "[244/1762] D loss: 1.3901, G loss: 0.7139\n",
      "[324/1762] D loss: 1.4037, G loss: 0.6709\n",
      "[404/1762] D loss: 1.3897, G loss: 0.7061\n",
      "[484/1762] D loss: 1.3941, G loss: 0.7330\n",
      "[564/1762] D loss: 1.4150, G loss: 0.6917\n",
      "[644/1762] D loss: 1.4735, G loss: 0.6645\n",
      "[724/1762] D loss: 1.2833, G loss: 0.6860\n",
      "[804/1762] D loss: 1.3902, G loss: 0.6579\n",
      "[884/1762] D loss: 1.4358, G loss: 0.6487\n",
      "[964/1762] D loss: 1.3905, G loss: 0.6475\n",
      "[1044/1762] D loss: 1.3851, G loss: 0.7580\n",
      "[1124/1762] D loss: 1.4192, G loss: 0.6294\n",
      "[1204/1762] D loss: 1.2807, G loss: 0.7024\n",
      "[1284/1762] D loss: 1.2808, G loss: 0.6752\n",
      "[1364/1762] D loss: 1.4378, G loss: 0.6311\n",
      "[1444/1762] D loss: 1.4135, G loss: 0.6977\n",
      "[1524/1762] D loss: 1.2725, G loss: 0.7537\n",
      "[1604/1762] D loss: 1.3923, G loss: 0.7143\n",
      "[1684/1762] D loss: 1.2552, G loss: 0.7746\n",
      "[1762/1762] D loss: 1.3733, G loss: 0.6737\n",
      "train error: \n",
      " D loss: 1.372013, G loss: 0.644393, D accuracy: 52.6%, cell accuracy: 99.8%, board accuracy: 78.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.369578, G loss: 0.639798, D accuracy: 53.2%, cell accuracy: 99.7%, board accuracy: 73.9% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4273, G loss: 0.5837\n",
      "[84/1762] D loss: 1.4109, G loss: 0.8812\n",
      "[164/1762] D loss: 1.6089, G loss: 0.6094\n",
      "[244/1762] D loss: 1.4743, G loss: 0.7372\n",
      "[324/1762] D loss: 1.3855, G loss: 0.7174\n",
      "[404/1762] D loss: 1.2689, G loss: 0.7015\n",
      "[484/1762] D loss: 1.1852, G loss: 0.8560\n",
      "[564/1762] D loss: 1.3991, G loss: 0.6472\n",
      "[644/1762] D loss: 1.3759, G loss: 0.6236\n",
      "[724/1762] D loss: 1.3995, G loss: 0.6128\n",
      "[804/1762] D loss: 1.3895, G loss: 0.7198\n",
      "[884/1762] D loss: 1.4052, G loss: 0.8115\n",
      "[964/1762] D loss: 1.3875, G loss: 0.7061\n",
      "[1044/1762] D loss: 1.3857, G loss: 0.6672\n",
      "[1124/1762] D loss: 1.3870, G loss: 0.7126\n",
      "[1204/1762] D loss: 1.4244, G loss: 0.6796\n",
      "[1284/1762] D loss: 1.3901, G loss: 0.6579\n",
      "[1364/1762] D loss: 1.4189, G loss: 0.7069\n",
      "[1444/1762] D loss: 1.3877, G loss: 0.6793\n",
      "[1524/1762] D loss: 1.3911, G loss: 0.6572\n",
      "[1604/1762] D loss: 1.3915, G loss: 0.6401\n",
      "[1684/1762] D loss: 1.3889, G loss: 0.6581\n",
      "[1762/1762] D loss: 1.3891, G loss: 0.7408\n",
      "train error: \n",
      " D loss: 1.392164, G loss: 0.734277, D accuracy: 50.4%, cell accuracy: 99.8%, board accuracy: 90.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.394940, G loss: 0.732618, D accuracy: 50.1%, cell accuracy: 99.8%, board accuracy: 85.9% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3922, G loss: 0.7357\n",
      "[84/1762] D loss: 1.4073, G loss: 0.6709\n",
      "[164/1762] D loss: 1.3881, G loss: 0.7242\n",
      "[244/1762] D loss: 1.3871, G loss: 0.7212\n",
      "[324/1762] D loss: 1.3661, G loss: 0.6731\n",
      "[404/1762] D loss: 1.3885, G loss: 0.6844\n",
      "[484/1762] D loss: 1.3863, G loss: 0.6998\n",
      "[564/1762] D loss: 1.3877, G loss: 0.7289\n",
      "[644/1762] D loss: 1.3877, G loss: 0.7051\n",
      "[724/1762] D loss: 1.3867, G loss: 0.6981\n",
      "[804/1762] D loss: 1.3880, G loss: 0.6878\n",
      "[884/1762] D loss: 1.3872, G loss: 0.6911\n",
      "[964/1762] D loss: 1.3873, G loss: 0.7122\n",
      "[1044/1762] D loss: 1.3978, G loss: 0.6525\n",
      "[1124/1762] D loss: 1.3918, G loss: 0.6887\n",
      "[1204/1762] D loss: 1.3451, G loss: 0.6912\n",
      "[1284/1762] D loss: 1.3723, G loss: 0.6713\n",
      "[1364/1762] D loss: 1.3510, G loss: 0.7488\n",
      "[1444/1762] D loss: 1.3652, G loss: 0.6792\n",
      "[1524/1762] D loss: 1.3875, G loss: 0.6861\n",
      "[1604/1762] D loss: 1.3879, G loss: 0.6901\n",
      "[1684/1762] D loss: 1.3849, G loss: 0.6866\n",
      "[1762/1762] D loss: 1.3907, G loss: 0.6792\n",
      "train error: \n",
      " D loss: 1.379290, G loss: 0.705337, D accuracy: 52.8%, cell accuracy: 99.8%, board accuracy: 91.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.379098, G loss: 0.702562, D accuracy: 53.1%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3871, G loss: 0.7057\n",
      "[84/1762] D loss: 1.3894, G loss: 0.6626\n",
      "[164/1762] D loss: 1.3870, G loss: 0.7107\n",
      "[244/1762] D loss: 1.3869, G loss: 0.7061\n",
      "[324/1762] D loss: 1.3887, G loss: 0.6711\n",
      "[404/1762] D loss: 1.2038, G loss: 0.7819\n",
      "[484/1762] D loss: 1.4263, G loss: 0.7263\n",
      "[564/1762] D loss: 1.3903, G loss: 0.6416\n",
      "[644/1762] D loss: 1.3889, G loss: 0.6767\n",
      "[724/1762] D loss: 1.3341, G loss: 0.7923\n",
      "[804/1762] D loss: 1.3071, G loss: 0.6521\n",
      "[884/1762] D loss: 1.3707, G loss: 0.7384\n",
      "[964/1762] D loss: 1.3919, G loss: 0.6400\n",
      "[1044/1762] D loss: 1.3934, G loss: 0.6791\n",
      "[1124/1762] D loss: 1.4632, G loss: 0.6030\n",
      "[1204/1762] D loss: 1.3575, G loss: 0.5748\n",
      "[1284/1762] D loss: 1.3961, G loss: 0.6586\n",
      "[1364/1762] D loss: 1.3641, G loss: 0.7550\n",
      "[1444/1762] D loss: 1.3925, G loss: 0.7043\n",
      "[1524/1762] D loss: 1.3621, G loss: 0.6340\n",
      "[1604/1762] D loss: 1.3668, G loss: 0.6960\n",
      "[1684/1762] D loss: 1.4008, G loss: 0.6683\n",
      "[1762/1762] D loss: 1.3865, G loss: 0.6965\n",
      "train error: \n",
      " D loss: 1.377651, G loss: 0.678162, D accuracy: 52.4%, cell accuracy: 99.8%, board accuracy: 87.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.376275, G loss: 0.676839, D accuracy: 52.5%, cell accuracy: 99.8%, board accuracy: 85.2% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3804, G loss: 0.6785\n",
      "[84/1762] D loss: 1.4039, G loss: 0.6918\n",
      "[164/1762] D loss: 1.3152, G loss: 0.7328\n",
      "[244/1762] D loss: 1.3874, G loss: 0.7001\n",
      "[324/1762] D loss: 1.3873, G loss: 0.7027\n",
      "[404/1762] D loss: 1.4179, G loss: 0.6900\n",
      "[484/1762] D loss: 1.3868, G loss: 0.6804\n",
      "[564/1762] D loss: 1.3464, G loss: 0.7380\n",
      "[644/1762] D loss: 1.3886, G loss: 0.7131\n",
      "[724/1762] D loss: 1.3884, G loss: 0.6710\n",
      "[804/1762] D loss: 1.3206, G loss: 0.6851\n",
      "[884/1762] D loss: 1.3911, G loss: 0.7374\n",
      "[964/1762] D loss: 1.3881, G loss: 0.6805\n",
      "[1044/1762] D loss: 1.3872, G loss: 0.7162\n",
      "[1124/1762] D loss: 1.3925, G loss: 0.6945\n",
      "[1204/1762] D loss: 1.3869, G loss: 0.6926\n",
      "[1284/1762] D loss: 1.3873, G loss: 0.6891\n",
      "[1364/1762] D loss: 1.3962, G loss: 0.6860\n",
      "[1444/1762] D loss: 1.3879, G loss: 0.7068\n",
      "[1524/1762] D loss: 1.3882, G loss: 0.7164\n",
      "[1604/1762] D loss: 1.2845, G loss: 0.6826\n",
      "[1684/1762] D loss: 1.3888, G loss: 0.6639\n",
      "[1762/1762] D loss: 1.1469, G loss: 0.8354\n",
      "train error: \n",
      " D loss: 1.366248, G loss: 0.740343, D accuracy: 51.7%, cell accuracy: 99.8%, board accuracy: 82.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.360645, G loss: 0.737455, D accuracy: 52.6%, cell accuracy: 99.7%, board accuracy: 80.0% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4286, G loss: 0.7576\n",
      "[84/1762] D loss: 1.4008, G loss: 0.6267\n",
      "[164/1762] D loss: 1.2631, G loss: 0.7401\n",
      "[244/1762] D loss: 1.3933, G loss: 0.7022\n",
      "[324/1762] D loss: 1.1622, G loss: 0.8227\n",
      "[404/1762] D loss: 1.4130, G loss: 0.6678\n",
      "[484/1762] D loss: 1.2929, G loss: 0.7648\n",
      "[564/1762] D loss: 1.3970, G loss: 0.7536\n",
      "[644/1762] D loss: 1.3889, G loss: 0.6435\n",
      "[724/1762] D loss: 0.9810, G loss: 0.8683\n",
      "[804/1762] D loss: 1.2604, G loss: 0.7698\n",
      "[884/1762] D loss: 1.4021, G loss: 0.6893\n",
      "[964/1762] D loss: 1.2421, G loss: 0.7575\n",
      "[1044/1762] D loss: 1.3909, G loss: 0.6847\n",
      "[1124/1762] D loss: 1.4139, G loss: 0.7109\n",
      "[1204/1762] D loss: 1.3890, G loss: 0.6855\n",
      "[1284/1762] D loss: 1.3939, G loss: 0.7037\n",
      "[1364/1762] D loss: 1.3866, G loss: 0.6861\n",
      "[1444/1762] D loss: 1.3883, G loss: 0.6847\n",
      "[1524/1762] D loss: 1.2394, G loss: 0.7218\n",
      "[1604/1762] D loss: 1.2470, G loss: 0.7275\n",
      "[1684/1762] D loss: 1.3997, G loss: 0.7202\n",
      "[1762/1762] D loss: 1.3878, G loss: 0.7572\n",
      "train error: \n",
      " D loss: 1.350931, G loss: 0.747658, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 84.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.342258, G loss: 0.747808, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 80.9% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3972, G loss: 0.7386\n",
      "[84/1762] D loss: 1.4071, G loss: 0.5711\n",
      "[164/1762] D loss: 1.3863, G loss: 0.8646\n",
      "[244/1762] D loss: 1.3908, G loss: 0.6327\n",
      "[324/1762] D loss: 1.3885, G loss: 0.6936\n",
      "[404/1762] D loss: 1.4103, G loss: 0.6466\n",
      "[484/1762] D loss: 1.3959, G loss: 0.6471\n",
      "[564/1762] D loss: 1.3987, G loss: 0.7676\n",
      "[644/1762] D loss: 1.2228, G loss: 0.7488\n",
      "[724/1762] D loss: 1.3937, G loss: 0.7137\n",
      "[804/1762] D loss: 1.3986, G loss: 0.7656\n",
      "[884/1762] D loss: 1.3939, G loss: 0.6944\n",
      "[964/1762] D loss: 1.2109, G loss: 0.7725\n",
      "[1044/1762] D loss: 1.4008, G loss: 0.7234\n",
      "[1124/1762] D loss: 1.3909, G loss: 0.6979\n",
      "[1204/1762] D loss: 1.1790, G loss: 0.9028\n",
      "[1284/1762] D loss: 1.3803, G loss: 0.6829\n",
      "[1364/1762] D loss: 1.3849, G loss: 0.7261\n",
      "[1444/1762] D loss: 1.4023, G loss: 0.7588\n",
      "[1524/1762] D loss: 1.3931, G loss: 0.7370\n",
      "[1604/1762] D loss: 1.3873, G loss: 0.6640\n",
      "[1684/1762] D loss: 1.4141, G loss: 0.9189\n",
      "[1762/1762] D loss: 2.2459, G loss: 0.3611\n",
      "train error: \n",
      " D loss: 1.783082, G loss: 0.596959, D accuracy: 16.8%, cell accuracy: 98.2%, board accuracy: 11.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.761439, G loss: 0.601434, D accuracy: 18.2%, cell accuracy: 98.2%, board accuracy: 10.9% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.7733, G loss: 0.6918\n",
      "[84/1762] D loss: 1.4980, G loss: 0.8343\n",
      "[164/1762] D loss: 1.3354, G loss: 0.7620\n",
      "[244/1762] D loss: 1.3800, G loss: 0.6364\n",
      "[324/1762] D loss: 1.3897, G loss: 0.7692\n",
      "[404/1762] D loss: 1.3872, G loss: 0.6837\n",
      "[484/1762] D loss: 1.3821, G loss: 0.7345\n",
      "[564/1762] D loss: 1.3761, G loss: 0.7190\n",
      "[644/1762] D loss: 1.3148, G loss: 0.6952\n",
      "[724/1762] D loss: 1.4076, G loss: 0.5896\n",
      "[804/1762] D loss: 1.3283, G loss: 0.7418\n",
      "[884/1762] D loss: 1.3879, G loss: 0.6933\n",
      "[964/1762] D loss: 1.3082, G loss: 0.7068\n",
      "[1044/1762] D loss: 1.2550, G loss: 0.7424\n",
      "[1124/1762] D loss: 1.3889, G loss: 0.7464\n",
      "[1204/1762] D loss: 1.3891, G loss: 0.6730\n",
      "[1284/1762] D loss: 1.3936, G loss: 0.6532\n",
      "[1364/1762] D loss: 1.3880, G loss: 0.6845\n",
      "[1444/1762] D loss: 1.3880, G loss: 0.7057\n",
      "[1524/1762] D loss: 1.3942, G loss: 0.7660\n",
      "[1604/1762] D loss: 1.3896, G loss: 0.6536\n",
      "[1684/1762] D loss: 1.3874, G loss: 0.7035\n",
      "[1762/1762] D loss: 1.3938, G loss: 0.6785\n",
      "train error: \n",
      " D loss: 1.348226, G loss: 0.771260, D accuracy: 53.3%, cell accuracy: 99.9%, board accuracy: 90.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.339125, G loss: 0.771258, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4014, G loss: 0.7923\n",
      "[84/1762] D loss: 1.3989, G loss: 0.7407\n",
      "[164/1762] D loss: 1.3905, G loss: 0.6832\n",
      "[244/1762] D loss: 1.3879, G loss: 0.6973\n",
      "[324/1762] D loss: 1.4114, G loss: 0.7990\n",
      "[404/1762] D loss: 1.3123, G loss: 0.7869\n",
      "[484/1762] D loss: 1.3927, G loss: 0.6467\n",
      "[564/1762] D loss: 1.3910, G loss: 0.7742\n",
      "[644/1762] D loss: 1.4005, G loss: 0.5960\n",
      "[724/1762] D loss: 1.3900, G loss: 0.7594\n",
      "[804/1762] D loss: 1.3901, G loss: 0.6446\n",
      "[884/1762] D loss: 1.1649, G loss: 0.8685\n",
      "[964/1762] D loss: 1.4049, G loss: 0.8092\n",
      "[1044/1762] D loss: 1.3908, G loss: 0.6441\n",
      "[1124/1762] D loss: 1.2002, G loss: 0.8898\n",
      "[1204/1762] D loss: 0.9770, G loss: 0.8707\n",
      "[1284/1762] D loss: 1.3952, G loss: 0.6687\n",
      "[1364/1762] D loss: 1.3878, G loss: 0.6717\n",
      "[1444/1762] D loss: 1.3928, G loss: 0.6956\n",
      "[1524/1762] D loss: 1.3917, G loss: 0.6904\n",
      "[1604/1762] D loss: 1.1699, G loss: 0.8160\n",
      "[1684/1762] D loss: 1.3868, G loss: 0.6826\n",
      "[1762/1762] D loss: 1.3880, G loss: 0.7239\n",
      "train error: \n",
      " D loss: 1.334705, G loss: 0.709371, D accuracy: 53.6%, cell accuracy: 99.9%, board accuracy: 91.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.321837, G loss: 0.712656, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1894, G loss: 0.7481\n",
      "[84/1762] D loss: 1.3955, G loss: 0.7090\n",
      "[164/1762] D loss: 1.3903, G loss: 0.7260\n",
      "[244/1762] D loss: 1.1827, G loss: 0.8658\n",
      "[324/1762] D loss: 1.3918, G loss: 0.6616\n",
      "[404/1762] D loss: 1.1566, G loss: 0.8333\n",
      "[484/1762] D loss: 1.1679, G loss: 0.8775\n",
      "[564/1762] D loss: 1.3898, G loss: 0.7169\n",
      "[644/1762] D loss: 1.3356, G loss: 0.7691\n",
      "[724/1762] D loss: 1.1349, G loss: 0.9209\n",
      "[804/1762] D loss: 1.3278, G loss: 0.7438\n",
      "[884/1762] D loss: 1.4666, G loss: 0.8528\n",
      "[964/1762] D loss: 1.3372, G loss: 0.9711\n",
      "[1044/1762] D loss: 1.2699, G loss: 0.6648\n",
      "[1124/1762] D loss: 1.2565, G loss: 0.7195\n",
      "[1204/1762] D loss: 1.4001, G loss: 0.6729\n",
      "[1284/1762] D loss: 1.3813, G loss: 0.6584\n",
      "[1364/1762] D loss: 1.3944, G loss: 0.7329\n",
      "[1444/1762] D loss: 1.4043, G loss: 0.6573\n",
      "[1524/1762] D loss: 1.2735, G loss: 0.7518\n",
      "[1604/1762] D loss: 1.3972, G loss: 0.7765\n",
      "[1684/1762] D loss: 1.3935, G loss: 0.6820\n",
      "[1762/1762] D loss: 1.4050, G loss: 0.6986\n",
      "train error: \n",
      " D loss: 1.364284, G loss: 0.704609, D accuracy: 52.0%, cell accuracy: 99.8%, board accuracy: 83.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.361062, G loss: 0.713127, D accuracy: 52.0%, cell accuracy: 99.8%, board accuracy: 80.0% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3885, G loss: 0.6744\n",
      "[84/1762] D loss: 1.3906, G loss: 0.6903\n",
      "[164/1762] D loss: 1.3963, G loss: 0.7649\n",
      "[244/1762] D loss: 1.2662, G loss: 0.7377\n",
      "[324/1762] D loss: 1.1799, G loss: 0.7673\n",
      "[404/1762] D loss: 1.4032, G loss: 0.7315\n",
      "[484/1762] D loss: 1.3975, G loss: 0.6925\n",
      "[564/1762] D loss: 1.4435, G loss: 0.6512\n",
      "[644/1762] D loss: 1.4613, G loss: 0.6962\n",
      "[724/1762] D loss: 1.3321, G loss: 0.6632\n",
      "[804/1762] D loss: 1.3965, G loss: 0.6212\n",
      "[884/1762] D loss: 1.4013, G loss: 0.7744\n",
      "[964/1762] D loss: 1.3900, G loss: 0.7448\n",
      "[1044/1762] D loss: 1.4109, G loss: 0.7328\n",
      "[1124/1762] D loss: 1.3925, G loss: 0.7568\n",
      "[1204/1762] D loss: 1.4362, G loss: 0.7092\n",
      "[1284/1762] D loss: 1.3922, G loss: 0.7138\n",
      "[1364/1762] D loss: 1.3866, G loss: 0.6793\n",
      "[1444/1762] D loss: 1.3875, G loss: 0.6937\n",
      "[1524/1762] D loss: 1.3896, G loss: 0.7265\n",
      "[1604/1762] D loss: 1.3875, G loss: 0.6616\n",
      "[1684/1762] D loss: 1.3912, G loss: 0.7467\n",
      "[1762/1762] D loss: 1.3868, G loss: 0.6835\n",
      "train error: \n",
      " D loss: 1.355645, G loss: 0.729379, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 89.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.351074, G loss: 0.731426, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2967, G loss: 0.8494\n",
      "[84/1762] D loss: 1.4102, G loss: 0.6995\n",
      "[164/1762] D loss: 1.3830, G loss: 0.6790\n",
      "[244/1762] D loss: 1.3894, G loss: 0.7116\n",
      "[324/1762] D loss: 1.3884, G loss: 0.7596\n",
      "[404/1762] D loss: 1.4008, G loss: 0.7121\n",
      "[484/1762] D loss: 1.3966, G loss: 0.7155\n",
      "[564/1762] D loss: 1.3949, G loss: 0.7064\n",
      "[644/1762] D loss: 1.3867, G loss: 0.6975\n",
      "[724/1762] D loss: 1.3284, G loss: 0.8216\n",
      "[804/1762] D loss: 1.3876, G loss: 0.6929\n",
      "[884/1762] D loss: 1.3901, G loss: 0.6828\n",
      "[964/1762] D loss: 1.1665, G loss: 0.8438\n",
      "[1044/1762] D loss: 1.4011, G loss: 0.8054\n",
      "[1124/1762] D loss: 1.3995, G loss: 0.6450\n",
      "[1204/1762] D loss: 1.3898, G loss: 0.6789\n",
      "[1284/1762] D loss: 1.3934, G loss: 0.7978\n",
      "[1364/1762] D loss: 1.3777, G loss: 0.7899\n",
      "[1444/1762] D loss: 1.4023, G loss: 0.6227\n",
      "[1524/1762] D loss: 1.3940, G loss: 0.7934\n",
      "[1604/1762] D loss: 1.2387, G loss: 0.7932\n",
      "[1684/1762] D loss: 1.0009, G loss: 0.8820\n",
      "[1762/1762] D loss: 1.3892, G loss: 0.6862\n",
      "train error: \n",
      " D loss: 1.336911, G loss: 0.721309, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 84.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.326661, G loss: 0.724145, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 80.7% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3881, G loss: 0.7037\n",
      "[84/1762] D loss: 1.3939, G loss: 0.7452\n",
      "[164/1762] D loss: 1.3892, G loss: 0.6813\n",
      "[244/1762] D loss: 1.3898, G loss: 0.6972\n",
      "[324/1762] D loss: 1.3922, G loss: 0.6187\n",
      "[404/1762] D loss: 1.0162, G loss: 0.8545\n",
      "[484/1762] D loss: 1.3904, G loss: 0.7602\n",
      "[564/1762] D loss: 1.1651, G loss: 0.8249\n",
      "[644/1762] D loss: 1.3944, G loss: 0.7497\n",
      "[724/1762] D loss: 1.3964, G loss: 0.7046\n",
      "[804/1762] D loss: 1.2036, G loss: 0.7302\n",
      "[884/1762] D loss: 1.3931, G loss: 0.7110\n",
      "[964/1762] D loss: 1.3877, G loss: 0.6926\n",
      "[1044/1762] D loss: 1.1665, G loss: 0.9361\n",
      "[1124/1762] D loss: 1.3936, G loss: 0.7206\n",
      "[1204/1762] D loss: 1.3875, G loss: 0.7156\n",
      "[1284/1762] D loss: 1.1696, G loss: 0.7890\n",
      "[1364/1762] D loss: 1.1471, G loss: 1.0086\n",
      "[1444/1762] D loss: 1.3976, G loss: 0.7503\n",
      "[1524/1762] D loss: 1.4383, G loss: 0.9086\n",
      "[1604/1762] D loss: 1.3885, G loss: 0.7288\n",
      "[1684/1762] D loss: 1.3906, G loss: 0.7368\n",
      "[1762/1762] D loss: 0.9643, G loss: 0.8432\n",
      "train error: \n",
      " D loss: 1.331500, G loss: 0.709550, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 84.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.320289, G loss: 0.711545, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 81.8% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.9234, G loss: 0.9928\n",
      "[84/1762] D loss: 1.3892, G loss: 0.7081\n",
      "[164/1762] D loss: 2.1914, G loss: 0.3258\n",
      "[244/1762] D loss: 1.4947, G loss: 0.6289\n",
      "[324/1762] D loss: 1.2691, G loss: 0.6964\n",
      "[404/1762] D loss: 0.9678, G loss: 1.0154\n",
      "[484/1762] D loss: 1.2671, G loss: 0.8447\n",
      "[564/1762] D loss: 1.3950, G loss: 0.6446\n",
      "[644/1762] D loss: 1.3979, G loss: 0.7910\n",
      "[724/1762] D loss: 1.3989, G loss: 0.6208\n",
      "[804/1762] D loss: 1.3859, G loss: 0.6624\n",
      "[884/1762] D loss: 1.3900, G loss: 0.7191\n",
      "[964/1762] D loss: 1.2602, G loss: 0.8193\n",
      "[1044/1762] D loss: 1.3868, G loss: 0.7244\n",
      "[1124/1762] D loss: 1.4019, G loss: 0.6452\n",
      "[1204/1762] D loss: 1.3978, G loss: 0.7341\n",
      "[1284/1762] D loss: 1.4050, G loss: 0.5796\n",
      "[1364/1762] D loss: 1.3907, G loss: 0.6635\n",
      "[1444/1762] D loss: 1.3929, G loss: 0.7631\n",
      "[1524/1762] D loss: 1.3952, G loss: 0.6833\n",
      "[1604/1762] D loss: 1.3958, G loss: 0.7516\n",
      "[1684/1762] D loss: 1.3900, G loss: 0.7130\n",
      "[1762/1762] D loss: 1.3887, G loss: 0.6575\n",
      "train error: \n",
      " D loss: 1.348442, G loss: 0.667279, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 86.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.344251, G loss: 0.669838, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 82.7% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.2204, G loss: 0.6954\n",
      "[84/1762] D loss: 1.3867, G loss: 0.7154\n",
      "[164/1762] D loss: 1.3922, G loss: 0.6793\n",
      "[244/1762] D loss: 1.3895, G loss: 0.7334\n",
      "[324/1762] D loss: 1.3343, G loss: 0.8326\n",
      "[404/1762] D loss: 1.1020, G loss: 1.0212\n",
      "[484/1762] D loss: 1.3883, G loss: 0.7002\n",
      "[564/1762] D loss: 1.3903, G loss: 0.6785\n",
      "[644/1762] D loss: 1.3900, G loss: 0.6793\n",
      "[724/1762] D loss: 1.3950, G loss: 0.6435\n",
      "[804/1762] D loss: 1.3876, G loss: 0.6684\n",
      "[884/1762] D loss: 1.3876, G loss: 0.6873\n",
      "[964/1762] D loss: 1.1775, G loss: 0.8073\n",
      "[1044/1762] D loss: 1.3913, G loss: 0.6383\n",
      "[1124/1762] D loss: 1.3892, G loss: 0.7437\n",
      "[1204/1762] D loss: 1.1786, G loss: 0.8392\n",
      "[1284/1762] D loss: 1.1624, G loss: 0.9004\n",
      "[1364/1762] D loss: 1.3913, G loss: 0.6877\n",
      "[1444/1762] D loss: 1.3932, G loss: 0.7332\n",
      "[1524/1762] D loss: 1.1662, G loss: 0.8447\n",
      "[1604/1762] D loss: 1.3932, G loss: 0.7529\n",
      "[1684/1762] D loss: 1.3991, G loss: 0.7138\n",
      "[1762/1762] D loss: 1.3884, G loss: 0.6907\n",
      "train error: \n",
      " D loss: 1.332868, G loss: 0.766703, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 88.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.323894, G loss: 0.770264, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 85.0% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1607, G loss: 0.8202\n",
      "[84/1762] D loss: 1.3956, G loss: 0.7891\n",
      "[164/1762] D loss: 1.3883, G loss: 0.6961\n",
      "[244/1762] D loss: 1.4027, G loss: 0.7911\n",
      "[324/1762] D loss: 1.3888, G loss: 0.7187\n",
      "[404/1762] D loss: 1.1776, G loss: 0.7841\n",
      "[484/1762] D loss: 1.1520, G loss: 0.8479\n",
      "[564/1762] D loss: 1.4080, G loss: 0.8052\n",
      "[644/1762] D loss: 1.3932, G loss: 0.6513\n",
      "[724/1762] D loss: 1.3898, G loss: 0.7258\n",
      "[804/1762] D loss: 1.3931, G loss: 0.6790\n",
      "[884/1762] D loss: 0.9228, G loss: 1.0771\n",
      "[964/1762] D loss: 1.3905, G loss: 0.6929\n",
      "[1044/1762] D loss: 1.3961, G loss: 0.7518\n",
      "[1124/1762] D loss: 1.4017, G loss: 0.5831\n",
      "[1204/1762] D loss: 1.4035, G loss: 0.7152\n",
      "[1284/1762] D loss: 1.4098, G loss: 0.6575\n",
      "[1364/1762] D loss: 1.4005, G loss: 0.6686\n",
      "[1444/1762] D loss: 1.3926, G loss: 0.7392\n",
      "[1524/1762] D loss: 1.3887, G loss: 0.7360\n",
      "[1604/1762] D loss: 1.3972, G loss: 0.7539\n",
      "[1684/1762] D loss: 1.3635, G loss: 0.6019\n",
      "[1762/1762] D loss: 0.9234, G loss: 0.9489\n",
      "train error: \n",
      " D loss: 1.282912, G loss: 0.849560, D accuracy: 57.9%, cell accuracy: 98.8%, board accuracy: 28.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.270870, G loss: 0.848413, D accuracy: 59.9%, cell accuracy: 98.7%, board accuracy: 23.9% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4093, G loss: 0.7493\n",
      "[84/1762] D loss: 1.3630, G loss: 0.8075\n",
      "[164/1762] D loss: 1.2817, G loss: 0.7113\n",
      "[244/1762] D loss: 1.4917, G loss: 1.0564\n",
      "[324/1762] D loss: 1.3920, G loss: 0.7753\n",
      "[404/1762] D loss: 2.1221, G loss: 0.5153\n",
      "[484/1762] D loss: 1.4774, G loss: 0.8883\n",
      "[564/1762] D loss: 1.8362, G loss: 1.1964\n",
      "[644/1762] D loss: 1.2729, G loss: 0.8580\n",
      "[724/1762] D loss: 1.0536, G loss: 0.8952\n",
      "[804/1762] D loss: 1.0977, G loss: 0.9823\n",
      "[884/1762] D loss: 1.0730, G loss: 0.8521\n",
      "[964/1762] D loss: 0.7849, G loss: 1.0121\n",
      "[1044/1762] D loss: 1.4098, G loss: 0.8403\n",
      "[1124/1762] D loss: 1.4631, G loss: 0.9601\n",
      "[1204/1762] D loss: 1.4541, G loss: 0.5611\n",
      "[1284/1762] D loss: 1.5431, G loss: 0.7905\n",
      "[1364/1762] D loss: 1.4009, G loss: 0.7248\n",
      "[1444/1762] D loss: 1.3097, G loss: 0.7414\n",
      "[1524/1762] D loss: 1.3961, G loss: 0.6506\n",
      "[1604/1762] D loss: 1.3944, G loss: 0.6590\n",
      "[1684/1762] D loss: 1.4178, G loss: 0.6932\n",
      "[1762/1762] D loss: 1.3908, G loss: 0.6951\n",
      "train error: \n",
      " D loss: 1.408425, G loss: 0.652032, D accuracy: 49.8%, cell accuracy: 99.7%, board accuracy: 79.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.419894, G loss: 0.654937, D accuracy: 49.0%, cell accuracy: 99.7%, board accuracy: 75.0% \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4048, G loss: 0.6268\n",
      "[84/1762] D loss: 1.3802, G loss: 0.6909\n",
      "[164/1762] D loss: 1.3977, G loss: 0.6266\n",
      "[244/1762] D loss: 1.5682, G loss: 0.7398\n",
      "[324/1762] D loss: 1.3919, G loss: 0.7580\n",
      "[404/1762] D loss: 1.4046, G loss: 0.7660\n",
      "[484/1762] D loss: 1.3886, G loss: 0.6385\n",
      "[564/1762] D loss: 1.3888, G loss: 0.7401\n",
      "[644/1762] D loss: 1.3920, G loss: 0.7587\n",
      "[724/1762] D loss: 1.3877, G loss: 0.7175\n",
      "[804/1762] D loss: 1.3946, G loss: 0.7687\n",
      "[884/1762] D loss: 1.3902, G loss: 0.6870\n",
      "[964/1762] D loss: 1.4078, G loss: 0.6854\n",
      "[1044/1762] D loss: 1.4139, G loss: 0.6760\n",
      "[1124/1762] D loss: 1.3886, G loss: 0.6884\n",
      "[1204/1762] D loss: 1.3881, G loss: 0.6742\n",
      "[1284/1762] D loss: 1.3916, G loss: 0.7432\n",
      "[1364/1762] D loss: 1.3894, G loss: 0.7368\n",
      "[1444/1762] D loss: 1.3887, G loss: 0.7382\n",
      "[1524/1762] D loss: 1.3903, G loss: 0.6793\n",
      "[1604/1762] D loss: 1.3885, G loss: 0.6638\n",
      "[1684/1762] D loss: 1.3921, G loss: 0.7507\n",
      "[1762/1762] D loss: 1.3888, G loss: 0.6548\n",
      "train error: \n",
      " D loss: 1.365948, G loss: 0.722977, D accuracy: 52.9%, cell accuracy: 99.8%, board accuracy: 88.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.367579, G loss: 0.727919, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 85.2% \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3878, G loss: 0.6899\n",
      "[84/1762] D loss: 1.2682, G loss: 0.7445\n",
      "[164/1762] D loss: 1.2389, G loss: 0.7654\n",
      "[244/1762] D loss: 1.4017, G loss: 0.6763\n",
      "[324/1762] D loss: 1.3898, G loss: 0.6671\n",
      "[404/1762] D loss: 1.3879, G loss: 0.6694\n",
      "[484/1762] D loss: 1.2401, G loss: 0.8282\n",
      "[564/1762] D loss: 1.2789, G loss: 0.7854\n",
      "[644/1762] D loss: 1.4006, G loss: 0.7835\n",
      "[724/1762] D loss: 1.3902, G loss: 0.7378\n",
      "[804/1762] D loss: 1.3877, G loss: 0.6873\n",
      "[884/1762] D loss: 1.3910, G loss: 0.6768\n",
      "[964/1762] D loss: 1.2455, G loss: 0.6761\n",
      "[1044/1762] D loss: 1.3919, G loss: 0.6394\n",
      "[1124/1762] D loss: 1.3871, G loss: 0.6896\n",
      "[1204/1762] D loss: 1.3868, G loss: 0.7239\n",
      "[1284/1762] D loss: 1.2140, G loss: 0.7118\n",
      "[1364/1762] D loss: 1.3892, G loss: 0.6857\n",
      "[1444/1762] D loss: 1.3939, G loss: 0.7797\n",
      "[1524/1762] D loss: 1.0184, G loss: 0.8496\n",
      "[1604/1762] D loss: 1.1940, G loss: 0.7831\n",
      "[1684/1762] D loss: 1.3891, G loss: 0.7482\n",
      "[1762/1762] D loss: 1.3876, G loss: 0.6427\n",
      "train error: \n",
      " D loss: 1.343727, G loss: 0.683912, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 88.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.338030, G loss: 0.685115, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3915, G loss: 0.6489\n",
      "[84/1762] D loss: 1.3885, G loss: 0.7300\n",
      "[164/1762] D loss: 1.3895, G loss: 0.7575\n",
      "[244/1762] D loss: 1.3852, G loss: 0.6194\n",
      "[324/1762] D loss: 1.1830, G loss: 0.7563\n",
      "[404/1762] D loss: 1.3865, G loss: 0.6816\n",
      "[484/1762] D loss: 1.3869, G loss: 0.6896\n",
      "[564/1762] D loss: 1.3856, G loss: 0.6976\n",
      "[644/1762] D loss: 1.3887, G loss: 0.6432\n",
      "[724/1762] D loss: 1.3879, G loss: 0.6813\n",
      "[804/1762] D loss: 1.3962, G loss: 0.8051\n",
      "[884/1762] D loss: 1.3542, G loss: 0.6881\n",
      "[964/1762] D loss: 1.3866, G loss: 0.7015\n",
      "[1044/1762] D loss: 1.3898, G loss: 0.6421\n",
      "[1124/1762] D loss: 1.3923, G loss: 0.6372\n",
      "[1204/1762] D loss: 1.3877, G loss: 0.6694\n",
      "[1284/1762] D loss: 1.1965, G loss: 0.7147\n",
      "[1364/1762] D loss: 1.3866, G loss: 0.6762\n",
      "[1444/1762] D loss: 1.1890, G loss: 0.7892\n",
      "[1524/1762] D loss: 1.3889, G loss: 0.7075\n",
      "[1604/1762] D loss: 1.3935, G loss: 0.7944\n",
      "[1684/1762] D loss: 1.3918, G loss: 0.7118\n",
      "[1762/1762] D loss: 1.3891, G loss: 0.7271\n",
      "train error: \n",
      " D loss: 1.331831, G loss: 0.720090, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 79.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.321169, G loss: 0.722076, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 77.7% \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1569, G loss: 0.8477\n",
      "[84/1762] D loss: 1.4011, G loss: 0.5684\n",
      "[164/1762] D loss: 1.3911, G loss: 0.6985\n",
      "[244/1762] D loss: 1.3912, G loss: 0.8107\n",
      "[324/1762] D loss: 1.3862, G loss: 0.7184\n",
      "[404/1762] D loss: 1.1483, G loss: 0.8411\n",
      "[484/1762] D loss: 1.1940, G loss: 0.7155\n",
      "[564/1762] D loss: 1.3783, G loss: 0.7210\n",
      "[644/1762] D loss: 1.0595, G loss: 0.9193\n",
      "[724/1762] D loss: 1.3866, G loss: 0.6738\n",
      "[804/1762] D loss: 1.3907, G loss: 0.6576\n",
      "[884/1762] D loss: 1.1637, G loss: 0.8505\n",
      "[964/1762] D loss: 1.3900, G loss: 0.6854\n",
      "[1044/1762] D loss: 1.3937, G loss: 0.6033\n",
      "[1124/1762] D loss: 1.3920, G loss: 0.6635\n",
      "[1204/1762] D loss: 1.1111, G loss: 1.0164\n",
      "[1284/1762] D loss: 1.4018, G loss: 0.7480\n",
      "[1364/1762] D loss: 1.1528, G loss: 0.7713\n",
      "[1444/1762] D loss: 1.3908, G loss: 0.7464\n",
      "[1524/1762] D loss: 1.3901, G loss: 0.7023\n",
      "[1604/1762] D loss: 1.3874, G loss: 0.6721\n",
      "[1684/1762] D loss: 1.3951, G loss: 0.7524\n",
      "[1762/1762] D loss: 1.4112, G loss: 0.7502\n",
      "train error: \n",
      " D loss: 1.323859, G loss: 0.737465, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 77.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.309515, G loss: 0.744893, D accuracy: 55.0%, cell accuracy: 99.7%, board accuracy: 73.0% \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3882, G loss: 0.6411\n",
      "[84/1762] D loss: 1.3747, G loss: 0.6798\n",
      "[164/1762] D loss: 1.3902, G loss: 0.7372\n",
      "[244/1762] D loss: 1.4009, G loss: 0.7997\n",
      "[324/1762] D loss: 1.3781, G loss: 0.6763\n",
      "[404/1762] D loss: 1.4067, G loss: 0.8336\n",
      "[484/1762] D loss: 1.3892, G loss: 0.7118\n",
      "[564/1762] D loss: 1.3941, G loss: 0.6794\n",
      "[644/1762] D loss: 1.3381, G loss: 0.7877\n",
      "[724/1762] D loss: 1.4003, G loss: 0.6087\n",
      "[804/1762] D loss: 1.3920, G loss: 0.6254\n",
      "[884/1762] D loss: 0.9074, G loss: 0.9956\n",
      "[964/1762] D loss: 1.3944, G loss: 0.7297\n",
      "[1044/1762] D loss: 1.4026, G loss: 0.6378\n",
      "[1124/1762] D loss: 1.3641, G loss: 0.8015\n",
      "[1204/1762] D loss: 1.1329, G loss: 0.8985\n",
      "[1284/1762] D loss: 1.3942, G loss: 0.7049\n",
      "[1364/1762] D loss: 1.3889, G loss: 0.6592\n",
      "[1444/1762] D loss: 1.1216, G loss: 1.0140\n",
      "[1524/1762] D loss: 1.3777, G loss: 0.6815\n",
      "[1604/1762] D loss: 1.3881, G loss: 0.7213\n",
      "[1684/1762] D loss: 1.3983, G loss: 0.5739\n",
      "[1762/1762] D loss: 1.4276, G loss: 0.8973\n",
      "train error: \n",
      " D loss: 1.314877, G loss: 0.766934, D accuracy: 55.4%, cell accuracy: 99.7%, board accuracy: 77.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.299294, G loss: 0.777351, D accuracy: 55.9%, cell accuracy: 99.7%, board accuracy: 73.9% \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3628, G loss: 0.6603\n",
      "[84/1762] D loss: 1.4020, G loss: 0.7551\n",
      "[164/1762] D loss: 1.3618, G loss: 0.7514\n",
      "[244/1762] D loss: 1.4058, G loss: 0.6253\n",
      "[324/1762] D loss: 1.3639, G loss: 0.7195\n",
      "[404/1762] D loss: 1.3503, G loss: 0.8118\n",
      "[484/1762] D loss: 1.3884, G loss: 0.7283\n",
      "[564/1762] D loss: 1.3482, G loss: 0.6604\n",
      "[644/1762] D loss: 1.4079, G loss: 0.7971\n",
      "[724/1762] D loss: 1.1185, G loss: 0.7543\n",
      "[804/1762] D loss: 1.1691, G loss: 0.9867\n",
      "[884/1762] D loss: 1.3985, G loss: 0.5870\n",
      "[964/1762] D loss: 1.3919, G loss: 0.7236\n",
      "[1044/1762] D loss: 1.3849, G loss: 0.6975\n",
      "[1124/1762] D loss: 1.3885, G loss: 0.7148\n",
      "[1204/1762] D loss: 1.4074, G loss: 0.8176\n",
      "[1284/1762] D loss: 1.9088, G loss: 0.5242\n",
      "[1364/1762] D loss: 1.9181, G loss: 0.7549\n",
      "[1444/1762] D loss: 1.1271, G loss: 1.0138\n",
      "[1524/1762] D loss: 0.9654, G loss: 1.0569\n",
      "[1604/1762] D loss: 0.8565, G loss: 1.2638\n",
      "[1684/1762] D loss: 0.8777, G loss: 1.1299\n",
      "[1762/1762] D loss: 1.4079, G loss: 0.7424\n",
      "train error: \n",
      " D loss: 1.431001, G loss: 0.855369, D accuracy: 53.0%, cell accuracy: 99.4%, board accuracy: 46.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.458029, G loss: 0.872876, D accuracy: 53.3%, cell accuracy: 99.3%, board accuracy: 45.2% \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3874, G loss: 0.7855\n",
      "[84/1762] D loss: 1.3970, G loss: 0.7888\n",
      "[164/1762] D loss: 1.4075, G loss: 0.7984\n",
      "[244/1762] D loss: 1.3768, G loss: 0.7355\n",
      "[324/1762] D loss: 1.4102, G loss: 0.6616\n",
      "[404/1762] D loss: 1.4180, G loss: 0.7580\n",
      "[484/1762] D loss: 1.3938, G loss: 0.7432\n",
      "[564/1762] D loss: 1.4057, G loss: 0.6465\n",
      "[644/1762] D loss: 1.4242, G loss: 0.6708\n",
      "[724/1762] D loss: 1.3691, G loss: 0.7297\n",
      "[804/1762] D loss: 1.3969, G loss: 0.7588\n",
      "[884/1762] D loss: 1.3890, G loss: 0.7248\n",
      "[964/1762] D loss: 1.3935, G loss: 0.7816\n",
      "[1044/1762] D loss: 1.3965, G loss: 0.6305\n",
      "[1124/1762] D loss: 1.3998, G loss: 0.6003\n",
      "[1204/1762] D loss: 1.3439, G loss: 0.6628\n",
      "[1284/1762] D loss: 1.3917, G loss: 0.6435\n",
      "[1364/1762] D loss: 1.3978, G loss: 0.6123\n",
      "[1444/1762] D loss: 1.3875, G loss: 0.6862\n",
      "[1524/1762] D loss: 1.3673, G loss: 0.7635\n",
      "[1604/1762] D loss: 1.3948, G loss: 0.6856\n",
      "[1684/1762] D loss: 1.2613, G loss: 0.7659\n",
      "[1762/1762] D loss: 1.3905, G loss: 0.6381\n",
      "train error: \n",
      " D loss: 1.363871, G loss: 0.704044, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.362542, G loss: 0.716287, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 82.7% \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3876, G loss: 0.7285\n",
      "[84/1762] D loss: 1.2558, G loss: 0.7866\n",
      "[164/1762] D loss: 1.3877, G loss: 0.7161\n",
      "[244/1762] D loss: 1.3894, G loss: 0.6830\n",
      "[324/1762] D loss: 1.2448, G loss: 0.6954\n",
      "[404/1762] D loss: 1.3955, G loss: 0.7665\n",
      "[484/1762] D loss: 1.3951, G loss: 0.6517\n",
      "[564/1762] D loss: 1.2183, G loss: 0.8061\n",
      "[644/1762] D loss: 1.4181, G loss: 0.6420\n",
      "[724/1762] D loss: 1.4409, G loss: 0.6354\n",
      "[804/1762] D loss: 1.3867, G loss: 0.6761\n",
      "[884/1762] D loss: 1.3901, G loss: 0.6902\n",
      "[964/1762] D loss: 1.3675, G loss: 0.7415\n",
      "[1044/1762] D loss: 1.2339, G loss: 0.7428\n",
      "[1124/1762] D loss: 1.1909, G loss: 0.8258\n",
      "[1204/1762] D loss: 1.3921, G loss: 0.6972\n",
      "[1284/1762] D loss: 1.3898, G loss: 0.7294\n",
      "[1364/1762] D loss: 1.3915, G loss: 0.6517\n",
      "[1444/1762] D loss: 1.3876, G loss: 0.7074\n",
      "[1524/1762] D loss: 1.3895, G loss: 0.7511\n",
      "[1604/1762] D loss: 1.3942, G loss: 0.7515\n",
      "[1684/1762] D loss: 1.3896, G loss: 0.7329\n",
      "[1762/1762] D loss: 0.9822, G loss: 0.8723\n",
      "train error: \n",
      " D loss: 1.336710, G loss: 0.739526, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 88.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.327109, G loss: 0.750235, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 84.5% \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3916, G loss: 0.6529\n",
      "[84/1762] D loss: 1.1238, G loss: 1.0193\n",
      "[164/1762] D loss: 1.3025, G loss: 0.7956\n",
      "[244/1762] D loss: 1.2252, G loss: 0.7249\n",
      "[324/1762] D loss: 1.1704, G loss: 0.8770\n",
      "[404/1762] D loss: 1.1776, G loss: 0.7974\n",
      "[484/1762] D loss: 1.3919, G loss: 0.7705\n",
      "[564/1762] D loss: 1.3856, G loss: 0.6839\n",
      "[644/1762] D loss: 1.3938, G loss: 0.7181\n",
      "[724/1762] D loss: 1.3940, G loss: 0.6921\n",
      "[804/1762] D loss: 1.3799, G loss: 0.6071\n",
      "[884/1762] D loss: 1.3875, G loss: 0.6628\n",
      "[964/1762] D loss: 1.1647, G loss: 0.7920\n",
      "[1044/1762] D loss: 1.3893, G loss: 0.7115\n",
      "[1124/1762] D loss: 1.3876, G loss: 0.7062\n",
      "[1204/1762] D loss: 1.3983, G loss: 0.7534\n",
      "[1284/1762] D loss: 1.3909, G loss: 0.6879\n",
      "[1364/1762] D loss: 1.3878, G loss: 0.6684\n",
      "[1444/1762] D loss: 1.1869, G loss: 0.6925\n",
      "[1524/1762] D loss: 1.3878, G loss: 0.7349\n",
      "[1604/1762] D loss: 1.3905, G loss: 0.7258\n",
      "[1684/1762] D loss: 1.3885, G loss: 0.6608\n",
      "[1762/1762] D loss: 1.3909, G loss: 0.6266\n",
      "train error: \n",
      " D loss: 1.330298, G loss: 0.681576, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 86.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.316046, G loss: 0.691979, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 82.3% \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3914, G loss: 0.6735\n",
      "[84/1762] D loss: 1.3882, G loss: 0.7298\n",
      "[164/1762] D loss: 1.3966, G loss: 0.7498\n",
      "[244/1762] D loss: 1.3879, G loss: 0.6969\n",
      "[324/1762] D loss: 1.3927, G loss: 0.7410\n",
      "[404/1762] D loss: 1.3959, G loss: 0.6865\n",
      "[484/1762] D loss: 1.3956, G loss: 0.7032\n",
      "[564/1762] D loss: 1.3863, G loss: 0.6303\n",
      "[644/1762] D loss: 1.1493, G loss: 0.8822\n",
      "[724/1762] D loss: 1.3886, G loss: 0.6785\n",
      "[804/1762] D loss: 1.1315, G loss: 0.8934\n",
      "[884/1762] D loss: 1.1649, G loss: 0.8229\n",
      "[964/1762] D loss: 1.1467, G loss: 0.9565\n",
      "[1044/1762] D loss: 1.1259, G loss: 0.9904\n",
      "[1124/1762] D loss: 1.3952, G loss: 0.7346\n",
      "[1204/1762] D loss: 1.1217, G loss: 0.8438\n",
      "[1284/1762] D loss: 1.1301, G loss: 0.8603\n",
      "[1364/1762] D loss: 1.8377, G loss: 0.5756\n",
      "[1444/1762] D loss: 1.3466, G loss: 0.8886\n",
      "[1524/1762] D loss: 0.9977, G loss: 0.8365\n",
      "[1604/1762] D loss: 1.1821, G loss: 0.9442\n",
      "[1684/1762] D loss: 1.2784, G loss: 1.0766\n",
      "[1762/1762] D loss: 1.4164, G loss: 0.6305\n",
      "train error: \n",
      " D loss: 1.366099, G loss: 0.714083, D accuracy: 52.5%, cell accuracy: 99.8%, board accuracy: 85.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.366157, G loss: 0.727484, D accuracy: 52.7%, cell accuracy: 99.8%, board accuracy: 81.8% \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4232, G loss: 0.7509\n",
      "[84/1762] D loss: 1.2488, G loss: 0.6491\n",
      "[164/1762] D loss: 1.3933, G loss: 0.7163\n",
      "[244/1762] D loss: 1.2126, G loss: 0.8156\n",
      "[324/1762] D loss: 1.3931, G loss: 0.7750\n",
      "[404/1762] D loss: 1.3907, G loss: 0.6301\n",
      "[484/1762] D loss: 1.3888, G loss: 0.7027\n",
      "[564/1762] D loss: 1.3939, G loss: 0.6655\n",
      "[644/1762] D loss: 1.0698, G loss: 0.8563\n",
      "[724/1762] D loss: 1.3896, G loss: 0.7376\n",
      "[804/1762] D loss: 0.6699, G loss: 1.0908\n",
      "[884/1762] D loss: 1.3925, G loss: 0.6996\n",
      "[964/1762] D loss: 1.3932, G loss: 0.7026\n",
      "[1044/1762] D loss: 1.3897, G loss: 0.7278\n",
      "[1124/1762] D loss: 1.1719, G loss: 0.7260\n",
      "[1204/1762] D loss: 1.3881, G loss: 0.6965\n",
      "[1284/1762] D loss: 1.1521, G loss: 0.9582\n",
      "[1364/1762] D loss: 0.8688, G loss: 1.1376\n",
      "[1444/1762] D loss: 1.3957, G loss: 0.6769\n",
      "[1524/1762] D loss: 1.3930, G loss: 0.6723\n",
      "[1604/1762] D loss: 1.1815, G loss: 0.7876\n",
      "[1684/1762] D loss: 1.3804, G loss: 0.7229\n",
      "[1762/1762] D loss: 0.9158, G loss: 0.9587\n",
      "train error: \n",
      " D loss: 1.327748, G loss: 0.778063, D accuracy: 53.1%, cell accuracy: 99.8%, board accuracy: 81.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.315322, G loss: 0.789053, D accuracy: 53.3%, cell accuracy: 99.7%, board accuracy: 77.0% \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3941, G loss: 0.7444\n",
      "[84/1762] D loss: 1.4035, G loss: 0.7435\n",
      "[164/1762] D loss: 1.3969, G loss: 0.5743\n",
      "[244/1762] D loss: 1.3971, G loss: 0.7112\n",
      "[324/1762] D loss: 1.3939, G loss: 0.6858\n",
      "[404/1762] D loss: 1.3917, G loss: 0.7583\n",
      "[484/1762] D loss: 1.4016, G loss: 0.6614\n",
      "[564/1762] D loss: 1.3856, G loss: 0.6483\n",
      "[644/1762] D loss: 1.3894, G loss: 0.7309\n",
      "[724/1762] D loss: 1.1429, G loss: 0.7860\n",
      "[804/1762] D loss: 1.1065, G loss: 1.0492\n",
      "[884/1762] D loss: 1.4108, G loss: 0.7550\n",
      "[964/1762] D loss: 1.1405, G loss: 0.8228\n",
      "[1044/1762] D loss: 1.3918, G loss: 0.7462\n",
      "[1124/1762] D loss: 1.3902, G loss: 0.6903\n",
      "[1204/1762] D loss: 1.3990, G loss: 0.6344\n",
      "[1284/1762] D loss: 1.1415, G loss: 0.8877\n",
      "[1364/1762] D loss: 1.1279, G loss: 0.9657\n",
      "[1444/1762] D loss: 1.4162, G loss: 0.8498\n",
      "[1524/1762] D loss: 1.1324, G loss: 0.8735\n",
      "[1604/1762] D loss: 1.3887, G loss: 0.7118\n",
      "[1684/1762] D loss: 1.4034, G loss: 0.7579\n",
      "[1762/1762] D loss: 1.3880, G loss: 0.6902\n",
      "train error: \n",
      " D loss: 1.319972, G loss: 0.767613, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 85.0% \n",
      "\n",
      "test error: \n",
      " D loss: 1.302979, G loss: 0.777021, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 82.3% \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1188, G loss: 0.8587\n",
      "[84/1762] D loss: 1.3933, G loss: 0.7667\n",
      "[164/1762] D loss: 1.4288, G loss: 0.8512\n",
      "[244/1762] D loss: 1.1289, G loss: 0.7958\n",
      "[324/1762] D loss: 1.3829, G loss: 0.6537\n",
      "[404/1762] D loss: 1.3987, G loss: 0.6060\n",
      "[484/1762] D loss: 0.8361, G loss: 1.1155\n",
      "[564/1762] D loss: 1.3935, G loss: 0.7281\n",
      "[644/1762] D loss: 1.1427, G loss: 0.8946\n",
      "[724/1762] D loss: 1.3960, G loss: 0.7173\n",
      "[804/1762] D loss: 1.1323, G loss: 0.8541\n",
      "[884/1762] D loss: 0.8835, G loss: 1.0083\n",
      "[964/1762] D loss: 1.4192, G loss: 0.5595\n",
      "[1044/1762] D loss: 1.3920, G loss: 0.6675\n",
      "[1124/1762] D loss: 1.1177, G loss: 0.9053\n",
      "[1204/1762] D loss: 1.3885, G loss: 0.6705\n",
      "[1284/1762] D loss: 1.3914, G loss: 0.6738\n",
      "[1364/1762] D loss: 1.1404, G loss: 0.9278\n",
      "[1444/1762] D loss: 1.1194, G loss: 0.9262\n",
      "[1524/1762] D loss: 1.3932, G loss: 0.7526\n",
      "[1604/1762] D loss: 1.3962, G loss: 0.6382\n",
      "[1684/1762] D loss: 1.3892, G loss: 0.6785\n",
      "[1762/1762] D loss: 1.3869, G loss: 0.6527\n",
      "train error: \n",
      " D loss: 1.317315, G loss: 0.755320, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 85.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.298816, G loss: 0.766926, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 82.3% \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4043, G loss: 0.7795\n",
      "[84/1762] D loss: 0.7907, G loss: 1.4826\n",
      "[164/1762] D loss: 1.1333, G loss: 0.9299\n",
      "[244/1762] D loss: 1.3959, G loss: 0.6200\n",
      "[324/1762] D loss: 1.3934, G loss: 0.7143\n",
      "[404/1762] D loss: 1.1196, G loss: 0.8087\n",
      "[484/1762] D loss: 1.3778, G loss: 0.6692\n",
      "[564/1762] D loss: 0.8564, G loss: 1.1366\n",
      "[644/1762] D loss: 1.4163, G loss: 0.8388\n",
      "[724/1762] D loss: 1.4001, G loss: 0.5985\n",
      "[804/1762] D loss: 0.8418, G loss: 1.2107\n",
      "[884/1762] D loss: 1.3907, G loss: 0.7317\n",
      "[964/1762] D loss: 1.1203, G loss: 0.7790\n",
      "[1044/1762] D loss: 1.4051, G loss: 0.8146\n",
      "[1124/1762] D loss: 1.3858, G loss: 0.7258\n",
      "[1204/1762] D loss: 1.1236, G loss: 0.8371\n",
      "[1284/1762] D loss: 1.1282, G loss: 0.9424\n",
      "[1364/1762] D loss: 1.1287, G loss: 0.9844\n",
      "[1444/1762] D loss: 1.3987, G loss: 0.6471\n",
      "[1524/1762] D loss: 1.4012, G loss: 0.6417\n",
      "[1604/1762] D loss: 1.3955, G loss: 0.7875\n",
      "[1684/1762] D loss: 1.1445, G loss: 1.0448\n",
      "[1762/1762] D loss: 1.3893, G loss: 0.7368\n",
      "train error: \n",
      " D loss: 1.314374, G loss: 0.771895, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 85.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.296275, G loss: 0.783503, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 81.4% \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3887, G loss: 0.6606\n",
      "[84/1762] D loss: 1.4023, G loss: 0.7685\n",
      "[164/1762] D loss: 1.3896, G loss: 0.7436\n",
      "[244/1762] D loss: 1.3984, G loss: 0.7411\n",
      "[324/1762] D loss: 1.4097, G loss: 0.7589\n",
      "[404/1762] D loss: 1.3989, G loss: 0.5768\n",
      "[484/1762] D loss: 1.3872, G loss: 0.7159\n",
      "[564/1762] D loss: 1.1167, G loss: 1.0583\n",
      "[644/1762] D loss: 1.3933, G loss: 0.7114\n",
      "[724/1762] D loss: 1.4029, G loss: 0.7172\n",
      "[804/1762] D loss: 1.3930, G loss: 0.6059\n",
      "[884/1762] D loss: 1.1392, G loss: 1.0022\n",
      "[964/1762] D loss: 1.1283, G loss: 0.9592\n",
      "[1044/1762] D loss: 1.3877, G loss: 0.7591\n",
      "[1124/1762] D loss: 1.3970, G loss: 0.6444\n",
      "[1204/1762] D loss: 1.3919, G loss: 0.7619\n",
      "[1284/1762] D loss: 1.1136, G loss: 0.8539\n",
      "[1364/1762] D loss: 1.0768, G loss: 1.0478\n",
      "[1444/1762] D loss: 1.4311, G loss: 0.8241\n",
      "[1524/1762] D loss: 1.3735, G loss: 0.7963\n",
      "[1604/1762] D loss: 1.3914, G loss: 0.6860\n",
      "[1684/1762] D loss: 1.3896, G loss: 0.6543\n",
      "[1762/1762] D loss: 1.4188, G loss: 0.8362\n",
      "train error: \n",
      " D loss: 1.317456, G loss: 0.848621, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 82.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.298568, G loss: 0.864203, D accuracy: 54.5%, cell accuracy: 99.7%, board accuracy: 78.2% \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0816, G loss: 1.1177\n",
      "[84/1762] D loss: 1.4040, G loss: 0.6018\n",
      "[164/1762] D loss: 1.1127, G loss: 0.9296\n",
      "[244/1762] D loss: 1.1236, G loss: 0.9086\n",
      "[324/1762] D loss: 1.3883, G loss: 0.7261\n",
      "[404/1762] D loss: 1.3936, G loss: 0.7125\n",
      "[484/1762] D loss: 1.0995, G loss: 0.9241\n",
      "[564/1762] D loss: 1.3907, G loss: 0.6636\n",
      "[644/1762] D loss: 1.3888, G loss: 0.6907\n",
      "[724/1762] D loss: 1.3996, G loss: 0.7458\n",
      "[804/1762] D loss: 1.3897, G loss: 0.6842\n",
      "[884/1762] D loss: 1.3874, G loss: 0.7616\n",
      "[964/1762] D loss: 1.3908, G loss: 0.7119\n",
      "[1044/1762] D loss: 1.3871, G loss: 0.6906\n",
      "[1124/1762] D loss: 1.3887, G loss: 0.7282\n",
      "[1204/1762] D loss: 1.3930, G loss: 0.7087\n",
      "[1284/1762] D loss: 1.4074, G loss: 0.7740\n",
      "[1364/1762] D loss: 1.1228, G loss: 0.8765\n",
      "[1444/1762] D loss: 1.4165, G loss: 0.7594\n",
      "[1524/1762] D loss: 1.4100, G loss: 0.8575\n",
      "[1604/1762] D loss: 1.3938, G loss: 0.6190\n",
      "[1684/1762] D loss: 1.3758, G loss: 0.7035\n",
      "[1762/1762] D loss: 1.3917, G loss: 0.6428\n",
      "train error: \n",
      " D loss: 1.318216, G loss: 0.734368, D accuracy: 53.1%, cell accuracy: 99.7%, board accuracy: 74.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.303326, G loss: 0.749945, D accuracy: 54.2%, cell accuracy: 99.7%, board accuracy: 69.8% \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3729, G loss: 0.6973\n",
      "[84/1762] D loss: 1.3853, G loss: 0.7084\n",
      "[164/1762] D loss: 1.4013, G loss: 0.6446\n",
      "[244/1762] D loss: 1.0630, G loss: 1.2536\n",
      "[324/1762] D loss: 1.4515, G loss: 0.7426\n",
      "[404/1762] D loss: 1.4324, G loss: 0.6717\n",
      "[484/1762] D loss: 1.1418, G loss: 0.8471\n",
      "[564/1762] D loss: 1.3457, G loss: 0.7142\n",
      "[644/1762] D loss: 1.4135, G loss: 0.8570\n",
      "[724/1762] D loss: 1.3892, G loss: 0.6857\n",
      "[804/1762] D loss: 1.3824, G loss: 0.7909\n",
      "[884/1762] D loss: 1.3899, G loss: 0.6189\n",
      "[964/1762] D loss: 1.3996, G loss: 0.7717\n",
      "[1044/1762] D loss: 0.9261, G loss: 0.9505\n",
      "[1124/1762] D loss: 1.3894, G loss: 0.7256\n",
      "[1204/1762] D loss: 1.3701, G loss: 0.6997\n",
      "[1284/1762] D loss: 1.0613, G loss: 0.9857\n",
      "[1364/1762] D loss: 1.3459, G loss: 0.7182\n",
      "[1444/1762] D loss: 1.0871, G loss: 1.0549\n",
      "[1524/1762] D loss: 1.3867, G loss: 0.7343\n",
      "[1604/1762] D loss: 1.3942, G loss: 0.6873\n",
      "[1684/1762] D loss: 0.8616, G loss: 1.0713\n",
      "[1762/1762] D loss: 1.3806, G loss: 0.7136\n",
      "train error: \n",
      " D loss: 1.343501, G loss: 0.688636, D accuracy: 54.3%, cell accuracy: 99.7%, board accuracy: 58.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.322202, G loss: 0.704730, D accuracy: 54.1%, cell accuracy: 99.7%, board accuracy: 58.9% \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4385, G loss: 0.5770\n",
      "[84/1762] D loss: 1.5016, G loss: 0.7470\n",
      "[164/1762] D loss: 0.8427, G loss: 1.0225\n",
      "[244/1762] D loss: 1.3127, G loss: 0.7364\n",
      "[324/1762] D loss: 1.3591, G loss: 0.7780\n",
      "[404/1762] D loss: 1.3872, G loss: 0.7543\n",
      "[484/1762] D loss: 1.4214, G loss: 0.7643\n",
      "[564/1762] D loss: 1.3852, G loss: 0.7267\n",
      "[644/1762] D loss: 1.1239, G loss: 0.9577\n",
      "[724/1762] D loss: 1.3909, G loss: 0.6497\n",
      "[804/1762] D loss: 1.1215, G loss: 0.7992\n",
      "[884/1762] D loss: 1.3875, G loss: 0.7115\n",
      "[964/1762] D loss: 1.3955, G loss: 0.7826\n",
      "[1044/1762] D loss: 1.3514, G loss: 0.6783\n",
      "[1124/1762] D loss: 1.3856, G loss: 0.8086\n",
      "[1204/1762] D loss: 1.3934, G loss: 0.6901\n",
      "[1284/1762] D loss: 1.4090, G loss: 0.7312\n",
      "[1364/1762] D loss: 1.3958, G loss: 0.6879\n",
      "[1444/1762] D loss: 1.1485, G loss: 0.9282\n",
      "[1524/1762] D loss: 1.1506, G loss: 0.7495\n",
      "[1604/1762] D loss: 1.0901, G loss: 1.1291\n",
      "[1684/1762] D loss: 1.0283, G loss: 1.0744\n",
      "[1762/1762] D loss: 1.3135, G loss: 0.7144\n",
      "train error: \n",
      " D loss: 1.311244, G loss: 0.807944, D accuracy: 54.3%, cell accuracy: 99.7%, board accuracy: 71.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.293448, G loss: 0.823412, D accuracy: 55.8%, cell accuracy: 99.7%, board accuracy: 68.0% \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3911, G loss: 0.7350\n",
      "[84/1762] D loss: 0.8798, G loss: 0.9468\n",
      "[164/1762] D loss: 1.4055, G loss: 0.7446\n",
      "[244/1762] D loss: 1.3783, G loss: 0.7245\n",
      "[324/1762] D loss: 1.3974, G loss: 0.7121\n",
      "[404/1762] D loss: 0.8600, G loss: 0.9317\n",
      "[484/1762] D loss: 1.1329, G loss: 0.8302\n",
      "[564/1762] D loss: 1.3916, G loss: 0.6933\n",
      "[644/1762] D loss: 1.3885, G loss: 0.7324\n",
      "[724/1762] D loss: 1.0713, G loss: 1.0670\n",
      "[804/1762] D loss: 1.3780, G loss: 0.6660\n",
      "[884/1762] D loss: 1.1329, G loss: 0.8206\n",
      "[964/1762] D loss: 1.3899, G loss: 0.7521\n",
      "[1044/1762] D loss: 1.3912, G loss: 0.7300\n",
      "[1124/1762] D loss: 1.3921, G loss: 0.7260\n",
      "[1204/1762] D loss: 1.3976, G loss: 0.7509\n",
      "[1284/1762] D loss: 1.3910, G loss: 0.6892\n",
      "[1364/1762] D loss: 1.3888, G loss: 0.6472\n",
      "[1444/1762] D loss: 1.4023, G loss: 0.8248\n",
      "[1524/1762] D loss: 1.3973, G loss: 0.6155\n",
      "[1604/1762] D loss: 1.4054, G loss: 0.5903\n",
      "[1684/1762] D loss: 1.3908, G loss: 0.7693\n",
      "[1762/1762] D loss: 1.3870, G loss: 0.6963\n",
      "train error: \n",
      " D loss: 1.310273, G loss: 0.770200, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 85.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.289779, G loss: 0.788444, D accuracy: 55.2%, cell accuracy: 99.8%, board accuracy: 81.8% \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3877, G loss: 0.6882\n",
      "[84/1762] D loss: 1.3960, G loss: 0.6967\n",
      "[164/1762] D loss: 1.0815, G loss: 1.1570\n",
      "[244/1762] D loss: 1.3859, G loss: 0.7274\n",
      "[324/1762] D loss: 1.0752, G loss: 1.0961\n",
      "[404/1762] D loss: 1.3837, G loss: 0.7919\n",
      "[484/1762] D loss: 1.3893, G loss: 0.7166\n",
      "[564/1762] D loss: 1.1067, G loss: 0.8750\n",
      "[644/1762] D loss: 1.4507, G loss: 0.9088\n",
      "[724/1762] D loss: 1.4074, G loss: 0.5890\n",
      "[804/1762] D loss: 1.1079, G loss: 0.9597\n",
      "[884/1762] D loss: 1.3630, G loss: 0.6921\n",
      "[964/1762] D loss: 1.1609, G loss: 0.7525\n",
      "[1044/1762] D loss: 1.1225, G loss: 0.9214\n",
      "[1124/1762] D loss: 1.3818, G loss: 0.6073\n",
      "[1204/1762] D loss: 1.3871, G loss: 0.6959\n",
      "[1284/1762] D loss: 1.1236, G loss: 0.9329\n",
      "[1364/1762] D loss: 1.1302, G loss: 0.8670\n",
      "[1444/1762] D loss: 1.4106, G loss: 0.8427\n",
      "[1524/1762] D loss: 1.4020, G loss: 0.5727\n",
      "[1604/1762] D loss: 1.4036, G loss: 0.6114\n",
      "[1684/1762] D loss: 1.1149, G loss: 0.9095\n",
      "[1762/1762] D loss: 1.4290, G loss: 0.9005\n",
      "train error: \n",
      " D loss: 1.325429, G loss: 0.889433, D accuracy: 53.1%, cell accuracy: 99.8%, board accuracy: 74.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.305206, G loss: 0.907852, D accuracy: 54.1%, cell accuracy: 99.7%, board accuracy: 70.9% \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3938, G loss: 0.7532\n",
      "[84/1762] D loss: 1.3977, G loss: 0.6217\n",
      "[164/1762] D loss: 1.3877, G loss: 0.6665\n",
      "[244/1762] D loss: 1.4075, G loss: 0.7583\n",
      "[324/1762] D loss: 1.3874, G loss: 0.6484\n",
      "[404/1762] D loss: 1.4127, G loss: 0.7922\n",
      "[484/1762] D loss: 1.4294, G loss: 0.5802\n",
      "[564/1762] D loss: 1.4113, G loss: 0.8596\n",
      "[644/1762] D loss: 1.3836, G loss: 0.6768\n",
      "[724/1762] D loss: 1.1225, G loss: 0.8850\n",
      "[804/1762] D loss: 1.3820, G loss: 0.7097\n",
      "[884/1762] D loss: 1.3944, G loss: 0.7325\n",
      "[964/1762] D loss: 1.0090, G loss: 1.1167\n",
      "[1044/1762] D loss: 1.3882, G loss: 0.6644\n",
      "[1124/1762] D loss: 1.3793, G loss: 0.6889\n",
      "[1204/1762] D loss: 1.3948, G loss: 0.6372\n",
      "[1284/1762] D loss: 1.4141, G loss: 0.6256\n",
      "[1364/1762] D loss: 1.3987, G loss: 0.7459\n",
      "[1444/1762] D loss: 1.3887, G loss: 0.7263\n",
      "[1524/1762] D loss: 1.1307, G loss: 0.9677\n",
      "[1604/1762] D loss: 1.1769, G loss: 0.8678\n",
      "[1684/1762] D loss: 1.3897, G loss: 0.6653\n",
      "[1762/1762] D loss: 1.4137, G loss: 0.6496\n",
      "train error: \n",
      " D loss: 1.310153, G loss: 0.771887, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 81.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.290696, G loss: 0.787428, D accuracy: 54.3%, cell accuracy: 99.7%, board accuracy: 77.7% \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3866, G loss: 0.7840\n",
      "[84/1762] D loss: 1.3887, G loss: 0.7315\n",
      "[164/1762] D loss: 1.1284, G loss: 0.8814\n",
      "[244/1762] D loss: 1.3900, G loss: 0.7529\n",
      "[324/1762] D loss: 1.3876, G loss: 0.6986\n",
      "[404/1762] D loss: 1.3919, G loss: 0.6501\n",
      "[484/1762] D loss: 1.3926, G loss: 0.6566\n",
      "[564/1762] D loss: 1.0871, G loss: 0.9561\n",
      "[644/1762] D loss: 1.1070, G loss: 0.9064\n",
      "[724/1762] D loss: 1.3948, G loss: 0.8029\n",
      "[804/1762] D loss: 1.3896, G loss: 0.6659\n",
      "[884/1762] D loss: 1.3881, G loss: 0.6738\n",
      "[964/1762] D loss: 1.3892, G loss: 0.7244\n",
      "[1044/1762] D loss: 0.8124, G loss: 1.1419\n",
      "[1124/1762] D loss: 1.4610, G loss: 0.8882\n",
      "[1204/1762] D loss: 1.3960, G loss: 0.6725\n",
      "[1284/1762] D loss: 1.4261, G loss: 0.7751\n",
      "[1364/1762] D loss: 1.4439, G loss: 0.9336\n",
      "[1444/1762] D loss: 1.3933, G loss: 0.7186\n",
      "[1524/1762] D loss: 1.3916, G loss: 0.7096\n",
      "[1604/1762] D loss: 1.4070, G loss: 0.6561\n",
      "[1684/1762] D loss: 1.4050, G loss: 0.7467\n",
      "[1762/1762] D loss: 1.3875, G loss: 0.6609\n",
      "train error: \n",
      " D loss: 1.311273, G loss: 0.815271, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 87.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.288694, G loss: 0.836730, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 83.0% \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1047, G loss: 0.9601\n",
      "[84/1762] D loss: 1.4305, G loss: 0.8455\n",
      "[164/1762] D loss: 1.3863, G loss: 0.6508\n",
      "[244/1762] D loss: 1.3890, G loss: 0.6642\n",
      "[324/1762] D loss: 0.7660, G loss: 1.4226\n",
      "[404/1762] D loss: 1.3910, G loss: 0.7500\n",
      "[484/1762] D loss: 1.3872, G loss: 0.7296\n",
      "[564/1762] D loss: 1.3950, G loss: 0.6310\n",
      "[644/1762] D loss: 1.3907, G loss: 0.7250\n",
      "[724/1762] D loss: 0.8469, G loss: 0.9957\n",
      "[804/1762] D loss: 1.3871, G loss: 0.6895\n",
      "[884/1762] D loss: 1.3912, G loss: 0.6614\n",
      "[964/1762] D loss: 1.3906, G loss: 0.7250\n",
      "[1044/1762] D loss: 1.1140, G loss: 0.9259\n",
      "[1124/1762] D loss: 1.3898, G loss: 0.7389\n",
      "[1204/1762] D loss: 1.3956, G loss: 0.6771\n",
      "[1284/1762] D loss: 0.8063, G loss: 1.2109\n",
      "[1364/1762] D loss: 1.1100, G loss: 0.9409\n",
      "[1444/1762] D loss: 1.1088, G loss: 1.0532\n",
      "[1524/1762] D loss: 1.3879, G loss: 0.6442\n",
      "[1604/1762] D loss: 1.3956, G loss: 0.6884\n",
      "[1684/1762] D loss: 1.3894, G loss: 0.6652\n",
      "[1762/1762] D loss: 0.7600, G loss: 1.4687\n",
      "train error: \n",
      " D loss: 1.310043, G loss: 0.793945, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.289736, G loss: 0.815284, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 83.0% \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3886, G loss: 0.6922\n",
      "[84/1762] D loss: 1.1038, G loss: 0.9379\n",
      "[164/1762] D loss: 1.3885, G loss: 0.6356\n",
      "[244/1762] D loss: 0.8170, G loss: 1.1490\n",
      "[324/1762] D loss: 1.3891, G loss: 0.6989\n",
      "[404/1762] D loss: 1.3893, G loss: 0.6695\n",
      "[484/1762] D loss: 1.3916, G loss: 0.6997\n",
      "[564/1762] D loss: 1.1017, G loss: 1.0495\n",
      "[644/1762] D loss: 1.3901, G loss: 0.6474\n",
      "[724/1762] D loss: 1.3984, G loss: 0.6320\n",
      "[804/1762] D loss: 1.3934, G loss: 0.7667\n",
      "[884/1762] D loss: 0.8295, G loss: 1.1490\n",
      "[964/1762] D loss: 1.3916, G loss: 0.6507\n",
      "[1044/1762] D loss: 1.3914, G loss: 0.6759\n",
      "[1124/1762] D loss: 1.4312, G loss: 0.8229\n",
      "[1204/1762] D loss: 1.3969, G loss: 0.6410\n",
      "[1284/1762] D loss: 1.3889, G loss: 0.7519\n",
      "[1364/1762] D loss: 1.0984, G loss: 0.8598\n",
      "[1444/1762] D loss: 1.0963, G loss: 0.8629\n",
      "[1524/1762] D loss: 1.1101, G loss: 0.8602\n",
      "[1604/1762] D loss: 1.3946, G loss: 0.7390\n",
      "[1684/1762] D loss: 1.3985, G loss: 0.6816\n",
      "[1762/1762] D loss: 1.3884, G loss: 0.7715\n",
      "train error: \n",
      " D loss: 1.308708, G loss: 0.840597, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 86.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.290338, G loss: 0.861210, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 81.8% \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3882, G loss: 0.7582\n",
      "[84/1762] D loss: 1.3865, G loss: 0.7037\n",
      "[164/1762] D loss: 1.3905, G loss: 0.6586\n",
      "[244/1762] D loss: 1.3965, G loss: 0.6160\n",
      "[324/1762] D loss: 1.1080, G loss: 0.9744\n",
      "[404/1762] D loss: 1.3822, G loss: 0.6199\n",
      "[484/1762] D loss: 1.3871, G loss: 0.6906\n",
      "[564/1762] D loss: 1.3873, G loss: 0.6896\n",
      "[644/1762] D loss: 1.0616, G loss: 1.1336\n",
      "[724/1762] D loss: 1.1054, G loss: 0.9409\n",
      "[804/1762] D loss: 1.3860, G loss: 0.7281\n",
      "[884/1762] D loss: 1.3895, G loss: 0.7026\n",
      "[964/1762] D loss: 1.3936, G loss: 0.7292\n",
      "[1044/1762] D loss: 1.3902, G loss: 0.6508\n",
      "[1124/1762] D loss: 1.0968, G loss: 0.9300\n",
      "[1204/1762] D loss: 1.3884, G loss: 0.6614\n",
      "[1284/1762] D loss: 1.3883, G loss: 0.7094\n",
      "[1364/1762] D loss: 1.0945, G loss: 0.8803\n",
      "[1444/1762] D loss: 1.3931, G loss: 0.7858\n",
      "[1524/1762] D loss: 1.3862, G loss: 0.7578\n",
      "[1604/1762] D loss: 1.3820, G loss: 0.7434\n",
      "[1684/1762] D loss: 1.3896, G loss: 0.6477\n",
      "[1762/1762] D loss: 1.3886, G loss: 0.7460\n",
      "train error: \n",
      " D loss: 1.304177, G loss: 0.822768, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 82.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.283846, G loss: 0.848659, D accuracy: 55.1%, cell accuracy: 99.7%, board accuracy: 78.9% \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3881, G loss: 0.7374\n",
      "[84/1762] D loss: 1.3892, G loss: 0.6559\n",
      "[164/1762] D loss: 1.4699, G loss: 0.8749\n",
      "[244/1762] D loss: 1.3869, G loss: 0.7320\n",
      "[324/1762] D loss: 1.4146, G loss: 0.7267\n",
      "[404/1762] D loss: 1.3998, G loss: 0.7856\n",
      "[484/1762] D loss: 1.3974, G loss: 0.6605\n",
      "[564/1762] D loss: 1.0598, G loss: 1.1677\n",
      "[644/1762] D loss: 1.4095, G loss: 0.7537\n",
      "[724/1762] D loss: 1.3964, G loss: 0.6593\n",
      "[804/1762] D loss: 1.3868, G loss: 0.6897\n",
      "[884/1762] D loss: 1.3664, G loss: 0.6525\n",
      "[964/1762] D loss: 1.3882, G loss: 0.7274\n",
      "[1044/1762] D loss: 1.0555, G loss: 1.2812\n",
      "[1124/1762] D loss: 1.3792, G loss: 0.8538\n",
      "[1204/1762] D loss: 1.3897, G loss: 0.7276\n",
      "[1284/1762] D loss: 1.3882, G loss: 0.6712\n",
      "[1364/1762] D loss: 1.0860, G loss: 1.1102\n",
      "[1444/1762] D loss: 1.4058, G loss: 0.7819\n",
      "[1524/1762] D loss: 1.4015, G loss: 0.6316\n",
      "[1604/1762] D loss: 1.3920, G loss: 0.6931\n",
      "[1684/1762] D loss: 1.0922, G loss: 1.0120\n",
      "[1762/1762] D loss: 1.3917, G loss: 0.5914\n",
      "train error: \n",
      " D loss: 1.318575, G loss: 0.690472, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 88.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.297930, G loss: 0.713014, D accuracy: 54.8%, cell accuracy: 99.8%, board accuracy: 85.5% \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.1165, G loss: 0.8402\n",
      "[84/1762] D loss: 1.1052, G loss: 1.0256\n",
      "[164/1762] D loss: 1.3844, G loss: 0.6643\n",
      "[244/1762] D loss: 0.8058, G loss: 1.1586\n",
      "[324/1762] D loss: 1.3899, G loss: 0.6820\n",
      "[404/1762] D loss: 1.3924, G loss: 0.6460\n",
      "[484/1762] D loss: 1.3909, G loss: 0.7753\n",
      "[564/1762] D loss: 1.3859, G loss: 0.6861\n",
      "[644/1762] D loss: 1.4143, G loss: 0.7651\n",
      "[724/1762] D loss: 1.3904, G loss: 0.6713\n",
      "[804/1762] D loss: 1.3900, G loss: 0.7322\n",
      "[884/1762] D loss: 1.4011, G loss: 0.7132\n",
      "[964/1762] D loss: 1.4045, G loss: 0.6926\n",
      "[1044/1762] D loss: 1.3886, G loss: 0.6311\n",
      "[1124/1762] D loss: 1.3960, G loss: 0.7886\n",
      "[1204/1762] D loss: 1.3873, G loss: 0.6834\n",
      "[1284/1762] D loss: 1.0897, G loss: 0.9972\n",
      "[1364/1762] D loss: 1.1030, G loss: 1.0407\n",
      "[1444/1762] D loss: 1.3972, G loss: 0.7468\n",
      "[1524/1762] D loss: 1.3872, G loss: 0.6978\n",
      "[1604/1762] D loss: 1.3957, G loss: 0.5840\n",
      "[1684/1762] D loss: 1.3927, G loss: 0.7596\n",
      "[1762/1762] D loss: 1.3869, G loss: 0.6559\n",
      "train error: \n",
      " D loss: 1.313177, G loss: 0.703189, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 88.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.292931, G loss: 0.728796, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 85.0% \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3960, G loss: 0.6043\n",
      "[84/1762] D loss: 1.3893, G loss: 0.6888\n",
      "[164/1762] D loss: 1.3874, G loss: 0.6656\n",
      "[244/1762] D loss: 1.0953, G loss: 0.9775\n",
      "[324/1762] D loss: 1.3921, G loss: 0.7140\n",
      "[404/1762] D loss: 1.3877, G loss: 0.6930\n",
      "[484/1762] D loss: 1.4048, G loss: 0.6474\n",
      "[564/1762] D loss: 1.0591, G loss: 1.2006\n",
      "[644/1762] D loss: 1.3872, G loss: 0.6784\n",
      "[724/1762] D loss: 1.3904, G loss: 0.7362\n",
      "[804/1762] D loss: 1.3683, G loss: 0.7412\n",
      "[884/1762] D loss: 1.1029, G loss: 0.9772\n",
      "[964/1762] D loss: 1.3959, G loss: 0.7574\n",
      "[1044/1762] D loss: 1.3879, G loss: 0.7402\n",
      "[1124/1762] D loss: 1.4008, G loss: 0.7453\n",
      "[1204/1762] D loss: 1.4082, G loss: 0.7782\n",
      "[1284/1762] D loss: 1.0955, G loss: 1.0642\n",
      "[1364/1762] D loss: 1.3912, G loss: 0.7280\n",
      "[1444/1762] D loss: 1.0884, G loss: 1.0103\n",
      "[1524/1762] D loss: 1.1153, G loss: 0.8686\n",
      "[1604/1762] D loss: 1.3942, G loss: 0.7934\n",
      "[1684/1762] D loss: 1.3968, G loss: 0.7508\n",
      "[1762/1762] D loss: 1.3878, G loss: 0.7351\n",
      "train error: \n",
      " D loss: 1.307574, G loss: 0.761497, D accuracy: 53.8%, cell accuracy: 99.8%, board accuracy: 87.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.286750, G loss: 0.790057, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 83.6% \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0875, G loss: 0.9613\n",
      "[84/1762] D loss: 1.4064, G loss: 0.7176\n",
      "[164/1762] D loss: 1.0822, G loss: 1.0172\n",
      "[244/1762] D loss: 1.3797, G loss: 0.6970\n",
      "[324/1762] D loss: 1.0629, G loss: 1.2965\n",
      "[404/1762] D loss: 1.3862, G loss: 0.6756\n",
      "[484/1762] D loss: 1.4219, G loss: 0.7582\n",
      "[564/1762] D loss: 1.3942, G loss: 0.6365\n",
      "[644/1762] D loss: 1.0970, G loss: 0.9275\n",
      "[724/1762] D loss: 1.3935, G loss: 0.7745\n",
      "[804/1762] D loss: 1.4133, G loss: 0.8281\n",
      "[884/1762] D loss: 1.3890, G loss: 0.6794\n",
      "[964/1762] D loss: 1.3927, G loss: 0.7796\n",
      "[1044/1762] D loss: 1.3875, G loss: 0.6411\n",
      "[1124/1762] D loss: 1.3898, G loss: 0.6696\n",
      "[1204/1762] D loss: 1.3886, G loss: 0.6880\n",
      "[1284/1762] D loss: 1.0819, G loss: 0.9885\n",
      "[1364/1762] D loss: 1.1142, G loss: 1.0787\n",
      "[1444/1762] D loss: 1.4108, G loss: 0.6475\n",
      "[1524/1762] D loss: 1.0975, G loss: 1.0215\n",
      "[1604/1762] D loss: 1.3144, G loss: 0.7051\n",
      "[1684/1762] D loss: 1.4006, G loss: 0.6826\n",
      "[1762/1762] D loss: 1.4177, G loss: 0.5635\n",
      "train error: \n",
      " D loss: 1.321673, G loss: 0.676608, D accuracy: 53.9%, cell accuracy: 99.8%, board accuracy: 82.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.301805, G loss: 0.698123, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 79.1% \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3934, G loss: 0.6543\n",
      "[84/1762] D loss: 1.3937, G loss: 0.7605\n",
      "[164/1762] D loss: 0.7708, G loss: 1.3511\n",
      "[244/1762] D loss: 1.0907, G loss: 0.9819\n",
      "[324/1762] D loss: 1.1044, G loss: 1.0736\n",
      "[404/1762] D loss: 1.0784, G loss: 1.0248\n",
      "[484/1762] D loss: 1.3861, G loss: 0.7236\n",
      "[564/1762] D loss: 1.3878, G loss: 0.6850\n",
      "[644/1762] D loss: 1.3887, G loss: 0.7141\n",
      "[724/1762] D loss: 1.3891, G loss: 0.6875\n",
      "[804/1762] D loss: 1.3538, G loss: 0.7726\n",
      "[884/1762] D loss: 1.3893, G loss: 0.7565\n",
      "[964/1762] D loss: 1.0944, G loss: 0.8879\n",
      "[1044/1762] D loss: 1.0869, G loss: 1.0399\n",
      "[1124/1762] D loss: 1.1039, G loss: 0.9422\n",
      "[1204/1762] D loss: 1.3903, G loss: 0.7617\n",
      "[1284/1762] D loss: 1.3882, G loss: 0.6737\n",
      "[1364/1762] D loss: 1.3899, G loss: 0.6937\n",
      "[1444/1762] D loss: 1.3899, G loss: 0.6761\n",
      "[1524/1762] D loss: 1.3892, G loss: 0.6991\n",
      "[1604/1762] D loss: 1.3700, G loss: 0.6856\n",
      "[1684/1762] D loss: 1.3945, G loss: 0.7375\n",
      "[1762/1762] D loss: 0.7820, G loss: 1.3409\n",
      "train error: \n",
      " D loss: 1.321533, G loss: 0.943103, D accuracy: 53.2%, cell accuracy: 99.8%, board accuracy: 85.7% \n",
      "\n",
      "test error: \n",
      " D loss: 1.300431, G loss: 0.971898, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 83.0% \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4258, G loss: 0.8654\n",
      "[84/1762] D loss: 1.0630, G loss: 1.1877\n",
      "[164/1762] D loss: 1.0753, G loss: 1.0868\n",
      "[244/1762] D loss: 1.3874, G loss: 0.6867\n",
      "[324/1762] D loss: 1.3891, G loss: 0.6772\n",
      "[404/1762] D loss: 1.3904, G loss: 0.6541\n",
      "[484/1762] D loss: 1.3872, G loss: 0.7210\n",
      "[564/1762] D loss: 1.3891, G loss: 0.7027\n",
      "[644/1762] D loss: 1.3888, G loss: 0.6616\n",
      "[724/1762] D loss: 1.0532, G loss: 1.4502\n",
      "[804/1762] D loss: 1.3878, G loss: 0.7430\n",
      "[884/1762] D loss: 1.4063, G loss: 0.7844\n",
      "[964/1762] D loss: 1.3918, G loss: 0.6250\n",
      "[1044/1762] D loss: 1.3888, G loss: 0.6903\n",
      "[1124/1762] D loss: 1.3835, G loss: 0.7335\n",
      "[1204/1762] D loss: 1.3869, G loss: 0.7735\n",
      "[1284/1762] D loss: 1.4531, G loss: 0.7581\n",
      "[1364/1762] D loss: 1.4699, G loss: 0.6420\n",
      "[1444/1762] D loss: 1.0590, G loss: 1.0145\n",
      "[1524/1762] D loss: 1.3512, G loss: 0.7108\n",
      "[1604/1762] D loss: 1.4061, G loss: 0.7830\n",
      "[1684/1762] D loss: 1.3469, G loss: 0.6702\n",
      "[1762/1762] D loss: 1.3970, G loss: 0.6161\n",
      "train error: \n",
      " D loss: 1.316729, G loss: 0.664130, D accuracy: 54.6%, cell accuracy: 99.7%, board accuracy: 74.3% \n",
      "\n",
      "test error: \n",
      " D loss: 1.295584, G loss: 0.689061, D accuracy: 55.2%, cell accuracy: 99.7%, board accuracy: 71.1% \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3810, G loss: 0.6032\n",
      "[84/1762] D loss: 1.3777, G loss: 0.7981\n",
      "[164/1762] D loss: 1.3919, G loss: 0.6500\n",
      "[244/1762] D loss: 1.4083, G loss: 0.7906\n",
      "[324/1762] D loss: 1.3319, G loss: 0.7649\n",
      "[404/1762] D loss: 1.4499, G loss: 0.5776\n",
      "[484/1762] D loss: 1.3819, G loss: 0.7155\n",
      "[564/1762] D loss: 1.4136, G loss: 0.7763\n",
      "[644/1762] D loss: 1.3878, G loss: 0.7295\n",
      "[724/1762] D loss: 1.1140, G loss: 0.9325\n",
      "[804/1762] D loss: 1.3890, G loss: 0.6851\n",
      "[884/1762] D loss: 1.1077, G loss: 1.0477\n",
      "[964/1762] D loss: 1.3308, G loss: 0.8000\n",
      "[1044/1762] D loss: 1.3891, G loss: 0.7468\n",
      "[1124/1762] D loss: 1.1271, G loss: 1.0065\n",
      "[1204/1762] D loss: 1.3958, G loss: 0.8180\n",
      "[1284/1762] D loss: 1.3894, G loss: 0.6768\n",
      "[1364/1762] D loss: 1.3464, G loss: 0.6942\n",
      "[1444/1762] D loss: 1.3889, G loss: 0.6811\n",
      "[1524/1762] D loss: 1.0661, G loss: 1.1596\n",
      "[1604/1762] D loss: 1.4068, G loss: 0.5590\n",
      "[1684/1762] D loss: 1.0694, G loss: 1.0950\n",
      "[1762/1762] D loss: 1.3911, G loss: 0.6074\n",
      "train error: \n",
      " D loss: 1.305274, G loss: 0.779262, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 87.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.283700, G loss: 0.803208, D accuracy: 55.0%, cell accuracy: 99.8%, board accuracy: 83.9% \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4074, G loss: 0.6238\n",
      "[84/1762] D loss: 1.3481, G loss: 0.8785\n",
      "[164/1762] D loss: 1.4112, G loss: 0.7555\n",
      "[244/1762] D loss: 1.0811, G loss: 1.0371\n",
      "[324/1762] D loss: 1.3912, G loss: 0.7612\n",
      "[404/1762] D loss: 1.3873, G loss: 0.7034\n",
      "[484/1762] D loss: 1.3982, G loss: 0.7409\n",
      "[564/1762] D loss: 1.0872, G loss: 0.9732\n",
      "[644/1762] D loss: 1.3925, G loss: 0.7253\n",
      "[724/1762] D loss: 1.3999, G loss: 0.6793\n",
      "[804/1762] D loss: 1.3931, G loss: 0.7934\n",
      "[884/1762] D loss: 1.0703, G loss: 1.2516\n",
      "[964/1762] D loss: 1.1082, G loss: 1.0538\n",
      "[1044/1762] D loss: 1.3948, G loss: 0.6501\n",
      "[1124/1762] D loss: 1.3935, G loss: 0.6291\n",
      "[1204/1762] D loss: 1.0889, G loss: 0.9553\n",
      "[1284/1762] D loss: 1.3967, G loss: 0.7378\n",
      "[1364/1762] D loss: 1.4014, G loss: 0.7246\n",
      "[1444/1762] D loss: 1.3952, G loss: 0.7583\n",
      "[1524/1762] D loss: 1.3920, G loss: 0.6787\n",
      "[1604/1762] D loss: 1.3912, G loss: 0.6954\n",
      "[1684/1762] D loss: 1.3837, G loss: 0.6518\n",
      "[1762/1762] D loss: 1.3873, G loss: 0.6965\n",
      "train error: \n",
      " D loss: 1.305750, G loss: 0.855535, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 87.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.284064, G loss: 0.882299, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 84.3% \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3505, G loss: 0.7959\n",
      "[84/1762] D loss: 1.3881, G loss: 0.7053\n",
      "[164/1762] D loss: 1.3914, G loss: 0.6883\n",
      "[244/1762] D loss: 1.3878, G loss: 0.7165\n",
      "[324/1762] D loss: 1.0617, G loss: 1.2378\n",
      "[404/1762] D loss: 1.4043, G loss: 0.7959\n",
      "[484/1762] D loss: 1.3896, G loss: 0.6633\n",
      "[564/1762] D loss: 1.3913, G loss: 0.6743\n",
      "[644/1762] D loss: 1.3876, G loss: 0.7138\n",
      "[724/1762] D loss: 1.3920, G loss: 0.7241\n",
      "[804/1762] D loss: 1.3688, G loss: 0.7887\n",
      "[884/1762] D loss: 1.3872, G loss: 0.7513\n",
      "[964/1762] D loss: 1.1019, G loss: 0.9786\n",
      "[1044/1762] D loss: 1.3893, G loss: 0.7191\n",
      "[1124/1762] D loss: 1.3901, G loss: 0.6687\n",
      "[1204/1762] D loss: 1.3897, G loss: 0.7510\n",
      "[1284/1762] D loss: 1.3906, G loss: 0.6235\n",
      "[1364/1762] D loss: 1.3959, G loss: 0.7726\n",
      "[1444/1762] D loss: 1.0937, G loss: 0.9698\n",
      "[1524/1762] D loss: 1.4120, G loss: 0.7581\n",
      "[1604/1762] D loss: 1.0919, G loss: 0.9418\n",
      "[1684/1762] D loss: 1.3917, G loss: 0.6269\n",
      "[1762/1762] D loss: 1.3864, G loss: 0.7092\n",
      "train error: \n",
      " D loss: 1.300323, G loss: 0.808592, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 88.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.277797, G loss: 0.839866, D accuracy: 55.1%, cell accuracy: 99.8%, board accuracy: 85.5% \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3865, G loss: 0.7114\n",
      "[84/1762] D loss: 1.4047, G loss: 0.7512\n",
      "[164/1762] D loss: 1.3880, G loss: 0.6509\n",
      "[244/1762] D loss: 1.3752, G loss: 0.7354\n",
      "[324/1762] D loss: 1.0796, G loss: 1.1231\n",
      "[404/1762] D loss: 1.3877, G loss: 0.6429\n",
      "[484/1762] D loss: 1.0893, G loss: 1.0023\n",
      "[564/1762] D loss: 1.3264, G loss: 0.6737\n",
      "[644/1762] D loss: 1.0925, G loss: 0.9754\n",
      "[724/1762] D loss: 1.0825, G loss: 1.0130\n",
      "[804/1762] D loss: 1.3902, G loss: 0.6757\n",
      "[884/1762] D loss: 1.3881, G loss: 0.7239\n",
      "[964/1762] D loss: 1.3903, G loss: 0.6855\n",
      "[1044/1762] D loss: 1.3882, G loss: 0.6607\n",
      "[1124/1762] D loss: 1.3942, G loss: 0.6511\n",
      "[1204/1762] D loss: 1.2605, G loss: 0.7391\n",
      "[1284/1762] D loss: 1.0864, G loss: 1.0937\n",
      "[1364/1762] D loss: 1.3819, G loss: 0.7236\n",
      "[1444/1762] D loss: 1.0992, G loss: 0.9238\n",
      "[1524/1762] D loss: 1.4064, G loss: 0.5946\n",
      "[1604/1762] D loss: 1.0630, G loss: 1.3147\n",
      "[1684/1762] D loss: 1.0838, G loss: 0.9970\n",
      "[1762/1762] D loss: 1.3925, G loss: 0.6454\n",
      "train error: \n",
      " D loss: 1.304542, G loss: 0.800365, D accuracy: 53.5%, cell accuracy: 99.8%, board accuracy: 88.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.282568, G loss: 0.831007, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 84.8% \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0798, G loss: 1.0980\n",
      "[84/1762] D loss: 1.0551, G loss: 1.3142\n",
      "[164/1762] D loss: 1.3927, G loss: 0.7582\n",
      "[244/1762] D loss: 1.5351, G loss: 1.0676\n",
      "[324/1762] D loss: 1.4055, G loss: 0.6172\n",
      "[404/1762] D loss: 1.3972, G loss: 0.7720\n",
      "[484/1762] D loss: 1.0863, G loss: 1.0032\n",
      "[564/1762] D loss: 1.4195, G loss: 0.7323\n",
      "[644/1762] D loss: 1.0760, G loss: 1.1095\n",
      "[724/1762] D loss: 1.4338, G loss: 0.6835\n",
      "[804/1762] D loss: 1.4265, G loss: 0.6727\n",
      "[884/1762] D loss: 1.3798, G loss: 0.7481\n",
      "[964/1762] D loss: 1.3905, G loss: 0.7741\n",
      "[1044/1762] D loss: 1.1136, G loss: 0.9287\n",
      "[1124/1762] D loss: 1.4023, G loss: 0.6927\n",
      "[1204/1762] D loss: 0.7287, G loss: 1.7878\n",
      "[1284/1762] D loss: 1.3985, G loss: 0.6993\n",
      "[1364/1762] D loss: 1.3788, G loss: 0.7696\n",
      "[1444/1762] D loss: 1.0878, G loss: 0.9707\n",
      "[1524/1762] D loss: 1.3918, G loss: 0.7491\n",
      "[1604/1762] D loss: 1.4035, G loss: 0.8239\n",
      "[1684/1762] D loss: 1.3923, G loss: 0.6760\n",
      "[1762/1762] D loss: 1.3938, G loss: 0.6328\n",
      "train error: \n",
      " D loss: 1.302869, G loss: 0.729947, D accuracy: 54.5%, cell accuracy: 99.6%, board accuracy: 74.8% \n",
      "\n",
      "test error: \n",
      " D loss: 1.282477, G loss: 0.747837, D accuracy: 55.3%, cell accuracy: 99.5%, board accuracy: 73.4% \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3658, G loss: 0.6238\n",
      "[84/1762] D loss: 1.3773, G loss: 0.8050\n",
      "[164/1762] D loss: 1.3908, G loss: 0.6461\n",
      "[244/1762] D loss: 1.1004, G loss: 0.9965\n",
      "[324/1762] D loss: 1.3949, G loss: 0.7259\n",
      "[404/1762] D loss: 1.3719, G loss: 0.6251\n",
      "[484/1762] D loss: 1.3885, G loss: 0.6994\n",
      "[564/1762] D loss: 1.3781, G loss: 0.7140\n",
      "[644/1762] D loss: 1.3927, G loss: 0.6731\n",
      "[724/1762] D loss: 1.4170, G loss: 0.6065\n",
      "[804/1762] D loss: 1.3910, G loss: 0.7298\n",
      "[884/1762] D loss: 1.1003, G loss: 1.0814\n",
      "[964/1762] D loss: 1.3953, G loss: 0.6284\n",
      "[1044/1762] D loss: 1.0797, G loss: 1.0454\n",
      "[1124/1762] D loss: 1.3632, G loss: 0.6681\n",
      "[1204/1762] D loss: 1.3933, G loss: 0.6568\n",
      "[1284/1762] D loss: 1.3915, G loss: 0.7843\n",
      "[1364/1762] D loss: 1.3886, G loss: 0.6775\n",
      "[1444/1762] D loss: 1.0949, G loss: 0.9810\n",
      "[1524/1762] D loss: 0.7896, G loss: 1.2168\n",
      "[1604/1762] D loss: 1.3779, G loss: 0.6498\n",
      "[1684/1762] D loss: 1.3971, G loss: 0.6529\n",
      "[1762/1762] D loss: 1.4043, G loss: 0.8079\n",
      "train error: \n",
      " D loss: 1.310645, G loss: 0.865490, D accuracy: 53.3%, cell accuracy: 99.8%, board accuracy: 86.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.286457, G loss: 0.898716, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 83.6% \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0624, G loss: 1.2218\n",
      "[84/1762] D loss: 1.3893, G loss: 0.6425\n",
      "[164/1762] D loss: 1.0914, G loss: 0.9749\n",
      "[244/1762] D loss: 1.3875, G loss: 0.7110\n",
      "[324/1762] D loss: 1.3965, G loss: 0.5964\n",
      "[404/1762] D loss: 1.4136, G loss: 0.8214\n",
      "[484/1762] D loss: 1.3982, G loss: 0.6188\n",
      "[564/1762] D loss: 1.0839, G loss: 1.0840\n",
      "[644/1762] D loss: 1.0764, G loss: 1.0513\n",
      "[724/1762] D loss: 1.3820, G loss: 0.6977\n",
      "[804/1762] D loss: 1.4049, G loss: 0.7867\n",
      "[884/1762] D loss: 1.3879, G loss: 0.7495\n",
      "[964/1762] D loss: 1.3910, G loss: 0.7279\n",
      "[1044/1762] D loss: 1.4079, G loss: 0.6639\n",
      "[1124/1762] D loss: 1.3852, G loss: 0.6752\n",
      "[1204/1762] D loss: 1.3908, G loss: 0.6977\n",
      "[1284/1762] D loss: 1.0447, G loss: 1.0516\n",
      "[1364/1762] D loss: 1.0940, G loss: 0.8914\n",
      "[1444/1762] D loss: 1.4121, G loss: 0.7059\n",
      "[1524/1762] D loss: 1.3965, G loss: 0.6952\n",
      "[1604/1762] D loss: 0.7911, G loss: 1.2842\n",
      "[1684/1762] D loss: 1.3833, G loss: 0.7149\n",
      "[1762/1762] D loss: 1.4009, G loss: 0.6614\n",
      "train error: \n",
      " D loss: 1.306998, G loss: 0.763232, D accuracy: 53.8%, cell accuracy: 99.7%, board accuracy: 74.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.286826, G loss: 0.790493, D accuracy: 54.3%, cell accuracy: 99.7%, board accuracy: 73.6% \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3866, G loss: 0.6798\n",
      "[84/1762] D loss: 1.3845, G loss: 0.6623\n",
      "[164/1762] D loss: 1.0635, G loss: 1.0942\n",
      "[244/1762] D loss: 1.3631, G loss: 0.7107\n",
      "[324/1762] D loss: 1.4211, G loss: 0.7379\n",
      "[404/1762] D loss: 1.3829, G loss: 0.7187\n",
      "[484/1762] D loss: 1.3896, G loss: 0.7314\n",
      "[564/1762] D loss: 1.3990, G loss: 0.7853\n",
      "[644/1762] D loss: 1.3975, G loss: 0.6280\n",
      "[724/1762] D loss: 1.1013, G loss: 0.9118\n",
      "[804/1762] D loss: 1.3865, G loss: 0.7184\n",
      "[884/1762] D loss: 1.3912, G loss: 0.6102\n",
      "[964/1762] D loss: 1.3909, G loss: 0.7334\n",
      "[1044/1762] D loss: 1.3917, G loss: 0.6652\n",
      "[1124/1762] D loss: 1.3974, G loss: 0.6184\n",
      "[1204/1762] D loss: 1.3945, G loss: 0.7461\n",
      "[1284/1762] D loss: 1.3931, G loss: 0.6460\n",
      "[1364/1762] D loss: 1.3902, G loss: 0.7352\n",
      "[1444/1762] D loss: 1.3910, G loss: 0.6124\n",
      "[1524/1762] D loss: 1.4019, G loss: 0.7669\n",
      "[1604/1762] D loss: 1.3973, G loss: 0.7581\n",
      "[1684/1762] D loss: 1.3896, G loss: 0.7926\n",
      "[1762/1762] D loss: 1.3937, G loss: 0.6438\n",
      "train error: \n",
      " D loss: 1.305106, G loss: 0.730827, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 79.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.286478, G loss: 0.752522, D accuracy: 54.9%, cell accuracy: 99.7%, board accuracy: 78.0% \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0445, G loss: 1.0765\n",
      "[84/1762] D loss: 1.3946, G loss: 0.7312\n",
      "[164/1762] D loss: 1.3734, G loss: 0.6812\n",
      "[244/1762] D loss: 1.1015, G loss: 0.9679\n",
      "[324/1762] D loss: 1.1027, G loss: 0.8896\n",
      "[404/1762] D loss: 1.3895, G loss: 0.6376\n",
      "[484/1762] D loss: 1.4028, G loss: 0.8031\n",
      "[564/1762] D loss: 1.3984, G loss: 0.5972\n",
      "[644/1762] D loss: 1.3973, G loss: 0.7383\n",
      "[724/1762] D loss: 1.3877, G loss: 0.6627\n",
      "[804/1762] D loss: 1.3917, G loss: 0.6862\n",
      "[884/1762] D loss: 1.0808, G loss: 1.0928\n",
      "[964/1762] D loss: 1.3868, G loss: 0.7037\n",
      "[1044/1762] D loss: 1.3729, G loss: 0.7613\n",
      "[1124/1762] D loss: 1.3932, G loss: 0.7589\n",
      "[1204/1762] D loss: 1.0714, G loss: 1.0603\n",
      "[1284/1762] D loss: 1.4125, G loss: 0.8929\n",
      "[1364/1762] D loss: 1.3874, G loss: 0.6506\n",
      "[1444/1762] D loss: 1.3770, G loss: 0.7569\n",
      "[1524/1762] D loss: 1.3792, G loss: 0.7295\n",
      "[1604/1762] D loss: 1.3983, G loss: 0.7860\n",
      "[1684/1762] D loss: 1.3894, G loss: 0.7553\n",
      "[1762/1762] D loss: 0.8045, G loss: 1.3585\n",
      "train error: \n",
      " D loss: 1.302551, G loss: 0.809606, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 84.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.279679, G loss: 0.840066, D accuracy: 55.3%, cell accuracy: 99.8%, board accuracy: 80.9% \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3898, G loss: 0.7150\n",
      "[84/1762] D loss: 1.0482, G loss: 1.0072\n",
      "[164/1762] D loss: 1.3698, G loss: 0.6734\n",
      "[244/1762] D loss: 1.4003, G loss: 0.7219\n",
      "[324/1762] D loss: 1.3681, G loss: 0.7294\n",
      "[404/1762] D loss: 1.3996, G loss: 0.6426\n",
      "[484/1762] D loss: 1.3910, G loss: 0.6626\n",
      "[564/1762] D loss: 1.3972, G loss: 0.6359\n",
      "[644/1762] D loss: 1.3883, G loss: 0.7009\n",
      "[724/1762] D loss: 1.0691, G loss: 1.1472\n",
      "[804/1762] D loss: 1.1059, G loss: 1.3419\n",
      "[884/1762] D loss: 1.3757, G loss: 0.6310\n",
      "[964/1762] D loss: 1.0743, G loss: 1.0872\n",
      "[1044/1762] D loss: 1.3905, G loss: 0.6871\n",
      "[1124/1762] D loss: 1.0962, G loss: 0.9250\n",
      "[1204/1762] D loss: 1.0572, G loss: 1.2381\n",
      "[1284/1762] D loss: 1.3932, G loss: 0.7014\n",
      "[1364/1762] D loss: 1.0913, G loss: 0.9271\n",
      "[1444/1762] D loss: 1.3781, G loss: 0.7237\n",
      "[1524/1762] D loss: 1.3667, G loss: 0.6756\n",
      "[1604/1762] D loss: 1.0829, G loss: 1.0183\n",
      "[1684/1762] D loss: 1.3988, G loss: 0.5871\n",
      "[1762/1762] D loss: 1.3866, G loss: 0.6665\n",
      "train error: \n",
      " D loss: 1.302544, G loss: 0.781518, D accuracy: 54.6%, cell accuracy: 99.8%, board accuracy: 82.4% \n",
      "\n",
      "test error: \n",
      " D loss: 1.282112, G loss: 0.808279, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 81.1% \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3880, G loss: 0.6469\n",
      "[84/1762] D loss: 1.3849, G loss: 0.5967\n",
      "[164/1762] D loss: 1.3904, G loss: 0.7912\n",
      "[244/1762] D loss: 1.3902, G loss: 0.6736\n",
      "[324/1762] D loss: 1.3895, G loss: 0.6615\n",
      "[404/1762] D loss: 1.3564, G loss: 0.7003\n",
      "[484/1762] D loss: 1.0612, G loss: 1.1111\n",
      "[564/1762] D loss: 1.3311, G loss: 0.6924\n",
      "[644/1762] D loss: 1.3758, G loss: 0.7264\n",
      "[724/1762] D loss: 1.3761, G loss: 0.6765\n",
      "[804/1762] D loss: 1.3905, G loss: 0.7441\n",
      "[884/1762] D loss: 1.3878, G loss: 0.6450\n",
      "[964/1762] D loss: 1.0651, G loss: 1.3838\n",
      "[1044/1762] D loss: 1.0873, G loss: 0.9446\n",
      "[1124/1762] D loss: 0.9450, G loss: 1.0413\n",
      "[1204/1762] D loss: 1.0533, G loss: 1.3706\n",
      "[1284/1762] D loss: 1.0170, G loss: 1.0655\n",
      "[1364/1762] D loss: 1.4159, G loss: 0.8142\n",
      "[1444/1762] D loss: 1.4042, G loss: 0.7584\n",
      "[1524/1762] D loss: 1.0807, G loss: 1.1043\n",
      "[1604/1762] D loss: 1.3883, G loss: 0.6585\n",
      "[1684/1762] D loss: 1.0908, G loss: 0.9790\n",
      "[1762/1762] D loss: 1.4325, G loss: 0.6828\n",
      "train error: \n",
      " D loss: 1.308040, G loss: 0.792715, D accuracy: 51.2%, cell accuracy: 99.7%, board accuracy: 60.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.288368, G loss: 0.816073, D accuracy: 51.7%, cell accuracy: 99.7%, board accuracy: 60.9% \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4129, G loss: 0.6605\n",
      "[84/1762] D loss: 1.4184, G loss: 0.5859\n",
      "[164/1762] D loss: 1.0899, G loss: 0.9597\n",
      "[244/1762] D loss: 1.3652, G loss: 0.8002\n",
      "[324/1762] D loss: 1.3648, G loss: 0.6978\n",
      "[404/1762] D loss: 1.0782, G loss: 1.0865\n",
      "[484/1762] D loss: 1.3939, G loss: 0.7706\n",
      "[564/1762] D loss: 1.3883, G loss: 0.6874\n",
      "[644/1762] D loss: 1.3888, G loss: 0.6645\n",
      "[724/1762] D loss: 1.0734, G loss: 1.0586\n",
      "[804/1762] D loss: 1.4087, G loss: 0.6356\n",
      "[884/1762] D loss: 1.0773, G loss: 1.2997\n",
      "[964/1762] D loss: 1.3933, G loss: 0.6378\n",
      "[1044/1762] D loss: 1.3880, G loss: 0.6742\n",
      "[1124/1762] D loss: 1.4018, G loss: 0.6534\n",
      "[1204/1762] D loss: 1.4009, G loss: 0.8318\n",
      "[1284/1762] D loss: 1.3886, G loss: 0.6841\n",
      "[1364/1762] D loss: 1.3962, G loss: 0.6561\n",
      "[1444/1762] D loss: 1.3927, G loss: 0.7734\n",
      "[1524/1762] D loss: 1.0937, G loss: 0.9229\n",
      "[1604/1762] D loss: 1.3932, G loss: 0.6912\n",
      "[1684/1762] D loss: 1.3792, G loss: 0.6696\n",
      "[1762/1762] D loss: 1.3963, G loss: 0.7974\n",
      "train error: \n",
      " D loss: 1.312132, G loss: 0.913229, D accuracy: 52.9%, cell accuracy: 99.8%, board accuracy: 85.1% \n",
      "\n",
      "test error: \n",
      " D loss: 1.289196, G loss: 0.951942, D accuracy: 54.2%, cell accuracy: 99.8%, board accuracy: 82.3% \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3957, G loss: 0.7606\n",
      "[84/1762] D loss: 1.3944, G loss: 0.7175\n",
      "[164/1762] D loss: 1.3921, G loss: 0.7091\n",
      "[244/1762] D loss: 1.0968, G loss: 1.0855\n",
      "[324/1762] D loss: 1.0825, G loss: 0.9469\n",
      "[404/1762] D loss: 1.0812, G loss: 1.0660\n",
      "[484/1762] D loss: 0.7782, G loss: 1.2972\n",
      "[564/1762] D loss: 0.7822, G loss: 1.2416\n",
      "[644/1762] D loss: 1.3745, G loss: 0.7129\n",
      "[724/1762] D loss: 1.3914, G loss: 0.6648\n",
      "[804/1762] D loss: 1.3878, G loss: 0.7455\n",
      "[884/1762] D loss: 1.3872, G loss: 0.6302\n",
      "[964/1762] D loss: 1.1599, G loss: 1.4081\n",
      "[1044/1762] D loss: 1.0780, G loss: 1.0042\n",
      "[1124/1762] D loss: 1.3895, G loss: 0.6300\n",
      "[1204/1762] D loss: 1.3883, G loss: 0.7218\n",
      "[1284/1762] D loss: 1.3988, G loss: 0.6375\n",
      "[1364/1762] D loss: 1.3901, G loss: 0.7296\n",
      "[1444/1762] D loss: 1.3917, G loss: 0.7071\n",
      "[1524/1762] D loss: 1.3402, G loss: 0.8164\n",
      "[1604/1762] D loss: 1.3911, G loss: 0.6604\n",
      "[1684/1762] D loss: 1.0790, G loss: 1.0968\n",
      "[1762/1762] D loss: 1.4003, G loss: 0.7338\n",
      "train error: \n",
      " D loss: 1.305527, G loss: 0.760665, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 89.9% \n",
      "\n",
      "test error: \n",
      " D loss: 1.286919, G loss: 0.786915, D accuracy: 54.5%, cell accuracy: 99.8%, board accuracy: 87.0% \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.0646, G loss: 1.1359\n",
      "[84/1762] D loss: 1.3912, G loss: 0.6841\n",
      "[164/1762] D loss: 1.3890, G loss: 0.6919\n",
      "[244/1762] D loss: 1.3791, G loss: 0.6971\n",
      "[324/1762] D loss: 1.3870, G loss: 0.7146\n",
      "[404/1762] D loss: 1.3900, G loss: 0.6908\n",
      "[484/1762] D loss: 1.3909, G loss: 0.6975\n",
      "[564/1762] D loss: 1.0847, G loss: 1.0651\n",
      "[644/1762] D loss: 1.3872, G loss: 0.6782\n",
      "[724/1762] D loss: 1.3961, G loss: 0.6422\n",
      "[804/1762] D loss: 1.3942, G loss: 0.6405\n",
      "[884/1762] D loss: 1.0704, G loss: 1.0499\n",
      "[964/1762] D loss: 1.3888, G loss: 0.7336\n",
      "[1044/1762] D loss: 1.4115, G loss: 0.6325\n",
      "[1124/1762] D loss: 1.3918, G loss: 0.6547\n",
      "[1204/1762] D loss: 1.3934, G loss: 0.7095\n",
      "[1284/1762] D loss: 1.0800, G loss: 1.0307\n",
      "[1364/1762] D loss: 1.3901, G loss: 0.6848\n",
      "[1444/1762] D loss: 1.3935, G loss: 0.6836\n",
      "[1524/1762] D loss: 1.3888, G loss: 0.7151\n",
      "[1604/1762] D loss: 1.3985, G loss: 0.6266\n",
      "[1684/1762] D loss: 1.0806, G loss: 1.0520\n",
      "[1762/1762] D loss: 1.3940, G loss: 0.7251\n",
      "train error: \n",
      " D loss: 1.306062, G loss: 0.745301, D accuracy: 53.7%, cell accuracy: 99.8%, board accuracy: 90.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.284673, G loss: 0.778544, D accuracy: 54.7%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3943, G loss: 0.6009\n",
      "[84/1762] D loss: 1.3871, G loss: 0.6887\n",
      "[164/1762] D loss: 1.3923, G loss: 0.7416\n",
      "[244/1762] D loss: 1.3892, G loss: 0.7314\n",
      "[324/1762] D loss: 1.3891, G loss: 0.6559\n",
      "[404/1762] D loss: 1.3996, G loss: 0.8118\n",
      "[484/1762] D loss: 1.3964, G loss: 0.7255\n",
      "[564/1762] D loss: 1.0864, G loss: 0.9704\n",
      "[644/1762] D loss: 1.3908, G loss: 0.6480\n",
      "[724/1762] D loss: 1.3898, G loss: 0.6970\n",
      "[804/1762] D loss: 1.3882, G loss: 0.7260\n",
      "[884/1762] D loss: 1.3894, G loss: 0.6932\n",
      "[964/1762] D loss: 1.3877, G loss: 0.7000\n",
      "[1044/1762] D loss: 1.1134, G loss: 1.0526\n",
      "[1124/1762] D loss: 1.3939, G loss: 0.7402\n",
      "[1204/1762] D loss: 1.0935, G loss: 0.9264\n",
      "[1284/1762] D loss: 1.3889, G loss: 0.6990\n",
      "[1364/1762] D loss: 1.0639, G loss: 0.9593\n",
      "[1444/1762] D loss: 0.7650, G loss: 1.4382\n",
      "[1524/1762] D loss: 1.3799, G loss: 0.7079\n",
      "[1604/1762] D loss: 1.3957, G loss: 0.6052\n",
      "[1684/1762] D loss: 1.3873, G loss: 0.6819\n",
      "[1762/1762] D loss: 1.4014, G loss: 0.7867\n",
      "train error: \n",
      " D loss: 1.302958, G loss: 0.842032, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 90.6% \n",
      "\n",
      "test error: \n",
      " D loss: 1.282152, G loss: 0.876010, D accuracy: 54.4%, cell accuracy: 99.8%, board accuracy: 88.2% \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3880, G loss: 0.6994\n",
      "[84/1762] D loss: 1.3962, G loss: 0.6669\n",
      "[164/1762] D loss: 1.3889, G loss: 0.7144\n",
      "[244/1762] D loss: 1.4266, G loss: 0.6832\n",
      "[324/1762] D loss: 1.3872, G loss: 0.6805\n",
      "[404/1762] D loss: 0.7658, G loss: 1.3910\n",
      "[484/1762] D loss: 1.4101, G loss: 0.5703\n",
      "[564/1762] D loss: 1.3955, G loss: 0.7598\n",
      "[644/1762] D loss: 1.3871, G loss: 0.6849\n",
      "[724/1762] D loss: 1.0793, G loss: 1.0458\n",
      "[804/1762] D loss: 1.3902, G loss: 0.7570\n",
      "[884/1762] D loss: 1.3902, G loss: 0.6928\n",
      "[964/1762] D loss: 1.3748, G loss: 0.6613\n",
      "[1044/1762] D loss: 1.4046, G loss: 0.6296\n",
      "[1124/1762] D loss: 1.0565, G loss: 1.4157\n",
      "[1204/1762] D loss: 1.3926, G loss: 0.6463\n",
      "[1284/1762] D loss: 1.3944, G loss: 0.6891\n",
      "[1364/1762] D loss: 1.3879, G loss: 0.7059\n",
      "[1444/1762] D loss: 1.3930, G loss: 0.6089\n",
      "[1524/1762] D loss: 1.0692, G loss: 1.1722\n",
      "[1604/1762] D loss: 1.3922, G loss: 0.7410\n",
      "[1684/1762] D loss: 1.3849, G loss: 0.7056\n",
      "[1762/1762] D loss: 1.3918, G loss: 0.6534\n",
      "train error: \n",
      " D loss: 1.305918, G loss: 0.872363, D accuracy: 53.4%, cell accuracy: 99.8%, board accuracy: 89.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.283307, G loss: 0.912548, D accuracy: 54.0%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3887, G loss: 0.7484\n",
      "[84/1762] D loss: 1.3873, G loss: 0.6593\n",
      "[164/1762] D loss: 1.3684, G loss: 0.7458\n",
      "[244/1762] D loss: 1.0699, G loss: 1.1195\n",
      "[324/1762] D loss: 1.3890, G loss: 0.6129\n",
      "[404/1762] D loss: 1.4874, G loss: 0.9324\n",
      "[484/1762] D loss: 0.7617, G loss: 1.4333\n",
      "[564/1762] D loss: 1.5316, G loss: 0.6708\n",
      "[644/1762] D loss: 1.3873, G loss: 0.6586\n",
      "[724/1762] D loss: 1.0694, G loss: 1.1146\n",
      "[804/1762] D loss: 1.3869, G loss: 0.6702\n",
      "[884/1762] D loss: 1.3961, G loss: 0.7554\n",
      "[964/1762] D loss: 1.0713, G loss: 1.0798\n",
      "[1044/1762] D loss: 1.3926, G loss: 0.7500\n",
      "[1124/1762] D loss: 3.6169, G loss: 0.3287\n",
      "[1204/1762] D loss: 1.6921, G loss: 0.5992\n",
      "[1284/1762] D loss: 1.2598, G loss: 0.6133\n",
      "[1364/1762] D loss: 1.1998, G loss: 1.4128\n",
      "[1444/1762] D loss: 0.6119, G loss: 1.4700\n",
      "[1524/1762] D loss: 1.1894, G loss: 0.5848\n",
      "[1604/1762] D loss: 1.5924, G loss: 0.4999\n",
      "[1684/1762] D loss: 1.3976, G loss: 0.5305\n",
      "[1762/1762] D loss: 1.4014, G loss: 0.6451\n",
      "train error: \n",
      " D loss: 1.443167, G loss: 0.678072, D accuracy: 49.9%, cell accuracy: 99.8%, board accuracy: 86.2% \n",
      "\n",
      "test error: \n",
      " D loss: 1.457914, G loss: 0.689268, D accuracy: 49.4%, cell accuracy: 99.8%, board accuracy: 84.5% \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.4357, G loss: 0.6805\n",
      "[84/1762] D loss: 1.5474, G loss: 0.7847\n",
      "[164/1762] D loss: 1.4059, G loss: 0.6353\n",
      "[244/1762] D loss: 1.3949, G loss: 0.6232\n",
      "[324/1762] D loss: 1.6453, G loss: 0.7531\n",
      "[404/1762] D loss: 1.3917, G loss: 0.6528\n",
      "[484/1762] D loss: 1.4087, G loss: 0.5671\n",
      "[564/1762] D loss: 1.2578, G loss: 0.7224\n",
      "[644/1762] D loss: 1.3048, G loss: 0.6864\n",
      "[724/1762] D loss: 1.3128, G loss: 0.5955\n",
      "[804/1762] D loss: 1.3916, G loss: 0.6935\n",
      "[884/1762] D loss: 1.4010, G loss: 0.6960\n",
      "[964/1762] D loss: 1.4720, G loss: 0.7216\n",
      "[1044/1762] D loss: 1.2992, G loss: 0.6681\n",
      "[1124/1762] D loss: 1.3950, G loss: 0.6641\n",
      "[1204/1762] D loss: 1.4027, G loss: 0.8083\n",
      "[1284/1762] D loss: 1.4613, G loss: 0.8763\n",
      "[1364/1762] D loss: 1.3959, G loss: 0.6384\n",
      "[1444/1762] D loss: 1.3896, G loss: 0.7168\n",
      "[1524/1762] D loss: 1.3946, G loss: 0.7235\n",
      "[1604/1762] D loss: 1.4910, G loss: 0.7432\n",
      "[1684/1762] D loss: 1.5100, G loss: 0.7251\n",
      "[1762/1762] D loss: 1.3907, G loss: 0.6617\n",
      "train error: \n",
      " D loss: 1.355508, G loss: 0.737854, D accuracy: 53.6%, cell accuracy: 99.8%, board accuracy: 89.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.352528, G loss: 0.744600, D accuracy: 54.1%, cell accuracy: 99.8%, board accuracy: 86.4% \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3910, G loss: 0.7381\n",
      "[84/1762] D loss: 1.2667, G loss: 0.8481\n",
      "[164/1762] D loss: 1.3345, G loss: 0.7937\n",
      "[244/1762] D loss: 1.3908, G loss: 0.7445\n",
      "[324/1762] D loss: 1.3908, G loss: 0.6638\n",
      "[404/1762] D loss: 1.3893, G loss: 0.7255\n",
      "[484/1762] D loss: 1.3897, G loss: 0.7479\n",
      "[564/1762] D loss: 1.3878, G loss: 0.6968\n",
      "[644/1762] D loss: 1.3902, G loss: 0.7190\n",
      "[724/1762] D loss: 1.4429, G loss: 0.7280\n",
      "[804/1762] D loss: 1.3924, G loss: 0.6410\n",
      "[884/1762] D loss: 1.3870, G loss: 0.6894\n",
      "[964/1762] D loss: 1.3898, G loss: 0.7442\n",
      "[1044/1762] D loss: 1.3911, G loss: 0.7191\n",
      "[1124/1762] D loss: 1.1732, G loss: 0.8338\n",
      "[1204/1762] D loss: 1.3947, G loss: 0.6716\n",
      "[1284/1762] D loss: 1.3904, G loss: 0.7303\n",
      "[1364/1762] D loss: 1.1504, G loss: 0.7912\n",
      "[1444/1762] D loss: 1.3906, G loss: 0.6716\n",
      "[1524/1762] D loss: 1.3896, G loss: 0.7262\n",
      "[1604/1762] D loss: 1.3921, G loss: 0.7505\n",
      "[1684/1762] D loss: 1.1488, G loss: 0.8099\n",
      "[1762/1762] D loss: 1.3954, G loss: 0.6459\n",
      "train error: \n",
      " D loss: 1.326991, G loss: 0.716821, D accuracy: 53.5%, cell accuracy: 99.9%, board accuracy: 90.5% \n",
      "\n",
      "test error: \n",
      " D loss: 1.314773, G loss: 0.728700, D accuracy: 54.3%, cell accuracy: 99.8%, board accuracy: 87.5% \n",
      "\n",
      "Done!\n",
      "Epoch 0\n",
      "-------------------------------\n",
      "[4/1762] D loss: 1.3876, G loss: 0.6640\n",
      "[84/1762] D loss: 1.3841, G loss: 0.6681\n",
      "[164/1762] D loss: 1.3791, G loss: 0.6757\n",
      "[244/1762] D loss: 1.3740, G loss: 0.6815\n",
      "[324/1762] D loss: 1.3727, G loss: 0.6856\n",
      "[404/1762] D loss: 1.3703, G loss: 0.6861\n",
      "[484/1762] D loss: 1.3524, G loss: 0.7111\n",
      "[564/1762] D loss: 1.3195, G loss: 0.7394\n",
      "[644/1762] D loss: 1.2836, G loss: 0.7732\n",
      "[724/1762] D loss: 1.1805, G loss: 0.8273\n",
      "[804/1762] D loss: 1.2496, G loss: 0.8615\n",
      "[884/1762] D loss: 0.7429, G loss: 1.1917\n",
      "[964/1762] D loss: 0.4222, G loss: 1.5957\n",
      "[1044/1762] D loss: 0.5873, G loss: 1.6377\n",
      "[1124/1762] D loss: 0.2116, G loss: 2.4540\n",
      "[1204/1762] D loss: 0.3031, G loss: 2.0771\n",
      "[1284/1762] D loss: 0.1634, G loss: 2.4842\n",
      "[1364/1762] D loss: 0.5265, G loss: 1.8451\n",
      "[1444/1762] D loss: 0.2602, G loss: 2.6888\n",
      "[1524/1762] D loss: 0.0228, G loss: 4.0528\n",
      "[1604/1762] D loss: 0.2430, G loss: 2.8814\n",
      "[1684/1762] D loss: 0.0908, G loss: 4.3669\n",
      "[1762/1762] D loss: 0.0766, G loss: 3.6064\n",
      "train error: \n",
      " D loss: 0.144659, G loss: 4.016777, D accuracy: 97.5%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.165493, G loss: 4.038957, D accuracy: 96.2%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0678, G loss: 4.1478\n",
      "[84/1762] D loss: 0.1190, G loss: 3.2546\n",
      "[164/1762] D loss: 0.2966, G loss: 3.3120\n",
      "[244/1762] D loss: 0.2778, G loss: 2.9704\n",
      "[324/1762] D loss: 0.0404, G loss: 4.1420\n",
      "[404/1762] D loss: 0.1489, G loss: 4.0612\n",
      "[484/1762] D loss: 0.0545, G loss: 3.9284\n",
      "[564/1762] D loss: 0.0288, G loss: 5.3678\n",
      "[644/1762] D loss: 0.1600, G loss: 4.3867\n",
      "[724/1762] D loss: 0.0079, G loss: 6.1096\n",
      "[804/1762] D loss: 0.0355, G loss: 5.4348\n",
      "[884/1762] D loss: 0.0080, G loss: 5.9179\n",
      "[964/1762] D loss: 0.0317, G loss: 4.1200\n",
      "[1044/1762] D loss: 0.2530, G loss: 6.3412\n",
      "[1124/1762] D loss: 0.0434, G loss: 4.4900\n",
      "[1204/1762] D loss: 0.0174, G loss: 6.3885\n",
      "[1284/1762] D loss: 0.0601, G loss: 4.7684\n",
      "[1364/1762] D loss: 0.0274, G loss: 4.9595\n",
      "[1444/1762] D loss: 0.0110, G loss: 5.2818\n",
      "[1524/1762] D loss: 0.0440, G loss: 5.0153\n",
      "[1604/1762] D loss: 0.0472, G loss: 3.5813\n",
      "[1684/1762] D loss: 0.0050, G loss: 6.4466\n",
      "[1762/1762] D loss: 0.0003, G loss: 8.1555\n",
      "train error: \n",
      " D loss: 0.034980, G loss: 5.608038, D accuracy: 99.9%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.044106, G loss: 5.644200, D accuracy: 99.8%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.1063, G loss: 4.3501\n",
      "[84/1762] D loss: 0.0007, G loss: 7.6111\n",
      "[164/1762] D loss: 0.0310, G loss: 4.7088\n",
      "[244/1762] D loss: 0.0106, G loss: 5.4678\n",
      "[324/1762] D loss: 0.1527, G loss: 3.7953\n",
      "[404/1762] D loss: 0.0453, G loss: 6.5503\n",
      "[484/1762] D loss: 0.0125, G loss: 5.1765\n",
      "[564/1762] D loss: 0.0163, G loss: 6.6308\n",
      "[644/1762] D loss: 0.0069, G loss: 6.3639\n",
      "[724/1762] D loss: 0.0442, G loss: 5.4362\n",
      "[804/1762] D loss: 0.0011, G loss: 7.3405\n",
      "[884/1762] D loss: 0.1277, G loss: 4.7164\n",
      "[964/1762] D loss: 0.0011, G loss: 7.7554\n",
      "[1044/1762] D loss: 0.3089, G loss: 5.5427\n",
      "[1124/1762] D loss: 0.0031, G loss: 6.3975\n",
      "[1204/1762] D loss: 0.0658, G loss: 5.4867\n",
      "[1284/1762] D loss: 0.0186, G loss: 6.3442\n",
      "[1364/1762] D loss: 0.0764, G loss: 5.1126\n",
      "[1444/1762] D loss: 0.0047, G loss: 7.7657\n",
      "[1524/1762] D loss: 0.0021, G loss: 7.9820\n",
      "[1604/1762] D loss: 0.0109, G loss: 4.8879\n",
      "[1684/1762] D loss: 0.0073, G loss: 7.7394\n",
      "[1762/1762] D loss: 0.0106, G loss: 6.5401\n",
      "train error: \n",
      " D loss: 0.018646, G loss: 7.310538, D accuracy: 99.7%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.027321, G loss: 7.341030, D accuracy: 99.7%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0020, G loss: 8.1216\n",
      "[84/1762] D loss: 0.0003, G loss: 8.9763\n",
      "[164/1762] D loss: 0.0026, G loss: 7.2504\n",
      "[244/1762] D loss: 0.0001, G loss: 9.3526\n",
      "[324/1762] D loss: 0.0015, G loss: 8.8956\n",
      "[404/1762] D loss: 0.0084, G loss: 5.9610\n",
      "[484/1762] D loss: 0.0072, G loss: 6.0108\n",
      "[564/1762] D loss: 0.0030, G loss: 7.5020\n",
      "[644/1762] D loss: 0.0011, G loss: 7.4567\n",
      "[724/1762] D loss: 0.0002, G loss: 9.5963\n",
      "[804/1762] D loss: 0.0047, G loss: 6.5150\n",
      "[884/1762] D loss: 0.0005, G loss: 8.0648\n",
      "[964/1762] D loss: 0.0054, G loss: 7.3361\n",
      "[1044/1762] D loss: 0.0316, G loss: 6.0035\n",
      "[1124/1762] D loss: 0.0318, G loss: 6.1741\n",
      "[1204/1762] D loss: 0.0176, G loss: 7.5000\n",
      "[1284/1762] D loss: 0.0012, G loss: 8.1762\n",
      "[1364/1762] D loss: 0.0188, G loss: 5.8749\n",
      "[1444/1762] D loss: 0.0018, G loss: 6.8134\n",
      "[1524/1762] D loss: 0.0504, G loss: 7.4044\n",
      "[1604/1762] D loss: 0.0015, G loss: 7.4036\n",
      "[1684/1762] D loss: 0.0007, G loss: 8.4768\n",
      "[1762/1762] D loss: 0.0005, G loss: 7.7410\n",
      "train error: \n",
      " D loss: 0.010576, G loss: 8.114498, D accuracy: 99.9%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.016149, G loss: 8.149278, D accuracy: 99.8%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0103, G loss: 8.5505\n",
      "[84/1762] D loss: 0.0020, G loss: 6.5112\n",
      "[164/1762] D loss: 0.0574, G loss: 8.1730\n",
      "[244/1762] D loss: 0.0012, G loss: 9.1877\n",
      "[324/1762] D loss: 0.0028, G loss: 6.1191\n",
      "[404/1762] D loss: 0.0007, G loss: 8.9290\n",
      "[484/1762] D loss: 0.0011, G loss: 8.9863\n",
      "[564/1762] D loss: 0.0127, G loss: 7.9890\n",
      "[644/1762] D loss: 0.0007, G loss: 7.5931\n",
      "[724/1762] D loss: 0.0016, G loss: 9.2124\n",
      "[804/1762] D loss: 0.0002, G loss: 9.9729\n",
      "[884/1762] D loss: 0.0025, G loss: 7.2492\n",
      "[964/1762] D loss: 0.0245, G loss: 6.3571\n",
      "[1044/1762] D loss: 0.0018, G loss: 8.2246\n",
      "[1124/1762] D loss: 0.0002, G loss: 9.1276\n",
      "[1204/1762] D loss: 0.0096, G loss: 8.0577\n",
      "[1284/1762] D loss: 0.0030, G loss: 7.3475\n",
      "[1364/1762] D loss: 0.0002, G loss: 9.2374\n",
      "[1444/1762] D loss: 0.0001, G loss: 10.1400\n",
      "[1524/1762] D loss: 0.0008, G loss: 8.2048\n",
      "[1604/1762] D loss: 0.0402, G loss: 6.4786\n",
      "[1684/1762] D loss: 0.0072, G loss: 6.5776\n",
      "[1762/1762] D loss: 0.0727, G loss: 5.4266\n",
      "train error: \n",
      " D loss: 0.025811, G loss: 7.275254, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.031624, G loss: 7.340974, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0163, G loss: 5.8657\n",
      "[84/1762] D loss: 0.0029, G loss: 8.3710\n",
      "[164/1762] D loss: 0.0001, G loss: 9.8995\n",
      "[244/1762] D loss: 0.0223, G loss: 6.8936\n",
      "[324/1762] D loss: 0.0012, G loss: 7.9619\n",
      "[404/1762] D loss: 0.0004, G loss: 8.3720\n",
      "[484/1762] D loss: 0.0002, G loss: 9.9980\n",
      "[564/1762] D loss: 0.0050, G loss: 7.5908\n",
      "[644/1762] D loss: 0.0087, G loss: 8.1229\n",
      "[724/1762] D loss: 0.0030, G loss: 7.3740\n",
      "[804/1762] D loss: 0.0152, G loss: 7.4361\n",
      "[884/1762] D loss: 0.0012, G loss: 9.3637\n",
      "[964/1762] D loss: 0.0002, G loss: 9.3553\n",
      "[1044/1762] D loss: 0.0001, G loss: 10.6117\n",
      "[1124/1762] D loss: 0.0162, G loss: 7.3875\n",
      "[1204/1762] D loss: 0.0000, G loss: 12.0656\n",
      "[1284/1762] D loss: 0.0249, G loss: 6.8677\n",
      "[1364/1762] D loss: 0.0004, G loss: 8.6194\n",
      "[1444/1762] D loss: 0.0001, G loss: 9.8412\n",
      "[1524/1762] D loss: 0.0004, G loss: 9.6516\n",
      "[1604/1762] D loss: 0.0008, G loss: 9.1202\n",
      "[1684/1762] D loss: 0.0040, G loss: 9.0929\n",
      "[1762/1762] D loss: 0.0000, G loss: 11.6091\n",
      "train error: \n",
      " D loss: 0.008620, G loss: 8.342398, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.011318, G loss: 8.402283, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0004, G loss: 7.9747\n",
      "[84/1762] D loss: 0.0379, G loss: 4.7412\n",
      "[164/1762] D loss: 0.0001, G loss: 10.2663\n",
      "[244/1762] D loss: 0.0006, G loss: 9.1012\n",
      "[324/1762] D loss: 0.0003, G loss: 8.2428\n",
      "[404/1762] D loss: 0.0000, G loss: 12.7144\n",
      "[484/1762] D loss: 0.0001, G loss: 10.7251\n",
      "[564/1762] D loss: 0.0001, G loss: 11.2208\n",
      "[644/1762] D loss: 0.0006, G loss: 8.4269\n",
      "[724/1762] D loss: 0.0003, G loss: 9.6746\n",
      "[804/1762] D loss: 0.0024, G loss: 10.6820\n",
      "[884/1762] D loss: 0.0003, G loss: 8.4922\n",
      "[964/1762] D loss: 0.0044, G loss: 9.5287\n",
      "[1044/1762] D loss: 0.0016, G loss: 7.9785\n",
      "[1124/1762] D loss: 0.0047, G loss: 7.4913\n",
      "[1204/1762] D loss: 0.0036, G loss: 7.8613\n",
      "[1284/1762] D loss: 0.0000, G loss: 12.7163\n",
      "[1364/1762] D loss: 0.0157, G loss: 9.4129\n",
      "[1444/1762] D loss: 0.0001, G loss: 10.4618\n",
      "[1524/1762] D loss: 0.3305, G loss: 8.2096\n",
      "[1604/1762] D loss: 0.0009, G loss: 9.1702\n",
      "[1684/1762] D loss: 0.0001, G loss: 9.5279\n",
      "[1762/1762] D loss: 0.0002, G loss: 11.0333\n",
      "train error: \n",
      " D loss: 0.004375, G loss: 9.703090, D accuracy: 99.9%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.007451, G loss: 9.737214, D accuracy: 99.8%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0038, G loss: 9.1058\n",
      "[84/1762] D loss: 0.0005, G loss: 8.3594\n",
      "[164/1762] D loss: 0.0000, G loss: 10.8678\n",
      "[244/1762] D loss: 0.0111, G loss: 6.7308\n",
      "[324/1762] D loss: 0.0001, G loss: 10.6465\n",
      "[404/1762] D loss: 0.0000, G loss: 10.6236\n",
      "[484/1762] D loss: 0.0002, G loss: 10.0422\n",
      "[564/1762] D loss: 0.0028, G loss: 11.3514\n",
      "[644/1762] D loss: 0.0002, G loss: 8.9836\n",
      "[724/1762] D loss: 0.0023, G loss: 8.7946\n",
      "[804/1762] D loss: 0.0004, G loss: 10.4445\n",
      "[884/1762] D loss: 0.0001, G loss: 10.3938\n",
      "[964/1762] D loss: 0.0075, G loss: 7.3117\n",
      "[1044/1762] D loss: 0.0007, G loss: 8.0965\n",
      "[1124/1762] D loss: 0.0000, G loss: 12.5586\n",
      "[1204/1762] D loss: 0.0072, G loss: 10.3203\n",
      "[1284/1762] D loss: 0.0001, G loss: 10.6623\n",
      "[1364/1762] D loss: 0.0004, G loss: 10.0427\n",
      "[1444/1762] D loss: 0.2233, G loss: 8.3309\n",
      "[1524/1762] D loss: 0.0313, G loss: 7.0887\n",
      "[1604/1762] D loss: 0.0022, G loss: 7.1775\n",
      "[1684/1762] D loss: 0.0000, G loss: 13.7763\n",
      "[1762/1762] D loss: 0.0000, G loss: 14.1551\n",
      "train error: \n",
      " D loss: 0.003767, G loss: 10.190825, D accuracy: 99.9%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.006630, G loss: 10.227648, D accuracy: 99.8%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001, G loss: 11.3161\n",
      "[84/1762] D loss: 0.0001, G loss: 10.0434\n",
      "[164/1762] D loss: 0.0001, G loss: 9.8462\n",
      "[244/1762] D loss: 0.0301, G loss: 10.3860\n",
      "[324/1762] D loss: 0.0000, G loss: 11.9859\n",
      "[404/1762] D loss: 0.0001, G loss: 9.8302\n",
      "[484/1762] D loss: 0.0002, G loss: 10.3969\n",
      "[564/1762] D loss: 0.0017, G loss: 8.5386\n",
      "[644/1762] D loss: 0.0012, G loss: 10.7380\n",
      "[724/1762] D loss: 0.0000, G loss: 11.5853\n",
      "[804/1762] D loss: 0.0004, G loss: 9.8402\n",
      "[884/1762] D loss: 0.0010, G loss: 10.0581\n",
      "[964/1762] D loss: 0.0021, G loss: 8.0181\n",
      "[1044/1762] D loss: 0.0001, G loss: 9.8677\n",
      "[1124/1762] D loss: 0.0002, G loss: 9.5592\n",
      "[1204/1762] D loss: 0.0001, G loss: 9.5429\n",
      "[1284/1762] D loss: 0.0000, G loss: 11.2435\n",
      "[1364/1762] D loss: 0.0001, G loss: 11.6456\n",
      "[1444/1762] D loss: 0.0002, G loss: 10.4231\n",
      "[1524/1762] D loss: 0.0001, G loss: 10.3123\n",
      "[1604/1762] D loss: 0.0001, G loss: 11.1201\n",
      "[1684/1762] D loss: 0.0249, G loss: 8.7021\n",
      "[1762/1762] D loss: 0.0189, G loss: 4.8154\n",
      "train error: \n",
      " D loss: 0.002489, G loss: 9.801343, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.003600, G loss: 9.848124, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0008, G loss: 7.9157\n",
      "[84/1762] D loss: 0.0002, G loss: 10.0347\n",
      "[164/1762] D loss: 0.0046, G loss: 8.0618\n",
      "[244/1762] D loss: 0.0002, G loss: 8.7659\n",
      "[324/1762] D loss: 0.0001, G loss: 10.4377\n",
      "[404/1762] D loss: 0.0004, G loss: 9.9209\n",
      "[484/1762] D loss: 0.0013, G loss: 9.5513\n",
      "[564/1762] D loss: 0.0010, G loss: 10.4701\n",
      "[644/1762] D loss: 0.0001, G loss: 10.8176\n",
      "[724/1762] D loss: 0.0013, G loss: 10.5536\n",
      "[804/1762] D loss: 0.0007, G loss: 9.9494\n",
      "[884/1762] D loss: 0.0000, G loss: 11.6503\n",
      "[964/1762] D loss: 0.0034, G loss: 10.2440\n",
      "[1044/1762] D loss: 0.0058, G loss: 6.4602\n",
      "[1124/1762] D loss: 0.0004, G loss: 9.4885\n",
      "[1204/1762] D loss: 0.0001, G loss: 10.7437\n",
      "[1284/1762] D loss: 0.0002, G loss: 10.2196\n",
      "[1364/1762] D loss: 0.0000, G loss: 12.8197\n",
      "[1444/1762] D loss: 0.0009, G loss: 9.5585\n",
      "[1524/1762] D loss: 0.0030, G loss: 10.9573\n",
      "[1604/1762] D loss: 0.0001, G loss: 10.2913\n",
      "[1684/1762] D loss: 0.0014, G loss: 9.9740\n",
      "[1762/1762] D loss: 0.0000, G loss: 10.8491\n",
      "train error: \n",
      " D loss: 0.002881, G loss: 9.791493, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.003863, G loss: 9.843009, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0002, G loss: 10.6466\n",
      "[84/1762] D loss: 0.0063, G loss: 10.6104\n",
      "[164/1762] D loss: 0.0003, G loss: 9.7812\n",
      "[244/1762] D loss: 0.0008, G loss: 10.4167\n",
      "[324/1762] D loss: 0.0002, G loss: 10.2477\n",
      "[404/1762] D loss: 0.0000, G loss: 11.8662\n",
      "[484/1762] D loss: 0.0035, G loss: 7.9715\n",
      "[564/1762] D loss: 0.0003, G loss: 8.9880\n",
      "[644/1762] D loss: 0.0000, G loss: 11.9352\n",
      "[724/1762] D loss: 0.0048, G loss: 10.1879\n",
      "[804/1762] D loss: 0.0000, G loss: 11.5748\n",
      "[884/1762] D loss: 0.0000, G loss: 13.0918\n",
      "[964/1762] D loss: 0.0008, G loss: 7.9391\n",
      "[1044/1762] D loss: 0.0001, G loss: 10.6563\n",
      "[1124/1762] D loss: 0.0003, G loss: 9.8591\n",
      "[1204/1762] D loss: 0.0002, G loss: 11.4752\n",
      "[1284/1762] D loss: 0.0018, G loss: 10.7932\n",
      "[1364/1762] D loss: 0.0002, G loss: 8.7338\n",
      "[1444/1762] D loss: 0.0005, G loss: 8.6291\n",
      "[1524/1762] D loss: 0.0003, G loss: 10.9306\n",
      "[1604/1762] D loss: 0.0009, G loss: 8.7608\n",
      "[1684/1762] D loss: 0.0007, G loss: 9.5288\n",
      "[1762/1762] D loss: 0.0002, G loss: 9.9019\n",
      "train error: \n",
      " D loss: 0.001239, G loss: 10.904821, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.002031, G loss: 10.944707, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001, G loss: 10.5887\n",
      "[84/1762] D loss: 0.0000, G loss: 12.9972\n",
      "[164/1762] D loss: 0.0007, G loss: 10.4500\n",
      "[244/1762] D loss: 0.0000, G loss: 11.1098\n",
      "[324/1762] D loss: 0.0000, G loss: 12.1835\n",
      "[404/1762] D loss: 0.0013, G loss: 10.7267\n",
      "[484/1762] D loss: 0.0000, G loss: 11.3820\n",
      "[564/1762] D loss: 0.0001, G loss: 11.3734\n",
      "[644/1762] D loss: 0.0002, G loss: 11.4543\n",
      "[724/1762] D loss: 0.0040, G loss: 8.5878\n",
      "[804/1762] D loss: 0.0002, G loss: 9.4198\n",
      "[884/1762] D loss: 0.0000, G loss: 11.9755\n",
      "[964/1762] D loss: 0.0001, G loss: 10.5190\n",
      "[1044/1762] D loss: 0.0005, G loss: 7.8833\n",
      "[1124/1762] D loss: 0.0000, G loss: 11.6235\n",
      "[1204/1762] D loss: 0.0002, G loss: 9.5715\n",
      "[1284/1762] D loss: 0.0005, G loss: 10.1055\n",
      "[1364/1762] D loss: 0.0006, G loss: 10.4129\n",
      "[1444/1762] D loss: 0.0045, G loss: 11.6709\n",
      "[1524/1762] D loss: 0.0000, G loss: 11.7343\n",
      "[1604/1762] D loss: 0.0000, G loss: 13.5426\n",
      "[1684/1762] D loss: 0.0003, G loss: 9.4853\n",
      "[1762/1762] D loss: 0.0000, G loss: 12.9290\n",
      "train error: \n",
      " D loss: 0.001075, G loss: 11.393859, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.001814, G loss: 11.438665, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 12.9121\n",
      "[84/1762] D loss: 0.0001, G loss: 11.0415\n",
      "[164/1762] D loss: 0.0022, G loss: 11.0344\n",
      "[244/1762] D loss: 0.0000, G loss: 12.2060\n",
      "[324/1762] D loss: 0.0052, G loss: 10.5071\n",
      "[404/1762] D loss: 0.0001, G loss: 9.8776\n",
      "[484/1762] D loss: 0.0004, G loss: 8.0887\n",
      "[564/1762] D loss: 0.0001, G loss: 10.1238\n",
      "[644/1762] D loss: 0.0001, G loss: 12.2296\n",
      "[724/1762] D loss: 0.0002, G loss: 11.1725\n",
      "[804/1762] D loss: 0.0018, G loss: 9.0388\n",
      "[884/1762] D loss: 0.0000, G loss: 13.1995\n",
      "[964/1762] D loss: 0.0000, G loss: 13.2702\n",
      "[1044/1762] D loss: 0.0000, G loss: 13.0412\n",
      "[1124/1762] D loss: 0.0000, G loss: 13.2804\n",
      "[1204/1762] D loss: 0.0000, G loss: 11.6361\n",
      "[1284/1762] D loss: 0.0001, G loss: 12.5000\n",
      "[1364/1762] D loss: 0.0000, G loss: 12.1131\n",
      "[1444/1762] D loss: 0.0000, G loss: 11.7611\n",
      "[1524/1762] D loss: 0.0000, G loss: 11.8528\n",
      "[1604/1762] D loss: 0.0001, G loss: 10.7244\n",
      "[1684/1762] D loss: 0.0002, G loss: 11.0797\n",
      "[1762/1762] D loss: 0.0000, G loss: 13.4832\n",
      "train error: \n",
      " D loss: 0.000757, G loss: 11.653200, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.001245, G loss: 11.701074, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 13.1003\n",
      "[84/1762] D loss: 0.0001, G loss: 12.3605\n",
      "[164/1762] D loss: 0.0056, G loss: 9.5133\n",
      "[244/1762] D loss: 0.0030, G loss: 9.5997\n",
      "[324/1762] D loss: 0.0001, G loss: 12.6719\n",
      "[404/1762] D loss: 0.0000, G loss: 12.6551\n",
      "[484/1762] D loss: 0.0001, G loss: 10.3683\n",
      "[564/1762] D loss: 0.0001, G loss: 11.1582\n",
      "[644/1762] D loss: 0.0000, G loss: 15.7624\n",
      "[724/1762] D loss: 0.0000, G loss: 14.0093\n",
      "[804/1762] D loss: 0.0001, G loss: 11.3207\n",
      "[884/1762] D loss: 0.0029, G loss: 8.7835\n",
      "[964/1762] D loss: 0.0000, G loss: 15.3794\n",
      "[1044/1762] D loss: 0.0001, G loss: 11.1425\n",
      "[1124/1762] D loss: 0.0001, G loss: 11.9043\n",
      "[1204/1762] D loss: 0.0001, G loss: 12.4998\n",
      "[1284/1762] D loss: 0.0000, G loss: 12.6229\n",
      "[1364/1762] D loss: 0.0000, G loss: 12.9470\n",
      "[1444/1762] D loss: 0.0000, G loss: 12.5876\n",
      "[1524/1762] D loss: 0.0014, G loss: 10.1595\n",
      "[1604/1762] D loss: 0.0000, G loss: 10.4005\n",
      "[1684/1762] D loss: 0.0000, G loss: 13.9560\n",
      "[1762/1762] D loss: 0.0010, G loss: 8.0412\n",
      "train error: \n",
      " D loss: 0.000801, G loss: 12.235398, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.001378, G loss: 12.289985, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001, G loss: 10.4847\n",
      "[84/1762] D loss: 0.0000, G loss: 11.9177\n",
      "[164/1762] D loss: 0.0000, G loss: 10.6521\n",
      "[244/1762] D loss: 0.0000, G loss: 11.8485\n",
      "[324/1762] D loss: 0.0000, G loss: 11.4914\n",
      "[404/1762] D loss: 0.0001, G loss: 11.4923\n",
      "[484/1762] D loss: 0.0000, G loss: 12.3938\n",
      "[564/1762] D loss: 0.0008, G loss: 10.3781\n",
      "[644/1762] D loss: 0.0002, G loss: 10.7697\n",
      "[724/1762] D loss: 0.0000, G loss: 13.7940\n",
      "[804/1762] D loss: 0.0000, G loss: 12.2344\n",
      "[884/1762] D loss: 0.0002, G loss: 12.1204\n",
      "[964/1762] D loss: 0.0002, G loss: 10.4894\n",
      "[1044/1762] D loss: 0.0000, G loss: 13.0776\n",
      "[1124/1762] D loss: 0.0001, G loss: 12.2728\n",
      "[1204/1762] D loss: 0.0000, G loss: 12.2810\n",
      "[1284/1762] D loss: 0.0000, G loss: 12.1890\n",
      "[1364/1762] D loss: 0.0001, G loss: 12.2333\n",
      "[1444/1762] D loss: 0.0000, G loss: 11.7641\n",
      "[1524/1762] D loss: 0.0000, G loss: 14.7556\n",
      "[1604/1762] D loss: 0.0006, G loss: 11.8679\n",
      "[1684/1762] D loss: 0.0000, G loss: 14.9461\n",
      "[1762/1762] D loss: 0.0005, G loss: 11.3966\n",
      "train error: \n",
      " D loss: 0.000528, G loss: 12.512254, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000891, G loss: 12.569123, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0002, G loss: 10.7678\n",
      "[84/1762] D loss: 0.0001, G loss: 11.3403\n",
      "[164/1762] D loss: 0.0000, G loss: 11.3832\n",
      "[244/1762] D loss: 0.0001, G loss: 10.1754\n",
      "[324/1762] D loss: 0.0001, G loss: 11.9744\n",
      "[404/1762] D loss: 0.0000, G loss: 14.2421\n",
      "[484/1762] D loss: 0.0000, G loss: 11.0502\n",
      "[564/1762] D loss: 0.0000, G loss: 14.2012\n",
      "[644/1762] D loss: 0.0000, G loss: 16.7401\n",
      "[724/1762] D loss: 0.0004, G loss: 12.0032\n",
      "[804/1762] D loss: 0.0003, G loss: 12.4693\n",
      "[884/1762] D loss: 0.0001, G loss: 11.0990\n",
      "[964/1762] D loss: 0.0000, G loss: 13.2135\n",
      "[1044/1762] D loss: 0.0000, G loss: 16.1789\n",
      "[1124/1762] D loss: 0.0000, G loss: 12.3944\n",
      "[1204/1762] D loss: 0.0000, G loss: 14.0629\n",
      "[1284/1762] D loss: 0.0000, G loss: 12.4207\n",
      "[1364/1762] D loss: 0.0025, G loss: 10.9500\n",
      "[1444/1762] D loss: 0.0000, G loss: 12.8018\n",
      "[1524/1762] D loss: 0.0000, G loss: 15.7396\n",
      "[1604/1762] D loss: 0.0000, G loss: 13.4797\n",
      "[1684/1762] D loss: 0.0015, G loss: 10.9519\n",
      "[1762/1762] D loss: 0.0000, G loss: 13.4353\n",
      "train error: \n",
      " D loss: 0.000320, G loss: 12.676936, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000509, G loss: 12.735123, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 12.9113\n",
      "[84/1762] D loss: 0.0000, G loss: 13.2281\n",
      "[164/1762] D loss: 0.0000, G loss: 10.7002\n",
      "[244/1762] D loss: 0.0000, G loss: 12.8900\n",
      "[324/1762] D loss: 0.0000, G loss: 14.0384\n",
      "[404/1762] D loss: 0.0000, G loss: 13.5307\n",
      "[484/1762] D loss: 0.0000, G loss: 14.2321\n",
      "[564/1762] D loss: 0.0000, G loss: 13.8756\n",
      "[644/1762] D loss: 0.0000, G loss: 14.2020\n",
      "[724/1762] D loss: 0.0000, G loss: 14.2988\n",
      "[804/1762] D loss: 0.0002, G loss: 10.8390\n",
      "[884/1762] D loss: 0.0001, G loss: 11.2435\n",
      "[964/1762] D loss: 0.0000, G loss: 13.2863\n",
      "[1044/1762] D loss: 0.0001, G loss: 12.1109\n",
      "[1124/1762] D loss: 0.0000, G loss: 12.2831\n",
      "[1204/1762] D loss: 0.0000, G loss: 15.1987\n",
      "[1284/1762] D loss: 0.0007, G loss: 11.3850\n",
      "[1364/1762] D loss: 0.0000, G loss: 12.8536\n",
      "[1444/1762] D loss: 0.0000, G loss: 13.9888\n",
      "[1524/1762] D loss: 0.0014, G loss: 10.6177\n",
      "[1604/1762] D loss: 0.0005, G loss: 11.0400\n",
      "[1684/1762] D loss: 0.0000, G loss: 13.0774\n",
      "[1762/1762] D loss: 0.0000, G loss: 13.1655\n",
      "train error: \n",
      " D loss: 0.000237, G loss: 12.909160, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000352, G loss: 12.974747, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0001, G loss: 11.9973\n",
      "[84/1762] D loss: 0.0000, G loss: 12.5520\n",
      "[164/1762] D loss: 0.0001, G loss: 14.1000\n",
      "[244/1762] D loss: 0.0000, G loss: 15.5233\n",
      "[324/1762] D loss: 0.0001, G loss: 13.4912\n",
      "[404/1762] D loss: 0.0001, G loss: 12.0232\n",
      "[484/1762] D loss: 0.0000, G loss: 12.3235\n",
      "[564/1762] D loss: 0.0000, G loss: 14.7751\n",
      "[644/1762] D loss: 0.0000, G loss: 13.6966\n",
      "[724/1762] D loss: 0.0000, G loss: 15.6997\n",
      "[804/1762] D loss: 0.0000, G loss: 15.1519\n",
      "[884/1762] D loss: 0.0000, G loss: 14.7990\n",
      "[964/1762] D loss: 0.0000, G loss: 11.8311\n",
      "[1044/1762] D loss: 0.0001, G loss: 11.2734\n",
      "[1124/1762] D loss: 0.0000, G loss: 16.2278\n",
      "[1204/1762] D loss: 0.0004, G loss: 12.8906\n",
      "[1284/1762] D loss: 0.0000, G loss: 15.5664\n",
      "[1364/1762] D loss: 0.0000, G loss: 12.6784\n",
      "[1444/1762] D loss: 0.0000, G loss: 13.5578\n",
      "[1524/1762] D loss: 0.0000, G loss: 14.7834\n",
      "[1604/1762] D loss: 0.0000, G loss: 13.0701\n",
      "[1684/1762] D loss: 0.0000, G loss: 14.7877\n",
      "[1762/1762] D loss: 0.0000, G loss: 11.9794\n",
      "train error: \n",
      " D loss: 0.000323, G loss: 13.853690, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000552, G loss: 13.916094, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0058, G loss: 10.5343\n",
      "[84/1762] D loss: 0.0000, G loss: 15.7934\n",
      "[164/1762] D loss: 0.0000, G loss: 16.0124\n",
      "[244/1762] D loss: 0.0033, G loss: 10.5357\n",
      "[324/1762] D loss: 0.0010, G loss: 10.6104\n",
      "[404/1762] D loss: 0.0000, G loss: 14.1670\n",
      "[484/1762] D loss: 0.0000, G loss: 15.2435\n",
      "[564/1762] D loss: 0.0000, G loss: 12.7420\n",
      "[644/1762] D loss: 0.0006, G loss: 10.9915\n",
      "[724/1762] D loss: 0.0000, G loss: 14.2274\n",
      "[804/1762] D loss: 0.0000, G loss: 14.6185\n",
      "[884/1762] D loss: 0.0000, G loss: 13.9754\n",
      "[964/1762] D loss: 0.0000, G loss: 14.9285\n",
      "[1044/1762] D loss: 0.0000, G loss: 11.8092\n",
      "[1124/1762] D loss: 0.0000, G loss: 14.1166\n",
      "[1204/1762] D loss: 0.0000, G loss: 13.6882\n",
      "[1284/1762] D loss: 0.0000, G loss: 16.5173\n",
      "[1364/1762] D loss: 0.0000, G loss: 14.0888\n",
      "[1444/1762] D loss: 0.0000, G loss: 15.3526\n",
      "[1524/1762] D loss: 0.0000, G loss: 12.2129\n",
      "[1604/1762] D loss: 0.0000, G loss: 11.9528\n",
      "[1684/1762] D loss: 0.0000, G loss: 13.6403\n",
      "[1762/1762] D loss: 0.0000, G loss: 16.8892\n",
      "train error: \n",
      " D loss: 0.000166, G loss: 14.035804, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000275, G loss: 14.102576, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 13.2545\n",
      "[84/1762] D loss: 0.0001, G loss: 12.3203\n",
      "[164/1762] D loss: 0.0000, G loss: 14.5700\n",
      "[244/1762] D loss: 0.0000, G loss: 12.2887\n",
      "[324/1762] D loss: 0.0000, G loss: 13.3794\n",
      "[404/1762] D loss: 0.0000, G loss: 15.7055\n",
      "[484/1762] D loss: 0.0001, G loss: 12.4576\n",
      "[564/1762] D loss: 0.0000, G loss: 12.9398\n",
      "[644/1762] D loss: 0.0000, G loss: 12.4791\n",
      "[724/1762] D loss: 0.0002, G loss: 14.3235\n",
      "[804/1762] D loss: 0.0000, G loss: 14.8237\n",
      "[884/1762] D loss: 0.0003, G loss: 12.7281\n",
      "[964/1762] D loss: 0.0000, G loss: 17.4427\n",
      "[1044/1762] D loss: 0.0005, G loss: 11.5416\n",
      "[1124/1762] D loss: 0.0002, G loss: 12.7227\n",
      "[1204/1762] D loss: 0.0000, G loss: 11.7956\n",
      "[1284/1762] D loss: 0.0030, G loss: 10.3080\n",
      "[1364/1762] D loss: 0.0000, G loss: 15.0078\n",
      "[1444/1762] D loss: 0.0000, G loss: 12.8789\n",
      "[1524/1762] D loss: 0.0000, G loss: 13.4948\n",
      "[1604/1762] D loss: 0.0000, G loss: 14.0514\n",
      "[1684/1762] D loss: 0.0000, G loss: 12.1141\n",
      "[1762/1762] D loss: 0.0002, G loss: 11.4471\n",
      "train error: \n",
      " D loss: 0.000109, G loss: 14.207716, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000167, G loss: 14.275107, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 13.0259\n",
      "[84/1762] D loss: 0.0000, G loss: 13.4701\n",
      "[164/1762] D loss: 0.0000, G loss: 15.0997\n",
      "[244/1762] D loss: 0.0000, G loss: 13.9227\n",
      "[324/1762] D loss: 0.0000, G loss: 14.4136\n",
      "[404/1762] D loss: 0.0000, G loss: 17.6157\n",
      "[484/1762] D loss: 0.0002, G loss: 12.6426\n",
      "[564/1762] D loss: 0.0000, G loss: 16.3918\n",
      "[644/1762] D loss: 0.0000, G loss: 15.3787\n",
      "[724/1762] D loss: 0.0000, G loss: 18.6696\n",
      "[804/1762] D loss: 0.0000, G loss: 12.8629\n",
      "[884/1762] D loss: 0.0000, G loss: 16.5627\n",
      "[964/1762] D loss: 0.0000, G loss: 15.9258\n",
      "[1044/1762] D loss: 0.0000, G loss: 16.1437\n",
      "[1124/1762] D loss: 0.0000, G loss: 15.3723\n",
      "[1204/1762] D loss: 0.0000, G loss: 13.9859\n",
      "[1284/1762] D loss: 0.0000, G loss: 12.2852\n",
      "[1364/1762] D loss: 0.0000, G loss: 14.8024\n",
      "[1444/1762] D loss: 0.0000, G loss: 13.2953\n",
      "[1524/1762] D loss: 0.0001, G loss: 13.5975\n",
      "[1604/1762] D loss: 0.0000, G loss: 12.6469\n",
      "[1684/1762] D loss: 0.0000, G loss: 12.2600\n",
      "[1762/1762] D loss: 0.0000, G loss: 15.4181\n",
      "train error: \n",
      " D loss: 0.000083, G loss: 14.562517, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000125, G loss: 14.634461, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 13.6277\n",
      "[84/1762] D loss: 0.0000, G loss: 17.3103\n",
      "[164/1762] D loss: 0.0000, G loss: 14.7369\n",
      "[244/1762] D loss: 0.0000, G loss: 14.3449\n",
      "[324/1762] D loss: 0.0000, G loss: 14.9738\n",
      "[404/1762] D loss: 0.0008, G loss: 10.5301\n",
      "[484/1762] D loss: 0.0000, G loss: 13.8570\n",
      "[564/1762] D loss: 0.0000, G loss: 14.2158\n",
      "[644/1762] D loss: 0.0000, G loss: 15.0061\n",
      "[724/1762] D loss: 0.0000, G loss: 16.4855\n",
      "[804/1762] D loss: 0.0000, G loss: 17.8250\n",
      "[884/1762] D loss: 0.0000, G loss: 14.1153\n",
      "[964/1762] D loss: 0.0000, G loss: 13.1154\n",
      "[1044/1762] D loss: 0.0000, G loss: 16.0791\n",
      "[1124/1762] D loss: 0.0000, G loss: 13.2774\n",
      "[1204/1762] D loss: 0.0000, G loss: 16.1288\n",
      "[1284/1762] D loss: 0.0000, G loss: 13.0242\n",
      "[1364/1762] D loss: 0.0014, G loss: 12.9191\n",
      "[1444/1762] D loss: 0.0038, G loss: 13.3023\n",
      "[1524/1762] D loss: 0.0000, G loss: 16.0382\n",
      "[1604/1762] D loss: 0.0000, G loss: 14.4448\n",
      "[1684/1762] D loss: 0.0000, G loss: 15.5532\n",
      "[1762/1762] D loss: 0.0000, G loss: 18.7052\n",
      "train error: \n",
      " D loss: 0.000062, G loss: 15.091164, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000096, G loss: 15.169394, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 15.7547\n",
      "[84/1762] D loss: 0.0000, G loss: 17.2782\n",
      "[164/1762] D loss: 0.0000, G loss: 17.5504\n",
      "[244/1762] D loss: 0.0000, G loss: 15.0209\n",
      "[324/1762] D loss: 0.0000, G loss: 15.2505\n",
      "[404/1762] D loss: 0.0001, G loss: 14.0270\n",
      "[484/1762] D loss: 0.0000, G loss: 14.4312\n",
      "[564/1762] D loss: 0.0000, G loss: 17.0880\n",
      "[644/1762] D loss: 0.0000, G loss: 16.2630\n",
      "[724/1762] D loss: 0.0001, G loss: 15.2881\n",
      "[804/1762] D loss: 0.0011, G loss: 14.9490\n",
      "[884/1762] D loss: 0.0000, G loss: 16.0954\n",
      "[964/1762] D loss: 0.0001, G loss: 14.9739\n",
      "[1044/1762] D loss: 0.0000, G loss: 18.3196\n",
      "[1124/1762] D loss: 0.0000, G loss: 15.4046\n",
      "[1204/1762] D loss: 0.0000, G loss: 13.0232\n",
      "[1284/1762] D loss: 0.0000, G loss: 14.0847\n",
      "[1364/1762] D loss: 0.0000, G loss: 12.7839\n",
      "[1444/1762] D loss: 0.0000, G loss: 16.6191\n",
      "[1524/1762] D loss: 0.0000, G loss: 17.4670\n",
      "[1604/1762] D loss: 0.0000, G loss: 18.5227\n",
      "[1684/1762] D loss: 0.0000, G loss: 15.7004\n",
      "[1762/1762] D loss: 0.0000, G loss: 13.8547\n",
      "train error: \n",
      " D loss: 0.000046, G loss: 15.484546, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000069, G loss: 15.560938, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 15.7584\n",
      "[84/1762] D loss: 0.0001, G loss: 15.4419\n",
      "[164/1762] D loss: 0.0000, G loss: 17.9890\n",
      "[244/1762] D loss: 0.0000, G loss: 13.4743\n",
      "[324/1762] D loss: 0.0000, G loss: 14.8761\n",
      "[404/1762] D loss: 0.0000, G loss: 15.1124\n",
      "[484/1762] D loss: 0.0000, G loss: 17.7801\n",
      "[564/1762] D loss: 0.0001, G loss: 16.5237\n",
      "[644/1762] D loss: 0.0000, G loss: 15.6556\n",
      "[724/1762] D loss: 0.0000, G loss: 17.1631\n",
      "[804/1762] D loss: 0.0000, G loss: 15.5642\n",
      "[884/1762] D loss: 0.0000, G loss: 15.0544\n",
      "[964/1762] D loss: 0.0002, G loss: 15.2341\n",
      "[1044/1762] D loss: 0.0000, G loss: 14.5652\n",
      "[1124/1762] D loss: 0.0000, G loss: 15.9619\n",
      "[1204/1762] D loss: 0.0000, G loss: 15.1821\n",
      "[1284/1762] D loss: 0.0000, G loss: 14.6542\n",
      "[1364/1762] D loss: 0.0000, G loss: 19.2912\n",
      "[1444/1762] D loss: 0.0000, G loss: 21.1411\n",
      "[1524/1762] D loss: 0.0000, G loss: 14.7006\n",
      "[1604/1762] D loss: 0.0001, G loss: 14.3862\n",
      "[1684/1762] D loss: 0.0000, G loss: 16.8917\n",
      "[1762/1762] D loss: 0.0000, G loss: 16.4099\n",
      "train error: \n",
      " D loss: 0.000039, G loss: 15.744721, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000055, G loss: 15.816854, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 13.7389\n",
      "[84/1762] D loss: 0.0000, G loss: 18.3827\n",
      "[164/1762] D loss: 0.0002, G loss: 14.6202\n",
      "[244/1762] D loss: 0.0000, G loss: 13.6253\n",
      "[324/1762] D loss: 0.0000, G loss: 18.4050\n",
      "[404/1762] D loss: 0.0000, G loss: 16.9121\n",
      "[484/1762] D loss: 0.0000, G loss: 16.8594\n",
      "[564/1762] D loss: 0.0007, G loss: 11.4908\n",
      "[644/1762] D loss: 0.0000, G loss: 13.9888\n",
      "[724/1762] D loss: 0.0000, G loss: 14.4804\n",
      "[804/1762] D loss: 0.0000, G loss: 16.0351\n",
      "[884/1762] D loss: 0.0000, G loss: 16.8446\n",
      "[964/1762] D loss: 0.0000, G loss: 16.3585\n",
      "[1044/1762] D loss: 0.0001, G loss: 14.7409\n",
      "[1124/1762] D loss: 0.0000, G loss: 19.4157\n",
      "[1204/1762] D loss: 0.0000, G loss: 13.8298\n",
      "[1284/1762] D loss: 0.0000, G loss: 18.0890\n",
      "[1364/1762] D loss: 0.0000, G loss: 14.0865\n",
      "[1444/1762] D loss: 0.0002, G loss: 10.1596\n",
      "[1524/1762] D loss: 0.0000, G loss: 14.5664\n",
      "[1604/1762] D loss: 0.0000, G loss: 16.3053\n",
      "[1684/1762] D loss: 0.0000, G loss: 17.2469\n",
      "[1762/1762] D loss: 0.0000, G loss: 20.8024\n",
      "train error: \n",
      " D loss: 0.000029, G loss: 16.488269, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000045, G loss: 16.572046, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 14.8837\n",
      "[84/1762] D loss: 0.0000, G loss: 18.0673\n",
      "[164/1762] D loss: 0.0000, G loss: 16.0323\n",
      "[244/1762] D loss: 0.0000, G loss: 17.8506\n",
      "[324/1762] D loss: 0.0000, G loss: 16.7352\n",
      "[404/1762] D loss: 0.0000, G loss: 17.0810\n",
      "[484/1762] D loss: 0.0000, G loss: 15.3754\n",
      "[564/1762] D loss: 0.0000, G loss: 17.1966\n",
      "[644/1762] D loss: 0.0000, G loss: 17.0953\n",
      "[724/1762] D loss: 0.0001, G loss: 17.1160\n",
      "[804/1762] D loss: 0.0000, G loss: 18.8115\n",
      "[884/1762] D loss: 0.0000, G loss: 18.7567\n",
      "[964/1762] D loss: 0.0000, G loss: 16.6267\n",
      "[1044/1762] D loss: 0.0000, G loss: 16.3487\n",
      "[1124/1762] D loss: 0.0000, G loss: 16.8829\n",
      "[1204/1762] D loss: 0.0000, G loss: 18.2973\n",
      "[1284/1762] D loss: 0.0000, G loss: 17.5834\n",
      "[1364/1762] D loss: 0.0000, G loss: 18.4462\n",
      "[1444/1762] D loss: 0.0000, G loss: 13.7561\n",
      "[1524/1762] D loss: 0.0000, G loss: 14.8073\n",
      "[1604/1762] D loss: 0.0000, G loss: 15.8917\n",
      "[1684/1762] D loss: 0.0000, G loss: 14.1124\n",
      "[1762/1762] D loss: 0.0000, G loss: 23.0467\n",
      "train error: \n",
      " D loss: 0.000021, G loss: 16.774070, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000033, G loss: 16.861528, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 17.3964\n",
      "[84/1762] D loss: 0.0000, G loss: 18.6817\n",
      "[164/1762] D loss: 0.0000, G loss: 18.3108\n",
      "[244/1762] D loss: 0.0000, G loss: 16.1314\n",
      "[324/1762] D loss: 0.0000, G loss: 16.5486\n",
      "[404/1762] D loss: 0.0000, G loss: 16.0476\n",
      "[484/1762] D loss: 0.0000, G loss: 22.6175\n",
      "[564/1762] D loss: 0.0000, G loss: 15.0797\n",
      "[644/1762] D loss: 0.0000, G loss: 15.1479\n",
      "[724/1762] D loss: 0.0000, G loss: 18.9185\n",
      "[804/1762] D loss: 0.0000, G loss: 19.5720\n",
      "[884/1762] D loss: 0.0000, G loss: 21.7090\n",
      "[964/1762] D loss: 0.0000, G loss: 12.9031\n",
      "[1044/1762] D loss: 0.0000, G loss: 18.7476\n",
      "[1124/1762] D loss: 0.0000, G loss: 16.1803\n",
      "[1204/1762] D loss: 0.0000, G loss: 13.1181\n",
      "[1284/1762] D loss: 0.0000, G loss: 19.1367\n",
      "[1364/1762] D loss: 0.0000, G loss: 17.6525\n",
      "[1444/1762] D loss: 0.0000, G loss: 18.2730\n",
      "[1524/1762] D loss: 0.0000, G loss: 19.5682\n",
      "[1604/1762] D loss: 0.0000, G loss: 15.4460\n",
      "[1684/1762] D loss: 0.0000, G loss: 18.5746\n",
      "[1762/1762] D loss: 0.0000, G loss: 18.5385\n",
      "train error: \n",
      " D loss: 0.000017, G loss: 16.943723, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000025, G loss: 17.030102, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 17.9372\n",
      "[84/1762] D loss: 0.0000, G loss: 18.7714\n",
      "[164/1762] D loss: 0.0000, G loss: 13.8568\n",
      "[244/1762] D loss: 0.0000, G loss: 17.1349\n",
      "[324/1762] D loss: 0.0000, G loss: 19.4247\n",
      "[404/1762] D loss: 0.0000, G loss: 17.9877\n",
      "[484/1762] D loss: 0.0000, G loss: 17.4489\n",
      "[564/1762] D loss: 0.0000, G loss: 16.1045\n",
      "[644/1762] D loss: 0.0001, G loss: 15.4437\n",
      "[724/1762] D loss: 0.0000, G loss: 14.1423\n",
      "[804/1762] D loss: 0.0001, G loss: 18.7994\n",
      "[884/1762] D loss: 0.0000, G loss: 17.4683\n",
      "[964/1762] D loss: 0.0000, G loss: 16.3821\n",
      "[1044/1762] D loss: 0.0000, G loss: 18.3611\n",
      "[1124/1762] D loss: 0.0000, G loss: 15.8438\n",
      "[1204/1762] D loss: 0.0000, G loss: 18.6545\n",
      "[1284/1762] D loss: 0.0000, G loss: 18.2532\n",
      "[1364/1762] D loss: 0.0000, G loss: 16.5637\n",
      "[1444/1762] D loss: 0.0000, G loss: 15.7825\n",
      "[1524/1762] D loss: 0.0000, G loss: 20.7133\n",
      "[1604/1762] D loss: 0.0000, G loss: 13.8610\n",
      "[1684/1762] D loss: 0.0000, G loss: 16.4651\n",
      "[1762/1762] D loss: 0.0000, G loss: 14.6875\n",
      "train error: \n",
      " D loss: 0.000013, G loss: 17.608283, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000020, G loss: 17.693596, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 21.4890\n",
      "[84/1762] D loss: 0.0000, G loss: 20.6555\n",
      "[164/1762] D loss: 0.0000, G loss: 16.6940\n",
      "[244/1762] D loss: 0.0001, G loss: 13.3038\n",
      "[324/1762] D loss: 0.0000, G loss: 18.4232\n",
      "[404/1762] D loss: 0.0000, G loss: 17.1717\n",
      "[484/1762] D loss: 0.0000, G loss: 21.7593\n",
      "[564/1762] D loss: 0.0000, G loss: 18.0583\n",
      "[644/1762] D loss: 0.0000, G loss: 16.7692\n",
      "[724/1762] D loss: 0.0000, G loss: 14.1011\n",
      "[804/1762] D loss: 0.0000, G loss: 16.1244\n",
      "[884/1762] D loss: 0.0000, G loss: 16.6914\n",
      "[964/1762] D loss: 0.0000, G loss: 19.6006\n",
      "[1044/1762] D loss: 0.0000, G loss: 17.1766\n",
      "[1124/1762] D loss: 0.0000, G loss: 21.9897\n",
      "[1204/1762] D loss: 0.0000, G loss: 15.8821\n",
      "[1284/1762] D loss: 0.0000, G loss: 21.2314\n",
      "[1364/1762] D loss: 0.0000, G loss: 15.2814\n",
      "[1444/1762] D loss: 0.0000, G loss: 14.9383\n",
      "[1524/1762] D loss: 0.0000, G loss: 18.0171\n",
      "[1604/1762] D loss: 0.0000, G loss: 20.1562\n",
      "[1684/1762] D loss: 0.0000, G loss: 17.1930\n",
      "[1762/1762] D loss: 0.0000, G loss: 23.9792\n",
      "train error: \n",
      " D loss: 0.000011, G loss: 17.596368, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000016, G loss: 17.687873, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 15.4411\n",
      "[84/1762] D loss: 0.0000, G loss: 18.0659\n",
      "[164/1762] D loss: 0.0000, G loss: 17.8791\n",
      "[244/1762] D loss: 0.0000, G loss: 15.8604\n",
      "[324/1762] D loss: 0.0000, G loss: 19.2127\n",
      "[404/1762] D loss: 0.0000, G loss: 22.4291\n",
      "[484/1762] D loss: 0.0000, G loss: 15.9430\n",
      "[564/1762] D loss: 0.0000, G loss: 21.2465\n",
      "[644/1762] D loss: 0.0005, G loss: 16.3776\n",
      "[724/1762] D loss: 0.0000, G loss: 18.5518\n",
      "[804/1762] D loss: 0.0000, G loss: 18.9500\n",
      "[884/1762] D loss: 0.0000, G loss: 15.2487\n",
      "[964/1762] D loss: 0.0000, G loss: 19.5735\n",
      "[1044/1762] D loss: 0.0000, G loss: 20.5250\n",
      "[1124/1762] D loss: 0.0000, G loss: 15.5559\n",
      "[1204/1762] D loss: 0.0000, G loss: 17.7675\n",
      "[1284/1762] D loss: 0.0000, G loss: 17.2328\n",
      "[1364/1762] D loss: 0.0000, G loss: 16.1223\n",
      "[1444/1762] D loss: 0.0000, G loss: 21.8406\n",
      "[1524/1762] D loss: 0.0000, G loss: 16.8349\n",
      "[1604/1762] D loss: 0.0000, G loss: 21.3613\n",
      "[1684/1762] D loss: 0.0000, G loss: 21.3113\n",
      "[1762/1762] D loss: 0.0000, G loss: 18.3384\n",
      "train error: \n",
      " D loss: 0.000008, G loss: 18.296042, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000012, G loss: 18.390348, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 21.1594\n",
      "[84/1762] D loss: 0.0000, G loss: 19.3086\n",
      "[164/1762] D loss: 0.0000, G loss: 18.5470\n",
      "[244/1762] D loss: 0.0000, G loss: 20.0345\n",
      "[324/1762] D loss: 0.0000, G loss: 21.4020\n",
      "[404/1762] D loss: 0.0000, G loss: 19.8859\n",
      "[484/1762] D loss: 0.0000, G loss: 20.9969\n",
      "[564/1762] D loss: 0.0000, G loss: 16.7360\n",
      "[644/1762] D loss: 0.0000, G loss: 17.7512\n",
      "[724/1762] D loss: 0.0000, G loss: 20.1905\n",
      "[804/1762] D loss: 0.0000, G loss: 17.2899\n",
      "[884/1762] D loss: 0.0000, G loss: 14.7794\n",
      "[964/1762] D loss: 0.0000, G loss: 18.6657\n",
      "[1044/1762] D loss: 0.0000, G loss: 19.9865\n",
      "[1124/1762] D loss: 0.0000, G loss: 15.2276\n",
      "[1204/1762] D loss: 0.0000, G loss: 19.6216\n",
      "[1284/1762] D loss: 0.0000, G loss: 19.6619\n",
      "[1364/1762] D loss: 0.0000, G loss: 18.9523\n",
      "[1444/1762] D loss: 0.0000, G loss: 19.6236\n",
      "[1524/1762] D loss: 0.0000, G loss: 19.3677\n",
      "[1604/1762] D loss: 0.0000, G loss: 21.4577\n",
      "[1684/1762] D loss: 0.0000, G loss: 22.0143\n",
      "[1762/1762] D loss: 0.0000, G loss: 19.8887\n",
      "train error: \n",
      " D loss: 0.000007, G loss: 18.735891, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000010, G loss: 18.831157, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 19.6107\n",
      "[84/1762] D loss: 0.0000, G loss: 24.2435\n",
      "[164/1762] D loss: 0.0000, G loss: 20.2667\n",
      "[244/1762] D loss: 0.0000, G loss: 19.4203\n",
      "[324/1762] D loss: 0.0000, G loss: 20.3064\n",
      "[404/1762] D loss: 0.0000, G loss: 21.2292\n",
      "[484/1762] D loss: 0.0000, G loss: 18.3715\n",
      "[564/1762] D loss: 0.0000, G loss: 18.4977\n",
      "[644/1762] D loss: 0.0004, G loss: 13.8285\n",
      "[724/1762] D loss: 0.0000, G loss: 16.5474\n",
      "[804/1762] D loss: 0.0000, G loss: 19.2742\n",
      "[884/1762] D loss: 0.0000, G loss: 20.3853\n",
      "[964/1762] D loss: 0.0000, G loss: 19.2705\n",
      "[1044/1762] D loss: 0.0000, G loss: 14.0183\n",
      "[1124/1762] D loss: 0.0000, G loss: 21.1696\n",
      "[1204/1762] D loss: 0.0000, G loss: 15.4947\n",
      "[1284/1762] D loss: 0.0000, G loss: 21.2575\n",
      "[1364/1762] D loss: 0.0000, G loss: 15.2226\n",
      "[1444/1762] D loss: 0.0000, G loss: 20.2162\n",
      "[1524/1762] D loss: 0.0000, G loss: 18.1767\n",
      "[1604/1762] D loss: 0.0002, G loss: 17.7747\n",
      "[1684/1762] D loss: 0.0000, G loss: 18.0548\n",
      "[1762/1762] D loss: 0.0000, G loss: 20.7640\n",
      "train error: \n",
      " D loss: 0.000005, G loss: 18.804976, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000007, G loss: 18.910918, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 15.6483\n",
      "[84/1762] D loss: 0.0000, G loss: 17.2449\n",
      "[164/1762] D loss: 0.0000, G loss: 20.0241\n",
      "[244/1762] D loss: 0.0000, G loss: 23.6188\n",
      "[324/1762] D loss: 0.0003, G loss: 15.7242\n",
      "[404/1762] D loss: 0.0000, G loss: 15.8401\n",
      "[484/1762] D loss: 0.0000, G loss: 17.4176\n",
      "[564/1762] D loss: 0.0000, G loss: 20.8356\n",
      "[644/1762] D loss: 0.0000, G loss: 20.5890\n",
      "[724/1762] D loss: 0.0000, G loss: 23.9457\n",
      "[804/1762] D loss: 0.0000, G loss: 17.4434\n",
      "[884/1762] D loss: 0.0000, G loss: 19.7652\n",
      "[964/1762] D loss: 0.0000, G loss: 17.9333\n",
      "[1044/1762] D loss: 0.0000, G loss: 17.1252\n",
      "[1124/1762] D loss: 0.0000, G loss: 18.8009\n",
      "[1204/1762] D loss: 0.0000, G loss: 14.4246\n",
      "[1284/1762] D loss: 0.0000, G loss: 17.8694\n",
      "[1364/1762] D loss: 0.0000, G loss: 19.8764\n",
      "[1444/1762] D loss: 0.0000, G loss: 17.9925\n",
      "[1524/1762] D loss: 0.0000, G loss: 19.4240\n",
      "[1604/1762] D loss: 0.0000, G loss: 21.1494\n",
      "[1684/1762] D loss: 0.0000, G loss: 16.9164\n",
      "[1762/1762] D loss: 0.0000, G loss: 17.0816\n",
      "train error: \n",
      " D loss: 0.000004, G loss: 19.181373, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000006, G loss: 19.285399, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 17.9529\n",
      "[84/1762] D loss: 0.0000, G loss: 19.1628\n",
      "[164/1762] D loss: 0.0000, G loss: 15.9845\n",
      "[244/1762] D loss: 0.0000, G loss: 18.6227\n",
      "[324/1762] D loss: 0.0000, G loss: 22.8797\n",
      "[404/1762] D loss: 0.0000, G loss: 18.9915\n",
      "[484/1762] D loss: 0.0000, G loss: 22.3812\n",
      "[564/1762] D loss: 0.0000, G loss: 21.1154\n",
      "[644/1762] D loss: 0.0000, G loss: 19.7961\n",
      "[724/1762] D loss: 0.0000, G loss: 20.3249\n",
      "[804/1762] D loss: 0.0000, G loss: 21.8394\n",
      "[884/1762] D loss: 0.0000, G loss: 19.6385\n",
      "[964/1762] D loss: 0.0000, G loss: 22.8367\n",
      "[1044/1762] D loss: 0.0000, G loss: 21.0927\n",
      "[1124/1762] D loss: 0.0000, G loss: 22.4624\n",
      "[1204/1762] D loss: 0.0000, G loss: 16.2842\n",
      "[1284/1762] D loss: 0.0000, G loss: 17.0931\n",
      "[1364/1762] D loss: 0.0000, G loss: 21.1027\n",
      "[1444/1762] D loss: 0.0000, G loss: 16.4167\n",
      "[1524/1762] D loss: 0.0000, G loss: 23.8447\n",
      "[1604/1762] D loss: 0.0000, G loss: 18.6370\n",
      "[1684/1762] D loss: 0.0000, G loss: 18.8292\n",
      "[1762/1762] D loss: 0.0000, G loss: 15.4489\n",
      "train error: \n",
      " D loss: 0.000003, G loss: 19.837271, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000004, G loss: 19.938570, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 15.9878\n",
      "[84/1762] D loss: 0.0000, G loss: 19.2937\n",
      "[164/1762] D loss: 0.0000, G loss: 18.4789\n",
      "[244/1762] D loss: 0.0000, G loss: 21.8661\n",
      "[324/1762] D loss: 0.0000, G loss: 19.1605\n",
      "[404/1762] D loss: 0.0000, G loss: 17.2831\n",
      "[484/1762] D loss: 0.0000, G loss: 23.3813\n",
      "[564/1762] D loss: 0.0000, G loss: 19.5165\n",
      "[644/1762] D loss: 0.0000, G loss: 20.5984\n",
      "[724/1762] D loss: 0.0000, G loss: 22.8228\n",
      "[804/1762] D loss: 0.0000, G loss: 19.7807\n",
      "[884/1762] D loss: 0.0000, G loss: 17.3431\n",
      "[964/1762] D loss: 0.0001, G loss: 16.7354\n",
      "[1044/1762] D loss: 0.0000, G loss: 22.2944\n",
      "[1124/1762] D loss: 0.0000, G loss: 24.9168\n",
      "[1204/1762] D loss: 0.0000, G loss: 23.2905\n",
      "[1284/1762] D loss: 0.0000, G loss: 18.7061\n",
      "[1364/1762] D loss: 0.0000, G loss: 20.8046\n",
      "[1444/1762] D loss: 0.0000, G loss: 19.8089\n",
      "[1524/1762] D loss: 0.0000, G loss: 23.2701\n",
      "[1604/1762] D loss: 0.0000, G loss: 20.5160\n",
      "[1684/1762] D loss: 0.0000, G loss: 20.4917\n",
      "[1762/1762] D loss: 0.0000, G loss: 19.5282\n",
      "train error: \n",
      " D loss: 0.000002, G loss: 20.083317, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000003, G loss: 20.192859, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 17.4311\n",
      "[84/1762] D loss: 0.0000, G loss: 18.9228\n",
      "[164/1762] D loss: 0.0000, G loss: 17.1372\n",
      "[244/1762] D loss: 0.0000, G loss: 23.4098\n",
      "[324/1762] D loss: 0.0000, G loss: 16.4998\n",
      "[404/1762] D loss: 0.0000, G loss: 21.0895\n",
      "[484/1762] D loss: 0.0000, G loss: 19.2451\n",
      "[564/1762] D loss: 0.0000, G loss: 19.0284\n",
      "[644/1762] D loss: 0.0000, G loss: 19.8957\n",
      "[724/1762] D loss: 0.0000, G loss: 24.8814\n",
      "[804/1762] D loss: 0.0000, G loss: 17.5967\n",
      "[884/1762] D loss: 0.0000, G loss: 23.7222\n",
      "[964/1762] D loss: 0.0000, G loss: 17.0086\n",
      "[1044/1762] D loss: 0.0000, G loss: 17.5969\n",
      "[1124/1762] D loss: 0.0000, G loss: 18.5531\n",
      "[1204/1762] D loss: 0.0000, G loss: 23.6668\n",
      "[1284/1762] D loss: 0.0000, G loss: 20.8759\n",
      "[1364/1762] D loss: 0.0000, G loss: 22.7032\n",
      "[1444/1762] D loss: 0.0000, G loss: 24.9327\n",
      "[1524/1762] D loss: 0.0000, G loss: 18.2295\n",
      "[1604/1762] D loss: 0.0000, G loss: 20.1798\n",
      "[1684/1762] D loss: 0.0000, G loss: 18.9483\n",
      "[1762/1762] D loss: 0.0000, G loss: 21.5518\n",
      "train error: \n",
      " D loss: 0.000002, G loss: 20.809962, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000003, G loss: 20.913992, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 19.8866\n",
      "[84/1762] D loss: 0.0000, G loss: 20.0722\n",
      "[164/1762] D loss: 0.0000, G loss: 22.0253\n",
      "[244/1762] D loss: 0.0000, G loss: 18.7781\n",
      "[324/1762] D loss: 0.0000, G loss: 21.9096\n",
      "[404/1762] D loss: 0.0000, G loss: 21.9078\n",
      "[484/1762] D loss: 0.0000, G loss: 21.4931\n",
      "[564/1762] D loss: 0.0000, G loss: 18.1726\n",
      "[644/1762] D loss: 0.0000, G loss: 25.4306\n",
      "[724/1762] D loss: 0.0000, G loss: 19.3916\n",
      "[804/1762] D loss: 0.0000, G loss: 24.9515\n",
      "[884/1762] D loss: 0.0000, G loss: 18.5003\n",
      "[964/1762] D loss: 0.0000, G loss: 21.1219\n",
      "[1044/1762] D loss: 0.0000, G loss: 19.1208\n",
      "[1124/1762] D loss: 0.0000, G loss: 23.9408\n",
      "[1204/1762] D loss: 0.0000, G loss: 17.2647\n",
      "[1284/1762] D loss: 0.0000, G loss: 21.9759\n",
      "[1364/1762] D loss: 0.0000, G loss: 21.2166\n",
      "[1444/1762] D loss: 0.0000, G loss: 20.8059\n",
      "[1524/1762] D loss: 0.0000, G loss: 22.1789\n",
      "[1604/1762] D loss: 0.0000, G loss: 21.4789\n",
      "[1684/1762] D loss: 0.0000, G loss: 17.7672\n",
      "[1762/1762] D loss: 0.0000, G loss: 20.6581\n",
      "train error: \n",
      " D loss: 0.000001, G loss: 20.897534, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000002, G loss: 21.015352, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 22.8358\n",
      "[84/1762] D loss: 0.0000, G loss: 22.3200\n",
      "[164/1762] D loss: 0.0000, G loss: 20.1138\n",
      "[244/1762] D loss: 0.0000, G loss: 24.5276\n",
      "[324/1762] D loss: 0.0000, G loss: 19.2298\n",
      "[404/1762] D loss: 0.0000, G loss: 20.4358\n",
      "[484/1762] D loss: 0.0000, G loss: 20.8534\n",
      "[564/1762] D loss: 0.0000, G loss: 24.8893\n",
      "[644/1762] D loss: 0.0000, G loss: 23.4262\n",
      "[724/1762] D loss: 0.0000, G loss: 24.1373\n",
      "[804/1762] D loss: 0.0000, G loss: 18.5657\n",
      "[884/1762] D loss: 0.0000, G loss: 22.4458\n",
      "[964/1762] D loss: 0.0000, G loss: 18.5379\n",
      "[1044/1762] D loss: 0.0000, G loss: 24.2741\n",
      "[1124/1762] D loss: 0.0000, G loss: 22.8946\n",
      "[1204/1762] D loss: 0.0000, G loss: 21.8441\n",
      "[1284/1762] D loss: 0.0000, G loss: 17.7297\n",
      "[1364/1762] D loss: 0.0000, G loss: 26.4115\n",
      "[1444/1762] D loss: 0.0000, G loss: 19.9873\n",
      "[1524/1762] D loss: 0.0000, G loss: 18.6845\n",
      "[1604/1762] D loss: 0.0000, G loss: 21.1798\n",
      "[1684/1762] D loss: 0.0000, G loss: 24.0957\n",
      "[1762/1762] D loss: 0.0000, G loss: 21.3935\n",
      "train error: \n",
      " D loss: 0.000001, G loss: 21.157228, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000002, G loss: 21.273362, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 21.8843\n",
      "[84/1762] D loss: 0.0000, G loss: 23.1147\n",
      "[164/1762] D loss: 0.0000, G loss: 21.8380\n",
      "[244/1762] D loss: 0.0000, G loss: 23.2216\n",
      "[324/1762] D loss: 0.0000, G loss: 24.8944\n",
      "[404/1762] D loss: 0.0000, G loss: 21.7926\n",
      "[484/1762] D loss: 0.0000, G loss: 20.0166\n",
      "[564/1762] D loss: 0.0000, G loss: 20.2183\n",
      "[644/1762] D loss: 0.0000, G loss: 17.1993\n",
      "[724/1762] D loss: 0.0000, G loss: 20.3338\n",
      "[804/1762] D loss: 0.0000, G loss: 22.0659\n",
      "[884/1762] D loss: 0.0000, G loss: 21.6472\n",
      "[964/1762] D loss: 0.0000, G loss: 24.2819\n",
      "[1044/1762] D loss: 0.0000, G loss: 27.9228\n",
      "[1124/1762] D loss: 0.0000, G loss: 22.6671\n",
      "[1204/1762] D loss: 0.0000, G loss: 20.0939\n",
      "[1284/1762] D loss: 0.0000, G loss: 20.9772\n",
      "[1364/1762] D loss: 0.0000, G loss: 21.6913\n",
      "[1444/1762] D loss: 0.0000, G loss: 27.8245\n",
      "[1524/1762] D loss: 0.0000, G loss: 23.4946\n",
      "[1604/1762] D loss: 0.0000, G loss: 24.6806\n",
      "[1684/1762] D loss: 0.0000, G loss: 21.7381\n",
      "[1762/1762] D loss: 0.0000, G loss: 22.6409\n",
      "train error: \n",
      " D loss: 0.000001, G loss: 21.700358, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000001, G loss: 21.815590, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 16.4232\n",
      "[84/1762] D loss: 0.0000, G loss: 19.1781\n",
      "[164/1762] D loss: 0.0000, G loss: 22.1412\n",
      "[244/1762] D loss: 0.0000, G loss: 23.9393\n",
      "[324/1762] D loss: 0.0000, G loss: 20.5395\n",
      "[404/1762] D loss: 0.0000, G loss: 23.5916\n",
      "[484/1762] D loss: 0.0000, G loss: 23.9553\n",
      "[564/1762] D loss: 0.0000, G loss: 22.5501\n",
      "[644/1762] D loss: 0.0000, G loss: 21.1646\n",
      "[724/1762] D loss: 0.0000, G loss: 28.8484\n",
      "[804/1762] D loss: 0.0000, G loss: 19.8928\n",
      "[884/1762] D loss: 0.0000, G loss: 22.7346\n",
      "[964/1762] D loss: 0.0000, G loss: 27.4616\n",
      "[1044/1762] D loss: 0.0000, G loss: 19.8321\n",
      "[1124/1762] D loss: 0.0000, G loss: 17.4573\n",
      "[1204/1762] D loss: 0.0000, G loss: 21.0943\n",
      "[1284/1762] D loss: 0.0000, G loss: 24.0513\n",
      "[1364/1762] D loss: 0.0000, G loss: 21.4136\n",
      "[1444/1762] D loss: 0.0000, G loss: 16.4948\n",
      "[1524/1762] D loss: 0.0000, G loss: 17.9716\n",
      "[1604/1762] D loss: 0.0000, G loss: 19.7010\n",
      "[1684/1762] D loss: 0.0000, G loss: 20.7118\n",
      "[1762/1762] D loss: 0.0000, G loss: 16.2309\n",
      "train error: \n",
      " D loss: 0.000001, G loss: 22.122388, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000001, G loss: 22.242271, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 18.4232\n",
      "[84/1762] D loss: 0.0000, G loss: 22.7837\n",
      "[164/1762] D loss: 0.0000, G loss: 22.0311\n",
      "[244/1762] D loss: 0.0000, G loss: 24.0265\n",
      "[324/1762] D loss: 0.0000, G loss: 24.6538\n",
      "[404/1762] D loss: 0.0000, G loss: 19.1720\n",
      "[484/1762] D loss: 0.0000, G loss: 22.2799\n",
      "[564/1762] D loss: 0.0000, G loss: 20.4305\n",
      "[644/1762] D loss: 0.0000, G loss: 22.9594\n",
      "[724/1762] D loss: 0.0000, G loss: 21.0145\n",
      "[804/1762] D loss: 0.0000, G loss: 25.5505\n",
      "[884/1762] D loss: 0.0000, G loss: 24.2610\n",
      "[964/1762] D loss: 0.0000, G loss: 21.0919\n",
      "[1044/1762] D loss: 0.0000, G loss: 22.4512\n",
      "[1124/1762] D loss: 0.0000, G loss: 21.1032\n",
      "[1204/1762] D loss: 0.0000, G loss: 23.1646\n",
      "[1284/1762] D loss: 0.0000, G loss: 18.6471\n",
      "[1364/1762] D loss: 0.0000, G loss: 21.7236\n",
      "[1444/1762] D loss: 0.0000, G loss: 22.1438\n",
      "[1524/1762] D loss: 0.0000, G loss: 24.7696\n",
      "[1604/1762] D loss: 0.0000, G loss: 20.7177\n",
      "[1684/1762] D loss: 0.0000, G loss: 20.5527\n",
      "[1762/1762] D loss: 0.0000, G loss: 19.7964\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 22.255160, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000001, G loss: 22.375795, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 17.6262\n",
      "[84/1762] D loss: 0.0000, G loss: 18.7780\n",
      "[164/1762] D loss: 0.0000, G loss: 21.3716\n",
      "[244/1762] D loss: 0.0000, G loss: 21.6825\n",
      "[324/1762] D loss: 0.0000, G loss: 19.4040\n",
      "[404/1762] D loss: 0.0000, G loss: 20.6083\n",
      "[484/1762] D loss: 0.0000, G loss: 19.9997\n",
      "[564/1762] D loss: 0.0000, G loss: 25.3064\n",
      "[644/1762] D loss: 0.0000, G loss: 24.6757\n",
      "[724/1762] D loss: 0.0000, G loss: 23.3993\n",
      "[804/1762] D loss: 0.0000, G loss: 25.7185\n",
      "[884/1762] D loss: 0.0000, G loss: 20.6645\n",
      "[964/1762] D loss: 0.0000, G loss: 24.4962\n",
      "[1044/1762] D loss: 0.0000, G loss: 29.2608\n",
      "[1124/1762] D loss: 0.0000, G loss: 20.0870\n",
      "[1204/1762] D loss: 0.0000, G loss: 18.7863\n",
      "[1284/1762] D loss: 0.0000, G loss: 19.4206\n",
      "[1364/1762] D loss: 0.0000, G loss: 20.8638\n",
      "[1444/1762] D loss: 0.0000, G loss: 22.9150\n",
      "[1524/1762] D loss: 0.0000, G loss: 22.1312\n",
      "[1604/1762] D loss: 0.0000, G loss: 21.4642\n",
      "[1684/1762] D loss: 0.0000, G loss: 19.7489\n",
      "[1762/1762] D loss: 0.0000, G loss: 21.6907\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 22.786788, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000001, G loss: 22.903093, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 27.5846\n",
      "[84/1762] D loss: 0.0000, G loss: 22.8286\n",
      "[164/1762] D loss: 0.0000, G loss: 23.7999\n",
      "[244/1762] D loss: 0.0000, G loss: 21.7794\n",
      "[324/1762] D loss: 0.0000, G loss: 21.7384\n",
      "[404/1762] D loss: 0.0000, G loss: 19.6487\n",
      "[484/1762] D loss: 0.0000, G loss: 24.6426\n",
      "[564/1762] D loss: 0.0000, G loss: 20.1997\n",
      "[644/1762] D loss: 0.0000, G loss: 27.8013\n",
      "[724/1762] D loss: 0.0000, G loss: 26.3438\n",
      "[804/1762] D loss: 0.0000, G loss: 22.3402\n",
      "[884/1762] D loss: 0.0000, G loss: 21.5700\n",
      "[964/1762] D loss: 0.0000, G loss: 22.4267\n",
      "[1044/1762] D loss: 0.0000, G loss: 26.4986\n",
      "[1124/1762] D loss: 0.0000, G loss: 24.6574\n",
      "[1204/1762] D loss: 0.0000, G loss: 23.8518\n",
      "[1284/1762] D loss: 0.0000, G loss: 16.9345\n",
      "[1364/1762] D loss: 0.0000, G loss: 19.1247\n",
      "[1444/1762] D loss: 0.0000, G loss: 19.3613\n",
      "[1524/1762] D loss: 0.0000, G loss: 27.7199\n",
      "[1604/1762] D loss: 0.0000, G loss: 21.6268\n",
      "[1684/1762] D loss: 0.0000, G loss: 17.1033\n",
      "[1762/1762] D loss: 0.0000, G loss: 19.2447\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 23.173150, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 23.297218, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 21.6212\n",
      "[84/1762] D loss: 0.0000, G loss: 24.0814\n",
      "[164/1762] D loss: 0.0000, G loss: 26.5113\n",
      "[244/1762] D loss: 0.0000, G loss: 17.5714\n",
      "[324/1762] D loss: 0.0000, G loss: 22.1057\n",
      "[404/1762] D loss: 0.0000, G loss: 22.1138\n",
      "[484/1762] D loss: 0.0000, G loss: 26.8475\n",
      "[564/1762] D loss: 0.0000, G loss: 21.5888\n",
      "[644/1762] D loss: 0.0000, G loss: 25.5478\n",
      "[724/1762] D loss: 0.0000, G loss: 19.1584\n",
      "[804/1762] D loss: 0.0000, G loss: 25.3288\n",
      "[884/1762] D loss: 0.0000, G loss: 25.6990\n",
      "[964/1762] D loss: 0.0000, G loss: 21.6915\n",
      "[1044/1762] D loss: 0.0000, G loss: 18.8338\n",
      "[1124/1762] D loss: 0.0000, G loss: 22.9318\n",
      "[1204/1762] D loss: 0.0000, G loss: 18.5764\n",
      "[1284/1762] D loss: 0.0000, G loss: 27.1780\n",
      "[1364/1762] D loss: 0.0000, G loss: 28.9044\n",
      "[1444/1762] D loss: 0.0000, G loss: 27.2265\n",
      "[1524/1762] D loss: 0.0000, G loss: 24.0821\n",
      "[1604/1762] D loss: 0.0000, G loss: 29.7928\n",
      "[1684/1762] D loss: 0.0000, G loss: 32.5768\n",
      "[1762/1762] D loss: 0.0000, G loss: 23.6632\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 23.579373, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 23.710776, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 21.1003\n",
      "[84/1762] D loss: 0.0000, G loss: 24.1698\n",
      "[164/1762] D loss: 0.0000, G loss: 19.3010\n",
      "[244/1762] D loss: 0.0000, G loss: 26.5057\n",
      "[324/1762] D loss: 0.0000, G loss: 25.6883\n",
      "[404/1762] D loss: 0.0000, G loss: 24.2772\n",
      "[484/1762] D loss: 0.0000, G loss: 24.5722\n",
      "[564/1762] D loss: 0.0000, G loss: 28.7269\n",
      "[644/1762] D loss: 0.0000, G loss: 19.6568\n",
      "[724/1762] D loss: 0.0000, G loss: 28.2094\n",
      "[804/1762] D loss: 0.0000, G loss: 21.8490\n",
      "[884/1762] D loss: 0.0000, G loss: 20.9767\n",
      "[964/1762] D loss: 0.0000, G loss: 27.0230\n",
      "[1044/1762] D loss: 0.0000, G loss: 23.9958\n",
      "[1124/1762] D loss: 0.0000, G loss: 26.7850\n",
      "[1204/1762] D loss: 0.0000, G loss: 21.6823\n",
      "[1284/1762] D loss: 0.0000, G loss: 25.0731\n",
      "[1364/1762] D loss: 0.0000, G loss: 23.8023\n",
      "[1444/1762] D loss: 0.0000, G loss: 25.2307\n",
      "[1524/1762] D loss: 0.0000, G loss: 23.9948\n",
      "[1604/1762] D loss: 0.0000, G loss: 20.5880\n",
      "[1684/1762] D loss: 0.0000, G loss: 20.9766\n",
      "[1762/1762] D loss: 0.0000, G loss: 21.8728\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 23.898349, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 24.023528, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 19.5705\n",
      "[84/1762] D loss: 0.0000, G loss: 21.3663\n",
      "[164/1762] D loss: 0.0000, G loss: 20.5775\n",
      "[244/1762] D loss: 0.0000, G loss: 22.4145\n",
      "[324/1762] D loss: 0.0000, G loss: 19.9511\n",
      "[404/1762] D loss: 0.0000, G loss: 27.5246\n",
      "[484/1762] D loss: 0.0000, G loss: 29.8535\n",
      "[564/1762] D loss: 0.0000, G loss: 26.5564\n",
      "[644/1762] D loss: 0.0005, G loss: 15.9386\n",
      "[724/1762] D loss: 0.0000, G loss: 20.5791\n",
      "[804/1762] D loss: 0.0000, G loss: 30.0577\n",
      "[884/1762] D loss: 0.0000, G loss: 22.3256\n",
      "[964/1762] D loss: 0.0000, G loss: 21.2384\n",
      "[1044/1762] D loss: 0.0000, G loss: 25.0380\n",
      "[1124/1762] D loss: 0.0000, G loss: 27.0772\n",
      "[1204/1762] D loss: 0.0000, G loss: 24.6591\n",
      "[1284/1762] D loss: 0.0000, G loss: 25.5084\n",
      "[1364/1762] D loss: 0.0000, G loss: 22.0214\n",
      "[1444/1762] D loss: 0.0000, G loss: 23.6095\n",
      "[1524/1762] D loss: 0.0000, G loss: 25.3028\n",
      "[1604/1762] D loss: 0.0000, G loss: 24.7683\n",
      "[1684/1762] D loss: 0.0000, G loss: 24.6848\n",
      "[1762/1762] D loss: 0.0000, G loss: 30.4364\n",
      "train error: \n",
      " D loss: 0.000001, G loss: 25.151898, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000001, G loss: 25.290950, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 24.8067\n",
      "[84/1762] D loss: 0.0000, G loss: 29.9552\n",
      "[164/1762] D loss: 0.0000, G loss: 25.0698\n",
      "[244/1762] D loss: 0.0000, G loss: 22.5071\n",
      "[324/1762] D loss: 0.0000, G loss: 26.4771\n",
      "[404/1762] D loss: 0.0000, G loss: 25.6704\n",
      "[484/1762] D loss: 0.0000, G loss: 23.2202\n",
      "[564/1762] D loss: 0.0000, G loss: 21.3034\n",
      "[644/1762] D loss: 0.0000, G loss: 25.8649\n",
      "[724/1762] D loss: 0.0000, G loss: 23.5658\n",
      "[804/1762] D loss: 0.0000, G loss: 25.6662\n",
      "[884/1762] D loss: 0.0000, G loss: 21.1083\n",
      "[964/1762] D loss: 0.0000, G loss: 23.1992\n",
      "[1044/1762] D loss: 0.0000, G loss: 26.3489\n",
      "[1124/1762] D loss: 0.0000, G loss: 26.2432\n",
      "[1204/1762] D loss: 0.0000, G loss: 26.5575\n",
      "[1284/1762] D loss: 0.0000, G loss: 23.0035\n",
      "[1364/1762] D loss: 0.0000, G loss: 30.0313\n",
      "[1444/1762] D loss: 0.0000, G loss: 26.2261\n",
      "[1524/1762] D loss: 0.0000, G loss: 19.2623\n",
      "[1604/1762] D loss: 0.0000, G loss: 25.0523\n",
      "[1684/1762] D loss: 0.0000, G loss: 24.9036\n",
      "[1762/1762] D loss: 0.0000, G loss: 23.6351\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 24.778397, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 24.917568, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 25.5179\n",
      "[84/1762] D loss: 0.0000, G loss: 18.0262\n",
      "[164/1762] D loss: 0.0000, G loss: 19.8248\n",
      "[244/1762] D loss: 0.0000, G loss: 26.2386\n",
      "[324/1762] D loss: 0.0000, G loss: 20.3594\n",
      "[404/1762] D loss: 0.0000, G loss: 29.4219\n",
      "[484/1762] D loss: 0.0000, G loss: 25.8816\n",
      "[564/1762] D loss: 0.0000, G loss: 24.7552\n",
      "[644/1762] D loss: 0.0000, G loss: 31.2432\n",
      "[724/1762] D loss: 0.0000, G loss: 27.9355\n",
      "[804/1762] D loss: 0.0000, G loss: 26.3564\n",
      "[884/1762] D loss: 0.0000, G loss: 31.3365\n",
      "[964/1762] D loss: 0.0000, G loss: 26.3910\n",
      "[1044/1762] D loss: 0.0000, G loss: 26.0936\n",
      "[1124/1762] D loss: 0.0000, G loss: 26.0675\n",
      "[1204/1762] D loss: 0.0000, G loss: 26.7518\n",
      "[1284/1762] D loss: 0.0000, G loss: 27.6578\n",
      "[1364/1762] D loss: 0.0000, G loss: 25.1506\n",
      "[1444/1762] D loss: 0.0000, G loss: 25.5276\n",
      "[1524/1762] D loss: 0.0000, G loss: 22.8686\n",
      "[1604/1762] D loss: 0.0000, G loss: 21.3081\n",
      "[1684/1762] D loss: 0.0000, G loss: 28.1368\n",
      "[1762/1762] D loss: 0.0000, G loss: 22.1439\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 24.599639, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 24.735794, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 19.3708\n",
      "[84/1762] D loss: 0.0000, G loss: 23.8391\n",
      "[164/1762] D loss: 0.0000, G loss: 25.7097\n",
      "[244/1762] D loss: 0.0000, G loss: 25.8415\n",
      "[324/1762] D loss: 0.0000, G loss: 27.2723\n",
      "[404/1762] D loss: 0.0000, G loss: 26.0542\n",
      "[484/1762] D loss: 0.0000, G loss: 27.7401\n",
      "[564/1762] D loss: 0.0000, G loss: 23.9123\n",
      "[644/1762] D loss: 0.0000, G loss: 23.1646\n",
      "[724/1762] D loss: 0.0000, G loss: 27.4657\n",
      "[804/1762] D loss: 0.0000, G loss: 27.1028\n",
      "[884/1762] D loss: 0.0000, G loss: 19.1926\n",
      "[964/1762] D loss: 0.0000, G loss: 24.0308\n",
      "[1044/1762] D loss: 0.0000, G loss: 25.1166\n",
      "[1124/1762] D loss: 0.0000, G loss: 23.9296\n",
      "[1204/1762] D loss: 0.0000, G loss: 24.1696\n",
      "[1284/1762] D loss: 0.0000, G loss: 24.3821\n",
      "[1364/1762] D loss: 0.0000, G loss: 22.2602\n",
      "[1444/1762] D loss: 0.0000, G loss: 19.8581\n",
      "[1524/1762] D loss: 0.0000, G loss: 23.7755\n",
      "[1604/1762] D loss: 0.0000, G loss: 25.1753\n",
      "[1684/1762] D loss: 0.0000, G loss: 24.6907\n",
      "[1762/1762] D loss: 0.0000, G loss: 22.2457\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 24.484170, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 24.622188, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 26.6754\n",
      "[84/1762] D loss: 0.0000, G loss: 24.3276\n",
      "[164/1762] D loss: 0.0000, G loss: 25.3973\n",
      "[244/1762] D loss: 0.0000, G loss: 25.7852\n",
      "[324/1762] D loss: 0.0000, G loss: 26.2334\n",
      "[404/1762] D loss: 0.0000, G loss: 20.1308\n",
      "[484/1762] D loss: 0.0000, G loss: 24.8878\n",
      "[564/1762] D loss: 0.0000, G loss: 28.3111\n",
      "[644/1762] D loss: 0.0000, G loss: 27.1716\n",
      "[724/1762] D loss: 0.0000, G loss: 25.9809\n",
      "[804/1762] D loss: 0.0000, G loss: 23.5835\n",
      "[884/1762] D loss: 0.0000, G loss: 22.5358\n",
      "[964/1762] D loss: 0.0000, G loss: 21.9983\n",
      "[1044/1762] D loss: 0.0000, G loss: 24.5350\n",
      "[1124/1762] D loss: 0.0000, G loss: 26.5036\n",
      "[1204/1762] D loss: 0.0000, G loss: 18.0586\n",
      "[1284/1762] D loss: 0.0000, G loss: 28.8293\n",
      "[1364/1762] D loss: 0.0000, G loss: 18.7555\n",
      "[1444/1762] D loss: 0.0000, G loss: 21.7178\n",
      "[1524/1762] D loss: 0.0000, G loss: 21.7661\n",
      "[1604/1762] D loss: 0.0000, G loss: 25.4021\n",
      "[1684/1762] D loss: 0.0000, G loss: 24.8576\n",
      "[1762/1762] D loss: 0.0000, G loss: 17.3633\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 24.414032, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 24.557148, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 27.1200\n",
      "[84/1762] D loss: 0.0000, G loss: 22.2978\n",
      "[164/1762] D loss: 0.0000, G loss: 25.0883\n",
      "[244/1762] D loss: 0.0000, G loss: 25.5753\n",
      "[324/1762] D loss: 0.0000, G loss: 26.2325\n",
      "[404/1762] D loss: 0.0000, G loss: 20.7166\n",
      "[484/1762] D loss: 0.0000, G loss: 23.4398\n",
      "[564/1762] D loss: 0.0000, G loss: 19.6234\n",
      "[644/1762] D loss: 0.0000, G loss: 24.2447\n",
      "[724/1762] D loss: 0.0000, G loss: 24.2378\n",
      "[804/1762] D loss: 0.0000, G loss: 18.5900\n",
      "[884/1762] D loss: 0.0000, G loss: 17.3111\n",
      "[964/1762] D loss: 0.0000, G loss: 22.6894\n",
      "[1044/1762] D loss: 0.0000, G loss: 20.6236\n",
      "[1124/1762] D loss: 0.0000, G loss: 28.2759\n",
      "[1204/1762] D loss: 0.0000, G loss: 27.2621\n",
      "[1284/1762] D loss: 0.0000, G loss: 26.4697\n",
      "[1364/1762] D loss: 0.0000, G loss: 22.7916\n",
      "[1444/1762] D loss: 0.0000, G loss: 23.0716\n",
      "[1524/1762] D loss: 0.0000, G loss: 22.6462\n",
      "[1604/1762] D loss: 0.0000, G loss: 22.6230\n",
      "[1684/1762] D loss: 0.0000, G loss: 24.1979\n",
      "[1762/1762] D loss: 0.0000, G loss: 20.1334\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 24.387517, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 24.527447, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 25.7513\n",
      "[84/1762] D loss: 0.0000, G loss: 24.7956\n",
      "[164/1762] D loss: 0.0000, G loss: 24.1203\n",
      "[244/1762] D loss: 0.0000, G loss: 24.9901\n",
      "[324/1762] D loss: 0.0000, G loss: 27.0244\n",
      "[404/1762] D loss: 0.0000, G loss: 19.1422\n",
      "[484/1762] D loss: 0.0000, G loss: 21.7576\n",
      "[564/1762] D loss: 0.0000, G loss: 25.3227\n",
      "[644/1762] D loss: 0.0000, G loss: 26.1653\n",
      "[724/1762] D loss: 0.0000, G loss: 25.2292\n",
      "[804/1762] D loss: 0.0000, G loss: 21.7437\n",
      "[884/1762] D loss: 0.0000, G loss: 20.6853\n",
      "[964/1762] D loss: 0.0000, G loss: 21.4088\n",
      "[1044/1762] D loss: 0.0000, G loss: 28.2116\n",
      "[1124/1762] D loss: 0.0000, G loss: 22.6738\n",
      "[1204/1762] D loss: 0.0000, G loss: 25.2481\n",
      "[1284/1762] D loss: 0.0000, G loss: 25.9861\n",
      "[1364/1762] D loss: 0.0000, G loss: 20.9068\n",
      "[1444/1762] D loss: 0.0000, G loss: 20.0714\n",
      "[1524/1762] D loss: 0.0000, G loss: 23.1106\n",
      "[1604/1762] D loss: 0.0000, G loss: 26.2369\n",
      "[1684/1762] D loss: 0.0000, G loss: 26.5275\n",
      "[1762/1762] D loss: 0.0000, G loss: 24.2742\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 24.395741, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 24.533241, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 23.1861\n",
      "[84/1762] D loss: 0.0000, G loss: 21.2473\n",
      "[164/1762] D loss: 0.0000, G loss: 21.3080\n",
      "[244/1762] D loss: 0.0000, G loss: 24.2478\n",
      "[324/1762] D loss: 0.0000, G loss: 20.0446\n",
      "[404/1762] D loss: 0.0000, G loss: 23.8297\n",
      "[484/1762] D loss: 0.0000, G loss: 25.3882\n",
      "[564/1762] D loss: 0.0000, G loss: 21.3253\n",
      "[644/1762] D loss: 0.0000, G loss: 20.0631\n",
      "[724/1762] D loss: 0.0000, G loss: 21.1325\n",
      "[804/1762] D loss: 0.0000, G loss: 25.4834\n",
      "[884/1762] D loss: 0.0000, G loss: 22.2598\n",
      "[964/1762] D loss: 0.0000, G loss: 21.0879\n",
      "[1044/1762] D loss: 0.0000, G loss: 23.9046\n",
      "[1124/1762] D loss: 0.0000, G loss: 23.7270\n",
      "[1204/1762] D loss: 0.0000, G loss: 23.7748\n",
      "[1284/1762] D loss: 0.0000, G loss: 27.1905\n",
      "[1364/1762] D loss: 0.0000, G loss: 27.3976\n",
      "[1444/1762] D loss: 0.0000, G loss: 22.0729\n",
      "[1524/1762] D loss: 0.0000, G loss: 26.7391\n",
      "[1604/1762] D loss: 0.0000, G loss: 23.6400\n",
      "[1684/1762] D loss: 0.0000, G loss: 19.9431\n",
      "[1762/1762] D loss: 0.0000, G loss: 20.1761\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 24.410063, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 24.549997, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 24.5491\n",
      "[84/1762] D loss: 0.0000, G loss: 24.9638\n",
      "[164/1762] D loss: 0.0000, G loss: 22.0900\n",
      "[244/1762] D loss: 0.0000, G loss: 29.4455\n",
      "[324/1762] D loss: 0.0000, G loss: 28.1603\n",
      "[404/1762] D loss: 0.0000, G loss: 25.1476\n",
      "[484/1762] D loss: 0.0000, G loss: 23.0828\n",
      "[564/1762] D loss: 0.0000, G loss: 24.1541\n",
      "[644/1762] D loss: 0.0000, G loss: 26.9676\n",
      "[724/1762] D loss: 0.0000, G loss: 24.7126\n",
      "[804/1762] D loss: 0.0000, G loss: 26.3701\n",
      "[884/1762] D loss: 0.0000, G loss: 26.3532\n",
      "[964/1762] D loss: 0.0000, G loss: 27.2837\n",
      "[1044/1762] D loss: 0.0000, G loss: 23.7326\n",
      "[1124/1762] D loss: 0.0000, G loss: 26.1364\n",
      "[1204/1762] D loss: 0.0000, G loss: 23.0748\n",
      "[1284/1762] D loss: 0.0000, G loss: 27.1419\n",
      "[1364/1762] D loss: 0.0000, G loss: 24.8088\n",
      "[1444/1762] D loss: 0.0000, G loss: 28.4772\n",
      "[1524/1762] D loss: 0.0000, G loss: 24.0359\n",
      "[1604/1762] D loss: 0.0000, G loss: 20.8724\n",
      "[1684/1762] D loss: 0.0000, G loss: 20.0778\n",
      "[1762/1762] D loss: 0.0000, G loss: 32.2559\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 24.460666, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 24.598909, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 29.4691\n",
      "[84/1762] D loss: 0.0000, G loss: 20.5321\n",
      "[164/1762] D loss: 0.0000, G loss: 26.4538\n",
      "[244/1762] D loss: 0.0000, G loss: 27.8006\n",
      "[324/1762] D loss: 0.0000, G loss: 22.5433\n",
      "[404/1762] D loss: 0.0000, G loss: 21.2605\n",
      "[484/1762] D loss: 0.0000, G loss: 27.5463\n",
      "[564/1762] D loss: 0.0000, G loss: 26.0406\n",
      "[644/1762] D loss: 0.0000, G loss: 25.0150\n",
      "[724/1762] D loss: 0.0000, G loss: 22.3171\n",
      "[804/1762] D loss: 0.0000, G loss: 23.1872\n",
      "[884/1762] D loss: 0.0000, G loss: 24.9961\n",
      "[964/1762] D loss: 0.0000, G loss: 21.8260\n",
      "[1044/1762] D loss: 0.0000, G loss: 21.9953\n",
      "[1124/1762] D loss: 0.0000, G loss: 23.5834\n",
      "[1204/1762] D loss: 0.0000, G loss: 24.6444\n",
      "[1284/1762] D loss: 0.0000, G loss: 24.4994\n",
      "[1364/1762] D loss: 0.0000, G loss: 21.8020\n",
      "[1444/1762] D loss: 0.0000, G loss: 26.3730\n",
      "[1524/1762] D loss: 0.0000, G loss: 23.1421\n",
      "[1604/1762] D loss: 0.0000, G loss: 23.6560\n",
      "[1684/1762] D loss: 0.0000, G loss: 25.7392\n",
      "[1762/1762] D loss: 0.0000, G loss: 32.6491\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 24.515458, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 24.660828, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 18.9242\n",
      "[84/1762] D loss: 0.0000, G loss: 27.0415\n",
      "[164/1762] D loss: 0.0000, G loss: 21.7201\n",
      "[244/1762] D loss: 0.0000, G loss: 23.0508\n",
      "[324/1762] D loss: 0.0000, G loss: 23.3879\n",
      "[404/1762] D loss: 0.0000, G loss: 26.6307\n",
      "[484/1762] D loss: 0.0000, G loss: 22.4835\n",
      "[564/1762] D loss: 0.0000, G loss: 24.4150\n",
      "[644/1762] D loss: 0.0000, G loss: 26.5984\n",
      "[724/1762] D loss: 0.0000, G loss: 26.8916\n",
      "[804/1762] D loss: 0.0000, G loss: 23.3846\n",
      "[884/1762] D loss: 0.0000, G loss: 23.4510\n",
      "[964/1762] D loss: 0.0000, G loss: 22.7386\n",
      "[1044/1762] D loss: 0.0000, G loss: 22.4457\n",
      "[1124/1762] D loss: 0.0000, G loss: 29.2805\n",
      "[1204/1762] D loss: 0.0000, G loss: 25.7207\n",
      "[1284/1762] D loss: 0.0000, G loss: 20.9741\n",
      "[1364/1762] D loss: 0.0000, G loss: 29.4795\n",
      "[1444/1762] D loss: 0.0000, G loss: 27.2021\n",
      "[1524/1762] D loss: 0.0000, G loss: 30.6776\n",
      "[1604/1762] D loss: 0.0000, G loss: 22.9974\n",
      "[1684/1762] D loss: 0.0000, G loss: 23.8256\n",
      "[1762/1762] D loss: 0.0000, G loss: 24.5823\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 24.565355, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 24.695292, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 24.7207\n",
      "[84/1762] D loss: 0.0000, G loss: 29.9927\n",
      "[164/1762] D loss: 0.0000, G loss: 24.1530\n",
      "[244/1762] D loss: 0.0000, G loss: 21.7800\n",
      "[324/1762] D loss: 0.0000, G loss: 20.4200\n",
      "[404/1762] D loss: 0.0000, G loss: 22.3880\n",
      "[484/1762] D loss: 0.0000, G loss: 24.5022\n",
      "[564/1762] D loss: 0.0000, G loss: 26.6412\n",
      "[644/1762] D loss: 0.0000, G loss: 22.0363\n",
      "[724/1762] D loss: 0.0000, G loss: 23.4849\n",
      "[804/1762] D loss: 0.0000, G loss: 23.7950\n",
      "[884/1762] D loss: 0.0000, G loss: 25.7883\n",
      "[964/1762] D loss: 0.0000, G loss: 21.3762\n",
      "[1044/1762] D loss: 0.0000, G loss: 26.5081\n",
      "[1124/1762] D loss: 0.0000, G loss: 23.9043\n",
      "[1204/1762] D loss: 0.0000, G loss: 32.2358\n",
      "[1284/1762] D loss: 0.0000, G loss: 21.3518\n",
      "[1364/1762] D loss: 0.0000, G loss: 25.2696\n",
      "[1444/1762] D loss: 0.0000, G loss: 26.6843\n",
      "[1524/1762] D loss: 0.0000, G loss: 22.1229\n",
      "[1604/1762] D loss: 0.0000, G loss: 23.6923\n",
      "[1684/1762] D loss: 0.0000, G loss: 23.6182\n",
      "[1762/1762] D loss: 0.0000, G loss: 21.4050\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 24.735261, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 24.871330, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 24.6950\n",
      "[84/1762] D loss: 0.0000, G loss: 25.3477\n",
      "[164/1762] D loss: 0.0000, G loss: 25.2491\n",
      "[244/1762] D loss: 0.0000, G loss: 24.1317\n",
      "[324/1762] D loss: 0.0000, G loss: 27.8993\n",
      "[404/1762] D loss: 0.0000, G loss: 19.8552\n",
      "[484/1762] D loss: 0.0000, G loss: 22.1824\n",
      "[564/1762] D loss: 0.0000, G loss: 26.0892\n",
      "[644/1762] D loss: 0.0000, G loss: 27.2313\n",
      "[724/1762] D loss: 0.0000, G loss: 21.4449\n",
      "[804/1762] D loss: 0.0000, G loss: 26.2263\n",
      "[884/1762] D loss: 0.0000, G loss: 28.0838\n",
      "[964/1762] D loss: 0.0000, G loss: 19.8866\n",
      "[1044/1762] D loss: 0.0000, G loss: 25.4376\n",
      "[1124/1762] D loss: 0.0000, G loss: 26.2496\n",
      "[1204/1762] D loss: 0.0000, G loss: 27.8082\n",
      "[1284/1762] D loss: 0.0000, G loss: 26.5311\n",
      "[1364/1762] D loss: 0.0000, G loss: 29.1060\n",
      "[1444/1762] D loss: 0.0000, G loss: 27.4640\n",
      "[1524/1762] D loss: 0.0000, G loss: 19.7582\n",
      "[1604/1762] D loss: 0.0000, G loss: 20.4168\n",
      "[1684/1762] D loss: 0.0000, G loss: 26.2392\n",
      "[1762/1762] D loss: 0.0000, G loss: 20.6895\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 24.740957, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 24.881556, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 21.6361\n",
      "[84/1762] D loss: 0.0000, G loss: 22.5057\n",
      "[164/1762] D loss: 0.0000, G loss: 23.9629\n",
      "[244/1762] D loss: 0.0000, G loss: 21.4260\n",
      "[324/1762] D loss: 0.0000, G loss: 20.9421\n",
      "[404/1762] D loss: 0.0000, G loss: 28.3004\n",
      "[484/1762] D loss: 0.0000, G loss: 27.8325\n",
      "[564/1762] D loss: 0.0000, G loss: 23.6293\n",
      "[644/1762] D loss: 0.0000, G loss: 22.9048\n",
      "[724/1762] D loss: 0.0000, G loss: 22.6357\n",
      "[804/1762] D loss: 0.0000, G loss: 23.7203\n",
      "[884/1762] D loss: 0.0000, G loss: 29.8610\n",
      "[964/1762] D loss: 0.0000, G loss: 22.3650\n",
      "[1044/1762] D loss: 0.0000, G loss: 29.1937\n",
      "[1124/1762] D loss: 0.0000, G loss: 27.9190\n",
      "[1204/1762] D loss: 0.0000, G loss: 27.9350\n",
      "[1284/1762] D loss: 0.0000, G loss: 25.1176\n",
      "[1364/1762] D loss: 0.0000, G loss: 25.4192\n",
      "[1444/1762] D loss: 0.0000, G loss: 24.2480\n",
      "[1524/1762] D loss: 0.0000, G loss: 31.3677\n",
      "[1604/1762] D loss: 0.0000, G loss: 28.8603\n",
      "[1684/1762] D loss: 0.0000, G loss: 24.7726\n",
      "[1762/1762] D loss: 0.0000, G loss: 22.9953\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 24.955183, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 25.095051, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 24.0169\n",
      "[84/1762] D loss: 0.0000, G loss: 26.0494\n",
      "[164/1762] D loss: 0.0000, G loss: 25.9231\n",
      "[244/1762] D loss: 0.0000, G loss: 22.7311\n",
      "[324/1762] D loss: 0.0000, G loss: 26.8740\n",
      "[404/1762] D loss: 0.0000, G loss: 23.0943\n",
      "[484/1762] D loss: 0.0000, G loss: 22.2471\n",
      "[564/1762] D loss: 0.0000, G loss: 29.1295\n",
      "[644/1762] D loss: 0.0000, G loss: 22.5834\n",
      "[724/1762] D loss: 0.0000, G loss: 27.4069\n",
      "[804/1762] D loss: 0.0000, G loss: 25.5770\n",
      "[884/1762] D loss: 0.0000, G loss: 28.4018\n",
      "[964/1762] D loss: 0.0000, G loss: 25.3290\n",
      "[1044/1762] D loss: 0.0000, G loss: 20.7643\n",
      "[1124/1762] D loss: 0.0000, G loss: 28.1630\n",
      "[1204/1762] D loss: 0.0000, G loss: 30.0049\n",
      "[1284/1762] D loss: 0.0000, G loss: 22.2749\n",
      "[1364/1762] D loss: 0.0000, G loss: 23.3276\n",
      "[1444/1762] D loss: 0.0000, G loss: 24.7427\n",
      "[1524/1762] D loss: 0.0000, G loss: 28.3197\n",
      "[1604/1762] D loss: 0.0000, G loss: 25.1250\n",
      "[1684/1762] D loss: 0.0000, G loss: 22.8736\n",
      "[1762/1762] D loss: 0.0000, G loss: 20.2600\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 25.113817, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 25.258752, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 29.1336\n",
      "[84/1762] D loss: 0.0000, G loss: 29.1679\n",
      "[164/1762] D loss: 0.0000, G loss: 21.7950\n",
      "[244/1762] D loss: 0.0000, G loss: 23.6733\n",
      "[324/1762] D loss: 0.0000, G loss: 30.3496\n",
      "[404/1762] D loss: 0.0000, G loss: 26.5344\n",
      "[484/1762] D loss: 0.0000, G loss: 29.6196\n",
      "[564/1762] D loss: 0.0000, G loss: 25.9802\n",
      "[644/1762] D loss: 0.0000, G loss: 28.6133\n",
      "[724/1762] D loss: 0.0000, G loss: 25.5957\n",
      "[804/1762] D loss: 0.0000, G loss: 25.6516\n",
      "[884/1762] D loss: 0.0000, G loss: 21.3061\n",
      "[964/1762] D loss: 0.0000, G loss: 26.5596\n",
      "[1044/1762] D loss: 0.0000, G loss: 26.3364\n",
      "[1124/1762] D loss: 0.0000, G loss: 22.4544\n",
      "[1204/1762] D loss: 0.0000, G loss: 29.9234\n",
      "[1284/1762] D loss: 0.0000, G loss: 28.9180\n",
      "[1364/1762] D loss: 0.0000, G loss: 23.5188\n",
      "[1444/1762] D loss: 0.0000, G loss: 27.1293\n",
      "[1524/1762] D loss: 0.0000, G loss: 19.3328\n",
      "[1604/1762] D loss: 0.0000, G loss: 23.8906\n",
      "[1684/1762] D loss: 0.0000, G loss: 25.9979\n",
      "[1762/1762] D loss: 0.0000, G loss: 25.1500\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 25.133686, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 25.269245, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 23.8190\n",
      "[84/1762] D loss: 0.0000, G loss: 23.6372\n",
      "[164/1762] D loss: 0.0000, G loss: 28.2118\n",
      "[244/1762] D loss: 0.0000, G loss: 29.7993\n",
      "[324/1762] D loss: 0.0000, G loss: 22.7379\n",
      "[404/1762] D loss: 0.0000, G loss: 27.3392\n",
      "[484/1762] D loss: 0.0000, G loss: 24.8619\n",
      "[564/1762] D loss: 0.0000, G loss: 26.7133\n",
      "[644/1762] D loss: 0.0000, G loss: 32.1277\n",
      "[724/1762] D loss: 0.0000, G loss: 22.1049\n",
      "[804/1762] D loss: 0.0000, G loss: 28.4665\n",
      "[884/1762] D loss: 0.0000, G loss: 25.5533\n",
      "[964/1762] D loss: 0.0000, G loss: 28.2752\n",
      "[1044/1762] D loss: 0.0000, G loss: 27.8432\n",
      "[1124/1762] D loss: 0.0000, G loss: 26.2789\n",
      "[1204/1762] D loss: 0.0000, G loss: 21.6466\n",
      "[1284/1762] D loss: 0.0000, G loss: 27.3946\n",
      "[1364/1762] D loss: 0.0000, G loss: 23.2192\n",
      "[1444/1762] D loss: 0.0000, G loss: 27.3559\n",
      "[1524/1762] D loss: 0.0000, G loss: 22.4832\n",
      "[1604/1762] D loss: 0.0000, G loss: 23.4334\n",
      "[1684/1762] D loss: 0.0000, G loss: 21.8214\n",
      "[1762/1762] D loss: 0.0000, G loss: 23.9099\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 25.430291, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 25.567942, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 26.2868\n",
      "[84/1762] D loss: 0.0000, G loss: 24.2957\n",
      "[164/1762] D loss: 0.0000, G loss: 25.3041\n",
      "[244/1762] D loss: 0.0000, G loss: 20.3475\n",
      "[324/1762] D loss: 0.0000, G loss: 23.3439\n",
      "[404/1762] D loss: 0.0000, G loss: 23.3467\n",
      "[484/1762] D loss: 0.0000, G loss: 20.2499\n",
      "[564/1762] D loss: 0.0000, G loss: 25.8597\n",
      "[644/1762] D loss: 0.0000, G loss: 27.7869\n",
      "[724/1762] D loss: 0.0000, G loss: 21.6028\n",
      "[804/1762] D loss: 0.0000, G loss: 32.1107\n",
      "[884/1762] D loss: 0.0000, G loss: 27.5161\n",
      "[964/1762] D loss: 0.0000, G loss: 24.7062\n",
      "[1044/1762] D loss: 0.0000, G loss: 27.7601\n",
      "[1124/1762] D loss: 0.0000, G loss: 24.0602\n",
      "[1204/1762] D loss: 0.0000, G loss: 29.9086\n",
      "[1284/1762] D loss: 0.0000, G loss: 23.3226\n",
      "[1364/1762] D loss: 0.0000, G loss: 25.1468\n",
      "[1444/1762] D loss: 0.0000, G loss: 24.7252\n",
      "[1524/1762] D loss: 0.0000, G loss: 24.3813\n",
      "[1604/1762] D loss: 0.0000, G loss: 28.3428\n",
      "[1684/1762] D loss: 0.0000, G loss: 26.8599\n",
      "[1762/1762] D loss: 0.0000, G loss: 21.5446\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 25.542191, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 25.675074, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 24.4796\n",
      "[84/1762] D loss: 0.0000, G loss: 23.9683\n",
      "[164/1762] D loss: 0.0000, G loss: 25.2538\n",
      "[244/1762] D loss: 0.0000, G loss: 26.6162\n",
      "[324/1762] D loss: 0.0000, G loss: 30.1544\n",
      "[404/1762] D loss: 0.0000, G loss: 30.8556\n",
      "[484/1762] D loss: 0.0000, G loss: 30.3809\n",
      "[564/1762] D loss: 0.0000, G loss: 23.6664\n",
      "[644/1762] D loss: 0.0000, G loss: 26.4791\n",
      "[724/1762] D loss: 0.0000, G loss: 33.7826\n",
      "[804/1762] D loss: 0.0000, G loss: 22.5112\n",
      "[884/1762] D loss: 0.0000, G loss: 23.7277\n",
      "[964/1762] D loss: 0.0000, G loss: 29.1957\n",
      "[1044/1762] D loss: 0.0000, G loss: 26.8455\n",
      "[1124/1762] D loss: 0.0000, G loss: 25.8154\n",
      "[1204/1762] D loss: 0.0000, G loss: 24.0512\n",
      "[1284/1762] D loss: 0.0000, G loss: 22.7707\n",
      "[1364/1762] D loss: 0.0000, G loss: 20.6673\n",
      "[1444/1762] D loss: 0.0000, G loss: 26.1109\n",
      "[1524/1762] D loss: 0.0000, G loss: 20.2265\n",
      "[1604/1762] D loss: 0.0000, G loss: 26.0041\n",
      "[1684/1762] D loss: 0.0000, G loss: 21.7656\n",
      "[1762/1762] D loss: 0.0000, G loss: 24.5966\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 25.761915, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 25.904332, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 25.7956\n",
      "[84/1762] D loss: 0.0000, G loss: 27.5089\n",
      "[164/1762] D loss: 0.0000, G loss: 30.0523\n",
      "[244/1762] D loss: 0.0000, G loss: 28.5157\n",
      "[324/1762] D loss: 0.0000, G loss: 26.7218\n",
      "[404/1762] D loss: 0.0000, G loss: 23.1574\n",
      "[484/1762] D loss: 0.0000, G loss: 27.2884\n",
      "[564/1762] D loss: 0.0000, G loss: 26.3102\n",
      "[644/1762] D loss: 0.0000, G loss: 27.5153\n",
      "[724/1762] D loss: 0.0000, G loss: 24.3942\n",
      "[804/1762] D loss: 0.0000, G loss: 26.1875\n",
      "[884/1762] D loss: 0.0000, G loss: 21.2416\n",
      "[964/1762] D loss: 0.0000, G loss: 23.6887\n",
      "[1044/1762] D loss: 0.0000, G loss: 26.7482\n",
      "[1124/1762] D loss: 0.0000, G loss: 28.1551\n",
      "[1204/1762] D loss: 0.0000, G loss: 30.2830\n",
      "[1284/1762] D loss: 0.0000, G loss: 22.5304\n",
      "[1364/1762] D loss: 0.0000, G loss: 25.6321\n",
      "[1444/1762] D loss: 0.0000, G loss: 27.3639\n",
      "[1524/1762] D loss: 0.0000, G loss: 28.0294\n",
      "[1604/1762] D loss: 0.0000, G loss: 24.3633\n",
      "[1684/1762] D loss: 0.0000, G loss: 29.3848\n",
      "[1762/1762] D loss: 0.0000, G loss: 22.0954\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 25.904497, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 26.043491, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 30.3450\n",
      "[84/1762] D loss: 0.0000, G loss: 23.6592\n",
      "[164/1762] D loss: 0.0000, G loss: 26.1651\n",
      "[244/1762] D loss: 0.0000, G loss: 29.3805\n",
      "[324/1762] D loss: 0.0000, G loss: 26.1497\n",
      "[404/1762] D loss: 0.0000, G loss: 21.6684\n",
      "[484/1762] D loss: 0.0000, G loss: 24.6148\n",
      "[564/1762] D loss: 0.0000, G loss: 27.7775\n",
      "[644/1762] D loss: 0.0000, G loss: 24.1770\n",
      "[724/1762] D loss: 0.0000, G loss: 28.0156\n",
      "[804/1762] D loss: 0.0000, G loss: 34.5879\n",
      "[884/1762] D loss: 0.0000, G loss: 27.0183\n",
      "[964/1762] D loss: 0.0000, G loss: 23.1331\n",
      "[1044/1762] D loss: 0.0000, G loss: 27.3095\n",
      "[1124/1762] D loss: 0.0000, G loss: 26.3817\n",
      "[1204/1762] D loss: 0.0000, G loss: 28.4640\n",
      "[1284/1762] D loss: 0.0000, G loss: 28.2393\n",
      "[1364/1762] D loss: 0.0000, G loss: 23.7175\n",
      "[1444/1762] D loss: 0.0000, G loss: 27.0171\n",
      "[1524/1762] D loss: 0.0000, G loss: 23.8823\n",
      "[1604/1762] D loss: 0.0000, G loss: 24.5305\n",
      "[1684/1762] D loss: 0.0000, G loss: 21.8614\n",
      "[1762/1762] D loss: 0.0000, G loss: 24.8710\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 26.206464, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 26.347942, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 21.3960\n",
      "[84/1762] D loss: 0.0000, G loss: 23.3968\n",
      "[164/1762] D loss: 0.0000, G loss: 24.5593\n",
      "[244/1762] D loss: 0.0000, G loss: 29.9216\n",
      "[324/1762] D loss: 0.0000, G loss: 25.3207\n",
      "[404/1762] D loss: 0.0000, G loss: 28.3499\n",
      "[484/1762] D loss: 0.0000, G loss: 23.8939\n",
      "[564/1762] D loss: 0.0000, G loss: 28.7224\n",
      "[644/1762] D loss: 0.0000, G loss: 32.0485\n",
      "[724/1762] D loss: 0.0000, G loss: 25.5070\n",
      "[804/1762] D loss: 0.0000, G loss: 24.5359\n",
      "[884/1762] D loss: 0.0000, G loss: 28.4927\n",
      "[964/1762] D loss: 0.0000, G loss: 24.5979\n",
      "[1044/1762] D loss: 0.0000, G loss: 27.6798\n",
      "[1124/1762] D loss: 0.0000, G loss: 23.7505\n",
      "[1204/1762] D loss: 0.0000, G loss: 25.1709\n",
      "[1284/1762] D loss: 0.0000, G loss: 23.1479\n",
      "[1364/1762] D loss: 0.0000, G loss: 30.2289\n",
      "[1444/1762] D loss: 0.0000, G loss: 31.8315\n",
      "[1524/1762] D loss: 0.0000, G loss: 29.0597\n",
      "[1604/1762] D loss: 0.0000, G loss: 26.3413\n",
      "[1684/1762] D loss: 0.0000, G loss: 25.9198\n",
      "[1762/1762] D loss: 0.0000, G loss: 31.5222\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 26.652757, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 26.804599, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 26.1828\n",
      "[84/1762] D loss: 0.0000, G loss: 31.3698\n",
      "[164/1762] D loss: 0.0000, G loss: 31.0389\n",
      "[244/1762] D loss: 0.0000, G loss: 31.0217\n",
      "[324/1762] D loss: 0.0000, G loss: 23.5950\n",
      "[404/1762] D loss: 0.0000, G loss: 24.7101\n",
      "[484/1762] D loss: 0.0000, G loss: 22.4982\n",
      "[564/1762] D loss: 0.0000, G loss: 25.6014\n",
      "[644/1762] D loss: 0.0000, G loss: 24.2308\n",
      "[724/1762] D loss: 0.0000, G loss: 22.6471\n",
      "[804/1762] D loss: 0.0000, G loss: 29.2203\n",
      "[884/1762] D loss: 0.0000, G loss: 22.9378\n",
      "[964/1762] D loss: 0.0000, G loss: 31.8519\n",
      "[1044/1762] D loss: 0.0000, G loss: 21.5124\n",
      "[1124/1762] D loss: 0.0000, G loss: 24.6898\n",
      "[1204/1762] D loss: 0.0000, G loss: 26.1517\n",
      "[1284/1762] D loss: 0.0000, G loss: 23.0298\n",
      "[1364/1762] D loss: 0.0000, G loss: 18.9988\n",
      "[1444/1762] D loss: 0.0000, G loss: 27.6241\n",
      "[1524/1762] D loss: 0.0000, G loss: 27.4093\n",
      "[1604/1762] D loss: 0.0000, G loss: 32.0397\n",
      "[1684/1762] D loss: 0.0000, G loss: 26.3868\n",
      "[1762/1762] D loss: 0.0000, G loss: 22.7312\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 26.861561, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 27.009650, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 23.4740\n",
      "[84/1762] D loss: 0.0000, G loss: 29.9277\n",
      "[164/1762] D loss: 0.0000, G loss: 22.9662\n",
      "[244/1762] D loss: 0.0000, G loss: 29.3643\n",
      "[324/1762] D loss: 0.0000, G loss: 24.9428\n",
      "[404/1762] D loss: 0.0000, G loss: 30.6912\n",
      "[484/1762] D loss: 0.0000, G loss: 27.7263\n",
      "[564/1762] D loss: 0.0000, G loss: 23.2761\n",
      "[644/1762] D loss: 0.0000, G loss: 27.2004\n",
      "[724/1762] D loss: 0.0000, G loss: 26.7356\n",
      "[804/1762] D loss: 0.0000, G loss: 27.5950\n",
      "[884/1762] D loss: 0.0000, G loss: 24.8934\n",
      "[964/1762] D loss: 0.0000, G loss: 28.1022\n",
      "[1044/1762] D loss: 0.0000, G loss: 24.7595\n",
      "[1124/1762] D loss: 0.0000, G loss: 24.2269\n",
      "[1204/1762] D loss: 0.0000, G loss: 32.6797\n",
      "[1284/1762] D loss: 0.0000, G loss: 24.3150\n",
      "[1364/1762] D loss: 0.0000, G loss: 28.5453\n",
      "[1444/1762] D loss: 0.0000, G loss: 30.3987\n",
      "[1524/1762] D loss: 0.0000, G loss: 26.7097\n",
      "[1604/1762] D loss: 0.0000, G loss: 30.8467\n",
      "[1684/1762] D loss: 0.0000, G loss: 27.9074\n",
      "[1762/1762] D loss: 0.0000, G loss: 25.5380\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 27.041390, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 27.189999, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 29.4541\n",
      "[84/1762] D loss: 0.0000, G loss: 23.2758\n",
      "[164/1762] D loss: 0.0000, G loss: 26.7208\n",
      "[244/1762] D loss: 0.0000, G loss: 25.7773\n",
      "[324/1762] D loss: 0.0000, G loss: 25.8896\n",
      "[404/1762] D loss: 0.0000, G loss: 26.4413\n",
      "[484/1762] D loss: 0.0000, G loss: 33.1748\n",
      "[564/1762] D loss: 0.0000, G loss: 29.9163\n",
      "[644/1762] D loss: 0.0000, G loss: 26.8605\n",
      "[724/1762] D loss: 0.0000, G loss: 25.8635\n",
      "[804/1762] D loss: 0.0000, G loss: 30.0714\n",
      "[884/1762] D loss: 0.0000, G loss: 32.3687\n",
      "[964/1762] D loss: 0.0000, G loss: 25.9177\n",
      "[1044/1762] D loss: 0.0000, G loss: 28.0974\n",
      "[1124/1762] D loss: 0.0000, G loss: 24.2640\n",
      "[1204/1762] D loss: 0.0000, G loss: 25.4718\n",
      "[1284/1762] D loss: 0.0000, G loss: 27.0609\n",
      "[1364/1762] D loss: 0.0000, G loss: 25.2673\n",
      "[1444/1762] D loss: 0.0000, G loss: 31.8659\n",
      "[1524/1762] D loss: 0.0000, G loss: 27.6388\n",
      "[1604/1762] D loss: 0.0000, G loss: 30.6374\n",
      "[1684/1762] D loss: 0.0000, G loss: 28.7211\n",
      "[1762/1762] D loss: 0.0000, G loss: 22.5510\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 27.258964, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 27.415254, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 31.5947\n",
      "[84/1762] D loss: 0.0000, G loss: 25.7587\n",
      "[164/1762] D loss: 0.0000, G loss: 27.7702\n",
      "[244/1762] D loss: 0.0000, G loss: 25.1854\n",
      "[324/1762] D loss: 0.0000, G loss: 25.1754\n",
      "[404/1762] D loss: 0.0000, G loss: 32.3979\n",
      "[484/1762] D loss: 0.0000, G loss: 28.0587\n",
      "[564/1762] D loss: 0.0000, G loss: 32.0030\n",
      "[644/1762] D loss: 0.0000, G loss: 25.6045\n",
      "[724/1762] D loss: 0.0000, G loss: 24.2043\n",
      "[804/1762] D loss: 0.0000, G loss: 32.2105\n",
      "[884/1762] D loss: 0.0000, G loss: 28.0433\n",
      "[964/1762] D loss: 0.0000, G loss: 29.4066\n",
      "[1044/1762] D loss: 0.0000, G loss: 32.1789\n",
      "[1124/1762] D loss: 0.0000, G loss: 24.1732\n",
      "[1204/1762] D loss: 0.0000, G loss: 33.9526\n",
      "[1284/1762] D loss: 0.0000, G loss: 29.4762\n",
      "[1364/1762] D loss: 0.0000, G loss: 25.5710\n",
      "[1444/1762] D loss: 0.0000, G loss: 24.5015\n",
      "[1524/1762] D loss: 0.0000, G loss: 27.5912\n",
      "[1604/1762] D loss: 0.0000, G loss: 30.2908\n",
      "[1684/1762] D loss: 0.0000, G loss: 21.2351\n",
      "[1762/1762] D loss: 0.0000, G loss: 23.4498\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 27.611394, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 27.771552, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 25.7233\n",
      "[84/1762] D loss: 0.0000, G loss: 27.2150\n",
      "[164/1762] D loss: 0.0000, G loss: 26.9271\n",
      "[244/1762] D loss: 0.0000, G loss: 24.8772\n",
      "[324/1762] D loss: 0.0000, G loss: 25.6828\n",
      "[404/1762] D loss: 0.0000, G loss: 27.0437\n",
      "[484/1762] D loss: 0.0000, G loss: 27.2248\n",
      "[564/1762] D loss: 0.0000, G loss: 25.8787\n",
      "[644/1762] D loss: 0.0000, G loss: 26.7747\n",
      "[724/1762] D loss: 0.0000, G loss: 30.2910\n",
      "[804/1762] D loss: 0.0000, G loss: 28.5697\n",
      "[884/1762] D loss: 0.0000, G loss: 31.3881\n",
      "[964/1762] D loss: 0.0000, G loss: 27.0702\n",
      "[1044/1762] D loss: 0.0000, G loss: 26.5408\n",
      "[1124/1762] D loss: 0.0000, G loss: 24.8633\n",
      "[1204/1762] D loss: 0.0000, G loss: 27.3749\n",
      "[1284/1762] D loss: 0.0000, G loss: 26.0930\n",
      "[1364/1762] D loss: 0.0000, G loss: 29.6693\n",
      "[1444/1762] D loss: 0.0000, G loss: 26.6904\n",
      "[1524/1762] D loss: 0.0000, G loss: 23.6441\n",
      "[1604/1762] D loss: 0.0000, G loss: 30.7501\n",
      "[1684/1762] D loss: 0.0000, G loss: 22.8749\n",
      "[1762/1762] D loss: 0.0000, G loss: 39.0469\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 27.811148, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 27.963523, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 28.3662\n",
      "[84/1762] D loss: 0.0000, G loss: 33.6096\n",
      "[164/1762] D loss: 0.0000, G loss: 29.3279\n",
      "[244/1762] D loss: 0.0000, G loss: 26.7064\n",
      "[324/1762] D loss: 0.0000, G loss: 23.4506\n",
      "[404/1762] D loss: 0.0000, G loss: 29.7358\n",
      "[484/1762] D loss: 0.0000, G loss: 25.9804\n",
      "[564/1762] D loss: 0.0000, G loss: 32.9373\n",
      "[644/1762] D loss: 0.0000, G loss: 31.3666\n",
      "[724/1762] D loss: 0.0000, G loss: 21.7392\n",
      "[804/1762] D loss: 0.0000, G loss: 28.7904\n",
      "[884/1762] D loss: 0.0000, G loss: 28.7593\n",
      "[964/1762] D loss: 0.0000, G loss: 29.8506\n",
      "[1044/1762] D loss: 0.0000, G loss: 31.0675\n",
      "[1124/1762] D loss: 0.0000, G loss: 26.7061\n",
      "[1204/1762] D loss: 0.0000, G loss: 30.1962\n",
      "[1284/1762] D loss: 0.0000, G loss: 29.4246\n",
      "[1364/1762] D loss: 0.0000, G loss: 19.7804\n",
      "[1444/1762] D loss: 0.0000, G loss: 25.1921\n",
      "[1524/1762] D loss: 0.0000, G loss: 30.2745\n",
      "[1604/1762] D loss: 0.0000, G loss: 28.6429\n",
      "[1684/1762] D loss: 0.0000, G loss: 25.0389\n",
      "[1762/1762] D loss: 0.0000, G loss: 22.8745\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 28.044990, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 28.199835, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 29.6265\n",
      "[84/1762] D loss: 0.0000, G loss: 28.3965\n",
      "[164/1762] D loss: 0.0000, G loss: 25.0160\n",
      "[244/1762] D loss: 0.0000, G loss: 26.1855\n",
      "[324/1762] D loss: 0.0000, G loss: 34.5975\n",
      "[404/1762] D loss: 0.0000, G loss: 30.1292\n",
      "[484/1762] D loss: 0.0000, G loss: 31.0518\n",
      "[564/1762] D loss: 0.0000, G loss: 27.8310\n",
      "[644/1762] D loss: 0.0000, G loss: 29.3693\n",
      "[724/1762] D loss: 0.0000, G loss: 27.3929\n",
      "[804/1762] D loss: 0.0000, G loss: 31.8134\n",
      "[884/1762] D loss: 0.0000, G loss: 28.7763\n",
      "[964/1762] D loss: 0.0000, G loss: 31.2925\n",
      "[1044/1762] D loss: 0.0000, G loss: 20.2478\n",
      "[1124/1762] D loss: 0.0000, G loss: 23.6156\n",
      "[1204/1762] D loss: 0.0000, G loss: 29.1925\n",
      "[1284/1762] D loss: 0.0000, G loss: 26.3214\n",
      "[1364/1762] D loss: 0.0000, G loss: 29.9059\n",
      "[1444/1762] D loss: 0.0000, G loss: 30.4841\n",
      "[1524/1762] D loss: 0.0000, G loss: 32.5356\n",
      "[1604/1762] D loss: 0.0000, G loss: 32.9814\n",
      "[1684/1762] D loss: 0.0000, G loss: 28.0921\n",
      "[1762/1762] D loss: 0.0000, G loss: 31.7268\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 28.559107, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 28.719814, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 27.5336\n",
      "[84/1762] D loss: 0.0000, G loss: 30.7756\n",
      "[164/1762] D loss: 0.0000, G loss: 30.2819\n",
      "[244/1762] D loss: 0.0000, G loss: 31.8002\n",
      "[324/1762] D loss: 0.0000, G loss: 25.5138\n",
      "[404/1762] D loss: 0.0000, G loss: 30.6800\n",
      "[484/1762] D loss: 0.0000, G loss: 26.2044\n",
      "[564/1762] D loss: 0.0000, G loss: 29.4732\n",
      "[644/1762] D loss: 0.0000, G loss: 30.0171\n",
      "[724/1762] D loss: 0.0000, G loss: 26.5987\n",
      "[804/1762] D loss: 0.0000, G loss: 36.4705\n",
      "[884/1762] D loss: 0.0000, G loss: 19.6241\n",
      "[964/1762] D loss: 0.0000, G loss: 30.5322\n",
      "[1044/1762] D loss: 0.0000, G loss: 31.2595\n",
      "[1124/1762] D loss: 0.0000, G loss: 27.7260\n",
      "[1204/1762] D loss: 0.0000, G loss: 30.5279\n",
      "[1284/1762] D loss: 0.0000, G loss: 27.3216\n",
      "[1364/1762] D loss: 0.0000, G loss: 32.4684\n",
      "[1444/1762] D loss: 0.0000, G loss: 28.4905\n",
      "[1524/1762] D loss: 0.0000, G loss: 29.7580\n",
      "[1604/1762] D loss: 0.0000, G loss: 32.0675\n",
      "[1684/1762] D loss: 0.0000, G loss: 28.6798\n",
      "[1762/1762] D loss: 0.0000, G loss: 31.6667\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 28.747390, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 28.897876, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 32.4684\n",
      "[84/1762] D loss: 0.0000, G loss: 28.5255\n",
      "[164/1762] D loss: 0.0000, G loss: 28.5055\n",
      "[244/1762] D loss: 0.0000, G loss: 27.9427\n",
      "[324/1762] D loss: 0.0000, G loss: 28.6283\n",
      "[404/1762] D loss: 0.0000, G loss: 28.7753\n",
      "[484/1762] D loss: 0.0000, G loss: 23.4787\n",
      "[564/1762] D loss: 0.0000, G loss: 35.3389\n",
      "[644/1762] D loss: 0.0000, G loss: 31.1173\n",
      "[724/1762] D loss: 0.0000, G loss: 29.4235\n",
      "[804/1762] D loss: 0.0000, G loss: 23.3410\n",
      "[884/1762] D loss: 0.0000, G loss: 28.9591\n",
      "[964/1762] D loss: 0.0000, G loss: 29.9864\n",
      "[1044/1762] D loss: 0.0000, G loss: 27.7643\n",
      "[1124/1762] D loss: 0.0000, G loss: 24.4048\n",
      "[1204/1762] D loss: 0.0000, G loss: 32.4871\n",
      "[1284/1762] D loss: 0.0000, G loss: 30.7235\n",
      "[1364/1762] D loss: 0.0000, G loss: 34.8880\n",
      "[1444/1762] D loss: 0.0000, G loss: 25.7869\n",
      "[1524/1762] D loss: 0.0000, G loss: 31.1238\n",
      "[1604/1762] D loss: 0.0000, G loss: 31.1853\n",
      "[1684/1762] D loss: 0.0000, G loss: 33.1509\n",
      "[1762/1762] D loss: 0.0000, G loss: 29.5086\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 29.248025, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 29.407483, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 25.5949\n",
      "[84/1762] D loss: 0.0000, G loss: 33.5512\n",
      "[164/1762] D loss: 0.0000, G loss: 32.6569\n",
      "[244/1762] D loss: 0.0000, G loss: 28.0327\n",
      "[324/1762] D loss: 0.0000, G loss: 24.5753\n",
      "[404/1762] D loss: 0.0000, G loss: 35.3878\n",
      "[484/1762] D loss: 0.0000, G loss: 29.6083\n",
      "[564/1762] D loss: 0.0000, G loss: 31.4915\n",
      "[644/1762] D loss: 0.0000, G loss: 22.4679\n",
      "[724/1762] D loss: 0.0000, G loss: 27.6289\n",
      "[804/1762] D loss: 0.0000, G loss: 32.7846\n",
      "[884/1762] D loss: 0.0000, G loss: 26.0735\n",
      "[964/1762] D loss: 0.0000, G loss: 29.5779\n",
      "[1044/1762] D loss: 0.0000, G loss: 28.4932\n",
      "[1124/1762] D loss: 0.0000, G loss: 35.2449\n",
      "[1204/1762] D loss: 0.0000, G loss: 32.4653\n",
      "[1284/1762] D loss: 0.0000, G loss: 28.9916\n",
      "[1364/1762] D loss: 0.0000, G loss: 30.9556\n",
      "[1444/1762] D loss: 0.0000, G loss: 27.5138\n",
      "[1524/1762] D loss: 0.0000, G loss: 29.8973\n",
      "[1604/1762] D loss: 0.0000, G loss: 28.9520\n",
      "[1684/1762] D loss: 0.0000, G loss: 33.5841\n",
      "[1762/1762] D loss: 0.0000, G loss: 24.1803\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 29.529524, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 29.695144, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 30.9829\n",
      "[84/1762] D loss: 0.0000, G loss: 25.2963\n",
      "[164/1762] D loss: 0.0000, G loss: 29.7120\n",
      "[244/1762] D loss: 0.0000, G loss: 26.0783\n",
      "[324/1762] D loss: 0.0000, G loss: 35.1249\n",
      "[404/1762] D loss: 0.0000, G loss: 26.7289\n",
      "[484/1762] D loss: 0.0000, G loss: 31.4494\n",
      "[564/1762] D loss: 0.0000, G loss: 27.7306\n",
      "[644/1762] D loss: 0.0000, G loss: 31.4142\n",
      "[724/1762] D loss: 0.0000, G loss: 28.7020\n",
      "[804/1762] D loss: 0.0000, G loss: 26.6125\n",
      "[884/1762] D loss: 0.0000, G loss: 31.6440\n",
      "[964/1762] D loss: 0.0000, G loss: 31.0829\n",
      "[1044/1762] D loss: 0.0000, G loss: 32.6968\n",
      "[1124/1762] D loss: 0.0000, G loss: 28.4504\n",
      "[1204/1762] D loss: 0.0000, G loss: 32.5723\n",
      "[1284/1762] D loss: 0.0000, G loss: 31.0314\n",
      "[1364/1762] D loss: 0.0000, G loss: 31.1954\n",
      "[1444/1762] D loss: 0.0000, G loss: 26.3394\n",
      "[1524/1762] D loss: 0.0000, G loss: 32.8225\n",
      "[1604/1762] D loss: 0.0000, G loss: 23.3881\n",
      "[1684/1762] D loss: 0.0000, G loss: 27.0012\n",
      "[1762/1762] D loss: 0.0000, G loss: 32.2730\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 29.745533, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 29.902265, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 33.9133\n",
      "[84/1762] D loss: 0.0000, G loss: 25.5980\n",
      "[164/1762] D loss: 0.0000, G loss: 28.7602\n",
      "[244/1762] D loss: 0.0000, G loss: 28.5632\n",
      "[324/1762] D loss: 0.0000, G loss: 33.9013\n",
      "[404/1762] D loss: 0.0000, G loss: 33.3597\n",
      "[484/1762] D loss: 0.0000, G loss: 30.6768\n",
      "[564/1762] D loss: 0.0000, G loss: 31.5480\n",
      "[644/1762] D loss: 0.0000, G loss: 30.6448\n",
      "[724/1762] D loss: 0.0000, G loss: 33.5812\n",
      "[804/1762] D loss: 0.0000, G loss: 26.2300\n",
      "[884/1762] D loss: 0.0000, G loss: 30.0689\n",
      "[964/1762] D loss: 0.0000, G loss: 29.7838\n",
      "[1044/1762] D loss: 0.0000, G loss: 30.5549\n",
      "[1124/1762] D loss: 0.0000, G loss: 29.1862\n",
      "[1204/1762] D loss: 0.0000, G loss: 25.0186\n",
      "[1284/1762] D loss: 0.0000, G loss: 33.4331\n",
      "[1364/1762] D loss: 0.0000, G loss: 30.6505\n",
      "[1444/1762] D loss: 0.0000, G loss: 34.7545\n",
      "[1524/1762] D loss: 0.0000, G loss: 33.0910\n",
      "[1604/1762] D loss: 0.0000, G loss: 25.3918\n",
      "[1684/1762] D loss: 0.0000, G loss: 26.0928\n",
      "[1762/1762] D loss: 0.0000, G loss: 27.5694\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 30.311662, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 30.465031, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 34.8515\n",
      "[84/1762] D loss: 0.0000, G loss: 26.3501\n",
      "[164/1762] D loss: 0.0000, G loss: 37.0657\n",
      "[244/1762] D loss: 0.0000, G loss: 28.5036\n",
      "[324/1762] D loss: 0.0000, G loss: 31.6155\n",
      "[404/1762] D loss: 0.0000, G loss: 23.4635\n",
      "[484/1762] D loss: 0.0000, G loss: 34.4435\n",
      "[564/1762] D loss: 0.0000, G loss: 32.4347\n",
      "[644/1762] D loss: 0.0000, G loss: 34.2976\n",
      "[724/1762] D loss: 0.0000, G loss: 26.2434\n",
      "[804/1762] D loss: 0.0000, G loss: 33.5177\n",
      "[884/1762] D loss: 0.0000, G loss: 27.5052\n",
      "[964/1762] D loss: 0.0000, G loss: 30.5606\n",
      "[1044/1762] D loss: 0.0000, G loss: 29.6040\n",
      "[1124/1762] D loss: 0.0000, G loss: 28.4245\n",
      "[1204/1762] D loss: 0.0000, G loss: 28.5996\n",
      "[1284/1762] D loss: 0.0000, G loss: 30.4391\n",
      "[1364/1762] D loss: 0.0000, G loss: 35.5641\n",
      "[1444/1762] D loss: 0.0000, G loss: 26.2900\n",
      "[1524/1762] D loss: 0.0000, G loss: 26.2942\n",
      "[1604/1762] D loss: 0.0000, G loss: 34.5263\n",
      "[1684/1762] D loss: 0.0000, G loss: 22.4718\n",
      "[1762/1762] D loss: 0.0000, G loss: 29.0396\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 30.535051, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 30.698774, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 37.2511\n",
      "[84/1762] D loss: 0.0000, G loss: 29.1728\n",
      "[164/1762] D loss: 0.0000, G loss: 29.7782\n",
      "[244/1762] D loss: 0.0000, G loss: 29.9275\n",
      "[324/1762] D loss: 0.0000, G loss: 26.5720\n",
      "[404/1762] D loss: 0.0000, G loss: 29.9179\n",
      "[484/1762] D loss: 0.0000, G loss: 30.1121\n",
      "[564/1762] D loss: 0.0000, G loss: 33.8768\n",
      "[644/1762] D loss: 0.0000, G loss: 32.0311\n",
      "[724/1762] D loss: 0.0000, G loss: 29.3877\n",
      "[804/1762] D loss: 0.0000, G loss: 29.4939\n",
      "[884/1762] D loss: 0.0000, G loss: 29.7364\n",
      "[964/1762] D loss: 0.0000, G loss: 30.6153\n",
      "[1044/1762] D loss: 0.0000, G loss: 24.7393\n",
      "[1124/1762] D loss: 0.0000, G loss: 32.1274\n",
      "[1204/1762] D loss: 0.0000, G loss: 27.5257\n",
      "[1284/1762] D loss: 0.0000, G loss: 33.4372\n",
      "[1364/1762] D loss: 0.0000, G loss: 37.6149\n",
      "[1444/1762] D loss: 0.0000, G loss: 29.2936\n",
      "[1524/1762] D loss: 0.0000, G loss: 26.5459\n",
      "[1604/1762] D loss: 0.0000, G loss: 33.3007\n",
      "[1684/1762] D loss: 0.0000, G loss: 33.7509\n",
      "[1762/1762] D loss: 0.0000, G loss: 29.1196\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 30.982099, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 31.153421, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 32.1494\n",
      "[84/1762] D loss: 0.0000, G loss: 29.4156\n",
      "[164/1762] D loss: 0.0000, G loss: 31.5362\n",
      "[244/1762] D loss: 0.0000, G loss: 25.8989\n",
      "[324/1762] D loss: 0.0000, G loss: 30.9599\n",
      "[404/1762] D loss: 0.0000, G loss: 33.8679\n",
      "[484/1762] D loss: 0.0000, G loss: 33.1178\n",
      "[564/1762] D loss: 0.0000, G loss: 29.6328\n",
      "[644/1762] D loss: 0.0000, G loss: 29.2610\n",
      "[724/1762] D loss: 0.0000, G loss: 28.5339\n",
      "[804/1762] D loss: 0.0000, G loss: 26.6671\n",
      "[884/1762] D loss: 0.0000, G loss: 27.9947\n",
      "[964/1762] D loss: 0.0000, G loss: 31.3761\n",
      "[1044/1762] D loss: 0.0000, G loss: 28.1306\n",
      "[1124/1762] D loss: 0.0000, G loss: 29.6955\n",
      "[1204/1762] D loss: 0.0000, G loss: 28.7110\n",
      "[1284/1762] D loss: 0.0000, G loss: 37.5868\n",
      "[1364/1762] D loss: 0.0000, G loss: 28.6211\n",
      "[1444/1762] D loss: 0.0000, G loss: 33.3187\n",
      "[1524/1762] D loss: 0.0000, G loss: 30.2881\n",
      "[1604/1762] D loss: 0.0000, G loss: 33.9631\n",
      "[1684/1762] D loss: 0.0000, G loss: 26.3230\n",
      "[1762/1762] D loss: 0.0000, G loss: 33.7452\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 30.792616, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 30.951637, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 25.4727\n",
      "[84/1762] D loss: 0.0000, G loss: 32.4502\n",
      "[164/1762] D loss: 0.0000, G loss: 28.9244\n",
      "[244/1762] D loss: 0.0000, G loss: 27.3821\n",
      "[324/1762] D loss: 0.0000, G loss: 32.2062\n",
      "[404/1762] D loss: 0.0000, G loss: 36.1814\n",
      "[484/1762] D loss: 0.0000, G loss: 24.4549\n",
      "[564/1762] D loss: 0.0000, G loss: 36.5351\n",
      "[644/1762] D loss: 0.0000, G loss: 27.6738\n",
      "[724/1762] D loss: 0.0000, G loss: 24.0095\n",
      "[804/1762] D loss: 0.0000, G loss: 27.8520\n",
      "[884/1762] D loss: 0.0000, G loss: 35.5747\n",
      "[964/1762] D loss: 0.0000, G loss: 32.5715\n",
      "[1044/1762] D loss: 0.0000, G loss: 27.4632\n",
      "[1124/1762] D loss: 0.0000, G loss: 29.3445\n",
      "[1204/1762] D loss: 0.0000, G loss: 33.0715\n",
      "[1284/1762] D loss: 0.0000, G loss: 35.2656\n",
      "[1364/1762] D loss: 0.0000, G loss: 30.1584\n",
      "[1444/1762] D loss: 0.0000, G loss: 31.1466\n",
      "[1524/1762] D loss: 0.0000, G loss: 31.9676\n",
      "[1604/1762] D loss: 0.0000, G loss: 35.0424\n",
      "[1684/1762] D loss: 0.0000, G loss: 22.8968\n",
      "[1762/1762] D loss: 0.0000, G loss: 33.4604\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 31.371356, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 31.549115, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 27.7280\n",
      "[84/1762] D loss: 0.0000, G loss: 30.0857\n",
      "[164/1762] D loss: 0.0000, G loss: 30.8747\n",
      "[244/1762] D loss: 0.0000, G loss: 27.5163\n",
      "[324/1762] D loss: 0.0000, G loss: 29.9092\n",
      "[404/1762] D loss: 0.0000, G loss: 32.9491\n",
      "[484/1762] D loss: 0.0000, G loss: 31.0599\n",
      "[564/1762] D loss: 0.0000, G loss: 35.1508\n",
      "[644/1762] D loss: 0.0000, G loss: 28.1237\n",
      "[724/1762] D loss: 0.0000, G loss: 31.6532\n",
      "[804/1762] D loss: 0.0000, G loss: 33.0373\n",
      "[884/1762] D loss: 0.0000, G loss: 29.7371\n",
      "[964/1762] D loss: 0.0000, G loss: 35.1795\n",
      "[1044/1762] D loss: 0.0000, G loss: 31.6873\n",
      "[1124/1762] D loss: 0.0000, G loss: 28.4169\n",
      "[1204/1762] D loss: 0.0000, G loss: 28.9875\n",
      "[1284/1762] D loss: 0.0000, G loss: 29.5928\n",
      "[1364/1762] D loss: 0.0000, G loss: 24.0193\n",
      "[1444/1762] D loss: 0.0000, G loss: 41.2510\n",
      "[1524/1762] D loss: 0.0000, G loss: 36.4713\n",
      "[1604/1762] D loss: 0.0000, G loss: 36.6406\n",
      "[1684/1762] D loss: 0.0000, G loss: 28.0516\n",
      "[1762/1762] D loss: 0.0000, G loss: 34.8273\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 31.795274, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 31.971601, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 35.8081\n",
      "[84/1762] D loss: 0.0000, G loss: 35.2272\n",
      "[164/1762] D loss: 0.0000, G loss: 29.3881\n",
      "[244/1762] D loss: 0.0000, G loss: 27.8012\n",
      "[324/1762] D loss: 0.0000, G loss: 30.2689\n",
      "[404/1762] D loss: 0.0000, G loss: 34.2487\n",
      "[484/1762] D loss: 0.0000, G loss: 32.6599\n",
      "[564/1762] D loss: 0.0000, G loss: 36.1666\n",
      "[644/1762] D loss: 0.0000, G loss: 29.3867\n",
      "[724/1762] D loss: 0.0000, G loss: 29.8950\n",
      "[804/1762] D loss: 0.0000, G loss: 32.8806\n",
      "[884/1762] D loss: 0.0000, G loss: 28.7829\n",
      "[964/1762] D loss: 0.0000, G loss: 30.5519\n",
      "[1044/1762] D loss: 0.0000, G loss: 26.9194\n",
      "[1124/1762] D loss: 0.0000, G loss: 31.5664\n",
      "[1204/1762] D loss: 0.0000, G loss: 32.6430\n",
      "[1284/1762] D loss: 0.0000, G loss: 28.8451\n",
      "[1364/1762] D loss: 0.0000, G loss: 32.1197\n",
      "[1444/1762] D loss: 0.0000, G loss: 32.0533\n",
      "[1524/1762] D loss: 0.0000, G loss: 26.4405\n",
      "[1604/1762] D loss: 0.0000, G loss: 35.5591\n",
      "[1684/1762] D loss: 0.0000, G loss: 28.8751\n",
      "[1762/1762] D loss: 0.0000, G loss: 33.3193\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 31.830752, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 32.003007, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 26.8007\n",
      "[84/1762] D loss: 0.0000, G loss: 30.9607\n",
      "[164/1762] D loss: 0.0000, G loss: 28.0467\n",
      "[244/1762] D loss: 0.0000, G loss: 27.2257\n",
      "[324/1762] D loss: 0.0000, G loss: 31.7113\n",
      "[404/1762] D loss: 0.0000, G loss: 28.5819\n",
      "[484/1762] D loss: 0.0000, G loss: 30.0883\n",
      "[564/1762] D loss: 0.0000, G loss: 26.2174\n",
      "[644/1762] D loss: 0.0000, G loss: 36.0044\n",
      "[724/1762] D loss: 0.0000, G loss: 36.9330\n",
      "[804/1762] D loss: 0.0000, G loss: 32.9662\n",
      "[884/1762] D loss: 0.0000, G loss: 35.3513\n",
      "[964/1762] D loss: 0.0000, G loss: 32.4824\n",
      "[1044/1762] D loss: 0.0000, G loss: 30.3218\n",
      "[1124/1762] D loss: 0.0000, G loss: 31.7391\n",
      "[1204/1762] D loss: 0.0000, G loss: 31.2970\n",
      "[1284/1762] D loss: 0.0000, G loss: 33.2879\n",
      "[1364/1762] D loss: 0.0000, G loss: 32.7298\n",
      "[1444/1762] D loss: 0.0000, G loss: 31.0190\n",
      "[1524/1762] D loss: 0.0000, G loss: 38.2209\n",
      "[1604/1762] D loss: 0.0000, G loss: 32.8106\n",
      "[1684/1762] D loss: 0.0000, G loss: 32.5535\n",
      "[1762/1762] D loss: 0.0000, G loss: 37.3350\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 32.139230, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 32.299911, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 27.6485\n",
      "[84/1762] D loss: 0.0000, G loss: 27.3202\n",
      "[164/1762] D loss: 0.0000, G loss: 28.7498\n",
      "[244/1762] D loss: 0.0000, G loss: 33.4071\n",
      "[324/1762] D loss: 0.0000, G loss: 33.7325\n",
      "[404/1762] D loss: 0.0000, G loss: 35.3332\n",
      "[484/1762] D loss: 0.0000, G loss: 31.0628\n",
      "[564/1762] D loss: 0.0000, G loss: 34.3805\n",
      "[644/1762] D loss: 0.0000, G loss: 32.6780\n",
      "[724/1762] D loss: 0.0000, G loss: 29.7672\n",
      "[804/1762] D loss: 0.0000, G loss: 30.4237\n",
      "[884/1762] D loss: 0.0000, G loss: 32.4697\n",
      "[964/1762] D loss: 0.0000, G loss: 31.7551\n",
      "[1044/1762] D loss: 0.0000, G loss: 29.3527\n",
      "[1124/1762] D loss: 0.0000, G loss: 29.1372\n",
      "[1204/1762] D loss: 0.0000, G loss: 31.4218\n",
      "[1284/1762] D loss: 0.0000, G loss: 34.5101\n",
      "[1364/1762] D loss: 0.0000, G loss: 31.3994\n",
      "[1444/1762] D loss: 0.0000, G loss: 29.4542\n",
      "[1524/1762] D loss: 0.0000, G loss: 29.2731\n",
      "[1604/1762] D loss: 0.0000, G loss: 31.8920\n",
      "[1684/1762] D loss: 0.0000, G loss: 30.4258\n",
      "[1762/1762] D loss: 0.0000, G loss: 25.9024\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 32.501562, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 32.679018, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 30.4100\n",
      "[84/1762] D loss: 0.0000, G loss: 31.8357\n",
      "[164/1762] D loss: 0.0000, G loss: 36.8109\n",
      "[244/1762] D loss: 0.0000, G loss: 32.2238\n",
      "[324/1762] D loss: 0.0000, G loss: 34.8855\n",
      "[404/1762] D loss: 0.0000, G loss: 29.4138\n",
      "[484/1762] D loss: 0.0000, G loss: 28.1842\n",
      "[564/1762] D loss: 0.0000, G loss: 33.3018\n",
      "[644/1762] D loss: 0.0000, G loss: 35.0237\n",
      "[724/1762] D loss: 0.0000, G loss: 31.1348\n",
      "[804/1762] D loss: 0.0000, G loss: 27.9727\n",
      "[884/1762] D loss: 0.0000, G loss: 35.5422\n",
      "[964/1762] D loss: 0.0000, G loss: 34.3163\n",
      "[1044/1762] D loss: 0.0000, G loss: 36.4097\n",
      "[1124/1762] D loss: 0.0000, G loss: 31.5414\n",
      "[1204/1762] D loss: 0.0000, G loss: 30.1310\n",
      "[1284/1762] D loss: 0.0000, G loss: 27.8908\n",
      "[1364/1762] D loss: 0.0000, G loss: 41.7071\n",
      "[1444/1762] D loss: 0.0000, G loss: 31.3867\n",
      "[1524/1762] D loss: 0.0000, G loss: 30.5480\n",
      "[1604/1762] D loss: 0.0000, G loss: 27.1790\n",
      "[1684/1762] D loss: 0.0000, G loss: 33.7353\n",
      "[1762/1762] D loss: 0.0000, G loss: 27.2289\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 32.483697, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 32.652021, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 37.6238\n",
      "[84/1762] D loss: 0.0000, G loss: 30.1133\n",
      "[164/1762] D loss: 0.0000, G loss: 33.7921\n",
      "[244/1762] D loss: 0.0000, G loss: 31.5147\n",
      "[324/1762] D loss: 0.0000, G loss: 34.9887\n",
      "[404/1762] D loss: 0.0000, G loss: 33.1243\n",
      "[484/1762] D loss: 0.0000, G loss: 33.4139\n",
      "[564/1762] D loss: 0.0000, G loss: 25.6467\n",
      "[644/1762] D loss: 0.0000, G loss: 34.2021\n",
      "[724/1762] D loss: 0.0000, G loss: 29.7376\n",
      "[804/1762] D loss: 0.0000, G loss: 34.1631\n",
      "[884/1762] D loss: 0.0000, G loss: 33.3889\n",
      "[964/1762] D loss: 0.0000, G loss: 37.6399\n",
      "[1044/1762] D loss: 0.0000, G loss: 34.0860\n",
      "[1124/1762] D loss: 0.0000, G loss: 33.2265\n",
      "[1204/1762] D loss: 0.0000, G loss: 38.0935\n",
      "[1284/1762] D loss: 0.0000, G loss: 28.5762\n",
      "[1364/1762] D loss: 0.0000, G loss: 33.9463\n",
      "[1444/1762] D loss: 0.0000, G loss: 31.5901\n",
      "[1524/1762] D loss: 0.0000, G loss: 36.5835\n",
      "[1604/1762] D loss: 0.0000, G loss: 36.1324\n",
      "[1684/1762] D loss: 0.0000, G loss: 32.0238\n",
      "[1762/1762] D loss: 0.0000, G loss: 42.0995\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 33.117510, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 33.289184, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 31.7966\n",
      "[84/1762] D loss: 0.0000, G loss: 25.3423\n",
      "[164/1762] D loss: 0.0000, G loss: 36.7903\n",
      "[244/1762] D loss: 0.0000, G loss: 34.9390\n",
      "[324/1762] D loss: 0.0000, G loss: 36.2005\n",
      "[404/1762] D loss: 0.0000, G loss: 32.8924\n",
      "[484/1762] D loss: 0.0000, G loss: 26.9709\n",
      "[564/1762] D loss: 0.0000, G loss: 37.8417\n",
      "[644/1762] D loss: 0.0000, G loss: 31.6706\n",
      "[724/1762] D loss: 0.0000, G loss: 34.8283\n",
      "[804/1762] D loss: 0.0000, G loss: 34.7215\n",
      "[884/1762] D loss: 0.0000, G loss: 39.9305\n",
      "[964/1762] D loss: 0.0000, G loss: 26.5850\n",
      "[1044/1762] D loss: 0.0000, G loss: 31.3150\n",
      "[1124/1762] D loss: 0.0000, G loss: 37.4844\n",
      "[1204/1762] D loss: 0.0000, G loss: 27.6253\n",
      "[1284/1762] D loss: 0.0000, G loss: 29.5862\n",
      "[1364/1762] D loss: 0.0000, G loss: 34.5788\n",
      "[1444/1762] D loss: 0.0000, G loss: 28.5690\n",
      "[1524/1762] D loss: 0.0000, G loss: 26.2248\n",
      "[1604/1762] D loss: 0.0000, G loss: 31.4899\n",
      "[1684/1762] D loss: 0.0000, G loss: 36.0133\n",
      "[1762/1762] D loss: 0.0000, G loss: 26.0140\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 32.594860, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 32.756596, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 26.5996\n",
      "[84/1762] D loss: 0.0000, G loss: 35.6191\n",
      "[164/1762] D loss: 0.0000, G loss: 37.0132\n",
      "[244/1762] D loss: 0.0000, G loss: 30.3745\n",
      "[324/1762] D loss: 0.0000, G loss: 36.1087\n",
      "[404/1762] D loss: 0.0000, G loss: 31.6582\n",
      "[484/1762] D loss: 0.0000, G loss: 27.6194\n",
      "[564/1762] D loss: 0.0000, G loss: 35.6035\n",
      "[644/1762] D loss: 0.0000, G loss: 30.5409\n",
      "[724/1762] D loss: 0.0000, G loss: 34.8718\n",
      "[804/1762] D loss: 0.0000, G loss: 26.8536\n",
      "[884/1762] D loss: 0.0000, G loss: 32.8732\n",
      "[964/1762] D loss: 0.0000, G loss: 28.6231\n",
      "[1044/1762] D loss: 0.0000, G loss: 33.3395\n",
      "[1124/1762] D loss: 0.0000, G loss: 28.5192\n",
      "[1204/1762] D loss: 0.0000, G loss: 33.1606\n",
      "[1284/1762] D loss: 0.0000, G loss: 33.5882\n",
      "[1364/1762] D loss: 0.0000, G loss: 32.1229\n",
      "[1444/1762] D loss: 0.0000, G loss: 33.7314\n",
      "[1524/1762] D loss: 0.0000, G loss: 34.1045\n",
      "[1604/1762] D loss: 0.0000, G loss: 33.3766\n",
      "[1684/1762] D loss: 0.0000, G loss: 30.4264\n",
      "[1762/1762] D loss: 0.0000, G loss: 33.3333\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 33.494878, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 33.674280, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 32.2759\n",
      "[84/1762] D loss: 0.0000, G loss: 32.3424\n",
      "[164/1762] D loss: 0.0000, G loss: 32.3439\n",
      "[244/1762] D loss: 0.0000, G loss: 27.9024\n",
      "[324/1762] D loss: 0.0000, G loss: 35.0927\n",
      "[404/1762] D loss: 0.0000, G loss: 37.6430\n",
      "[484/1762] D loss: 0.0000, G loss: 39.8313\n",
      "[564/1762] D loss: 0.0000, G loss: 34.0995\n",
      "[644/1762] D loss: 0.0000, G loss: 33.3257\n",
      "[724/1762] D loss: 0.0000, G loss: 31.6425\n",
      "[804/1762] D loss: 0.0000, G loss: 30.7169\n",
      "[884/1762] D loss: 0.0000, G loss: 35.4923\n",
      "[964/1762] D loss: 0.0000, G loss: 41.1277\n",
      "[1044/1762] D loss: 0.0000, G loss: 28.7095\n",
      "[1124/1762] D loss: 0.0000, G loss: 32.1937\n",
      "[1204/1762] D loss: 0.0000, G loss: 35.9333\n",
      "[1284/1762] D loss: 0.0000, G loss: 28.7230\n",
      "[1364/1762] D loss: 0.0000, G loss: 34.6535\n",
      "[1444/1762] D loss: 0.0000, G loss: 34.8695\n",
      "[1524/1762] D loss: 0.0000, G loss: 35.6208\n",
      "[1604/1762] D loss: 0.0000, G loss: 33.0220\n",
      "[1684/1762] D loss: 0.0000, G loss: 35.2412\n",
      "[1762/1762] D loss: 0.0000, G loss: 34.6095\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 33.664436, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 33.833140, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 32.3410\n",
      "[84/1762] D loss: 0.0000, G loss: 31.5692\n",
      "[164/1762] D loss: 0.0000, G loss: 39.9907\n",
      "[244/1762] D loss: 0.0000, G loss: 39.2344\n",
      "[324/1762] D loss: 0.0000, G loss: 35.7609\n",
      "[404/1762] D loss: 0.0000, G loss: 37.7545\n",
      "[484/1762] D loss: 0.0000, G loss: 27.0865\n",
      "[564/1762] D loss: 0.0000, G loss: 36.9933\n",
      "[644/1762] D loss: 0.0000, G loss: 32.7963\n",
      "[724/1762] D loss: 0.0000, G loss: 36.2423\n",
      "[804/1762] D loss: 0.0000, G loss: 28.8361\n",
      "[884/1762] D loss: 0.0000, G loss: 27.2858\n",
      "[964/1762] D loss: 0.0000, G loss: 34.0289\n",
      "[1044/1762] D loss: 0.0000, G loss: 32.0465\n",
      "[1124/1762] D loss: 0.0000, G loss: 34.1849\n",
      "[1204/1762] D loss: 0.0000, G loss: 34.8911\n",
      "[1284/1762] D loss: 0.0000, G loss: 29.6463\n",
      "[1364/1762] D loss: 0.0000, G loss: 33.8854\n",
      "[1444/1762] D loss: 0.0000, G loss: 31.5219\n",
      "[1524/1762] D loss: 0.0000, G loss: 35.8210\n",
      "[1604/1762] D loss: 0.0000, G loss: 40.7792\n",
      "[1684/1762] D loss: 0.0000, G loss: 32.4154\n",
      "[1762/1762] D loss: 0.0000, G loss: 30.7359\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 33.178534, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 33.357109, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 31.8848\n",
      "[84/1762] D loss: 0.0000, G loss: 39.7201\n",
      "[164/1762] D loss: 0.0000, G loss: 33.3784\n",
      "[244/1762] D loss: 0.0000, G loss: 28.0789\n",
      "[324/1762] D loss: 0.0000, G loss: 31.8092\n",
      "[404/1762] D loss: 0.0000, G loss: 32.3846\n",
      "[484/1762] D loss: 0.0000, G loss: 35.8459\n",
      "[564/1762] D loss: 0.0000, G loss: 29.8562\n",
      "[644/1762] D loss: 0.0000, G loss: 36.5709\n",
      "[724/1762] D loss: 0.0000, G loss: 35.2696\n",
      "[804/1762] D loss: 0.0000, G loss: 34.6278\n",
      "[884/1762] D loss: 0.0000, G loss: 32.9980\n",
      "[964/1762] D loss: 0.0000, G loss: 31.3037\n",
      "[1044/1762] D loss: 0.0000, G loss: 36.4909\n",
      "[1124/1762] D loss: 0.0000, G loss: 31.4329\n",
      "[1204/1762] D loss: 0.0000, G loss: 30.2802\n",
      "[1284/1762] D loss: 0.0000, G loss: 37.0372\n",
      "[1364/1762] D loss: 0.0000, G loss: 35.4903\n",
      "[1444/1762] D loss: 0.0000, G loss: 38.0843\n",
      "[1524/1762] D loss: 0.0000, G loss: 35.3032\n",
      "[1604/1762] D loss: 0.0000, G loss: 34.1347\n",
      "[1684/1762] D loss: 0.0000, G loss: 29.3365\n",
      "[1762/1762] D loss: 0.0000, G loss: 28.7390\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 34.713190, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 34.900134, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 37.9644\n",
      "[84/1762] D loss: 0.0000, G loss: 36.8575\n",
      "[164/1762] D loss: 0.0000, G loss: 39.2360\n",
      "[244/1762] D loss: 0.0000, G loss: 33.0385\n",
      "[324/1762] D loss: 0.0000, G loss: 36.3373\n",
      "[404/1762] D loss: 0.0000, G loss: 30.8500\n",
      "[484/1762] D loss: 0.0000, G loss: 35.2588\n",
      "[564/1762] D loss: 0.0000, G loss: 33.6933\n",
      "[644/1762] D loss: 0.0000, G loss: 38.0892\n",
      "[724/1762] D loss: 0.0000, G loss: 34.2282\n",
      "[804/1762] D loss: 0.0000, G loss: 39.6547\n",
      "[884/1762] D loss: 0.0000, G loss: 33.0523\n",
      "[964/1762] D loss: 0.0000, G loss: 37.1944\n",
      "[1044/1762] D loss: 0.0000, G loss: 36.0624\n",
      "[1124/1762] D loss: 0.0000, G loss: 36.6955\n",
      "[1204/1762] D loss: 0.0000, G loss: 35.2504\n",
      "[1284/1762] D loss: 0.0000, G loss: 34.3959\n",
      "[1364/1762] D loss: 0.0000, G loss: 33.3077\n",
      "[1444/1762] D loss: 0.0000, G loss: 36.2285\n",
      "[1524/1762] D loss: 0.0000, G loss: 33.5726\n",
      "[1604/1762] D loss: 0.0000, G loss: 35.4805\n",
      "[1684/1762] D loss: 0.0000, G loss: 34.4052\n",
      "[1762/1762] D loss: 0.0000, G loss: 31.9115\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 34.434790, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 34.621977, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 35.1847\n",
      "[84/1762] D loss: 0.0000, G loss: 35.4009\n",
      "[164/1762] D loss: 0.0000, G loss: 34.7432\n",
      "[244/1762] D loss: 0.0000, G loss: 36.1541\n",
      "[324/1762] D loss: 0.0000, G loss: 35.3847\n",
      "[404/1762] D loss: 0.0000, G loss: 31.0937\n",
      "[484/1762] D loss: 0.0000, G loss: 39.3705\n",
      "[564/1762] D loss: 0.0000, G loss: 34.5877\n",
      "[644/1762] D loss: 0.0000, G loss: 39.6020\n",
      "[724/1762] D loss: 0.0000, G loss: 36.8396\n",
      "[804/1762] D loss: 0.0000, G loss: 39.4091\n",
      "[884/1762] D loss: 0.0000, G loss: 33.4340\n",
      "[964/1762] D loss: 0.0000, G loss: 41.3668\n",
      "[1044/1762] D loss: 0.0000, G loss: 30.9689\n",
      "[1124/1762] D loss: 0.0000, G loss: 33.9976\n",
      "[1204/1762] D loss: 0.0000, G loss: 37.5687\n",
      "[1284/1762] D loss: 0.0000, G loss: 34.4682\n",
      "[1364/1762] D loss: 0.0000, G loss: 40.2674\n",
      "[1444/1762] D loss: 0.0000, G loss: 30.0824\n",
      "[1524/1762] D loss: 0.0000, G loss: 27.4110\n",
      "[1604/1762] D loss: 0.0000, G loss: 33.7398\n",
      "[1684/1762] D loss: 0.0000, G loss: 42.9887\n",
      "[1762/1762] D loss: 0.0000, G loss: 37.1263\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 35.092244, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 35.278566, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 33.0581\n",
      "[84/1762] D loss: 0.0000, G loss: 34.1517\n",
      "[164/1762] D loss: 0.0000, G loss: 36.8888\n",
      "[244/1762] D loss: 0.0000, G loss: 39.0433\n",
      "[324/1762] D loss: 0.0000, G loss: 36.5023\n",
      "[404/1762] D loss: 0.0000, G loss: 35.2389\n",
      "[484/1762] D loss: 0.0000, G loss: 27.9690\n",
      "[564/1762] D loss: 0.0000, G loss: 29.9612\n",
      "[644/1762] D loss: 0.0000, G loss: 32.5430\n",
      "[724/1762] D loss: 0.0000, G loss: 40.4298\n",
      "[804/1762] D loss: 0.0000, G loss: 28.4851\n",
      "[884/1762] D loss: 0.0000, G loss: 37.9718\n",
      "[964/1762] D loss: 0.0000, G loss: 33.4855\n",
      "[1044/1762] D loss: 0.0000, G loss: 33.3160\n",
      "[1124/1762] D loss: 0.0000, G loss: 33.7599\n",
      "[1204/1762] D loss: 0.0000, G loss: 38.7843\n",
      "[1284/1762] D loss: 0.0000, G loss: 33.9223\n",
      "[1364/1762] D loss: 0.0000, G loss: 40.9877\n",
      "[1444/1762] D loss: 0.0000, G loss: 31.9700\n",
      "[1524/1762] D loss: 0.0000, G loss: 36.4224\n",
      "[1604/1762] D loss: 0.0000, G loss: 39.7780\n",
      "[1684/1762] D loss: 0.0000, G loss: 35.1729\n",
      "[1762/1762] D loss: 0.0000, G loss: 35.9228\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 36.171094, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 36.356859, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 33.7000\n",
      "[84/1762] D loss: 0.0000, G loss: 40.9600\n",
      "[164/1762] D loss: 0.0000, G loss: 36.2413\n",
      "[244/1762] D loss: 0.0000, G loss: 45.1356\n",
      "[324/1762] D loss: 0.0000, G loss: 39.6948\n",
      "[404/1762] D loss: 0.0000, G loss: 41.9689\n",
      "[484/1762] D loss: 0.0000, G loss: 37.6449\n",
      "[564/1762] D loss: 0.0000, G loss: 34.7497\n",
      "[644/1762] D loss: 0.0000, G loss: 29.6339\n",
      "[724/1762] D loss: 0.0000, G loss: 37.6216\n",
      "[804/1762] D loss: 0.0000, G loss: 36.5071\n",
      "[884/1762] D loss: 0.0000, G loss: 30.8700\n",
      "[964/1762] D loss: 0.0000, G loss: 39.5118\n",
      "[1044/1762] D loss: 0.0000, G loss: 43.5709\n",
      "[1124/1762] D loss: 0.0000, G loss: 32.3614\n",
      "[1204/1762] D loss: 0.0000, G loss: 33.7249\n",
      "[1284/1762] D loss: 0.0000, G loss: 34.6227\n",
      "[1364/1762] D loss: 0.0000, G loss: 37.3939\n",
      "[1444/1762] D loss: 0.0000, G loss: 35.8724\n",
      "[1524/1762] D loss: 0.0000, G loss: 32.2204\n",
      "[1604/1762] D loss: 0.0000, G loss: 33.9658\n",
      "[1684/1762] D loss: 0.0000, G loss: 35.1145\n",
      "[1762/1762] D loss: 0.0000, G loss: 36.8523\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 36.054661, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 36.234310, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 32.9373\n",
      "[84/1762] D loss: 0.0000, G loss: 37.1674\n",
      "[164/1762] D loss: 0.0000, G loss: 42.7103\n",
      "[244/1762] D loss: 0.0000, G loss: 32.4525\n",
      "[324/1762] D loss: 0.0000, G loss: 34.5058\n",
      "[404/1762] D loss: 0.0000, G loss: 34.8035\n",
      "[484/1762] D loss: 0.0000, G loss: 30.9395\n",
      "[564/1762] D loss: 0.0000, G loss: 37.4832\n",
      "[644/1762] D loss: 0.0000, G loss: 32.4658\n",
      "[724/1762] D loss: 0.0000, G loss: 33.0621\n",
      "[804/1762] D loss: 0.0000, G loss: 37.8717\n",
      "[884/1762] D loss: 0.0000, G loss: 32.2876\n",
      "[964/1762] D loss: 0.0000, G loss: 33.8453\n",
      "[1044/1762] D loss: 0.0000, G loss: 31.3427\n",
      "[1124/1762] D loss: 0.0000, G loss: 29.7185\n",
      "[1204/1762] D loss: 0.0000, G loss: 33.9546\n",
      "[1284/1762] D loss: 0.0000, G loss: 35.6407\n",
      "[1364/1762] D loss: 0.0000, G loss: 35.3619\n",
      "[1444/1762] D loss: 0.0000, G loss: 37.5038\n",
      "[1524/1762] D loss: 0.0000, G loss: 33.9650\n",
      "[1604/1762] D loss: 0.0000, G loss: 34.4062\n",
      "[1684/1762] D loss: 0.0000, G loss: 31.0497\n",
      "[1762/1762] D loss: 0.0000, G loss: 38.4352\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 35.956698, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 36.143922, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "[4/1762] D loss: 0.0000, G loss: 37.9309\n",
      "[84/1762] D loss: 0.0000, G loss: 32.0428\n",
      "[164/1762] D loss: 0.0000, G loss: 33.4952\n",
      "[244/1762] D loss: 0.0000, G loss: 37.0778\n",
      "[324/1762] D loss: 0.0000, G loss: 34.2455\n",
      "[404/1762] D loss: 0.0000, G loss: 37.3337\n",
      "[484/1762] D loss: 0.0000, G loss: 35.1471\n",
      "[564/1762] D loss: 0.0000, G loss: 36.2391\n",
      "[644/1762] D loss: 0.0000, G loss: 33.4449\n",
      "[724/1762] D loss: 0.0000, G loss: 33.9073\n",
      "[804/1762] D loss: 0.0000, G loss: 36.6969\n",
      "[884/1762] D loss: 0.0000, G loss: 36.8828\n",
      "[964/1762] D loss: 0.0000, G loss: 37.6889\n",
      "[1044/1762] D loss: 0.0000, G loss: 39.1376\n",
      "[1124/1762] D loss: 0.0000, G loss: 36.9404\n",
      "[1204/1762] D loss: 0.0000, G loss: 33.8550\n",
      "[1284/1762] D loss: 0.0000, G loss: 33.2940\n",
      "[1364/1762] D loss: 0.0000, G loss: 40.6210\n",
      "[1444/1762] D loss: 0.0000, G loss: 38.4688\n",
      "[1524/1762] D loss: 0.0000, G loss: 38.7658\n",
      "[1604/1762] D loss: 0.0000, G loss: 34.5608\n",
      "[1684/1762] D loss: 0.0000, G loss: 38.3436\n",
      "[1762/1762] D loss: 0.0000, G loss: 33.1622\n",
      "train error: \n",
      " D loss: 0.000000, G loss: 35.885064, D accuracy: 100.0%, cell accuracy: 91.5%, board accuracy: 0.0% \n",
      "\n",
      "test error: \n",
      " D loss: 0.000000, G loss: 36.072266, D accuracy: 100.0%, cell accuracy: 91.4%, board accuracy: 0.0% \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    for cls in [GenWithLessBatchNorm, GenWithNoBatchNorm]:\n",
    "        train(run_name=cls.__name__, gen_cls=cls)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing the batch normalization seems to stabilise the board accuracy over short intervals of epochs, but the model gets stuck in local minima much more easily and on one run it didn't even go above 0% board accuracy."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Removing batch normalization from the generator makes the training process worse and we should keep the batch normalization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
